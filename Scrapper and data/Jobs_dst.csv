,Job Title,Job Description,Rating,Company Name,Location,Headquarters,Size,Founded,Type of ownership,Industry,Sector,Revenue,Competitors
0,Data Scientist,"Job Description – Data Scientist

Location: Chennai or Bengaluru, India


Buckman is a privately held, global specialty chemical company with headquarters in Memphis, TN, USA, committed to safeguarding the environment, maintaining safety in the workplace, and promoting sustainable development. Buckman works proactively and collaboratively with its worldwide customers in pulp and paper, leather, and water treatment to deliver exceptional service and innovative specialty chemical solutions to help boost productivity, reduce risk, improve product quality, and provide a measurable return on investment. Buckman is in the middle of a digital transformation of its businesses and focused on building the capabilities and tools in support of this.

Job Description


Buckman is seeking an experienced Data Scientist to lead the development of a Data Science program. You will work closely with Buckman stakeholders to derive deep industry knowledge across paper, water, leather, and performance chemical industries. You will help develop a data strategy for the company including collection of the right data, creation of the data science project portfolio, partnering with external providers, and augmenting capabilities with additional internal hires. A large part of the job is communicating and developing relationship with key stakeholders and subject matter experts to tee up proofs of concept projects to demonstrate how data science can be used to solve old problems in unique and novel ways. You will not have a large internal team to rely on, at least initially, so individual expertise, breadth of data science knowledge, and ability to partner with external companies will be essential for success. In addition to the pure data science problems, you will be working closely with a multi-disciplinary team consisting of sensor scientists, software engineers, network engineers, mechanical/electrical engineers, and chemical engineers in the development, and deployment of IoT solutions. If you like working for an entrepreneurial company with a Sustainability mission and digital ambitions at the core of its strategy, Buckman is the place for you.

Basic Qualifications
Bachelor’s degree in a quantitative field such as Data Science, Statistics, Applied Mathematics, Physics, Engineering, or Computer Science
5+ years of relevant working experience in an analytical role involving data extraction, analysis, and visualization and expertise in the following areas:
Expertise in one or more programming languages R, Python, MATLAB, JMP, Minitab, Java, C++, Scala
Key libraries such as Sklearn, XgBoost, GLMNet, Dplyr, ggplot, Rshiny
Experience and knowledge of data mining algorithms including supervised and unsupervised machine learning techniques areas such as Gradient Boosting, Decision Trees, Multivariate Regressions, Logistic regressions, Neural Network, Random Forest, Support Vector Machine, Naive Bayes, Time Series, Optimization
Microsoft IoT/data science toolkit: Azure Machine Learning, Datalake, Datalake analytics, Workbench, IoT Hub, Stream Analytics, CosmosDB, Time Series Insights, PowerBI
Data querying languages (e.g. SQL, Hadoop/Hive) and Preferred Qualifications
A demonstrated record of success with a verifiable portfolio of problems tackled
Preferred qualifications
Master’s or PhD degree in a quantitative field such as Data Science, Statistics, Applied Mathematics, Physics, Engineering, or Computer Science
Experience in the specialty chemicals sector or similar industry
Background in engineering, especially Chemical Engineering
Experience starting up a data science program
Experience working with global stakeholders
Experience working in a start-up environment, preferably in an IoT company
Knowledge in quantitative modeling tools and statistical analysis
Personality Traits
A strong business focus, ownership and inner self-drive to data science solutions to real-world customers with tangible impact.
Ability to collaborate effectively with multi-disciplinary and passionate team members.
Ability to communicate with a diverse set of stakeholders
Strong planning and organization skills, with the ability to manage multiple complex projects
A life-long learner who constantly updates skills",3.5,"Buckman
3.5",Chennai,"Memphis, TN",1001 to 5000 employees,1945,Company - Private,Chemical Manufacturing,Manufacturing,₹50 to ₹100 billion (INR),-1
1,Data Scientist,"Introduction
• The role will involve running workshops to define the problem statement, identifying the data that is required, cleaning up the data, running feature engineering techniques and building / testing ML/DL models. A combination of one of more of IBM AI technologies from the Watson portfolio, Open Source and 3rd Party technologies will be used to be deliver the required outcomes.

Your Role and Responsibilities
The responsibility of a Data Scientists will include working with Sales, Tech Sales & IBM Clients to define an approach to Machine/Deep Learning problems, building the models and delivering them.
Required Technical and Professional Expertise
Python - 3-5 Years
Machine learning Model (Regression, Classification, Unsupervised techniques, ensemble modeling) - 2-3 Years (Mtech) / 0-1 Years (PhD)
Deep Learning models (Image, NLP, Structured data) - 1-2 Years (Mtech) / 0-1 Years (PhD)
Tech Sales, Sellers, Architects
Cloud native technologies
Agile development
Preferred Technical and Professional Expertise
Specialisation in any of the following fields - NLP, NLU, NLG, Computer Vision, Facial Recognition - 0-2 Years
Good communication
Active listener
About Business Unit
IBM has a global presence, operating in more than 175 countries with a broad-based geographic distribution of revenue. The companys Global Markets organization is a strategic sales business unit that manages IBMs global footprint, working closely with dedicated country-based operating units to serve clients locally. These country teams have client relationship managers who lead integrated teams of consultants, solution specialists and delivery professionals to enable clients growth and innovation. By complementing local expertise with global experience and digital capabilities, IBM builds deep and broad-based client relationships. This local management focus fosters speed in supporting clients, addressing new markets and making investments in emerging opportunities. Additionally, the Global Markets organization serves clients with expertise in their industry as well as through the products and services that IBM and partners supply. IBM is also expanding its reach to new and existing clients through digital marketplaces.

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Gurgaon,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
2,Data Scientist,"Driving Infinite Possibilities Within A Diversified, Global Organization


Data Scientist

Were looking for a new
team member who is motivated by cracking tough challenges with data, trained in
problem solving, and with an unending thirst for learning.
As a Data Scientist, you
will join a high-performing, global team, and assist with designing,
developing, and deploying data driven solutions for all Honeywell business
groups and functions. You will work closely with application architects to
integrate results into operational platforms, including Hadoop and NoSQL
architectures.
Additionally, the Data
Scientist role is expected to work within Honeywell to identify opportunities
for new growth and efficiencies based on data analyses both in adjacencies
based on previous engagements, as well as larger industry developments.
Specific Responsibilities
Develop data analytics, data modeling, mining,
pattern analysis, data visualization and machine learning solutions to address
customer needs
Foster relationships with business
team members by being proactive, displaying a thorough understanding of the
business processes and by recommending innovative solutions
Communicate project output in terms of
customer value, business objectives, and product opportunity
Promote data
science methods and processes across functions
Work with our businesses and
infrastructure teams to develop a strategy that will clearly outline how our
enterprise platforms can enable business growth & productivity and discover
efficiencies to drive costs out of the ISC.

CORPIT2020

You must have:

· Bachelors degree in Computer Science, Engineering, Applied Mathematics or related field

· Minimum of 4 years of experience with distributed storage and compute tools (e.g. Hive and Spark)
6-8 years of experience within Analytics
Experience with data visualization, Tableau preferred.
Understanding of machine learning techniques and algorithms, such as k-NN, Logistic/Linear Regression, Naive Bayes, SVM, Decision Forests, etc.
Knowledge of cloud platforms AWS, Google Cloud, Azure, SnowFlake
Strong knowledge of SQL, Python/R, query optimization and DBMS concepts
Advanced knowledge of excel
Strong analytical skills with an inherent ability to find, understand and work with large amounts of data.
We value:

· Experience bringing prototypes to production on Hadoop platforms and/or as containerized services
Experience with SAP HANA, Snowflake, Redshift and Tableau
· Experience with Streaming Analytics (i.e. Spark Streaming)

· Experience with Natural Language Processing

· Experience working with global teams

· Results driven with a positive can-do attitude.

· Thrives in a rapidly changing environment.

Additional Information
JOB ID: HRD94048
Category: Information Technology
Location: Devarabisanahalli Village, KR Varturhobli,,East Taluk - Phase I,Bangalore,KARNATAKA,560103,India
Exempt
Business Services",3.8,"Honeywell
3.8",Bengaluru,"Charlotte, NC",10000+ employees,1885,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"GE, Johnson Controls, United Technologies"
3,Data Scientist,"At Amazon, we strive to be most customer-centric company on the earth. To get there, we need exceptionally talented, bright, dynamic and driven people to develop the next-generation technologies.
Are you champion of innovating on behalf of the customer by turning data insights into action? Do you want to be part of Amazons strategic and highly impactful finance and payroll technology projects? Amazons Finance Automation Payroll Tech team has an opportunity for a seasoned Data Scientist whose experience illustrates a clear ability to create world class machine learning systems to meet long-term Payroll needs.

At Finance Automation, we are passionate about building systems and services that deliver a seamless and transparent finance experience for Amazon partners. We build, operate, and scale systems that are responsible for billions of dollars in transactions, and are central to the success of worldwide finance. We ""think globally, act locally"" to revolutionize a worldwide employee and customer experience and fulfill our promise to pay accurately, on-time, with lowest cost to Amazon.

As a Data Scientist at Finance Automation, you are self-driven leader with extensive experience in applying statistics and data science concepts to bring tangible benefits for global finance operations. Finance and Payroll domain knowledge is a plus but not required.

· Work with finance and payroll stakeholders to understand the organization goals, objectives, and pain points. Identify key areas to drive Machine Learning initiatives, define needle-moving business questions and success criteria.
· Collect and analyze finance, HR, and payroll data across multiple isolated systems. Derive actionable insights from large volumes of heterogeneous data.
· Create reliable and maintainable code to build regression, classification, clustering, and anomaly detection systems. Work closely with software engineers to develop data ingestion and visualization, and productionize your models.
· Partner with finance analysts, and payroll managers to deploy and test machine learning systems with your statistical models at the core. Automate feedback loops, tune, and improve the models in production.
· Train non-tech stakeholders and partners to effectively use your machine learning systems. Set the right expectations on model limitations and prove business value.
· Create and maintain business and technical artifacts such as requirements documentation, use cases, performance evaluation, and model metrics.
· Learn and utilize AWS technologies and Amazon machine learning systems to effectively work with terabytes of data.

Being part of Amazon Finance Automation gives you the opportunity to work in a rapidly growing organization with many high performing global technology teams. Come join us in making history!




Basic Qualifications

· Bachelor's or Masters degree in Statistics, Applied Math, Operations Research, Economics, Engineering or a related quantitative field with 5 years of working experience as a Data Scientist.
· In-depth knowledge on supervised and unsupervised machine learning algorithms including classification, clustering, and regression.
· Experience building productions systems with statistical analysis, data modeling, regression modeling and forecasting, time series analysis, and deep learning neural networks.
· Expertise in coding using one or more programming languages such as R, Python, MATLAB, and Spark to build machine learning models. Skilled in manipulating and processing data using libraries such as Scikit-learn, Pandas, and NumPy. Demonstrated experience in SQL and/or NoSQL data modeling.
· Experience processing, filtering, and presenting large quantities of data. Ability to design for performance, scalability, and availability.
· Excellent communication, analytical and problem-solving skills. Ability to distill informal customer requirements into problem definitions, dealing with ambiguity and competing objectives.
· Obsession with quality, operational excellence, and customer experience. Ability to convey rigorous mathematical concepts and considerations to non-experts.

Preferred Qualifications

· Passion to dive deep to resolve problems at their root, looking for failure patterns amenable to long-term solutions via simplification and automation.
· Experience in AWS is a huge plus. Functional knowledge of AWS platforms such as Sagemaker, S3, Glue, Dynamodb, and RedShift.
· Exposure to finance and payments domain is a plus.
· Deep understanding of data, application, server, and network security.
· Experience with agile or scrum methodology.",4.2,"Amazon
4.2",Hyderabad,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
4,Data Scientist,"Provide analytical insights into emerging problems, trends and portfolios
Work closely with business partners and stakeholders to determine how to design analysis and measurement approaches that will significantly improve our ability to understand and address emerging business issues
Bringing data to life and making it actionable and relevant to stakeholders through exploratory analysis of internal and external data sources using advanced and innovative analytical techniques, algorithms, and tools
Identifying present or future gaps in the teams existing reporting and tools suite and managing portfolio monitoring, dashboards and reporting
Providing regular updates to leadership, product and other stakeholders that will simplify and clarify complex concepts and the results of analyses effectively with emphasis on the actionable outcomes and impact to business
Experience with standard statistical techniques and tools a plus
Required Qualifications
Bachelor's Degree in a quantitative discipline (Economics, Engineering, Computer Science, Math, Statistics)
1-2 years experience in analytics or management consulting
Proficiency using SQL and querying relational databases
Experience in at least one statistical programming language (SAS, R, Python)
Experience in at least one data visualization tool (Tableau, Qlikview)
Experience with project management
Preferred Skills:
Strong communication skills
Quick learning
Out-of-box Problem Solving",3.6,"PayPal
3.6",Bengaluru,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple"
5,Data Scientist,"What You Should Expect

To ride the wave of AI/ML with deeply enmeshed Operations Research and Mathematics to make real impact in the world of Supply Chain Planning, Retail and Execution.

What your work will be

» Develop and operate solutions that optimize and automate business decisions using large data sets and algorithms

» Work with complex data analysis, data preparation and developing prognostic models based on modern statistical methods

» Develop a deep understanding of retail and supply chain problems

» Write productive software that generates value for our customers

Apply if you have

» Good understanding and insight of Machine Learning Techniques – Supervised, Unsupervised or Semi-Supervised

» Passion for writing software with emphasis on quality, testability and automation

» Experience in building machine learning models or optimization software to solve business problems

» Ability to communicate and contextualize results

We believe that the individuality and diversity of our employees make a decisive

contribution to our success. Our hiring process is based on qualifications and career profile.

Our Values

If you want to know the heart of a company, take a look at their values. Ours unite us. They are what drive our success – and the success of our customers. Does your heart beat like ours? Find out here: Core Values

Check out JDA's blog - Supply Chain Nation - the platform for supply chain trends and innovations.",4.3,"Blue Yonder
4.3",Bengaluru,"Scottsdale, AZ",5001 to 10000 employees,1985,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 billion (INR),"SAP, Oracle, Manhattan Associates"
6,Data Scientist,"Overview


We have an exciting opportunity for a Data Scientist to join our dynamic AI Development team. This permanent position is well suited to an individual that is looking to advance their career in Python / R / Java Programming and gain hands-on experience in a thriving and supportive workplace.

Responsibilities


Objectives: 
Primary focus on applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.
Ability to manage time and follow guidelines and processes.
Procedures: 
Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.
 Selecting features, building and optimizing classifiers using machine learning techniques
 Once the data source has been identified, mine and analyse data to drive optimization and improvement of product development, marketing techniques and business strategies.
 Enhancing data collection procedures to include information that is relevant for building analytic systems
 Design and review data collection procedures for regulatory compliance.
 Develop custom data models and algorithms to apply to data sets.
 Present information using data visualization techniques
 Propose solutions and strategies to business challenges
 Collaborate with SAS programming and Statistics teams
 Develop company A/B testing framework and test model quality.
 Develop processes and tools to monitor and analyse model performance and data accuracy.
 Raise awareness with other team on Data Science techniques and approaches.
 Have a good understanding of ICH/GCP guidelines.
 Follow appropriate Project Management procedures.
 Communicate effectively with project team.
Key Contacts/Relationships (Internal & External):

Internal:Work closely with other project team members, mentor and line manager.

External:Under supervision, may have limited interaction with internal clients to complete various programming activities. To fulfil this role, the Data Scientist supported by AI team members, may be required to participate in project team meetings and be responsive on an ad-hoc basis.

Qualifications
Qualified to degree level or equivalent, preferably in a numerate discipline
Good knowledge on statistics.
5 years of experience on Programming / Data Science Industry and minimum 2 year as Data Scientist",4.0,"Quanticate
4.0",Bengaluru,"Hitchin, United Kingdom",201 to 500 employees,1995,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹1 to ₹5 billion (INR),"GCE Solutions, Parexel, IQVIA"
7,Data Scientist,"Essential Day-to-Day Responsibilities:

Data handling, data processing and programming
Developing automated solutions for sourcing/loading Legal entity data onto DB
Analysis of Legal entity Content and trends
Develop, improve and run quantitative models
Work with business, content and product groups for large-scale analytics problems
Builds POCs, visualizations and pipeline tools for product design and development
Works with development groups for deployment of analytics solutions
Interacts with other internal teams as needed, with supervision.
Qualification:
Higher education in economics, statistics, mathematics, physics or engineering
Impressive benefits? Of course.

We support our colleagues health and wellbeing with inclusive benefits. So that's support for physical, financial, mental and environmental health, paid time off to volunteer, consumer discounts& savings and so much more. All of which are tailored to your needs and may vary by location. For more details talk to your recruiter.

As a global business, Refinitiv relies on diversity of culture and thought to deliver on our goals. Therefore we seek hardworking, qualified employees in all our operations around the worldregardless of race, color, sex/gender, including pregnancy, gender identity and expression, national origin, religion, sexual orientation, disability, age, marital status, citizen status, veteran status, or any other protected classification under country or local law. Refinitiv is proud to be an Equal Employment Opportunity/Affirmative Action Employer providing a drug-free workplace.

Refinitiv makes reasonable accommodations for applicants and employees with disabilities. If an accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact us to request an accommodation. A full list of our office locations and contact information can be found at: Refinitiv Office Locations.

Be the breakthrough, activate your future and shape ours.",3.5,"Refinitiv
3.5",Bengaluru,"London, United Kingdom",10000+ employees,2018,Company - Private,Computer Hardware & Software,Information Technology,₹500+ billion (INR),-1
8,Data Scientist,"Senior Data Scientist

Responsibilities
Conduct large-scale data analysis and develop fraud prevention predictive models for financial institutions.
Mine and analyze data to drive optimization and improvement of product development and business strategies.
Maintain and analyze information about multiple clients’ models, to derive insights for clients and for enhancing risk model performance.
Help maintain and improve model development tools.
Take part in the formation of a new team and help setup practices and processes.


Qualifications
Advanced degree in a quantitative area (statistics, mathematics, physics, computer science, engineering)
Experience of 4-7 years with statistical model development. Deep and diverse experience with multiple statistical procedures and machine learning algorithms.
Strong general analytical skills, agility with using quantitative tools to solve analytical problems
Good oral and written communications skills, and ability to interact with engineers, software developers, project managers, business analysts, product managers and with clients.
Vast experience using SQL and modeling with Python.
Innovative aptitude and can-do approach.",3.9,"NICE Actimize
3.9",Pune,"Hoboken, NJ",501 to 1000 employees,1999,Subsidiary or Business Segment,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"SAS, Feedzai"
9,Junior Data Analyst,"Role: Junior Data Analyst

Location: Gurgaon, India

GroundTruth is the leading global location platform that leverages data and insights to drive business performance. Using its proprietary Blueprints technology, GroundTruth is able to learn about mobile users and reach them at the right place and right time, ultimately helping companies make smarter marketing decisions, increase sales, and grow their businesses. Since its foundation in 2009, GroundTruth has launched several innovative products and won numerous awards, including Inc. 5000s Fast Growing Private Companies and Deloitte's Fast 500 Technology companies. Today, we're proud to employ over 400 employees across three continents and serve millions of marketers across 21 countries. Learn more: www.groundtruth.com

This will be an exciting and challenging role that will enable you to work with very large data sets, expose you to cutting edge analysis techniques, work with the latest components in cloud architecture and gain experience in the usage of location data to drive businesses. As an early member you will have significant opportunities for growth within the organization. A successful applicant will be passionate about technology and developing a deep understanding of human behavior in the real world. They would also have excellent communication skills, be able to synthesize and present complex information and be a fast learner.

You will:

• Learn about location-driven marketing and how companies are using location signals to drive their business

• Work closely with marketing, growth strategy and sales teams based out of our offices in USA, UK, Germany

• Develop re-usable tools and templates to quickly create data driven narratives

• Gather requirements, design analyses, identify data sources and define measurement metrics to present insights and recommendations for ready consumption

• Be responsible for managing your work pipeline and creating re-usable analysis and documentation

You have:

• BA/BSc/B.E./BTech degree in Computer Science, Statistics, Mathematics, Economics, Physics or related fields

• 1-2 years of experience in working with data and conducting statistical and/or numerical analysis

• Strong understanding of how data can be stored and accessed in different structures

• Experience with writing computer programs to solve problems

• Strong understanding of data operations such as sub-setting, sorting, merging, aggregating and CRUD operations

• Ability to write SQL code and familiarity with R/Python, Linux shell commands

• Be willing and able to quickly learn about new businesses, database technologies and analysis techniques

• Ability to tell a good story and support it with numbers and visuals

• Strong oral and written communication

•

How you can impress us:

• Experience working with large datasets

• Experience with AWS analytics infrastructure (Redshift, S3, Athena, Boto3)

• Experience building analytics applications leveraging R, Python, Tableau, Looker or other • Experience in geo-spatial analysis with POSTGIS, QGIS

We operate in a fast paced, dynamic environment where everyone on the team is committed to the success and growth of GroundTruth. Our culture is highly entrepreneurial and our success comes from our employees who voice their opinions and ideas to facilitate growth to our bottom line. We reward hard work, support career development, offer comprehensive benefits, and foster a fun and friendly work environment.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status",3.3,"GroundTruth
3.3",Gurgaon,"New York, NY",201 to 500 employees,2009,Company - Private,-1,-1,Unknown / Non-Applicable,-1
10,"Advisor, Data Science & Analytics","What We'll Bring:

TransUnion, a global information and insights company, is seeking a highly-skilled Advisor for its Data Science & Analytics team.

You will apply your analytical skills to work on all aspects of the account lifecycle in the consumer credit domain on behalf of a diverse set of clients, ranging from marketing and propensity models for customer acquisition and retention, fraud detection solutions, credit risk models for acquisition and account management, cross-sell applications, portfolio models for regulatory applications, event-based trigger solutions, and strategy analyses of various kinds. You will also develop complex analytic solutions to help streamline Transunion’s IT operations, improve data quality and customer experience partnering with other departments.

Advancement opportunities exist in both a technical and managerial track depending on the candidate’s desires and aptitudes.

What You'll Bring:

Dynamics of the Role

TransUnion, a global information and insights company, is seeking a highly-skilled Advisor for its Data Science & Analytics team.

You will apply your analytical skills to work on all aspects of the account lifecycle in the consumer credit domain on behalf of a diverse set of clients, ranging from marketing and propensity models for customer acquisition and retention, fraud detection solutions, credit risk models for acquisition and account management, cross-sell applications, portfolio models for regulatory applications, event-based trigger solutions, and strategy analyses of various kinds. You will also develop complex analytic solutions to help streamline Transunion’s IT operations, improve data quality and customer experience partnering with other departments.

Advancement opportunities exist in both a technical and managerial track depending on the candidate’s desires and aptitudes.

The Team’s Focus

The Data Science & Analytics team is an industry-recognized, client-facing department that rewards an entrepreneurial spirit. We have deep technical expertise and an established reputation as an analytic solutions provider in the consumer identity and credit information space. We have a wealth of data and industry experience within our large group of highly-trained analysts, data scientists, engineers, and economists. We also have a modern computing environment based on best-in-class “big data” technologies and the freedom to explore new data sources and statistical and machine learning methodologies. All of these resources will enable you to help us deliver next-generation analytic solutions for our customers.

How You’ll Contribute

This position is responsible for developing data-driven solutions to challenging and complex problems related to IT infrastructure/ operations, data ingestion and quality control, and enhancing customer experience. You will also be responsible for consumer credit models, strategies, and business intelligence solutions through consulting engagements and research serving TransUnion and its clients. This position requires an understanding of consumer lending, credit risk management practices, IT operations and process engineering.
You will partner with internal and external cross-functional teams to drive new business initiatives and deliver long term value-added product propositions for B2B customers in the financial services segment at TransUnion. This includes but is not limited to the development of predictive risk management and business intelligence solutions for credit card issuers, auto & mortgage lenders, collections agencies and retail banks.
You will lead analytic client engagements involving descriptive, predictive, and prescriptive analysis leveraging a variety of techniques (e.g., segmentation, logistic regression, survival analysis, principal component analysis, Monte Carlo simulation, scenario and sensitivity analysis) to address client needs that may, at first, not be clearly defined.
You will design and write programs for data extraction, segmentation and statistical analysis on large population datasets using languages such as R, SAS, Python, SQL, Hive, and Pig on Linux, PC, and mainframe computing platforms.
You will deliver analytic insights and recommendations in succinct and compelling presentations for internal and external customers and an executive audience.
You will develop project proposals, sales presentations, and promotional collateral to enable the adoption of integrated customer solutions supported by TransUnion.
You will identify strategies and opportunities for customers to test and adopt TransUnion’s analytic products and services.
You will provide mentorship and training to junior colleagues and maintain progress on all initiatives without supervision.
You will foster a high-performance culture and cultivate an environment that promotes excellence and reflects the TransUnion brand.
What You’ll Bring
Master’s or PhD degree in statistics, applied mathematics, financial mathematics, engineering, operations research, or another highly quantitative field. A track record of academic excellence
Seven (7) or more years of professional experience performing analytic work in Financial Services, Technology or related industries. Experience applying advanced analytics to planning and infrastructure problems is preferred.
Deep professional expertise in one or more subject-matter areas or technical disciplines that would complement and significantly enhance TransUnion’s existing analytic capabilities. A consistent record of applying this expertise to drive positive outcomes, and a passion for sharing it with colleagues and business partners.
Multiple examples of demonstrated success in client-facing roles over a period of at least five (5) years
Ability to travel 10-20%
Strong analytical, critical thinking, and creative problem-solving skills
Advanced programming skills; mastery of a statistical language such as R or SAS; experience using other programming and data manipulation languages (SQL, Hive, Pig, Python, C/C++, Java); proficiency with Microsoft Office tools
Versatile interpersonal and communication style with the ability to effectively communicate at multiple levels within and outside the organization; ability to work in a collaborative, fast-paced environment
Strong project management skills with the ability to manage multiple assignments effectively
A deep understanding of current industry challenges and trends at the level needed to proactively identify customers’ analytical needs and related business opportunities

Impact You'll Make:

What We Offer

We aim high — and are reaching for new heights every day. This is a terrific time to join our team as we build on our commitment to integrity, service, reliability and innovation. These values stand behind the decisions we make every day, as well as our relationships at work and with the customers we serve. We believe in the power to achieve and are taking it in bold new directions.

Who We Are

A global leader in credit information and information management services, TransUnion gives businesses, consumers and the global community the power to achieve their goals. Businesses count on us to better manage risk and customer relationships. Consumers are able to better manage credit to achieve their financial goals. And in communities around the world, we help build strong economies and give people the power to achieve their dreams.

Exceptional opportunities are coming as we build on this strong foundation. Our ambitious growth strategy includes substantial new investment worldwide, a wide range of new solutions to help our customers succeed like never before, and new ideas for expanding our reach in every part of our dynamic and fast-moving industry. We’re on an exciting journey and you can be a part of it.

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law.

TransUnion Job Title

Advisor, Data Science and Analytics",4.0,"TransUnion
4.0",Chennai,"Chicago, IL",5001 to 10000 employees,1968,Company - Public,Financial Analytics & Research,Finance,₹100 to ₹500 billion (INR),-1
11,Data Scientist,"When everything's connected, how we connect is everything… and we'd like to connect with you too! We are looking for you to help us deliver exceptional customer experiences as a Data Scientist.
At TTEC Digital, we combine human insight and the speed of technology to transform our clients’ interactions with their customers. Advanced analytics of the customer experience and customer interactions is our expertise.
Check out our website below to learn more about what we do and how we help our clients.
What you’ll be doing
This person will be a part of our Global Data Science Center focused on helping our clients find and seize opportunities in their markets.

Support the development of consulting products such as proprietary customer experience scores and marketing optimization solutions
Maintain our stellar reputation with our clients and drive >80 client NPS
Leverage a mixture of data science methods such as SVM, neural nets, decision trees, and regression models to deliver proprietary uplift model solutions
Support the introduction and advancement of decision science throughout our contact center engagement
Recommend and introduce new methods where relevant
Resource Planning
Recommend required resources to managers
Align required resources to client schedules
Mentor data engineers and architects on requirements
Develop requirements and technical specifications documents for use by engineers

Delivery
Recommend project timelines to managers
Drive on-time delivery and identify and escalate risks to managers
Support attainment of annual goals for client satisfaction
Deliver your own solutions while collaborating on other projects

What you’ll bring to the role
Masters in Statistics, Economics, IE/OR, Computer Science, Applied Mathematics or related field is required; PhD is a plus
1-5 years' experience delivering advanced analytics solutions since graduate program
Ability to translate client requests into approach statements and project plans
Ability to work in a highly collaborative, team-oriented environment
Ability to identify effective, relevant statistical and/or mathematical methods to solve complex business problems
Expert at data wrangling both structured and unstructured data
Experience delivering solutions using regression modeling or machine learning techniques; experience with both is desired
Expert in developing and implementing predictive analytics solutions in one or more of the following languages: R or Python experience with SAS is desired
Experience delivering solutions using large datasets (multi-Gb or larger)
Experience in MS Office suite of products, especially Excel and Powerpoint
Ability to work within any modern big data environment (AWS, MS Azure, SAP Hana, etc.) is desired
Experience with text analytic or speech analytic is desired.
Experience with one or more modern social listening tools (Crimson Hexagon, TheySay, etc.) is desired
What skills you’ll need:
Excellent analytic and data-driven thinking skills
Strong communication skills and an ability to work successfully in a distributed workforce
Creative problem solving and an understanding of analytics workflows
Strong background in consulting a plus

About TTEC
We help global brands provide a great experience to their customers, build customer loyalty, and grow their business. We were founded on one guiding principle: customer experiences that are simple, inspired, and more human deliver lasting value for everyone. Your role brings that principle to life.",3.4,"TTEC
3.4",Hyderabad,"Englewood, CO",10000+ employees,1982,Company - Public,Staffing & Outsourcing,Business Services,₹100 to ₹500 billion (INR),"Teleperformance, TaskUs, Convergys"
12,Data Scientist,"Responsibilities for Data Scientist
Work with stakeholders throughout the organization to build proof of concepts for new business solutions.
Efficiently explore new data sources and assess data gathering techniques.
Help to conceptually frame and refine relevant business questions.
Build robust data pipelines.
Develop custom machine learning models and algorithms.
Coordinate with different functional teams to implement and productionize models while monitoring the performance.
Communicate findings to different stakeholders.
Essential Skills and Qualifications for Data Scientist
At least 3 years experience in a Data Science role
Strong critical thinking and problem-solving skills.
Experience using statistical computer languages (preferably python or R) to manipulate data and draw insights from large data sets.
Experience working with databases (e.g. SQL).
Profound knowledge of a variety of machine learning techniques (clustering, classification, regression, deep learning) and their real-world advatages/drawbacks.
Good knowledge of advanced statistical techniques and concepts (hypothesis testing, Bayesian statistics, properties of distributions) and experience with applications.
Excellent written and verbal communication skills for coordination and communication.
Curiosity and research attitude to learn new ideas and techniques.
Coding experience (preferably python) to write robust and high standard code; experience with version control (preferably git)
Its a bonus if you also have
Automotive
Deep learning
Probabilistic graphical models
Numerical optimization
Economics
-----------------------------------------------
IHS Markit is committed to providing equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by the laws and regulations in any of our locations.

We are proud to provide reasonable accommodations to applicants with disabilities. If you are interested in applying for employment with IHS Markit and need special assistance or an accommodation to use our website or to apply for a position, please contact or call +1 212 849 0399. Determination on requests for reasonable accommodation are considered on a case-by-case basis. This contact information (email and phone) is intended for application assistance and accommodation requests only. We are unable to accept resumes or provide information about application status through the phone number or email address above. Resumes are only accepted through the online application process, and only qualified candidates will receive consideration and follow-up.

IHS Markit maintains a substance-free workplace; employees may be asked to submit to a drug test (where permitted by law). In addition, as a federal contractor in the United States, the company participates in the E-Verify Program to confirm eligibility to work.

For information please click on the following links:

IHS Markit Business Code of Conduct
Right to Work
EEO is the Law
EEO is the Law Supplement
Pay Transparency Statement

-----------------------------------------------

Current Colleagues

If you are currently employed by IHS Markit, please apply internally via the Workday internal careers site.",3.5,"IHS Markit
3.5",Gurgaon,"London, United Kingdom",10000+ employees,2016,Company - Public,Consulting,Business Services,₹100 to ₹500 billion (INR),"Thomson Reuters, International Data Group"
13,Associate Data Scientist,"Position Title
Associate Data Scientist

05-Jun-2020

Job ID
296716BR

Job Description
20 petabytes of data across 30 data domain across the whole bio-pharma value chain waiting for you to unlock the next breakthrough in medicine.
Your responsibilities include, but are not limited to:
•Understand complex and critical business problems from Country/Regional/Global business functions, formulate integrated data science based approaches to mine data sources, employ statistical methods and machine learning algorithms to derive actionable insights. High agility to be able to work across various business domains (commercial, NTO, GDD,NIBR, NBS). Able to use business presentations, smart visualization tools and contextual story-telling to translate findings back to business users with a clear impact.
•Think creatively, conceptualize and lead projects resulting in substantial long-term impact on the company’s vision in many key strategic areas such as drug discovery/manufacturing, product launches, determining optimal treatment plans/courses, expanding patient access, predictive/precision medicine, risk mitigation, business growth, brand management, product life cycle, data strategy etc.
•Design, develop and deliver various data science based insights, outcomes and innovation (using mathematics, computer science, statistics, engineering, management science, technology, economics, etc) and create “proof of concepts & blueprints” to drive faster, timely, highly precise, workable and proactive decision making based on data based insights and science and shape strategic glidepath of the company.
•Lead successful cross-functional collaborations with significant execution rigor, customer focus and “Data to Decision” thinking.
•Demonstrate a comprehensive view of science and technology and deliver a compelling enterprise vision of how Data, Digital & Artificial Intelligence can contribute to providing quantum in leap in building foundational/groundbreaking capabilities.
•Transcending a wide spectrum of areas such as research/science, drug discovery/development, commercial, procurement, technology, product, brand, business, strategy, analytics, operations, risk/compliance, legal, etc and propel growth and performance.
•Design and develop state-of-the-art, data-driven analysis, models and decision strategies to solve science and business problems. Choose and apply appropriate predictive analytic technologies (such as statistical modeling, neural networks, scorecards, machine learning, pattern recognition and artificial intelligence) heavily injected with domain expertise.
•Appropriately, question the veracity and business relevance of data, assumptions, and results and use of solution at all steps of the process. The outcome is improved performance through the design, development, and deployment of project deliverables.

https://www.youtube.com/embed/Mo1vwtVPVA0

Minimum requirements
•M.S/Ph.d in Computer Science, Mathematics, Statistics, Operations Research, Cognitive Sciences, Engineering, Finance, Economics, Medicine, Technology, Management Science, other Quant discip
•Experience :0-2 years
Why consider Novartis?
799 million. That’s how many lives our products touched in 2019. And while we’re proud of that fact, in this world of digital and technological transformation, we must also ask ourselves this: how can we continue to improve and extend even more people’s lives?

We believe the answers are found when curious, courageous and collaborative people like you are brought together in an inspiring environment. Where you’re given opportunities to explore the power of digital and data. Where you’re empowered to risk failure by taking smart risks, and where you’re surrounded by people who share your determination to tackle the world’s toughest medical challenges.

Imagine what you could do at Novartis!
Commitment to Diversity & Inclusion:
Novartis embraces diversity, equal opportunity and inclusion. We are committed to building diverse teams, representative of the patients and communities we serve, and we strive to create an inclusive workplace that cultivates bold innovation through collaboration, and empowers our people to unleash their full potential.

Join our Novartis Network: If this role is not suitable to your experience or career goals but you wish to stay connected to learn more about Novartis and our career opportunities, join the Novartis Network here: https://talentnetwork.novartis.com/network

Job Type
Full Time

Country
India

Work Location
Hyderabad, AP

Functional Area
BD&L & Strategic Planning

Division
CORPORATE

Business Unit
DIGITAL OFFICE

Employment Type
Regular

Company/Legal Entity
Nov Hltcr Shared Services Ind

Shift Work
No",3.9,"Novartis
3.9",Hyderabad,"Basel, Switzerland",10000+ employees,1996,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
14,Data Scientist,"Location: Guntur or Mumbai.
Salary Rs. 60,000 to Rs 1,00,000 per month.
As a Data Scientist you will work with huge datasets, troubleshooting challenging issues with machine learning, programming and analytical techniques.

Requirements:
Strong C/C++ or Java skillsExperience building and deploying real world machine learning applications in a production environment
Previous experience of large datasets
Excellent mathematical skills
Degree educated in Computer Science or related subject

Desirable: MSc Maths, Deep Learning, HPC/GPU experience in the context of machine learning, KDB, Python, Unix, Machine Learning Frameworks
Visualization Tools: SAS VA, TABLEAU, SAP FIORI

Send your resume with cover letter to hr@coveventure.com",-1,Cove Venture,Guntur,"Scottsdale, AZ",51 to 200 employees,-1,Company - Private,Real Estate,Real Estate,₹100 to ₹500 million (INR),-1
15,Data Scientist cl 10,"Job Skill: NA
Designation: Career Level - 10-Analyst
Job Location: Mumbai
Qualifications: Any Graduation
Years of Experience: 5-7 years
About Accenture


Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Combining unmatched experience and specialized skills across more than 40 industries and all business functions underpinned by the worlds largest delivery network Accenture works at the intersection of business and technology to help clients improve their performance and create sustainable value for their stakeholders. With 500,000 people serving clients in more than 120 countries, Accenture drives innovation to improve the way the world works and lives. Visit us at www.accenture.com



Job Summary


Good to have skills: You will be aligned with our Data Analytics vertical and help us with your expertise in building world class solutions, conquering the business problems, addressing technical challenges using Data management and Visualization tools and techniques. You will be working as a part of Data Management team which is accountable for Data Management that includes fully scalable relational database management system. ETL(Extract, Transport and Load) - Set of methods and tools to extract data from outside sources, transform it to fit an organization`s business needs and load it into a target such as the organization`s data warehouse.

Roles and Responsibilities


In this role you are required to do analysis and solving of increasingly complex problems. Interaction is with peers within Accenture before updating supervisors. Likely has some interaction with clients and/or Accenture management. Minimal instruction on daily work tasks and a moderate level of instruction on new assignments will be provided. Decisions made by you impact your own work and may impact the work of others. In this role the person would be an Individual contributor and/or oversees a small work effort and/or team. Please note that this role may require you to work in rotational shifts.",3.9,"Accenture
3.9",Mumbai,"Dublin, Ireland",10000+ employees,1989,Company - Public,Consulting,Business Services,₹500+ billion (INR),"Cognizant Technology Solutions, EY, McKinsey & Company"
16,Dev - Data Scientist,"Requirements:
Qualification: Master’s Degree in Computer Science, Statistics, Applied Math or related field.
7+ years’ practical experience with SAS, ETL, Data Processing, Database Programming and Data Analytics.
Excellent understanding of Machine Learning and Artificial Intelligence Techniques and Algorithms.
Experience with common data science tools like (but not limited to) R, Weka, NumPy, MatLab, etc.
Good knowledge of statistics.
Experience with programming languages such as Java and Python.
Skilled in Reporting and Data Visualization Software, with strong presentation skills.
Experience with SQL (Structured Query language) programming.
Extensive background in data mining and statistical analysis.
Ability to understand various data structures and common methods in data transformation.
Excellent pattern recognition and predictive modeling skills.
NoSQL and BigData experience preferred.
Skills Required
Java, Python, SQL, SAS, ETL, Data Processing, Database Programming, Data Analytics.
Research and develop statistical learning and Machine Learning models for data analysis.
Understanding information needs and extracting data from a variety of sources in order to create analytics deliverables that meet those needs.
Leverage models to address key growth challenges, cross-channel spend allocation, response modeling and marketing program attribution.
Collaborate with Product Management to understand Business needs and devise possible solutions.
Ideas to generate key decision making KPIs.
Implement new statistical or other mathematical methodologies as needed for specific models or analysis.
Optimize joint development efforts through appropriate database use and project design.",4.8,"Diamondpick
4.8",Bengaluru,"Chennai, India",51 to 200 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
17,Data Scientist,"“Make every logistics journey your best one yet” - Quincus

The Company.

At Quincus, our technology is designed to ease shipping issues—wherever in the world they may be. We commit ourselves in designing the most effective total end to end supply chain solutions through a dedicated technology ecosystem. This offers our users a personalized experience that bypasses traditional and expensive logistics options. By combining advanced technology, data analytics, and hands-on experience, we eliminate traditional and expensive logistics options.

The Opportunity.

As our business continues to grow, we are looking for a Data Scientist to join our team. The incumbent will turn data into understandable information for effective business making decisions. This person is passionate about Machine Learning. numbers and loves the idea of helping to make decisions with the support of data.

Your day to day.

- Partner with Product and Engineering teams to solve problems and identify trends.
- Creating and interpreting dashboards and reports to help leaders make more effective decisions.
- Building key data sets to empower operational and exploratory analysis.
- Experiments against data points and provide previously undiscovered solutions to command data challenges.

Who you are.

- Bachelor’s/Master’s in Computer Science/Engineering/Mathematics. [MCA, B.tech, M.tech]
- Minimum 5 years of experience in the same role.
- Proficient with one or more programming languages (Java, Python, R, etc.)
- Demonstrated experience applying data science methods to real-world data problems
- Ability to integrate multiple data sources and databases into one system.

What’s in it for you.

People: Work with passionate, smart, and entrepreneurial go-getters.
Fun environment: cool office space, stocked pantry, and team bonding.
Compensation: competitive salaries and benefits.



QUINCUS is not obligated to accept candidate profiles from any third parties on behalf of potential candidates for any position (advertised or otherwise) by any means, unless QUINCUS has fully executed a written agreement with such third party and has expressly requested such third party for candidate referrals/introductions. Third parties who provide unsolicited resumes of candidate(s) shall waive and forfeit all rights to claim for any placement fees or referral fees in the event that such candidate is eventually engaged and/or employed by QUINCUS.",4.0,"Quincus
4.0",New Delhi,"Singapore, Singapore",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
18,Data Scientist - NLP - Internal Audit AVP-VP # 153992,"We are a department
which values Diversity and Inclusion (D&I) and is committed to realizing
the firm’s D&I ambition which is an integral part of our global Conduct and
Ethics Standards

You have an exciting
opportunity to work with the Global Data Analytics team within Internal Audit
(IA), to apply your technical skills against a wide range of problem statements
across the bank. At Credit Suisse, we’re proud that Internal Audit is seen as a
“compelling voice encouraging confidence in the ability of the Bank to deliver
its strategy”. Our Auditors build and maintain direct and positive lasting
relationships with the Bank’s leadership. They are actively consulted for their
independent advice and insights to encourage positive change. Our global
Internal Audit function reflects the Bank’s entrepreneurial spirit; we’re
investing in new technologies, data analytics, and the latest training
techniques to ensure that both people and platforms are outstanding.
Opportunities:
Benefit from
working within a highly motivated, diverse, dynamic and a fast paced team,
with expertise across variety of technical skillsets.
Improve your
understanding of the Bank by working alongside auditors on a wide variety
of different topics.
Become a trusted
advisor and partner to audit teams, and see your the impact on the bank’s
people, processes and clients.
Key Responsibilities:
Investigate
risks using forensic analysis, data science and modelling techniques to
identify issues and root causes, and predict future incidents.
Serve as an
internal specialist on Natural Language Processing (NLP), related data
sources, analytics and data science techniques.
Build and
maintain strategic processes and solutions that can be reused continuously
by both Internal Audit and other partners.
Advance the
overall data science capability of the department by developing and
conducting training, deploying reusable assets and extending existing
libraries or frameworks to tackle problems in innovative ways.
Remain on top of
your game in the rapidly changing field of NLP and machine learning and
keep the IA function up-to-date with industry advancements.
Understand the
value of diversity in the workplace and are dedicated to fostering an
inclusive culture in all aspects of working life so that people from all
backgrounds receive equal treatment, realize their full potential and can
bring their full, authentic selves to work. This should be further
elaborated on in your application.
Possess an
inquisitive nature and ability to ask questions to fully understand a
requirement or a problem.
Phenomenal
analytical and problem solving skills, with a practical approach and a
positive can-do attitude.
Innovative
thinking, able to expand our analytics and data science services through
identification and development of new insights.
An ability to
work and connect with all levels of the business and multifunctional
teams.
An agile
demeanor, can work under pressure and manage multiple tasks and priorities
that are constantly evolving
Possess the
desire and the self-motivation to learn new skills, toolsets and
programming languages.
Strong NLP
skills including working experience with topic modelling, summarization,
semantic analysis, entity identification, OCR and word embedding vectors.
Minimum 5 years
of proven experience applying common NLP frameworks and languages
including NLTK, Spacy, Stanford NLP, BERT, RASA and others to tackle
business problems.
Experience with
machine learning libraries and platforms including scikit-learn,
tensorflow, pyTorch etc.
Experience using
statistical computer languages such as R and Python to classify data and
build predictive models and perform NLP tasks.
Result oriented,
dedicated, who can work on own initiative and can deliver on time with a
high level of integrity and flexibility, sense of urgency, attention to
detail and quality standards",3.8,"Credit Suisse
3.8",Pune,"ZÜRICH, Switzerland",10000+ employees,1856,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"UBS, J.P. Morgan, Goldman Sachs"
19,Data Scientist,"At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.

What is the Data Scientist – Client Analytics group responsible for?
Works with their team in support of a single business unit, providing support for solving more complex problems for their domain by developing a variety of models and statistical techniques. They also perform ad hoc statistical and data mining analysis as required
What are the ongoing responsibilities of a Data Scientist?
Data Preparation, Gathering and Analysis Collects data from disparate systems, analyzes it, and delivers the data as intelligence that is actionable Analyzes and interprets the results of research experiments through statistical models Solves analytical problems utilizing large structured, semi-structured and un-structured data in a distributed processing environment (Required)
Statistical Analysis - Data Mining and Advanced Analytic Techniques Develops predictive, statistical, behavioral, or other models using supervised and un-supervised machine learning / statistical modeling techniques Performs ad hoc statistical and data mining analyses (Required)
Training, Research and Development Conducts research on various advanced statistical techniques to apply to appropriate analytical problems (Required)
Skills:
Ability to translate business challenges into analytical problems
Ability to articulate and explain statistical / machine learning techniques to business partners
Proven experience in telling stories using data
Ability to handle large datasets for building Statistical/Machine learning models which includes hands on experience working on data cleansing, manipulation and data mining
Proven ability to work with ambiguous (not well defined) challenges
Displays curiosity to learn and learns independently
Excellent written and verbal communication skills
Excellent organizational and planning skills
Proven ability to take initiative and work under pressure in a changing/growing environment
Ability to work individually or as a team as task requires
Able to cultivate interpersonal customer and co-worker relationships
What ideal qualifications, skills & experience would help someone to be Successful?
Master’s / Bachelor’s degree in Statistics, Mathematics, Econometrics, Computer Science, Engineering or related disciplines, preferably from premier Institutes
3-5 years of experience in advanced analytics
Proven Experience in Statistical and Machine learning techniques
Desirable to have experience in Time Series modelling as well
Experience in SAS or R or Python
Experience in SQL
What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.

Highlights of our benefits include:

Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.",3.8,"Franklin Templeton Investments
3.8",Hyderabad,"San Mateo, CA",5001 to 10000 employees,1947,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Fidelity Investments, Vanguard"
20,Data Scientist,"Jr. Data Scientist / Data Scientist

Having a strong background in machine learning who are extremely passionate about solving real-world applied problems in the various business domains. A real opportunity to expand skill-sets and a chance to learn and use the latest advances and approaches in machine learning and data mining on real-world datasets.

Working at a fast-paced work environment where one is expected to be self-motivated and are measured on performance.

Job Responsibilities

Ability to understand a problem statement and implement analytical solutions & techniques independently or with minimal supervision

Work and collaborate with other teams to deliver and create value for clients

Fast learner: ability to learn and pick up a new language/tool/ platform quickly

Conceptualize, design and deliver high-quality solutions and insightful analysis

Conduct research and prototyping innovations; data and requirements gathering; solution scoping and architecture; consulting clients and client-facing teams on advanced statistical and machine learning problems.

Ability to deliver AIML based solutions around a host of domains and problems, with some of them being: Customer -Segmentation & Targeting, Propensity Modeling, Churn Modeling, Lifetime Value Estimation, Forecasting, Recommender Systems, Modeling Response to Incentives, Marketing Mix Optimization, Price Optimization

Experience Required:

Intermediate to expert level proficiency in at least one of R and Python

Ability to discover effective solutions to complex problems. Strong skills in data structures and algorithms.

Experience of working on a project end-to-end: problem scoping, data gathering, EDA, modelling, insights, and visualizations

Problem-solving: Ability to break the problem into small problems and think of relevant techniques which can be explored & used to cater to those

Intermediate to advanced knowledge of machine learning, probability theory, statistics, and algorithms. You will be required to discuss and use various algorithms and approaches on a daily basis.

We use regression, Bayesian methods, tree-based learners, SVM, RF, XGBOOST, time series modelling, dimensionality reduction, SEM, GLM, GLMM, clustering etc on a regular basis. If you know a few of them you are good to go.

Experience of working in cloud-based environments such as AWS, GCP, Azure

Good to Have:

Experience in one of the upcoming technologies like deep learning, NLP, image processing, recommender systems

The experience of working in on one or more domains:

CPG: pricing and promotion analytics, marketing analytics, trade promotions, supply chain management

BFSI: cross-sell, up-sell, campaign analytics, treasury analytics, fraud detection

Healthcare: medical adherence, medical risk profiling, EHR data, fraud-waste-abuse

Experience in working with Linux computing environment and use of command-line tools like sed/awk

Grasp at databases including RDBMS, NoSQL, MongoDB etc.

Requirements

Education Qualification

B.Tech / M.Tech in Computer Science / Mathematics / Signal Processing or related fields from one of the premier Institutes (IITs/NITs/BITS)",3.6,"Mastek Limited
3.6",Mumbai,"Reading, United Kingdom",1001 to 5000 employees,1982,Company - Public,IT Services,Information Technology,₹10 to ₹50 billion (INR),"Capgemini, Cognizant Technology Solutions, Mindtree"
21,Data Scientist,"Experience : NA
Qualification : Bachelors in Computer Science.
Functional Area : IT Software (Banking)
Employment Type : Full time
Location : Bangalore
Job Description

We are looking for a data scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.

Applications include Fraud Analytics, Automated credit scoring using Machine Learning Techniques, Recommendation system for credit products.

Responsibilities

Selecting features, building and optimizing classifiers using machine learning techniques.
Data mining using state-of-the-art methods.
Extending company’s data with third party sources of information when needed.
Enhancing data collection procedures to include information that is relevant for building analytic systems.
Processing, cleansing, and verifying the integrity of data used for analysis.
Doing ad-hoc analysis and presenting results in a clear manner.
Creating automated anomaly detection systems and constant tracking of its performance.
Designing algorithms to solve specific issues faced by the financial sector.
Skills and Qualifications

Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.
Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc. Excellence in at least one of these is highly desirable.
Great communication skills.
Experience with data visualisation tools, such as Microsoft SSRS.
Proficiency in using query languages such as SQL.
Experience with NoSQL databases, such as MongoDB, Cassandra.
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills .
Data-oriented personality.
Bachelors in Computer Science with relevant experience is preferred.

Email : hr@processwaresystems.com

Phone No : 080-26572188, 26579635",3.5,"Processware Systems
3.5",Bengaluru,"BENGALURU, India",51 to 200 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
22,Data Scientist,"Ahmedabad
Be a part of the movement to revolutionize the in-store customer experience through the loyalty program and the other features we have to offer.We believe in creating memories that will last forever. We want to help businesses develop personal connections with their customers and provide the customers with experiences that they will cherish forever and will keep them coming back.
We’re scrappy, hard-working perfectionists looking for people who can add immediate value to our team. As a member of the founding team of # Loyalty, you will have the opportunity to work across different business verticals in an extremely faced paced environment. You'll play a key role in product development, strategy and other business decision.

Job Description
Machine Learning & Artificial Intelligence are embedded deeply into our products evolution. We are looking for talented individuals to help us build these tools and embed them into our product offering. The exposure and impact on the product will be massive! And select individuals would be offered a full-time or part-time position post the internship, depending on the performance during the same.

What we're looking for:
Experience working with Python and libraries like NumPy, SciPy, Pandas, Scikit-learn, Tensorflow etc.
Experience working with large data-sets (provide links to your work on Github/Kaggle)
Solve complex performance problems and architectural challenges
Passionate about Machine Learning and AI
Strong knowledge of PHP web frameworks {{such as Laravel, CI,}}
Worked on real world recommender / ranking systems
Prior experience working at a startup environment would be great
Other Skills
Python, Machine Learning, Numpy/Scipy/Pandas/Scikit-learn
Should be able to handle a team technically.
Experience
PHP: 1+ years (Preferred)

Contact Us to Apply : (+91) 851 187 8094 info@r3coder.com",-1,R3coder,Ahmedabad,"Ahmedabad, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
23,Sr Advisor Data Engineering,"Job Title: Sr Advisor, Data Engineering

Location: Bangalore

Competitive Salary

Company Description:

Dell is a collective of customer-obsessed, industry-leading visionaries. At our core is a commitment to diversity, sustainability and our communities. We offer unparalleled growth and development opportunities for our team members. We believe that technology is essential for driving human progress, and we’re committed to providing that technology to people and organizations everywhere, so they can transform the way they work and live.

Why Work For Us:

Dell is primed to recruit the best and brightest candidates from all across the globe. We take pride in fostering a winning, innovative, inclusive employee culture. We also take calculated risks and we celebrate big victories when they pay off.

Our Employee Value Proposition:

Our Culture Code unites us and makes us a great family of companies and a great place to work. It’s how we run the business, go to market, work together and provide inspirational leadership. Our culture code is defined by our values and are made real every day by defining expectations for how we work and how we lead.

About Business Unit:

We provide solutions to drive the business and decision making by delivering on-demand business insights and solutions that emphasize one version of the truth and data integrity.

Role Overview:

Interacts with business leaders and internal customers to create and establish design standards and assurance processes for software, systems and applications development to ensure compatibility and operability

Analyzes business goals, defines project scope and identifies functional and technical requirements

The job function may include the following disciplines: Data analysis and science, data architecture and solutions engineering, visual design and analytics enablement and internal consulting

Key Responsibilities:

Develops technical processes and programming to cleanse, organize and transform data and to maintain, protect and update data structures and integrity on an automated basis.

Applies data extraction, transformation, and loading techniques in order to tie together large data sets from a variety of sources

Partners with both internal & external resources to design, build and oversee the deployment and operation of technology architecture, solutions and software

Designs, develops and programs methods, processes and systems to capture, manage, store and utilize structured and unstructured data to generate actionable insights and solutions

Responsible for the maintenance, optimization, improvement, cleaning, and manipulation of data in the business’s operational and analytics databases

Work in collaboration with data engineers, data scientists, architects and business to design actionable strategic projects and break complex problems into actionable tasks

Essential Requirements:

Pulls together cross-functional teams in order to achieve goals and serves as expert spokesperson

Builds assigned solutions within the infrastructure provided for optimal extraction, transformation, and loading of data from a limited set of structured data sources using specified data engineering tools

Follows data engineering process standards and participates in testing of new data engineering technologies, providing feedback to leadership for global data solutions.

Drives assigned projects that deliver improvement any one of the following five data stages: ingestion, storing, packaging, modeling and consumption.

Drives projects with a short-term (

Build/maintain analysis, monitoring, and productivity tools

Integrates medium to large structured data sets that meet business requirements

Proactively monitors and manages data design tenets and drives corrective actions regarding data quality issues

Provides leadership support in on-board training and mentoring junior level data engineers

Responsible for data engineering project deliverables, timeline commitments and cost management

Desirable Requirements:

Passion for innovation and the application of emerging data technologies to the delivery of cutting-edge business intelligence solutions, and the ability to quickly learn new tools/technologies as required.

Experienced in working both independently and in a collaborative, cross-functional team environment.

Strong verbal/written communication and presentation skills. Ability to clearly discuss applied big data platforms and applied solution designs to both technical and non-technical peers.

Strong understanding of business functions, CRM transactional systems, data sets, data relationships and KPI measures.

Strong project management and organizational skills.

Strives for professional development

Customer focused

Experienced in coaching/training data engineering teams

Strong skills in building processes supporting data transformation, data structures, metadata dependency and workload management

""Strong knowledge and experience in key data engineering technologies, including:

- Big Data Tools(Spark, Hadoop, Python, Tableau etc)

- Relational SQL and NoSQL Databases

- Data Pipeline and Workflow Management Tools

- Cloud Services

- Stream-Processing Systems

- Object-Oriented/Object Function Scripting Languages""

7-11 years of exprience

Benefits:

We offer highly competitive salaries, bonus programs, world-class benefits, and unparalleled growth and development opportunities — all to create a compelling and rewarding work environment.

Apply now!

Dell is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Dell are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Dell will not tolerate discrimination or harassment based on any of these characteristics. Dell encourages applicants of all ages. Learn more about Diversity and Inclusion at Dell here.",4.1,"Dell Technologies
4.1",Bengaluru,"Round Rock, TX",10000+ employees,1984,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"IBM, Apple, HP Inc."
24,Machine Learning Engineer/Data Scientist,"Location : Bangalore- India
Job Id: 20WD40887
Position Overview

Autodesk is seeking a
Machine Learning Engineer/Data Scientist to join our Sales Data Science team.
We build innovative data products and machine learning solutions for Autodesk’s
sales teams. In this critical role, you will work alongside product development,
product managers, and data engineers to tackle fundamental data gathering,
management, and understanding of our APAC sales region. The ideal candidate is
a strong communicator and has experience as a Data Analyst or Data Engineer who
has strong Data Science leanings and has built out multiple analytic models and
machine learning algorithms before. Data, automation and advanced
analytics technologies are drastically transforming our sales team in APAC and
this person will be the data scientist in charge of overviewing our data
science practice in Singapore, India, China, Korea, Australia, and New Zealand

As the Data Scientist
for APAC, your primary responsibility will be to empower our sales teams with
machine learning models and data analytics to make them more productive and
better equipped to be customer centric. You will collaborate with our Data
Scientists in Barcelona and the US to build major data science products. You
will be in charge of establishing and maintaining machine learning deployment
pipelines, including their associated life-cycle management systems and
practices, in coordination with their architecture peers and communities of
practice throughout the company
Responsibilities:
Designing and implementing
Machine Learning models and algorithms that enable account selection,
customer targeting, and process improvements for the sales teams in APAC
Develop and maintain model
deployment pipelines for many types of machine learning including
supervised and unsupervised learning as well as CNNs, RNNs or other deep
learning algorithms
Working closely with data
scientists, domain experts and sales team, both to understand model
performance management requirements and design suitable inferencing
instrumentation systems and practices that meet them
Designing and implementing
outbound data engineering pipelines that serve curated datasets to
business intelligence and reporting
Designing integration solutions
including applications as needed to deliver inferencing outcomes or
curated data sets for consumption and action
Ensuring your model deployment,
outbound data engineering and integration pipelines are architecturally
and operationally integrated with inbound ingestion and contextualization
pipelines designed by your peer domain architects
Delivering and presenting
results to sales leaders regarding their business, forecast, pipeline, and
potential customers

Minimum Qualification
Advanced degrees in computer
science and data science strongly preferred, though an equivalent level
engineering, data science or mathematics degree, a technical undergraduate
degree and relevant experience will also be considered
8 plus years of relevant work
experience
3 years of experience working
with data scientists in a data engineering or production machine learning
inferencing capacity, working with various types of supervised and
unsupervised learning algorithms for classification, recommendation,
anomaly detection, clustering and segmentation, as well as CNNs, RNNs or
other deep learning algorithms
5 years of full-stack
experience developing large scale distributed systems and multi-tier
applications
5 years of programming
proficiency in, at least, one modern JVM language (e.g. Java, Kotlin,
Scala) and at least one other high-level programming language such as
Python
2 years of production DevOps
experience
3 years of programming on the
Apache Spark platform, leveraging both low level RDD and MLlib APIs and
the higher-level APIs (SparkContext, DataFrames, DataSets, GraphFrames,
SparkSQL, SparkML).
Demonstrated deep understanding
of Spark core architecture including physical plans, DAGs, UDFs, job management
and resource management
At least 1 year of
implementation experience with Apache Airflow, and a demonstrated expert
level understanding of both segmented and unsegmented Directed Acyclic
Graphs and their operationalization
Experience working with Neo4J
and a demonstrated ability to lead architecture efforts for its
implementation
Strong technical collaboration
and communication skills
Very strong communicator
Passion for sales and customer
segmentation
Proficiency with functional
programming methods and their appropriate use in distributed systems
Proficiency with AWS
foundational compute services, including S3 and EC2, ECS and EKS, IAM and
CloudWatch
Proficiency with Sagemaker,
Kubernetes, and Docker

Preferred Qualifications
Experience with data science
toolkits like: R, Pandas, Jupyter, scikit, TensorFlow, etc.
Experience with Sagemaker and
data pipelines in AWS
Familiarity with statistics
concepts and analysis, e.g. hypothesis testing, regression, etc.
Experience building dashboards
in platform: Power BI, Tableau, Qlik, Looker, etc.
Salesforce experience is a plus",4.0,"Autodesk
4.0",Bengaluru,"San Rafael, CA",5001 to 10000 employees,1982,Company - Public,Computer Hardware & Software,Information Technology,₹100 to ₹500 billion (INR),-1
25,Data Scientist,"COMPANY OVERVIEW
Tata Group is an Indian multinational conglomerate company headquartered in Mumbai, India. It encompasses seven business sectors: communications and information technology, engineering, materials, services, energy, consumer products and chemicals. Tata Group was founded in 1868 by Jamsetji Tata as a trading company. It has operations in more than 80 countries across six continents. Tata Group has over 100 operating companies with each of them operating independently.
Tata Sons is the promoter of all key Tata companies and holds the bulk of shareholding in these companies.

BACKGROUND The Tata companies together serve over million consumer and commercial customers today across several products and services. In order for the Tata companies to better understand customer and client needs and preferences, action life stages, needs, value, and potential, and enhance value and experience; the Tata companies need to develop robust data and information management capability and customer analytics. The vision is to eventually create the best in-house capability for data analytics amongst any large corporate. To achieve the above aims, it has been decided to establish an independent Tata company focused on building a common data analytics platform and help Tata Group companies. This company is being incubated in the initial phase as a division of Tata Industries and will subsequently be structured as a separate company to build Big Data Analytics and Data Science capabilities catering to but not limited to the ‘Consumer’ brands of the group.

Tata Insights and Quants – Journey to Date
Company: Tata - Insights and Quants – A Newly started division by Tata Industries.
http://www.livemint.com/Companies/PCgvCZILuJKV68UKVHZRJO/With-new-analytics-arm-Tata-aims-to-make-better-sense-of-da.html
Employer Brand: Tata iQ in 18 months of its inception was recognized in the list of Analytics India Magazine’s (AIM)
Top 10 most desirable Analytics Indian Firms to work for in 2016:
http://analyticsindiamag.com/top-10-analytics-firm-wish-worked-2016/
Generating Value for Customer: Fourteen Tata companies are partnering Tata Insights and Quants (Tata iQ), a Big Data firm, to analyse data collected from users, consumers and make sense of it to put changes in place http://www.livemint.com/Companies/5om8ebrv6p02jGCcRB3j3K/Tata-companies-use-Big-Data-to-craft-strategies.html https://cio.economictimes.indiatimes.com/news/strategy-and-management/how-ranjit-satyanath-plugs-into-it-to-power-up-croma-for-the-digital-era/65050926

Contributing to Community through big data:
In line with the Tata group’s philosophy of giving back more to the society than what it takes, Tata iQ, Tata group’s big data and decision Sciences Company.
Okhai partners with Tata iQ to deliver big impact through big data

Company : Tata Insights and Quants
Role : Data Scientist
Level : Analyst – Associate - Senior Associate
Role Type : Individual Contributor
Location : Mumbai | Bangalore | Jamshedpur | Kalinga Nagar – All Options open

Job Description The incumbent will be part of the Predictive Analytics, Digital Analytics, Data Sciences, Advanced Visualization, Insights & Experimentation team and will report to the Manager/Senior Manager. He/she will be an individual contributor working on multiple data sciences, advanced visualization and data management initiatives across multiple companies and industries leveraging traditional and big data. The incumbent will have the unique opportunity to witness the application of analytics across multiple industry verticals. Close partnership with business and the senior leadership of multiple Tata Companies will enable a clear understanding of the business perspectives and the application of analytics for solving real business problems.

Key Responsibilities:
Apply Data Mining/ Data Analysis methods using a variety of data tools, building and implementing models using algorithms and creating/ running simulations to drive optimisation and improvement across business functions
Assess accuracy of new data sources and data gathering techniques
Perform Exploratory Data Analysis, detailed analysis of business problems and technical environments in designing the solution
Apply Supervised, Unsupervised, Reinforcement Learning and Deep Learning algorithms
Apply advanced Machine Learning Algorithms and Statistics:
o Regression, Simulation, Scenario Analysis
o Time Series Modelling
o Classification - Logistic Regression, Decision Trees, SVM, KNN, Naive Bayes
o Clustering, K-Means
o Ensemble Models - Random Forest, Boosting, Bagging
o Neural Networks
Lead and manage Proof of Concepts and demonstrate the outcomes quickly
Document use cases, solutions and recommendations
Work analytically in a problem-solving environment
Work in a fast-paced agile development environment
Coordinate with different functional teams to implement models and monitor outcomes
Work with stakeholders throughout the organization to identify opportunities for leveraging organisation data and apply Predictive Modelling techniques to gain insights across business functions - Operations, Products, Sales, Marketing, HR and Finance teams
Help program and project managers in the design, planning and governance of implementing Data Science solutions
Experience and Skills:
2-7 years of professional working experience in Analytics
Experience in Retail, Financial Services and Manufacturing
Experience using statistical packages of R, Python and Spark ML to work with data and draw insights from large data sets
Experience with distributed data/ computing tools: Hadoop, Hive, Spark, Python
Experience with SQL
Experience visualizing/ presenting data for stakeholders using matplot, ggplot or Excel or Tableau
Excellent written and verbal communication skills for coordinating across teams
Education qualification:
Bachelors/ Masters in a quantitative discipline (Statistics, Econometrics, Mathematics, Engineering and Science)
Reach us on careers@tataiq.com",4.0,"Tata Insights and Quants
4.0",Mumbai,"Zug, Switzerland",10000+ employees,1980,Unknown,Architectural & Engineering Services,Business Services,Unknown / Non-Applicable,-1
26,Data Scientist,"• Good Knowledge on the automotive Communication protocols like CAN, Flex ray
• Sound knowledge on the Driver assistance systems (feature functions like lane departure prevention, collision avoidance etc.)
• Practical knowledge of automotive sensors like Camera, RADAR etc.
• Testing, Debugging and validation of application software as per the Requirement (in DOORS)

Additional skills: (Optional)
• Overview on Ethernet communication protocol
• Hands on with visualization tools for sensors
• Good Overview on analyzing time series data, (ASC, MAT, DAT file),
• Good knowledge on latest trends like LIDARs and multi-mode RADARs.
• Knowledge on Atlasian tools like Confluence, JIRA etc.

• Good Knowledge on the automotive Communication protocols like CAN, Flex ray
• Sound knowledge on the Driver assistance systems (feature functions like lane departure prevention, collision avoidance etc.)
• Practical knowledge of automotive sensors like Camera, RADAR etc.
• Testing, Debugging and validation of application software as per the Requirement (in DOORS)

Additional skills: (Optional)
• Overview on Ethernet communication protocol
• Hands on with visualization tools for sensors
• Good Overview on analyzing time series data, (ASC, MAT, DAT file),
• Good knowledge on latest trends like LIDARs and multi-mode RADARs.
• Knowledge on Atlasian tools like Confluence, JIRA etc.",3.5,"Mercedes-Benz Research and Development India Private Limited
3.5",Bengaluru,"Chakan, India",1001 to 5000 employees,1996,Company - Private,IT Services,Information Technology,₹10 to ₹50 billion (INR),"Volkswagen, Tata Motors"
27,Data Scientist,"JOB DESCRIPTION
</b></u></h2>

KEY RESPONSIBILITIES :
Using techniques from supervised and unsupervised machine learning, statistical analysis and predictive modelling to deliver business insights to business units based on data
Working directly with internal customers to educate them on moving beyond BI and training their internal resources to execute advanced forms of analytics
Creating reusable implementations of statistical tests and models using cutting edge technologies
Working with the academic and business community to develop new techniques and to contribute to research in the area of advanced analytics in media
Assisting in engagement management, requirements definition, project scoping, timeline management, and results documentation to ensure professional relationship management
PERFORMANCE MEASURES :
As per role KPIs
QUALIFICATION :
2-8 Years plus post qualification
Degree in computer science with a machine learning focus (other technical degrees also accepted e.g. applied mathematics, statistics, physics, operations research). PhD will be desirable.
KNOWLEDGE AND SKILLS :
Advanced knowledge of statistical and machine learning methods, particularly in the areas of modelling and business analytics
Strong programming skills
Experience with statistical languages and packages, such as R, SAS, Mat-Lab, and/or Mahout
Experience working with relational databases and/or distributed computing platforms, and their query interfaces, such as SQL, MapReduce and Hive.
Experience with additional programming languages, such as Python, Java, and C/C++.
Excellent written and verbal communications skills, with a proven ability to translate complex methodologies and analytical results to higher-level business insights and key take-away
A proven passion for generating insights from data, with a strong familiarity with the higher-level trends in data growth, open-source platforms, and public data sets.
Experience working hands-on with large-scale data sets
Familiarity with visualization software and techniques (including Tableau), and business intelligence (BI) software, such as Micro-strategy, Cognos, Pentaho, etc.
PERSONAL ATTRIBUTES :
Creative, gritty, driven by curiosity and comfortable with failure
Strong Data intuition: Talent to identify and visualize patterns
Multi Modal Communication skills
We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, gender identity, disability, protected veteran status, or any other characteristic protected by law. We will consider for employment qualified applicants with criminal histories consistent with applicable law.",3.9,"Walt Disney Company
3.9",Mumbai,"Burbank, CA",10000+ employees,1923,Company - Public,Film Production & Distribution,Media,₹500+ billion (INR),"News Corp, WarnerMedia, NBCUniversal"
28,Data Scientist,"Eyeota is looking for an exceptional Data Scientist who is passionate about data and motivated to build large scale machine learning solutions to shine our data products. This person will be contributing to the analytics of data for insight discovery and development of machine learning pipeline to support modeling of terabytes of daily data for various use cases.

Qualifications:
2+ years relevant working experience
Master/Bachelors in computer science or engineering
Working knowledge of Python and SQL
Experience in time series data, data manipulation, analytics and visualization
Experience working with large-scale data
Proficiency of various ML algorithms for supervised and unsupervised learning
Experience working in Agile/Lean model
Experience with Java and Golang is a plus
Experience with BI toolkit such as Tableau, Superset, Quicksight, etc is a plus
Exposure to building large-scale ML models using one or more of modern tools and libraries such as AWS Sagemaker, Spark ML-Lib, Dask, Tensorflow, PyTorch, Keras, GCP ML Stack
Exposure to modern Big Data tech such as Cassandra/Scylla, Kafka, Ceph, Hadoop, Spark
Exposure to IAAS platforms such as AWS, GCP, Azure
About Eyeota

Eyeota provides a dynamic, fun workplace filled with passionate individuals. We are at the cutting edge of advertising technology and there is never a dull moment at work.

We have a truly global footprint, with our headquarters in Singapore and offices in Australia, United States, United Kingdom and India

At Eyeota you will gain work experience in a global startup. We speak over 20 different languages, from more than 16 different nationalities and over 42% of our staff are multilingual.

Eyeota is an Equal Opportunity Employer.

Powered by JazzHR",3.1,"Eyeota
3.1",Pune,"Singapore, Singapore",51 to 200 employees,2010,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,"Lotame, Krux"
29,Data Scientist,"Description
We are looking for a Data Scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.
You will be responsible for researching, innovate and implementing state-of-the-art algorithms using deep learning, reinforcement learning techniques in Natural Language Processing task, Machine Reading Comprehension, Recognizing Textual Entailment, Document Classification, Text Analytics, Sentiment Analysis, recommendation engine, A/B testing and more.
Responsibilities
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending company’s data with third party sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
research and innovation of state-of-the-art papers in NLP problems
Working with Backend Engineers to ship your models to production and publish research in top journals e.g.: NIPS, Arxiv and Nature
Skills and Qualifications
Proficiency in Python, R or Java and data science tools.
Experience in modern Deep Learning and Natural Language Processing / Natural Language Understanding (NLP, NLU), including Neural Networks, RNNs, seq2seq+attention models, and real world machine learning in TensorFlow.
Great communication skills
Experience with data visualisation tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive or Pig.
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Experience building production-ready NLP systems
Familiarity with non-standard machine intelligence models (Reinforcement Learning, Hierarchical Temporal Memory, Capsule Networks) is a plus
Familiarity with Distributed systems (Docker, Kubernetes, Kafka, Spark, Redis, AWS S3/EC2/RDS/KMS, MongoDB, or Lucene) is a plus
Proficient understanding of code versioning tools such as Git, Mercurial or SVN, continuous integration tool like Jenkins.
Bachelor’s degree or higher in a technical field of study
Job Location: Indore, Mumbai | Openings",4.4,"GenieTalk
4.4",Indore,"Mumbai, India",1 to 50 employees,2016,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
30,Data Scientist,"Are you passionate about learning and intellectually curious? Do you thrive in a fast-paced, innovative work environment where team members hold themselves and others accountable? Are you energized by trying new things, have an agile mindset, and enjoy making an impact? Is working for a purpose driven organization important to you? If the answers to these questions are a resounding YES, then read on!

Skillsoft is the global leader in helping businesses solve their biggest challenge – attracting, motivating, and retaining world-class talent. Our team is recognized for cutting-edge digital learning and human capital management solutions. Trusted by the world's leading organizations, including 65% of the Fortune 500, we train more professionals than any other company in the world. Our 100,000+ courses, videos, and books are accessed over 130 million times every month, in 160 countries and 29 languages. At Skillsoft, we believe that knowledge is the fuel for innovation and innovation is the fuel for business growth.

Skillsoft’s SumTotal Strategic Business Unit has nearly 30 years of learning and HR software experience. High-performing organizations recognize that learning and development are core to their business success and overall talent management and workforce initiatives. That’s why more than 3,500 organizations, including many of Fortune’s “Best Places to Work,” rely on SumTotal’s solutions to enable their employees.

We are all about ""Making Work Matter."" With over 2,000 employees around the world, we are always looking for amazing talent!

Overview:
Opportunity Highlights:
Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.
Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
Develop company A/B testing framework and test model quality.
Develop processes and tools to monitor and analyze model performance and data accuracy.

Skills & Qualifications:
Bachelors and 5+ yrs. relevant experience required in Statistics, Math, Finance or other quantitative field or Master’s degree and 3+ years of post-degree experience in Statistics, Math, Finance or other quantitative field (preferred).
Problem Analysis Skills- Understand and be able to apply advanced modeling techniques such as logistic regression, generalized linear models, decision trees, cluster analysis, survival analysis, etc. to answer specific business queries or situations.
Independent - Advanced knowledge of the entire modelling process (design, develop, test, implement, measure) and demonstrated ability to manage time/resources to bring projects to completion.
Results Oriented - Proficient leveraging financial techniques i.e. ROI, NPV and Cashflow to measurement the effectiveness of tools/models.
Technical Expertise - Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets

Success Qualities:
Adaptable and Agile. Responds quickly to the changing needs of the business and is resilient in the face of setbacks or adversity.

Confident & Audacious Achiever. Champions breakthrough initiatives and holds him/herself and others accountable for delivering. Enjoys working hard; is action-oriented and full of energy for the things he/she sees as challenging; not fearful of acting without over-analysis.

Entrepreneurial Spirit with Learner’s Mindset. Is uncomfortable with simply maintaining ""status quo"" and is intellectually curious and demanding of excellence and continuous improvement.

Committed to our Collective Purpose. Leverages cross functional collaboration to solve complex business issues and drive greater results.

Authentic & Customer Centric. Never compromises integrity to achieve results while constantly being mindful of creating a positive customer experience both internally and externally. Adheres to an uncompromising set of core values and beliefs during both good and bad times; practices what he/she preaches. Acts with the highest standards of conduct and is seen as a direct, truthful individual.

Thank you for taking the time to learn more about us.
If this opportunity intrigues you, we'd love for you to apply!

NOTE TO EMPLOYMENT AGENCIES: We value the partnerships we have built with our preferred vendors. Skillsoft does not accept unsolicited resumes from employment agencies. All resumes submitted by employment agencies directly to any Skillsoft employee or hiring manager in any form without a signed Skillsoft Employment Agency Agreement on file and search engagement for that position will be deemed unsolicited in nature. No fee will be paid in the event the candidate is subsequently hired as a result of the referral or through other means.",2.8,"SumTotal
2.8",Andhra Pradesh,"Gainesville, FL",1001 to 5000 employees,1998,Subsidiary or Business Segment,Computer Hardware & Software,Information Technology,₹5 to ₹10 billion (INR),-1
31,Data Scientist,Data Scientist,3.6,"Bookmyshow
3.6",Mumbai,"Mumbai, India",1001 to 5000 employees,2007,Company - Private,Ticket Sales,"Arts, Entertainment & Recreation",Unknown / Non-Applicable,-1
32,Data Scientist,"Key Responsibilities
Build Data Pipelines for AI/ML Solutions using Python
Build Data Pipelines deployed at the edge (customer locations)
Programming skills:- Python (with working experience in most of common libraries like Scikit , numpy, pandas, mathplotlib, keras, tensorflow, nltk, genism, spacy etc)
Good knowledge in statistics and deep understanding on ML algorithms and their usage
Working experience in end to end data science project life cycles from use case framing, data collection, data exploration, model building, deployment
Working experience in most of the common Machine Learning techniques related to Time series, Regression, Classification, Clustering, NLP, working with IoT data
Good to have working exposure in common cloud environments and understanding of robust on premise data science infrastructure.
Nice to have understanding of big data related technologies and DevOps(Dockers, Singularity)
Other skills/ expectations
Good communication and presentation skill
Proven ability be creative and analytical in trouble shooting issues
Ability to work in a fast-paced and high-pressure environment to manage competing priorities
Qualifications

Education
Bachelor's Degree in computer sciences or related field
3+ total years of Experience
1+ years of relevant Experience

Functional Knowledge

Demonstrates expanded conceptual knowledge in own discipline and broadens capabilities

Business Expertise

Understands key business drivers; uses this understanding to accomplish own work

Leadership

No supervisory responsibilities but provides informal guidance to new team members

Problem Solving

Solves problems in straightforward situations; analyzes possible solutions using technical experience and judgment and precedents

Impact

Impacts quality of own work and the work of others on the team; works within guidelines and policies

Interpersonal Skills

Explains complex information to others in straightforward situations

Qualifications

Education:
Bachelor's Degree

Skills

Certifications:
Languages:
Years of Experience:
2 - 4 Years

Work Experience:
Additional Information

Travel:
Yes, 10% of the Time

Relocation Eligible:
Yes

Applied Materials is committed to diversity in its workforce including Equal Employment Opportunity for Minorities, Females, Protected Veterans and Individuals with Disabilities.",3.7,"Applied Materials Inc.
3.7",Bengaluru,"Santa Clara, CA",10000+ employees,1967,Company - Public,Electrical & Electronic Manufacturing,Manufacturing,₹500+ billion (INR),-1
33,Data Analyst,"Join a team recognized for leadership, innovation and diversity
JOB DETAILS:
Position: Data Analyst - IDQ
Experience: 3+ years

Job Description

Gather requirements from the Data Modelers and understand the design from the technical analysis provided.
Perform data profiling to understand data domains, validation rules and data dependencies
Develop Data Quality Mappings and Workflows, Preparation of Unit Test Case and Unit Test Data and data validation.
Develop Mapplets Using IDQ Tools and generate Profiling Reports for concerned Data.
Work with Informatica Data Quality 10.X (IDQ) toolkit, Analysis, data cleansing, data matching, data conversion, exception handling, and reporting and monitoring capabilities.
Develop IDQ mappings using various transformation like Standardization, Case Converter, Match and Address Validation Transformation.
Import mapplets and mappings from Informatica developer (IDQ) to Power Center.
Create generic rules in Informatica developer as per the business.
Design complex UNIX scripts and automate it to run the workflows daily, weekly and Monthly.
Schedule jobs and automate the workload using Autosys Job Scheduler, Control-M Job Scheduler or Informatica Scheduler (Any One)
Build reusable components for a scalable ETL
methodology such as error handling, logging and recoverability

Must Have

· Strong knowledge of master data management, match/merge, golden record concepts.

· Experience in creating ETL jobs with delta detection, SCD implementations, bulk loads, real-time integration.

· Good hands on experience on Informatica Data Quality tools and Informatic Power center tools

· Working experience in Partitions, Materialized views, Collections, Packages, Stored Procedure, Functions, DBMS packages, triggers etc.

· Implementing error and exception handling, auditing, data purging and restoration in ETL jobs.

· Strong SQL and PLSQL experience with working knowledge on databases such as Oracle, SQL Server, DB2, etc.

· Experience with trouble-shooting Informatica session failures and the ability to performance tuning of mappings.

We Value

· Knowledge on address doctor validation, Dun & Bradstreet enrichment

· Knowledge in Data Governance and Collibra will be a huge plus

· Good communication and interpersonal skills.

· Experience in Informatica MDM

""CORPIT2020""

Additional Information
JOB ID: HRD94071
Category: Information Technology
Location: Devarabisanahalli Village, KR Varturhobli,,East Taluk - Phase I,Bangalore,KARNATAKA,560103,India
Exempt
Business Services",3.8,"Honeywell
3.8",Bengaluru,"Charlotte, NC",10000+ employees,1885,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"GE, Johnson Controls, United Technologies"
34,Data Scientist,"Primary role

Staying abreast with the latest techniques and algorithms used in data analytics and overseeing their adoption by delivery teams. Leading in house efforts in researching newer and novel analytics methodologies. Expected to be actively involved in all stages of solution delivery to the client.

Secondary role

Mentoring junior staff.

Basic skills

An expert in any two or more of the following; Machine learning, Operations research, Agent based modeling, game theory, statistics or similar methodologies.

A strong experience with at least one of the following; R, Matlab, SAS, SPSS or similar packages.

A basic knowledge of one of the following; Python, C/C++, Java.

Preferred skills

Experience with analyzing actual business data.

Domain knowledge of industry verticals (such as healthcare, telecom etc.)

Education

PhD or MS (with peer reviewed publications) in a quantitative field, such as Physics, Machine Learning, Artificial Intelligence, Statistics, Mathematics, Engineering, etc.

If interested, kindly send your cv on hr@gaugeanalytics.com",3.1,"Gauge Data Solutions
3.1",Noida,"Noida, India",1 to 50 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
35,Data Scientist,"We are looking for a data scientist with an experience of 3+ years in deriving insights using analytical models handling vast amounts of data available across multiple platforms. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products. Experience in social media analytics is a must.

RESPONSIBILITIES
Data mining using state-of-the-art methods
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Selecting features, building and optimizing models using machine learning techniques
Doing ad-hoc analysis and presenting results in a clear manner
Creating proposals and presentations
SKILLS
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests etc.
Experience in Predictive modelling, ensemble modelling, sentiment analysis, NLP, Time-Series Analysis, Deep Learning, Reinforcement learning, Recommender Systems
Experience with common data science toolkits, such as R, Python etc.
Experience with data visualisation tools, such as Tableau, Power BI, Qlikview etc.
Proficiency in using query languages such as SQL and HQL
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Great communication skills
Benefits and Perks
Working with smart, young, mission-driven people
Approachable management team
Mobile allowance
Travel allowance
Regular team outings
Flexible Schedules",1.0,"Emerging India Group
1.0",India,"Noida, India",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
36,Data Scientist,"Job Description :
3+ years of experience as a Data Scientist in delivering building complex ML models and delivering key business insights and metrics for financial or product organizations
One or more analytic software tools or languages (e.g., R, Python, Hadoop)
Experience in applied analytics, descriptive statistics, and predictive analytics on industrial datasets
Demonstrated in modeling techniques, Predictive modeling, Supervised learning, Unsupervised learning, Machine Learning, Statistical Modeling
Experienced in working with large data sets, with big data processing tools like MapReduce, Spark, Hive, etc.
Experience with cloud service providers like AWS, GCP, Azure.
Understanding of how to apply predictive and machine learning techniques like logistic regression, random forest, GBM, Neural Nets, SVM etc is required
Additional Responsibilities
Work with business teams to understand the analytical products/platform being used, asks and identify opportunities to re-design using scalable open-source big data technologies
Work with large datasets to investigate key business trends, behaviours, and metrics
Develop, build and train machine learning models using a wide range of machine learning tools
Key Job Attributes :


Data Science
Data Scientist
Machine learning
Python
Hadoop

Educational Qualifications :


B.E/B.Tech

Key Skills :


Machine learning
Statistical modelling
Python
Predictive modeling
Mapreduce
Big data

Contact Details :


Email Id : anbu@handigital.com",3.6,"Han Digital Solution
3.6",Pune,"Bengaluru, India",51 to 200 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
37,Research Data Scientist,"dunnhumby is looking for a talented Applied Data Scientist!

You will execute projects to distil complex problems into compelling insights that resonate with clients, using the best of dunnhumby science.

What you'll be doing:
Build strong relationships with immediate internal contacts and direct external client to ensure full understanding of client requirements, ensuring clear and effective communication.
Investigate and implement the most appropriate analytical technique for each project, re-using and further developing global solutions or code written by others.
Deploy data science algorithms and market products on chosen tech stack for efficient and cost-effective delivery.
Execute projects that distil complex problems into compelling insights that resonate with clients.
Participate, as required, in client meetings to help explain the proposed methodology and solutions.
Document learnings after deploying solutions for a client to increase the existing knowledge repository.
Ensure smooth running of your projects, working with senior team members for direction.
Follow dunnhumby Quality Assurance processes, ways of working and meet coding standards.
Implement advice from colleagues to resolve challenges.
Who you’ll get to work with:

Within dunnhumby you’ll work with
Applied and Research Data Scientist teams
Client / Commercial teams
Global Capability teams
Data Science Engineering teams
Externally, you’ll frequently be in contact with:
Senior Retail/Customer Packaged Goods Analysts and Insights contacts
What you'll need:
Bachelor’s degree or equivalent in Computer Science, Artificial Intelligence, Machine Learning, Applied Statistics, Physics, Engineering or related field.
Experience with and passion for connecting your work directly to the customer experience, making a real and tangible impact.
Some experience with programming, and the ability to quickly pick up handling large data volumes with modern data processing tools, e.g. by using Hadoop / Spark / SQL / Python.
Analytical Techniques
Analytical Technology
Desk Research
Prototyping
Quality Assurance and Testing
Statistical Modelling
Programming (Python, SQL, R, …)
Data Interpretation/ Insight Analysis
Data Visualisation
Insight Storytelling
Client relationship building and management
Presentation skills
A plus if you also have:
Master’s degree or equivalent in in Computer Science, Artificial Intelligence, Machine Learning, Applied Statistics, Physics, Engineering or related field.
Programming experience on any standard data mining and modelling packages such as Python and R.",3.6,"dunnhumby
3.6",Gurgaon,"Hammersmith, United Kingdom",1001 to 5000 employees,1989,Company - Private,Consulting,Business Services,₹50 to ₹100 billion (INR),-1
38,Data Scientist,"As a Data Science Associate Manager at PayPal, you will apply your leadership, strategic and analytical skills to major company challenges. You will act as a business consultant to drive recommendations and implement solutions that ultimately impact the bottom line. And you will do it all by collaborating with a global team of colleagues across sales, operations, product, data science, and finance in an environment that values your insight, encourages you to take on new responsibility, promotes continuous learning, and rewards innovation.",3.2,"Stark Inc.
3.2",New Delhi,"Cambridge, MA",1001 to 5000 employees,1972,Non-profit Organisation,Aerospace & Defence,Aerospace & Defence,₹50 to ₹100 billion (INR),"BAE Systems USA, MITRE, Raytheon Technologies"
39,Specialist Data Scientist,"Primary Skills
Supervised and Unsupervised machine learning models
NLP Text Analytics - Text summarization- both abstractive and extractive types.
Exposure in solving Regression/Classification/Clustering problems in financial compliance domain.
Predictive Analytics in financial market domain.
Image recognition
Machine learning, data visualization, BI and data analytics
Algorithms such as linear regression, decision tree, random forest
Regularization techniques (Model Tuning)
A/B Testing.
Neural Networks
Data Modeling
Comprehensive knowledge of Algorithms like Multiple Linear Regression, Polynomial Regression, Ridge, Lasso, Logistic, K-NN, Decision Trees, Random Forest, XGBoost, K-means.
Complete understanding of neural network training process of Feed Forward and backpropagation along with complete understanding of ANN, CNN, RNN Networks.
Technology: Python, SQL, Tableau, MSSQL, Unix, AWS.

Responsibilities:
Understand the business domain and data
Extract data from various sources, perform data cleansing and transformation using Python.
Create required graphs and dashboards in Tableau to get deep insights into trends and data.
Dashboard creation using Tableau, Matplotlib and Seaborn library to get data insights.
Working with platform architects, Engineering team, Product Managers to understand & develop the Analytics solutions.
Should have good knowledge on Linux and windows servers
Good communication and presentation skills (English)
Strong analytical skills with an ability to influence decision making
A team player that demonstrates a strong work ethic, creativity, assertiveness, and flexibility


Preferred skills:
Experience with Agile Development methodologies, user stories, acceptance criteria, feature prioritization, and defining product specifications
Experience with product development.",3.7,"NICE
3.7",Pune,"Raanana, Israel",5001 to 10000 employees,1986,Company - Public,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 billion (INR),-1
40,Data Scientist,"Job Description
What will a 'Data Scientist - Data Analytics' do?
Providing a full range of Data and Analytic services(ML, Data Mining, EDA, Feature Engineering, Statistical modeling for Predictive and Prescriptive enterprise analytics) to clients across multiple sectors.
Applicants will be expected to work with a diverse set of data sources, such as time series data, spatial, graph data, semi-structured and unstructured data, and build statistical/machine-learning models in support of on-demand, real-time analytic services.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences, revenue generation and many other business outcomes.
Develop company A / B testing framework and test model quality.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Work with partners in Data Engineering, Product, Programmatic and business teams, to operationalize integration of analytic models into the production environment(s).
Stay current on relevant academic and industry developments to identify best-in-class algorithms, techniques, libraries, etc.

What we are looking for?

Business-minded data scientist with a demonstrated ability to deliver valuable insights via data analytics and advanced data-driven methods.
Developed intricate algorithms based on deep-dive statistical analysis and predictive data modeling.
Experience using statistical computer languages like R, SAS, Python etc.. to manipulate data and draw insights from large data sets.
Analyze and process complex data sets using advanced querying, visualization andanalytics tools.
Passion for solving unstructured and non-standard mathematical and behavioral problems
End-to-end experience with data, including querying, aggregation, analysis, and visualization.
Experience implementing Machine Learning and Deep Learning Algorithms, Data-Driven Personalization.
Excellent communication and presentation skills, being able to explain complex problems and the solutions applied.
Demonstrating data analysis and visualization with one or more leading COTS analytic and presentation solutions including Tableau, Power BI, Qlik view or Qlik Sense, and MS Excel and other MS Office suite applications.
Experience in an Agile environment (SAFe) and work within the Atlassian suite (Jira, Bitbucket, Confluence) and AWS or other computing environments.
Tools: R, Python, Spark, PySpark, Scala, Tensorflow, Keras, Big Data, AWS",4.0,"MTW LABS
4.0",Hyderabad,"Hyderabad, India",1 to 50 employees,2016,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
41,MS Data Scientist,"The MS
Data Scientist- Manager

Will be responsible to
define and implement the Client Data Management Strategy, considering the integrity,
governance and curation of the data in order to guarantee a smooth transition
data to EY Service Platform or Client legacy service platform. The role acts as
an interface to other service delivery partner groups (e.g. Business Systems,
Data Center), ensuring effective integration of the Data Management process
with other processes in order to meet service level requirements. Data
scientist will discover the information hidden in vast amounts of data, and make
smarter decisions to deliver even better products. The primary focus will be in
applying data mining techniques, doing statistical analysis, and building high
quality prediction systems integrated with our products
Essential Functions of the Job:
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art method
Extending company’s data with third party sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance
Define Client Data Management Strategy
Agree KPIs of the Client Data Transfer Process
Planning the Client Data Transfer activities in the MS project
Define the best transfer and storage tools for the specific client process
Verify client data structure and integrity
Mapping Client Data with the different process
Assess client data framework
Define and build data report to stakeholders
Define measurement and controls of data governance
Define client data transfer process reports
Manages the effective implementation of backup and restore procedures and working practices
Monitors backup and restore information, standards, procedures, measurements, tools and technology.
Ensures compliance with data architecture and data management standards and procedures defined in the Data Management Framework
Works closely with Service Level Management to ensure that data management services remain capable of meeting ongoing and future requirements
Estimates overall storage resource and budget requirements for Asset Management as input to the IT Plan in conjunction with other process owners.
Carries out the Process Manager responsibilities for the Data Management process

Primary Objectives:
Beyond what the person in the position actually does, list the primary goals and objectives of the position for its overall contribution to the MS organization.

The Data Scientist have to meet a number of general objectives:
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.
Experience with common data science toolkits
Experience with data visualisation tools
Proficiency in using query languages such as SQL, Hive, Pig, etc
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase, etc
Good applied statistics skills, such as distributions, statistical testing, regression, etc
Successfully implement the Data Management Strategy in the MS Transition phase
Ensure the integrity of client data during the Data Transfer Process
Implement process and activities accordingly with Data Management Framework

Knowledge and Skills Requirements:

Broad knowledge and experience in:
Data Stores in the Cloud
Service IT Platforms Knowledge

Business Process Modeling

Above average skills in:
Analyze data architecture
Data Base Management
Navigating Data Base SW
Self-starter with strong written and verbal communication skills.
Analytical and problem-solving skills

Excellent skills in:
Data Analytics Software Business
Intelligence SW Applications
Data Analytics Software

Job Requirements:

Education:
BSc/BA in computer science bachelor degree or similar
Master’s degree in computer science or similar is ideal

Experience:
10+/13 + years of experience in Data Management
Expertise in relationship building with different roles and level in the organization",3.8,"EY
3.8",India,"London, United Kingdom",10000+ employees,1989,Company - Private,Accounting,Accounting & Legal,₹500+ billion (INR),"Deloitte, KPMG, PwC"
42,Data Scientist,"Capable in creating analytics pipelines to pre process, visualize and create machine learning models using at least two of R/SAS/Python
Should have at least working knowledge of SQL and RDBMS
Should have worked on/lead projects using statistical analysis/regression/clustering/other supervised and non-supervised learning algorithms using R/SAS/Python - should have sound basics in Statistics and Machine learning.
Should have experience in working with clients in gathering the requirements and handling client queries
Should have a knack for Problem Solving using technology
Should be capable of working under tight deadlines independently",4.2,"Data Semantics
4.2",Bengaluru,"Bengaluru, India",51 to 200 employees,2012,Company - Private,IT Services,Information Technology,₹100 to ₹500 billion (INR),-1
43,Data Scientist,"• Good Knowledge on the automotive Communication protocols like CAN, Flex ray
• Sound knowledge on the Driver assistance systems (feature functions like lane departure prevention, collision avoidance etc.)
• Practical knowledge of automotive sensors like Camera, RADAR etc.
• Testing, Debugging and validation of application software as per the Requirement (in DOORS)

Additional skills: (Optional)
• Overview on Ethernet communication protocol
• Hands on with visualization tools for sensors
• Good Overview on analyzing time series data, (ASC, MAT, DAT file),
• Good knowledge on latest trends like LIDARs and multi-mode RADARs.
• Knowledge on Atlasian tools like Confluence, JIRA etc.

• Good Knowledge on the automotive Communication protocols like CAN, Flex ray
• Sound knowledge on the Driver assistance systems (feature functions like lane departure prevention, collision avoidance etc.)
• Practical knowledge of automotive sensors like Camera, RADAR etc.
• Testing, Debugging and validation of application software as per the Requirement (in DOORS)

Additional skills: (Optional)
• Overview on Ethernet communication protocol
• Hands on with visualization tools for sensors
• Good Overview on analyzing time series data, (ASC, MAT, DAT file),
• Good knowledge on latest trends like LIDARs and multi-mode RADARs.
• Knowledge on Atlasian tools like Confluence, JIRA etc.",4.2,"Daimler
4.2",Bengaluru,"Stuttgart, Germany",10000+ employees,1886,Company - Public,Transportation Equipment Manufacturing,Manufacturing,₹500+ billion (INR),"Audi, Porsche, BMW"
44,Data Scientist,"Click to Apply

Company Description

Entytle is at the perfect intersection of big data analysis, predictive analytics, machine learning and sales automation.

We are revolutionizing the way industrial OEM manufacturers can leverage existing information to make highly profitable data driven decisions and increase recurring revenue from their customer installed base.

Our highly satisfied customers have derived tremendous ROI from our cutting edge software.

Mission

Deliver innovative but pragmatic solutions to help our customers drive recurring revenue sales, increase loyalty and capture lifetime value from their customers.

Outcomes

Work collaboratively with Entytle stakeholders to create AI and Machine Learning algorithms that address recurring revenue sales
Utilize our data science platform to research and generate new insights into customer loyalty and lifetime value
Provide our internal teams and customers a clear understanding of the models and research generated

Position Description

The position reports to the Head of Data Science. You will work with other data scientists, engineers and product management team members in developing insights and innovative data science models (e.g. AI, ML) in support of our installed base sales automation application. Your communication skills will allow you to work with internal teams and, as needed, our manufacturing-based customers. You will use your agile experience to work with our geographically dispersed teams.

Responsibilities

Work with, as needed, customers to understand business challenges and propose new modeling and algorithmic solutions that leverage the latest in statistical and machine learning techniques.
Work collaboratively with the rest of the data science team, data engineers, developers and product management to translate business requirements into technical requirements that can be addressed with statistical and machine learning techniques.
Study data sources and find insights/correlation to investigate how data science can be used to solve existing and new business challenges.
Apply statistical analysis and modeling techniques on small and large datasets to solve specific business problems in the installed base sales automation domain.
Use best practices in applying and deploying data science at scale.

Competencies

Strong sense of and an ability to cultivate an environment of teamwork, and a willingness to help others.
Ability to effectively communicate technical concepts to both technical and non-technical staff members and customers.
Proficiency in data analysis and programming languages such as SQL, Python, and R.
2-4 years hands-on experience in machine learning, statistics or experiment design.
Master’s Degree required in Statistics, Mathematics, Econometrics, Operations Research, Computer Science, Physics or a related field with focus on data analysis.
Expertise in machine learning, statistics, data analysis. Must have an excellent knowledge of advanced methods, and experience in applying those methods to a variety of problems.
Solid grasp of probability, statistical or mathematical modeling with analytical and quantitative problem-solving ability. Experience with time-series analysis would be a plus.
Demonstrated experience in applying machine learning to real-world problems
Familiarity with software development cycles, source control systems (including Git), databases, and cloud computing platforms such as AWS.
Knowledge of large equipment manufacturing, installed base sales, recurring revenue, and equipment service would be a plus.",4.6,"Entytle
4.6",Pune,"Palo Alto, CA",1 to 50 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
45,Data Scientist,"Experience

1 to 4 years.

Roles and Responsibilities
Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
Develop company A/B testing framework and test model quality.
Coordinate with different functional teams to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Qualifications
Strong problem solving skills with an emphasis on product development.
Experience using statistical computer languages (R, Python, SQL, etc.) to manipulate data and draw insights from large data sets.
Experience working with and creating data architectures.
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
Excellent written and verbal communication skills for coordinating across teams.
A drive to learn and master new technologies and techniques.
Technologies and tools needed
R, Python, SQL.",-1,CogniSure,Bengaluru,"Warrenville, IL",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
46,Data Scientist-1,"Required Technical Skills
Good understanding of machine learning (both analytics and engineering).
Hadoop and big data technologies skills, streaming technology.
Robotics Process Automation techniques.
Artificial Intelligence.
Analytical mindset.
Good in Data Structure.
Good in Problem solving.
Preferred Technical Skills
Deep understanding of statistics and ML algorithms work internally with proficiency in at least 2 supervised and unsupervised algorithms in each bucket.
Supervised algorithms : Regression [linear/polynomial], Decision Tree, Random Forest or classification [Logistic Regression, Naïve Bayes, SVM etc]
- Model design and implementation : Experience in deriving feature sets, model training and testing

- Preferred tools and programming languages: TensorFlow/Keras, Python

- Exposure to Deep Learning and NLP is an added advantage.

Required Soft Skills
A team player who values collaboration, innovation, and inclusion.
Interested in keeping update with the latest technological developments.
Comfortable working in an Agile environment.
Strong verbal and written communication skills.
Interest in the payments industry.",3.6,"PayPal
3.6",Bengaluru,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple"
47,Data Scientist,"Data Scientist

Advanced Analytics - Data Scientist will execute advanced computational approaches to accelerate and optimize evidence-based pharmaceutical product development. He/She will leverage high-dimensional population health data to support R&D, Medical, HEVA, commercial product development, access and business strategy. The Advanced Analytics Data Scientist roles will generate analytics required by healthcare decision makers to support patient access and use of Sanofi medicines and he/she will contribute to the insights required by Sanofi internal teams to develop and commercialize the most impactful medicines.

People
Contribute to the Advanced Analytics plans for projects across R&D, Medical Affairs, HEVA and Market Access Strategies and Plans
Performance
Work with the latest tools and technologies that impact drug development.
Leverage analytics involving large datasets to refine and improve data models.
Build and construct prototypes of Advanced Analytic work-flows.
Process
Apply a broad array of capabilities spanning machine learning, statistics, text-mining/NLP, and modelling to extract insights to structured and unstructured healthcare data sources, pre-clinical, clinical trial and complementary real-world information streams.
Work on a variety of team-based projects providing expertise in analytical and computational approaches.
Design and implement data models, perform statistical analysis and create predictive analysis models
Required Skills & Experiences:
Experience with open source technologies, ML libraries, and programming languages (R, python)
Experience with advanced ML techniques - neural networks/deep learning, reinforcement learning, SVM, PCA, etc.
An ability to interact with a variety of large-scale data structures e.g. HDFS, SQL, noSQL
Experience working across multiple compute environments to create workflows and pipelines (e.g. HPC, cloud, Linux systems)
Experience with any of the following: biomedical data types/population health data/real world data/novel data streams.
Strong oral and written communication skills
A demonstrated ability to work and collaborate in a team environment
Desirable Skills & Experiences:
Experience with reproducible and collaborative technology platforms (e.g. GitHub, containers, Jupyter notebooks)
Experience with big data analytics platforms and/or workflow tools
Exposure to NLP technologies and analyses
Knowledge of some datavis technologies (ggplot2, shiny, plotly, d3, Tableau or Spotfire)
Qualifications
Relevant Masters degree, with at least 2-3 years of relevant industry experience (level II), or Masters degree with relevant Essential Skills and Experience (level I)
At Sanofi diversity and inclusion is foundational to how we operate and embedded in our Core Values. We recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our colleagues, patients and customers. We respect and celebrate the diversity of our people, their backgrounds and experiences and provide equal opportunity for all.",3.7,"Sanofi
3.7",Mumbai,"Paris, France",10000+ employees,1973,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Pfizer, GlaxoSmithKline"
48,Data Scientist,"Technical Skills:
A Ph.D., (or master’s degree plus at least 8 years’ relevant experience), in Computer Science, Statistics, Linguistics, Mathematics, Economics, Physics, or a related scientific discipline.
5+ years of experience working with large datasets for drawing business insights.
Research experience and coursework in Machine Learning
Experience with statistical software (e.g. MLlib, R, pandas) and database languages (e.g., SQL)
Fluency in Scala/Python programming.
Experience identifying business problems and selecting/finding the most appropriate data sets and statistical models to formulate solutions.
Experience with large data sets.
Strong understanding of statistics and modeling techniques.
Desire to work in a highly collaborative environment.
Experience with Natural Language Processing, Information Retrieval, or Recommender Systems.
Experience with distributed computing, such as Hadoop, Spark, or related technologies would also be an added advantage.
Experience with mathematical optimization, control theory, time-series analysis would also be an added advantage.

Additional Skills:
A strong work ethic and the ability to manage yourself and your time
Outstanding teamwork skills
Excellent written and verbal communication skills as well as active listening skills
Demonstrated analytical abilities
Experience managing and/or mentoring junior developers
Experience with Agile/SCRUM development methodologie",4.7,"Firminiq
4.7",Chandigarh,"Buffalo Grove, IL",51 to 200 employees,2018,Company - Private,IT Services,Information Technology,₹100 to ₹500 million (INR),-1
49,Data Scientist,"NLP, ML, Python/R, Hadoop, strong mathematical bacground
If you are intrested, please send us your resume at hr@teqnirvana.com",4.2,"TEQNirvana
4.2",Mumbai,"Bengaluru, India",1 to 50 employees,2005,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
50,Data Scientist,"Do you feel passionately about solving problems through data? Have you spent 2+ years solving business problems through data?

Do you aspire to take data science to millions of people out there? Can the leader in you make people follow data science out of sheer passion? Would you enjoy helping people solve problems with out expecting any thing in return?

If the answer to all the questions is yes – look no more. Analytics Vidhya is looking for evangelists who can carry and deliver their baton to the world.

What should you expect?
A team of best data scientists and thought leaders from industry.
Disciplined entrepreneurship within team. Each person is owner of his own work – you set the milestones, the pace and the achievements.
High standards, deep passion for data science and a commitment to find out ways to make things work.

Who can fill in the shoes?

This role is best suited for:
Person with 2+ years of experience in data science. The person should have prior experience with practical data science applications and use cases.
Person who loves problem solving through data. She/He should be able to do things hands on by himself or guide a team of data scientists to solve a problem.
A person with deep experience in tools like SAS / R / Python / Julia / Matlab and machine learning / predictive modeling techniques/ Machine Learning Algorithms.
Strong problem solving and communication skills (English).
An avid reader.

What is the role?

Being a startup, the role would evolve over time. But, here are a few things you can expect:

Creating problems for our hackathons by working closely with the clients
Continuously learning new skills and evangelizing them with in our community
Defining and leading our strategy in making data science easy and accessible to all
Leading industry events, meetups, webinars and competitions
Develop custom data models and algorithms to apply to data problems
Use predictive modeling to increase and optimize customer experiences and other business outcomes.

Where is the role based?

We would love to have you in our office in Gurgaon.

If the role excites you, drop an email to hiring@analyticsvidhya.com with your CV, mentioning “Why do you think you are the perfect fit for this role”.",4.1,"Analytics Vidhya
4.1",Gurgaon,"Gurgaon, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
51,Data Scientist,"JOB DESCRIPTION

Data Scientist

Role : Data Scientist

Experience : 5+ years

Education

Graduation / Post Graduation : Specialization in Computer Science, Software Engineering, Business Analytics etc.

Role Background

Inteliment is looking for people who aspire to solve real and complex business problems with their Data Science expertise. You will be a part of our Data Science Centre of Excellence that implements Inteliment’s Data Science Platform as well as on other industry leading platforms.

Key Responsibilities

Work closely with product engineering, client and project teams and align them with respect to your focus area.

Developing advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner.

Enhancing data collection, processing, cleansing and verifying the integrity of data used for advance analytics

Be a subject matter expert in Data Science Platform Data Science & Analytics products and offerings.

Selecting features, building and optimizing classifiers using machine learning techniques, understand and work around possible limitations in models.

To develop hypothesis and test them with careful experiments.

Aid in project planning to determine effort and time estimations.

Contributing to creation of knowledgebase for Technology platform & practise and related KMS initiatives.

Required Skills

Data-oriented personality with a good scripting and programming skills and hands-on expertise on data science toolkits, such as R, MatLab, SAS, SPSS

Hands-on expertise and exposure in NLP, machine & deep learning algorithms, model building, statistical modelling, predictive modelling environments

Excellent track record of delivery using languages like Python, R, Java and technologies like Hadoop, Git / Stash, JIRA / Rally etc.

Desired Skills

Demonstrated clear and thorough logical and analytical thinking, as well as problem solving skills

Self-directed, ability to work independently and research innovative solutions to business problems

Must be flexible to travel onsite if required.

Effective interpersonal communication across various levels of the organization.

Ability to interpret, evaluate and communicate detailed information in a manner that is appropriate to the audience.

Ability to conduct root cause analysis and performance tuning for complex business processes and functionality.

Ability to interact with IT and business users across the organization to resolve issues and provide solutions in a timely manner.

Should be proactive & transparent in the in the deliverables & critical thinker while designing the solutions.

Team oriented and enjoys working in a collaborative development environment.

Tools & Technologies

Excellent track record of delivery using languages like Python, R, Java and technologies like Hadoop, Git / Stash, JIRA / Rally, SAS, SPSS, Statistic etc.

Experience with NoSQL databases (MongoDB, Cassandra, HBase) and SQL, Hive, Pig.

Experience with data-viz tools to present trends, forecasts, patters Tools & Technologies

If you have got it all.. What are you waiting for?",3.8,"inteliment
3.8",Pune,"Pune, India",51 to 200 employees,-1,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
52,Data Scientist,"Position title
Data Scientist
Description
Excellent understanding of machine learning techniques and algorithms
Proficiency with R/ Octave for modeling, Python & Java for production-ready code.
Experience with common data science toolkits, such as R/ Octave for modeling, Python & Java for production-ready code. Excellence in at least one of these is highly desirable.
Experience with data visualization and extracting insights from them.
Proficiency in using query languages such as SQL, Learning in the area of NLP, predictive models & recommendation engines is a big plus
Crunch a large volume of data, observe trends and build scalable & analytical models.
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Data-oriented personality
Good knowledge of databases like NoSQL, MongoDB, Postgre, etc.
Perform Exploratory Data Analysis and Statistical Analysis; clearly present the results of an analysis to customers and management.
Experience with AWS, Google Cloud is a plus
Exposure with deep learning algorithms is a big plus
Required Skills
Selecting features, building and optimizing models using machine learning techniques
Data mining using state-of-the-art methods
Extending company’s data with third party sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance
Adopting new research methodologies including deep learning (CNNs LSTMs) on projects
Job Responsibilities
Bachelors/ Masters in Computer Science or Electronics from tier 1 & 2 colleges
Contacts

careers@algoscale.com",3.7,"Algoscale
3.7",Noida,"Noida, India",1 to 50 employees,2014,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
53,Data Scientist,"Job Title
Data Scientist

18-May-2020

No. of Positions
1

Job Description
General Position Definition
Finance & Data Operations Data Science Team is tasked with delivering tangible value to business units within Shell through data-driven decision making.
This position is part of Finance & Data Operations Data Science team delivering advanced analytics projects for different businesses within Shell. The individual will join a growing global data science organization spanning both on/offshore.
Incumbent is responsible for developing analytical models for projects collaborating with different business stakeholders & other partners and working across a range of technologies and tools.
The ideal candidate has strong background in quantitative skills (like statistics, mathematics, advanced computing, machine learning) and has applied those skills in solving real world problems across different businesses / functions.
Purpose
Develops analytics models using specialized tools based on the business problem and data available
Identifies the right set of models and develops the right code / package to execute them
Evaluates the validity of the model (both scientifically as well as from a business perspective)
Support the Data Science Team Lead in design and execution of analytics projects
Work with Shell stakeholders and subject matter experts to complete tasks and deliverables on projects
Skills
Stakeholder Engagement Skills
Working collaboratively across multiple sets of stakeholders – business SMEs, IT, Data teams, Analytics resources, etc. to deliver on project deliverables and tasks
Identify actionable insights that directly address challenges / opportunities
Articulate business insights and recommendations (based on model output) to respective stakeholders
Understanding business KPI's, frameworks and drivers for performance
Proficiency Level: Skill
Industry / Functional Expertise
Provide deep business expertise preferably Oil & Gas - Upstream or Downstream businesses. (If these are not available, willing to consider other industries that are similar or related - manufacturing, mining, power generation, etc.)
functional expertise in any one or more of the following industry / functional areas
Manufacturing / Industrial: Equipment Failure prediction, Maintenance Scheduling & Optimization, Inventory optimization, Cost Diagnostics, Energy Management
Customer / Marketing – pricing analytics, churn prediction, cross-sell / up-sell, Market Basket Analysis, Product Recommendation, Marketing Mix Modeling, Campaign design and effectiveness testing, Network Modeling, Customer segmentation, propensity analysis, customer lifetime value, profitability analysis, Customer experience (incl. voice of customer), CRM, Loyalty program management,
Supply Chain / Spend: Demand & Supply Forecasting, Spend Analytics, Vendor Scoring, Pricing analysis (buy-side), product substitution analysis, product portfolio optimization, Tail spend analysis, logistics / network / route optimization, Contract Compliance
Functional Analytics: Order-to-cash, Procure-to-Pay, Record-to-Report, Tax (Direct & Indirect), Financial Risk and Assurance (controls and governance), Master Data Management, Inter-group / Intra-group
Trading & Risk Management: Across Credit & Market Risk - Value at Risk (VAR), Back testing, Stress testing
Proficiency Level: Skill
Modeling and Technology Skills
Deep expertise in machine learning techniques (supervised and unsupervised) statistics / mathematics / operations research including (but not limited to):
Advanced Machine learning techniques: Decision Trees, Neural Networks, Deep Learning, Support Vector Machines, Clustering, Bayesian Networks, Reinforcement Learning, Feature Reduction / engineering, Anomaly deduction, Natural Language Processing (incl. Theme deduction, sentiment analysis, Topic Modeling), Natural Language Generation
Statistics / Mathematics: Data Quality Analysis, Data identification, Hypothesis testing, Univariate / Multivariate Analysis, Cluster Analysis, Classification/PCA, Factor Analysis, Linear Modeling, Logit/Probit Model, Affinity & Association, Time Series, DoE, distribution / probability theory
Operations Research: Sensitivity Analysis – Shadow price, Allowable decrease or increase, Transportation problem & variants, Allocation Problem & variants, Selection problem, Multi-criteria decision-making, models, DEA, Employee Scheduling, Knapsack problem, Supply Chain Problem & variants, Location Selection, Network designing – VRP, TSP, Heuristics Modeling
Risk: Simulation design and high-performance computing, GARCH modeling, Macro-economic / Market behaviour modeling
Process Analytics Process Discovery / Mining, BottleNeck analysis, Confirmation Testing, Process Benchmarking, Gap-to-Potential Assessment, SAP Data Models, SAP Table Structures (across SAP Modules – 5-6 of the following: General Ledger Accounting, Accounts Payable, Accounts Receivable, Purchasing, Inventory Management, Material Planning, Invoice Verification, Material Requirement Planning (MRP), Warehouse Management, Vendor Valuation, Sales, Sales, Shipping and transportation, Billing or Invoice generation, Bills of Material (BOM), Sales Information system, Credit Control, Sales and production Planning, Demand Management, Material Requirement Planning, Capacity Requirement Planning
Typically, each role will look at one of two of the above skills – not all of them
Strong experience in specialized analytics tools and technologies (including, but not limited to)
SAS, Python, R, SPSS (preferably two out of 4)
Spotfire, Tableau, Qlickview
For Operations Research (AIMS, Cplex, Matlab)
Awareness of Data Bricks, Apache Spark, Hadoop
Awareness of Agile / Scrum ways of working
Identify the right modeling approach(es) for given scenario and articulate why the approach fits
Assess data availability and modeling feasibility
Review interpretation of models results
Evaluate model fit and based on business / function scenario
Proficiency Level: Skill-to-Mastery
Special Challenges
Rapid onboarding on projects, understanding analytics goal and working with ill-defined datasets
Communicating technical jargon in plain English to colleagues within Data Science team and outside
Virtual working with network of colleagues located throughout the globe
Dimensions
Support design and delivery of analytics projects, within or cutting across upstream and downstream business units in Shell
Auto req ID
134728BR

Country of Work Location
India

Employment Type
Full Time

Company Description
The aim of the Shell Business Operations, Chennai is to provide the Group with operational excellence through highlighting and utilizing process improvements and functional efficiencies as well as by leveraging economies of scale. Currently, the Chennai centre provides a wide range of finance, accounting and business services to Shell operating companies across several business sectors globally.

Set up in September 2007, the Chennai centre has grown rapidly and now , in its fourth year of operations , it has crossed the 1600 staff mark. The centre is located in the RMZ Millennia Business Park, where the Shell campus is a LEED Platinum building with world class infrastructure. The business is expected to grow further over the next two years and infrastructural additions to support this have been planned.

The main focus in Chennai is on Finance Operations which supports delivery of the global Finance functional plan. There is also a ‘Downstream India’ - Customer Services Team that handles lubricant depot ordering within the country. The Shell Business Operations (SBO Team) manages the centre facilities and supports business partners’ operations on site. There is a strong focus at SBO on safety & well being of staff and on its three core values: Compliance, Intervention & Respect.

Disclaimer
Please note: We occasionally amend or withdraw Shell jobs and reserve the right to do so at any time, including prior to the advertised closing date.

Before applying, you are advised to read our data protection policy. This policy describes the processing that may be associated with your personal data and informs you that your personal data may be transferred to Royal Dutch/Shell Group companies around the world.

The Shell Group and its approved recruitment consultants will never ask you for a fee to process or consider your application for a career with Shell. Anyone who demands such a fee is not an authorised Shell representative and you are strongly advised to refuse any such demand.

Shell is an Equal Opportunity Employer.

Work Location
Chennai - RMZ Millenia

Requirements
5+ years of relevant experience
Advanced university degree in Mathematics, Statistics, Engineering, Economics, Quantitative Finance, OR, etc.
Good interpersonal communication skills and influencing skills
Eagerness to learn and ability to work with limited supervision
SBO Location
Chennai

City, State (if applicable)
Chennai",4.0,"Shell
4.0",Chennai,"Houston, TX",10000+ employees,1907,Company - Public,Oil & Gas Exploration & Production,"Oil, Gas, Energy & Utilities",₹500+ billion (INR),"ExxonMobil, BP, Chevron"
54,Data Scientist,"AppZen delivers the world’s leading AI platform for modern finance teams. Starting with business spend, we automate manual process, uncover problems, and optimize decision making for enterprises around the globe, including one-fourth of the Fortune 500. Our platform combines patented deep learning, computer vision, and semantic analysis with intelligence from thousands of online data sources to understand financial transactions in business context and make decisions before those transactions happen. AppZen is a must have for CFOs and their teams to reduce spend, achieve compliance, and streamline process.

We’ve taken off this year! Since we released our platform in 2016, over 1,800 enterprises have standardized on AppZen, including three of the top ten banks, four of the top ten media companies, three of the top ten pharmaceutical manufacturers, two of the top five aerospace companies, and five of the top ten software providers. We were a Gartner Cool Vendor last year, have been recognized as one of the fastest-growing technology companies in the market, and we just announced $50 million in Series C funding.

We are looking for a Data Scientist to come and work on our growing AI stack. You will be working with a team of highly skilled and motivated data scientists and machine learning engineers. If you are excited about natural language understanding and machine translation, AppZen is the right place for you to apply and grow your skills.

Must-Have:
Solid understanding of machine learning fundamentals, and familiar with standard algorithms and techniques.
Ability to analyze a wide variety of data: structured and unstructured, observational and experimental, to drive system designs and product implementations.
Expert knowledge of a statistical computing language such as Python or R Knowledge of probability and statistics, including experimental design, predictive modeling, optimization, and causal inference Experience in design and deployment of real-world, large-scale, user-facing systems.
Ensure data quality throughout all stages of acquisition and processing, including such areas as data sourcing/collection, ground truth generation, normalization, transformation, cross-lingual alignment/mapping, etc.
Manage your own process: identify and execute on high impact projects, triage external requests, and make sure you bring projects to conclusion in time for the results to be useful.
Excellent written and verbal technical communication skills; communicate proposals and results in a clear manner backed by data and coupled with actionable conclusions to drive business decisions.
M.Sc. or M.E. or M.Tech in Computer Science, Engineering, Statistics, or other relevant technical fieldMust have 4-6 years of industry experience.
Able to work onsite in Pune, IN
You are a team player
Come as you are, we do not discriminate! We celebrate, support, and thrive upon our diverse customer and employee base.",3.6,"AppZen
3.6",Pune,"San Jose, CA",201 to 500 employees,2012,Company - Private,Financial Transaction Processing,Finance,₹500 million to ₹1 billion (INR),-1
55,Applied Scientist,"Amazons Selection Monitoring team is responsible for making the biggest catalog on the planet even bigger. We build software to find products not already sold on Amazon and algorithmically add them to the Amazon catalog. Our work involves building Information Retrieval (IR) infrastructure, Machine Learning systems, and distributed compute and storage systems to process data at cloud-scale to extend and enrich the Amazon catalog. We apply the state- of- the-art Web-mining, Cloud Computing and Deep Learning to process millions of products from the web every day and make the data actionable. We constantly stretch the boundaries of Machine Learning to tackle business challenges. If you are customer obsessed, self-driven, tenacious and analytical, you will have fun solving our business problems of unprecedented scale. As an experienced machine learning scientist, you will help research and develop new computer algorithms leveraging both classical and deep learning techniques.

We are looking for ML Scientist to tackle challenging problems in the areas of information retrieval at internet scale using data science. You should have depth and breadth of knowledge in text mining, information retrieval and deep learning. You should also have programming and design skills to manipulate unstructured data and systems that work at internet scale.


You will encounter many challenges, including
· Scale (build models to handle billions of pages),
· Accuracy (extreme requirements for precision and recall),
· Speed (generate predictions for millions of new or changed pages with low latency),
· Diversity (models need to work across different languages, market places and data sources)

Come join us in our journey to make everything and yes, we do mean *everything* that anyone wants to buy, available on Amazon!

Basic Qualifications


· Bachelors/Master Degree in Computer Science with advanced degrees preferred.
· 5+ years of hands on experience in building machine learning systems for large data sets.
· Strong skills in problem solving, programming and computer science fundamentals.
· Expertise in using Python, Java / C++, or other programming languages, as well as ML toolkits such as scikit-learn, Theano, Tensorflow, Keras or similar machine learning tools.



Preferred Qualifications


· PhDs, specialized in Information Retrieval and Machine Learning.
· Experience in designing and implementing information retrieval, web mining systems using Deep Learning and Neural Networks.
· Big thinker that can take broad visions and concepts and develop structured plans, actions and measurable metrics and then execute those plans.",4.2,"Amazon
4.2",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
56,Data Scientist,"This position requires a person to design, implement and processes large data sets used for modeling, data mining.

Responsibilities :
Develop and plan required analytic projects in response to business needs.
In conjunction with data owners and department managers, contribute to the development of data models and protocols for mining production databases.
Develop new analytical methods and/or tools as required.
Contribute to data mining architectures, modeling standards, reporting, and data analysis methodologies.
Conduct research and make recommendations on data mining products, services, protocols, and standards in support of procurement and development efforts.
Work with application developers to extract data relevant for analysis.
Collaborate with unit managers, end users, development staff, and other stakeholders to integrate data mining results with existing systems.
Provide and apply quality assurance best practices for data mining/analysis services.
Adhere to change control and testing processes for modifications to analytical models.
Create data definitions for new database file/table development and/or changes to existing ones as needed for analysis.
Determine required network components to ensure data access, as well as data consistency and integrity.
Respond to and resolve data mining performance issues. Monitor data mining system performance and implement efficiency improvements.
Manage and/or provide guidance to junior members of the team.

Send us the Resume at info@zettamine.com",3.9,"ZettaMine
3.9",Hyderabad,"Hyderabad, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
57,Data Scientist,"RequirementsBS/MS degree in Computer science, MathsYou are experienced with data stores such as Mysql, MongoDB, Cassandra, HBase, HiveExperienced with data visualisation tools, such as Tableau, D3.js, GGplot, etcPast experience with Deep Learning/NLP would be an advantage (although not necessary)Good Communication SkillsTeam PlayerWhat We Expect.?You take pride in your knowledge of design patterns, algorithms and data structuresYou are comfortable processing, cleansing, and verifying the integrity of data used for analysisYou understand machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, CART, CHAID etcYou understand feature selection, model performance metrics, building and optimizing machine learning modelsYou are good at doing ad-hoc analysis and presenting results in a clear mannerYou are good at creating automated anomaly detection systems and constant performance trackingYou can code comfortably in R & Python (NumPy, sklearn, xgboost)",5.0,"Pivotchain Solutions
5.0",Maharashtra,"Viman Nagar, India",1 to 50 employees,2017,Company - Private,-1,-1,Unknown / Non-Applicable,-1
58,Data Scientist,"We are looking for a Data Scientist with experience of 3-6 years that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in building data science solutions using machine learning algorithms, doing statistical analysis, and building high quality prediction systems integrated with our products.

Responsibilities:
Identifying the key problem in the system and proposing a solution
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Identify third party data that can be used to enhance the information gained
Processing, cleansing, and verifying the integrity of data used for analysis
Building unsupervised and supervised learning algorithms on existing data such that systems should be proactive in nature

Skills and Qualifications
3-6 years of experience with post graduate/Phd degree in mathematics, statistics, IT or Computer science from IIT/IIIT/NIT/recognized universities
Excellent understanding of machine learning techniques and algorithms, such as Random Forest, Regression, XG Boost, k-NN, Naive Bayes, SVM, Decision Forests, etc.
Experience with common data science toolkits, such as R, Python, Octave, Java. Excellence in at least one of these is a must.
Great communication skills
Proficiency in SQL is must.
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase will be good to have.
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Data-oriented personality
To apply on this job, email your resume at alka.dhingra@magicbricks.com",3.8,"Magicbricks
3.8",Bengaluru,"Noida, India",1001 to 5000 employees,2006,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
59,Data Scientist,"Data Scientist


Full time

-

Pune

The Company


Talentica Software is a boutique software development company started by ex-IITB grads and industry veterans. It is a privately held company. The company is 16 years old and 400+ employees work exclusively for startups as Tech Partners taking them from a Series-A position to Series-B position and possible acquisition (for example Citrus Pay).
We have built products for over 125 startups, most of them are based in the Bay Area or Europe. These startups come to us primarily because we know the issues that plague startup product development and the solutions for the same, thereby improving their success chances. Owing to the unique space we are in, we deal extensively with cutting edge technology.

The data science team works under the purview of the Technology Excellence Group at Talentica Software. The goal of this team is to solve problems and build algorithms that are typically data driven. Hence, problems involving statistics, optimization, computer vision, machine learning, and natural language processing are of interest to this group.

We are looking to hire a Data Scientist with Computer Vision and Machine Learning experience.

Here is what we are looking for in prospective candidates: Mandatory
Has completed his/her PhD from one of the old IITs or IISc-Bangalore
Should have completed full-time PhD degree
Graduated from IIT or IISc or IIIT-Hyderabad or ISI-Kolkata with a Master’s degree
Should have at least one published full paper in CVPR or ECCV or ICML or NIPS
Excellent programming skills and must be able to implement complex algorithms in Python
Hands-on experience with use of standard image processing and machine learning libraries such as OpenCV, Tensorflow, Keras

Here is what we are looking for in prospective candidates: Good to have
Graduated from IIT-Bombay or IISc-Bangalore or IIT-Delhi
Not required for the current role but it is good to have worked with Mongo/Cassandra/PostgreSQL/Neo4J
Credited courses focused on linear algebra, stochastic models, pattern recognition, design and analysis of algorithms, machine learning
Interest in applications of computer vision algorithms for video, shape recognition, matching & retrieval

Experience:
Should have worked in the industry for at least 2 years.
Should like to work in a startup environment.
Should be capable of converting theory to practice by reading relevant papers.
Should be capable of conceiving original ideas and coding them as working algorithms.",3.8,"Talentica
3.8",Pune,"Pune, India",201 to 500 employees,2003,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
60,Data Scientist,"We are looking for strong Data Scientists/Analysts, who will be problem solvers, using predictive modelling techniques and machine learning algorithms, to solve complex business problems in credit and risk domains, and also provide business strategies.

Roles and Responsibilities:
Use of cutting edge machine learning techniques for solving supervised and unsupervised learning problems
Design analytical solutions for complex business problems
Dig deep into data, understand characteristics, evaluate and validate hypotheses through empirical approaches
Recommend and implement best practices around application of statistical modelling
Develop and implement predictive models solving business problems and recommend actionable insights
Mentor and train new recruits
Qualification & Experience
2+ years of experience in the field of analytics, predictive modeling or data science
Strong with programming languages like Python and data processing using SQL or equivalent
Strong with analytical and statistical packages like R, Python Scikit-Learn
Additional familiarity with C/C++ welcome
Experience with the following machine learning algorithms desirable: Gradient Boosting, Decision Trees, Logistic Regression, Random Forests, Deep Neural Networks, Ensemble methods
Experience with NoSQL and distributed data processing technologies such as Hadoop is also desirable
Bachelor or Master in Operations Research, Computer Engineering or in closely related Quantitative Disciplines from a premier institution.
Interested? Please send your resume to careersindia@applieddatafinance.com.",4.5,"Applied Data Finance
4.5",Chennai,"San Diego, CA",51 to 200 employees,2014,Company - Private,Lending,Finance,Unknown / Non-Applicable,Avant
61,Data Scientist,"Educational qualifications
B Tech/ BE, M.Sc.(Maths) or M Tech/ MS or equivalent in Mechanical/Metallurgical/ Electrical/ Electronics/ Computer Science/Instrumentation/Industrial Engineering/Operations Research or in any other relevant discipline.

Relevant experience (Type/ Nature and years of relevant experience required to execute the role)
Min. 2-4 years of experience

Locations: Jamshedpur / Kalinga nagar / Kolkata/ Mumbai

Experience related to advanced analytics
Machine learning, Deep learning, Fuzzy logic, data visualisation, statistics, Derived data analysis etc.
Programming and process trouble-shooting experience will be preferred.
Exposure to mathematical modelling will be preferred.
Understanding of statistics and statistical modelling will be required.
Good process knowledge related to supply chain, iron and steel manufacturing, marketing or mining/mineral processing is preferable.
Programming skills using a high level language (preferably in .net environment) will be necessary.
Knowledge on data acquisition, analytics, statistics and other mathematical modelling tools will be useful.
Sound concepts on Big data analytics will be helpful.

Technical Competencies
Statistics, Data analytics, Artificial intelligence, programming, system engineering and flow design, Logic building, Scenario analysis.
Coding in R/ Python language is Compulsory.

Behavioral Competencies
Learning inclination, Collaboration, Achievement orientation, change orientation",-1,Imurgence,Jamshedpur,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
62,Data Scientist,"Qualification: BS/MS/MCA, BCA in Computer Science or equivalent Experience: 3+ Years

Key Responsibilities:
Dive into the data and identify patterns
Development of end-to-end models and policy for our existing products
Development of Fraud models and fraud rule engine
Collaborate with various stakeholders (e.g. tech, product) to understand and design best solutions which can be implemented
Work on cutting-edge techniques e.g. machine learning and deep learning models

Skills Required:
Strong Mathematics Basics
Proficiency in Python, Matlab, C++ or any other AI language of choice
Demonstrated expertise in solving Data Science problems from first principles
Familiarity with relational and NoSQL databases
Experience with Unix/Linux
Good Problem solving & Analytical Skills",3.9,"Redian Software
3.9",Gurgaon,"Noida, India",1 to 50 employees,2016,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
63,Data Scientist,"Data Scientist ( > 4 years experience ) :
Should be highly skilled in using deep learning algorithms and have expertise on tweaking them for Dunzo specific problem statement
Should be able to program in python. Should be highly skilled in this.
Should have experience in formulating problem statement and decide what data can help in solving the problem.
Should have overall idea on how to put machine learning models into production. Although there is no need to work on this directly, it is important to guide data engineering and backend team for getting desired results
Should be able to communicate with business and other stakeholders for understanding problems for producing possible solutions. Should give demos for proof of concepts(poc)
Should be interested in learning about advancements in deep learning field and going through research papers and latest updates of the field.
Should have skills in using pandas,numpy, scipy, sklearn, spacy, nltk, keras/pytorch/tensorflow and familiar in using gpu machines for training purpose
Should have an attitude of owning the problem and generating industry standard solutions and ultimately reach to state of the art solutions to the problems.
It will be really great if presenting at tech conferences is one of the interests. Also, we encourage you to write on tech blog. This part is optional",3.2,"Dunzo
3.2",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
64,Data Scientist,"Greetings from Careator Technologies Private Limited., (CTPL).

CAREATOR Technologies is an emerging technology company, based on the strengths of understanding evolution of technologies right from the inception stage, offers a wide spectrum of services that span across both Application Life Cycle Management process of Software Engineering and Resource Management of Projects that deliver complex IT solutions for critical business processes. We @ CAREATOR, closely work with best MNCs (Product Based Companies & Service Based Companies) in India, UK, Australia, Canada & USA. CAREATOR is always been successful in meeting their customer needs and follows best IT practices to retain the right talented professional

We are hiring the following professionals on immediate basis. If you are interested and suitable for this position, please apply immediately.

Experience: 2-5 Years

Job Summary

Design and execute statistical analysis, modelling, and simulation efforts for clients that lead to actionable decisions affecting operations.

Analyse data sets to summarize, identify trends, predict future states, and characterize uncertainty.

Author complex written products documenting study results. Apply analytical approaches using statistical programming languages, including Python, and R.

Work closely with teammates from non-mathematical disciplines to ensure that operational strategies are considered in the context of applying statistical theory.

Use statistical theory on modelling, simulation, and data analysis to deliver measurable improvements to organizational policies and programs.

Responsibilities
Engage in data mining, algorithm development, statistical analysis, regression, and machine-learning initiatives
As part of ongoing work and interaction with the broader team, identify new opportunities to use modelling and advanced analytics to drive business value
High Proficiency in SQL
Expertise in applied statistics.
Able to translate business objectives into actionable analyses.
Able to communicate findings clearly to both technical and non-technical audiences
Expertise in Python for ML model development.
Experience with machine learning & Deep learning algorithms and predictive analytics
Natural curiosity to enjoy diving deep into the material to find answers to yet unknown questions.
Demonstrated ability to perform comfortably in a fast-paced work environment
Education, Skills and Abilities Required for Consideration:
Sound experience in using statistical and data mining techniques to solve real business problems
Having skills on Python for ML model Development
Passion for problem-solving, developing creative solutions, and continuous learning.
1+ years of Experience in Automotive / Mechanical background.
2+ years of ML/ Data science Experience
Good to have: Having worked on connected device. Having Idea on Clustering etc
Preferred : Deep Learning with Pytorch or TensorFLow Location: Bangalore",4.4,"Careator Technologies
4.4",Bengaluru,"Hyderabad, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
65,Data Scientist,"About the Company

Meesho is India’s top reselling platform, used by more than 1 million resellers across the country. Resellers are small business owners and home entrepreneurs who sell stuff using Meesho, within their extended social circles. Meesho is reimagining e-commerce for India, and building a platform for the next 20 million entrepreneurs in the country.

Meesho is one of the fastest growing startups in the world, and is backed by top investors globally, including DST Global, YCombinator and Sequoia. You can read more about Meesho’s journey on TechCrunch.

About the role

As a data driven organisation with the core mission of empowering 20 million entrepreneurs throughout the country, Data scientists are an integral part of the Meesho team. You'll develop models and run experiments to infer insights from hard data that meaningfully impacts our 1Million+ resellers. From improving our product usability to identifying new growth opportunities data scientists help all teams within Meesho develop effective solutions.

Here are some of the problems you'll be working on: -

- Understanding reseller preferences to provide them with the most relevant products

- Modelling which resellers will be the most impacted by changes in our incentive structures

- Designing discount programs to help our resellers sell more

- Inferring insights from our existing data to identify new growth opportunities

- Designing experiments to improve usability across our product suite

- How can you help resellers better recognise end customer preferences to improve their revenue?

- Using data to identify bottlenecks that helps our suppliers meet their SLA requirements

- What frontend visualisations will best help category managers understand the current demand for products?

- Modelling seasonal demand to predict key organisational metrics

Mandatory Requirements:-
Bachelor’s Degree from a Tier 1 school (IIT, NIT, IIIT, BITS, DCE)
1-3 years of experience as a Data Scientist
Familiarity with concepts like Neural Networks, Machine Learning etc and tools like SQL, R, Python
Capabilities The ideal candidate for this role has:-
A good understanding of and belief in Meesho’s business model and product
Strong understanding of Statistics and Linear Algebra
Strong understanding of hypothesis/model testing and ability to identify common model testing errors like overfitting, underfitting, type I and type II errors
Experience designing and running A/B tests and drawing insights from them
Familiarity with Python or R, proficiency with SQL
Strong communication skills to explain your analysis
Bonus points We will prefer candidates who have:-
A Computer Science degree
Experience in working on personalization or other ML problems
Familiarity with Big Data tech stack like Apache Spark, Hadoop, Redshift",3.8,"Meesho
3.8",Bengaluru,"Bengaluru, India",501 to 1000 employees,2015,Company - Private,"Department, Clothing, & Shoe Shops",Retail,Unknown / Non-Applicable,"GlowRoad, Shop101, Wooplr"
66,Data Scientist,"Experience : 3 – 8 Years

Location : India – Pune
Hands-on experience as a Data Scientist
Through understanding of Machine Learning and Statistical models
Experience in R and Python
Experience in one or more areas of predictive modelling, text mining, time series analysis and unsupervised learning methods
Innovative thinking in building complex learning models
Identify and extract interesting pattern from structured and unstructured data
Experience in building state of the art solutions with structured, semi structured and unstructured data
Collaborate with a cross-functional team including data scientists, business analysts and software engineers
Experience with machine learning frameworks e.g., Theano, KERAS,Tensorflow
Additional programming skills like Java and Scala would be a plus",3.3,"Nitor Infotech
3.3",Pune,"Pune, India",201 to 500 employees,2006,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
67,Data Scientist,"Position: Data Scientist (Intern)
Status: Open
AGNIK is hiring a Data Science Intern with some background in the following areas and strong motivation. Candidates must have:
1) Familiarity with Machine Learning, Data Mining, Statistics, and Signal Processing
2) Some Experience in Programming in C++/Java/Distributed Programming
3) Pursuing a Degree in Electrical Engineering, Math, Physics, Statistics

Positions do not require US citizenship but the candidates should be authorized to work in the United States. If you are interested, please send resume to jobs@agnik.com with ""Application for Data Science Intern"" in the Subject line.",4.8,"Agnik
4.8",India,"Columbia, MD",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,₹10 to ₹50 million (INR),-1
68,Data Scientist,"KEY RESPONSIBILITIES :
Using techniques from supervised and unsupervised machine learning, statistical analysis and predictive modelling to deliver business insights to business units based on data
Working directly with internal customers to educate them on “moving beyond BI” and training their internal resources to execute advanced forms of analytics
Creating reusable implementations of statistical tests and models using cutting edge technologies
Working with the academic and business community to develop new techniques and to contribute to research in the area of advanced analytics in media
Assisting in engagement management, requirements definition, project scoping, timeline management, and results documentation to ensure professional relationship management

PERFORMANCE MEASURES :
As per role KPIs

QUALIFICATION :
2-8 Years plus post qualification
Degree in computer science with a machine learning focus (other technical degrees also accepted e.g. applied mathematics, statistics, physics, operations research). PhD will be desirable.

KNOWLEDGE AND SKILLS :
Advanced knowledge of statistical and machine learning methods, particularly in the areas of modelling and business analytics
Strong programming skills
Experience with statistical languages and packages, such as R, SAS, Mat-Lab, and/or Mahout
Experience working with relational databases and/or distributed computing platforms, and their query interfaces, such as SQL, MapReduce and Hive.
Experience with additional programming languages, such as Python, Java, and C/C++.
Excellent written and verbal communications skills, with a proven ability to translate complex methodologies and analytical results to higher-level business insights and key take-away
A proven passion for generating insights from data, with a strong familiarity with the higher-level trends in data growth, open-source platforms, and public data sets.
Experience working hands-on with large-scale data sets
Familiarity with visualization software and techniques (including Tableau), and business intelligence (BI) software, such as Micro-strategy, Cognos, Pentaho, etc.

PERSONAL ATTRIBUTES :
Creative, gritty, driven by curiosity and comfortable with failure
Strong Data intuition: Talent to identify and visualize patterns
Multi Modal Communication skills",4.0,"Star India
4.0",Mumbai,"Mumbai, India",51 to 200 employees,-1,Company - Private,Film Production & Distribution,Media,Unknown / Non-Applicable,-1
69,Data Scientist,"Data Scientist


You will discover the information hidden in vast amounts of data, and help clients make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.

Responsibilities
– Selecting features, building and optimizing classifiers using machine learning techniques
– Data mining using state-of-the-art methods
– Extending company’s data with third party sources of information when needed
– Enhancing data collection procedures to include information that is relevant for building analytic systems
– Processing, cleansing, and verifying the integrity of data used for analysis
– Doing ad-hoc analysis and presenting results in a clear manner
– Creating automated anomaly detection systems and constant tracking of its performance
Skills And Qualifications
– Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.
– Experience with common data science toolkits. Excellence in at least one of these is highly desirable
– Great communication skills
– Experience with data visualisation tools, such as D3.js, GGplot, etc.
– Proficiency in using query languages
– Experience with NoSQL databases, such as MongoDB, Cassandra, HBase
– Good applied statistics skills, such as distributions, statistical testing, regression, etc.
– Good scripting and programming skills
– Data-oriented personality
Education
UG:Any Graduate – Any Specialization
PG:Any Postgraduate – Any Specialization",-1,Acies,Chennai,"Chicago, IL",1 to 50 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
70,Data Scientist,"Data Sciences team at Priority Vendor uses data and algorithms to build large scale systems to enable better decision making for the invoice discounting as well as render better customer experience to suppliers. Some of the areas of our focus are Rate Determination, Demand Sensing, Recommendation Systems, etc.

Some of the things we are working on:
Daily Rate Determination

Building algorithms to predict supplier expectation on discount amount

Building prediction models to improve on invoice discounting%

Role & Responsibilities

As a data scientist, he/she will have the opportunity to leverage Priority Vendor 3 year old rich data to develop data products that are used by millions of suppliers (end user) and propel the growth of our business. He/she will collaborate with a strong team of engineers, product managers in defining the frontier of data products. Data scientists will work on how to evaluate potential approaches, build features, statistical/machine learning models and determine metrics. He/she will communicate insights/recommendations to a wide spectrum of stakeholders across the company.

Qualification & Skillset

Advanced degree in the quantitative field preferred.

3+ year’s industry experience developing machine learning models at scale from inception to business impact.

Deep understanding of modern machine learning techniques and their mathematical underpinnings such as classification, recommendation systems, and natural language processing.

Proven ability to tailor machine learning solutions to business problems in a cross-functional team.

Experience with distributed machine learning and computing framework (Spark, Hadoop, Mahout or equivalent). Applied experience preferred.

Strong programming skill (Python, R, or Scala preferred).

Experience productionizing machine learning model is a plus.

High proficiency in at least one of the following broad areas:

Machine learning

Statistical modeling/inference

Information retrieval,

Data mining

NLP",4.0,"Priority Vendor
4.0",Noida,"Noida, India",51 to 200 employees,2014,Company - Private,-1,Finance,Unknown / Non-Applicable,-1
71,Data analyst/ Data scientist,"We are looking for data analyst/ data scientist/Module lead||

Job role:
As a data analyst, you will be responsible for compiling actionable insights from data, sales and marketing managers build data-driven processes. Your role will involve driving initiatives to optimize for operational excellence and revenue and more..
Experience- Min 1yr and above required

Location-Indore, Madhya Pradesh

Salary- negotiable

Note-Applicant should be from Indore only.

For details call

Seven four one five zero three one six eight three

Thank you!

Job Type: Full-time

Experience:
work: 1 year (Preferred)
total work: 1 year (Preferred)
Education:
Bachelor's (Preferred)
Benefits:
Travel allowance",4.0,"emerging business consultant
4.0",Indore,"San Francisco, CA",1 to 50 employees,-1,Company - Private,-1,-1,₹100 to ₹500 million (INR),-1
72,Data Scientist,"Our client is seeking a creative Data Scientist to explore unstructured data from diverse sources in order to extract insights that enable us to create new investment strategies. The candidate should demonstrate a wealth of experience in building models that required advanced machine learning and statistical analysis.

In this position, you will be a cornerstone member collaborating closely with our researchers and engineers to test research hypotheses and build forecasting models. You will play a key role in the global race for financial firms to adopt data-driven investment strategies and your research will have the potential to shape the nascent field of quantitative finance.

The company is looking for a deeply curious candidate who is expert at extracting signal out of flawed data to make valid inferences. You are fascinated and energized by cutting-edge, data-driven techniques increasingly utilized in the financial world. Excited to leverage your data science skills, you can imagine yourself thriving in the fast pace, highly experimental of a start-up.

What you’ll do
Modelling research hypotheses and assumptions of financial experts by pulling all the necessary data from disparate sources and designing and validating models that transform that data into actionable insights
Developing and testing the most predictive and robust statistical, machine learning, and deep learning methods to forecast factors, features, metrics, drivers, etc.
Tackle the challenges of featurizing and modelling large and unstructured data using machine learning and statistical techniques
Manage all aspects of the research and execution process including methodology selection, data collection and quality, modelling and analysis, and performance monitoring
Iterating quickly to test the additive impact of new data and research findings on alpha generation
Deliver research findings to investment teams, portfolio managers, and partners
What’s required:
Advanced degree in computer science, machine learning, applied mathematics, or another technical discipline
Experience in text mining/NLP in a relevant field researching real-world data problems (though not necessarily in finance)
3+ years of experience in data analysis and utilizing statistical modeling techniques (e.g. machine learning, deep learning, or signal processing)
Ability to extract data from varied stores (t-sql, hadoop) and write code for models that can stand up to large datasets (python, spark)
Creative thinker excited by the prospect of ideating and evaluating experiments
Background in time series analysis and interest in time series-related machine learning research
Excited by a high learning curve in the field of financial technology
Excellent written and oral communicator of data-driven findings
Company’s culture:
The company is driven by the mission of shaping the future of investment management. They have an international and multicultural team of creative and open-minded problem solvers.

Combining the best talents from physics, computer science, mathematics, social sciences and finance, the company all together are striving for constant innovation.

For your valuable work, the company offers:
Highly dynamic, innovative, passionate and entrepreneurial team
Open and inclusive company culture
Autonomous and self-managed agile teams
About the company:
The company, backed by leading industry giants, is a developing next generation technology to revolutionize how investment decisions are made. The company offers differentiated, amplified and future-oriented investment intelligence mined from alternative data. Extracting early signals from the vast amount of data, empowering investment professionals with unique investible insight and hence better returns. From hedge fund to asset manager, they help our clients to enhance their investment models and derive information edge from a variety of data sources.

Location: Gurgaon, India

Job Type: Permanent and Full-Tim",5.0,"itForte
5.0",Gurgaon,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
73,Data Scientist,"Key Responsibilities:
As a Data Scientist on our team, you will be responsible for solving complex big-data problems for various clients (on-site and off-site) using data mining, statistical analysis, machine learning, deep learning.
One of the primary responsibilities will be to understand the business need and translate it into an actionable analytical plan in consultation with the team.
Ensure that the analytical plan aligns with the customer’s overall strategic need.
Understand and identify appropriate data sources required for solving the business problem at hand.
Explore, diagnose and resolve any data discrepancies – including but not limited to any ETL that may be required, missing value and extreme value/outlier treatment using appropriate methods.
Execute project plan to meet requirements and timelines.
Identify success metrics and monitor them to ensure high-quality output for the client.
Deliver production-ready models that can be deployed in the production system.
Create relevant output documents, as required – power point deck/ excel files, data frames etc.
Overall project management – Creating a project plan and timelines for the project and obtain sign-off.
Monitor project progress in conjunction with the project plan – report risks, scope creep etc. in a timely manner.
Identify and evangelize new and upcoming analytical trends in the market within the organization.
Implementing the applications of these algorithms/methods/techniques in R/Python

Key Skills:
3+ years experience working Data Mining and Statistical Modeling for predictive and prescriptive enterprise analytics.
2+ years of working with Python, Machine learning with exposure to one or more ML/DL frameworks like Tensorflow, Caffe, Scikit-Learn, MXNet, CNTK.
Exposure to ML techniques and algorithms to work with different data formats including Structured Data, Unstructured Data, and Natural Language.
Experience working with data retrieval and manipulation tools for various data sources like: Rest/Soap APIs, Relational (MySQL) and No-SQL Databases (MongoDB), IOT data streams, Cloud-based storage, and HDFS.
Strong foundation in Algorithms and Data Science theory.
Strong verbal and written communication skills with other developers and business client
Knowledge of Telecom and/or FinTech Domain is a plus.

Job Type: Full-time

Salary: ₹450,000.00 to ₹850,000.00 /year

Experience: Machine Learning: 2 years (Required)

Education: Master’s (Preferred)

Language:English (Required)

Interested Candidates please share their resume at careers@datatobiz.com",4.8,"DataToBiz
4.8",Chandigarh,"Chandigarh, India",1 to 50 employees,2018,Self-employed,IT Services,Information Technology,₹10 to ₹50 million (INR),-1
74,Data Scientist,"We are building our team to offer business and operations analytics solutions to our international and

domestic clients, and are looking for a Data Scientist with comprehensive knowledge of existing and next

gen analytics tools and technology platforms. Passionate, self-starter and innovative our Data Scientist will

bring expert skills and meaningful experience to fore, focusing primarily on Healthcare, Pharmaceuticals,

Banking, Financial Services & Insurance industry verticals.

Responsible for leading client engagements and People, our Data Scientist will be a problem solver, who

relishes the journey of crafting intelligent client solutions – live to find patterns and insights within structured

and unstructured data. Industrious, analytical and result-oriented, our Data Scientist will be a thinker with

natural desire to go beneath the surface of a problem; understand how the products are developed; and

have statistical, mathematical, predictive modelling as well as business strategy skills to build the algorithms

necessary to ask the right questions and find the right answers – You propose analytics strategies and

solutions that challenge and expand the thinking of everyone around you. With hands-on knowledge of

the business, products, technology, regulatory environment, operations our Data Scientist will continuously

seek fresh challenges to engineer solutions that make valuable client business impacts.

A seasoned professional our Data Scientist will operate in collaboration with cross-industry, cross-function,

experts and be a leading example of the Profisor People Culture, independently managing client

engagements, multiple projects and project teams.

Careers

Responsibilities:
Results-based quality delivery of data analytics solutions and services

Manage multiple client projects, problem statements, and multiple project teams

Organize and manage quality review of data analytics operations delivery

Design & develop client solutions and collaboratively respond to client RFP’s & RFI’s

Lead thought leadership articles – point of views – and business development initiatives

Manage client relationships, client experience and client feedback to resolve engagement issues

Co-develop Profisor People and People career models

Manage team performance reviews, expansion and progression planning and People reporting

Lead analytics capability development, learning and training

Counsel, develop People, and manage talent identification and hiring

Minimum Knowledge, Skills & Abilities Required:
8+ years of experience designing and devising data analytics capabilities and solutions for

Healthcare, Pharmaceuticals, BFSI and or Cross-industry clients

Comprehensive knowledge of Natural Language Processing, Machine Learning, Conceptual Modelling,

Statistical Analysis, Predictive Modelling & Hypothesis Testing

Solution-oriented thinker, capable of managing business and technology challenges

Data driven and highly analytical with working knowledge of compliance and ethical standards and

evolving global regulatory environment

Excellent communication (both written and vocal), problem solving and presentation skills

Good human relations and interpersonal skills to collaborate and manage People with diverse

backgrounds

Additional Knowledge, Skills & Abilities:
Data munging, visualization and communication knowledge

Hands-on knowledge of Lean and Agile delivery techniques

Demonstrated ability to maintain strict confidentiality of internal and external customer information

Desirable Knowledge, Skills & Abilities:
Ph.D. or Master’s degree in operations research, applied statistics, mathematics, data mining, machine

learning, physics or a related quantitative discipline

Management experience in Big Data or Data Analytics practice setup",4.5,"Profisor Services
4.5",Gurgaon,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
75,Data Scientist,"Job Family Descriptor
Level Descriptor
Data Scientist is responsible for analyzing data and developing forward-looking business solutions for TCL’s SCM function. He / She would need to evaluate and find areas of improvement in SCM’s way of working basis data. He / She is responsible for bringing scientific rigor and statistical methods to the challenges of strategic procurement.

He / She would be responsible for working closely with internal stakeholders such as Sourcing, Operations, and Logistics teams to produce innovative and actionable quantitative models and analyses to achieve the goals of cost leadership and business velocity. He / She would be required to have a customer-centric approach when helping TCL attain its business goals while building long-term capabilities. He / She would need to have a thorough understanding of how SCM functions interact with each other, with Product / Engineering teams and with external stakeholders such as vendors to create actionable solutions.

He / She would need to drive effective written, verbal, and visual presentation to concisely communicate in a way that provides context, offers insights, and minimizes misinterpretation. He / She would need to be a self-starter, quick learner, and be able to work independently. He / She would need to demonstrate attention to detail and resourcefulness. This is a pivotal role that embraces and promotes a change mindset and driving a change to move away from traditional reporting.
Purpose - Broad objective of the role
Operating Network - Key External
Data Scientist is responsible for analyzing data and developing forward-looking business solutions for TCL’s SCM function. He / She would need to evaluate and find areas of improvement in SCM’s way of working basis data. He / She is responsible for bringing scientific rigor and statistical methods to the challenges of strategic procurement.

He / She would be responsible for working closely with internal stakeholders such as Sourcing, Operations, and Logistics teams to produce innovative and actionable quantitative models and analyses to achieve the goals of cost leadership and business velocity. He / She would be required to have a customer-centric approach when helping TCL attain its business goals while building long-term capabilities. He / She would need to have a thorough understanding of how SCM functions interact with each other, with Product / Engineering teams and with external stakeholders such as vendors to create actionable solutions.

He / She would need to drive effective written, verbal, and visual presentation to concisely communicate in a way that provides context, offers insights, and minimizes misinterpretation. He / She would need to be a self-starter, quick learner, and be able to work independently. He / She would need to demonstrate attention to detail and resourcefulness. This is a pivotal role that embraces and promotes a change mindset and driving a change to move away from traditional reporting.
Operating Network - Key Internal
Size and Scope of Role - Financial
Size and Scope of Role - No. of direct reports
Size and Scope of Role - Total team size
Size and Scope of Role - Other size parameters
Minimum qualification & experience
Bachelor’s Degree in quantitative disciplines (e.g., Engineering, Statistics, Computer Science)
3 - 5 years of work experience in vendor data analysis related field in procurement department / supply chain managment
Experience in articulating and translating business questions and using statistical techniques to arrive at an answer using available data
Strong understanding of fundamentals of finance and accounting such as debit/credit and opex/capex expenses etc.,
Demonstrated skills in selecting the right statistical tools given a data analysis problem
Ability to visualize models and results to provide data-driven insights (PowerBI experience is preferred)
Demonstrated resourcefulness, self-direction, attention to detail, meticulous
Change management and automation experience is mush
Ability to handle larget data sets and drive insights to support informed management decisions
Preferred
Master's degree in Engineering, Statistics, Mathematics, Economics or an Applied Science or equivalent practical experience
Experience with statistical software (e.g., R, Python, MATLAB, pandas) and database languages (e.g., SQL)
Experience in delivering bespoke analytics to stakeholders
Experience in using and/or deploying digital analytics and measurement solutions
Other knowledge/skills
Key Responsibilities
Data Management &Analysis:

Work effectively with large, complex datasets to derive actionable insights
Conduct analysis that includes data gathering and requirements specification, processing, analysis, ongoing deliverables, and presentations
Solve difficult, non-routine analysis problems, applying advanced analytical methods as needed
Leverage data to identify potential supply chain risks

Innovative Solution&Group:

Leverage data analytics and visualization tools to propose innovative solutions for growth, aligned with overall TCL objectives and KPIs
Translate data and model results into tactical and strategic insights that are clear, complete, accurate, relevant, understandable, and applicable to decision-making and needs of varying stakeholders

Stakeholder Management:

Interact cross-functionally, making business recommendations (e.g., cost-benefit, forecasting) with effective presentations of findings at multiple levels of stakeholders through visual displays of quantitative information
Make presentations to internal stakeholders to integrate recommendations into business processes
Lead and/or participate in cross-functional team projects
Technical Competencies
Knowledge / Skills
Communication Skills

Job Segment:
Database, Scientific, Engineer, Computer Science, Logistics, Technology, Engineering, Operations",3.8,"Tata Communications
3.8",Mumbai,"Mumbai, India",5001 to 10000 employees,-1,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,₹500+ billion (INR),-1
76,Data Scientist,"Currently we are looking for a Senior Computer Vision Engineer who is passionate about the sphere of Big Data, Data Science and AI.

Responsibilities:
Creating solutions and products for leading representatives of different industries;
Analysing business problems, looking for better technical solutions and their implementation;
Expanding company’s expertise in the field of Computer Vision;
Management of the direction of the company in the future.",-1,Exeliq Consulting,Maharashtra,"Schaumburg, IL",1 to 50 employees,2019,Company - Public,-1,-1,₹10 to ₹50 million (INR),-1
77,Data Scientist,"A dynamic professional with 8 years of work experience in ERP.
Extensive experience in implementation, customization and production support of ERP systems.
Excellent in interacting with the users in collecting the requirements and Proficient in customizing the requirements to Functional Specifications.",4.4,"Sulekha
4.4",Chennai,"Chennai, India",1001 to 5000 employees,2004,Company - Private,Internet,Information Technology,₹10 to ₹50 billion (INR),-1
78,Data Scientist,"Job Description

We are looking for a Data Scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.

Responsibilities
Selecting features, building and optimizing classifiers using machine learning techniques.
Data mining using state-of-the-art methods.
Extending company’s data with third party sources of information when needed.
Enhancing data collection procedures to include information that is relevant for building analytic systems.
Processing, cleansing, and verifying the integrity of data used for analysis.
Doing ad-hoc analysis and presenting results in a clear manner.
Creating automated anomaly detection systems and constant tracking of its performance.
Required Skills
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.
Experience with common data science toolkits, such as R, Perl, Python, SparkML, Weka, NumPy, MatLab, etc.
Experience with data visualization tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive, Pig.
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase.
Experience with Hadoop or similar distributed computing and storage platforms.
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills.
Exceptional analytical abilities,creativity and attention to details.
Good organizational and problem solving skills.
Good team player who is a self-starter and well organized.
Strong oral and written communication skills.
Required Education
Graduate degree in Math, Statistics, Computer Science, or other quantitative discipline.
Please email your resume to careers@gtpltech.com",-1,GridEdge Technologies,Pune,"Rockaway, NJ",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
79,Data Scientist,"Data Scientist

About the job

We are looking for a data scientist to help us discover the information hidden in vast amounts of data and help us make smarter decisions to deliver even better products. Your primary focus is to apply data mining techniques, doing statistical analysis, and building high-quality prediction systems integrated with our products.
Responsibilities
Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.
Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques, and business strategies.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting, and other business outcomes.
Develop company A/B testing framework and test model quality.
Coordinate with different functional teams to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Requirements
5-7 years of experience manipulating data sets and building statistical models, has a Masters or Ph.D. in Statistics, Mathematics, Computer Science or another quantitative field
Strong problem-solving skills with an emphasis on product development.
Experience using statistical computer languages (R, Python, SLQ) to manipulate data and draw insights from large data sets.
Experience working with and creating data architectures.
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, and more) and their real-world advantages/drawbacks.
Understanding of advanced statistical methods and concepts (regression, properties of distributions, statistical tests, and proper usage, etc.) and experience with applications.
Excellent written and verbal communication skills for coordinating across teams.
A drive to learn and master new technologies and techniques.
Familiar with the following software/tools:
Coding knowledge and experience with several languages: C, C++, Java,JavaScript, and more.
Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, and more.
Experience querying databases and using statistical computer languages: R, Python, SLQ, and more.
Experience using web services: Redshift, S3, Spark, DigitalOcean, and more.
Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, and more.
Experience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, and more.
Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, and more.
Experience visualizing/presenting data for stakeholders using: Periscope, Business Objects, D3, ggplot, and more.
Job Type: Full time
Job Location: Technopark, Trivandrum",4.5,"NetObjex
4.5",Thiruvananthapuram,"Irvine, CA",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
80,Data Scientist,"Machine Learning & AI - Bangalore, IN

Responsibilities

We are looking for a capable data scientist to join the Analytics team, reporting locally in India Bangalore. This person’s responsibilities include research, design and development of Machine Learning and Deep Learning algorithms to tackle a variety of Fraud oriented challenges. The data scientist will work closely with software engineers and program managers to deliver end-to-end products, including: data collection in big scale and analysis, exploring different algorithmic approaches, model development, assessment and validation – all the way through production.

Qualifications

At least 3 years of hands-on development of complex Machine Learning models using modern frameworks and tools, ideally Python based.
Solid understanding of statistics and applied mathematics
Creative thinker with a proven ability to tackle open problems and apply non-trivial solutions.
Experience in software development using Python, Java or a similar language.
Any Graduate or M.Sc. in Computer Science, Mathematics or equivalent, preferably in Machine Learning
Ability to write clean and concise code
Quick learner, independent, methodical, and detail oriented.
Team player, positive attitude, collaborative, good communication skills.
Dedicated, makes things happen.
Flexible, capable of making decisions in an ambiguous and changing environment.

Advantages:
Prior experience as a software developer or data engineer – advantage
Experience with Big data – advantage
Experience with Spark – big advantage
Experience with Deep Learning frameworks (PyTorch, TensorFlow, Keras) – advantage.
Experience in the Telecommunication domain and/or Fraud prevention - advantage",3.5,"Tomia
3.5",Bengaluru,"Vienna, VA",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
81,Data Scientist,"Tools and Technologies - SAS, R, Python, SPSS, NoSQL , postgresql ,PySpark, IBM Cloud Visualization tools like Tableau, Rshiny.
Data cleansing, Data Extraction, Data Definition, Data Dictionaries, Data Preparation.
Statistical Analysis (variable creation, selection of sampling criteria, generating performance definitions, missing data discovery and imputation.
Data Segmentation and Profiling. Root Cause Analysis, Process maps.
Logistic Regression Analysis, Linear Regression Analysis, Time Series forecasting, Dashboard Development, Clustering.
Develop and Evaluate - Descriptive, Predictive and Diagnostic Models.
NLP - language identification, sentiment analysis, named entity recognition, Text Recognition.
Machine Learning - Supervised Learning (Classification Model --Logistic, Decision Tree & Random Forest, Regression)
Machine Learning - Unsupervised Learning (Clustering, Anomaly detection, Dimensionality reduction)
Time Series
Possess calculation skills.
Data mining methods
Train, tune, validate, and monitor predictive models
Write algorithms based of statistical models
Enhancing data collection processes
Generating Visualization and data presentation
Understanding and extracting meaning from complex data relationships.
Ability to analyse and predict various business outcomes
Understanding of Statistical models and implementation of quantitative models.
*
Ability to translate a business problem into an analytics problem, recommend, implement and validate quantitative model
Investigate and recommend best-suited analysis, Machine Learning (ML), optimization, simulation, and other quantitative methods/tools to create robust solutions for business problems
Good listening, presentation and interpersonal skills.
Good written and oral communication skills
Advanced knowledge with Microsoft Office Suite (Word, Excel, Power Point)
Strong Data analysis, data verification and problem-solving abilities
Strong Analytical, mathematical & logical bent of mind
Job Type: Full-time

Experience:
data analytics: 3 years (Required)
total work: 4 years (Preferred)
Education:
Bachelor's (Required)
Work Remotely:
Temporarily due to COVID-19",4.8,"Northcorp Software Pvt. Ltd.
4.8",Gurgaon,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
82,Data Scientist,"Overview:
We at Solugenix are hiring Data Scientist for a full-time job at Hyderabad, the detailed job description is mentioned below. If this job interests you, I urge you to email me your updated resume with your phone number and the best time to call you.

Title: Data Scientist

Location: Hyderabad

Position: Full Time

Solugenix, the longest serving independent IT consulting firm in the nation, delivers comprehensive, managed-services IT solutions known for their innovation, value and dependability. With a strong emphasis on innovation, Solugenix has now created an independent branded Data Science and AI based Incubation center for building next generation solutions which include new and emerging technologies around Machine Learning, Artificial Intelligence, Big Data, Data Science and distributed Cloud computing.

Do you thrive on working on the cutting edge? Working with innovators in the early stages of ideas, products, or platforms? Do you crave new challenges and solving hard customer problems using the latest in technology? Do you want to become part of a high-energy team in Hyderabad where you will play a key role in building a successful company that already has great traction?

In this role, you will work on some of the latest applications of data science to business. You will directly work with key stakeholders to define the business problem and determine solution requirements. You will be responsible for ensuring business value and communicating results, making presentations, etc. If you are passionate to work on unstructured business problems that can be solved using data, we would like to talk to you.

We are looking for candidates with minimum of 5+ years of consulting experience possessing Life Sciences secondary data familiarity – experience working with a variety of Patient, Physician and Payer datasets on solving strategic and tactical sales & marketing business problems across life sciences, biotechnology and healthcare industries.

Responsibilities:
Technical – Able to comprehend complex tasks assigned and execute them with little to no supervision

Hands on in a range of analytics tools (SAS, SQL, R/Python) and big data hosting technologies (at least 1 of AWS, GCP, Azure), with advanced expertise in MS Office (Excel and PowerPoint)
Have in depth knowledge of the various commercially available Physician, Patient and Payer level Life Sciences data sources in the US
Must have experience in development or maintenance of processes to manage and improve sales and marketing operations such as: Sales Force Sizing, Promotion Response Modeling, Promotional Effectiveness, Market Mix Optimization, etc.
Execute analyses and make the results accessible and relevant to a wide variety of business users
Develop and refine analysis templates for problem diagnosis and opportunities assessment
Knowledge of advanced analytics and ability to blend consulting, analytics, and technology to help life sciences and healthcare clients improve the ROI of their sales and marketing functions
Must have experience in using Statistical techniques like: Regression Modeling/ Optimization/ Structuring/ Machine Learning Techniques
Calculation of all sales, activity and managed care KPIs

Logical Thinking – Able to think analytically, use a systematic and logical approach to analyze data, problems, and situations. Spot discrepancies and inconsistencies in information and materials. Collaborate effectively with other analytical team members

Task Management – Basic level of project management knowledge and experience. Should be able to plan tasks, discuss and work on priorities. Support analytical projects by formulating methodology, establish data requirements, identify client deliverables, determine tasks and timing. Demonstrate initiative to improve quality and customer service by striving to exceed customer expectations. Balance team and individual responsibilities and put the success of the team above own interests

Communication – Convey ideas and information clearly and accurately to self or others in writing and verbally. Establish effective mechanisms of communication with team, and the organization’s leadership to foster an environment of openness, trust and teamwork

Qualifications:
You will score brownie points if you:
Can synthesize complex data into user friendly visual presentations for use by Commercial and Strategy leadership folks
Have exceptional communications skills to effectively collaborate with broad customer base
Possess excellent writing and verbal communications skills and the ability to understand and communicate concepts and recommendations
Can understand and deal effectively with problems and opportunities, which arise, in a complex multiprocessing environment

Education:
B-Tech or BE in any engineering discipline from Tier 1 college with a minimum of 5+ years of experience, OR
B-Tech or BE or Bachelors in a quantitative discipline such as Statistics, Mathematics, Operations, Research, Economics or Econometrics from Tier 1 College with a minimum of 5+ years of experience",4.3,"Solugenix Corp
4.3",Hyderabad,"Brea, CA",201 to 500 employees,1969,Company - Private,IT Services,Information Technology,₹5 to ₹10 billion (INR),-1
83,Data Scientist,"Location:
Defence Colony, New Delhi

Job Purpose Summary:
Responsible for driving Mahajan Imaging's new focus on medical informatics and data analytics:
Preferably well aquainted with SQL based PACS and Hospital Information Systems.
Putting medical reports and images into an easily searchable structured format for clinical research and scientific purposes.
Responsible for pulling relevant information from company databases.
Would have access to high-end servers and other equipment.
Would have opportunity to work with leading medical imaging companies and universities.",4.0,"Mahajan Imaging
4.0",New Delhi,"New Delhi , India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
84,Data Scientist,"Data Scientist

Job Description:
Expertise or extensive experience with Python/ R -programming
· A thorough understanding of SQL databases
· Excellent technical abilities
statistics and machine-learning optimization skills;
knowledge of big data
insightful data visualization capability
to use algorithms and programming to efficiently go through large datasets
Define unstructured data needs, evaluate data quality, and extract/transform data
data science programming languages and big data tools including R, Python, Spark, SQL, Hadoop
Development and deployment of an advanced solution in a Big Data

Experience Range:

4 - 8 years

Educational Qualifications:

Any graduation,

Skills Required :

data scientist,

data analyst,

Candidate Attributes :

Should be good at R Python and Big Data",3.0,"Angel Broking
3.0",Andheri,"Mumbai, India",1001 to 5000 employees,1987,Company - Private,Brokerage Services,Finance,Unknown / Non-Applicable,-1
85,Data Scientist,"LocationIndia / US / EuropeExperience2 YearsAcademic Qualification:B.S, B.E., B.Tech/MBA from top-tier Engineering /B-School ORMasters in Statistics/Economics from leading UniversityOverviewContinuous, growth opportunities for career progression and personal developmentProfessional, stimulating, continuous learning, work environment based on camaraderie, individual mentorship, on-the-job and corporate trainingCompetitive and performance-oriented compensation and employee benefits packageIndustry benchmarked HR policies and practices, particularly in areas such as Performance Management, Learning and Professional Development, Career Planning and Compensation and Rewards.Roles and responsibilitiesWill involve teamwork as well as work in which individual contribution will be needed.Clear, articulate and confident written and verbal communication skills.Working experience in Advanced Analytics Techniques Predictive modelling Time series forecasting Machine Learning etc.The role will require a sound understanding of business functions, statistical concepts and algorithm design/implementation skills.Core responsibilities include leveraging data science to solve business cases, training other team members, and contributing to pre-sales through quick execution of PoCs. Typical activities will include:Interacting with business stake holders for gathering requirementsAnalysing data to develop key insights on business trends and performanceApplying statistical/mathematical algorithms as needed to address specific business problemsProficiency in using query languages such as SQL(preferable), Hive, Pig, R, SAS, PythonAdditional Skills (preferred)Will involve teamwork as well as work in which individual contribution will be needed.Intermediate querying and scripting skills in SQLExperience in relevant field such as Statistics, Computer Science or Applied Math.SPOCBuddhadeb BhattacharjeeMail toBuddhadeb.bhattacharjee@tcg-digital.com",3.0,"TCG Digital
3.0",India,"Somerset, NJ",201 to 500 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
86,DATA SCIENTIST,"The required skills are :
Post graduate degree in Statistics, Math or any other with strong analytical background .
Must have exposure to Big Data analytics..
Need Strong mathematical background (calculus, linearalgebra, probability and statistics).
Applied Machine Learning experience (regression and classification, supervised, and unsupervised learning) is a plus.
Must be a quick learner and capable to solve complex problems in multiple domains.
Skill Set : Language - C#,C++, Python or R, Scripting - Java script Position Type : Permanent Qualification : Any postgraduate degree with analytics Experience : 0 - 4 Yrs Salary Package :Best in Industry Job Location : Calicut, Kerala, India Recruitment Process : Technical Interview & HR interview",4.0,"Tech27 Systems Ltd.
4.0",Kozhikode,"Aberdeen, United Kingdom",51 to 200 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
87,Data Scientist,"About us & Vision

Sequretek is an Indian MNC focused on Information Security and Information Management space. The company is backed by industry veterans who have come together with a vision to build India’s leading Information Security company.
Sequretek’s customers have appreciated its solution offerings, and within a short span the company has acquired marquee clientele in Financial, Pharmaceutical, IT/ITES, and Retail and Logistics sectors.
Sequretek probably is the one of the very few companies that offers a blend of its own core threat intelligence products along with both on-premise and cloud solutions. Our end point detection, protection, and response technology – EDPR is the industry’s only product that replaces up to six different endpoint technologies for our customers.
Our vision is to establish and sustain Sequretek as a Global Leader in terms of the ‘Security’ of Enterprise-level Information-Assets through the consistent delivery of world-class products and solutions that leverage state-of-the-art technologies relevant to the contemporary digital economy.

Why Sequretek?

You will be part of an award winning ""Security Product Company of the Year – 2019” announced by Data Security Council of India (A NASSCOM Initiative).
The team is highly visible, agile, and working on critical problems that directly affect the company’s success.
Our researchers regularly appear at various global conferences and are some of the most sought-after thought leaders in the security industry.
Our ML Engine was certified by ICSA Labs for its detection against unknown / little known malwares.
As part of the research group, you will leverage your problem-solving and analytical skills to further our capabilities, as well as publish and present new and novel research.

Education & Experience

Education:The candidate must have any of the below:
BE/B.Tech/MTech in Computer Science, Statistics, or Data Science.
Experience:
Minimum 1-2 years of experience in applying ML/Deep Learning algorithms and
techniques to real-world data sets.

Key Responsibilities

Skills:
Knowledge of Core Python
Proficiency in Machine learning algorithms (SVM, Decision Trees, PCA, Clustering etc.).
Knowledge and Experience of Deep Learning Algorithms (CNN, RNN, LSTM etc.)
Knowledge of major ML frameworks such as TensorFlow, PyTorch, Keras, and Scikit-Learn.
Strong analytical thinking and problem solving.
Designs scalable processes to collect, manipulate, present, and analyze large datasets in a production-ready environment
Demonstrated participation on platforms like Kaggle is a plus
Prefer great appreciation or expertise in Security products such as End point detection, protection and response, Managed detection and response etc
Must be proactive and flexible and have the ability to work under pressure and possess good follow-through skills.
Must possess excellent written and verbal communication and a quick learner.
Responsibilities:
Wants to build and develop innovative intellectual property through the research and implementation of new approaches in machine learning and simplifying security
Approaches problems from an adversarial mindset in an effort to circumvent prediction systems
Works with internal product and engineering teams to drive development of new products
Has the capability to translate and implement newly published research on specific datasets and problems to validate approaches and potentially improve
Experienced wrangling large volumes of data and applying machine learning techniques towards real product and business problems
Invests time in research including publications, and is committed to keeping up with AI trends
Develop working prototypes of algorithms and evaluate and compare metrics based on large, real-world data sets",4.0,"Sequretek
4.0",Bengaluru,"Mumbai, India",201 to 500 employees,2013,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
88,Data Scientist,"Analytics

Data Scientist

Pune, Maharashtra, India
APPLY

Job title

Data Scientist
Department

Analytics
Report To

NA
Work Location

Pune

It’s Time For A Change…

Your Future Evolves Here

Evolent Health has a bold mission to change the health of the nation by changing the way health care is delivered. Our pursuit of this mission is the driving force that brings us to work each day. We believe in embracing new ideas, challenging ourselves and failing forward. We respect and celebrate individual talents and team wins. We have fun while working hard and Evolenteers often make a difference in everything from scrubs to jeans.

Are we growing? Absolutelyabout 40% in year-over-year revenue growth in 2018. Are we recognized? Definitely. We have been named one of “Becker’s 150 Great Places to Work in Healthcare” in 2016, 2017, 2018 and 2019, and One of the “50 Great Places to Work” in 2017 by Washingtonian. If you’re looking for a place where your work can be personally and professionally rewarding, don’t just join a company with a mission. Join a mission with a company behind it.

Who You’ll Be Working With:

You’ll join a team of data scientists, analysts, and software engineers working to push the boundaries of data science in health care. We like to experiment, iterate, and innovate with technology, from developing new algorithms specific to health care’s challenges, to bringing the latest machine learning practices and applications developed in other industries into the health care world. We know that algorithms are only valuable when powered by the right data, so we focus on fully understanding the problems we need to solve, and truly understanding the data behind them before launching into solutions – ensuring that the solutions we do land on are impactful and powerful.

What You’ll Be Doing:
Research, conceptualize, and implement analytical approaches and predictive modeling to evaluate scenarios, predict utilization and clinical outcomes, and recommend actions to impact results.
Manage and execute on the entire model development process, including scope definition, hypothesis formation, data cleaning and preparation, feature selection, model implementation, validation and iteration, using multiple data sources.
Provide guidance on necessary data and software infrastructure capabilities to deliver a scalable solution across partners and support the implementation of the team’s algorithms and models into Evolent’s product offerings.
Contribute to the development and publication of white papers showcasing Evolent’s leadership in healthcare data science.
Collaborate with stakeholders from clinical, operations, and product teams to identify advanced analytics opportunities to add value to Evolent’s solution offerings.
Leverage clinical and administrative data to support other business needs related to clinical program improvement, networks optimization, and other strategic initiatives.
The Experience You’ll Need (Required):
Master’s Degree with a quantitative focus (e.g. data science program, software engineering, statistics, mathematics, computer science, health services research).
3-6 years of professional experience in an analytical field related to health service analytics, predictive modeling in health care, or other health care-related experience.
Strong technical abilities with advanced data and analytics tools and programming languages, including Python or R, and at least one database language such as SQL or Mongodb.
Foundational understanding of core concepts in applying machine learning algorithms: data cleaning, feature selection, and parameter tuning.
Strong communication skills, including both communicating with other stakeholders to fully evaluate project requirements and context, as well as communicating project results, findings, and applicability.
Ability to work independently with little technical guidance day-to-day, in a fast-paced environment.
Finishing Touches (Preferred):
Experience in SAS, SAS/CONNECT, and disparate programming language integration techniques
Proficiency in most areas of mathematical analysis methods, statistical analyses, predictive modeling, and/or machine learning (such as neural networks, random forests, gradient boosting, etc), and in-depth specialization in some areas.
Working knowledge of analyzing administrative medical claims, pharmacy claims, and/or EMR data and clinical data.
Proficiency with git or other version-control software, especially in collaboration with others.
Proficiency working at the command line / shell.
Experience in reporting and visualization tools such as R’sggplot, Python’s bokeh, Tableau, MSTR, or geo-mapping tools.
Experience building and/or using APIs.
Work Environment: The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. This position primarily works in a climate controlled based setting.The noise level and the work environment are moderately quiet. This role routinely uses standard office equipment such as computers, phones, photocopiers, filing cabinets and fax machines

Physical demand: Include the physical demands of the job, including bending, sitting, lifting and driving. For example, while performing the duties of this job, the employee is regularly required to talk or hear. The employee frequently is required to stand; walk; use hands to finger, handle or feel; and reach with hands and arms.

Why Join Evolent?Evolent Health developed an integrated value-based care platform for payers and providers. The company created an internal recognition program that encourages departments to acknowledge outstanding achievement as well as focusing on philanthropic values. The company spent four weeks in 2018 giving back to more than 60 local charities and engaged 3,700-plus employees to participate. Evolent provides healthy snacks and drinks in most of its offices as well as an in-office gym at its headquarters and workstations that include treadmill desks. In 2016, the company launched its diversity and inclusion committee that promotes unconscious bias training and established several business resource groups. In 2017, Washingtonian Magazine named Evolent among the 50 Great Places to Work.

APPLY",2.8,"Evolent Health
2.8",Pune,"Arlington, VA",1001 to 5000 employees,2011,Company - Public,Healthcare Services & Hospitals,Healthcare,₹1 to ₹5 billion (INR),-1
89,Senior Data Scientist,"Location:
Chennai, Mumbai, New Delhi

Geography:
Asia Pacific

Capabilities:
Big data & advanced analytics

Industries:
Technology industries

About Us


Boston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.

To succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.

Practice Area Profile

BCG GAMMA combines innovative skills in computer science, artificial intelligence, statistics, and machine learning with deep industry expertise. The BCG GAMMA team is comprised of world-class data scientists and business consultants who specialize in the use of advanced analytics to get breakthrough business results. Our teams own the full analytics value-chain end to end: framing new business challenges, building fact-bases, designing innovative algorithms, creating scale through designing tools and apps, and training colleagues and clients in new solutions. Here at BCG GAMMA, you’ll have the chance to work with clients in every BCG region and every industry area. We are also a core member of a rapidly growing analytics enterprise at BCG - a constellation of teams focused on driving practical results for BCG clients by applying leading edge analytics approaches, data, and technology.

Role Profile

POSITION PROFILE:
We are seeking a strong candidate with advanced analytics experience to fill an exciting Senior Data
Scientist (SDS) position within BCG Gamma. The SDS is a valuable expert in Data Science and Analytics
and will design and build analytics methodologies, solutions, and products to deliver value to BCG's clients
in collaboration with case teams. Exceptional candidates will also show an analytical curiosity, going
beyond the immediate requirements of the project to find deep insights that others have missed. They will
ask questions about outliers, seek to understand the fundamental drivers of advantage and look for clues
that may change the basis of competition.

As a Senior Data Scientist you design and build analytics solutions for our clients where data and
analytics are at the heart of the question. The team interaction centers on use of statistical programs and
others tools to conduct intensive analysis of objective data and open discussion, complemented by
objective research into the competitive environment. Responsibilities / duties to include: understand
problems from the client’s point of view, build and execute solid analytics work plans, gather and organize
large and complex data assets, perform relevant analyses (data exploration and statistical modeling),
manage priorities and deadlines, foster teamwork in interactions, develop client relationships with client
counterparts, and communicate hypotheses and findings in a structured way.

As the field of advanced analytics is rapidly evolving, the SDS is responsible for staying current on
leading-edge business applications, tools and approaches, proactively working with the Analytics
Leadership to enhance offerings that deliver competitive advantage to BCG.

Your Qualifications

JOB REQUIREMENTS:
PhD and 1-2 years of relevant industry work experience or a Masters Degree with significant relevant experience providing advanced analytics solutions is required. The degree should be in computer science, applied mathematics, statistics, machine learning, or a related data centric field.
Looking for individuals with deep technical and data science expertise, acute strategic and analytical skills, ability to lead and persuade, drive and energy, and desire to work in a project based environment on strategic issues.
Strong record of professional accomplishment and leadership.

Date Posted:
13-Feb-2019

Boston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.
BCG is an E-Verify Employer. Click here for more information on E-Verify.",4.0,"Boston Consulting Group
4.0",New Delhi,"Boston, MA",10000+ employees,1963,Company - Private,Consulting,Business Services,₹500 million to ₹1 billion (INR),"McKinsey & Company, Bain & Company, Accenture"
90,Data Scientist,"Experience : 2+ years

What will you do:
Should have working knowledge of relational Database designs (SQL Server, MySQL, Oracle).
Should have knowledge of Queue management systems (Redis, MSMQ, RabitMQ etc).
Should have knowledge of SQL query, Stored Procedures, Functions.
Should have knowledge of No SQL will be an added advantage.
Shall analyze, define and document system requirements for data, workflow, logical processes, interfaces with other systems, auditing, reporting requirements and production configuration.
Shall write and maintain functional and technical specifications.
Shall create scripts and packages for data integration, data maintenance or bug fixes.
Shall analyze code for problem resolution and performance optimizations.
Shall write SQL statement for ad-hoc report generation.

What we can offer
Are a young organization and the workplace is an extension of our families back home
Mondays and Fridays have the same effect on us
Value positive vibes, honesty, sense of judgment, empathy and self-motivation
Believe in experimentation and don't think of new things as daunting enough to take up at any point in time
Are looking for driven and focused individuals
Will be more than happy to hear from you
We want to hear from you
Why don't go ahead and send us a video clip of yourself, giving us a creative brief of who you really are.Once you're done with that, jobs@bookmyshow.com :).",3.9,"Bigtree Entertainment Pvt.Ltd.
3.9",Mumbai,"Mumbai, India",201 to 500 employees,-1,Company - Private,Financial Transaction Processing,Finance,Unknown / Non-Applicable,-1
91,Data Scientist,"Miles is looking to expand its data science and data engineering team in INDIA!

Here's a quick checklist:
You live in India
Want to work for a fast-growing Silicon Valley Startup
You are passionate about solving challenging problems
You are looking to put your stamp on the product

What you'll need:

Education
Master's/PhD (preferred) or Bachelor's (required) in CS/ML/AI or relevant computational/engineering discipline

Machine Learning/Data Science:
Solid theoretical understanding of ML fundamentals: linear algebra, probability, statistics (as relevant to ML), optimization
Knowledge of different ML techniques and when/how to use them: classification, regression, clustering, outlier detection, dimensionality reduction, etc.
Comfortable manipulating and analyzing complex, high-volume, high-dimensionality data from varying, heterogeneous sources
Experience with messy real-world data -- handling missing/incomplete/inaccurate data
Proficient in the Python ML ecosystem: NumPy, Pandas, SciPy, Scikit-Learn
Strong understanding of relational databases like PostgreSQL is a plus

Programming experience:
At least 2+ years of experience writing production-quality Python code
Version control: Git, GitHub/Bitbucket
Experience delivering large-scale deployable projects

Great to have
We deal with large volumes of geospatial data, so experience working with geospatial data at scale is a big plus
Knowledge of Python (Shapely, GeoPandas, Fiona, CartoPy, etc) and/or database (PostGIS) geometry/geospatial tools
Domain experience in building models for location-based services, transportation, scheduling, vehicle routing",2.3,"Miles
2.3",Bengaluru,"Redwood City, CA",1 to 50 employees,2016,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
92,Marketing Analytics-Data Science Manager,"Job Title
Marketing Analytics-Data Science Manager
Job Description


About the organization

Philips Global Business Services LLP is a limited liability partnership organization with Royal Philips of the Netherlands. Royal Philips is a diversified technology company, focused on improving people's lives through meaningful innovation in the areas of Health Systems and Personal Health.

Royal Philips (NYSE: PHG, AEX: PHIA) is a leading health technology company focused on improving people's health and enabling better outcomes across the health continuum from healthy living and prevention, to diagnosis, treatment and home care. Philips leverages advanced technology, deep clinical, and consumer insights to deliver integrated solutions. Headquartered in the Netherlands, the company is a leader in diagnostic imaging, image-guided therapy, patient monitoring and health informatics, as well as in consumer health and home care. Philips' health technology portfolio generated 2017 sales of EUR 17.8 billion and employs approximately 74,000 employees with sales and services in more than 100 countries.

For information on Royal Philips, please visit www.philips.com

JD: Data Science Manager/Deputy Manager

Job location: Bangalore

Responsibilities
Analyzes, measures, and facilitates optimization of our marketing return on investments and tactics across multiple channels. Drive excellent practices and technical standards for establishing KPIs and goals for Marketing, developing information suites (Dashboards, reports, visualizations) fit for C-level consumption, and marketing campaign tracking and measurement.
Leverage machine learning models to address key growth challenges such as lifecycle marketing, predictive LTV, cross-channel spend allocation, response modelling, campaign/channel performance measurement methodologies, Program effectiveness and media attribution.
Develop and improve marketing mix and A&P models and frameworks to assign credit for traffic and conversions across a variety of Marketing channels and touchpoints.
Leverage Philips’ data to scale our ability to optimize marketing across the customer journey to optimize return on investment through analysis, modelling, experiments and pre-post analyses.
Develop and implement marketing data management practices
Ability to use data for Exploratory, descriptive, Inferential, Prescriptive, and Advanced Analytics - Mandatory
Ability to share dashboards, reports, and Analytical insights from data – Mandatory
Technical Knowledge and Skills required
Econometrics, Market mix modeling, some Operations research and affinity modeling experience is mandatory
Track record in delivering strong and impactful; competitor and market tracking insights
High affinity with applying new IT platforms / dash boarding software tools for reporting and Experience in a consumer focused, complex, matrixed, multinational environment, e.g. consumer goods, online services, e-commerce, or mobile applications
Competitor insight generation
Strong background into Database design, modeling and architecture – preferred Fluency in web analytics and deep technical understanding of how data are created from first party and third-party web beacons
Proficiency with R and/or Python libraries commonly used in data science

Soft Skills Required
Good communication and presentation skills
Highly driven, energetic, flexible, resourceful & ability to multitask
Clarity of thoughts and vision
Ability to ideate and bring solutions to the table
Adherence to timelines, without sacrificing quality of output
Hands on and detail oriented, with a strong ability to co-ordinate across different Geographies and with different stakeholders at Exec and Director levels
Straightforward, honest and succinct communicator. Can organize, clarify and communicate complex ideas quickly, succinctly and accurately.
Creative. Demonstrated ability to think innovatively—connecting the dots where others cannot when it comes to consumer/ customer and user data to create business building insights

Work Experience
Minimum 3-8 years of increasingly responsible experience in high impactful marketing analytics individual contributor roles
Can be from e-Commerce companies like Amazon, Flipkart etc.
In depth knowledge of multivariate statistical techniques including marketing mix modeling, attribution modelling, TURF, RAD, clustering, churn, customer scoring, neural networks amongst others
High affinity with AI powered insight tools and engines and application of data science to marketing problems
Rich experience in Marketing analytics with a strong understanding of the full range of online marketing channels, how they work, how they can be integrated, and how to evaluate them
Academics
Master’s degree in a quantitative discipline, e.g., Math, Statistics, Physics, Operations Research, Economics, Econometrics
MBA /BTech-BE from IIT/NITs or Tier 1 engineering schools only, , MS Analytics from Tier 1 schools; special preference to MBA from Mudra Institute of Communication, Ahmedabad or MBA schools that excel in Marketing
Strong exposure to Statistics – Predictive Analytics – Mandatory
Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Bengaluru,"Amsterdam, Netherlands",10000+ employees,1891,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),-1
93,Data Scientist,"About Mate Labs (https://www.matelabs.ai/):

Mate Labs is looking for a kick-ass and enthusiastic Data Scientist who has a really good understanding of machine learning and deep learning. We love GitHub and open source projects. We look for guys who are passionate for open source projects and contributions.

Mate Labs has built Mateverse for Data Analysts so that they can build customized machine learning and data science models for quick prediction like sales forecasting without writing even a single line of code.

At Mate Labs, we are solving a unique problem of algorithm & Hyperparameter selection in the field of Artificial Intelligence.

Job Responsibilities:

Be working on client projects, majorly on the solutions.

Be working with Regression Algorithms (Linear Regression, Logistic Regression, Polynomial Regression, Ridge Regression, Lasso Regression etc.)

Be working with ARIMA and LSTMs for time-series forecasting

Be working with custom Mateverse algorithms

Be working with technologies like Scikit-learn, Pandas, Numpy, Scipy, Matplotlib, Seaborn and Statsmodels

Be building mathematical models and implementing it in Python (preferably).

Skills Required:

Machine Learning Algorithms(Regression(MUST)& Time-series forecasting (MUST), Classification, Clustering)

Frameworks - Scikit-learn, Keras, Tensorflow, Pandas, Numpy, Scipy, Matplotlib, Seaborn and Statsmodels

Has worked on multiple business use-cases.

SAS or equivalent, Tableau or any other data preparation tools.

Requirements:

2 - 3 years of experience

B.Tech graduate.

Benefits:

Startup culture (immense scope to learn and grow).

Amazing team to work with.

Health Insurance for the employees.

A lot of freedom to experiment with new things.",-1,Matelabs Innovations Pvt. Ltd.,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
94,Data Scientist,"Skill: Data Scientists
Experience : 4+ Years.
Work Location : Pune.
Preferred : Immediate Joiners (10-15 Days Post Selection).

Job Description: -Â
Â
â€¢Python - ScikitLearn
â€¢Keras, tensorflow,Scala, Spark, py Spark,
â€¢Telecom Network Domain knowledge
00-12.00 Years",3.6,"Unionsys Technologies
3.6",Pune,"Pune, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
95,Data Scientist,"Position: Data Scientist with NLP

Location: Noida & Remote

Experience Required: 3 to 5 years

As a Data Scientist with NLP skills, you must have hands-on experience in working with natural language processing (NLP), building computation models with libraries or others, analysing large structured and unstructured dataset and familiar with machine learning concepts.
NLP Engineer responsibilities include transforming natural language data into useful features using NLP techniques to feed classification algorithms. To succeed in this role, you should possess outstanding skills in statistical analysis, machine learning methods and text representation techniques.

Your ultimate goal is to develop efficient self-learning NLP applications.
Responsibilities
Study and transform data science prototypes
Design NLP applications
Select appropriate annotated datasets for Supervised Learning methods
Use effective text representations to transform natural language into useful features
Find and implement the right algorithms and tools for NLP tasks
Develop NLP systems according to requirements
Train the developed model and run evaluation experiments
Perform statistical analysis of results and refine models
Extend ML libraries and frameworks to apply in NLP tasks
Remain updated in the rapidly changing field of machine learning
Requirements
Proven experience as an NLP Engineer or similar role
Understanding of NLP techniques for text representation, semantic extraction techniques, data structures and modeling
Ability to effectively design software architecture
Deep understanding of text representation techniques (such as n-grams, bag of words, sentiment analysis etc), statistics and classification algorithms
Knowledge of Python, R, Hadoop
Familiar with No-SQL such as MongoDB, relational databases and unstructured data.
Ability to write robust and scalable code
Experience with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)
Strong communication skills
An analytical mind with problem-solving abilities
Degree in Computer Science, Mathematics, Computational Linguistics or similar field
*

Expected Start Date: 8/6/2020

Job Types: Full-time, Contract

Salary: ₹60,000.00 to ₹130,000.00 /month

Experience:
total work: 3 years (Preferred)
Education:
Bachelor's (Preferred)
Work Remotely:
Yes",4.5,"Infiniticube Services Pvt Ltd
4.5",Noida,"Noida, India",1 to 50 employees,2017,Company - Private,IT Services,Information Technology,₹10 to ₹50 million (INR),-1
96,Data Scientist,"About Company:
Casepoint provides full eDiscovery capabilities through a powerful, secure, cloud-based platform. We are repeatedly chosen by leading law firms and multinational corporations for their largest matters. On an upward trajectory for almost a decade, Casepoint is looking to expand its team globally. Team cooperation, work hard, play hard attitude, open communication, and kindness mark Casepoints culture.
Job Description
We are looking for a Data Scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products
Key job responsibilities:
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending companys data with third party sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance
Required skills & experience
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, Logistic Regression (LR), Linear Discriminant Analysis (LDA), K-Nearest Neighbors (KNN), Classification and Regression Trees (CART), Gaussian Naive Bayes (NB), Support Vector Machines (SVM).
Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc. Excellence in at least one of these is highly desirableX
Great communication skills
Experience with data visualization tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive, Pig
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Data-oriented personality
Compensation & culture:
Excellent culture produces an excellent product. We value our team members, so we provide a nurturing environment of camaraderie. We recognize talent with competitive compensation and career empowerment.
Location: Surat, India",3.5,"Casepoint Pvt. Ltd
3.5",Surat,"Washington, DC",51 to 200 employees,2006,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
97,Data Scientist,"Job Type: Full Time
Location: Bangalore

Purpose of Position:
The purpose of hiring this person is for his Robust experience in the area of Software Development in Computer Vision using a blend of traditional Image Processing based & modern Machine Learning/Deep Learning based techniques.

Roles & Responsibilities:
Experience with object detection, tracking, classification, recognition, scene understanding.
Excellent programming & rapid prototyping skills in Python & C / C++ (Optionally).
Exposure to Data structures / Algorithms is a must.
Expertise on OpenCV, DLib.
Excellent knowledge on any / all of the given concepts in Computer Vision – namely Image Classification, Object Detection and Semantic Segmentation developed using state of the art deep learning algorithms.
Hands on experience in developing efficient and real-time convolution neural network models.
Hands on working experience with anyone of the deep learning frameworks – TensorFlow, Caffe, Pytorch, Keras, MXNet, Theano.
Exposure to model compression and pruning in deep learning.
Familiarity with GPU computing (CUDA, OpenCL) and HPC.
Experience / exposure to usage of Open Source technologies.
Experience / exposure to Product development methodologies & Software Engineering processes.
Experience in owning technical architecture of the products, planning roadmaps & technically managing the team.
Job Requirements::
BE / B.Tech, MS/M.Tech (Electronics, Computer Science or related) Experience – 4+ Years.
Strong Problem Solving & Communication skills.
Highly Motivated, Creative and a Team player.",4.1,"Lincode
4.1",Bengaluru,"Menlo Park, CA",1 to 50 employees,2017,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹10 to ₹50 million (INR),-1
98,Data Scientist,"Kline, a global management consulting and market research firm, is looking for a Data Scientist. This data science professional will help interpret and draw inferences from the information hidden in vast amounts of data, both internal and external, to make more meaningful and insightful decisions that will enable the delivery of better products and services. This technologist should have a minimum of two (2) years of experience working in the data science field or 2 to 4 years of experience working in the predictive analytics, visualization or other ancillary data science sub-field.

The ideal candidate will come from a services firm engaged in Business Intelligence/Market Research or Business/Management Consulting with a focus on Data Management, Knowledge Services, and Business Analytics.

This individual is expected to: use modern technology and state-of-the-art data mining & analysis techniques to conduct statistical and quantitative analyses and build high-quality prediction systems integrated with Kline’s product and service portfolio, build and enhance predictive modelling data products via proprietary models, utilize machine learning to build competitive recommendation engines comparable to those employed by service firms, and guide and grow the data science team.

Candidates must have excellent English verbal and written communication skills.

Responsibilities
Data mining and analysis using state-of-the-art methods
Building and optimizing classifiers using machine learning techniques
Creating/maintaining automated anomaly detection systems and tracking their performance
Enhancing data collection procedures to include relevant information for analytic solutions
Processing, cleansing, and verifying the integrity of data used for analyses
Interacting with and utilizing Azure cloud databases and on-prem Microsoft databases
Conducting ad-hoc analysis and presenting results using modern data visualizers
Skills and Qualifications
Knowledge of developing machine learning models and applying advanced analytics solutions to solve complex business problems
Proficiency with programming languages: Python, Scala, R, SQL, or equivalent
Proficiency with common data science tools: Scikit-learn, TensorFlow, Keras, PyTorch or equivalent
Proficiency with applied statistics, such as statistical forecasting & testing, regression analysis, and multivariate analysis
Experience in constructing and executing queries to extract data in support of Exploratory Data Analysis (EDA) and model development
Experience with supervised Machine Learning techniques like Multiple Regression, Logistic Regression, Decision Trees, k-nearest neighbors (k-NN), SVM, Ensembles, etc.
Experience with unsupervised Machine Learning techniques like PCA, LDA, k-means, DBSCAN, Autoencoder etc.
Experience with forecasting techniques using Time series methods and causal forecasting methods
Experience with predictive modeling, deploying and monitoring ML solutions in an iterative or Agile/DevOps environment using lifecycle management methods and tools
Experience with analyzing and visualizing data from diverse sources, interpreting results in the business context, and reporting results clearly and concisely using tools like Power BI or Tableau
Familiarity with Microsoft Azure services and tools is a plus
Degree in Statistics/Quantitative Analyses, Computer Science, Mathematics, Operations Research, or other related technical fields with equivalent practical experience
Strong communications skills
Kline offers…
A world-class international work environment located in Hyderabad, India
A dynamic, multi-cultural team and collegial work atmosphere
Practical use of English and valuable work experience with a well-established consulting and market research firm
Kline & Company offers a competitive compensation and benefits package in a supportive work environment. Interested and qualified candidates should apply by submitting their resumes and salary history/salary requirements via our website.

Equal Opportunity Employer, M/F/D/V",2.9,"Kline & Company
2.9",Hyderabad,"Parsippany, NJ",51 to 200 employees,1959,Company - Private,Consulting,Business Services,₹1 to ₹5 billion (INR),"McKinsey & Company, Euromonitor, Frost & Sullivan"
99,Data Scientist,"Brillio
is forging ahead aggressively amidst the current COVID-19 situation and
continues to hire for various roles globally - with all interviewing and
on-boarding done virtually. Brillio has invested in the right capabilities to
adapt to the new normal and empower its employees to operate seamlessly. All
the new joiners, along with the Brillio family, will temporarily work remotely
until it is safe to return to our offices.

Read
Brillio’s Chief Operating and Delivery Officer, Aftab Ullah’s statement about
Brillio's hiring plans in the leading publications - The Times
of Indiaand The
Week’s latest stories about the positive hiring sentiments of tech
firms.

Job
Description:

· B.
Tech & M.B.A (preferred) /MTech / M.B.A with 3 years of minimum experience
in data science/machine learning (OR) PhD degree specializing in a relevant
field such as Probability, Statistics, Machine Learning, Data Mining,
Artificial intelligence/Computer Science.

· Should
have deep experience in either Image Analytics / Computer Vision using Deep
Neural Networks in domains such as object detection, object identification

· Should
have experience in Text Mining / Natural Language processing in domains such as
Chat Bots, or Translations or Document Summarization

· Deep
understanding of statistical modelling/machine learning/ data mining concepts

· Strong
analytical and quantitative problem-solving ability

· Strong
interpersonal and communication skills: ability to tell a clear, concise,
actionable story with data, to folks across various levels of the company.

· Proficiency
with data analysis platforms, preferably R/Python/any other open source
statistical platform

· Attitude
to work in a fast paced and continuously changing environment

· Business
focused and result oriented

· Enjoys
dirtying hands with data, coding is part of life

·Expresses
himself/herself in thought leadership forums, blogs, participates in AI/ML
competitions/programs/events/groups

· Should
be able to talk even with business analysts, technologists, statisticians and
business stakeholders",3.1,"Brillio
3.1",Bengaluru,"Santa Clara, CA",1001 to 5000 employees,2014,Company - Private,IT Services,Information Technology,₹10 to ₹50 billion (INR),-1
100,Data Scientist,"For Data Scientist Developer role:
1.Strong programming skill in C++, Object orientated programming and File based Design.
2.Hands-on experience of video Surveillance domain and algorithms evaluation / Testing [AI/ML/Deep learning domain]
3.Familiar with the Linux platform based development
4.Python/Go programming expertise â€“ highly preferred
5.Familiarity with Kaffe, tensor flow is very useful for C++ with python candidates

For QA / Automation Testing role:
1.Strong knowledge in Test Requirement analysis and Design, reviewing software requirements and preparing test scenarios and executing tests on software usability [AI/ML/Deep learning domain].
2.Good Knowledge in Automation using Python, JS Scripting.
3.Hands-on experience of video Surveillance domain and algorithms Testing/evaluation using different automation tools and standard compliance check.
4.Preparing reports on all aspects related to the software testing carried out and reporting to the design team.
5.API testing experience, testing of deep learning machine learning systems is very useful for testers.

4.00-9.00 Years",3.6,"Wipro Limited
3.6",Bengaluru,"Bengaluru, India",10000+ employees,1945,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Cognizant Technology Solutions, Tata Consultancy Services, Accenture"
101,Data Scientist,"OVERVIEW OF THE COMPANY

StarStar India has defined the Indian media landscape for over two decades and today is one of the country’s leading media conglomerates, reaching approximately 650 million viewers a month across India and more than 100 other countries. Star generates 20,000 hours of content every year and broadcasts 40+ channels in 8 different languages, reaching 9 out of 10 C&S TV homes in India. The network’s entertainment channel portfolio includes Star Gold, Channel V, Star World, Star Movies, Star Utsav, Life OK, Movies OK and Star Plus, India's No. 1 Hindi General Entertainment Channel. It has a leading presence in regional broadcasting as well, through a bouquet of affiliate channels which includes Star Jalsha, Jalsha Movies, Star Pravah, Asianet, Asianet Plus, Suvarna, Suvarna Plus, Vijay and now Maa. It is also present in the Indian movie production and distribution space through Fox Star Studios, an affiliate joint venture company.
JOB DESCRIPTION


KEY RESPONSIBILITIES :
Using techniques from supervised and unsupervised machine learning, statistical analysis and predictive modelling to deliver business insights to business units based on data
Working directly with internal customers to educate them on “moving beyond BI” and training their internal resources to execute advanced forms of analytics
Creating reusable implementations of statistical tests and models using cutting edge technologies
Working with the academic and business community to develop new techniques and to contribute to research in the area of advanced analytics in media
Assisting in engagement management, requirements definition, project scoping, timeline management, and results documentation to ensure professional relationship management
PERFORMANCE MEASURES :
As per role KPIs
QUALIFICATION :
2-8 Years plus post qualification
Degree in computer science with a machine learning focus (other technical degrees also accepted e.g. applied mathematics, statistics, physics, operations research). PhD will be desirable.
KNOWLEDGE AND SKILLS :
Advanced knowledge of statistical and machine learning methods, particularly in the areas of modelling and business analytics
Strong programming skills
Experience with statistical languages and packages, such as R, SAS, Mat-Lab, and/or Mahout
Experience working with relational databases and/or distributed computing platforms, and their query interfaces, such as SQL, MapReduce and Hive.
Experience with additional programming languages, such as Python, Java, and C/C++.
Excellent written and verbal communications skills, with a proven ability to translate complex methodologies and analytical results to higher-level business insights and key take-away
A proven passion for generating insights from data, with a strong familiarity with the higher-level trends in data growth, open-source platforms, and public data sets.
Experience working hands-on with large-scale data sets
Familiarity with visualization software and techniques (including Tableau), and business intelligence (BI) software, such as Micro-strategy, Cognos, Pentaho, etc.
PERSONAL ATTRIBUTES :
Creative, gritty, driven by curiosity and comfortable with failure
Strong Data intuition: Talent to identify and visualize patterns
Multi Modal Communication skills
We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, gender identity, disability, protected veteran status, or any other characteristic protected by law. We will consider for employment qualified applicants with criminal histories consistent with applicable law.",3.8,"Star TV Network
3.8",Mumbai,"Mumbai, India",1001 to 5000 employees,1991,Company - Private,TV Broadcasting & Cable Networks,Media,Unknown / Non-Applicable,-1
102,Data Scientist,"Data Scientist Bangalore As a fully functioning analytics team member, applies best practices to analytics solutions and contributes to the development of improved best practices. Below are the MUST HAVES: • Experience as Data Scientist - Fortune 100 Clients - Prefer Product Base. • Data analysis experience working with large-scale data. • Strong experience using Python & SQL for analysis, modeling, and data visualization.
Advanced statistics, data mining and modeling knowledge. Requirements: • Advanced Python for Data Science (descriptive / predictive models) + Strong Stats background Own the end to end data science process, from initiation to deployment, and through ongoing communication and collaboration. • Drive personalization, real-time decision-making, causal inference, and predictive analytics capabilities through the application of Machine Learning, Deep Learning, NLP, and Simulation in an agile development framework. • Conduct quantitative analysis of experimental, and textual data to generate insights and drive decision making (ANOVA, Regression, Chi-Sq, AB, pre-post etc..) Working knowledge of SQL, Tableau, Hadoop, BigQuery, Presto, Vertica Write well documented code that can be shared and used across teams, and can scale to be used in existing products",3.2,"Calsoft Labs
3.2",Bengaluru,"Bengaluru, India",1001 to 5000 employees,1992,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,"Mindtree, Happiest Minds Technologies, Altran Americas"
103,Data Scientist,"Min. Exp: 3 years
Ahmedabad, India
Job Role
Skills Required
Personality
Job Role
Develop and refine algorithms for machine learning from large datasets.
Write offline as well as efficient runtime programs for meaning extraction and real-time response systems.
Develop and improve Ad-Targeting based on various criteria like demographics, location, user-interests and many more.
Design and develop techniques for handling real-time budget and campaign updates.
Be open to learning new technologies.
Collaborate with team members in building products.
Skills Required
MS/PhD in Computer Science or other highly quantitative field.
Minimum 8 - 10 yrs of hands on experience in different machine-learning techniques.
Strong expertise in Big-data processing.
(Combination of the technologies you should be familiar with Kafka, Storm, Logstash, ElasticSearch, Hadoop, Spark)
Strong coding skills in at-least one object-oriented programming language (e.g. Java, Python).
Strong problem solving and analytical ability.
Prior 4+ year experience in advertising technology is preferred.
Personality
You want to work in a small, agile team.
You mentor other developers when needed.
You work hard and don’t need much oversight.
You like variety in your projects.
You want to be proud of what you do at your job.
Interested applicants should send their resume and cover letter at career@iqm.com",-1,iqm.com,Ahmedabad,"New York, NY",1 to 50 employees,2014,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
104,Data Scientist,"Location: Chennai, Mumbai, Bengaluru - India
1+ years of Analytics experience
Understand business requirements and technical requirements
Can handle data extraction, preparation and transformation
Create and implement data models
write to careers@ganitinc.com",3.0,"Ganit
3.0",Bengaluru,"Chennai, India",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
105,Data Scientist,"Profile Requirements
Analyze and dig out carefully vetted, actionable insights from (mostly! pre-cleaned) data.
Turn insights into precise changes in the system; applying a toolset including calculus, statistical modeling, advanced algorithms, and machine learning to create measurable dollar impact.
Scale and generalize forecasting models and optimization algorithms to handle requirements from new markets and clients.
Travel and engage clients directly to translate their business needs into implementable science.
Fundamental math and designing robust algorithms from scratch excites you (as opposed to just running boost.fit).
You care deeply about true measurable value, not just methods; and you are willing to go the many extra miles to create it.
You are hands-on, like to get in there yourself; and can take a vague problem all the way through to designing, implementing, and proving the solution.
You pay attention to writing clean, minimal code; bugs really bother you.
You are pragmatic and have an eye for detail.
Solid understanding of machine learning fundamentals, probability, and algorithms.
At least 1-year of experience coding in R/Python .
1 – 3 years of experience in building analytical models; familiarity with common machine learning techniques.
Experience in C a big plus.
Experience in statistical inference and causal experimentation design a big plus.
Knowledge of data visualization tools like Tableau/Power Bi etc will be an added advantage
Pay Scale : 4.8 Lac – 13.0 Lac
Positions : 3",-1,SearchUrCollege,Noida,"Noida, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
106,Data Scientist,"Full Time
Gurgaon
Posted on June 3, 2020

Website
Redian Software Redian Software

Redian Software

Qualification: BS/MS/MCA, BCA in Computer Science or equivalent Experience: 3+ Years

Key Responsibilities:
Dive into the data and identify patterns
Development of end-to-end models and policy for our existing products
Development of Fraud models and fraud rule engine
Collaborate with various stakeholders (e.g. tech, product) to understand and design best solutions which can be implemented
Work on cutting-edge techniques e.g. machine learning and deep learning models
Skills Required:
Strong Mathematics Basics
Proficiency in Python, Matlab, C++ or any other AI language of choice
Demonstrated expertise in solving Data Science problems from first principles
Familiarity with relational and NoSQL databases
Experience with Unix/Linux
Good Problem solving & Analytical Skills

To apply for this job email your details to hr@rediansoftware.com.",3.9,"Cubic Web Solutions
3.9",Gurgaon,"Noida, India",1 to 50 employees,2011,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
107,Data Scientist,"Experience
1 - 5 years of relevant experience building AI/ML models and rich experience in python.

Reports To


Director - Product Management

Qualification

Bachelor's Degree in a technology or technical related field (e.g., Computer Science, Industrial Engineering, Applied Math/Statistics). Post-graduation preferred

Roles & Responsibilities
Must Have
Strong coding experience with programming tools R, Python, Unix, SQL, Git/SVN
Ability to work on data science projects from problem formulation, requirement gathering, design, coding, assessment through production implementation.
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Trees, Random Forest, etc.
Ability to understand business problems from domain experts and develop predictive models using python/R.
Ability to work with large volumes of data; extract and manipulate large datasets using standard tools such as Python, and SQL
Ability to communicate complex concepts and the results of the models and analyses to technical and non-technical audience
Ability to apply best in class approaches and innovative ideas in developing models
Flexibility to work across India and US time zones
Exceptional problem solving and communication skills
Powered by JazzHR",3.5,"iNVERTEDi IT Consultancy Pvt Ltd
3.5",India,"Chandigarh, India",1 to 50 employees,2011,Company - Private,-1,-1,Unknown / Non-Applicable,-1
108,Chief Data Scientist - ML/AI,"Icertis, the leading enterprise contract management platform in the cloud, solves the hardest contract management problems on the easiest to use platform. With Icertis, companies accelerate their business by increasing contract velocity, protect against risk by ensuring regulatory and policy compliance, and optimize their commercial relationships by maximizing revenue and reducing costs. The AI-infused Icertis Contract Management (ICM) platform is used by companies like Airbus, Cognizant, Daimler, Microsoft and Sanofi to manage 6.5 million contracts in 40+ languages across 90+ countries.

Contracts have always been the foundation of commerce - determining, influencing and guarding the balance between risk and reward. This is the first time in history that almost all contracts have been digitized and the risks and rewards expressed in legal language can now potentially be enshrined in computer readable logic. This role at Icertis is to bring thought leadership to computational law and its journey towards autonomous contracts. With insights into the contracting processes of some of the largest organizations in the world, this role will be responsible for evolving new tenets of contracting and reinforcing existing ones. The Chief Data Scientist will study current trends and data, evolve new methodologies and platform features to set the direction of Icertis enterprise contract management intelligence. The role reports to the CTO.
Role Requirements
You have demonstrated skills to go deep into a domain and transform business processes in that domain by applying the right AI techniques. You are a respected and recognized leader in the field, and have deep knowledge of machine learning and NLP techniques. You bring teams together, break new ground and provide thought leadership in areas that have the potential to make deep impact to how we live and work. Research or application background in computational law or related domains is a big plus. You bring the right values and team work to build a world class analytics team
Responsibilities
Deeply understand the mechanics of the enterprise contract management lifecycle
Help define and own the direction of the Icertis platform for applying AI to contracting processes
Establish Icertis’ s thought leadership in this area
Build a strong team of data scientists and engineers to help realize the Icertis vision of transforming the foundation of commerce through AI/ML
Provide pragmatic solutions to tough contracting problems using AI working with a team of data scientists and engineers
Qualifications
Holds a PhD degree in a quantitative discipline: computer science, applied mathematics, statistics, engineering or equivalent
5+ years of industry experience
5+ years of hands-on data science and NLP experience
Knowledge of machine learning techniques (regression, classification, clustering, dimension reduction, etc.) and their real-world advantages/drawbacks
Deep knowledge of Machine Learning, NLP related mathematical domains such as statistics (distributions, tests), calculus, linear algebra, probability, etc.
Icertis is not open to 3rd party solicitation or resumes for our posted FTE positions. Resumes received from 3rd party agencies that are unsolicited will be considered complimentary.

Icertis, Inc. provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, gender, sexual orientation, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. Icertis, Inc. complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities.",4.2,"Icertis
4.2",Pune,"Bellevue, WA",1001 to 5000 employees,2009,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,"Selectica, SAP Ariba"
109,Data Scientist,"Looking for:
Strong background in Machine Learning and Statistics.
Fluency in Python and R programming language.
Good understanding of Relational & Non- Relational database and SQL.
Familiar with Tensor Flow, OpenCV and Tesseract OCR.
1-3 years of relevant experience.
Good communication skills.
Portfolio/Demoable project from previous experience.

Responsbilities:
Work on projects related to healthcare.
Build models and analyze medical data collected from healthcare devices and apps.
Build models and tools for analyzing pills and different medicine images.
Expose this data to mobile and web apps to build feature set.

Job Perks:",4.6,"Cumulations Technologies
4.6",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
110,Data Scientist,"Key Responsibilities

Understand the key end to end analytics of project requirements and scoping the existing & new requirements.
Assessing the quality & comprehensiveness of data.
Analyzing KPI’s of key business functions like sales & marketing and supply chain.
Work with Data architects to create and evolve dashboard templates.
Set data standards for enhancing data maturity for analytics.
Data pre-processing, modelling & post-processing of data.
Comfortable with basic statistical principles and apply them with the data sets.
Machine Learning: Ability to work with algorithms, understand, interpret and devise your own algorithm for the business problem.
Selection of right algorithms (Regression, Naïve Bayes and Random Forest).

Job Requirements and Skills

Data modelling Skills: SQL, Python and analytics model building using Machine Learning.
Data visualisation skills: Power BI / Tableau / Qlikview / Cognos.
Big Data: Spark, Hive.
ETL.
Domain: Automotive / Non-Automotive (Industrial Manufacturing/Retail/Energy & utilities, Finance)

Years of Experience

Experience: Minimum 5 years of relevant experience.
Projects: Minimum 3 projects in data science delivered to customers (not academic with Kaggle competitions)

Job Location: Chennai

Academic Qualification: B.E or any equivalent degree

No of positions: 3

Proceed to apply job",3.2,"Hindujatech
3.2",Chennai,"Chennai, India",1001 to 5000 employees,2011,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
111,Data Scientist,"JOB DESCRIPTION

KEY RESPONSIBILITIES :
Using techniques from supervised and unsupervised machine learning, statistical analysis and predictive modelling to deliver business insights to business units based on data
Working directly with internal customers to educate them on “moving beyond BI” and training their internal resources to execute advanced forms of analytics
Creating reusable implementations of statistical tests and models using cutting edge technologies
Working with the academic and business community to develop new techniques and to contribute to research in the area of advanced analytics in media
Assisting in engagement management, requirements definition, project scoping, timeline management, and results documentation to ensure professional relationship management

PERFORMANCE MEASURES :
As per role KPIs

QUALIFICATION :
2-8 Years plus post qualification
Degree in computer science with a machine learning focus (other technical degrees also accepted e.g. applied mathematics, statistics, physics, operations research). PhD will be desirable.

KNOWLEDGE AND SKILLS :
Advanced knowledge of statistical and machine learning methods, particularly in the areas of modelling and business analytics
Strong programming skills
Experience with statistical languages and packages, such as R, SAS, Mat-Lab, and/or Mahout
Experience working with relational databases and/or distributed computing platforms, and their query interfaces, such as SQL, MapReduce and Hive.
Experience with additional programming languages, such as Python, Java, and C/C++.
Excellent written and verbal communications skills, with a proven ability to translate complex methodologies and analytical results to higher-level business insights and key take-away
A proven passion for generating insights from data, with a strong familiarity with the higher-level trends in data growth, open-source platforms, and public data sets.
Experience working hands-on with large-scale data sets
Familiarity with visualization software and techniques (including Tableau), and business intelligence (BI) software, such as Micro-strategy, Cognos, Pentaho, etc.

PERSONAL ATTRIBUTES :
Creative, gritty, driven by curiosity and comfortable with failure
Strong Data intuition: Talent to identify and visualize patterns
Multi Modal Communication skills

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, gender identity, disability, protected veteran status, or any other characteristic protected by law. We will consider for employment qualified applicants with criminal histories consistent with applicable law.",3.7,"Star
3.7",Mumbai,"ALESSANDRIA, Italy",51 to 200 employees,-1,Company - Private,-1,-1,₹1 to ₹5 billion (INR),-1
112,Data Scientist,"Description
BizViz provides a 360 degree view of a business's data, serving any vertical and meeting the demanding needs of all business executives. With a 50+ strong team building the BizViz platform over several years, it is targeted at creating technological solutions that will give our customers the edge they need to succeed.

We strongly believe that our success lies in the success of our customers. We aim to build applications the way they envisioned, keeping each business' unique ideas and requirements in mind. We offer businesses a better alternative to using standard cookie-cutter ERP templates.

Job Summary
Design and execute statistical analysis, modeling, and simulation efforts for clients that lead to actionable decisions affecting operations. Analyze data sets to summarize, identify trends, predict future states, and characterize uncertainty. Author complex written products documenting study results. Apply analytical approaches using statistical programming languages, including Python, SAS, and R. Work closely with teammates from non-mathematical disciplines to ensure that operational strategies are considered in the context of applying statistical theory. Use statistical theory on modeling, simulation, and data analysis to deliver measurable improvements to organizational policies and programs.

Responsibilities
Engage in data mining, algorithm development, statistical analysis, regression, and machine-learning initiatives
As part of ongoing work and interaction with the broader team, identify new opportunities to use modeling and advanced analytics to drive business value
High Proficiency in SQL
Expertise in applied statistics.
Able to translate business objectives into actionable analyses.
Able to communicate findings clearly to both technical and non-technical audiences
Expertise in at least one statistical software package such as SAS or Python and R
Experience with machine learning algorithms and predictive analytics
Natural curiosity to enjoy diving deep into the material to find answers to yet unknown questions.
Demonstrated ability to perform comfortably in a fast-paced work environment
Education, Experience, Skills and Abilities Required for Consideration as a Candidate:
PhD or MSC in a quantitative discipline: Statistics, Applied Mathematics, Operations Research, etc.
3+ years of experience in using statistical and data mining techniques to solve real business problems

Minimum of 3 years of experience in any one of the following:
Machine Learning
Data Mining
Predictive analysis
R & Python or SAS.
Passion for problem-solving, developing creative solutions, and continuous learning.
Experience in at least one of the following domain - Retail, Healthcare & Education.
Location
Bangalore & Hyderabad.",3.0,"BDB
3.0",Bengaluru,"London, United Kingdom",51 to 200 employees,1993,Company - Private,-1,-1,Unknown / Non-Applicable,-1
113,Data Scientist 2,"Strong analytical skills: ability to build quick estimates using back-of-the-envelope analysis, structure (and, if needed, execute) more complex analyses, pull together business cases and forecasts to navigate through multi-dimensional sets of trade-offs. Experience in Payment fraud / risk analytics is an advantage.
Enthusiasm for data-driven problem solving within a fast-paced environment is a must. In addition, experience with Microsoft Excel or statistical software, working knowledge of SQL/ BigData/Hadoop, and hands-on experience in Analytics techniques involving large data sets such as Decision Tree, AI/ ML techniques, etc. Knowledge of Hadoop is must.
Polished communication skills: risk analysts need to collaborate cross-functionally with product managers, data scientists, business owners, and customers to learn from subject-matter experts, present findings in a clear and concise manner, and reach alignment on how to execute risk strategies.
Education: Graduate degree from good colleges with 5-9 years of experience",3.6,"PayPal
3.6",Bengaluru,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple"
114,Data Scientist,"Data Scientist
Experience

– 2 to 4 Years
Education

– B.Sc / M.Sc (Maths / Statistics) B.Tech /B.E. – Computer Science
Job Description:


2 - 4 years of experience in machine learning and data mining
Excellent understanding of different software such as Perl, Python, Hadoop, Java and R programming
Strong technical background and have excellent problem-solving abilities
Good in at least one programming or scripting language
Understanding of databases and ability to write SQL queries
Excellent oral and written communication skills with business acumen
Should be a self-starter with high initiative and enthusiastic to learn and deliver on latest tools and technologies
Experience worked in big data environment is an added advantage
Apply",3.1,"Sybrant Technologies
3.1",Chennai,"Chennai, India",1 to 50 employees,2007,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
115,Machine Learning Engineer,"Experience: 5+ years

Location: Madurai, Tamil Nadu, India

Technology: Python, ML libraries scikit-learn and pandas, DL Framework TensorFlow/Keras, datasets visualisation, OpenCV, Linux.

Desired Skills and Experience:
Analyzing the ML algorithms that could be used to solve a given problem and ranking them by their success probability.

Exploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real world.

Verifying data quality, and/or ensuring it via data cleaning.

Supervising the data acquisition process if more data is needed.

Finding available datasets online that could be used for training.

Defining validation strategies.

Defining the preprocessing or feature engineering to be done on a given dataset.

Defining data augmentation pipelines.

Training models and tuning their hyperparameters.

Analyzing the errors of the model and designing strategies to overcome them.

Deploying models to production.

Email to: careers@techmango.net",3.7,"Techmango Technology Services
3.7",Madurai,"Westchester, IL",51 to 200 employees,2014,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,-1
116,Data Scientist,"Data Scientist
Job Description


ITS Data Scientist

Job Description Summary

The ITS Data Scientist is responsible for integrating business, information, and technology into analytical models that help drive business performance and competitive advantage and providing the business with answers to questions. The role collaborates with Business, IT Functional Engineers and Platform architects to create value from varied data sources. Creating value from data requires a range of talents: from data integration and preparation, to architecting specialized computing/database environments, to data mining and intelligent algorithm development.

Hiring Requirements

Job Details

Development of analytics to help drive competitive advantage from data with accountabilities across multiple functional and technical areas with wide range of complexity.
The Data Scientist must understand medium/complex data types (integrate, manipulate, prepare), know advanced analytics (appropriate techniques, interpret data and diagnose models, meet business requirements), and focus on the business outcomes (goals, constraints, decisions while communicating outcomes via presentations).
Develop models and algorithms that drive innovation throughout the organization. This may include marketing, supply chain, inventory planning and deployment, network planning, order routing, and order fulfillment and delivery.
Conduct advanced statistical analysis to provide actionable insights, identify trends, and measure performance Build learning systems that monitor data flows and react to changes in customer preferences, network constraints, and business objectives.
Collaborate with engineers to implement and deploy scalable solutions Provide thought leadership by researching best practices, conducting experiments, and collaborating with industry leaders.
Partners as a bridge between the business and the information management teams to make sure that the solution fits within the data management principals.
Coordinates data science implementations while leading design variances based upon business needs while ensuring artifacts and repositories are documented.
Manages engagements with vendors as they relate to evaluation, design and delivery of business capabilities.
Contributes to the evaluation and selection of software product standards.
Leader in industry representation, policy formation, User Groups, and strategic direction
Mentors others to complete Continuous Improvement (CI) initiatives; consults and shares knowledge across org; awareness of industry trends.
Education required/ preferred:
MS/PhD in computer science, statistics, or operations research or related technical discipline.
Experience:
3-5+ years of continuous experience in software engineering, software development, solution architecture
Knowledge of machine learning, statistics, optimization or related field
Experience with R, Python, Matlab is required
Experience building machine learning application in areas like time series forecasting, classification models, clustering models, multivariate regression models etc
Experience in Microsoft Azure Stack in the Cloud with focus on Data Factory, Data Bricks, BLOBs, Data Lake Storage, ML Studio, Azure Analysis Services, Azure Data Warehouse, Power BI etc
Experience working with large data sets and distributed computing tools a plus (Map/Reduce, Hadoop, Hive, Spark, Python, R, Gurobi, MySQL, etc.)
Excellent written and verbal communication skills along with strong desire to work in cross functional teams
Consumer products experience in an online and/or retail/manufacturing environment is preferred
Possess strong leadership skills and exhibit creative thinking to be able to come up with inventive solutions to solve business challenges
Provide thought leadership while keeping up with industry trends and disseminating information across the organization
Experience working with blended teams consisting of employees, vendors, and consultants with both onshore and offshore resources
Strong Technical leadership of advanced analytics teams and vendors
Extensive experience collaborating with Enterprise Architects and infrastructure engineers to identify, design, and implement highly complex, end-to-end solutions
Cultivates networking opportunities within the organization
Broad range of business and IT experiences; Has achieved technical and/or business certification(s).
Global VISA and Relocation Specifications:
K-C requires that an employee have authorization to work in the country in which the role is based. In the event an applicant does not have current work authorization, K-C will determine, in its sole discretion, whether to sponsor an individual for work authorization. However, based on immigration requirements, not all roles are suitable for sponsorship.
This role is available for local candidates already authorized to work in the role’s country only. K-C will not provide relocation support for this role.
Primary Location
IT Centre Bangalore GDTC
Additional Locations
Worker Type
Employee
Worker Sub-Type
Regular
Time Type
Full time",3.9,"Kimberly-Clark
3.9",Bengaluru,"Irving, TX",10000+ employees,1872,Company - Public,Consumer Products Manufacturing,Manufacturing,₹500+ billion (INR),"Procter & Gamble, Georgia-Pacific, Unilever"
117,Data Scientist,"We have immediate requirement for Data Scientist
Data Scientist having skills in Python, ML, Statistical modelling,NLP with experience years 5 to 8 years in the respective filed
Interested please share updated CV
00-8.00 Years",3.5,"Unitforce Technologies Consulting Pvt Ltd
3.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2003,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
118,Data Scientist,"Locations: Bangalore, Data Science & Analytics, Mountain View, New Jersey, New York

Alphonso is a TV data company and the market leader in providing brands and agencies with verified TV audiences across all screens. Alphonso’s TV data platform processes billions of data points every day about TV content and ad viewership, in the US and internationally.

Our best-in-class automated content recognition (ACR) uses advanced fingerprinting technology to identify ads and programming on TV in real time. With the industry’s largest TV data footprint, we map ad exposure data from tens of millions of households to a broad range of third-party data sets such as demographic data, location data, transaction data, web visit data and more, all in a privacy-safe fashion, to help brands understand consumer behavior across the digital and offline realms.

We are looking for data scientists / ML engineers who go above and beyond textbook solutions; critical thinkers who apply their expertise to solve unique problems and draw deep insights from this vast pool of data. You will have the opportunity to drive impact across the board, including making strategic decisions about our products and infrastructure.

Responsibilities:
Develop scalable data models, machine learning algorithms to facilitate data-driven decision making
Take advantage of massive amounts of structured data to understand end user behavior and help our advertising customers get better bang for the buck
Design and evaluate experiments
Use AI/deep learning techniques in conjunction with our ACR technology to extract deep insights
Be a thought leader and go-to expert on everything data

Requirements:
MS/PhD in Computer Science, Statistics, Engineering, or another relevant quantitative field
Experience with machine learning algorithms and/or statistical modeling
Proficiency in Python/R/Scala or other programming languages
Familiarity with Big data technologies like Hadoop, Map/Reduce, Spark, Hive etc. is a plus",4.1,"Alphonso
4.1",Bengaluru,"Mountain View, CA",51 to 200 employees,2012,Company - Private,TV Broadcasting & Cable Networks,Media,Unknown / Non-Applicable,-1
119,Data Scientist,"Location Pune, India – Full Time
Position Expectations
Our Data Science & Machine Learning team is looking for a hands-on data scientist who can independently build statistical & mathematical models and can design & develop performant algorithms of the highest quality. Need to have an aspiration to become an exceptional data scientist with a passion for learning new technologies and high inclination towards research.

Responsibilities

You would be responsible for managing, developing, maintaining industry specific analytical models
The role would involve conducting research and prototyping innovations (new product ideas) along with data and requirements gathering.
The role would also involve testing various machine learning and analytical tools to build prototypes and production-grade systems. Familiarity with big data technologies and distributed computing concepts will be an advantage.

Qualification & Experience
Knowledge of designing & developing analytical solutions (Statistical & Machine Learning) for complex business problems. Below qualities are desired

Technical Graduates

Understanding of concepts and algorithms used in design of experiments
Understanding of R or Python’s data science stack
Understanding of business statistical/ML predictive techniques such as Regression, ANN, Bayesian methods, Decision Trees, SVM etc.
Understanding of NLP and related areas.
Thorough understanding of RDBMS,NoSQL and data management concepts , fluency in SQL scripting
Understanding of cloud computing platforms (AWS/ IBM Watson/ Google Analytics/ MS Azure)

Management Graduates

Domain knowledge in Finance (Corporate/Retail/Investment Banking) and/or Operations (Retail/ SCM/Logistics) and/or Marketing
Good understanding of Business Statistics
Knowledge of IT systems & applications in your area of expertise

General Requirements

Ability to formulate a problem statement and implement analytical solutions by understanding data and problem statement
Passionate about solving problems, quality and learning new technologies
Good communication skills
A flexibility required in terms of performing different types of responsibilities from a start-up perspective
Strong sense of team work, ownership, and accountability

Education
B.E/ B.Tech./M. Tech/ MBA in any field with significant knowledge in one or more of the following : Statistics, Mathematics, Machine Learning, Economics, Finance or Marketing.

Note
Training on core and advanced statistical techniques/methods would be provided",-1,Right Steps Consultancy,Pune,"Noida, India",1 to 50 employees,-1,Unknown,Consulting,Business Services,Unknown / Non-Applicable,-1
120,Data Scientist,"Requirements
Should have good knowledge of statistics and machine learning techniques
Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value
Should have good problem solving skills
Should have working knowledge or experience with tools such as R, Matlab etc
Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem
Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner

Responsibilities
Selecting features, building and optimizing classifiers using machine learning techniques.
Data mining using state-of-the-art methods.
Extending company’s data with third party sources of information when needed.
Enhancing data collection procedures to include information that is relevant for building analytic systems.
Processing, cleansing, and verifying the integrity of data used for analysis.
Doing ad-hoc analysis and presenting results in a clear manner.
Creating automated anomaly detection systems and constant tracking of its performance

Skills and Qualifications
Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc...
Experience with common data science toolkits, such as R, Matlab, Python related etc.
Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard
Proficiency in using query languages such as R, SQL etc. Experience in Python is plus
Experience with various sdks like mitie, dib, stanford NLP, etc are preferred
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise
We’re looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Master’s or PHD in Statistics, Mathematics, Computer Science or another quantitative field",3.8,"IQLECT
3.8",Bengaluru,"Bengaluru, India",1 to 50 employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
121,Data Scientist,"Job Description – Data Scientist
Roles & Responsibilities:
Ability to understand a problem statement and implement solutions & techniques for solving natural language processing, text analytics, and information extraction problems, as well as structured data problems.
Work and collaborate with other teams to deliver and create value for clients
Fast learner: ability to learn and pick up a new language/tool/ platform quickly
Conceptualize, design and deliver high-quality solutions and insightful analysis
Conduct research and prototyping innovations; data and requirements gathering; solution scoping and architecture; consulting clients and client facing teams on advanced statistical and machine learning problems.
Come up with actionable ideas to solve problems and implement those ideas.
Communicate context, data, solution and implications to the team, senior leaders and stakeholders.


Skills:
Intermediate to expert level proficiency in at least one of Python and R
Ability to discover effective solutions to complex problems. Strong skills in data-structures and algorithms.
Experience of working on a project end-to-end: problem scoping, data gathering, EDA, modeling, insights, and visualizations
Problem-solving: Ability to break the problem into small problems and think of relevant techniques which can be explored & used to cater to those
Intermediate to advanced knowledge of regular expressions, machine learning, probability theory, information theory, statistics, and algorithms. Discuss and use various algorithms and approaches on a daily basis.
Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, MySQL, etc.


Qualifications & Experience :
Bachelor's or Master's degree in engineering.
Good knowledge of Basic Statistics (Hypothesis testing, probability, distributions, etc.)
Exposure towards multivariate statistical Analysis (such as PCA, PLS, etc.).
Strong in Machine learning and supervised Learning techniques such as ANN, Decision Trees, SVM, Naïve Bayes etc.
Knowledge on Unsupervised learning techniques such as k-means, hierarchical clustering etc.",3.5,"CoStrategix Technologies
3.5",Bengaluru,"Cincinnati, OH",51 to 200 employees,2006,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
122,Data Scientist,"Role: Data Scientist
Location: Bhubaneswar

Key Responsibilities:
Apply Data Mining/ Data Analysis methods using a variety of data tools, building and implementing models using algorithms and creating / running simulations to drive optimization and improvement across business functions.
Assess accuracy of new data sources and data gathering techniques.
Perform Exploratory Data Analysis, detailed analysis of business problems and technical environments in designing the solution.
Apply Supervised, Unsupervised and Reinforcement Learning Algorithms.
Apply advanced Machine Learning Algorithms and Statistics: Regression, Simulation, Scenario Analysis, Time Series Modelling, Classification (Logistic Regression, Decision Trees, SVM, KNN, Naive Bayes, Clustering, K-Means, Apriopri), Ensemble Models (Random Forest, Boosting, Bagging and Neural Networks).
Lead and manage Proof of Concepts and demonstrate the outcomes quickly.
Document use cases, solutions and recommendations.
Work analytically in a problem-solving environment.
Work in a fast-paced agile development environment.
Coordinate with different functional teams to implement models and monitor outcomes.
Work with stakeholders throughout the organization to identify opportunities for leveraging organisation data and apply Predictive Modelling techniques to gain insights across business functions – Operations, Products, Sales, Marketing, HR and Finance teams.
Help program and project managers in the design, planning and governance of implementing Data Science solutions.

Experience and Skills:
2+ years of professional working experience in Analytics.
Experience in Retail, Financial Services and Manufacturing.
Experience using statistical packages of R, Python and Spark ML to work with data and draw insights from large data sets.
Experience with distributed data/ computing tools: Hadoop, Hive, Spark, Python.
Experience with SQL.
Experience visualizing/ presenting data for stakeholders using matplotlib, ggplot or Excel or Tableau.
Excellent written and verbal communication skills for coordinating across teams.

Education qualification:
Bachelors/ Masters in a Quantitative Discipline (Statistics, Econometrics, Mathematics, Engineering and Science)
Reach us on careers@eta-iota.com.",-1,ETAIOTA Systems,Bhubaneswar,-1,-1,-1,-1,-1,-1,-1,-1
123,Data Scientist,"Role: Data Scientist
Location: Bhubaneswar

Key Responsibilities:
Apply Data Mining/ Data Analysis methods using a variety of data tools, building and implementing models using algorithms and creating / running simulations to drive optimization and improvement across business functions.
Assess accuracy of new data sources and data gathering techniques.
Perform Exploratory Data Analysis, detailed analysis of business problems and technical environments in designing the solution.
Apply Supervised, Unsupervised and Reinforcement Learning Algorithms.
Apply advanced Machine Learning Algorithms and Statistics: Regression, Simulation, Scenario Analysis, Time Series Modelling, Classification (Logistic Regression, Decision Trees, SVM, KNN, Naive Bayes, Clustering, K-Means, Apriopri), Ensemble Models (Random Forest, Boosting, Bagging and Neural Networks).
Lead and manage Proof of Concepts and demonstrate the outcomes quickly.
Document use cases, solutions and recommendations.
Work analytically in a problem-solving environment.
Work in a fast-paced agile development environment.
Coordinate with different functional teams to implement models and monitor outcomes.
Work with stakeholders throughout the organization to identify opportunities for leveraging organisation data and apply Predictive Modelling techniques to gain insights across business functions – Operations, Products, Sales, Marketing, HR and Finance teams.
Help program and project managers in the design, planning and governance of implementing Data Science solutions.

Experience and Skills:
2+ years of professional working experience in Analytics.
Experience in Retail, Financial Services and Manufacturing.
Experience using statistical packages of R, Python and Spark ML to work with data and draw insights from large data sets.
Experience with distributed data/ computing tools: Hadoop, Hive, Spark, Python.
Experience with SQL.
Experience visualizing/ presenting data for stakeholders using matplotlib, ggplot or Excel or Tableau.
Excellent written and verbal communication skills for coordinating across teams.

Education qualification:
Bachelors/ Masters in a Quantitative Discipline (Statistics, Econometrics, Mathematics, Engineering and Science)
Reach us on careers@eta-iota.com.",-1,ETAIOTA Systems,Bhubaneswar,-1,-1,-1,-1,-1,-1,-1,-1
124,Data Scientist,"Experience : 4-10 Years

Salary : As per the Industry Norms

Job Type : Permanent

Job Location : Noida

Job Description

Understand problem statement, identify and apply appropriate family of predictive models / machine learning algorithms.
Apply proven machine learning methods in open-source and proprietary technologies to explore and extrapolate insights from divergent data types.
Continuously monitor and challenge implemented models in existing projects / solutions and explore opportunities for continuous improvements.
Keep up to date with latest developments in the associated domain and technology areas and utilize them to improve existing projects and solutions.
Assist Healtheoz developing reusable digital assets.
Collaborate with cross-functional teams Works closely with Big Data developers and product owners to prioritize business and information needs.

Job Requirements

4+ years experience in Data Science, Predictive Modeling, and Machine Learning. Demonstrable experience in applying data science tools/techniques to business problem statements.
Graduate / Post Graduate degree in Statistics, Math or Computer Science fields
At least intermediate level skills in either R or Python.
Comfortable with the following at the minimum: Linear Regression and its variations, Logistic regression, kNN, Nave Bayes, Decision Trees and its variations, kMeans, Hierarchical clustering
Good understanding of topics such as Data Pre processing, Visualizations (ggplot2 / matplotlib etc), Cross validation, ensemble modeling.
Basic understanding of the Mathematics (Linear algebra, Calculus) and Statistics (Descriptive, Inferential) behind machine learning algorithms.

Preferred skills

Experience with Big Data technologies, SPARK.
Experience with cloud computing infrastructure like AWS.
Experience with data visualization tools like Tableau.
Good communication and interpersonal skills.",5.0,"Healtheoz India
5.0",Noida,"Noida, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
125,Data Scientist,"Work with clients to identify opportunities for leveraging company data to drive business solutions.
Mine and analyze data from company databases, live feeds, third pary sources etc to drive optimization and improvement of product development, marketing techniques and business strategies.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
Develop company A/B testing framework and test model quality.
Coordinate with different functional teams to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Primary Skills: 1. Strong problem solving skills with an emphasis on product development.
Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.
Experience working with and creating data architectures.
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
Excellent written and verbal communication skills for coordinating across teams.
A drive to learn and master new technologies and techniques.
We’re looking for someone with experience in manipulating data sets and building statistical models, and is familiar with the following software/tools:
a. Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.
b. Experience querying databases and using statistical computer languages: R, Python, SLQ, etc.
c. Experience using web services: Redshift, S3, Spark, DigitalOcean, etc.
d. Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.
e. Experience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.
f. Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.
g. Experience visualizing/presenting data for stakeholders using: Periscope, Business Objects, D3, ggplot, etc.

Secondary Skills: a. Coding knowledge and experience with several languages: C, C++, Java, JavaScript, etc.
b. Experience in multiple industry verticals will be an added advantage.

Soft Skills: a. Must be good at Client interaction skills.
b. Excellent oral and written communication skills.

Educational Background: Must have Master’s or PHD in Statistics, Mathema
Experience Range: 8 Years - 10 Years
Number of Positions: 2
Timeline: Immediate
Location: Bangalore, India
Travel Needs: Occasional Travel to Client Locations.",-1,Germane Analytics Pvt Ltd,Bengaluru,"Bengaluru, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
126,Data Scientist,"Experience
– 2 to 4 Years
Education
– B.Sc / M.Sc (Maths / Statistics) B.Tech /B.E. – Computer Science

Job Description:
2 - 4 years of experience in machine learning and data mining
Excellent understanding of different software such as Perl, Python, Hadoop, Java and R programming
Strong technical background and have excellent problem-solving abilities
Good in at least one programming or scripting language
Understanding of databases and ability to write SQL queries
Excellent oral and written communication skills with business acumen
Should be a self-starter with high initiative and enthusiastic to learn and deliver on latest tools and technologies
Experience worked in big data environment is an added advantage",-1,Sybrant Data,Chennai,-1,-1,-1,-1,-1,-1,-1,-1
127,Data Scientist,"Experience
– 2 to 4 Years
Education
– B.Sc / M.Sc (Maths / Statistics) B.Tech /B.E. – Computer Science

Job Description:
2 - 4 years of experience in machine learning and data mining
Excellent understanding of different software such as Perl, Python, Hadoop, Java and R programming
Strong technical background and have excellent problem-solving abilities
Good in at least one programming or scripting language
Understanding of databases and ability to write SQL queries
Excellent oral and written communication skills with business acumen
Should be a self-starter with high initiative and enthusiastic to learn and deliver on latest tools and technologies
Experience worked in big data environment is an added advantage",-1,Sybrant Data,Chennai,-1,-1,-1,-1,-1,-1,-1,-1
128,Data Scientist,"Primary Responsibilities:
This project requires a data scientist to build a python-based classification model prototype that analyses raw data files and establishes output data ranges across dimensions.
This data model will deliver analytical results indicating type based on the inputted data.
This model should run on all new samples received in our cloud, accepting payloads and outputting staged-output scores. Outputs will be appended to existing record for review, analysis, and reporting.
Sample data is currently in an AWS cloud which is where your model will reside and be deployed. Upon completion, the deployed model will automatically ingest, process new data samples received through a web app and stored in an AWS DB, outputting classification results. Results will classify/stratify into groups of cohorts.
Specific Responsibilities:
Build, develop, and deliver core model in AWS infrastructure (EC2 (preferred), Sagemaker, Lambda, etc)
Configure necessary AWS infrastructure to support the model
Model must be deployed in AWS environment
Model must process payloads and produce scores saved for reporting and access
Daily or every-other-day check-ins to discuss updates, progress, challenges, and results
Knowledge/Skills/Abilities:
3-5 years of work experience.
Good understanding of how machine learning, deep learning and A.I. algorithms work
A person experienced in performing data analysis and model development for data set related to spectroscopy / chemo-metrics or similar will be an added advantage
Extensive experience in model serving and workflow tools to enable rapid and reliable ML experimentation at scale.
Practical cloud computing experience with AWS technologies utilizing infrastructure as code methodologies to create high performance and data intensive platforms.
Programming skills in Python, R, SQL programming with the ability to quickly create prototype and debug solutions on Cloud Native / Linux /embedded platforms.
More information will be provided to the successful applicant.

Job Type: Contract

Pay: ₹400,000.00 - ₹500,000.00 per year

Experience:
Software Development: 2 years (Preferred)
Education:
Bachelor's (Required)
Benefits:
None
Work Remotely:
Temporarily due to COVID-19",-1,"BreathX Technologies Inc, ( Canary Health Technologies)",Pune,-1,-1,-1,-1,-1,-1,-1,-1
129,Principal Data Scientist,"Introduction
As a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether its investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.

Your Role and Responsibilities

IBM Global Technology Services (GTS) is the IT infrastructure and business process services segment of IBM, one of the largest IT and software companies in the world.

GTS Analytics team in IBM is building new innovative AIOPS solution by combining big data with Machine Learning and Deep Learning

AIOPS refers to multi-layered technology platforms that automate and enhance IT operations by using analytics and machine learning to analyse big data collected from various IT operations tools and devices, in order to automatically spot and react to issues in real time. AIOPS bridges three different IT disciplinesservice management, performance management, and automationto accomplish its goals of continuous insights and improvements.

Some of the Solutions we work involve the following

Ø Real time anomaly detection solutions that proactively identify service impacting incidents and prevent system downtimes. This is done by leveraging an ensemble of Deep learning and LSTM models.

Ø Natural Language Processing for entity, topic clusters and relationship extraction

Ø Text Analytics in human generated tickets and correlation with event tickets for event noise reduction. ApplyNatural Language Classification and RNN algorithms to automatically route tickets

Ø Log Analysis - Text mining, message clustering / templatization, Logs to metrics, anomaly detection, event annotation and sequencing

Ø Learn Log Message Sequence for each mainframe batch job and Identify Anomalies during job runs using sequence mining techniques and provide early warning / alerts

Ø Cloud Migration - Patterns-based discovery optimization: Identify potential business application boundaries using algorithmic approach from Cloudscape data.

Ø Wave planner: Employ goal-based reasoning from AI planning capabilities for Server affinity, cost, time, black-out windows, etc.

To power the above use cases, we have a Big Data system that can handle 2-3 TB of data daily and we manage a data lake that is 15 PB in size.

As a Principal Data Scientist, you will be responsible for identifying and supporting current and new hypotheses. With your understanding of complex concepts, you will translate hypotheses into actionable items that are understandable by non-technical business users.

As a Principal Data Scientist you will take the lead to provide strategic direction on large scale business problems. You understand challenges in multiple business domains, are able to discover new business opportunities and at times you may not even fully understand what the problem is before starting. The problems we address are significantly complex and we expect you to lead excellence in our data science methodologies. You have scientific and industrial maturity to deliver designs and algorithms that set the standard for the organization. You have a distinct ability to identify and implement robust, efficient and scalable solutions that leverage multiple techniques and/or technologies

You will gather, evaluate and document business use cases in the IT Infrastructure and Cloud domain and translate them to data science solution definition . You will Provide guidance and architecture support to platform development teams and oversee the development from initial concept to production deployment

Required Technical and Professional Expertise
Master's degree in a quantitative field such as computer science, applied mathematics, statistics, physics, engineering or finance
6+ years of industrial experience in implementing data science or AI solutions from exploration to production
3+ years of experience in a responsible senior or team lead role managing a team of data scientists who develop robust machine learning models to solve actual business problems
Extensive overview of applied methods in statistics, machine learning and artificial intelligence
Solid understanding of data analytics infrastructure and data engineering: data storage and retrieval, ETL pipelines, Docker, Kubernetes
Knowledge of software engineering practices such as version control, continuous delivery, unit testing, documentation, release management
Experience in natural language processing, text analytics, data mining, text processing or other AI subdomains and techniques
Preferred Technical and Professional Expertise
Experience with open-source distributed data processing frameworks, such as Spark
Experience working in a Linux environment
Experience working on a development team building product
Experience with presenting complex data science processes/information to non-data scientists
Experience with Information Retrieval and relevant tools such as Lucene, Elasticsearch, Solr
Experience with conducting projects from requirements generation, annotation, and modeling, through NLP output deliverables and management of internal/external clients
Prioritization skills; ability to manage ad-hoc requests in parallel with ongoing projects
Experience with Scikit-learn, TensorFlow, Keras, NLTK
Experience with leveraging best practices conducting advanced analytics projects
Experience building scalable machine learning applications and deploying them in production
About Business Unit
At Global Technology Services (GTS), we help our clients envision the future by offering end-to-end IT and technology support services, supported by an unmatched global delivery network. It's a unique blend of bold new ideas and client-first thinking. If you can restlessly reinvent yourself and solve problems in new ways, work on both technology and business projects, and ask, ""What else is possible?"" GTS is the place for you!

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Bengaluru,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
130,Data Scientist,"Design and lead the development of various machine learning initiatives for improving search relevance and personalized ranking that drives product metrics
Understand the user and their behavior and continuously contribute to making their experience better with each release
Lead the experimentation strategy with measurement frameworks
Partner with various business stakeholders and product leads to build the future of search for various products within Khatabook
Define and execute an iterative search maturity improvement roadmap • Identify ways to better leverage our content and improve its quality and attributes, to improve the overall search experience",4.5,"KhataBook
4.5",Bengaluru,"Bangalore Rural, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
131,Data Scientist,"Roles and Responsibilities
Understand clients business objectives and strategy to ensure that analysis work is focused on the areas where most value can be added.
Collaborate with stakeholders/ team leaders in order to understand problem statements and design and execute potential solutions.
Mentor team members and ensure fault-free execution of projects / solutions.
Integration of multiple sources of data working on BigData platforms.
Perform Exploratory Data Analysis on large and complex data sets comprising of structured, semi-structured and unstructured data.
Work on multiple unstructured problems to deliver insights/ end-to- end solutions and improve our clients- understanding of their customers using analysis / statistics / machine learning algorithms.
Keep abreast of the latest developments in the data science space across industries for potential uses.

Please mail your CV to career@torcai.com",-1,torcai digital media,Pune,-1,-1,-1,-1,-1,-1,-1,-1
132,Data Scientist,"Position: Data Scientist

About us: WebMD Health Corp., an Internet Brands Company, is the leading provider of health information services, serving patients, physicians, health care professionals, employers, and health plans through our public and private online portals, mobile platforms, and health-focused publications. The WebMD Health Network includes WebMD Health, Medscape, Jobson Healthcare Information, prIME Oncology, MediQuality, Frontline, QxMD, Vitals Consumer Services, MedicineNet, eMedicineHealth, RxList, OnHealth, Medscape Education, and other owned WebMD sites. WebMD®, Medscape®, CME Circle®, Medpulse®, eMedicine®, MedicineNet®, theheart.org®, and RxList® are among the trademarks of WebMD Health Corp. or its subsidiaries.

Aptus Health is a wholly-owned subsidiary of WebMD. As the analytics arm of Aptus Health, we help our clients and our products realize their potential. Helping understand customer behaviour and traits is at the core of what we do. A team of 8 members, we are analogous to a start-up centre with hands-on responsibility for every member.

Role & Responsibilities:


The selected candidate will work on the following:
• Work with real-world case studies in Data Science and a chance to implement various modeling techniques
• Get real-life experience of working with big data in the digital marketing sphere.
• Opportunity to independently execute and lead analytical projects and assignments
• Help solve some challenging Healthcare related digital marketing problems globally. Transform business question into data requirements; collect and merge the data; analyse the data, link it to the business reality and present the results
• Develop predictive models and machine learning algorithms to study the change in physician prescribing behaviour as well as WebMD integrated campaign response behaviour. Build analysis to understand user engagement and behaviours across various WebMD products.
• Build expertise in data preparation, data visualisations and transformations through SAS, R, Tableau and other analytical tools.

Technical Skills needed:
• Experience with data manipulation in SQL environment is a must. Knowledge of Snowflake data warehousing is good to have

• Experience with statistical and data manipulation tools such as SAS or R is a must • Need very good expertise in using Microsoft Excel, and Microsoft PowerPoint. Excellent presentation skills required

• Experience developing statistical models like hypothesis testing, regression models, classifications models, forecasting etc is a must

• Algorithm designing and implementation skills in R or Python is required

Requirements:
• B.Tech/B.E. / MSc Statistics from premier institutes with minimum 80% marks in 10th and 12th grade
• 1.5-2.5 years of relevant work experience in Analytics field",3.4,"Aptus Health
3.4",Mumbai,"Reading, MA",201 to 500 employees,2008,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
133,Data Scientist,"Location
Powai, Mumbai
Experience
5+ years
Education
BE/B.Tech
Type
Regular/Full time
Roles and Responsibilities

Identify valuable data sources and automate collection processes
Undertake reprocessing of structured and unstructured data
Analyze large amounts of information to discover trends and patterns
Build predictive models and machine-learning algorithms
Combine models through ensemble modeling
Present information using data visualization techniques
Propose solutions and strategies to business challenges
Collaborate with engineering and product development teams

Desired skills and experience

Deep experience in machine learning
Excellent skills in Python
Exposure to advanced deep learning techniques such as LSTM, CNN, Dense neural networks as well as neural networks design and implementation through tools like tensorflow/keras/pytorch/deep AI or equivalent
Experience of working in multiple text mining / NLP solution
Should have experience of deploying and putting into production ML based solution
Should have at-least 1 end-to-end ML project experience
Must possess experience in Python
Experience: 5+ years",3.7,"NSEIT
3.7",Maharashtra,"Mumbai, India",1001 to 5000 employees,1999,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,-1
134,Data Scientist,"Job Title: Data Scientist
Experience required: 3-4 years

Job Summary:
We are looking for a passionate Data Scientist to turn data into meaningful information that can help our clients make data informed decisions
Typical responsibilities include end to end execution of advanced data science projects primarily involving applying data mining techniques, doing statistical analysis, and building high quality prediction systems. You’ll have access to large B2B and B2C data sets on a robust analytic platform. Customer and account data is enriched with demographics and firmographics, transactional purchase history, Web behavior and cross-channel marketing campaign history. Tools and analytic environment include SAS, Tableau, R/Python and well-managed MPP RDBMS, Hadoop & Hive.
Loyalytics is a startup and our work environment is very conducive to trying and testing out a variety of new things. A high degree of passion, commitment to our customers’ priorities and willingness to learn new things on the go are some of the qualities that will help individuals succeed at Loyalytics.

Job Description:
3-4 years real world experience working as a data scientist
Hands on experience in statistical modelling software such as R, Python or SAS (optional) along with data visualization tools like Tableau/Power BI
Good understanding of statistical and predictive modeling concepts.
Strong expertise in either R or Python
Excellent analytical thinking, and problem-solving skills.
Hands on experience in working on data mining and statistical machine learning problems
In depth understanding of advance ML techniques and algorithms like regression, clustering, decision trees, Neural Networks, Gradient descent, SVM etc
Experience in project management and handling client communications
Excellent communication (written/verbal) skills, including logically structuring and delivering presentations.
Open to learning new methods/techniques in the ever-changing world of analytics. High aptitude to learn quickly, assimilate to new teams and projects, and work well under pressure with appropriate attention to detail.",4.2,"loyalytics consulting
4.2",Bengaluru,"Bengaluru, India",1 to 50 employees,2015,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
135,Data Scientist,"Data Scientist Large Banking MNC 5 - 10 years Bangalore QUALIFICATION Bachelor’s or Masters Technology Degree in Computer science or Equivalent Job Description The senior data scientist will get the opportunity to work in an agile software development enviornment addressing machine learning and optimization analytics problems. The senior data scientist will be part of cross diciplinary data science team working on software development projects, typically involving large, complex data sets. They will work with technical team in development and deployment and application of predictive analytics. Key Skills Required Demonstrated skill of data cleansing, data qualityy assesment.

Use the descriptive statistics, feature extraction and predictive analytics on real datasets. Skills at data visualization and storytelling for an audience of stakeholders. Experience in working with Hadoop and spark will be added advantages.",-1,TALCHEMIST,Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Public,-1,-1,Unknown / Non-Applicable,-1
136,Data Scientist,"We are looking for a data scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.

Responsibilities
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending company’s data with third party sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance.
Requirements
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.
Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc (depending on specific project requirements). Excellence in at least one of these is highly desirable
Great communication skills
Experience with data visualisation tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive, Pig
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills (if you expect that the person in this role will integrate the solution within the base application, list any programming languages and core frameworks currently being used)
Data-oriented personality",-1,Hookfish,Mumbai,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
137,Data Scientist,"Miles is looking to expand its data science and data engineering team in INDIA!

Here's a quick checklist:
You live in India
Want to work for a fast-growing Silicon Valley Startup
You are passionate about solving challenging problems
You are looking to put your stamp on the product
What you'll need:
Education
Master's/PhD (preferred) or Bachelor's (required) in CS/ML/AI or relevant computational/engineering discipline

Machine Learning/Data Science:
Solid theoretical understanding of ML fundamentals: linear algebra, probability, statistics (as relevant to ML), optimization
Knowledge of different ML techniques and when/how to use them: classification, regression, clustering, outlier detection, dimensionality reduction, etc.
Comfortable manipulating and analyzing complex, high-volume, high-dimensionality data from varying, heterogeneous sources
Experience with messy real-world data - handling missing/incomplete/inaccurate data
Proficient in the Python ML ecosystem: NumPy, Pandas, SciPy, Scikit-Learn
Strong understanding of relational databases like PostgreSQL is a plus

Programming experience:
At least 2+ years of experience writing production-quality Python code
Version control: Git, GitHub/Bitbucket
Experience delivering large-scale deployable projects

Great to have
We deal with large volumes of geospatial data, so experience working with geospatial data at scale is a big plus
Knowledge of Python (Shapely, GeoPandas, Fiona, CartoPy, etc) and/or database (PostGIS) geometry/geospatial tools
Domain experience in building models for location-based services, transportation, scheduling, vehicle routing",3.9,"Miles
3.9",Bengaluru,"Bergen, Norway",51 to 200 employees,2005,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
138,Data Scientist,"Location: Bangalore

Skill Sets:
Strong learning acumen
Team Player
High sense of ownership
Ability to work in a fast-paced and deadline driven environment
Passion for technology
Highly skilled at Data Interpretation
Problem solver
Responsibilities:
Hypothesis testing, insights generation, root cause analysis, factor analysis
Statistical model (predictive & prescriptive) development using various statistical methods
Familiar with Machine learning techniques/algorithms
Test/train the model, Improve Model accuracy, Execute & Monitor model performance, prepare reports based on the results of the analysis
Data Extraction from various platforms such as SQL/Big Data Platform/Google CP, Dataset Preparation (creation of base data, aggregation, transformation), performing EDA
Qualifications:
Experience with data analysis/Modelling
Postgraduate with Engineering Background
Hands on exposure of machine learning concepts and algorithms
Must be fluent with any one of these Python, R or Java
Strong in statistical & machine learning concepts
Knowledge of Python Libraries – Scipy, Numpy, Pandas, IPython, Scikit-learn, Tensor-flow, Keras, Theano etc.
Strong Python skills for data wrangling / analysis / visualization / modeling
Experience with distributed big data processing (PySpark, Jupyter, Linux, AWS)
Deployed at least one industrial project using supervised / unsupervised machine learning",2.5,"Bharat Light & Power
2.5",Bengaluru,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
139,Data Scientist,"Location: Bhubaneswar/

Technology:
Job Descriptions:
Any BE/ B.Tech / M. Tech/ MCA minimum 1-5 year expertise. Good in Mathematics & Statistics (Distributions, Statistical testing, Regression), Machine Learning & Algorithm (k-NN, Naive Bayes, SVM, Decision Forests), R/WEKA/NumPy, Data Visualization tools (D3.js, GGPlot), SQL, Hive, Pig, NoSQL databases (MongoDB, Cassandra, HBase), Good scripting and programming skills

Send your Resume at: hr@silicontechlab.com",3.2,"Bharat Light & Power
2.5",Bengaluru,-1,1 to 50 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
140,Data Scientist,"Help us improve access to life-changing therapies that can transform human health
We are Cytiva, a global provider of technologies and services that advance and accelerate the development and manufacture of therapeutics. Formerly part of GE Healthcare, we have a rich heritage tracing back hundreds of years, and a fresh beginning since 2020.

Our customers undertake life-saving activities. These range from fundamental biological research to developing innovative vaccines, biologic drugs, and novel cell and gene therapies. Our job is to supply the tools and services - the pots, pans, soups and sauces - they need to work better, faster and safer, leading to better patient outcomes.

What you’ll do
The candidate will be working with multiple teams & functions for data collation, data deep dives and analytical story building. The individual will be responsible for communicating insights from available data sources to Marketing & Commercial teams. The individual must have strong experience of using a variety of data mining/data analysis methods & tools, building and implementing models, using/developing algorithms and creating/running simulations. We are looking for solid communication and presentation skills in this role.
Mine and analyze data from databases to drive the optimization and improvement of marketing techniques and business strategies.
Program management of critical Advanced Analytics programs (incl Forecasting, Targeting and Propensity models, etc.)
Use predictive & prescriptive modeling to increase and optimize customer experiences, revenue generation, marketing initiatives and other business outcomes.
Processing, cleansing, and verifying the integrity of data used for analysis.
Being a key contributor / influencer to strategic marketing plans
Clear communication with stakeholders: help our business understand in a very simple manner what we are doing, how we are going to do it (per project and more conceptually) – raising awareness of the fundamentals and details of data science.

Who you are
Masters Degree in Marketing, Business Administration or Statistics/Economics or equivalent
4 - 5 years’ experience in Analytics
Well versed with Statistical tools (eg R / SAS / Python, etc) and techniques feeding into advanced predictive & prescriptive analytics.
Knowledge of a variety of machine learning techniques (statistical tests, regressions, clustering, decision trees, artificial neural network, etc) and experience in their application and output interpretation.
Knowledge on classification, prediction, optimization, clustering and market basket analysis models.
Working experience with visualization tools incl Spotfire / Tableau / Qlikview / Power BI
Well versed with Digital Analytics and understanding digital & web data.
Co-ordinate with different functional teams to implement models and monitor outcomes.
Excellent English oral and written communications skills.
Desirable Experience
Background in biopharma, pharma, life sciences or healthcare industry.
Experience of working in Marketing & Commercial teams.
Experience / knowledge of working with databases & data architecture.
Ability to influence and make recommendations at all levels of the company
Excellent project management skills – able to lead and manage complex matrix teams
Experience working in a dynamic and horizontal team environment.
High energy, works proactively and demonstrates flexibility in approach to changing priorities.
Team oriented – ability work well with diverse, cross-functional teams

What to expect as a career path in this role
This individual will grow as an Advanced Analytics professional along with a) core exposure in the
analytics industry & b) business and domain knowledge of the BioPharma industry.
Who we are
Whatever your role, we bring purpose and challenge into our everyday work. If you are driven to make the world a better place thanks to science and medicine, you’ll feel right at home here. If you’re flexible, curious and relentless, you’ll belong. If you are excited about a global culture, this can be the place to further your career.

Want to know more? Experience life at Cytiva on our Careers website , Instagram channel and LinkedIn page !

Cytiva is a 3.3 billion USD global life sciences leader with nearly 7000 associates across 40 countries who are dedicated to our mission to advance and accelerate therapeutics. As a trusted partner to customers that range in scale and scope, Cytiva brings efficiencies to research and manufacturing workflows, ensuring the development, manufacture and delivery of transformative medicines to patients.

Cytiva is part of the Danaher family of companies, a global science and technology innovator committed to helping customers solve complex challenges and improving quality of life around the world.",-1,Cytiva,Bengaluru,"Vancouver, Canada",1 to 50 employees,-1,Subsidiary or Business Segment,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 million (INR),-1
141,Data Scientist,"FiFyles is changing lives!

As Data Scientist eager to jump into brand new learning experiences, you’ll have fun analyzing complex, massive data sets. If this sounds like you, please read on!

Who You Are

You cut your baby teeth on Bayesian modeling and Markov chains
You love the idea of working at a startup-within-a-startup
You are curious enough to always want to dig deeper
You dream of applying machine learning to everyday tasks
You never wait for someone else to ask “why?”
You drive others crazy with how open-minded you are
Your imagination knows no bounds when it comes to slicing and dicing complex problems and data sets
You are strongly opinionated on what makes for great software skills, and love playing devil’s advocate
You believe every experience, good or bad, is an opportunity to grow
You are convinced that the best use of experience is to leverage it to learn more
You are a natural-born leader
You know how to prioritize
You are analytically curious
You still like to play “Where’s Waldo?” on occasion to test your awesome pattern-recognition skills
There’s always methodology to your madness
You know that numbers tell a good story
Spock is your favorite Star Trek character

What You Want From Your Next Career Move

To change the world using your skills in solving analytical problems. To learn. To perform data analyses on massive data sets, at scale. To manage the data demands of a company with a heart.

Why We Need You

FitFyles is a company that saves lives. A company that is going to change the face of health care for good. We need someone to administer the flow of ideas regarding data and make recommendations to influence the direction of our business by communicating results to numerous stakeholder groups. You’ll work with the massive datasets, information, and knowledge that we’re collecting and organizing, and help to drive innovation in our product and enhance user experiences. We need your unique skills to:

Help manage our intense growth by developing and executing data analyses to manage the growth demands of FitFyles
Develop, implement and maintain robust reporting methodologies and tool to support mission-critical business objectives
Pioneer new uses of data to help save lives by enhancing user growth and engagement

How You’ll Change Global Healthcare

You’ll help millions live longer, healthier, happier lives through your ability to exercise creativity in addition to your analytic skills.

What you’ve achieved

BS / MS / PhD in a quantitative discipline (applied mathematics, statistics, CS, OR, or related field)
5+ years of experience using quantitative approaches to solve challenging and meaningful analytical problems (or equivalent)
Proficiency in programming and the use of analytic tools to perform rapid design, prototyping, analysis, simulation of, and experimentation with, advanced algorithms and applications (such as Matlab / Mathematica, Java, Ruby, Python, and experience in various relational and non-relational databases)
Solid grounding in applied mathematics and statistics including expertise in Bayesian modeling, multivariate regression, logistic regression, machine learning, cluster analysis, decision analysis, time series analysis and forecasting, factor analysis, structural equation modeling, item response theory, Markov chains, and data visualization (preferred)
Startup or equivalent experience (preferred) and the drive to live the dream (required)",-1,Fitfyles,New Delhi,"New Delhi, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
142,Data Scientist Bangalore,"Data Scientist

Exp: 3+ Years

We are hiring for the role of Data Scientist for a Sweden based company for their offices in Bangalore.
Bachelor in Engineering, Data Science, Maths, Stats or Computer Science
2+ years of related work experience in Data science field
Fluency in SQL for data access, manipulation, and validation
Proficiency in either R, Python or SAS for data analysis
Passion for data visualization and information design
Capable of clearly communicating complex analyses to a non-technical audience, including extensive experience presenting to leadership groups
Ability to initiate, refine, and complete projects with minimal guidance
Mail your resume to team@equinoxes.in",-1,Equinox e Services,Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
143,Data Scientist,"RESPONSIBILITIES
To analyse data and support the development of technology tools relevant for the development sector. Work on creating data insights on developmental and public policy issues with a focus on providing knowledge support to policy makers and informing public discourse.
Support in providing data analytics for all data and technology related projects esp. Jaano India.
Use multivariate statistical analysis to analyse data and produce detailed project reports. Ensure data integrity and consistency across relevant data systems. Making recommendations for solving some of these real world problems.
Collecting, cleaning and maintaining data from Open Government Datasets. Data from all major government schemes and departments must be maintained in a structured data warehouse and updated regularly.
Analysis of cleaned data to identify patterns, correlations and infer meaningful conclusions. Thereafter, presenting them in a visually lucid manner to various stakeholders and policymakers through Swaniti’s Jigyasa portal.
Creating data packages for standardized and customized research output for use of Members of Parliament, Members of Legislative Assembly and Civil Servants.
Conceptualize and create standalone data visualizations and info-graphics on development and governance issues for dissemination to media outlets and general public
Analyzing and interpreting primary level data for Swaniti’s micro planning projects to identify key patterns for national and state level policy making.
If needed provide inputs for knowledge consultations and/or the Jigyasa platform.
QUALIFICATIONS
Graduate degree in any field with courses in Statistics, Econometrics or any data-related subjects. Those with advanced degrees will be given preference.
At least 2 years of active work experience in the public or private sector with a role dealing directly with data cleaning, analysis and visualizations.
SKILLS

Required

The Data Scientist will be expected to have a demonstrated record of being a ‘problem solver’ with ability to analyse big data, and commitment to working on policy and developmental challenges in India.
Familiarity with handling database systems like MySQL and Hive.
Proficiency in Python and Java. Familiarity with packages/libraries used for data manipulation and plotting (eg – numpy, panda, scikit-learn)
Understanding of statistical concepts involving descriptive and inferential stats, hypothesis testing, confidence intervals and sampling, clustering and classification.
Knowledge of common machine learning algorithms, from dimensionality reduction to supervised and unsupervised techniques.
Excellent working knowledge of MS Excel
Strong leadership skills, excellent people and team skills and a constant willingness to learn.

Recommended

Proficiency in R, Python, SAS, SPSS and/or STATA.
Familiarity with MongoDB, Hadoop, Spark.
Understanding of linear algebra concepts such as matrix manipulations, Eigen values and vectors and multivariable calculus.
Knowledge regarding government policies, schemes and their implementation.
Ability to write complex Macros in Excel.",3.9,"Ank Aha
3.9",New Delhi,"New Delhi, India",1 to 50 employees,2016,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
144,Data Scientist,"PipeCandy is a 'one of its kind', 'data science' driven market intelligence platform that tracks the global eCommerce landscape. Our insights are used by well known global brands and startups. We are venture funded by India, the US, and Singapore based investors.

About the Role:
We are building a complex data product that aims to revolutionize industry intelligence by applying sophisticated machine learning & AI algorithms on millions of data points.
We are looking for a Data Scientist to ensure that the quality of this product always stays top-notch and world-class. If you love working with data, have an eye for detail and a strong adherence to quality then we’d love to hear from you.

This is a senior position where the analyst will work under the general direction of the Chief Data Scientist and senior staff in the Data Management team. The primary responsibility is to treat data as an asset and become the expert source for data standards and policy-related questions.

Key Responsibilities:
Manage the creation, deployment, and maturity of data governance processes and technology including master data, metadata, and data quality initiatives
Identify opportunities to ensure transparent, high-quality data across sources and platforms
Review, clean and add business records and formatting rules to every taxonomy/hierarchy in the product database in support of long-term data governance.
Develop processes and tools for data cleansing, de-duplicating, and other data preparation, standardization, and transformation
Collaborate with various teams to standardize data and ensure adherence to data ingestion and governance standards
Conduct root cause analysis and proposed improvement solutions
Leverage subject matter expertise to ensure data products are understood by the business users
This position requires a proficient level of experienced analytical and programming capabilities, defining requirements, developing and/or maintaining computer applications/systems, and ability to meet business needs within deadlines.

Here’s what we’re looking for in you:
Works to develop analytical/ data mining/ machine learning models using Python, R and other tools
Gather, evaluate and document requirements, ability to build an algorithm (statistical/ data mining/ machine learning) based on requirements and specifications provided
Works with data and is able conceptualize and improvise analytical solutions to problems
Ability to deploy analytical algorithms within a larger business application
Ability to visualize data and results of data analysis & analytical models
Create model documentation as per client/ regulatory standards

Qualifications & Competencies Required:
1+ years of total relevant experience
Degree in a quantitative field (Math, Statistics, Economics, Physics, and/ or Engineering, MBA)

Desired:
Ability to work with business and technology teams to build and deploy an analytical solution as per needs
Ability to multi-task, solve problems and think strategically
Strong communication and collaboration skills

Skills Required:
Experience with statistical analysis using R and Python. Experience with Spark and ML as plus
Good experience in data discovery, exploration and algorithm development
Experience with working on large data sets and developing scalable algorithms
Hands-on experience of machine learning and data mining algorithms such as decision trees, classifiers, text mining/ NLP, clustering, and regression
Exp in SAS, SPSS, or scripting languages such as Java a plus
Knowledge of Hadoop and other distributed computing platforms
Broad knowledge of data mining, NLP algorithms, machine learning algorithms and other techniques technologies
Strong analytical and problem solving skills
Excellent presentation and communication skills

Perks:
Flat organization structure with an opportunity to work very closely with the founders
Access to learning, training sessions outside of your immediate line of work
Access to group kindle account with latest titles
Stocked pantry, of course",4.6,"PipeCandy
4.6",Chennai,"Walnut, CA",1 to 50 employees,2016,Company - Private,Internet,Information Technology,₹100 to ₹500 million (INR),-1
145,Data Scientist,"Roles and responsibilities

Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight:
Translate business objectives into analytic approaches, and identify data sources to support analysis.
Analyze and model structured data using advanced statistical methods
Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns.
Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications.
Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods.
Implement algorithms and software needed to perform analyses
Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management.
Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data
Communicate results and educate others through reports and presentations.
Essential skills required
Education / professional qualifications

Masters, or PhD in Computer Science, Statistics, Mathematics

Prior Experience:

Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience

Technical skills
Ability to break down complex problems, and develop strategies to solve them
Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience
Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint.
Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval
Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing
Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred
Experience with command-line scripting, data structures and algorithms
Ability to work in a Linux environment, and process large amounts of data in a cloud environment
Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby)
Behavioral / team skills
Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations
Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills
Excellent written and verbal communication skills Team player; self-driven and ability to work independently
Team player; self-driven and ability to work independently",4.2,"Anlage HRO Services
4.2",Bengaluru,"Mumbai, India",201 to 500 employees,1996,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
146,Data Scientist,"1. Design, develop, test, deploy, maintain & document innovative solutions for challenging problems with robust, scalable, reusable, efficient, production-quality software
2. To identify, propose and build infrastructure, large-scale data pipelines, data storage strategy, common libraries and useful tools needed to manipulate data so as to create inputs for deep learning algorithms
3.Perform statistical analysis and fine-tuning using test results
4.Train and retrain systems when necessary
5.Extend existing ML/DL libraries and frameworks
6.Understanding of data structures, data modeling, and software architecture
7.Deep knowledge of maths, probability, statistics, and algorithms
8.Ability to write robust code in Python, Java, and R
9.Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)
10. Keep abreast of developments in the field
11.An intense sense of ownership, initiative-taking, and a can-do attitude
12.Great attention to detail and a data-driven approach to problem-solving

1.00-5.00 Years",3.8,"Verzeo Edutech Private Limited
3.8",Bengaluru,"Brooklyn, NY",1 to 50 employees,-1,Company - Public,-1,-1,Unknown / Non-Applicable,-1
147,Data Scientist,"Responsibilities
Ability to translate business problems into analytical structures and can be solved using statistical/ML techniques.
3+ years of applied work experience with analytics & machine learning on large datasets.
Experience with statistical software (e.g., R, Python, MATLAB, pandas) and database languages (e.g., SQL).
Good exposure to exploratory analysis and knack of deriving business insights & value. Comfortable with exploring large data sets.
Develops recommendation from complex data and business analyses and formulates them into business plan.
Has strong consultative skills in addition to quantitative (and statistical) ability to harness customer data in order to address business problems that materially impact business.
Work under minimal supervision and display strong independent behaviour while leading the team in developing structured analysis.
Must Have Skills
Build statistical models/ ML models, train and test them to and drive towards the optimal level of model performance.
Quickly prototype solutions and build models to test feasibility of solution approach.
Work across the spectrum of reporting and data visualization, statistical modelling and supervised learning tools and techniques and apply the right level of solution to the right problem.
Exposure to Big Data platforms like Hadoop and its eco-system (Hive, Pig, Sqoop, Mahout) is a plus.
Passion to learn new tools, languages and framework.",-1,Tenzai,Karnataka,-1,-1,-1,-1,-1,-1,-1,-1
148,Data Scientist,"Responsibilities
Ability to translate business problems into analytical structures and can be solved using statistical/ML techniques.
3+ years of applied work experience with analytics & machine learning on large datasets.
Experience with statistical software (e.g., R, Python, MATLAB, pandas) and database languages (e.g., SQL).
Good exposure to exploratory analysis and knack of deriving business insights & value. Comfortable with exploring large data sets.
Develops recommendation from complex data and business analyses and formulates them into business plan.
Has strong consultative skills in addition to quantitative (and statistical) ability to harness customer data in order to address business problems that materially impact business.
Work under minimal supervision and display strong independent behaviour while leading the team in developing structured analysis.
Must Have Skills
Build statistical models/ ML models, train and test them to and drive towards the optimal level of model performance.
Quickly prototype solutions and build models to test feasibility of solution approach.
Work across the spectrum of reporting and data visualization, statistical modelling and supervised learning tools and techniques and apply the right level of solution to the right problem.
Exposure to Big Data platforms like Hadoop and its eco-system (Hive, Pig, Sqoop, Mahout) is a plus.
Passion to learn new tools, languages and framework.",-1,Tenzai,Karnataka,-1,-1,-1,-1,-1,-1,-1,-1
149,Data Scientist,"Candidate should be able to analyse data and discover information, with high level inputs from the functional team. Understanding of data mining techniques and statistical analysis is important.",3.5,"Pattern Effects Labs
3.5",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
150,Data Scientist,"Primary Responsibility: The data scientist/analyst will support DSS in the areas of advanced data analytics. The analyst will be required to provide support in client engagement and data analysis, create dashboards, benchmarking.

Need strong power point, excel modeling skills, analytical and quantitative problem-solving skills, work effectively with people at all levels, and communicate complex ideas effectively – both verbally and in writing. Willingness to travel extensively. Experience in the areas of Operations Management in industry verticals such as Oil & Gas/ Chemicals/ Utilities/ Mining & Metals would be an added advantage.

Desired Skillsets

2-4 years of professional experience in Data insights generation & storytelling,
Ability to build Visualization layers using Tableau/Power BI to drive the story
Have working knowledge in predictive models using R/Python etc.
Good knowledge in writing efficient SQL queries and stored procedures
Full understanding of the processes of data quality, data cleansing, and data transformation
Good presentation skills (powerpoint etc.) and ability to articulate insights clearly and manage client expectations independently
Comfortable in manipulating and analyzing complex, high-volume, high-dimensionality data from varying sources. Ability to research and troubleshoot technical problems.

Other Requirements

Experience in operations risk management consulting space is added advantage
Preferably in one of the industries - Oil & Gas/ Chemical & Petrochemicals/Utilities/Mining & Metals
Proven work experience as a data analyst / data scientist
Programming experience in statistical modeling languages such as R, Python is a plus
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information/data with attention to detail and accuracy
Technical expertise regarding data models, database design development, data mining and segmentation techniques
Knowledge and experience with reporting packages and databases

Knowledge of statistics and experience using statistical packages for analyzing large datasets",-1,DSS Sustainable Solutions,Hyderabad,-1,-1,-1,-1,-1,-1,-1,-1
151,Data Scientist,"If the below JD matches to your teck stack please share youe updated to benchire.com

Purpose of Role:
? This position seeks a data engineer who designs, builds, tests and deploy
data analytics models
? The position will be involved in Data Analytics Lifecycle from data preparation
for data mapping, descriptive, predictive and prescriptive modelling to
deployment.

? The candidate also supports the maintenance of on-premises and cloud-
based data structures such as data marts, data warehouses, data lakes and

data pipelines from various sources and databases.
Reporting: Head of R&D

Main Responsibilities:
? Design and deploy data science models and data pipeline
? Develop python scripts, deployment scripts into data pipeline
? Designs, builds, tests and maintains on-premises and cloud-based data
architecture and structures such as data marts, data warehouses, data lakes
and data pipelines.
? Develops and deploy ETL processes for the data lakes lifecycle (staging of
data, ODS data integration, EDW and data lakes).
? Prepares and documentation technical specifications, authors and executes
unit test scripts/cases.
? Works with internal and external data providers and subject matter experts to
understand data sources and formats.
? Keeps apprised of current and emerging data science, development and
cloud-based technologies and best practices.
? Identifies opportunities for process improvement/optimization; designs and
implements these improvements as directed.
? Works within the Business Team and to define feature development, testing
and deployment
? Helps implement and plan for disaster recovery
? Identify, design, and implement internal process improvements: automating
manual processes, optimizing data delivery, re-designing infrastructure for
greater scalability.

Key Performance Indicator:
? Successful design and implementation of data science model and analytics
? Support and ensure continuity of data service
? Support IT systems and infrastructure, including data services

Qualifications:
? A good bachelor’s degree in computer science or similar.

Competence/Experience Required:
? Good experience in development using Java, Python
programming language, scripting like YAML and SQL databases,
development of server-client interfaces and APIs
? Experienced in product development, SDLC and agile methodology, source
control management
? With good knowledge on data analytics life cycle, data collection, analysis,
modelling to deployment
? With good working knowledge data models and data flows with a good
understanding of databases
? Preferably hands-on experience with Big Data Analytics
? Familiar with database systems like Microsoft SQL Server,
? Experience with various messaging systems, such as Kafka, RabbitMQ and
others
? Web technologies including Apache HTTP server, LDAP server, SSO, SAML,
OIDC
? Knowledgeable with Linux shell and security
? Familiar with Azure and its services
? Familiar with latest web application technologies including NodeJS, ReactJS
? Strong project management and organizational experience.

Upload Resume Close",-1,Benchire,Bengaluru,"Bengaluru, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
152,Data Scientist,"Apply Now

Understanding and experience with leading supervised and unsupervised machine learning methods such as GLM/Regression, Logistic Regression, Neural Networks, Deep Learning, KNN, Naive Bayes, SVM, Decision Trees, Random Forest, Gradient Boosting, Ensemble Methods, Text Mining, Social Network Analysis, Unobserved Components Modeling (UCM) and Use Scenario based Optimization Techniques.
Should be a Data Scientist with extensive predictive Modeling and Machine Learning Experience. The Candidate will be responsible for conducting data analysis and developing predictive models leveraging data science and machine learning to solve various business use cases, including marketing intelligence, customer segmentation, and predictive models for sales and marketing organization.
Candidate should have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.

For more details, Contact :
+91 - 7022998695",-1,Shiras HR Advisory & Services,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
153,Data Scientist,"Job: Technology
Primary Location: ASEAN & South Asia-India-Chennai
Schedule: Full-time
Employee Status: Permanent
Posting Date: 08/Jun/2020
Unposting Date: Ongoing

About Standard Chartered :-

We are a leading international bank focused on helping people and companies prosper across Asia, Africa and the Middle East.
To us, good performance is about much more than turning a profit. It's about showing how you embody our valued behaviours - do the right thing, better together and never settle - as well as our brand promise, Here for good.
We're committed to promoting equality in the workplace and creating an inclusive and flexible culture - one where everyone can realise their full potential and make a positive contribution to our organisation. This in turn helps us to provide better support to our broad client base.

AFD Full stack Java
Data visualisation skills: Power BI / Tableau / Qlikview / Cognos

To view information on our benefits including our flexible working please visit our career pages. We welcome conversations on flexible working.

Ø Highly experienced in Java, J2EE, REST, Struts, XML, JSON ,Web services

Ø Solid grasp of Angular or similar frameworks - Angular , HTML/5, XML, JavaScript, Type script, JQuery

Ø Experience in HTML, CSS, JavaScript

Ø Experience with Spring Boot is a plus

Ø Tools: Maven, Ant, Grunt, SystemJS, Eclipse, SVN,

Ø Application Servers: WebLogic, Tomcat, NodeJS

Ø Early Technology Adopter

Ø Strong and accurate analytical and communication skills

Ø Self-motivated and initiative personality with a can do attitude and the ability to learn quickly

Ø Preferable for Banking Client/Projects or Product Based clients/projects

Skills:-

Ø Data modelling Skills: SQL , Python,R and analytics model building using Machine Learning/ Deep Learning - ANN, CNN, LSTM,NLP,GNN

Ø Deep Learning Frameworks : Caffe, Keras, Theano, TensorFlow, or Torch.

Ø Experience working on Big Data technologies (e.g. Hadoop MR, Hive, NoSQL, Spark, Kafka, Graph Databases etc.)

Ø Big Data: Spark , Hive,Hadoop

Apply now to join the Bank for those with big career ambitions.",3.7,"Standard Chartered
3.7",Chennai,"London, United Kingdom",10000+ employees,-1,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
154,Data Scientist II,"Join a team recognized for leadership, innovation and diversity


YOU MUST HAVE
Bachelors in Computer Science, Data Science or Engineering fields
4+ years of IT experience in data scientist / software development for large corporate/organizations
2+ years of experience in building and deploying Machine Learning solutions using various supervised/unsupervised ML algorithms such as Linear/Logistic Regression, Support Vector Machines, (Deep) Neural Networks, Random Forest, etc
2+ years of hands-on experience with Python and/or R programming and statistical packages, and ML libraries such as scikit-learn, Keras, TensorFlow, PyTorch, MXNet, etc, and/or natural language processing using NLTK, spaCy, Gensim, etc.
2+ years of experience in building IT use cases / solutions especially around AI/ML cognitive services, based on Cloud infrastructure and services such as AWS and/or Azure cloud platforms.
Excellent understanding of Machine Learning techniques and proficiency in feature analysis, algorithm selection and model hyperparameter tuning.
WE VALUE
Bachelors degree in computer science, Data Science or Engineering fields
Work experience / education in data science, data engineering and analytics
Project experience with NLP/NLG, AI Conversational Agent (Chatbot), OCR
Experience with Domino Data Lab, Hadoop, PySpark, Hive, SQL, NiFi, Airflow, etc.
Development experience in RPA Tools & Platform & Implementations: Examples - UiPath, Automation Anywhere and other leading RPA platform vendors
1+ years experience in Web Service/Restful API Integration
Experience in ERP platform integration, preferably with SAP
Working Experience in an Agile/Scrum/Scaled Agile and DevOps based team environment
Certifications AI / ML and Cloud platforms
Great communication skills
Additional Information
JOB ID: req234049
Category: Engineering
Location: Devarabisanahalli Village, KR Varturhobli,,East Taluk - Phase I,Bangalore,KARNATAKA,560103,India
Exempt
Sales (LATAM)",3.8,"Honeywell
3.8",Bengaluru,"Charlotte, NC",10000+ employees,1885,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"GE, Johnson Controls, United Technologies"
155,Data Scientist,"SkillData Scientist
Experience7-9yrs
Job Location:Bangalore.

Job Description:
3 year of relevant experience
Expertise in machine / deep learning, and used various complex algorithms related to NLP, Recommendation Systems, Scoring, etc.
Good knowledge on different Neural Networks (RNN, CNN), Tensor Flow, NeuMF, Google Cloud API, etc.
00-9.00 Years",3.1,"Indecomm Global Services India Private Limited
3.1",Bengaluru,"Edison, NJ",1001 to 5000 employees,2003,Company - Private,IT Services,Information Technology,₹10 to ₹50 billion (INR),-1
156,SAP Senior Data Scientist,"Requisition ID: 252452
Work Area: Software-Design and Development
Expected Travel: 0 - 10%
Career Status: Professional
Employment Type: Regular Full Time

COMPANY DESCRIPTION

SAP started in 1972 as a team of five colleagues with a desire to do something new. Together, they changed enterprise software and reinvented how business was done. Today, as a market leader in enterprise application software, we remain true to our roots. That’s why we engineer solutions to fuel innovation, foster equality and spread opportunity for our employees and customers across borders and cultures.

SAP values the entrepreneurial spirit, fostering creativity and building lasting relationships with our employees. We know that a diverse and inclusive workforce keeps us competitive and provides opportunities for all. We believe that together we can transform industries, grow economics, lift up societies and sustain our environment. Because it’s the best-run businesses that make the world run better and improve people’s lives.

Purpose & Objective

As Customer eXperience & Solutions (CXS) team, we develop products & solutions that enable digital transformation for our customers. As the thought leaders for Application Lifecycle Management we develop the Cloud Application Lifecycle Management (CALM) platform with applications and services to support the complete application lifecycle for all SAP solutions. CALM is being built on the latest version SAP Cloud Platform – Cloud Foundry and is an essential part to deliver the Integrated Enterprise Suite. Our team focus on automated Service Delivery Applications within CALM using the CSI Data Lake and AI.

Expectation & Task
Oversee the entire machine learning lifecycle (research, design, experimentation, development. deployment, monitoring, and maintenance)
Maintain and optimize machine learning models, identify new ideas to evolve them, develop new ones & benchmark possible solutions.
Research & implement best practices to enhance existing machine learning infrastructure
Implement machine learning algorithms and libraries
Analyze large and complex data sets to derive valuable insights
Design & develop large scale training & deployment systems, using multiple GPU's and servers, dedicated H/W, Multi-threading and Parallelization
Collaborate with data engineers to develop data and model pipelines
Apply machine learning & data science techniques & design distributed systems
Write production-level code, bring code to production and engage in code reviews
Experience & Education
At least 8 yrs experience as technology leader, architect or principal engineer and 5 yrs experience working with big-data and no-SQL technologies.
M.Tech / MCA or master’s degree in mathematics or Data Science from reputed institutes
Extensive knowledge of machine learning evaluation metrics and best practices, building, validating and evaluating of machine learning model, designing and implementing machine learning pipelines in production environments & experience in architecting, training and analyzing deep learning models
Experience with building big data pipelines and Data Manipulation /data analytics / data management / Big data system.
Ability to perform technology selection and technology evaluation.
Experience in modern DevOps practice and ability to establish CI/CD process and Docker & Kubernetes
Industry experience with writing code (e.g., Python, Scala, PySpark, JavaScrip) and taking ML models/ algorithms to production
Strong analytical skills, results-oriented, customer-oriented attitude, good strategic and conceptual thinking skills
Ability to present complex information in a clear and concise manner
Experience in cloud-based SaaS applications
WHAT YOU GET FROM US

Success is what you make it. At SAP, we help you make it your own. A career at SAP can open many doors for you. If you’re searching for a company that’s dedicated to your ideas and individual growth, recognizes you for your unique contributions, fills you with a strong sense of purpose, and provides a fun, flexible and inclusive work environment – apply now.

SAP'S DIVERSITY COMMITMENT
To harness the power of innovation, SAP invests in the development of its diverse employees. We aspire to leverage the qualities and appreciate the unique competencies that each person brings to the company.

SAP is committed to the principles of Equal Employment Opportunity and to providing reasonable accommodations to applicants with physical and/or mental disabilities. If you are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to Recruiting Operations Team (Americas: Careers.NorthAmerica@sap.com or Careers.LatinAmerica@sap.com, APJ: Careers.APJ@sap.com, EMEA: Careers@sap.com).

Successful candidates might be required to undergo a background verification with an external vendor.

Additional Locations:",4.5,"SAP
4.5",Bengaluru,"Walldorf, Germany",10000+ employees,1972,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Salesforce, Oracle, Microsoft"
157,Data Scientist,"Job ID: JDS01

As a Data Scientist, you will work to resolve ambiguity with data, play a crucial role in the iteration and optimization solutions, and support data-driven decision-making across the organization.

ROLE RESPONSIBILITIES
Tasked with solving a real-life business problem that requires a processing/analyzing large amounts of data and handling a variety of data sources.
Take ownership of successful completion for the end to end life cycle and implementation.
Proactively investigate, report, and where possible, address data quality issues.
S
Can envision & implement the optimal analytics technique/approach required for the problem.
Ability to work and execute projects on both structured and unstructured data in a big data environment.
Ability to work across geographies and interact with global stakeholders.
Ability to coordinate and work within multiple business units from a project management perspective.
Prior experience working in Agile methodologies/JIRA would be a plus.
MINIMUM REQUIREMENTS
BS/BE in Computer Sciences, Math, Statistics, or related field. Masters preferred.
An expert in at least one of the machine learning frameworks - Keras, Tensorflow, PyTorch, etc, as well as programming, visualization, and statistical tools such as R, JMP, SAS, Tableau, Python, Perl, Java/C++
Minimum of 4+ years of experience in data, advanced analytics, data science, and business intelligence.
Proficient in SQL and experience with efficient processing of large data sets. Ability to write sophisticated and optimized queries against large databases.
Proficient in Python ML libraries, Hadoop/Redshift/BigQuery.
Experience in the Ad-Tech industry is a must.
OTHER INFORMATION

Join a fun and lively young Startup based in Dubai Silicon Oasis (while operating from Noida, India). Boost your experience and learn about the different types on Online AdTech environments and models. Show your skills and potentially become a pillar of our fast-growing team.Jubna offers an Attractive compensation, Health Insurance, Travel Allowance.
Some travel to Dubai, UAE is required (10%)",-1,Jubna,Noida,"Dubai, United Arab Emirates",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
158,Data Scientist,"Implement and support data discovery and predictive analytics models by analyzing business data.

Qualifications:
3+ years of experience with R
3+ years of experience with mahout or machine learning algorithms
1+ years of experience with deep learning libraries like TensorFlow or equivalent
Working experience with java or python
Database experience with MySQL or NoSQL database solutions
Ability to design the models to work on small to very large data sets
If interested, please send the latest CV to data@scalein.com or contact using our contact page.",-1,ScaleIn,Bengaluru,"San Jose, CA",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
159,Data Scientist,"We are looking for Data Scientist for our client in J.P Nagar, Bangalore. Let me know if you would be interested in it.

Job Title : Data Scientist
Location : J.P Nagar, Bangalore.
Duration : Full Time

Job Description:
The Data Scientist will work on challenging problems extracting actionable information out of the many data sources available to Client. Application areas include Identity Resolution, Marketing Analytics Security and Fraud and other Business Solutions supported by our or our clientâ€™s data.
Data Scientists create prototypes of new algorithms and support Engineering teams in productizing these capabilities. Data Scientists work closely with various teams including data acquisition, data products, data sciences and various business units including marketing, security, and internet of things to ensure implementation of capabilities that enable the organizationâ€™s vision. The role is based out of India at the Clientâ€™s offices in either Bangalore or Hyderabad.

Responsibilities:
â€¢Algorithm Development: Develop a deep understanding of all the data relevant to the problem to be addressed. Establish deterministic and probabilistic linkages between data sources and develop ways to extract and summarize the sought information in the data using a wide variety of statistical, data mining and machine learning techniques.
â€¢Prototyping: Create prototypes of productizable ways to perform the analysis at scale, provide documentation and help educate your colleagues in different function about the solution
â€¢Support Implementation: Closely work with product, engineering and client teams to incorporate Data Science capabilities into Clientâ€™s products and services

Skills and Experience:
â€¢Mastersâ€™s degree in Data Science, Statistics or a related field (we will consider applicants with a Bachelorâ€™s degree and relevant work experience as well)
Solid understanding of data mining and expert in real-world applications of these techniques

â€¢Hadoop/Big Data
â€¢Hive/SQL - traditional databases and distributed computing environments
â€¢MapReduce
â€¢Spark
â€¢Scala
â€¢Python
â€¢AWS
â€¢ETL Techniques
â€¢Statistics
â€¢Model Building
â€¢Machine Learning
â€¢Experience working with commercial and/or open source statistics and data mining packages

Familiarity with real-world applications of these techniques

â€¢Statistics
â€¢Model Building
â€¢Machine Learning
â€¢
â€¢Strong written and oral communication skills
â€¢Strong inter-personal collaboration skills. Being able to both work in groups or as an individual contributor
â€¢General curiosity, a willingness to experiment, pragmatism and the ability to handle ambiguity

Why work with us?
â€¢Because you love to build beautiful, innovative solutions that wow the customer
â€¢Because you believe in changing the status quo and are up for the challenge of your life
â€¢Because you know you can make a difference to people, places and things!

About Us
Every day, the world generates roughly 2.5 quadrillion bits of data. Client isolates certain elements and analyzes, simplifies and edits them to make precise and valuable decisions that drive results. As one of the few companies capable of knowing with certainty who is on the other end of every interaction, weâ€™re trusted by the worldâ€™s great brands to make critical decisions some 20 billion times a day.
00-11.00 Years",-1,JMA Global IT Solutions SDN BHD,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
160,Data Scientist,"We are looking for Data Scientist for our client in J.P Nagar, Bangalore. Let me know if you would be interested in it.

Job Title : Data Scientist
Location : J.P Nagar, Bangalore.
Duration : Full Time

Job Description:
The Data Scientist will work on challenging problems extracting actionable information out of the many data sources available to Client. Application areas include Identity Resolution, Marketing Analytics Security and Fraud and other Business Solutions supported by our or our clientâ€™s data.
Data Scientists create prototypes of new algorithms and support Engineering teams in productizing these capabilities. Data Scientists work closely with various teams including data acquisition, data products, data sciences and various business units including marketing, security, and internet of things to ensure implementation of capabilities that enable the organizationâ€™s vision. The role is based out of India at the Clientâ€™s offices in either Bangalore or Hyderabad.

Responsibilities:
â€¢Algorithm Development: Develop a deep understanding of all the data relevant to the problem to be addressed. Establish deterministic and probabilistic linkages between data sources and develop ways to extract and summarize the sought information in the data using a wide variety of statistical, data mining and machine learning techniques.
â€¢Prototyping: Create prototypes of productizable ways to perform the analysis at scale, provide documentation and help educate your colleagues in different function about the solution
â€¢Support Implementation: Closely work with product, engineering and client teams to incorporate Data Science capabilities into Clientâ€™s products and services

Skills and Experience:
â€¢Mastersâ€™s degree in Data Science, Statistics or a related field (we will consider applicants with a Bachelorâ€™s degree and relevant work experience as well)
Solid understanding of data mining and expert in real-world applications of these techniques

â€¢Hadoop/Big Data
â€¢Hive/SQL - traditional databases and distributed computing environments
â€¢MapReduce
â€¢Spark
â€¢Scala
â€¢Python
â€¢AWS
â€¢ETL Techniques
â€¢Statistics
â€¢Model Building
â€¢Machine Learning
â€¢Experience working with commercial and/or open source statistics and data mining packages

Familiarity with real-world applications of these techniques

â€¢Statistics
â€¢Model Building
â€¢Machine Learning
â€¢
â€¢Strong written and oral communication skills
â€¢Strong inter-personal collaboration skills. Being able to both work in groups or as an individual contributor
â€¢General curiosity, a willingness to experiment, pragmatism and the ability to handle ambiguity

Why work with us?
â€¢Because you love to build beautiful, innovative solutions that wow the customer
â€¢Because you believe in changing the status quo and are up for the challenge of your life
â€¢Because you know you can make a difference to people, places and things!

About Us
Every day, the world generates roughly 2.5 quadrillion bits of data. Client isolates certain elements and analyzes, simplifies and edits them to make precise and valuable decisions that drive results. As one of the few companies capable of knowing with certainty who is on the other end of every interaction, weâ€™re trusted by the worldâ€™s great brands to make critical decisions some 20 billion times a day.
00-11.00 Years",-1,JMA Global IT Solutions SDN BHD,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
161,Applied Scientist - Intern,"Excited by Big Data, Machine Learning and Predictive Software? Interested in creating new state-of-the-art solutions using Machine Learning and Data Mining techniques on Terabytes of Data?

At Amazon Bangalore, we are developing state-of-the-art large-scale Machine Learning Services and Applications on the Cloud involving Terabytes of data. We work on applying predictive technology to a wide spectrum of problems in areas such as Amazon Retail, Seller Services, Customer Service, Alexa, Chatbots and so on. We are looking for talented and experienced Machine Learning Scientists (Ph.D. in a related area preferred) who can apply innovative Machine Learning techniques to real-world e-Commerce problems. You will get to work in a team dedicated to advancing Machine Learning technology at Amazon and converting it to business-impacting solutions.

Major responsibilities
· Use machine learning, data mining and statistical techniques to create new, scalable solutions for business problems
· Analyze and extract relevant information from large amounts of Amazons historical business data to help automate and optimize key processes
· Design, develop and evaluate highly innovative models for predictive learning
· Establish scalable, efficient, automated processes for large scale data analyses model development, model validation and model implementation
· Research and implement novel machine learning and statistical approaches

Basic Qualifications

Basic Qualifications
· A Masters and/or PhD in CS, Machine Learning, Operational research, Statistics or in a highly quantitative field.
· Experience in predictive modelling and analysis, predictive software development.
· Strong problem-solving ability
· Good skills with Java/Scala or C++, Perl/Python (or similar scripting language)
· Experience in using R, Matlab, or any other statistical software
· Strong communication and data presentation skills

Preferred Qualifications

Preferred Qualifications
· Experience handling gigabyte and terabyte size datasets
· Experience working with distributed systems and grid computing
· Knowledge of the latest and state of the art ML technology.
· Publications or presentation in recognized Machine Learning and Data Mining journals/conferences",4.2,"Amazon
4.2",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
162,Data Scientist,"Job Description :
Required competencies:
Phd/MTech/MS or equivalent degree in Computer Science or Mathematics or Statistics
Relevant industry or research experience
Strong knowledge of data mining, machine learning techniques and statistics
Experience with analysis on large scale datasets
Strong problem solving, programming skills and computer science fundamentals
Preferred Skills:
Knowledge of Hadoop and other distributed computing platforms
Experience with tools like Weka, R and other machine learning packages
Location : Bangalore",-1,WeRecruit Talent,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
163,Data Scientist,"We provide Virtual Business Process Services to various types of overseas clients and this position is to be part of the team which provides support to USA client from Mortgage Finance industry. Hence we are looking to hire Data Scientist with experience in analyzing large amounts of data and information. Data Scientist will provide data manipulation, scrubbing and synthesizing of information into easy to read weekly, monthly and quarterly reports.

RESPONSIBILITIES

Work with large data sets and produce real-time and streamlined analysis
Work will include analyzing lender performance, asset type, leverage, etc.
Analyze third party vendor data and helping to apply that data retroactively to back-test default history
Ability to perform data mining
Pro-actively apply data frameworks to better optimize pool performance
Participate in client conversations, phone calls, company presentations, etc.
Develop forms and enhanced data tools to streamline processes and create efficiencies.
Will include data tracking and pipeline management.

QUALIFICATIONS and EXPERIENCE

Strong intellect with solid communication, quantitative, financial and analytical skills
College degree in Finance, Math, Engineering, Computer Science, Statistics, Economics or related field
Strong modeling skills to include Excel VBA and Macros, SQL (Python and Tableau a plus), Access, etc.
3+ Years of experience in similar roles
Excellent written and English verbal communication skills who works well with others in a team environment.
Strong analytical skills and attention to detail
Ability to interpret and error-check work to ensure analysis is logical
Experience with real estate mortgages is a plus
Self-starter and motivated individual with a good attitude
Ability to multi-task while working independently in a fast-pace environment

SKILLS

Advanced MS Excel skills, Excel VBA and Macros and MS PowerPoint skills
Data Science, Data Analytics and Reporting
Working Knowledge in Data Visualization Applications
Creative problem solver, Exceptional interpersonal skills, Impeccable integrity and trustworthiness
Strong Knowledge in using internet and web based applications

QUALITIES

Strong commitment to support overseas client with utmost care.
Good team player with greater level of integrity
Maintains Strict confidentiality of Client’s Data and information
Self-Motivated and Tough task master.
Quick learner and continuous learner of new technologies.

Location: Hi-Tech City, Hyderabad

Timings: USA Shift IST 5-30pm to 2-30am

salary range: As Per Industry Standards

Send Application TO: hr@finacplus.com",4.4,"FinAcPlus
4.4",Hyderabad,"Hyderabad, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
164,Data Scientist,"Description

Key Responsibilities: Team leads for small or module leads for large teams. Responsible for delivery of assigned module/ components /phases of a project.Responsible for people Management, including goal setting and providing performance feedback.Responsible for Status reporting .Responsible for Knowledge transfer and arriving at SLAs for steady state.Technical problem solving skills. Job Requirement and Skills Has a good practical understanding of technology and its application. Good grasp of technology and tools used for development. Good design skills and architectural skills in the technical area.Fair amount of domain expertise gained through working on the application or certification programs (if working in a vertical).Good understanding of the sphere of activities in a horizontal domain. Anticipates and resolves potential problems , handles escalations. Supervisory Level: Works under general supervision with few direct instructions. Carries out routine and semi-routine tasks. Provides input to project-related decisions.People Interactions Within own team or department at operational level.Contact with user/customer at peer / first /middle management level. Qualifications

About ECS

ECS is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., ECS is ranked 205 on the Fortune 500 and is consistently listed among the most admired companies in the world.",3.0,"ECS
3.0",Chennai,"Jersey City, NJ",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
165,Data Scientist,"FincluS is a Bengaluru, India based start-up focused on revolutionizing the age-old conventional methods of borrowing, lending and financial transactions. FincluS- which in simple terms means Financial Inclusion and Speed. We aim at simplifying borrowing and lending and resolving credit issues using first design principle thinking coupled with our hunger to challenge the status quo and achieve financial inclusion globally. We at FincluS highly value openness, originality, integrity and transparency.
Our ideal candidate is a passionate, self-driven, and tactful individual working with us to achieve our ambition of financial freedom and inclusion.

We are looking for a Data Scientist interested in solving one of the world's largest problems: financial inclusion. If this excites you and you love working with data and people to help achieve financial freedom, then we would love to talk to you.

Responsibilities:
Leverage a unique, diverse, and deep data set to find connections across these data sources.
Communicate findings to the team and integrate them into models.
Own the full-cycle of a model from ideation and training through deployment into our production environment.
This might be a credit model, fraud model, marketing model, or an iteration of an existing model.
Monitor model - Performance once deployed and iterate rapidly if necessary.
Contribute and share your findings and knowledge of data science and other modeling with all appropriate cross-functional teams.
Partner with the Engineering team to develop, test and deploy models.
Pull data from MySQL or other data stores, handling all the ETL from the DB to running the model to obtaining a decision.
Requirements:
2+ years of experience in a data science role or equivalent position.
Masters or PhD in a quantitative field.
Fluent in Python and packages related to machine learning.
Experience with maintaining data science models in a production environment.
Experience with data querying languages, and statistical or mathematical software.
Proficient in writing algorithms, and knowing when to apply them.
Preferred Skills & Experience:
Experience in building fraud, credit, or risk models
Expertise in NLP, network analysis, or geospatial analysis.
Problem solving skills - You thrive on finding novel solutions to hard problems. These problems may have ranged from extracting a new dataset from an unexpected source, to building cohorts for customer retention analysis, or the Times of india Saturday crossword.
Outstanding communication skills -You know your stuff is complicated, but can you communicate complex ideas to others in a manner that is easily understood and digestible.
Curious and a Self-learner – You should have the ability to ask questions, and find answers till your curiosity is curbed.
Open minded with excellent team-skills - We are looking for diverse and open minded individually with teamwork and adaptability skills.
Job Type: Full-time

Salary: ₹50,000.00 to ₹60,000.00 /month

Experience:
total work: 3 years (Preferred)
Benefits:
Health insurance
Paid leaves / Leave encashment
Travel allowance
Work from home
Flexible work hours
Education assistance
Phone / Internet reimbursement
Industry:
Banking & Finance
Work Remotely:
Yes",-1,Tekumani Agri Assest Private Ltd,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
166,Data Scientist,"Msc Statistics with 2 to 5 yrs experience as data scientist
Job location Pune City
Working day 5 ( Sat n Sunday weekly off)
Client one of the oldest n largest mfg sector into defences marine aerospace sugar n cement equipment n machines
Job Type: Full-time
Salary: ₹300,000.00 to ₹600,000.00 /year
Experience:
work: 2 years (Preferred)
total work: 2 years (Required)
Education:
Master's (Preferred)
Location:
Pune, Maharashtra (Required)
Benefits:
Health insurance
Provident fund (PF)
Paid leaves / Leave encashment
Travel allowance
Meal card / Food coupons
Education assistance
Industry:
Mechanical Engineering
Work Remotely:
Temporarily due to COVID-19",-1,Shree Consultancy Services,Pune,"VADODRA (BARODA - INDIA), India",1 to 50 employees,-1,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
167,Senior Data Scientist,"Role Summary:
We are looking for a highly motivated individual, passionate about technology to join Baker Hughes Digital team. As the Senior Data Scientist, in Baker Hughes Digital, you will focus on developing impactful and innovative analytics products for the O&G industry. The candidate will be responsible for designing analytics for products and solutions, leverage strong machine learning expertise to develop new analytics for driving growth in asset, application & industry coverage and lead engagements with external/internal customers. The candidate is also expected to mentor other engineers in analytics methods.

Essential Responsibilities:
Work in cross-functional teams to translate algorithms into commercially viable products and services.
Contribute to technical teams in development, deployment and application of applied analytics, predictive analytics and prescriptive analytics capabilities.
Develop self-learning systems that can predict failures and autocorrect based on multiple data sources
Work with the engineering team to incorporate your analyses and solutions, including working with the visualization team to create intuitive UI and rich UX stories. Partner with data engineers on data quality assessment, data cleansing and data analytics efforts
Gather and analyze data, devise innovative data science solutions and build prototypes to enable development of high-performance algorithms in scalable, product-ready code.
Initiate and propose unique and promising modeling features, develop new and innovative algorithms and technologies, pursuing patents where appropriate
Stay current on published state-of-the-art algorithms and competing technologies.
Contribute to the development of software and data delivery platforms that are service-oriented with reusable components across teams (multiple teams) that can be orchestrated together into different methods for different businesses.
Research and evaluate emerging technology, industry and market trends to assist in project development and/or operational support activities to for multiple teams or complex scenarios.

Qualifications/Requirements:
MS Degree in Computer Science or in “STEM” Majors (Science, Technology, Engineering and Math)
A minimum of 2 years as data scientist
A minimum of 3 years of technical hands-on coding experience

Eligibility Requirements:
Legal authorization to work in India. We will not sponsor individuals for employment visas, now or in the future, for this job
Any offer of employment is conditioned upon the successful completion of a background investigation and drug screen
Must be willing to travel

Desired Characteristics:
PhD in Computer Science or in “STEM” Majors (Science, Technology, Engineering and Math)
Strong distributed systems and architecture knowledge, and experience with multitier architecture
Mission critical systems experience is preferred
Ability to manage complex technical projects.
Demonstrates expertise in problem solving and technical innovation.
Demonstrated experience of delivering on commitments to clients.
Demonstrates capability of 'rolling up sleeves and getting hands dirty'.
Works well in fast paced growing environment.
Provides excellent influential communication skills and business acumen to both an arbitrator and advocate for technical issues.
Experience developing applications in an agile/DevOps environment would be a distinct advantage
Solid understanding of software development tools & infrastructure

Effective teaming and problem-solving abilities

Strong interpersonal and leadership skills
Able to interface effectively with all levels of the organization and external customers

Technical Expertise:
Proven experience coding in Machine Learning/AI techniques including Deep learning techniques (RNN, CNN, GAN, etc), Support Vector Machines; Regularization Techniques; Boosting, Random Forests, Ensemble Methods, image/video/audio processing, Bayesian modeling, time series modeling
Demonstrated experience in Parallel programming frameworks for GPUs, TPUs
Demonstrated ability to develop containerized solutions (Docker/Mesos etc)
Strong implementation experience with high-level languages and frameworks such as R, Python, Perl, Ruby, Scala, Apache Spark, Storm, SAS
Demonstrated ability to work with a variety of Deep learning frameworks including TensorFlow, Keras, Caffe, CNTK, etc…
Strong hands-on skills in sourcing, cleaning, manipulating and analyzing large volumes of data including SQL and NoSQL databases
Experience with end-to-end modeling projects, from research to solutions to analytic products
Proven experience in using well-established supervised and unsupervised machine learning methods for large industry-strength data analysis problems.
Participates in enterprise strategy development, including environmental analysis, opportunity identification, value cases and business innovation portfolio development. Reviews and/or analyzes and develops architectural requirements at domain level, aligning architectural requirements with software development strategy.
Leads and facilitates the domain’s architecture governance process based on EA’s governance structure.
Leads teams in developing plans and assessing improvement options.

Business Acumen:
Create, analyze and manage projects that provide direct business benefit; demonstrate detailed knowledge of business operations and strategic direction, including merger & acquisition opportunities
Understand industry trends and competitive landscape and the implications for your business
Partner with business leaders to align projects with business goals and needs.

Leadership:
Recommends allocation of budget to meet architectural initiatives critical to business/mission success.
Develops the business case for approval.
Provides leadership, technology guidance and mentors others throughout their domain.
Define the skills, competencies in the skills and talents for architecture team members.
Facilitates dialogues that produce new perspectives and trigger recommendations for substantial innovative / enhancements, and analysis of consequences.
Influences through others.
Uses experts or other third parties to influence.
Builds direct and ""behind the scenes"" support for ideas, uses chains of indirect influence.

Personal Attributes:
Challenges conventional thinking and traditional ways of operating and invites stakeholders to identify issues and opportunities.
Takes a holistic systems perspective.
Envisions, compares and contrasts multiple potential long-range enterprise-wide futures.
Empathizes with multiple points of view

Locations:
Bangalore, India",3.5,"Baker Hughes
3.5",Bengaluru,"Houston, TX",10000+ employees,-1,Company - Public,Oil & Gas Services,"Oil, Gas, Energy & Utilities",₹500+ billion (INR),-1
168,Data Scientist,"Responsibilities:
Undertake preprocessing of structured and unstructured data.
Build data products to extract valuable business insights
Build models to address business problems.
Propose solutions and strategies to business challenges.
Presenting information using data visualization techniques.

Requirements:
MSc / PhD in Computer Science, Statistics, Engineering or related field
Experience in probability, statistics, and statistical modeling or machine learning
Fluency in at least one scripting language
Excellent analytical and problem-solving skills
Excellent communication skills and business acumen
Good command in written and spoken English",-1,RedLotus,Mumbai,"Kowloon City, Hong Kong",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
169,Data Scientist,"Experienced professional or an active researcher in one or multiple of the following areas: OCR-ICR technologies, Artificial Intelligence, Semantic Technologies, Natural Language Processing, Image Mining, Pattern Recognition on Digital Media ,and Information Retrieval (handling data types, ranging from traditional structured data, semi-structured data such as logs; text, social networks, audio, images, and video)
Experience in Neural network, Deep learning (Feed forward, Recursive, Recurrent LSTM, Auto encoder, CNN), Transfer
Minimum 4-8 years of
Full Stack developer using Tensor flow, Theano, Caffe
Familiarity with details of implementing algorithms on multi-core CPUs, clusters (MPI), GPUs
Strong knowledge in Capability to develop production ready solution using Python.
Worked as a Data Scientist in the product development project
Experience in distributed frameworks (e.g. Graph Lab, Spark, Hadoop)
Experience in Mongo DB, Index server, Graph DB, MQ.",3.0,"Innominds Software
3.0",Hyderabad,"San Jose, CA",501 to 1000 employees,2003,Company - Private,Computer Hardware & Software,Information Technology,₹1 to ₹5 billion (INR),"GlobalLogic, Persistent Systems (India), Mobica"
170,Breeding Design Implementation Scientist,"Job Description

PURPOSE:
Leads the development of digital Advancement Playbooks and Advancement Thresholds to implement playbook driven line and hybrid prescription and implementation of Auto advancement of pipeline with no-touch for all APAC pipeline across corn, Rice, Cotton, Peral Millet and Mustard crops

Develop GBLUP, HBLUP, COGs BLUP, Plant health BLUP, prediction reports and drive product concept driven pipeline advancement for all APAC pipelines for Corn, Rice, Cotton, Pearl Millet and Mustard. Maintain, update and curation of digital pipeline for all crops. Build and support advancement and local analysis need for all crops

WHAT YOU DO:
Develop and implementation of digital advancement pipeline for all screening and PCM stages to ensure long term genetic gain in alignment with the product concepts. Development of product concept driven advancement thresholds for APAC pipelines.
Coordination with breeding and APD to implement Eva line and hybrid prescription for all APAC pipelines
Historical data and advancement decision exploration to develop data driven trait weightage in coordination with APD and breeding
Prescription model evaluation and recommend improvements with End to end playbook driven advancement workflow management for all APAC crops
Work with APC, APD, Plant Health, SPR and SPPD to ensure all data and reports needed for product advancement
Maintenance and support for report generation, alignment with advancement templet, Eva prescriptions. Make sure GBLUP, HBLUP, SC2 BLUP, COGs BLUP, Plant Health BLUPs are available in time for advancement
Maintenance and curation of digital pipeline/Horizon, checkmate. Timely decision transfer
Coordination with APD to support short term analytics need for rice, cotton, pearl millet and mustard. BLUP report, pathology report generation
Deployment of tools and software for data management, and statistical field testing analysis. Provide effective training and guidance to implement best practices
Accountable and responsible for data management, data curation, and data integrity/quality across all APAC crops and pipelines
Provide data analytics to be presented in standard visualizations and reporting that enable timely key decisions, with agile learning for new methods
Support Breeding and Field Testing teams to improve data quality and completeness as it relates to QA QC, plot designs, testing location information

Required Candidate profile

PhD in genetics or plant breeding or animal breeding or bioinformatics with expertise in the field of data science, analytics.
MS genetics or plant breeding or animal breeding or bioinformatics with 2 years of experience in breeding data management and analytics
Working expertise in programming language is desirable
Handling of genetic marker data, large phenotypic data, haplotype database will be added advantage
Proven program management skill is desirable
Ability to work in a matrix environment, influencing people at varying levels of responsibility, collaborating effectively in interdisciplinary teams
Ability to deliver innovative and creative solutions to complex problems.

Salary: Not Disclosed by Recruiter

Industry:Agriculture / Dairy

Functional Area:Other

Keyskills
genetics
data analytics
haplotype database
bioinformatics
phenotypic data
pipeline breeding
BLUP
plant breeding
digital advancement pipeline
GBLUP
genetic marker data
breeding
Desired Candidate Profile
Please refer to the Job description above

Education-

UG:B.Sc - Agriculture

PG:MS/M.Sc(Science) - Any Specialization, Agriculture, Biotechnology, Data Informatics

Doctorate:Ph.D - Agriculture, Bio-Chemistry/Bio-Technology, Other, Biotechnology

Company Profile

Bayer Group

Bayer CropScience Ltd.",3.5,"Bayer Group
3.5",Bengaluru,"Las Vegas, NV",201 to 500 employees,-1,Company - Public,Vehicle Dealers,Retail,₹5 to ₹10 billion (INR),-1
171,Data Scientist,"5+ years of experience in software development of large-scale data infrastructure and distributed systems
5+ years of experience in data extraction, transformation, statistical analysis and data modeling
5+ years of experience developing enterprise software using Java or Python
3+ years of experience in applying Data Mining and Machine Learning techniques to solve business problems
3+ years of experience using major RDBMS, Hadoop, Spark, Elasticsearch, or similar technologies
3+ years of experience with statistical modeling tools such as R, SAS, SciKit-learn, or TensorFlow
Bachelor’s degree in Computer Science, Computer Engineering, Machine Learning, or related field or equivalent experience.
Amazon strives to be Earth's most customer-centric company where people can find and discover anything they want to buy online. We hire the world's brightest minds, offering them a fast paced, technologically sophisticated, and friendly work environment.

The FinAuto Data Engineering and Analytics team, part of Finance Automation Org focuses on the application of machine learning methods designed to enable Amazon to increase free cash flow by optimizing spend, expense, payroll defects. All of this work is performed in close coordination with senior business leaders. These are exciting fast-paced businesses in which we get to work on extremely interesting analytical problems, in an environment where you get to learn from other data engineers and apply econometric, statistics, and machine learning at massive scale.
As a member of the FinAuto Data Engineering and Analytics team, you will partner closely with a team of stake holders, payment teams, data engineers and software engineers.

In this role you will:
Work with data engineers to design and implement machine learning applications and solutions.
Implement and maintain a high-volume, highly available, hybrid (SQL + No SQL) data processing solutions that consists of structured and semi-structured data.
Design and implement a very large distributed data warehousing and reporting solution and integrate it with business intelligence tools
Master’s degree in Computer Science, Computer Engineering, Machine Learning, or related field; PhD a plus
Deep expertise in Statistics, Machine Learning or related disciplines
Advanced knowledge in performance, scalability, numerical accuracy, enterprise system architecture, best practices.
Experience building solutions using AWS big data and machine learning services
Ability to communicate complex technical concepts and solutions to all levels of the organization",-1,Amazon Dev Center India - Hyd,Hyderabad,-1,-1,-1,-1,-1,-1,-1,-1
172,Data Scientist,"5+ years of experience in software development of large-scale data infrastructure and distributed systems
5+ years of experience in data extraction, transformation, statistical analysis and data modeling
5+ years of experience developing enterprise software using Java or Python
3+ years of experience in applying Data Mining and Machine Learning techniques to solve business problems
3+ years of experience using major RDBMS, Hadoop, Spark, Elasticsearch, or similar technologies
3+ years of experience with statistical modeling tools such as R, SAS, SciKit-learn, or TensorFlow
Bachelor’s degree in Computer Science, Computer Engineering, Machine Learning, or related field or equivalent experience.
Amazon strives to be Earth's most customer-centric company where people can find and discover anything they want to buy online. We hire the world's brightest minds, offering them a fast paced, technologically sophisticated, and friendly work environment.

The FinAuto Data Engineering and Analytics team, part of Finance Automation Org focuses on the application of machine learning methods designed to enable Amazon to increase free cash flow by optimizing spend, expense, payroll defects. All of this work is performed in close coordination with senior business leaders. These are exciting fast-paced businesses in which we get to work on extremely interesting analytical problems, in an environment where you get to learn from other data engineers and apply econometric, statistics, and machine learning at massive scale.
As a member of the FinAuto Data Engineering and Analytics team, you will partner closely with a team of stake holders, payment teams, data engineers and software engineers.

In this role you will:
Work with data engineers to design and implement machine learning applications and solutions.
Implement and maintain a high-volume, highly available, hybrid (SQL + No SQL) data processing solutions that consists of structured and semi-structured data.
Design and implement a very large distributed data warehousing and reporting solution and integrate it with business intelligence tools
Master’s degree in Computer Science, Computer Engineering, Machine Learning, or related field; PhD a plus
Deep expertise in Statistics, Machine Learning or related disciplines
Advanced knowledge in performance, scalability, numerical accuracy, enterprise system architecture, best practices.
Experience building solutions using AWS big data and machine learning services
Ability to communicate complex technical concepts and solutions to all levels of the organization",-1,Amazon Dev Center India - Hyd,Hyderabad,-1,-1,-1,-1,-1,-1,-1,-1
173,Data Scientist,"Role Summary/Purpose:
The Data Scientist will work in teams addressing statistical, machine learning and data understanding problems in a commercial technology and consultancy development environment. In this role, they will contribute to the development and deployment of modern machine learning, operational research, semantic analysis, and statistical methods for finding structure in large data sets.

Essential Responsibilities:
The Data Scientist will be part of a data science or cross-disciplinary team, typically including statisticians, computer scientists, software developers, engineers, product managers, and end users, working in concert with partners in BH. Potential application areas include remote monitoring and diagnostics across infrastructure and industrial sectors, and business operations optimization. The data scientist will lead engagements with internal/external customers, and develop analytics within defined business objectives to address customer needs and opportunities. The work will involve a range of activities, including but not limited to:

Working with business stakeholders to understand the business problem/requirements and helping define analytic objectives
Forming hypotheses, exploratory data analysis, generating insights and validating the hypothesis,
Working with engineering teams to incorporate analyses and solutions, including working with data engineers on data quality assessment, data cleansing and data analytics efforts, and visualization team on representing results
Developing re-usable components that can be applied to similar problem classes across contexts

Qualifications/Requirements:
Bachelor's Degree in a STEM major (Science, Technology, Engineering, Mathematics)
Minimum 8 years analytics development in a commercial setting
Demonstrated skill in the use of one or more analytic software tools or languages (e.g., R, Python)
Demonstrated skill at data cleansing, data quality assessment, and using analytics for data assessment
Demonstrated skill in the use of applied analytics, descriptive statistics, and predictive analytics on industrial datasets
Demonstrated skill in modeling techniques, including but not limited to Predictive modeling, Supervised learning, Unsupervised learning, Machine Learning, Statistical Modeling
Demonstrated skill in analytic prototyping, analytic scaling, and solutions integration
Strong communication & visualization skills to help stakeholders define requirements, and explaining data science outcomes to non-expert audiences
Generating insights for a business context

Desired:
Experience with cloud technologies for building, deploying and delivering data science applications.
Experience in building digital twin and analysing stream data is a plus.
Must have strong product intuition, data analysis skills and business presentation skills.
Must be a self-starter and a great team player with excellent interpersonal skills.

Location:
Bangalore, India

Baker Hughes Company is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law.",3.5,"Baker Hughes
3.5",Bengaluru,"Houston, TX",10000+ employees,-1,Company - Public,Oil & Gas Services,"Oil, Gas, Energy & Utilities",₹500+ billion (INR),-1
174,Data Scientist,"About Dasceq
Dasceq is transforming collection industry in USA using AI/ML and Big Data. We are focused to build a best in class Collection AI SaaS Product and have already established our product for $320billion Auto and Short Term Industry. We are expanding our team and looking for next generations data scientist with experience to lead high end AI Product Development. We don’t do lip service and we are committed to solve a $1.6 Trillion collection problem and looking to expand our amazing Data Science team. If you would like to build something high end and push boundaries contact us today!

Job codes: DASDS1

Qualifications :
Masters in Data Science ; Econometrics ; Statistics ; Math; Computer Science preferred with 2 to 3 years experience in Product Experience or Financial Services Experience or Marketing Modelling

Preferred Institutes:
ISI; Delhi School of Economics ; Madras School of Economics; Calcutta University; IITs/ IISc/ NIT’s – Relevant Tier 1 Colleges or Top Tier 2 colleges

Job Description :
The prospective hire would be part of a data Science Implementation team and be able to support independently client requirements, historical retro scoring, benefit analysis and other core financial lending and collections ; Knowledge of product development and implementation is a must for the role

Pay:
As per experience and market standards

Apply at: ritu@dasceq.com

Please send: Latest resume with current Salary and Bonus components mentioned",2.0,"Dasceq
2.0",India,"Irving, TX",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
175,Data Scientist,"Experience : 2+ years

What will you do:
Should have working knowledge of relational Database designs (SQL Server, MySQL, Oracle).
Should have knowledge of Queue management systems (Redis, MSMQ, RabitMQ etc).
Should have knowledge of SQL query, Stored Procedures, Functions.
Should have knowledge of No SQL will be an added advantage.
Shall analyze, define and document system requirements for data, workflow, logical processes, interfaces with other systems, auditing, reporting requirements and production configuration.
Shall write and maintain functional and technical specifications.
Shall create scripts and packages for data integration, data maintenance or bug fixes.
Shall analyze code for problem resolution and performance optimizations.
Shall write SQL statement for ad-hoc report generation.

What we can offer

Are a young organization and the workplace is an extension of our families back home
Mondays and Fridays have the same effect on us
Value positive vibes, honesty, sense of judgment, empathy and self-motivation
Believe in experimentation and don't think of new things as daunting enough to take up at any point in time
Are looking for driven and focused individuals
Will be more than happy to hear from you

We want to hear from you
Why don't go ahead and send us a video clip of yourself, giving us a creative brief of who you really are.Once you're done with that, [email protected] :).",-1,big tree,Mumbai,"Großostheim, Germany",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
176,"Data Scientist[ Image Processing, Computer Vision,tensorRT,keras]","Job Description
Job Description

Need Data Scientist - for our Fortune Wireless Ecosystem, who can contribute in Image Processing & Neural Network domain
NOTE:
Need someone who can join within 30 days.
Work Location: Magarpatta,Pune


Essential Requirements

5+ years of experience in understanding the problem statement, data handling/triage, selecting and improving neural network models using deep learning frameworks to solve business problems
Thorough understanding and experience of DL/AI/ML lifecycle - full neural network pipeline, starting from data collection to model building to experimental framework to data analytics
Developed/optimized various models in image domain
Computer Vision - Experience with object detection, tracking, classification, recognition using deep neural network
Hands on experience of popular frameworks (Tensorflow, Keras, MxNet, Caffe. CNTK, Theano / Pytorch, python), their strength and applicable AI use-cases.
Experience in design and developing deep neural networks for large datasets
Proven record of improving current models for accuracy and speed for specific use case
Good to have
Published research papers on neural network
PhD/Masters in DL/ML/AI domain.
Demonstrated prowess in ML in public competitions: Kaggle or participation at other worldwide competitions, etc
GitHub code repository
To book your appointment, please call 9898791075.

Perks and Benefits

Training/certifications + 5 Days + Other Fringe Benefits

Salary: Not Disclosed by Recruiter
Keyskills
PytorchTensorflowObject DetectionArtificial IntelligenceNeural NetworksCaffeKerasComputer VisionDeep LearningPython
Desired Candidate Profile
Please refer to the Job description above

Education-

UG:B.Sc - Computers, B.Tech/B.E. - Computers

PG:MS/M.Sc(Science) - Any Specialization, Computers, MCA - Computers, M.Tech - Computers

Doctorate:Ph.D - Computers, Doctorate Not Required
Company Profile
eInfochips Limited
eInfochips, an Arrow company, is a leading global provider of product engineering and semiconductor design services. With over 500+ products developed and 40M deployments in 140 countries, eInfochips continues to fuel technological innovations in multiple verticals. The company€™s service offerings include digital transformation and connected IoT solutions across various cloud platforms, including AWS and Azure.

Along with Arrow€™s $27B in revenues, 19,000 employees, and 345 locations serving over 80 countries, eInfochips is primed to accelerate connected products innovation for 150,000+ global clients. eInfochips acts as a catalyst to Arrow€™s Sensor-to-Sunset initiative and offers complete edge-to-cloud capabilities for its clients through Arrow Connect.
View Contact Details+
Recruiter Name:Einfochips Talent Acquisition

Contact Company:eInfochips Limited

Website:https://www.einfochips.com",3.4,"Einfochips
3.4",Pune,"Ahmadabad, India",1001 to 5000 employees,1994,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
177,Data Scientist,"We are hiring for Data Scientist/Data Engineer/Data processor
Candidate must have worked on large set of data.
Candidate must have worked on either scala/python and used apache,spark
Thanks & Regards
Sandeep Kaur
HR Executive
9877730843
Job Type: Full-time
Experience:
4: 1 year (Preferred)",-1,spineor webservices Pvt Ltd Mohali,SAS Nagar,-1,-1,-1,-1,-1,-1,-1,-1
178,Data Scientist II,"Position Title
Data Scientist II

04-Jun-2020

Job ID
294694BR

Job Description
Understand complex and critical business problems from Country/Regional/Global business functions, formulate integrated analytical approach to mine data sources, employ statistical methods and machine learning algorithms to discover actionable insights and automate process for reducing effort and time for repeated use. Able to use business presentations, smart visualization tools and contextual story-telling to translate findings back to business users with a clear impact on ROI Through strong subject matter expertise and role modelling skills, guide the Business Analytics team in Hyderabad to enable delivery of analytical insights to the commercial stakeholders worldwide. Coach and mentor aspirant SMEs in Business Analytics team at Hyderabad in line with Novartis people development requirements and Novartis Values and Behaviours. No direct team management.

• Provide solutions for a variety of business applications including but not limited to: Customer Segmentation & Targeting, Event Prediction, Propensity Modelling, Churn Modelling, Customer Lifetime Value Estimation, Forecasting, Recommender Systems, Modelling Response to Incentives, Marketing Mix Optimization, Price Optimization • Develop automation for repeatedly refreshing analysis and generating insights. • Collaborates with globally dispersed internal stakeholders and cross-functional teams to solve critical business problems, drive operational efficiencies, and deliver successfully on high visibility strategic initiatives • Understands commercial data sources including sales, contracting, promotions, social media, patient claims and Real World Evidence • Makes right choices from a breadth of tools, data sources and analytical techniques to answer a wide range of critical business questions • Articulates solutions/recommendations to business users. Presents analytical content concisely and effectively to non-technical audiences and influences non-analytical business leaders to drive major strategic decisions basis analytical inputs • Project manages critical initiatives: plans proactively, anticipates and actively manages change, sets stakeholder expectations as required, identifies operational risks and independently drives issues to resolution, balances multiple priorities and minimizes surprise escalations • Works closely with MES Function Head, Business Analytics Group Head and Regional Account Directors to shape strategy and build capability (including hiring and training) for advanced analytics delivery • Works with other teams (Forecasting, Sales Force Effectiveness, Pricing and Access etc.) at PLS Hyderabad to leverage cross-functional learnings and synergies • Ensures exemplary communication with all stakeholders including internal PLS associates and senior business leaders across Novartis • Acts as an evangelist and catalyst for innovation in BI & Analytics • Grooms Subject Matter Experts, and mentors associates for higher responsibilities. Identifies learning needs for analyst teams and plans for training implementation in alignment with training manager to expand NGSC capabilities • Identifies key skill requirements for the Business Analytics team and facilitates design and content creation for knowledge repositories and training material

Minimum requirements
Graduate or Post-graduate or Ph.D. in any quantitative discipline, e.g. Statistics, Applied Mathematics, Econometrics, Computer Science, Engineering, Operations Research. MBA preferred English • 8+ years of hands-on experience in analytics. Experience with a leading pharma or service provider highly desirable • Extensive experience in Statistical and Machine Learning techniques like Regression (Linear/Logit/Gamma), Clustering (K-Means/Modes/Hier), Decision Trees, Text Mining and Natural Language Processing, Stochastic models, Bayesian Models, Markov Chains, Monte Carlo Simulations, Non-linear Time Series, Dynamic Programming and Optimization techniques,Design of Experiments, Neural Networks, Statistical Inference,Collaborative Filtering, Feature Engineering, etc. • Extensive experience in working with large-scale datasets (in bigdata architecture, data lake, data mart, data warehouse). Demonstrateduse of analytical packages and query languages such as SAS, R, SQL,SPSS, Matlab, Alteryx • Experience in Big Data platforms like Hadoop eco-system (i.e. Hive, Pig, Sqoop, Mahout), other large scale computing systems (e.g. COSMOS,MapReduce) or modern coding languages

Job Type
Full Time

Country
India

Work Location
Hyderabad, AP

Functional Area
BD&L & Strategic Planning

Division
NBS

Business Unit
PLS NBS

Employment Type
Regular

Company/Legal Entity
Nov Hltcr Shared Services Ind

Shift Work
No",3.9,"Novartis
3.9",Hyderabad,"Basel, Switzerland",10000+ employees,1996,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
179,Data Scientists,"CAREERS

Data Scientists

Bengaluru, India
JOB DESCRIPTION

As a Data Scientist with Tredence, you will play a key role in translating data into insights for our clients. You will design, develop and implement processes and framework that will help our clients make sense of the data they generate, and consume the insights to make informed decisions.
THE IDEAL CANDIDATE WILL

Have the ability to handle structured /unstructured data and have prior experience in loading, validating and cleaning various types of data.
Have very good understanding of data structures and algorithms.
Have excellent coding skills in one or more of the following languages: Python, Java, C++ or R
Have thorough understanding of one or more of the following: Machine Learning algorithms, Natural Language Processing techniques, and Information Retrieval techniques
Have the ability to apply these algorithms in a professional setting.
Be accountable for measuring and optimizing the quality of algorithms.
Have good background in Math and Statistics.
Have ability to identify opportunities where data science techniques can be applied to solve business problems.
Take ownership of the end to end system from Problem statement to Solution Delivery
Preferred Skills
Experience working with Hadoop/AzureML/Hive/H2O would be an added advantage.
Experience with deep learning techniques like Theano, Torch and TensorFlow is preferred.
ELIGIBILITY CRITERIA

BE/B. Tech/MS degree in Computer Science or related quantitative field with 2-8 years or relevant experience in a team building world class applications in the areas of Predictive Analytics and Data Science.
Send your CV to careers@tredence.com",3.5,"Tredence
3.5",Bengaluru,"San Jose, CA",501 to 1000 employees,2013,Company - Private,Consulting,Business Services,₹1 to ₹5 billion (INR),-1
180,Data Scientist,"Data Scientist Responsibilities:
Having meetings with team members regarding projects.
Collecting and interpreting data.
Automating and integrating processes.
Researching solutions to overcome data analytics challenges.
Developing complex mathematical models that integrate business rules and requirements.
Creating machine learning models.
Communicating and meeting with engineers, IT teams and other interested parties.
Sharing complex ideas verbally and visually in an understandable manner with non-technical stakeholders.
Data Scientist Requirements:
A MSc or PhD degree in Applied Mathematics or Statistics.
5+ years industry experience.
Advanced coursework in machine learning and programming.
Experience using data visualization tools.
Experience with data querying languages, and statistical or mathematical software.
Proficient in writing algorithms, and knowing when to apply them.
Excellent understanding of statistics, multi-variable calculus and linear algebra.
Outstanding communication skills.
Job Type: Full-time

Salary: ₹347,000.00 to ₹708,000.00 /year

Experience:
work: 5 years (Preferred)
Data Scientist: 5 years (Preferred)
Education:
Bachelor's (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,Futurious Technologies,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
181,Data Scientist,"Perform data-mining, modeling and hypothesis generation in support of high-level business goals.
Stay current with emerging tools and techniques in machine learning, statistical modeling & analytics.
Strong aptitudes for business, technology, mathematics & statistics.
Need strong oral & written communication skills to present data as a concise story for diverse audiences.
Develop customized algorithms to solve analytical problems with incomplete data sets.

Skills Needed:
R/Python Programming

SQL

Statistical Modeling

Machine Learning Techniques

Knowledge on Software Development is an added advantage",2.5,"BrandIdea Consultancy P Ltd
2.5",Chennai,"Mumbai, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
182,Data Scientist,"Responsibilities
¢¢ Work closely with business partners and engagement managers to translate complex business
problems into analytics problems and solutions. Ask questions to understand business intent,
problem statement, analytics opportunity and value creation.
¢¢ Work closely with data engineering team to identify and consume relevant structured and
unstructured data sources (including IoT sources such as manufacturing sensors systems).
¢¢ Identify key hypotheses and data science approaches to answering analytics problems and getting
to business outcomes.
¢¢ Develop statistical and machine learning models/algorithms through iterative process and rapid
prototyping.

Qualifications
¢¢ A master¢¢s degree in data science, predictive analytics, computer science, applied mathematics,
statistics, software engineering, physics, or related quantitative discipline.

¢¢ 5+ years of hands-on experience in machine learning and statistical modelling, including a
demonstrated high-level of proficiency in applying data science techniques to solving customer
problems.
¢¢ High proficiency in conducting analyses using tools like Python, R and data visualization tools (e.g.
Tableau, Power BI, Qlik, Ploty) .
¢¢ Rigorous understanding of the fundamentals of statistics, machine learning and artificial
intelligence using both structured and unstructured data sets.
¢¢ Experience in presenting complex analytics methodologies, analyses and insights in simple and
concise manner to the business partners and senior leaders.

We Value
¢¢ A PhD degree and/or additional relevant industry certifications (in analytics, software platforms,
cloud environments, etc.).
¢¢ Experience in analytics solutions in industrial and/or manufacturing domains.
¢¢ Experience moving prototypes to production environment and optimizing models in production
environment.
¢¢ Experience mentoring business analysts and other data scientists.
¢¢ Exposure to distributed computing frameworks as well as cloud technologies.
Keyskills
predictive modelling
r
python
data science
data modelling
predictive analytics
machine learning
ML
Desired Candidate Profile
Please refer to the Job description above
Company Profile

Cerentral Consultants Pvt Ltd

Technology company that designs and manufactures connectivity and sensor products for harsh environments in a variety of industries, such as automotive, industrial equipment, data communication systems, aerospace, defense, medical, oil and gas, consumer electronics and energy.

It has a global workforce of 80,000 employees, including more than 8,000 engineers. The company serves customers in approximately 140 countries.
Experience 5 - 10 Years",-1,Cerentral Consultants,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
183,Data Scientist (Machine Learning),"Qualification : MCA or Bachelor's Degree in Computer Science, Information Technology, Engineering or a related field.

Key skill requirements are

Total experience - 2-4 years of experience
Excel , Machine Learning , Predictive Modeling , Python , R

2-4 years experience of building and deploying Machine Learning models, preferably in internet industry

Sound knowledge of R, Python and different data mining tools (Advanced Excel, MySQL,SQL etc.)

Deep knowledge of various predictive modeling and machine learning algorithms and underlying Maths and Stats behind them.

Bachelors / Masters degree / in CS/IT/Mathematics/Statistics.

Strong analytical, numerical, interpersonal skills and business acumen.
Forward your CV at esconinfosystems@gmail.com",-1,Escon Info Systems,Barabanki,"Lucknow, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
184,Applied Data Scientist,"dunnhumby is looking for a talented Applied Data Scientist!

You will execute projects to distil complex problems into compelling insights that resonate with clients, using the best of dunnhumby science.

What you'll be doing:
Build strong relationships with immediate internal contacts and direct external client to ensure full understanding of client requirements, ensuring clear and effective communication.
Investigate and implement the most appropriate analytical technique for each project, re-using and further developing global solutions or code written by others.
Deploy data science algorithms and market products on chosen tech stack for efficient and cost-effective delivery.
Execute projects that distil complex problems into compelling insights that resonate with clients.
Participate, as required, in client meetings to help explain the proposed methodology and solutions.
Document learnings after deploying solutions for a client to increase the existing knowledge repository.
Ensure smooth running of your projects, working with senior team members for direction.
Follow dunnhumby Quality Assurance processes, ways of working and meet coding standards.
Implement advice from colleagues to resolve challenges.
Who you’ll get to work with:

Within dunnhumby you’ll work with
Applied and Research Data Scientist teams
Client / Commercial teams
Global Capability teams
Data Science Engineering teams
Externally, you’ll frequently be in contact with:
Senior Retail/Customer Packaged Goods Analysts and Insights contacts
What you'll need:
Bachelor’s degree or equivalent in Computer Science, Artificial Intelligence, Machine Learning, Applied Statistics, Physics, Engineering or related field.
Experience with and passion for connecting your work directly to the customer experience, making a real and tangible impact.
Some experience with programming, and the ability to quickly pick up handling large data volumes with modern data processing tools, e.g. by using Hadoop / Spark / SQL / Python.
Analytical Techniques
Analytical Technology
Desk Research
Prototyping
Quality Assurance and Testing
Statistical Modelling
Programming (Python, SQL, R, …)
Data Interpretation/ Insight Analysis
Data Visualisation
Insight Storytelling
Client relationship building and management
Presentation skills
A plus if you also have:
Master’s degree or equivalent in in Computer Science, Artificial Intelligence, Machine Learning, Applied Statistics, Physics, Engineering or related field.
Programming experience on any standard data mining and modelling packages such as Python and R.",3.6,"dunnhumby
3.6",Gurgaon,"Hammersmith, United Kingdom",1001 to 5000 employees,1989,Company - Private,Consulting,Business Services,₹50 to ₹100 billion (INR),-1
185,Senior Data Engineer/Data Analyst,"data science tools and techniques including python, machine learning and data visualization.

Build and own the enterprise data sets.

Who You’ll Work With


In this role you will be collaborating closely with Engineering, CX, Finance, Sales and IT groups.

Who You Are


You've got experience with identifying a business problem and solving it through data driven insights.

Experience in building requirements to improve data gathering for analytic purposes.

Got experience to Perform, Support and Lead all aspects of Data Engineering strategy, Data Warehousing, Data Integration and Report, ETL/ELT builds, and the Data Visualization.

Highly motivated, a self-starter and able to work in a fast-paced environment.

You are a creative problem solver and highly collaborative teammate who is comfortable working as a SME and key contributor on a matrixed team and able to navigate many cross-flow dependencies and diverse partner groups

Minimum Qualifications


BS/MS or equivalent (Sophisticated degree preferred)

10+ years of full-time data engineering/analytics experience.

Should have a very good hands on experience in working with BigData Platforms, ETL/ELT technologies, Cloud DB platforms (Snowflake), Informatica, SQL for Data Engineering and Data Science, and Python.

Able to take a concept or an idea and work through the different stages all the way to the execution and outcome.

Superb analytical thinking and aptitude.

Experience leading Data Engineering/Data Migration projects.

Customer Success, Customer Experience, Product Telemetry, Finance domain knowledge preferred.

Familiarity with advance analytics and machine learning topics.

Solid grasp in Tableau or similar data analytics and presentation tools.

Should have experience in storytelling with data in form of visuals.

Certification in Data Engineering/Data Science is a plus.

Good written and verbal communication skills, and comfortable presenting findings to executive level audience and translating data into understandable documents.

Why you'll love Cisco


We change the World, you will become passionate about your employer and the brand you represent. Everything is converging on the Internet, making networked connections more meaningful than ever before in our lives. Our employees' groundbreaking ideas impact everything. Here, that means we take creative ideas from the drawing board to dynamic solutions that have real world impact. You'll collaborate with Cisco leaders, partner with mentors, and develop incredible relationships with colleagues who",4.3,"Cisco Systems
4.3",Bengaluru,"San Jose, CA",10000+ employees,1984,Company - Private,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Alcatel-Lucent, Juniper Networks"
186,Data Scientist DA4AD,"Responsibilities
Selecting features, building and optimizing classifiers using machine learning and Deep Learning techniques
Data mining using state-of-the-art methods
Extending company’s data with third party sources of information when needed
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance

Skills
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, CNNs, etc.
Very good experience with common data science toolkits of Python like numpy, pandas, pyTorch. Excellence in at least one of these is highly desirable
Great communication skills
Experience with data visualisation tools like matplotlib, Tableau
Proficiency in using query languages such as SQL
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Data-oriented personality

Responsibilities
Selecting features, building and optimizing classifiers using machine learning and Deep Learning techniques
Data mining using state-of-the-art methods
Extending company’s data with third party sources of information when needed
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance

Skills
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, CNNs, etc.
Very good experience with common data science toolkits of Python like numpy, pandas, pyTorch. Excellence in at least one of these is highly desirable
Great communication skills
Experience with data visualisation tools like matplotlib, Tableau
Proficiency in using query languages such as SQL
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Data-oriented personality",3.5,"Mercedes-Benz Research and Development India Private Limited
3.5",Bengaluru,"Chakan, India",1001 to 5000 employees,1996,Company - Private,IT Services,Information Technology,₹10 to ₹50 billion (INR),"Volkswagen, Tata Motors"
187,ML Engineer/Statistician/Data Scientist – Pre-IPO Unicorn,"As a Data Scientist / ML specialist you will focus on building next-generation platform services to identify right business problems that will be more effectively solved with Machine Learning techniques

Then you will apply your algorithmic/statistical skills, analytical skills, knowledge of ML techniques and distributed systems to solve the problem in the simplest possible way.

Experience

3 to 12 years

Qualification

A Bachelor’s degree or a higher degree in Computer Science, Statistics, Mathematics or a related field.
A strong grounding in Data structures and algorithms, Database concepts
Solid understanding of mathematical underpinnings behind Machine Learning algorithms and proficiency in probability, statistics, linear algebra, calculus, and optimization.
Prior experience in building and deploying ML systems and familiarity with Machine learning algorithms
Experience with NLP, Distributed Systems, large scale computing, Big Data technologies like Hadoop and Spark are plus.

Responsibilities

Collaborate with product and business teams to understand all aspects of the problem
Deliver scalable, low latency, and high-performance ML solutions for different
Apply knowledge of ML, statistics, and advanced mathematics to conceptualize, experiment and design an intelligent system
Drive solutions and implementation leveraging different open source libraries and distributed systems
Work with engineers to build the system end-to-end including Big Data pipelines and ensure the serving system is scalable and highly performant.

We value intellectual curiosity, open communication and creative thinkers who know how to stand up and be counted. If this sounds like who you are, we should talk.

Write to deepa.m@careerxperts.com to set up this adventure! #HighBarOfEntry

Job Location

Bengaluru",-1,CareerXperts,Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
188,Data Engineer,"Do you want to define the future of Internet commerce?
Are you a top-notch software engineer with a creative flare, strong problem-solving skills, the drive to build and ship products often, a solid computer science foundation, and the desire to build Amazon's next generation Internet-facing technology? Come talk with us about joining our team to help our tax teams serve customers better.
Is your next project defining a world class Internet service?
With us, you will be building cutting-edge applications and services in an environment of highly distributed systems used by Amazon Tax teams. Your innovation will provide new functionality for millions of vendors/payees globally with a goal of making it easy to comply with tax regulations.
Are you ready to create systems to expand one of the worlds largest e-commerce engines?
If so, come be a member of Amazons Taskless Technology team. Taskless Tech builds software systems that ensure compliance for Amazon businesses and its subsidiaries and makes it easy for for millions of Amazon vendors including publishers, app developers, game developers, marketplace sellers, associates and others to comply for tens of billions of dollars in transactions. We're constantly looking for opportunities to expand capabilities in new geographies and new lines of business.
Can you work at the scale of the biggest Internet companies?
The solutions that you will deploy must scale to accommodate rapid processing and integration with large enterprise customers. However, to add to the challenge, the solutions must also support intuitive world class UI for Amazon Tax teams to pay millions of vendors.
Amazon is a premier place to build, deploy and operate Internet-scale services.
Join our development team to work hard, have fun and make history. You will join a highly technical and entrepreneurial culture defining and building a selling experience to complement Amazons world-class websites.



Basic Qualifications

· Strong problem solving skills
· Strong coding skills
· Passion for building scalable, global, complex systems to solve problems with proven ability to deliver high quality software.
· Solid understanding of Object-Oriented design and concepts.
· Innovative and creative with Web technologies to build high performing websites and web services.
· Demonstrated proficiency with AJAX, Javascript, CSS is a plus.

Preferred Qualifications

· BS or MS in Computer Science or in a relevant Engineering discipline.
· 5+ years of industry experience
· Strong analytical thinker who knows how to pick the right tool for the job
· Knowledge of professional software engineering practices & best practices for the full software development life cycle, including
· Agile methodologies, coding standards, code reviews, source control management, build processes, testing, and operations
· Ability to communicate clearly and concisely with technical and non-technical customers in order to understand ambiguous problems and articulate technical designs and solutions to complex problem",4.2,"Amazon
4.2",Gurgaon,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
189,Lead Data Scientist,"Data Scientist role @ ThoughtWorks India

Gurgaon, India

We are passionate technologists who believe in the power of software and technology as tools for social change. The 1000+ people in ThoughtWorks India are as diverse in personality as we are in our backgrounds, culture, and expertise.

If you're someone who's passionate about technology, by joining ThoughtWorks, you become a part of a community. People join because they get to talk to the people who wrote the books that influenced them, work with tools they wish to use, and collaborate on projects that propel change in the real world.

ThoughtWorks India is looking for talented Data scientists passionate about building large scale Machine Learning Solutions to help manage the ever-growing information needs of our clients.

As a Data Scientist Practitioner, here's what you can do at ThoughtWorks:
Understand business challenges and goals of a client to formulate the approach for data analysis and model creation that will support their business decision making
Create advanced analytics models using statistical and machine learning methods
Work with software developers and solutions designers to deliver analytics-driven solutions
Interact with clients in a variety of domains, who have a spectrum of challenging problems
Represent ThoughtWorks and Data community in various online and offline forums (events, conferences)
Work in a dynamic, collaborative, transparent, non-hierarchical, and ego-free culture where your talent is valued over a role title
Develop your career outside of the confinements of a traditional career path by focusing on what you're passionate about rather than a predetermined one-size-fits-all plan
Here is what you will bring:
PhD/MS/BS or equivalent in Applied mathematics, statistics, physics, computer science or operations research background.
At least 2-3 years commercial experience with PhD or at least 8+ years of experience with MS/BS degree
Depth of knowledge in advanced analytics methods such as parametric, non-parametric and graphical models
Breadth of knowledge across statistical methods and machine learning algorithms
Programming skills in languages like R and Python is a MUST
Familiarity with large scale data processing tools like Hadoop and Spark
Strong algorithmic problem-solving skills
Ability to design effective experiments in business and social environments
Understand how to harvest complex data from a variety of sources
Consultative skills and the ability to communicate complicated technical and analytical information to non technical audiences
Other desirable skills include: relational databases, NoSQL and visualisation techniques, knowledge and experience in any software technologies along with research experience
If you relish the idea of being part of ThoughtWorks' Data Practice that extends beyond the work we do for our customers, you may find ThoughtWorks is the right place for you. If you share our passion for technology and want to help change the world with software, we want to hear from you!

#LI-INDIA

#LI- RP1",4.3,"ThoughtWorks
4.3",Gurgaon,"Chicago, IL",5001 to 10000 employees,1993,Company - Private,IT Services,Information Technology,₹10 to ₹50 billion (INR),"Accenture, Infosys, Boston Consulting Group"
190,Applied Scientist 1,"Amazon Selling Partner Services team drives the Selling On Amazon business and develops solutions that enable millions of sellers around the world to sell on Amazon's Marketplaces. More than half of shipments for Amazon customers are generated from this business. The team is focused on building a technology platform that will support the explosive business growth in existing markets, streamline the business for Amazon and the Selling partners and launch business in new markets and establish a fair marketplace.

Our team is seeking engineers with broad technical skills to help us optimize how we synthesize massive amounts of data and complex business rules into mission critical financial information. As a member of this team you will employ object oriented techniques in Java, and DynamoB, PostGres and ElasticSearch skills to help us support Amazon's next generation of selling partner services. Along the way you'll gain and leverage a unique understanding of how Amazon.com works; from the numerous software systems that comprise the website's back-end, to the details of our business model, and the relationships we're establishing with an ever-growing network of selling partners who depend on Amazon.com to run their businesses.

The ideal candidate will draw upon exemplary analytical, critical thinking, and problem solving skills, and a passion for maintaining highly reliable, distributed systems which operate 24/7/365. Successful members of this team collaborate effectively with internal end-users, aggressive cross-functional software development teams, and technical support/sustaining engineering teams to solve problems and deliver successfully against high operational standards of system availability and reliability. We look for engineers who are excellent communicators, self-motivated, flexible, hardworking, and who like to have fun!

Position Responsibilities:

Participate in the design, development, implementation, testing and documentation of large-scale, multi-tiered, distributed software applications, tools, systems and services using [Java, Object Oriented Design and Distributed Programming]. Translate functional requirements into robust, scalable, supportable solutions that work well within the overall system architecture. Participate in the full development cycle, end-to-end, from design, implementation, and testing to documentation, delivery and maintenance. Produce comprehensive, usable software documentation. Evaluate and make decisions around the use of new or existing software products and tools.


Basic Qualifications

Position Requirements:

Master's degree in Computer Science, Computer or Electrical Engineer, Mathematics, or a related field plus at least one year of experience in the job offered or related occupations of Software Engineer, Software Developer, or a related occupation. Employer will accept a Bachelors degree and five years of experience in the job offered or a related occupation as equivalent to the Masters degree and one year of experience. One year of experience in the job offered or related occupation must involve designing and developing large-scale, multi-tiered, distributed software applications, tools, systems and services using Java, Object Oriented Design and Distributed Programming].

Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, Oracle/Berkeley databases, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills


Preferred Qualifications

Preferred Qualifications
Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills",4.2,"Amazon
4.2",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
191,Data Scientist - Sr. Analyst,"Profile Required

Deliver and complete KRI activities and tasks related to assigned process with expected quality and timeliness. Monitoring and tracking on Operation KRI process handling additional ad hoc responsibilities i.e., updating SOP’s, taking cross trainings, PDP’s, completion of controls with in agree timelines etc.

· Work on projects and process improvements which will lead to better efficiency of implemented controls, Automation of dashboards to meet the changing needs of the BL. Collaborates with peers, Lead, Supervisor, stakeholders to implement system/process improvements.

· Analytical - Ability to analyze data sets for irregularities. Uses intuition and experience to complement data;

· Work with business unit to understand business, concerns, future plans and offer support to mitigate risk.

· Being Proactive in resolving cases rather than reactive.

· Individuals work directly with data and information, creating meaningful analyses, reports and management presentations in support of client, business unit or function activities and performance. Types of analysis and reporting may include: quality review, workflow analysis, process improvement, regular business or client reporting, budget management, financial reporting and/or a variety of other function specific purposes.

· Advanced knowledge on Reporting tools, Dashboard KRI,KPI creation, Advance Excel, VBA, Macro. Skilled knowledge on the Technical and functional aspect of the process

· Level of Autonomy - Problem Solving, Take Ownership, Client Focus

· Delivers Production with no assistance of SME, is independent in performing all the tasks. Maintains 100% quality and adheres to all timelines.

Competencies

· Excellent command of English, solid writing and oral presentation skills

· Self motivator and team player with strong interpersonal skills

· Have a strong hold on various reporting tools like VBA, advance Excel, Macro Creation, SQL.

· Strong problem-solving abilities, excellent analytical skills

· Basic knowledge or experience in Global markets and Operational Risk.. Knowledge of national as well as

· Display team spirit - Ability to work well within a team environment

· Should have stress tolerance

· Flexible and adaptable to suit the requirements of the team and organization.

· Integrity

· Ability to work effectively at all levels of the organization

· Takes initiative and is accountable

· Ability to work independently

· Competent project facilitation skills

· Ability to work effectively with business management

· Ability to think conceptually

· Strong interpersonal, analytical, and communication skills

· Ability to contribute to large, complex working groups

· Experience working under tight deadlines with multiple deliverables

· Candidate should be self-motivated

· Eye for Details - Good attention to quality and detail to Risk.

Why Join Us

“We are committed to creating a diverse environment and are proud to be an equal opportunity employer. All qualified applicants receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status”.

Business Insight

Societe Generale Global Solution Centre (SG GSC), a 100% owned subsidiary of European banking major Societe Generale (SG), Our role and purpose is to enable the strategic vision of Societe Generale Group. We are doing this by pioneering cutting edge innovation from Design Thinking to Smart Automation & Artificial Intelligence, and applying it to banking.

SG Global Solution Centre provides services in the areas of Application Development and Maintenance, Infrastructure Management, Business Process Management, and Knowledge Process Management, to Societe Generale's business lines around the world.",3.5,"Société Générale
3.5",Bengaluru,"Paris, France",10000+ employees,1864,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"BNP Paribas, Natixis, Calyon Securities USA"
192,Jr. Data scientist,"Responsibilities :
Responsibilities include Identify, develop and implement the appropriate statistical
techniques, algorithms and Deep learning / ML Models to create new, scalable solutions that
address business challenges across industry domains.
Define and develop, maintain and evolve data models, tools and capabilities.
Communicate your findings to the appropriate teams through visualisations.
Collaborate and communicate findings to diverse stakeholders.
Provide solutions but not limited to: Object detection/Image recognition, natural language
processing, Sentiment Analysis, Topic Modeling, Concept Extraction, Recommender
Systems, Text Classification, Clustering , Customer Segmentation & Targeting, Propensity
Modeling, Churn Modeling, Lifetime Value Estimation, Forecasting, Modeling Response to
Incentives, Marketing Mix Optimization, Price Optimization.

Qualifications and Experience :
Bachelors Computer Science, Information Systems, Machine Learning, Statistics,
Econometrics, Applied Mathematics, Operations Research or related technical degree with
ability to break complex business problems.
Minimum of 1 to 3 years of experience in a related position, as a data scientist or business
analyst building predictive analytics solutions for various types of business problems.
Knowledge of statistical techniques, machine learning algorithms and deep learning
frameworks like Tensorflow, Theano, Keras, Pytorch.
Minimum 1 years of Programming background and expertise in building models using at
least one of the following languages: Python, R ,Java, C,C++.",4.6,"Blackstraw
4.6",Chennai,"Tampa, FL",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
193,Staff Machine Learning Engineer,"Business Title
Staff Machine Learning Engineer

17-Apr-2020

Requisition Number
22965BR

Job Description and Requirements
Overview

Join a new and growing team at Synopsys focused on advancing state-of-the-art in Machine Learning. The team is working on developing Chip Design Solutions that will change the way how Chips are designed. Our focus is to develop ML driven technologies that could improve Quality of Results as well as Time to Results.

Ongoing research and development involve following technologies …
• Deep Learning
• Reinforcement Learning
• Bayesian Optimization, Gaussian Processes
• Unsupervised Learning
• Probabilistic Modeling
• Bayesian Network Modeling

Minimum Qualifications
• Exceptional team player
• Research oriented mindset : Should be able to review existing research publications in the relevant area and provide feedback on applicability in the current problem
• Strong understanding of Machine Learning fundamentals
• Strong analytical and communication skills
• Prior experience in some of the Machine Learning research areas listed above
• Proficiency in developing code in Python, TensorFlow, PyTorch, C++
• Object Oriented Software architecture Design

Education Requirements Required: Bachelor's, Computer Engineering and/or Computer Science and/or Electrical Engineering
Preferred: Master's, Computer Engineering and/or Computer Science and/or Electrical Engineering

Hiring Location
INDIA - Bangalore

Hire Type
Employee

Job Category
Engineering

Country
India",4.1,"Synopsys
4.1",Bengaluru,"Mountain View, CA",10000+ employees,1986,Company - Public,Computer Hardware & Software,Information Technology,₹100 to ₹500 billion (INR),"Cadence Design Systems, Mentor Graphics, Ansys"
194,Data Scientist,"We are looking for people with the right blend of technology skills, business knowledge and a passion for revolutionizing machine vision.

Explore and prototype solutions or products at intersection of computer vision, image processing, applied machine learning by leverage existing or new vision or machine learning algorithms.
Solid understanding on linear algebra, image processing, computer vision and machine learning knowledge.
Develop and prototype computer vision algorithms in Python or C++
Familiar with one or two deep learning frameworks: Tensorflow, Pytorch/Caffe2, Keras etc.
Hands on experience in one or more of the following areas: real-time object detection/segmentation/recognition/tracking, visual scene understanding, 3d vision, augmented reality
Minimum Qualifications

Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field OR Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field

Additional Preferred Qualifications

Experience with C++/CUDA/TensorRT and model compression is a plus
Send in your resume to Careers@JidokaTechnologies.com",-1,Jidoka Technologies,Chennai,"Chennai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
195,Data Scientist,"About us :

Remember the days when the phone rang and you didn't know who it was? If it was the company you always dreamt of working for? A call from a hospital trying to tell you someone close to you got sick? Or just that stubborn sales guy.
Our mission is to make it possible for you to know who's trying to contact you, and also tell you when not to pick up. We want to remove all uncertainty, making your communication safe and efficient by separating the important stuff from the noise and create trust, no matter if it's in the beginning of a call, in the middle of a transaction or at the end of a signature. We are building a platform which empowers our users to take control of their own digital identity and making their communication more safe and efficient.
Truecaller is one of the fastest growing tech companies in the world. We have 100 million daily active users around the world with the strongest presence in South Asia, Middle East and Africa.
We are backed by some of the most prominent investors in the world such as Sequoia Capital, Atomico, and Kleiner Perkins Caufield & Byers.

Your Mission :

The Data Scientist is responsible for collecting, organizing, analyzing and interpreting Truecaller data and drawing insightful conclusions with the aim of enhancing BU's road map, business plan and customer experience. The individual will work in close collaboration with the Product, Engineering and platform team in order to identify and follow up on metrics, evaluate A/B tests and user behavior and identify product insights. The role requires working both independently and proactively with identifying improvement opportunities as well as being involved in separate projects. The Data Scientist will act as an advisor to the BU's Product improvement, strategy building and Management Team by identifying and communicating data insight.

Key responsibilities:
Collecting, organizing, analyzing and interpreting all data and drawing insightful conclusions from it that enables us to work in a smarter way
Create visual interpretations from data and explain graphs and charts with insightful notes and summaries
Analyzing users data and assist product development in finding new innovative ways of presenting and making use of data
Support our management team in identifying, measuring and following up on key metrics
Providing regular, accurate and comprehensive statistical reports
Providing objective insight and analysis to influence decision making
Constantly asking the right but difficult questions on why, what and how and also help us answering those questions
Ensuring quality of data and actively working on cleaning data to make sure of top notch relevance and accuracy
Actively keep up to date on external market and data research and work towards adding data points from external sources to our own data in order to create a value added analysis
Required minimum competencies:

3 to 5 Years Experience in an Analytics/Data Science or similar roles, self- curated projects
Familiarity with database modeling and data warehousing principles with a working knowledge of SQL
Familiarity with data modeling on Hadoop clusters, the tools in Big Query, Hive, Spark Kafka ecosystem, stream processing to support the day-to-day work
Extensive experience with analytical and quantitative problem solving
Experience with analysis tools, open source or commercially available libraries and toolsets
Excellent communication skills
Great attention to detail and analytical skills
A passion for numbers, data and finding patterns
Ability to excel with challenging tasks with a calm and positive attitude
Working knowledge of data mining algorithms including decision trees, probability networks, association rules, clustering, regression, neural networks and reinforcement learning
Experience from working with mobile applications and big data is a great advantage
Programming knowledge in at least one language in addition to SQL
Global / multinational experience
Applying:

This position is located in Bengaluru, India.
We only accept applications in English.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, or marital status.",3.5,Jidoka Technologies,Chennai,"Stockholm, Sweden",201 to 500 employees,2009,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
196,SERM Scientist,"Site Name: India - Andra Pradesh - Hyderabad
Posted Date: Jun 10 2020

Are you energized by a highly visible safety role that ensures the accuracy of critical safety data? If so, this Safety Pharmacovigilance Manager role could be an ideal opportunity to explore.

As a Safety Pharmacovigilance Manager, you will be responsible for ensuring local regulatory obligations for clinical safety reports are met. This includes the appropriate collection, processing and reporting of adverse events (AEs) for GSK marketed and investigational products.

This role will provide YOU the opportunity to lead key activities to progress YOUR career, these responsibilities include some of the following
Review, extract, and accurately enter Adverse Event (AE) data from marketed product, reports received from spontaneous and solicited sources including health professionals, sales representatives, consumers and drug information in accordance with defined case handling procedures
Review, extract, and accurately enter all serious AE information from clinical trial reports in accordance with defined case handling procedures
Interpret case-related information including medical conditions, lab results and procedures, as well as compile complete and accurate narrative summaries
Ensure proper coding of Adverse Event terms and other medical terms into the global AE database.
Process and prepare reportable cases within applicable timelines including accurate determination of expectedness using the relevant core safety information
Review and comment on protocols/Case Report Forms (CRFs) for established and new products/programs and develops appropriate data entry protocol specific guidelines
Remain current with case handling standards, guidance documents and database technology.
Demonstrate in-depth working knowledge of regulatory environment & ensures compliance with safety data exchange agreements
Work with departmental teams in maintaining and upgrading the safety database
Why you?
Basic Qualifications:


We are looking for professionals with these required skills to achieve our goals:
Bachelors degree
Experience with Good Clinical Practices (GCCP), clinical safety documentation and reporting of adverse events from clinical trials
Experience with local regulatory requirements and pharmacovigilance methodology
Experience working with the principles of data collection, manipulation and retrieval
Preferred Qualifications:


If you have the following characteristics, it would be a plus:
Advanced Degree in Life Sciences or medical field
Previous experience as a Health care professional (e.g. pharmacist or nurse)
Demonstrated planning and organizational skills
Why GSK?


Our values and expectationsare at the heart of everything we do and form an important part of our culture.

These include Patient focus, Transparency, Respect, Integrity along with Courage, Accountability, Development, and Teamwork. As GSK focuses on our values and expectations and a culture of innovation, performance, and trust, the successful candidate will demonstrate the following capabilities:
Operating at pace and agile decision-making using evidence and applying judgement to balance pace, rigour and risk.
Committed to delivering high quality results, overcoming challenges, focusing on what matters, execution.
Continuously looking for opportunities to learn, build skills and share learning.
Sustaining energy and well-being
Building strong relationships and collaboration, honest and open conversations.
Budgeting and cost-consciousness
*This is a job description to aide in the job posting, but does not include all job evaluation details.

Our goal is to be one of the worlds most innovative, best performing and trusted healthcare companies. We believe that we all bring something unique to GSK and when we combine our knowledge, experiences and styles together, the impact is incredible. Come join our adventure at GSK where you will be inspired to do your best work for our patients and consumers. A place where you can be you, feel good and keep growing.

Important notice to Employment businesses/ Agencies

GSK does not accept referrals from employment businesses and/or employment agencies in respect of the vacancies posted on this site. All employment businesses/agencies are required to contact GSK's commercial and general procurement/human resources department to obtain prior written authorization before referring any candidates to GSK. The obtaining of prior written authorization is a condition precedent to any agreement (verbal or written) between the employment business/ agency and GSK. In the absence of such written authorization being obtained any actions undertaken by the employment business/agency shall be deemed to have been performed without the consent or contractual agreement of GSK. GSK shall therefore not be liable for any fees arising from such actions or any fees arising from any referrals by employment businesses/agencies in respect of the vacancies posted on this site.",3.9,"Truecaller
3.5",Bengaluru,"Brentford, United Kingdom",10000+ employees,1830,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Pfizer, AstraZeneca, Merck"
197,Customer Scientist,"Customer Scientist

Who are we?

A young, fast-growing AI and big data company, with an ambitious vision to simplify the world’s choices. Our clients are top-tier enterprises in the banking, e-commerce and travel spaces. They use our core AI-based choice engine maya.ai, to deliver personal digital experiences centered around taste. The maya.ai platform now touches over 125M customers globally. You’ll find Crayon Boxes in Chennai and Singapore. But you’ll find Crayons in every corner of the world. Especially where our client projects are – UAE, India, SE Asia and pretty soon the US.

Life in the Crayon Box is a little chaotic, largely dynamic and keeps us on our toes! Crayons are a diverse and passionate bunch. Challenges excite us. Our mission drives us. And good food, caffeine (for the most part) and youthful energy fuel us. Over the last year alone, Crayon has seen a growth rate of 3x, and we believe this is just the start.

We’re looking for young and young-at-heart professionals with a relentless drive to help Crayon double its growth. Leaders, doers, innovators, dreamers, implementers and eccentric visionaries, we have a place for you all.

Can you say “Yes, I have!” to the below?
3+ years of experience
Knowledge of advanced analytics techniques, including Predictive Modelling (Logistic regression), segmentation, forecasting, data mining, and optimizations
Knowledge of software packages such as SAS, R, Rapidminer for analytical modelling and data management.
Experience in using Business Intelligence tools such as SAS, Microsoft, Tableau for business applications
Can you say “Yes, I will!” to the below?
Design algorithms for product development and build analytics-based product
Coordinate individual teams to fulfil client requirements and manage deliverables
Lead analytical projects and deliver value to customers
Communicate and present complex concepts to business audiences
Manage and strategize business from an analytics point of view
Travel to client locations when necessary
Requirements

You’ll get brownie points for:
An aptitude for analytical problem solving
The capability of working effectively in a global team",4.4,"Crayon Data
4.4",Chennai,"Singapore, Singapore",51 to 200 employees,2012,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
198,Senior Data Scientist (ML/Deep Learning Expert),"Skills:
1. Good understanding of basics of Statistics, Probability, Linear Algebra and Calculus
2. Should be able to explain all ML/DS projects mentioned in resume
3. Good in qualitative and result interpretation
4. Good understanding of business problem
5. Profound understanding of basic DS and ML skills like outlier handling, data imputation, bias, variance, cross validation etc.
6. Good understanding of basic ML algorithm, like linear regression, logistic regression, random forest etc.
7. Take Ownership of on boarding new customers and continuously improve our existing.
8. Experience in building machine learning models or optimization software to solve business problems.
9. Ability to communicate results clearly to both colleagues and less technically versed audiences.
10. Knowledge of multivariate preferably in the Python Data ecosystem.
11. Good communication skills.
12. Passion to learn new tools, languages and frameworks
13. Good either at Python or R from DS perspective
Good in terms of Python
• Understand and uses pandas, numpy, scikit-learn and other scientific libraries
• effectively and efficiently.
• Understand basic data structure of python
• Write pythonic code
Good in terms of R.
• Good understanding on using packages like data. table, ggplot, dplyr etc.
• Good understanding of matrix algebra and memory management.

Desired Skills:
1. Basic understanding of version control systems
2. Experience of working in agile development environment.
Supply Chain Nation
Our Values

If you want to know the heart of a company, take a look at their values. Ours unite us. They are what drive our success – and the success of our customers. Does your heart beat like ours? Find out here: Core Values
Check out Blue Yonder's blog - Supply Chain Nation - the platform for supply chain trends and innovations.",4.3,"Blue Yonder
4.3",Bengaluru,"Scottsdale, AZ",5001 to 10000 employees,1985,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 billion (INR),"SAP, Oracle, Manhattan Associates"
199,Data Science Engineer - Image Database,"Senior Data Architect

Summary

We are looking for a technical lead who will design, build and maintain the data pipeline for creating training datasets for our AI research engineers. Additionally he or she will be responsible for automating the large dataset creation process. The ideal candidate should have 6-10 years of industrial experience in related field as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence/Data/DW Engineer, Data Scientist etc.) and 1-2 years of experience in leading a team.


Responsibilities
Lead the data pipeline setup, operation and maintenance.
Assemble large, complex data sets that are analysis/training ready for the machine learning engineers/researchers
Design and build scalable and reliable data pipeline that collects, transforms, loads and curates data from internal systems. Ensure high data quality for pipelines you build and make them auditable. Support design and deployment of distributed data store that will be central source of truth across the group.
Develop, customize, configure automation scripts/tools that help engineers to extract and analyze data from our internal data store. Develop reporting and data visualization solutions, as well as looking to build out a dynamic platform
Evaluate new technologies and build prototypes for continuous improvements in data engineering. Creation of new capabilities and modules in our data pipeline. Develop and maintain expertise in advanced and/or emerging data management and analytical information technologies such as data warehouse, data lake and Big Data
Build data connections to company's internal IT systems
Design, implement and continuously optimize the group’s data strategy. Provide thought leadership and lead efforts to design data integration and implement extract, transform and load (ETL) jobs/processes, detailed data warehouse models and data mappings. Provide consultation on best practices and standard practices to internal team members
Perform performance optimization and tuning on new and/or existing data warehouse implementations.
Requirements
5 years of hands on industry experience with a track record of manipulating, processing, and extracting value from large data sets.
Demonstrated ability in building data pipelines, data modeling, ETL development and familiarity with design principles. Experience building data products incrementally, integrating, and managing data sets from multiple sources. Knowledge of data warehouse technologies and relevant data modeling best practices. Experience with a DW technology (Redshift, SQL Server, etc.) and relevant data modeling. Experience processing large amounts of data, in various formats and processing data in batch mode and streaming mode
Excellent SQL skills. Proficiency in a scripting language (Python, Ruby, Perl etc.) and/or a major programming language (C , Java etc.). Knowledge of R is a plus.
Experience with working in Spark/Hadoop and/or other distributed computing frameworks is required
Experience working in a multi-layered distributed architecture is essential. Experience with scalable service architecture and design
Exposure and knowledge of Data Security and Governance. Awareness of best practices to secure data and processes from unauthorized access.
Knowledge and direct experience using business intelligence reporting tools (Tableau, PowerBI etc.) is a plus.
Understanding of data science, machine learning, and AI is a plus.
Strong analytical and problem solving skills (data analysis and requirement documentation)
Excellent project management skills and ability to prioritize issues
Excellent oral and written communication, organizational and client facing skills.
Academic Qualification Profile:


B.E. / B. Tech in Computer Science

Certification or Masters in Big Data Science",3.5,"Mercedes-Benz Research and Development India Private Limited
3.5",Bengaluru,"Chakan, India",1001 to 5000 employees,1996,Company - Private,IT Services,Information Technology,₹10 to ₹50 billion (INR),"Volkswagen, Tata Motors"
200,Data Scientist,"Required Experience, Skills and Qualifications :
Basic understanding of statistics, linear algebra and calculus.

Good understanding of data structures.

Proficient in Python and should have worked on statistical packages

Good understanding of AI and ML technology

Working with big data sets; data extraction, data mining, visualization, storytelling

Comfortable working on both supervised and unsupervised machine learning problems.

Worked on (at-least one of) the specialized packages pertaining to textual data like nltk and image data like pil, opencv, etc.

Worked on deep learning frameworks like tensorflow, etc

Hands-on experience in dealing with text and/or image data

Knowledge of distributed and parallel processing frameworks like Spark.

Understanding of search platforms like Solr/Elastic Search.

Qualification : Bachelor of Computer Application Bachelor of Engineering/ Bachelor of Technology Master of Computer Application Masters of Engineering/ Masters of Technology
Working Days : 5 Days a Week ( to )
Job Nature : Full Time

Salary 15 Lac To 25 Lac P.A.
Industry IT Software - Application Programming / Maintenance
Work Experience 5 - 12 Years
Qualification Professional Degree

Key Skills

Data Science Data Analysis AI Python IT linear algebra calculus big data

Company Profile

Email ID getintouch@saffroncareers.in",-1,Saffron Consultancy Services,New Delhi,"Gurgaon, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
201,Ai Scientist,"Location: Mumbai, India
About Us
Most of the world’s digital information was created in the last few years with the vast majority of that information being unstructured in the form of text, tweets, videos, images, blogs, etc. The rate of growth of digital information vastly exceeds our biological processing abilities. The consequence for investors is that it’s becoming harder to make sense of the factors that drive financial markets. Acting upon partial understanding of vast quantities of information (i.e., heuristics) infuses investment decisions with cognitive biases. In order to beat markets and make money, humans need to augment their reasoning capacity, consider the relevance of more information, and make bias-free decisions.
At Accrete.AI, our vision is to help investors generate alpha, or excess returns, by training machines to think in the language of the markets. We leverage deep learning and Machine Augmented Collective Intelligence (MACI) to train machines to reason and learn so they can help human investors make better investment decisions.

About You:
Two to three years of experience with Artificial Intelligence, Quantitative and Qualitative Analytics, Deep Learning, Machine Learning, Natural Language processing and Unstructured data analytics
Good knowledge of machine learning techniques, feed-forward, recurrent and convolutional neural networks, entropy models, supervised and unsupervised learning
Experience with one of the following: Theano, Tensorflow, Caffe, or any other deep learning/machine learning framework
Strong willingness and aptitude for learning new concepts and analytical approaches
Ability to formulate hypotheses, draw conclusions and deliver results
Experience working with datasets, and strong interest in deep data analysis – you need to be a detective at heart.
Effective interpersonal communication skills
Must have at least a Master’s degree or PhD, preferably in Applied Mathematics, Computer Science, Statistics or Economics
Responsibilities
Work with deep learning models optimize/customize/refine them
Define and design corpus structures, ANNs, and required activation functions
Document use cases and develop component and Interaction (sequence) diagrams
Design, development and delivery of tested code in an innovative, and, evolutionary environment.
Work effectively in teams, managing and leading teams
Provide effective, constructive feedback to the delivery leader
Manage client expectations and work with an agile mindset with machine learning and AI technology",-1,Accrete.AI,Mumbai,"New York, NY",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
202,Data Scientist,"Novique is a revolutionary online clinic startup that reverses type 2 diabetes safely and sustainably, without the risks, costs, or side effects of medications or surgery. Our innovations in nutritional biochemistry, data science and digital tools combined with our clinical expertise are shifting the diabetes treatment paradigm from management to reversal. Our mission – to reverse type 2 diabetes in 10 million people by 2030.

As a full stack health care company of physicians, engineers, scientists, marketers and more under one roof – Novique collects comprehensive data on our patients’ experience. The Data Science & Engineering team leverages this data and our growing compute resources to build the next generation of health care for chronic diseases. Data scientists at Novique drive science and algorithmic solutions into the fabric of Novique’s products, operations, and decision making. You will be an evidence-based partner to our department leaders and executive team as we scale our operation to reverse type 2 diabetes in millions of people.

Responsibilities:
2+ years experience applying statistical or machine learning models to real business problems
A strong ability to break down vague business problems into component parts that can be solved algorithmically
Experience with Python’s open source data ecosystem (e.g. numpy, pandas, sklearn, tensorflow, statsmodels, spacy etc.)
Familiarity with SQL

Bonus Points for:
Complex data domains, especially: natural language, health data e.g. insurance claims
Recommender systems
Sequential decision-making: reinforcement learning, bandit algorithms, adaptive clinical trials
Probabilistic programming: e.g. mc-stan, pymc3, or edward

Responsibilities:
Translate nebulous, mission-critical business problems into the language of science and algorithms. Then, build high-performance systems to solve those problems
Partner closely with our product, sales, and clinical leaders to set company priorities, define data-driven cross-functional initiatives, and drive execution.
Work autonomously on your projects, supported by a growing and ambitious team of data scientists and engineers

Apply to careers@noviquehealth.com with subject line: Data Scientist",-1,NOVIQUE HEALTH,Mumbai,"New Delhi, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
203,Data Scientist,"Exp: 3 - 8 years

CTC: 12 - 42 LPA

Preferred: Talents from eComms/Product/BFS

Responsibilities
• Work with a team of high-performing data science professionals, and cross-functional teams to identify business opportunities, optimize product performance or go to market strategy.
• Build data expertise, act like an owner for the company and manage complex data systems for a product or a group of products.
• Performing all of the necessary data transformations to serve products that empower data-driven decision making.
• Establishing efficient design and programming patterns for engineers as well as for non-technical partners.
• Designing, integrating and documenting technical components for data flows or applications that perform analysis at a massive scale.
• Ensuring best practices and standards in our data ecosystem are shared across teams.
• Understand the analytical objectives to make logical recommendations and drive informed actions.
• Engage with internal platform teams to prototype and validate tools developed in-house to derive insight from very large datasets or automate complex algorithms.
• Initiate and drive projects to completion with minimal guidance.
• Contribute to engineering innovations that fuel LinkedIns vision and mission.

Basic Qualifications
• Bachelor or higher degree in a quantitative discipline: statistics, operations research, computer science, informatics, engineering, applied mathematics, economics, etc.
• 3+ years relevant industry or relevant academia experience working with large amounts of data
• Experience with SQL/Relational databases
• Experience with manipulating massive-scale structured and unstructured data.
• Experience with distributed data systems such as Hadoop and related technologies (Spark, Presto, Pig, Hive, etc.).
• Background in at least one programming languages (e.g., R, Python, Java, Scala, PHP, JavaScript)
• Experience with data modelling, ETL (Extraction, Transformation & Load) concepts, and patterns for efficient data governance.
• Understanding of technical and functional designs for relational and MPP Databases, Reporting and Data Mining systems.
• Experience working with databases that power APIs for front-end applications.
• Knowledge of Unix and Unix-like systems, git and review board.

Preferred Qualifications
• Masters or Ph.D. degree in a quantitative discipline: statistics, operations research, computer science, informatics, engineering, applied mathematics, economics, etc.
• Bachelors with 10+ years or Masters with 6+ years or Ph.D. with 4+ years of industry experience
• Experience in developing data pipelines using Spark and Hive.
• Experience with either data workflows/modeling, front-end engineering, or back-end engineering.
• Strong communication skills, with the ability to synthesize, simplify and explain complex problems to different audiences.
• Experience in either the front-end or back-end development of data-powered applications.
• Experience working in the product, sales, or marketing analytics domains.
• Experience in data visualization and dashboard design including tools such as Tableau, R visualization packages, D3, and other Javascript libraries, etc.",-1,Staffio HR,Bengaluru,"Bengaluru, India",1 to 50 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
204,Data Scientist,"3- 6 Years – Hyderabad, Gurgaon
Job Description

Big Data Eco System like Hadoop and Spark and Scala ML

Machine learning models. Predictive Analytics .

Exp Range: 3 Years to 6 Years

Salary: Open

Industry: IT-Software / Software Services

Functional Area: Analytics & Business Intelligence

Role Category: Analytics & BI

Role: Data Analyst

Keyskills:
Hadoop, Spark, SCALA, BigData, Machine Learning, Predictive Analytics.",-1,AGUILASS,Hyderabad,-1,-1,-1,-1,-1,-1,-1,-1
205,Data Scientist,"Bachelor's or Master’s degree in Statistics, Applied Math, Operations Research, Economics, Engineering or a related quantitative field with 5 years of working experience as a Data Scientist.
In-depth knowledge on supervised and unsupervised machine learning algorithms including classification, clustering, and regression.
Experience building productions systems with statistical analysis, data modeling, regression modeling and forecasting, time series analysis, and deep learning neural networks.
Expertise in coding using one or more programming languages such as R, Python, MATLAB, and Spark to build machine learning models. Skilled in manipulating and processing data using libraries such as Scikit-learn, Pandas, and NumPy. Demonstrated experience in SQL and/or NoSQL data modeling.
Experience processing, filtering, and presenting large quantities of data. Ability to design for performance, scalability, and availability.
Excellent communication, analytical and problem-solving skills. Ability to distill informal customer requirements into problem definitions, dealing with ambiguity and competing objectives.
Obsession with quality, operational excellence, and customer experience. Ability to convey rigorous mathematical concepts and considerations to non-experts.
At Amazon, we strive to be most customer-centric company on the earth. To get there, we need exceptionally talented, bright, dynamic and driven people to develop the next-generation technologies.
Are you champion of innovating on behalf of the customer by turning data insights into action? Do you want to be part of Amazon’s strategic and highly impactful finance and payroll technology projects? Amazon’s Finance Automation Payroll Tech team has an opportunity for a seasoned Data Scientist whose experience illustrates a clear ability to create world class machine learning systems to meet long-term Payroll needs.

At Finance Automation, we are passionate about building systems and services that deliver a seamless and transparent finance experience for Amazon partners. We build, operate, and scale systems that are responsible for billions of dollars in transactions, and are central to the success of worldwide finance. We ""think globally, act locally"" to revolutionize a worldwide employee and customer experience and fulfill our promise to pay accurately, on-time, with lowest cost to Amazon.

As a Data Scientist at Finance Automation, you are self-driven leader with extensive experience in applying statistics and data science concepts to bring tangible benefits for global finance operations. Finance and Payroll domain knowledge is a plus but not required.
Work with finance and payroll stakeholders to understand the organization goals, objectives, and pain points. Identify key areas to drive Machine Learning initiatives, define needle-moving business questions and success criteria.
Collect and analyze finance, HR, and payroll data across multiple isolated systems. Derive actionable insights from large volumes of heterogeneous data.
Create reliable and maintainable code to build regression, classification, clustering, and anomaly detection systems. Work closely with software engineers to develop data ingestion and visualization, and productionize your models.
Partner with finance analysts, and payroll managers to deploy and test machine learning systems with your statistical models at the core. Automate feedback loops, tune, and improve the models in production.
Train non-tech stakeholders and partners to effectively use your machine learning systems. Set the right expectations on model limitations and prove business value.
Create and maintain business and technical artifacts such as requirements documentation, use cases, performance evaluation, and model metrics.
Learn and utilize AWS technologies and Amazon machine learning systems to effectively work with terabytes of data.
Being part of Amazon Finance Automation gives you the opportunity to work in a rapidly growing organization with many high performing global technology teams. Come join us in making history!
Passion to dive deep to resolve problems at their root, looking for failure patterns amenable to long-term solutions via simplification and automation.
Experience in AWS is a huge plus. Functional knowledge of AWS platforms such as Sagemaker, S3, Glue, Dynamodb, and RedShift.
Exposure to finance and payments domain is a plus.
Deep understanding of data, application, server, and network security.
Experience with agile or scrum methodology.",-1,ADCI HYD 13 SEZ,Hyderabad,-1,-1,-1,-1,-1,-1,-1,-1
206,DA&I DATA ENGINEER,"Position Title
DA&I DATA ENGINEER

05-May-2020

Business Group
Control Products and Solutions

No. of Positions
1

Requisition Number
92123BR

Job Category
Software and Engineering

Position Type
Full Time

Relocation Eligible
Not Applicable

Position Summary
Role Purpose: The Full Stack Data Engineer will design, develop, and deliver reliable, scalable data management (acquisition, integration, transformation) using DevOps methodologies and DA&I Microsoft PaaS platforms. Design and enable DA&I solutions and services throughout the company. This role is DA&I’s competitive advantage to delivering business outcomes via actionable analytics, decision intelligence and help our businesses recognize value and here to shape how we deliver analytics solutions going forward.

The Data Engineer is multi-skilled engineer who helps to estimate work, accept stories into delivery increments and complete tasks to deliver the work. Is proficient in Source Data Analysis, profiling, integration, modelling. Has expertise in data management technologies such as SAP data services, Azure ADF, ADLS, Databricks, SQL DB, Open source data management tools or equivalent.
Company Background
Rockwell Automation, a $7B industrial with 23,000 employees in 100 countries is at the forefront of the IoT revolution and is transforming its IT organization to digitize our customer experiences. We need full stack engineering professionals with a passion for technology to drive innovative solutions.

Key Responsibilities:
Designs, codes and tests new data management solutions, including supporting applications and interfaces.
Architects data structures to provision and enable “Data as a Service” .
Supports cross-functional development activity in various DA&I and Connected Enterprise related projects, for internal and external customers
Develops and tests infrastructure components in Cloud and Edge-level environments
Proactively monitors industry trends and identifies opportunities to implement new technologies
Manages the DevOps pipeline deployment model
Implements software in all environments
Leverages containerization models and works with other engineers and architects to keep the architecture current
Assists in the support and enhancement of applications
Writes high-quality code compliant with regulations
Collaborates with business systems analysts and product owners to define requirements

Qualifications
Skills, Knowledge, Experience and Education
Bachelor’s Degree in computer science, software engineering, management information systems, or related field
Experience in systems development lifecycle
Experience in Data management concepts and implementations
Experience with Agile development methodologies and system/process documentation
Experience with server-side architectures and containerization
Experience with SAP Data Services, Azure ADF, ADLS, SQL, Tabular models, or other domain-specific programming languages
Familiarity with business concepts and impact of data on business processes
Experience managing multiple projects simultaneously
Excellent interpersonal, verbal and written communication skills
Ability to adapt quickly to new technologies and changing business requirements
Solid problem-solving skills, attention to detail, and critical thinking abilities

Temperament
Ability to adapt to and assist colleagues to work through change and support change management processes
Strong team orientation and ability to collaborate with the business and IT organizations
Ability to retain and convey a positive attitude in challenging circumstances
Act courageously by sharing viewpoints openly and directly with others, providing relevant and timely information and feedback, as required
Ability to influence and obtains results through others within Rockwell in a respectful way
Adapt appropriately to competing demands and shifting priorities

IPC - Information Processing Capability (Factors of Complexity)
Ability to work on issues of moderate scope where analysis of situations or data requires a review of relevant factors.
Exercise judgment within defined procedures and practices to determine appropriate action.
Seek out and embrace relevant perspectives when assessing a situation or making a decision; demonstrate clear understanding of multiple viewpoints
Leverage business insights in proposing solutions and facilitating change
Ability to manage competing demands, accept criticism and constructive feedback, while being extremely adaptable and flexible
Strong analytical skills; ability to distill information from disparate data sources and the capability to tell the “story” behind it, as well as recommendations for next steps

Accepts Role Requirements
Unwavering commitment to, and the ability to model, the standards of behavior set in our Code of Conduct.
Enthusiasm for relationship building and partnership across the organization at all levels
Values working in a team-oriented culture and building consensus with stakeholders before making key decisions
Actively pursues personal continuous learning and development of skills

Country(s)
India

Company Overview
Over centuries, the world has evolved and advanced. New innovations change how we work. How we live. How things get made.

The next industrial evolution is here — a new test of intelligence for humans and machines. Where breakthroughs are hard–won and success requires sifting through overwhelming data for insights, clarity and confidence.

Rather than fearing change, we embrace its possibilities. We know how to connect the imaginations of people with the potential of machines to make the world work better. More intelligent. More connected. More productive.

We stand with the problem solvers, the builders, the makers, the innovators because we belong to that community. And we stand ready to lead the way. At Rockwell Automation, we are expanding human possibility.

Work State/City
Noida, Pune",3.8,"Rockwell Automation
3.8",Noida,"Milwaukee, WI",10000+ employees,1903,Company - Public,Industrial Manufacturing,Manufacturing,₹500+ billion (INR),"Emerson, ABB, Siemens"
207,Data Scientist (Open),"Qualification: Masters in statistics, mathematics or any other masters with very good analytical skills

Skills required:
– Experience in using any of the deep learning frameworks ( Tensorflow, Keras, and Pytorch etc) in a professional environment.
– Expertise in Python programming language with exposure to computational libraries like Pandas, Numpy etc.
– Expertise in traditional machine learning frameworks such as Scikit-learn, Stanford NLP or NLTK.
– Comfortable in solving both computer vision ( Classification, Segmentation, and Object detection ) and NLP problems ( Text classification, Named entity recognition etc).
– Experience in using CV libraries like OpenCV etc.
Experience: 1-4 yrs
Job location: Ahmedabad
Employment type: Full time",-1,Protocolzone,Ahmedabad,-1,-1,-1,-1,-1,-1,-1,-1
208,Senior Research Scientist,"Company Description

FireEye is the leader in intelligence-led security-as-a-service. Working as a seamless, scalable extension of customer security operations, FireEye offers a single platform that blends innovative security technologies, nation-state grade threat intelligence, and world-renowned Mandiant® consulting. With this approach, FireEye eliminates the complexity and burden of cyber security for organizations struggling to prepare for, prevent, and respond to cyber attacks. FireEye has over 7,500 customers across 67 countries, including more than 50 percent of the Forbes Global 2000.
Job Description

FireEye’s network research team focuses on finding and preventing cyber attacks to protect our customer base. Attacks comes from various vectors such as social engineering threats and various exploits, but if a customer is breached, we are there to detect malicious C2 traffic as well as lateral movement activity in our customer environments.

We’re looking for security savvy candidates who understand the current threat landscape. As a security researcher, you’ll get the satisfaction of understanding the attacker mentality and stop intrusions. Security operations is just one aspect of the job and you’ll have the opportunity to learn new areas and develop new, innovative ways to detect threats in the cloud.

What You Will Do:
Develop network detection to block threats as they come into the network
Handle customer detection issues, provide prompt and accurate feedback to customers
Understand network-based vulnerabilities and develop new content to detect potential exploits
Identify new techiques used by attackers to traverse laterally in a customer environment
Brainstorm and develop new detection modules in the cloud to identify unknown threats
Discover, track and analyze latest malware, network and email cyber threats
Qualifications
At least 3-5 years direct or equivalent experience in areas of network (IPS) detection, vulnerability analysis and other aspects of cyber-attacks discovery.
Specialist in programming with Python
Candidate should have good communication skills to respond to the support/customer queries.
Able to work independently and occasionally available during non-business hours to handle critical customer issues/malware outbreak
Knowledge in security and malware detection technologies",3.3,"FireEye, Inc.
3.3",Bengaluru,"Milpitas, CA",1001 to 5000 employees,2004,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Palo Alto Networks, Tanium"
209,Senior Data Scientist,"TechVantage is a product engineering company that builds first-of-its-kind AI-centric products is looking for Senior Data Scientist to be a part of product development of AI powered software.
The work location is in Technopark, Trivandrum and the ideal candidate should be willing to travel to client sites outside India

What we are looking from an ideal candidate?

You need to be a thinker. We are looking for a very curious Lead data scientist who enjoys a deep dive into the raw data to help figure out the right set of questions and find the answers to those questions.
You need to be a doer. You will be responsible for data cleansing, transformation and creating predictive models and classifiers.
You need to be ambitious. You must be passionate about applying mathematical modeling to solve real world problems.
You need to be smart and build smart products. A big part of this job is about creating actionable insights for our customers and the business using machine learning and statistical techniques. Translate analytic insights into concrete, actionable recommendations for business or product improvement.
Design and build Machine Learning, Deep Learning, and NLP, infrastructure, models and applications to generate scalable and high-performance Prediction, Evaluation, Recommendation, anomaly detection, bots, sentiment insights and ontologies from structured/unstructured Big Data and domain rules
Determine the best AI technique for a particular customer problem in any industry domain and apply, learn, and adapt.

Limited front row seats are available. If you fit the description, do not hesitate to apply- jobs@techvantagesystems.com. This is the job for you! - See you soon at TechVantage! For more information about us, please visit www.techvantagesystems.com

Preferred Skills:
What skills do you need?

A big part of this job is about creating actionable insights for our customers and the business using machine learning and statistical techniques.

Should be strong in Probability, Statistics, Optimization, Calculus, General Math
Experience with some or all of the following: data mining, predictive modeling, statistics, experimental design, computational analytics, econometric modeling, data visualization
Hands-on experience in feature engineering and building scalable machine learning algorithms
Prior experience of handling large volumes of unstructured data with high diversity
Excellent client management skills
Tech/MS/M.Tech or PhD in Computer Science, Machine Learning, AI, or related field
Prior experience with start-up environment preferred is a plus",4.1,"Techvantage Systems
4.1",Thiruvananthapuram,"New York, NY",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
210,Senior Data Scientist,"Summary


Do you get excited by intellectually stimulating problems? The Senior Data Scientist has to have a mix of advanced technology, customer and strategic business acumen. You will work in and lead teams as technical domain expert addressing statistical, machine learning and data understanding problems. You will be part of a data science or cross-disciplinary team on commercially-facing development projects, typically involving large, complex data sets. These teams typically include statisticians, computer scientists, software developers, engineers, product managers, and analysts

What you get to do

Develop analytics solutions to address customer needs and opportunities
Work alongside software developers and data engineers to translate algorithms into commercially viable products and services
Work in technical teams in development, deployment, and application of analytics solutions, leveraging technical components
Take responsibility for insights, reports, annotated code, and other projects artifacts to document, archive, and communicate outcomes to client and prospects based on these
Be responsible for entire solutioning and implementation cycle: From definition of business questions and hypotheses, to data sourcing and preparation, model development, and insight generation. Output of these analyses will be the basis for strategic resource allocation by BU and Leadership
Collaborate closely with other functions to advise, and support Business leadership in various types of advanced quantitative analyses, including but not limited to: Marketing Mix Analysis, Advanced Segmentation & Targeting, Personalization, Chatbot & Personal Assistant, CLTV etc
Lead and mentor a highly motivated team with exceptional talent
Work with the Business Development team in the pre sales & pilot engagements for analytics engagements
Evangelize TEG’s vision through case studies, participation at conferences, and creating thought leadership articles

What you will need to make an Impact
Should maintain high standards of quality and thoroughness. Should be able to monitor accuracy and quality of others work
Ability to lead new initiatives, prepare project plans and other supporting information
Experience across verticals will be a plus
Strategic business acumen, focus on results, passion for keeping up with media and technology trends
Ability to influence cross-functional and upper management to impact decision-making
Ten years of progressive advanced analytics work experience
Experience in marketing mix modeling, promotional response and price modeling, forecasting, optimization, simulation, and/or decision analysis
Post-graduate degree (Master’s/Ph.D) in a quantitative field (Statistics, Management Science, Operations Research, Engineering, Finance, Applied Mathematics, Mathematics, Business Administration etc, from Tier-1 institute",3.1,"TEG Analytics
3.1",Bengaluru,"Bengaluru, India",51 to 200 employees,2008,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
211,Data Scientist / Engineer,"Division : Machine Learning /AI
Education :MSc(IT/Maths) /BCA /MCA /BE(IT)
Relevant Exp : 2 years
At : Ahmedabad

ML Engineer with atleast 2 year experience in design and development of machine learning algorithms and active involvement in deep learning systems. To do this job successfully, you need exceptional skills in statistics, mathematics and programming. Your ultimate goal will be to shape and build efficient self-learning applications.

key Skills & Attributes
Python
PyTorch
Numpy
SciPy
Matplotlib
Pandas
MySql
Statastics
Lineer Algebra",-1,FrankPro Consulting [OPC],Ahmedabad,"Ahmedabad, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
212,Data Science Engineer,"We are looking for a Data Scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.

Responsibilities
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending company's data with third party sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance

Skills and Qualifications
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.
Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc. (excellence in at least one of these is highly desirable)
Great communication skills
Experience with data visualisation tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive, Pig
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills in Ruby and Python
Data-oriented personality",3.9,"Involvio
3.9",Bengaluru,"New York, NY",1 to 50 employees,-1,Company - Private,Colleges & Universities,Education,Unknown / Non-Applicable,-1
213,Lead Data Scientist,"Join a team recognized for leadership, innovation and diversity


YOU MUST HAVE
Bachelors in Computer Science, Data Science or Engineering fields
7+ years of IT experience in solution architect / data scientist / software development for large corporate/organizations
5+ years of experience in building and deploying Machine Learning solutions using various supervised/unsupervised ML algorithms such as Linear/Logistic Regression, Support Vector Machines, (Deep) Neural Networks, Random Forest, etc
5+ years of hands-on experience with Python and/or R programming and statistical packages, and ML libraries such as scikit-learn, Keras, TensorFlow, PyTorch, MXNet, etc, and/or natural language processing using NLTK, spaCy, Gensim, etc.
2+ years of experience in building IT use cases / solutions especially around AI/ML cognitive services, based on Cloud infrastructure and services such as AWS and/or Azure cloud platforms.
Excellent understanding of Machine Learning techniques and proficiency in feature analysis, algorithm selection and model hyperparameter tuning.
Demonstrated hands-on experience in working with Hadoop, Hive, Apache Spark, etc.
WE VALUE
Bachelors Degree in Computer Science, Data Science or Engineering fields
Work experience / education in data science, data engineering and analytics
Project experience with NLP/NLG, AI Conversational Agent (Chatbot), OCR
Experience with Domino Data Lab, NiFi, Airflow, etc.
Development experience in RPA Tools & Platform & Implementations: Examples - UiPath, Automation Anywhere and other leading RPA platform vendors
Experience in Web Service/Restful API Integration
Experience in ERP platform integration, preferably with SAP
Working Experience in an Agile/Scrum/Scaled Agile and DevOps based team environment
Project management skills and experience
Certifications AI / ML and Cloud platforms
Great communication skills
Additional Information
JOB ID: req234050
Category: Engineering
Location: Devarabisanahalli Village, KR Varturhobli,,East Taluk - Phase I,Bangalore,KARNATAKA,560103,India
Exempt
Software (GLOBAL)",3.8,"Honeywell
3.8",Bengaluru,"Charlotte, NC",10000+ employees,1885,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"GE, Johnson Controls, United Technologies"
214,Junior Data Scientist/ta,"1 - 5 Years

Gurgaon, Bangalore, Mumbai, Pune, Chennai, Hyderabad

Job Description

candidate should qualify checklist written below:
Ques: Does the candidate has strong knowledge in Data Science/ Machine Learning/ Artificial Intelligence ? Please mention

Ques: Is the candidate willing to work full time as a Data Science program Manager/ Academic and content delivery/ End to End Curriculam delivery and management ?

Ques: Does the candidate has Data Science/ Machine learning content development and academic delivery experience/ Faculty Development programs in any Teaching Institution or E - Learning Companies?

Job Specifications

Exp. 1.0 - 5.0 Year(s)
Annual Fixed CTC Min : 7.0 Lacs Max: 15.0 Lacs
Qualification B.Tech/B.E. , Any Post Graduation
No of openings 3
Additional Doc/Msg

Salary 7 Lac To 15 Lac P.A.
Industry IT Software - Application Programming / Maintenance
Work Experience 1 - 5 Years
Qualification Other Bachelor Degree, MD/Medicinae Doctor, Other Doctorate Degree

Key Skills

Data Scientist

Company Profile

Company Name

Great Learning

About Company Great Learning is an online and hybrid learning company that offers high-quality, impactful, and industry-relevant learning programs to working professionals. These programs help them master data-driven decision-making regardless of the sector or function they work in and secure their career growth into the future. These programs are delivered through a convenient and robust technology-enabled experience with no disruption to their careers.
Contact Person Pramod Kumar
Address Gurgaon
Mobile 8506010400
Email ID jobwsd@gmail.com",-1,WSD Consultant,Gurgaon,"Ghaziabad, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
215,Data Sciences - Associate,"Job Description – Associate - Data Science

We, at TheMathCompany, enable data analytics transformations for Fortune 500 organizations across the world. We enable our clients to build core capabilities that set them on a path to achieve analytics self-sufficiency.
Over the last three years, we have been consistently doubling in size year-on-year with 300 (and counting…) Data Scientists & Engineers, Consultants, and Visualization experts
TheMathCompany has won multiple awards recognizing us as a global Data and Analytics firm – We ranked #23 in the Deloitte Technology Fast 500™ Asia Pacific 2019 and #2 in Deloitte Technology Fast 50™ India 2019.
35+ Fortune 500 Companies, from almost 10 different industries and countries, trust us to power their analytical transformation.
WHAT’S IN IT FOR YOU:
An exciting opportunity to be a part of the growth journey of one of the fastest-growing AI & ML firms – scope for experimentation, the big & small victories, the learnings and everything in between
Our in-house learning and development cell - Co.ach, run by world-class data analytics experts, enables our folks to stay up to date with the latest trends and technologies
At TheMathCompany, we insist on a culture that provides us all with enough flexibility to accommodate our personal lives without compromising on the dream of building a great company
We are changing the way companies go about executing enterprise-wide data engineering and data science initiatives, and we’d love to have you grow with us on this journey
ROLE DESCRIPTION

As an Associate, you will be responsible for a wide range of opportunities to ensure you have a steep learning curve. Along with solving complicated business problems for organizations using data science techniques, you will be the face of MathCo. in client engagements. You will also have multiple opportunities to build, design & execute initiatives (ranging from contributing to the hiring & training programs to developing learning packages utilizing hot Analytics industry trends) that help us in our growth trajectory

The responsibilities are detailed as below:
Liaising with clients/stakeholders to understand the business problem
Define, breakdown and solve the business problems across domains while leveraging conventional & new age data sources, and a wide array of techniques
Accountable for the delivery of end to end analytical solutions
Depending on the engagement, lead a team of Analysts/Associates to enable consumption of the analytical solution
Contributing to the learning programs through sessions, content creations, etc. based on the nature of the engagements
REQUIRED QUALIFICATIONS

We are looking for individuals who are curious, excited about learning and navigating through the uncertainties and complexities that are associated with a growing company. Some qualifications that we think would help you thrive in this role are:
Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series, etc.)
Experience of working on analytics projects and initiatives, preferably around 2-5 years
Strong analytical/problem-solving skills/mindset
Bachelor/Master of Engineering, BSc/MSc Honours, Ph.D. or equivalent
PREFERRED QUALIFICATIONS
Experience or certifications with visualization tools (Tableau/Qlik/PowerBI etc)
Understanding of software development methodologies (Agile essential), values, and procedures
Well versed with big data handling using Hadoop, etc.
Strong cultural fit
Ability to work without guidance
Focused on continuous learning and improvement
Ownership to drive results and strive for excellence
Takes initiatives to foster company growth
Develops and Engages the team
Supports diversity and understand different perspectives
Communicates effectively
High Emotional Quotient
TheMathCompany would provide you with an ecosystem to learn and grow in your professional journey, offering guidance to help you be successful. We are also a fun bunch and will help you in making this memorable.

Do you believe you have what it takes to build TheMathCompany and analytics capabilities for Fortune 500 organizations?

Have some questions or suggestions? Unclear about certain opportunities? Feel free to reach out to us anytime for a friendly chat:

Website: http://themathcompany.com/

e-mail: careers@themathcompany.com

About US | LinkedIn | Culture",4.2,"TheMathCompany
4.2",Bengaluru,"Bengaluru, India",201 to 500 employees,2016,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
216,Data Scientist / Senior Data Scientist,"Position Summary

NextNav is launching a groundbreaking location service for smartphones, IOT, and other devices – an ability to determine floor level altitude service across the country – a capability that does not exist at scale anywhere today! No longer constrained by legacy “flat earth” technologies, applications and users will be able to determine floor-level altitude, which is essential for navigation, user context and relevancy and many other applications that are used indoors.

This position will consist of building tools to aid with alerting of our system, developing real-time metrics of our end-to-end network performance, and calibration quality at all levels. The position will also develop models to aid in our end-to-end system, including calibration and forecasting, as well as applying machine learning and deep learning algorithms.

Responsibilities

·Develop algorithms to further improve the accuracy of NextNav's Z-axis solution.

·Efficiently clean, prune, fix, prepare, process and analyze network and field data.

·Create and develop machine learning algorithms to help aid in positioning and calibration of devices and network.

·Develop strong domain expertise with atmospheric science.

·Interpret data and guide company to maximal benefit.

Desired Skills& Experience

Required:

·Bachelor's degree with 2-3 years’ experience, orMaster's/PhDin engineering disciplines such as mechanical engineering, electrical engineering, or sciences such as mathematics, statistics, computer science, physics, or another closely related field, with research emphasis on data modelling and analysis.

·Solid foundation in statistics and data processing, including data reduction, regression, automation and visualization.

·Strong scientific coding skills, including proficiency in one or more of the following: Python, R, MatLab, SQL, etc. Expertise with object-oriented languages such as Java or C++ a bonus.

·Familiarity with machine learning and deep learning framework applied to real world problems.

·Ability to work independently and collaboratively across multiple departments, including hardware and software.

·Strong written and oral communication skills, with the ability to communicate clearly and effectively across teams.

Preferred:

·Experience in performing analysis of large data sets by exploiting parallel computing infrastructure.
1-2 years’ experience with machine learning and deep learning framework, including scikit-learn, Tensor Flow, or PyTorch.
·Experience in providing data support for internal and external engagements for trials and demos.

·Demonstrated experience as a problem solver and a data analyst of a variety of gridded and point weather data.

·Experience with driving projects across all stages, including ideation, testing, and marketing.

·Track record of source code contribution to open source projects.",3.4,"NextNav
3.4",Bengaluru,"Sunnyvale, CA",51 to 200 employees,2007,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹1 to ₹5 billion (INR),-1
217,Data Analyst,"Posted: May 15, 2020
Weekly Hours: 40
Role Number:
200170317
Imagine what you could do here. At Apple, new ideas have a way of becoming extraordinary products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish.
The people here at Apple don’t just create products — they create the kind of wonder that’s revolutionized entire industries. It’s the diversity of those people and their ideas that inspires the innovation that runs through everything we do, from amazing technology to industry-leading environmental efforts. Join Apple, and help us leave the world better than we found it.
It takes deeply dedicated, intelligent and hard-working individuals to maintain and exceed the high expectations for the exciting iPhone brand at Apple. The iPhone Operations team is seeking a Sr. Data Analytics Lead to take on the responsibility of improving superior quality and manufacturing goals through statistics, analytics, modeling, and business intelligence tools.
Key Qualifications
he role includes the following main duties:
Employ statistical techniques with big data initiatives and tools to drive major operational business decisions.
Answer complex questions through data, analysis, and clearly communicate findings to multi-functional teams for direction.
Influence repair processes and fraud detection improvements by scripting analysis on very high volumes of data at a commodity and parametric level.
Seek opportunities to improve data collection, reporting and consumption based on business needs.
Regularly collaborate with internal and external information technology teams on resolving data issues, as well as mitigation plans to avoid errors in the future.
Participate in strategic capital systems planning. Required Experience:
Excellent analytical skills, advanced level of statistics with the ability to identify and predict trends and anomalies.
You should have expertise, aptitude or prior background understanding complex data sets to be able to translate to: product testing, parametric big data, manufacturing, robotics and capital equipment.
Creative and innovative ideas to select and configure appropriate technologies and programming languages required to ensure successful business impact.
Experience in data mining very large data sets, high proficiency in SQL (Teradata, Oracle, or MySQL or other RDBMS.)
Experience in Hadoop, Hive, HDFS, Spark, AWS Redshift, Presto, and other distributed processing systems preferred.
You will have superb software development skills with proficiency in Python, R and libraries such as (scikit- learn, scipy, R, NetworkX, Spacy, and NLTK).
Data visualization experience with tools such as: Tableau, JMP, R creating dashboards and presenting data through reports.
Proven ability to handle various tasks concurrently and in a timely manner, including large, complex projects.
Effective presentation skills and be able to explain complex data and charts in a concise manner to large audiences.
Superb communication skills, both verbal and written.
Prior experience in Manufacturing, Test, and Consumer Electronics is a plus
Description
The Data Analyst utilizes data, infrastructure and intelligence tools to tackle interesting problems every day. You will be tasked with finding insights from data that will improve product operations, quality, and manufacturing efficiencies by understanding the variables impacting yield. You will drive strategic initiatives for better data collection and reporting, ensure data integrity across multiple data sources, and reduce analysis time through automation and creative solutions.
You will present data to peers, managers, directors, and VPs; and highlight data patterns that could be useful for making business decisions. You will work closely with a variety of lines of business: Operations, Test Engineering, Quality, Engineering, Product Development, Customer Service, Supplier Quality, Global Supply Managers, Suppliers, Contract Manufacturers, Repair, Fraud Detection, Business Intelligence and IT teams.
You will take data from disparate sources, apply statistical modeling, analyze and interpret its specific meaning, and clearly convey the significance of the assessment, tailored to individual teams, as well as the business as a whole.
The position requires a software programming skill set (preferably python), utilization of statistical techniques, experience understanding data integrity, and implementing automated solutions. You will need to have a grasp of relational database management systems, design, and structured query language (SQL).
Education & Experience
Master of Machine Learning, Data Science, Statistics, Operations Research or related fields with 5+ years’ experience applying machine learning techniques to real business problems.",4.7,"Apple
4.7",Bengaluru,"Cupertino, CA",10000+ employees,1976,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Google, Microsoft, Samsung Electronics"
218,Associate - Data Science,"? Publishing of Regular Portfolio Performance Deck and regular dashboards
? Automation of existing dashboards using SAS / Python / SQL / Tableau
? Adhoc – analysis for top management.
? Data maintenance, Data Quality, Enrichment and Validation
? Cross functional analytical projects
? Customer/Stakeholder Management for dashboard automation and regular dashboards

Job Description ? Publishing of Regular Portfolio Performance Deck and regular dashboards
? Automation of existing dashboards using SAS / Python / SQL / Tableau
? Adhoc – analysis for top management.
? Data maintenance, Data Quality, Enrichment and Validation
? Cross functional analytical projects
? Customer/Stakeholder Management for dashboard automation and regular dashboards
? SAS
? Tableau
? Python
? Dashboard Automation",3.4,"TATA Capital
3.4",Mumbai,"Mumbai, India",1001 to 5000 employees,-1,Subsidiary or Business Segment,Investment Banking & Asset Management,Finance,₹100 to ₹500 billion (INR),-1
219,Data Scientist (Upto 5years),"Desired Candidate Profile

Experience in relevant field such as Statistics, Computer Science or Applied Math or Operational Research.
Must have Masters in (Maths/Statistics or Applied Mathematics/Machine Learning etc.)
History of successfully performing customer implementations
Strong customer facing skills, and previous consulting experience.
Experience of handling high frequency streaming data for real time analysis and reporting.
Familiarity with - Natural Language Processing, Statistical Analysis (distribution analysis, correlation, variance
Experience with open source technologies is a must.
Energy/Hunger for Growth
Excellent communication and executive presence to connect at CXO levels
Ability to lead & build strong teams
Ability to work in an ambiguous environment.
Desired Skills and Experience

Languages/Tools:Python/R,Scala,SQL,
Experience in applying Data Science methods to Business Problems. Machine Learning,
Concepts: Strong presentation and communication skills with a knack for explaining complex analytical concepts to people from other fields.
Team leadership, Mentoring and project management skills.
Education :PG - Any Postgraduate - Any Specialization, MS/M.Sc(Science) - Any Specialization, Maths, Statistics",5.0,"XLNC Technologies
5.0",Mumbai,"Mumbai, India",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
220,Data Science Manager-R&D,"Qualification and Experience:M.Tech / M.E / MS / M.Sc / Ph.D ; 2+ Years

Qualification and Experience
M.Tech / M.E / MS / M.Sc / Ph.D in Computer Science or a related discipline (Applied Mathematics, Statistics, Electrical and/or Computer Engineering) with a focus on Artificial Intelligence / Machine Learning
A CGPA of 7.5/10 or above in UG as well as PG level (in case of percentage, 70% or above)
2+ Years
Responsibilities
Responsible for applied research, development and validation of advanced machine learning and AI algorithms for solving complex real-world problems at scale
Work closely with product team to understand business problems and product vision to come up with innovative algorithmic solutions
Create prototypes and demonstrations to validate/establish innovative ideas and translate research outcomes to productized innovation by working with AI Engineers and/or software engineers
Create and maintain research plans, conduct experiments, consolidate and document results, and publish works as appropriate
Document and protect intellectual property (IP) generated from R&D efforts by collaborating with designated teams and/or external agencies
Mentor junior staff to ensure that correct procedures are followed; collaborate with stakeholders, academic/research partners and peer researchers to deliver tangible outcomes
Requirements of the role
The candidate is expected to be strong in fundamentals of computer science as well as in analyzing and designing AI/Machine learning algorithms
Hands-on experience in at least two of the following areas are required :
Supervised, unsupervised and semi-supervised machine learning algorithms
Reinforcement Learning
Deep learning & Representation Learning
Knowledge based systems (knowledge representation, reasoning and planning; FOL, ontologies etc.)
Evolutionary Computing
Probabilistic Graphical Models
Streaming, incremental and non-stationary learning
Candidate should be strong in at least one programming language, and should have experience in implementing AI/machine learning algorithms in python or R
Experience with tools/frameworks/libraries such as Jupyter/Zeppelin, scikit-learn, matplotlib, pandas, Tensorflow, Keras, Apache Spark etc. would be desirable
Applied research experience of at least 2 – 5 years on real-world problems using AI/Machine Learning techniques
At least one publication in a top tier conference/journal related to AI/Machine Learning (E.g. ICML, AAAI, NIPS, ICCV, CVPR, KDD, SIGMOD, IJCNN, IJCAI, EMNLP, ICPR, ICDM etc.) and/or patents
Experience in contributing to open-source projects related to AI/Machine Learning would be a strong plus
Job Code: DSM_TVM
Location: Trivandrum

For more information, Please mail to: recruitment@flytxt.com",3.8,"Flytxt Mobile Solutions
3.8",Thiruvananthapuram,"Trivandrum, India",201 to 500 employees,2007,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹10 to ₹50 billion (INR),-1
221,Sr. Data Scientist,"Brillio is forging ahead aggressively amidst the current COVID-19 situation and continues to hire for various roles globally - with all interviewing and on-boarding done virtually. Brillio has invested in the right capabilities to adapt to the new normal and empower its employees to operate seamlessly. All the new joiners, along with the Brillio family, will temporarily work remotely until it is safe to return to our offices.

Read Brillio’s Chief Operating and Delivery Officer, Aftab Ullah’s statement about Brillio's hiring plans in the leading publications - The Times of India and The Week’s latest stories about the positive hiring sentiments of tech firms.

To succeed, you’d have technical experience and
expertise in –

A.

For you to be successful, you must:

· Create value by
meeting needs of stakeholders and delivering high-quality results

· Open and flexible to
accommodate and implement new ideas, understand business complexities, nurture
innovation and challenge the status quo persistently

· Strive to be subject
matter expert in chosen area of specialty through continuous learning

· Have an eye for detail
to ensure accurate conclusions in data analysis and presentations

· Disseminate knowledge
and share own experiential learning with others

B.
You’ll bring this to the table: -

· Critical Thinking:
ability to work in ambiguous situations with unstructured problems

· Strong analytical
skills with the ability to collect, organize, review significant amounts of
information

· Experience using
statistical computer languages (R, Python, SAS) to manipulate data and draw
insights from large data sets.

· Working knowledge in
basic statistical concepts such as properties of distributions, statistical
tests and their proper usage

· Expertise in some of
the advanced machine learning techniques such as Clustering,
Regression/Classification, Time Series Analysis, Network Analysis, Popular Deep
Learning architectures and theory, simulation, scenario analysis

· Clear, professional
written and verbal communication skills, ability to easily communicate complex
ideas

· Experience with any
distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, etc.

· Experience with
machine learning on big data.

C.

It would be exceptional, if you also have
this:

· Expertise in Image,
Video, Speech, Sound, Text domain

· Working knowledge of
concepts and application of Design of Experiments

· Depth across areas
within the domain or industry",3.1,"Brillio
3.1",Bengaluru,"Santa Clara, CA",1001 to 5000 employees,2014,Company - Private,IT Services,Information Technology,₹10 to ₹50 billion (INR),-1
222,"Intern, Data Science Developer (Python, Data Analyst)","Who we are and what we do:

Founded in 2002, Cactus Communications (CACTUS) is a global scientific communications company that collaborates with researchers across academic disciplines, universities, publishers, societies, and life science organizations to accelerate research impact. CACTUS’ portfolio of products and services meet a wide spectrum of research needs: Editage provides editorial, translation, education, and training solutions for researchers; Cactus Life Sciences offers strategic and tactical scientific content solutions to global life sciences organizations; PubSURE is the first AI-powered scholarly publishing platform connecting journals and researchers; Impact Science ensures wider research impact via dissemination solutions and research engagement with peers, public, and policy makers; Cactus Labs Powering all CACTUS businesses with latest technologies is its innovation and R&D cell. We also incubate seed and early stage start-ups that share its mission to solve global problems with science and technology solutions.

CACTUS is an international enterprise with offices in Tokyo, Seoul, Shanghai, Beijing, London, Princeton, Mumbai, Bangalore, and Singapore; a global workforce of over 3,000 experts; and customers from over 173 countries.

People with an international work experience will feel at home with the work culture at CACTUS.

The opportunity

We are looking for a kick-ass Intern, Data Science Developer for our Research and Development cell Cactus Labs. You will work directly with the Chief Technology Officer’s team on interesting real world business challenges.

We are a 130+ agile and driven technology team. Our products have a global reach with users in 170+ countries. We are hosted completely on Amazon cloud and employ various technologies like (but not limited to) AngularJS, Laravel, PHP, Solr, MySQL, PostgreSQL, Elasticsearch, Nodejs, Mongodb, Python, Tensorflow, Pytorch, Flair and more.

Unlike most techies, we are extremely social and believe that happiness levels are directly linked to performance. We are generous with our lunchboxes, quirks, smiles, and pranks – all of which help us maintain a vibrant work environment. What’s more - with the best work hours ethic in the industry and a company policy that takes fun very seriously, we make sure that we work hard and party harder!

To know more about CACTUS Tech, please visit https://tech.cactusglobal.io/

You fit the bill, if you:
Are extremely driven and can work independently
Consider yourself a techie and a hacker
Have implemented a solution in one or more programming language
Can explore, work with data, find solutions and create proof of concepts
Required skills & experience:
Experience with Python and working knowledge of python notebooks
Experience with technical tools for data analysis like NumPy, pandas, R, SQL, etc.
Some experience with data wrangling and visualization
Experience with Tableau, H2O, AWS cloud, machine learning a plus
What’s in it for you?
Global exposure: work in a global organization and interact with colleagues from different nationalities.
Learn & Grow: Our goal is to keep you as long possible and help you build a career with us. We do this by creating an environment where you will grow both personally and professionally.
Culture & Team: We never stop recruiting the best people because without an amazing team nothing is possible. People at CACTUS are awesome to work with, driven, smart and know how to get things done like nobody else.",3.7,"Cactus Communications
3.7",Mumbai,"Mumbai, India",1001 to 5000 employees,2002,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
223,Customer Data Scientist,"Company Overview

H2O.ai is the open source leader in AI with a mission to democratize AI for everyone. H2O.ai is transforming the use of AI with software with its category-creating visionary open-source machine learning platform, H2O. More than 18,000 companies use open-source H2O in mission-critical use cases for Finance, Insurance, Healthcare, Retail, Telco, Sales and Marketing. H2O Driverless AI uses ""AI to do AI"" in order to provide an easier, faster and cost-effective means of implementing data science. H2O.ai partners with leading technology companies such as NVIDIA, IBM, AWS, Intel, Microsoft Azure, and Google Cloud Platform and is proud of its growing customer base which includes Capital One, Progressive Insurance, Comcast, Walgreens, and MarketAxess. For more information and to learn more about how H2O.ai is driving an AI Transformation, visit www.h2o.ai.

Job Summary:
Can you code proficiently in at least one language used by data scientists and/or data engineers, and does it excite you to learn more?
Are you skilled at predictive modeling?
Do you view communication skills just as important as technical ones?
Can you listen to the needs of your peers and customers and adapt where need be?
Do you have a competitive drive to be the best you can be?
Can you finish what you start?
Can you own assignments given to you?
If the answer is ""yes"" to these questions, you potentially could be an excellent fit to join the team of customer engineering makers at H2O.ai. We deliver world-class solution experiences for our customers and drive revenue for our organization. Some of the technical projects you will work on include: training advanced machine learning models at scale in distributed environments, influencing next-generation data science tools and data products, and pioneering ideas and products in new areas, such as machine learning interpretability, automatic machine learning, model management, deployment pipelines, and GPU computing.

Responsibilities and Duties:

As a Customer Data Scientist, you will be part of Customer Success team working closely with sales directors to:
Problem solve and assess technical problems, determine solutions, and work with internal engineering and customer teams to resolve them.
Demonstrate ML solutions with engaging storytelling and technical accuracy.
Architect, Design, and Deliver end to end machine learning workflows and systems from data ingestion to model deployment.
Provide best practices and guidance to customers on machine learning workflows and systems from data ingestion to model deployment.
Own account-related technical activities and relationships.
Translate business use cases and requirements into technical ones.
Communicate effectively to a diverse audience, including engineers, business people, and executives. Audiences will be large and small, and interactions will be in-person and online.
Drive field feedback back into product development and be very hands-on for all technical activities.
Qualifications and Skills
Bachelor's degree in engineering, computer science, mathematics or a related field. A graduate degree is a plus.
2+ years experience with performing hands-on Data Science and Machine Learning
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Visualization skills using R, Python or other languages and frameworks.
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, and proper usage, etc.) and experience with applications.
2+ years experience using statistical computer languages (R, Python, etc.) to manipulate data and draw insights from large data sets.
2+ year working with data in Hadoop and /or Spark ecosystem
Desirable: Maker mindset, coachable, and have an urge to learn/master new technologies
Work Location - Chennai

H2O.ai Perks!
Flexible work hours and time off.
H2O.ai is an equal opportunity employer. We welcome and encourage diversity in the workplace regardless of race, gender, sexual orientation, gender identity, disability or veteran status.

Powered by JazzHR",4.1,"h2o.ai
4.1",Chennai,"Mountain View, CA",201 to 500 employees,2011,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
224,Senior Data Scientist and Machine Learning Engineer,"Job Title:
Senior Data Scientist and Machine Learning Engineer

Location:
India, Bangalore
Role Overview:


Job Title:
Senior Data Scientist and Machine Learning Engineer

Work Location:
Bangalore, MIC

Role Overview:
McAfee is seeking an experienced data scientist to work on our next-gen threat assessment platform. In this position, you will work with experienced developers, security researchers and data scientists to understand, design and implement solutions to the problems found in todays fast-changing security landscape. You will also work with development teams in Oregon, UK and India as they maintain and extend our existing classification systems.

Company Overview:
From device to cloud, McAfee provides market-leading cybersecurity solutions for both business and consumers. McAfee helps businesses orchestrate cyber environments that are truly integrated, where protection, detection, and correction of security threats happen simultaneously and collaboratively. For consumers, McAfee secures your devices against viruses, malware, and other threats at home and away. With the mission of capturing the biggest market share in the area of cyber security, network security, endpoint security, threat research, malware research, cloud security, we work together for a common goal of shaping the companys future by designing and building best in class cyber security solutions.

About the role:
In this role you will collect and analyze data to spot trends and help the company face the challenges of an evolving security landscape. Design, develop, debug & test complex software in the field of data science. Manipulate large volumes of data, create new solutions for data collection, usage and malware classification. Work with stakeholders (developers and malware researchers) to develop and review designs and requirements to analyze data and build effective ML models. This position requires knowledge of security practices, procedures and capabilities in order to perform non-repetitive, analytical work.

About you:

• You have the following required knowledge, skills and abilities:
Displays understanding of and ability to use programming languages: C++, Python, C#, and SQL.
Possesses a strong knowledge of security research (malware analysis tools, filetypes), statistics, programming, data mining, machine learning, algorithms and advanced mathematics.
Demonstrated ability to think and research creatively.
Displays exceptional organizational skills and is detail oriented.
Excellent verbal and written communication skills.
Able to convey stories told by the data and presents them to other scientists.

• Education and Experience
Masters degree in an advanced computer programming field.
5+ years experience working in security research, data mining or natural language processing.

Company Benefits:
Our corporate culture and values are central to McAfees philosophy. Every day we embrace a more diverse workforce and inclusive environment. We are encouraged to bring your true selves to work. Our wide range of social communities & programs, flexible work hours and family-friendly benefits, all allow our employees to feel valued as people, while enjoying positive and challenging work. Check out more: Careers & Life at McAfee. Perks include:
• Pension / Retirement Programs
• Medical, Dental and Vision Coverage Programs
• Support for Community Involvement and Programs



Company Overview


From device to cloud, McAfee provides market-leading cybersecurity solutions for both business and consumers. We help businesses orchestrate cyber environments that are truly integrated, where protection, detection, and correction of security threats happen simultaneously. For consumers, McAfee secures your devices against viruses, malware, and other threats, both at home and away. We want to continue to shape the future of cybersecurity by working together to build best in class products and solutions.

Uses predictive modeling, statistics, Machine Learning, Data Mining, and other data analysis techniques to collect, explore, and extract insights from structure and unstructured data . Develop software, algorithms and applications to apply mathematics to data, perform large scale experimentation and build data driven apps to translate data into intelligence, solve a variety of business problems and enable business strategy. Assists business with casual inferences & observations with finding patterns , relationships in data. Must possess strong understanding of internal business segment (stakeholders) and possess strong written and communication skills. Typically requires expertise in relational database structures, research methods, machine learning, Cloud based technologies, Big Data technologies (i.e. Hadoop , HBase, Lucene/Solr), analytics packages (i.e. R, Mahout, Matlab, Octave, Weka), scripting languages (i.e. Python, Perl), programing languages (i.e. Java, C/C++, SQL). Typically possesses advanced degree in Computer Science, Mathematics, Machine Learning, Operation Research, and Statistics or equivalent expertise.

Company Benefits and Perks:


We work hard to embrace diversity and inclusion and encourage everyone at McAfee to bring their authentic selves to work every day. We offer a variety of social programs, flexible work hours and family-friendly benefits to all of our employees.
Pension and Retirement Plans
Medical, Dental and Vision Coverage
Paid Time Off
Paid Parental Leave
Support for Community Involvement
We're serious about our commitment to diversity which is why McAfee prohibits discrimination based on race, color, religion, gender, national origin, age, disability, veteran status, marital status, pregnancy, gender expression or identity, sexual orientation or any other legally protected status.

Job Type:


Experienced Hire

Primary Location:
India, Bangalore

Additional Locations:",3.6,"h2o.ai
4.1",Chennai,"Santa Clara, CA",5001 to 10000 employees,1987,Company - Private,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Palo Alto Networks, NortonLifeLock, CrowdStrike"
225,DATA SCIENTIST,"Should have a Master’s degree in Statistics, Mathematics, Computer Science

Responsibilities Include:
Interacting with the stakeholders, within the company and the customers, to understand the needs
Exploratory analysis from the existing data
Formulating the questions to be answered and hypotheses to be tested
Identifying additional data to be collected and third-party data sources that will help the analysis
Developing data presentations, models and algorithms required
Using data analysis tools and algorithms and to build “prototypes” to obtain stakeholders’ feedback
Providing inputs and support to software / firmware developers to build the required software components, data structures and dashboards
Interact with other project team members to adhere to overall project schedules
Ensure Adherence to internal development policies and participating in continually improving existing processes

Mandatory Technical Abilities:
Strong problem-solving skills with an emphasis on product development
Experience using statistical computer languages (R, Python…) to manipulate data and draw insights from large data sets
Experience of working with and creating data architectures
Experience of analyzing data from 3rd party providers (Google Analytics, SiteCatalyst, Coremetrics, Crimson Hexagon…)
Experience with data analytics and visualization tools (Tibco Spotfire, Business Objects…)
Proficiency in using query languages such as SQL, Hive
Experience with NoSql databases (MongoDB, Cassandra…)
Knowledge of machine learning techniques (classification, clustering, decision tree, artificial neural networks, etc.) and their real-world applications, advantages/drawbacks
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, Bayesian statistics, Inferences...) and experience with applications
Good written and verbal communication skills for coordinating across teams
Ability to learn and master new technologies and techniques",3.8,"Alpha ICT LLP
3.8",Maharashtra,"Pune, India",51 to 200 employees,-1,Other Organisation,-1,-1,Unknown / Non-Applicable,-1
226,Senior Data Scientist,"We are establishing a world class Data Engineering Team in our Digital Centre in Bangalore to service Global Equipment, one of the fundamental departments in Maersk which is responsible for management of all Containers and associated assets. As part of your role, you will collaborate very closely with our business stakeholders spread across the globe in converting business needs into cutting edge data platform products that will deliver significant bottom line impact. If you have a strong data engineering background, are passionate about quality, speed and impact, and have a service mindset, then read on!

Show More
We offer

Joining Maersk will embark you on a great journey with career development in a global organization. As Senior Data Engineer, you will gain broad business knowledge of the company’s activities globally, as well as take part in the digitalization of the transport and logistics industry.

You will be exposed to a wide and challenging range of business issues through regular engagement with key stakeholders across all management levels within Maersk.

You will work and communicate across geographical and cultural borders that will enable you to build a strong professional network. We believe people thrive when they are in-charge of their career paths and professional growth. We will provide you with opportunities that broaden your knowledge and strengthen your technical and professional foundation.

By choosing Maersk’s Technology vertical, you join not only for the role, but for a career. From here your path may take you towards extended responsibilities within Product Service and Engineering, Technology Delivery or Technology Leadership.

We aim to be a world-class professional Technology organization that delivers business value through turning ideas into prototypes and data products driving automation, standardization and innovation. We believe in empowerment where each of us takes ownership and responsibility for developing and implementing new ways of working.

Show More
Key responsibilities

• Be part of a team of highly skilled data engineers and analysts, responsible for designing and developing cutting edge end to end big data products for our global organization
• Build, develop and maintain data models, data automation products, reporting systems and performance metrics that ensure ongoing realization of business value
• Define and utilize statistical methods to solve domain-specific problems in logistics relevant to the organization
• Work closely with internal customers in researching problems and determine the data required to answer specific questions
• Compare and analyze provided statistical information to identify patterns and relationships that can be developed into new initiatives
• Examine, interpret and report results of products to stakeholders in leadership, technology and other departments
• Design appropriate enhancements and recommend alternative approaches, when necessary to drive delivery of superior products
• Train other members of the team how to properly organize findings and read data collected

Show More
We are looking for

• Master’s degree in mathematics, statistics or related field
• Strong math and analytical skills are essential to complete job requirements successfully
• Technical expertise regarding data models, database design development, data mining and segmentation techniques
• Exposure to coding languages like R, Python, Pyspark and Scala
• Able to compile and organize statistical information retrieved and present findings to management
• Good instincts around data analytics with confidence in decision making and the ability to explain processes or choices as needed

Great to have
• Solid experience in contributing hands-on products built within data technologies, ranging from relational databases to big data solutions (Hadoop or Spark)
• Data engineering and pipeline technology experience - particularly open source and modern frameworks
• Familiarity and experience with Azure services particularly DevOps, Data Factory and Databricks in implementing new applications

Generic Skills

• Fluent and effective communication in both written and oral English
• An excellent team player who can at the same time demonstrate strong autonomy and high motivation to produce individually with a “can do” attitude
• Someone who is open to new ideas, demonstrates steep learning curve and is innovative in approach
• Able to work in remote teams for a large program and distributed organization while showcasing a service mindset
• Willingness and interest to travel when required to be close to our internal customers

Show More",3.9,"Maersk Group
3.9",Bengaluru,"Copenhagen, Denmark",10000+ employees,1928,Subsidiary or Business Segment,Shipping,Transportation & Logistics,₹100 to ₹500 billion (INR),-1
227,Senior Business and Data Analyst,"Locations: Bangalore, Data Science & Analytics, Mountain View, New Jersey

We are looking for a Business and Data Analyst for a growing portfolio of customers. As a member of the TV Retargeting products, analytics and business operations team, you will have a huge impact on our business and the success of our customers. You will be one of the early members of the team and will help shape the growth of this team. You should have interest in solving business challenges using data, gathering requirements, analyzing use cases and working towards efficient solutions.

Responsibilities:
Work with our Sales and Account Managers to understand customers’ KPIs and goals
Work with Business Operations team to launch new and optimize ongoing TV Retargeting digital media campaigns
Create case studies by analyzing past viewership and exposure data
Work closely with the data engineering team to understand the underlying drivers of positive and negative performance across our customers
Develop and run data science experiments and interpret the results
Implement the insights gained from your experiments across customers
Proactively communicate the key insights from the performance to the relevant internal teams: sales, account management and engineering
Communicate your ideas for improvement for our internal toolset within the TV Retargeting product and engineering team
Lead an industry vertical like automotive, entertainment, CPG, and others
Mentor team of Business Analysts

Requirements:
Strong analytical background and critical thinking
Strong organizational skills and attention to detail
Ability to thrive in a fast-paced, high-volume, and deadline-driven environment
Engineering and Technical degree preferred.
Marketing / Advertising / Analytics related experience is preferred but not necessary
Familiarity with the TV or Digital advertising ecosystem is helpful, but not required
Experience with a scripting programming language and SQL is helpful, but not required
Experience leading a vertical and managing teams",4.1,"Alphonso
4.1",Bengaluru,"Mountain View, CA",51 to 200 employees,2012,Company - Private,TV Broadcasting & Cable Networks,Media,Unknown / Non-Applicable,-1
228,Data scientist,"Job Description
Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.
Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
Develop company A/B testing framework and test model quality.
Coordinate with different functional teams to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.
· Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.
· Experience working with and creating data architectures.
· Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks
Functional Area : Information Technology

Seniority Level : Mid-Senior level

Annual Total Earnability : INR 9 - 12 (LPA)

Job ID : 10003454

Opening : 1

Closure Date :
29-07-2020

Contact Person : Priyanka Sethi

Apply Now",3.8,"Trident Group
3.8",Ludhiana,"Ludhiana, India",10000+ employees,1990,Company - Private,Miscellaneous Manufacturing,Manufacturing,₹100 to ₹500 billion (INR),"Welspun Group, Bombay Dyeing, Vardhman Yarns & Threads"
229,"Machine Learning Engineer / Architect Pune, Maharashtra","Operations

Cloud Management / Office of the CTO

Are you excited about machine learning and artificial intelligence, but not sure how to get involved? Were you impressed by recent AI/ML breakthroughs like AlphaGo, and are curious to see how these advances can transform the modern enterprise?

Join us.

VMware is launching a machine-learning initiative for cloud applications, and we're looking for a talented machine learning engineer to help our small, dedicated team build the future.

As a part of our top-secret project, you'll employ cutting-edge ML/AI research to craft our operational platform directly in Tensorflow, working with live application and more data than you've ever seen before. You'll also use your skills to take early prototypes all the way to production-quality code, working with our team to instrument and monitor a business-critical platform.

We're a veteran team of machine learning and infrastructure software experts, with backgrounds ranging from search engines to financial payments to databases. We've collectively built some of the largest, state-of-the-art data pipelines in the world. But there's a missing piece of the puzzle - you.

Job Role and Responsibility:
Responsible for leadership of key initiatives within the machine learning team
Ability to lead teams and work individually on projects to implement software solutions into product
You'll implement core ML algorithms for application control/optimization directly in Tensorflow/python.
You'll work with the ML Architecture team to implement novel and ground-breaking approaches to performance observability and improvement.
You'll work with our Integration engineering team to make the entire system operationally robust and observable.

Required Qualifications:
You have a strong and broad background in Tensorflow or another deep learning framework (Torch/PyTorch, Theano, MXNet, Caffe, etc).
You have 7+ years of production software engineering experience.
You have a working familiarity with the mathematical foundations of machine learning, including linear algebra, backpropogation, and common activation functions.
You have some understanding of GPU vs. CPU performance for different model architectures.
You have experience with modern source control (git, svn, etc).

Preferred Qualifications:
You have strong self-motivation and interpersonal skills
You have experience with high-data-volume training and inference.
You understand CUDA.

Category : Engineering and Technology
Subcategory: Software Engineering
Experience: Business Leadership
Full Time/ Part Time: Full Time
Posted Date: 2020-04-09

VMware Company Overview: At VMware, we believe that software has the power to unlock new opportunities for people and our planet. We look beyond the barriers of compromise to engineer new ways to make technologies work together seamlessly. Our cloud, mobility, and security software form a flexible, consistent digital foundation for securely delivering the apps, services and experiences that are transforming business innovation around the globe. At the core of what we do are our people who deeply value execution, passion, integrity, customers, and community. Shape what’s possible today at http://careers.vmware.com.

Equal Employment Opportunity Statement: VMware is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any Kind: VMware is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at VMware are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. VMware will not tolerate discrimination or harassment based on any of these characteristics. VMware encourages applicants of all ages. Vmware will provide reasonable accommodation to employees who have protected disabilities consistent with local law.",4.3,"VMware
4.3",Pune,"Palo Alto, CA",10000+ employees,1998,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),-1
230,Advanced Multiscale Process Modeling Engineer,"Relocation Level: Domestic

Hiring Manager: Sumeet Pandey

Recruiter: RAGHUNATH RAO PASUPULATY

Micron Technology’s vision is to transform how the world uses information to enrich life and our commitment to people, innovation, tenacity, collaboration, and customer focus allows us to fulfill our mission to be a global leader in memory and storage solutions. This means conducting business with integrity, accountability, and professionalism while supporting our global community.

As an Advanced Modeling Engineer in the Technology Development Group at Micron Technology, Inc., you will be responsible for developing first-principles physical, chemical, thermal, mechanical, materials, and statistical/ML/AI models for unit processes (such as, Plasma etch, Wet etch, ALE, CVD/ALD/Diffusion, PVD, CMP, etc. that enables manufacturing of next generation memory chips). You will model the unit process at multiple length scales, calibrate against process data, and train the models to provide for predictive unit-process modeling capability. You will contribute and develop modeling workflows, platforms, and applications working with other members of the TDE modeling team.

Responsibilities include but are not limited to:
Development of unit-process models and its cross-interactions in a process flow
Perform process space exploration, and statistical studies to derive margin and sensitivity
Perform process simulations, validation, optimization, and devise predictive control strategies
Build unit-process models to better predict memory scaling roadmap
Estimate impact of process on structural stability, electrical performance, yield, and reliability
Model and simulate processes at reactor-, wafer-, die-, and feature-scale
Modeling of plasma in reactor/equipment, plasma-surface/materials interactions, and feature profile evolution
Process simulations using various methods: MC, MD, phase-field, cellular-automata, level-set, computational fluid dynamics (NS and LBM), reactive multiphase flows, micro-/nano-fluidics, immersed boundary, mesh-free, and various finite-differences, finite-elements, and finite volume simulations of mass, heat, and fluid transport
Perform mesh generation, structure conversions, algorithms and software development, large-scale visualization, and parallel programming
Development of advanced numerical methods, meshing algorithms, multi-scale modeling and coupling schemes, and stand-alone applications
Work with process teams and equipment suppliers to deliver process-equipment models to process teams
Develop stress/strain models that captures process-induced deformation and failures using finite element structural mechanics, thermo-mechanical, and fluid-structure simulations
Apply and implement ML/AI techniques for process analytics
Design, develop, test, deploy and maintain applications/software
Qualifications:
3+ years of experience in the use of process modeling tools
3+ years of experience in multi-scale multi-physics modeling/simulations
2+ years of experience in statistical, machine learning, and AI techniques
2+ years of experience with stress/strain modeling
Strong background in thermodynamics and kinetics
Strong background in semiconductor processes and fabrication
Strong background in machine learning algorithms and image processing
Strong knowledge of solid mechanics
Experience with application development is strongly desired
Excellent verbal and written communication skills with the ability to operate across large teams in a fast-paced dynamic environment
Education:
A MS/M.Tech or PhD in Chemical Engineering, Electrical Engineering, Computer Science, Materials Science, Physics, Chemistry, Mechanical Engineering, or related discipline.
About Us

As the leader in innovative memory solutions, Micron is helping the world make sense of data by delivering technology that is transforming how the world uses information. Through our global brands - Micron, Crucial and Ballistix - we offer the industry's broadest portfolio. We are the only company manufacturing today's major memory and storage technologies: DRAM, NAND, NOR and 3D XPoint™ memory. Our solutions are purpose built to leverage the value of data to unlock financial insights, accelerate scientific break throughs and enhance communication around the world.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.

Keywords: Hyderabad || Andhra Pradesh (IN-AP) || India (IN) || Technology Development || Experienced || Regular || Engineering || #LI-RR1 || Tier 4 ||",3.5,"Micron
3.5",Hyderabad,"Boise, ID",10000+ employees,1978,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Samsung Electronics, SK hynix, Toshiba"
231,Associate Data Scientist - MFG,"Noodle's Data Scientists build advanced AI models that change the way our clients do business by empowering them to make better decisions. Our solutions impact small and large businesses ranging from media, to retail companies, to airlines, to e-commerce, financial services, to government agencies. Members of our Data Science team are passionate about problem solving with applied data science and work with clients to explore, specify, and communicate high-value, AI- based solutions. We geek out about AI technology.

As a Data Scientist at Noodle.ai, you will collaborate with the Noodle Client Service team, Data Engineers, SW Engineers, UX Designers, and industry-specific experts from our client companies to build a deep understanding of our clients' business context and then develop, test, and deploy advanced AI models. As we grow, you will also develop reusable IP to help us move faster, dive deeper, and work more efficiently by generalizing the models, methodologies, and supporting infrastructure that you build. As one of the early hires to join the Noodle.ai team, you will have a significant impact on the future of Enterprise Artificial Intelligence.

Qualifications:

Must haves
1+ years of experience in applied artificial intelligence technologies including machine learning, predictive data analytics, and/or data science
BE/B.Tech or Advanced degree in a relevant field (Computer Science, Operations Research, Statistics, Mathematics, Electrical Engineering, or other Computational Science)
Proficient in python
Experience with spark
Knowledge of data science/machine learning concepts
Demonstrated ability to iteratively conceptualize, design and build data-driven analytical models
Strong capabilities in modern analytics languages/tools
Collaborative, open, and respectful working style
Passion for learning and a desire to grow – Noodlers are life-long learners!
Nice to haves
Experience applying advanced AI techniques (g., machine learning, predictive analytics. optimization, semantic analysis, time-series analysis, advanced visualization) to real-world problems
Experience with R
Experience manipulating and preparing large, heterogeneous data sets (""Big Data"") to support advanced analytics
Demonstrated energy and passion that extends beyond your field of study – Are you a computer scientist who writes poetry? A mathematician who loves psychology? An engineer passionate about public policy? We want to build something with
Experience with (and excitement for) interdisciplinary collaboration",4.5,"Noodle.ai
4.5",Bengaluru,"San Francisco, CA",201 to 500 employees,2016,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹1 to ₹5 billion (INR),-1
232,Data Scientist / Machine Learning Engineer,"Sony Corporation of America, located in New York, NY, is the U.S. headquarters of Sony Corporation, based in Tokyo, Japan. Sony's principal U.S. businesses include Sony Electronics Inc., Sony Mobile Communications (USA) Inc., Sony Interactive Entertainment LLC., Sony Pictures Entertainment Inc., Sony Music Entertainment, and Sony/ATV Music Publishing LLC. With some 900 million Sony devices in hands and homes worldwide today, a vast array of Sony movies, television shows and music, and the PlayStation Network, Sony creates and delivers more entertainment experiences to more people than anyone else on earth. To learn more: www.sony.com.

Sony’s new Research and Development Center will be established in Bangalore / Mumbai, India by end of 2020. Would you like to be a part of that team?

We are looking for excellent candidates possessing relevant information technology-related skills who are currently working in USA and are willing to relocate to India.

Key Responsibilities

Together with the lead data scientist or other team members, try to address Sony's various business pain points and propose technical or business level solutions.

Responsibilities include:
Research and develop a novel recommender system for OTT service
Research, develop, evaluate, and optimize recommender algorithms using actual log data Executing feature engineering, model selection and other optimization to improve accuracy Design data flow, MLOps flow, A/B test, monitoring, and other connected systems with the Sony engineering team Collaborate with UI/UX designers to realize effective user experience
Research and develop algorithms for growth of OTT service
New customer acquisition, churn prevention Causal inference / explainable AI for business action and customer insight Novel adaptive UX And others
Research various technology fields in data science for other entertainment business
Interlinkage
R&D Center of Sony Tokyo, US, Europe, etc.
Sony Pictures Networks India in Mumbai
Other Sony development team in India, Japan and US
Work Location
Mumbai, Bangalore
May need to stay for a few weeks in Tokyo / US
Essential Education / Qualifications / Experience
Academic basis for data science:
Computer science (> bachelor) Basic mathematics (linear algebra, statistics etc.) Machine learning (Classification/regression models, reinforcement learning, statistical learning theory, mathematical optimization etc.)
3+ years of professional experience of developing recommender systems in commercial systems
Professional experience of the following languages, software, tools: Python (scikit-learn, pandas, TensorFlow, PyTorch, etc.) (3+ years) Any other object-oriented languages (Java, C++, C#, Kotlin etc.) (2+ years) SQL/KVS Linux
Preferred Qualifications / Experience
Publication records in top-tier conferences such as NeurIPS, ICML, KDD, RecSys or equivalent.
Building data analysis environment (AWS/GCP, container technologies, distributed system like Hadoop/Spark etc.)
Professional experience on experimental design and causal effect inference from observational data.
Professional experience with any kind of machine learning systems in production
Experience with MLOps Experience in Kaggle competition
Critical Success Factors
Strong will to contribute Sony’s entertainment business with technologies
Good communication skills with engineer side (data scientists, machine learning engineers, system engineers etc.) and business side (business planner, marketer, sales etc.)
Positive attitude and genuine enthusiasm for data-driven business process
Sony is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religious creed, sex (including pregnancy), gender, national origin, citizenship, ancestry, age, physical or mental disability, military status, status as a veteran or disabled veteran, sexual orientation, gender identity or expression, marital or family status, genetic information, medical condition, or any other basis protected by applicable federal, state, or local law, ordinance, or regulation.

Disability Accommodation for Applicants to Sony Corporation of America

Sony Corporation of America provides reasonable accommodation for qualified individuals with disabilities and disabled veterans in job application procedures. For reasonable accommodation requests, please contact us by email at careers@sonyusa.com or by mail to: Sony Corporation of America, Human Resources Department, 25 Madison Avenue, New York, NY 10010. Please indicate the position you are applying for.",3.5,"Sony/ATV Music Publishing
3.5",Bengaluru,"New York, NY",51 to 200 employees,-1,Company - Private,Music Production & Distribution,Media,₹1 to ₹5 billion (INR),-1
233,Machine Learning Engineer,"We are looking for a Machine Learning (ML) Engineer to help us create artificial intelligence products. Machine Learning Engineer responsibilities include creating machine learning models and retraining systems. To do this job successfully, you need exceptional skills in statistics and programming. If you also have knowledge of data science and software engineering, we'd like to meet you. Your ultimate goal will be to shape and build efficient self-learning applications.

Responsibilities:
Designing and developing machine learning and deep learning systems.
Running machine learning tests and experiments.
Implementing appropriate ML algorithms.
Study and transform data science prototypes.
Design machine learning systems.
Research and implement appropriate ML algorithms and tools.
Develop machine learning applications according to requirements.
Select appropriate datasets and data representation methods.
Run machine learning tests and experiments.
Perform statistical analysis and fine-tuning using test results.
Train and retrain systems when necessary.
Extend existing ML libraries and frameworks.
Keep abreast of developments in the field.

Requirements:
Proven experience as a Machine Learning Engineer or similar role.
Understanding of data structures, data modeling and software architecture.
Deep knowledge of math, probability, statistics and algorithms.
Ability to write robust code in Python, Java and R.
Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn).
Excellent communication skills.
Ability to work in a team.
Outstanding analytical and problem-solving skills.
BSc in Computer Science, Mathematics or similar field; Master's degree is a plus.",3.9,"Involvio
3.9",Bengaluru,"New York, NY",1 to 50 employees,-1,Company - Private,Colleges & Universities,Education,Unknown / Non-Applicable,-1
234,Machine Learning Scientist,"Description

Job Responsibilities

Machine Learning Scientist, Hyderabad

This is an open invitation for India’s best in class Machine Learning Scientist - Product Engineering to join the disruptive technology and thought leader in the global Talent Relationship Marketing Cloud Platform. If you live & breath engineering by solving not only engineering problems but are passionate about building state of the art products that help a billion+ job seekers, then welcome to Phenom People. At Phenom we build products that connect right fit talented candidates (job seekers) with companies seeking for Phenomenal talent. We help companies establish, nurture and mature relationship with talented candidates through the hiring life-cycle. Based in Greater Philadelphia area, we server global fortune 500 companies. To know more about Phenom People, visit phenompeople.com
Looking for talented engineers with interests in Machine Learning & Data Science
Build amazing products, you will shape the future of our products
What you will do:
Design and implement machine learning, information extraction, probabilistic matching algorithms and models
Research and develop innovative, scalable and dynamic solutions to hard problems
Work closely with Machine Learning Scientists (PhDs), ML engineers, data scientists and data engineers to address challenges head on
Use the latest advances in NLP, data science and machine leaning to enhance our products and create new experiences
Scale machine learning algorithm that powers our platform to support our growing customer base and increasing data volume
Be a valued contributor in shaping the future of our products and services
You will be part of our Data Science & Algorithms team and collaborate product management and other team members
Be part of a fast pace, fun focused, agile team
Job Requirements
1+ years of industry experience (Not Mandatory)
Ph.d in computer science, information systems, or similar technical field
Strong mathematics, statistics, and data analytics
Solid coding and engineering skills preferably in Machine Learning (not mandatory)
Proficient in Java, Python, and Scala
Industry experience building and productionizing end-to-end systems
Knowledge of Information Extraction, NLP algorithms coupled with Deep Learning
Experience with data processing and storage frameworks like Hadoop, Spark, Kafka etc.
Education
Ph.D in computer science, information systems, or similar technical field
About Company

At Phenom People, we believe great people build great companies. We know that there is no difference between marketing and selling products and jobs, so we took CRM best practices and applied them to talent acquisition and built the world’s first Talent Relationship Marketing platform.

Candidates today are not job hunters; they are savvy shoppers. They expect a certain quality of user experience when browsing jobs, researching companies and applying for positions - an experience traditional recruiting tools and tactics cannot deliver. Welcome to the talent relationship business.

TRM is an automated system for managing the talent relationship lifecycle of current and future candidates, driving awareness, interest, engagement and acquisition. Our Phenom TRM platform aligns the objectives, priorities and actions of candidates, recruiters, hiring managers and talent acquisition leaders.

Phenom People strives to be the most innovative HR tech company in the world. By offering unique, engaging experiences for candidates, our platform helps put the right opportunity in front of the right person at the right time so you can continue to build phenomenal teams and achieve business goals for years to come. Stop recruiting. Start relationship marketing.

Explore Location
Close the mapbox popup

No locations found

Apply Now
Add To Cart",4.3,"Phenom People
4.3",Hyderabad,"Ambler, PA",501 to 1000 employees,2011,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
235,Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision),"Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision)

With over 1900 researchers, Corporate Technology (CT) occupies a special position within Siemens' R&D facilities. It functions as an international network of expertise and as a global partner for technology and innovations.

Our Research Group (Advanced Data Management) is part of Business Analytics and Monitoring (BAM) Technology Field of CT Research. Headquartered in Munich, we are a hardworking distributed team of around 240 researchers, data scientists and architects distributed across the globe. In the team in Bangalore where we are based out of, we strive to seek complex problems in various domains ranging from mobility, industry, energy, and buildings to smart cities by applying methods and principles of data analytics and artificial intelligence. We are looking for equally hardworking techies to join us in this exciting journey of finding innovative solutions to some non-trivial industrial problems.

Change the Future with us

• You will analyze large, complex data sets by developing advanced machine learning and deep learning pipelines based on business initiatives.

• Your ability to move beyond theoretical models and build innovative, practical and robust real-world solutions for problems in traffic management, autonomous building control for energy and comfort optimization, medical image analysis for assisting pathologists/radiologists, smart robotics for Industry 4.0 will make valuable contribution.

• You will find it exciting to dive deep into an ocean of data and seek challenges associated with transforming and enriching large complex datasets.

• You will drive innovation and research in the form of patents and publishing papers at outstanding conferences/journals?

What you need to make real what matters

• You have PhD/Masters/Bachelors degree in Computer Science or related field from a reputed institute with grass-root experience of at least 2 years in solving complex problems.

• Closely follow the latest developments in artificial intelligence and be an early adopter of disruptive trends/technologies

• Collaborate with team members from prototyping through production, present developed solutions and recommendations to business partners, and influence future product roadmap and strategy based on insights

• Research, develop and prototype software technologies related to Object detection, tracking, 3D reconstruction, SLAM and photometric stereo

• Experience in Machine Learning techniques such as Forecasting, Classification, Clustering, Text Mining, Decision Trees, Random Forest and Search algorithms

• Understanding and tried hands-on experience in training deep convolutional and/or recurrent networks using frameworks like Tensorflow, Caffe, MXNet, etc.

• Minimum of 1-2 years experience working on image processing and computer vision problems with a clear understanding and ability to implement algorithms (especially deep learning algorithms)

• Hands-on experience using OpenCV and OpenGL

• Optimization techniques for model training and deployment on GPUs

Make your mark in our exciting world at Siemens

This role is based in Bangalore. Youll also get to visit other locations in India and beyond, so youll need to go where this journey takes you. In return, youll get the chance to work with teams impacting entire cities, countries and the shape of things to come.

Were Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality, and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination, and help us shape tomorrow.

Find out more about department at: Corporate Research, Siemens India at www.ct.siemens.com and about Siemens careers at: www.siemens.com/careers

Organization: Corporate Technology

Company: Siemens Technology and Services Private Limited

Experience Level: Mid-level Professional

Job Type: Full-time",4.0,"Siemens
4.0",Bengaluru,"Munich, Germany",10000+ employees,1843,Company - Public,Electrical & Electronic Manufacturing,Manufacturing,₹500+ billion (INR),"GE, ABB, Philips"
236,DATA SCIENTIST,"Employment: Full time.

Role: Data Scientist

Job Summary

We are looking for experienced data scientists with strong advanced analysis and machine learning model development experience. Data scientists will be working with a team of technical experts on the development of a scalable, real-time, big data analytics solutions with data visualizations leveraging the latest technologies. The ideal candidate will have a proven track record of solving large, complex big data challenges and developing machine learning models to address emerging cybersecurity requirements. Responsibilities will include the analysis of the data to uncover useful and valuable information and finally supporting the engineering team to build the results into the end product. You will be working with an experienced team of data scientists and technical experts, and be part of the Security, Risk, and Governance (SR&G) solutions Centers of Excellence (COE). This position is responsible for the design, architecture, development, and implementation of emerging Security and Operations use cases, and partner with R&D engineers to productize the same to support go-to-market initiatives.

Responsibilities and Duties
Collaborate with a multi-disciplinary team of engineers and analysts on a wide range of cybersecurity problems.
Bring analytical rigour and statistical methods to the challenges of measuring quality, improving security products, and understanding the behaviour of end-users, computer systems, and network devices.
Build innovative predictive analytics and data science solutions for a myriad of cybersecurity problems.
Multi-task and work independently
‘Think like an adversary’
Identify and articulate risks and remediation in a relevant and approachable manner with both technical and non-technical audiences.
Identifies data sources, collects, transforms and prepares large amounts of data for analysis. May also develop tools to help the data collection process as needed.
Uses appropriate methods, tools, and algorithms to analyze the data and create an implementation plan from the business problem.
Validates the results of the data analysis to avoid errors.
Interprets results and identifies value form the analysis to help solve the business problems. Works with the business or customer and provides guidance on risks and limitations.
Monitors and continuously improves the data sources, usability and data
mining results.

Required Experience, Skills and Qualifications Education and Experience
Bachelor’s or Master’s degree in Computer Science, Statistics or similar quantitative field
3-5 years of working experience in machine learning and data science projects;
2-3 years of experience in working with large scale production data sets
Good understanding of the foundations of machine learning methods
Exceptional coding skills in SQL, and Python or R
Excellent communication skills
Knowledge and Skills

Basic Qualification:
Experience with deep learning methods, models and frameworks
Familiarity with multiple programming and scripting languages (such as Java, Javascript, C/C++, Perl, etc.)
Familiarity with data visualization tools
Experience with passive and active measurement techniques
Experience with applying statistical modelling, machine learning and data mining algorithms to business problems.
A profound understanding of big data systems
Must have:
Background in statistics
Linux System knowledge as user and administrator
Experience with Vertica or other column store databases is a plus
Experience in cybersecurity, network data
Knowledge of networking concepts and devices (Firewalls, Routers, Switches,
and Load Balancers)
Knowledge of network and web related protocols (such as TCP/IP, UDP, IPSEC,
HTTP, HTTPS, DNS, SSH, routing protocols)",-1,Inference Labs,Bengaluru,"Bengaluru, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
237,"Sr Data Scientist - Computer Vision, Deep Learning","What's the role?


As a Senior Data Scientist within Quality Testing and Statistics (QTST), you are passionate about statistical sampling and analytic methods, measurements and machine learning models. You will work with map and location experts, engineering teams and fellow data scientists to develop testing plans, quality benchmarks, and predictive models to deliver analytic insights and solutions enabling the highest levels of quality throughout HERE’s offerings.

• Subject Matter Expert (SME) for sampling and test designs, statistics, analytics, training data, and predictive modeling.• Create summary results and reports with graphs, tables, and charts; provide interpretations to project leaders.• Develop sampling plans for data collection, quality evaluation, and the production of training data. Design and create estimators for the evaluation of map quality along various customer use-cases. Design and analyze A/B experiments that validate different optimization and solution approaches, and to calibrate model parameters.• Build and test statistical and machine learning models to support improvement of a wide variety of data-driven processes for map-making data evaluation and decisions. Develop code, databases, tools, and outputs in the R programming environment.• Work with map experts, engineering teams, and other analytic teams. Provide support to the statistical and analytical needs of various departments within the company.

Who are you?
MS or PhD degree in Statistics, Mathematics, Econometrics, or related fields.
5+ years of related work experience
Proficiency of sampling methods, and analytic methods such as regression, classifiers, clustering, association rules, decision trees, etc.
Proficiency with analysis and programming in R, or any similar package (Python, SAS, etc).
Knowledge and experience with using GIS tools for spatial data analysis.
Knowledge of tools such as Pig, Hive, etc. for working with big data in Hadoop or Spark for data extraction/prep for analysis.
Application of statistics in quality area or Six Sigma will be a plus.
Excellent oral and written communication skills.
What we Offer

We will support you in delivering your day to day tasks and achieving your personal goals and develop your skills. Personal development is highly encouraged at HERE. You can take different courses and trainings at our online University and join cross-functional team projects within our Talent Platform. Our office is located with easy access by public transportation options. So, what are you waiting for? Apply now and make HERE your destination. We are just getting started...!

HERE is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, age, gender identity, sexual orientation, marital status, parental status, religion, sex, national origin, disability, veteran status, and other legally protected characteristics.

Make HERE your destination, we are just getting started! Apply now!

Who are we?


Ever checked in somewhere on social media? Ever tracked your online orders? You might be using HERE Technologies every single day without even realizing it. You can find us everywhere: in vehicles, smartphones, drones or third-party apps. We believe that with the right people, we will continue to be a game-changer in the technology industry and improve the daily lives of people around the world. Find out more by clicking the video below or going HERE.",3.7,"HERE Technologies
3.7",Mumbai,"Amsterdam, Netherlands",5001 to 10000 employees,1984,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Google, TomTom, Apple"
238,Data Scientists,"Looking for Data scientist professionals.

Candidate should be a creative, detail-oriented problem solver with a passion for machine learning and data-driven insights generation.

* You should possess customer-centric thought process and is able to understand client's business processes with ease, identify problems with precision and develop customized, accurate analytical solutions.

Roles and responsibilities

· Translating muddy and fuzzy business needs into clear data science problems through structured problem-solving.

· Perform data collection, develop robust and intuitive predictive models using Statistical/ML/deep learning techniques.

· Research and build statistical/machine-learning models.

· Perform Exploratory Data Analysis and Statistical Analysis; clearly present the results of an analysis to customers and management.

· Research and develop AI based solutions that can be applied to multiple research projects tied to various business needs.

· Transforms business problems into data problems.

· Have the ability to discover new opportunities where advanced analytical techniques can be leveraged for solving business problems.

· Candidate will be expected to communicate insights and recommendations to different stakeholders with various levels of technical knowledge.

· Come up with innovative algorithms and solutions.

Eligibility

- Proficient coding skills in R / Python/ Java/. Master-level skills in SQL and query languages.

- Relevant Data Science experience of 3-6 years in End to end data science project life cycle (data preparation, EDA, modeling, deployment).

- A graduate/master's degree in computer science, applied statistics or a quantitative domain.

- Excellent knowledge of various machine learning algorithms, statistical and optimization techniques.

- Advanced proficiency in at-least one data science language (Python, Scala, R).

- Good modelling and communication skills.

Job Type: Full-time",-1,Light Speed Web Inc.,Coimbatore,-1,-1,-1,-1,-1,-1,-1,-1
239,Data Analyst,"ABOUT THE ROLE

Toppr is looking for a Data Analyst (DA) in its Product Marketing team. You’ll be a part of a core team that drives strategic decisions for product marketing. Your primary responsibility will be to derive insights that improve business performance. You’ll conduct exploratory analyses of large data sets, metrics identification and report creation, and development and maintenance of analytical systems. You’ll broadly influence Toppr’s product, marketing effectiveness and elevate the role of data as an asset to the business.

If you are technically adept with excellent ability to write optimised queries and possess a keen eye for business with a real passion for making an impact, then we’d love to talk to you!

HOW YOU’LL RAMP

In First Week…

● Understand Toppr’s journey, its values and mission.

● Spend time with the Business Intelligence, Marketing, Product, and Sales teams to get up-to-speed on Toppr’s offering, its competition, and future outlook.

By Day 30…

● Answer questions by querying our databases and systems of record while increasing the adoption of data across the company.

● Start to identify and pursue projects that directly drive retention, engagement and revenue.

● Implement a single source of truth by updating existing models and generating new data resources from customer interaction logs, and sales and marketing data.

By Day 90…

● Make recommendations that directly influence business outcomes. Identify areas of opportunity, spin up collaborative teams, and report on successes.

● Coach and mentor your new team members.

● Dig deeper and pick a project that matters to Toppr and its success. By doing so, you’ll be solving problems on a pan-India level.

Requirements

KEY QUALIFICATIONS

● B.Tech/BE from recognized (Tier 1) institutes.

● 1+ years of experience in data analytics, or BA/BS in Statistics, Mathematics, Economics, Computer Science or related field.

Benefits

WHY SHOULD YOU JOIN TOPPR

● Full exposure to all parts of the business: You will partner with and be exposed to every team: an unparalleled opportunity to learn about all the nuts and bolts of a business.

● As the business grows, you grow: We want Toppr to be built from within. We look at you as a business leader with the potential to make Toppr a $10B company.

● Work with the best: Learn from leaders who have built Toppr from the ground up. Work with down-to-earth, highly experienced, and insanely ambitious colleagues.

● High-growth industry: India’s online education industry is an ever-expanding pie and is poised to grow to $2 billion in by 2020.

● High-growth startup: Toppr has grown over 50x in the last 3 years, and we aim to grab a big chunk of this ever-expanding pie.",3.1,"Toppr
3.1",Hiranandani Gardens,"Mumbai, India",51 to 200 employees,2013,Company - Private,Primary & Secondary Education,Education,Unknown / Non-Applicable,-1
240,Scientific Research Data Scientist R&D,"We are looking for self-motivated scientists & engineers to join a supercharged workplace and build a first-generation analytical product. If you are a geek about anything – algorithms, math, machine learning, data wrangling/visualizing, high performance computing, scientific computing & tools, or anything else you can convince us about – we want to talk to you!

Experience
4 - 7 Years of Experience

Qualification

Bachelors or Masters in CS / Electronics from a premier institute with 4-7 years of industry experience
Solid design, excellent programming and debugging skills on a Unix-based OS (Ubuntu, Fedora, OSX) and fluency with a DVCS like Git.
Programming Languages: Python, C++
Deal-clinchers

Any of these – more the better!
Skilled with python packages: scikit-learn, pandas, numpy and scipy
Understanding of common algorithms and their application in solving real-world problems
Strong mathematical background in linear algebra, optimization and descriptive & inferential statistics
Understanding of machine learning concepts like generalization, regularization, linear models, neural network and expertise with using data to build systems based on machine learning techniques
Responsibilities

Individual technical contributor with self-drive to understand problem statements and make design decisions – ‘own’ what you do, make your calls, and defend them
Build a first generation analytical software product – design, code, test (unit & functional) and maintain the software, while proving that your implementations ‘work’
Implement software engineering processes and discipline for fast and reliable development of high-quality software product – make the software ‘elegant’
Work as a team player in a high performance environment that rewards ownership – make your opinion count within the team and the organization
Write to deepa.m@careerxperts.com to get started!

Job Location
Bengaluru",-1,CareerXperts,Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
241,Assistant Manager - Data Scientist,"With a startup spirit and 90,000 curious and courageous minds, we have the expertise to go deep with the world’s biggest brands—and we have fun doing it. Now, we’re calling all you rule-breakers and risk-takers who see the world differently, and are bold enough to reinvent it. Come, transform with us.
Are you the one we are looking for?
We are inviting applications for the role of AM, Data scientist
Role involves to think strategically about data as a core enterprise asset and assist in all phases of the advanced analytic development process
Support advanced analytical and data mining efforts which could include but not limited to clustering, segmentation, logistic and multivariate regression, decision/CART trees, neural networks, time-series analysis, sentiment analysis, topic modeling, random forests, and Bayesian analysis
Responsibilities
The scope of work includes Forecast, Prediction Models, Outlier Reporting, Payment Integrity violation identification, Adhoc analysis
Implementation of Supervised and Unsupervised model development techniques
Work with Data engineers to supervise and help institutionalize models and dashboards for Analytics team of leading Healthcare client
Develops ML models using identified features and packages
Responsible for maintenance and performance monitoring of the production environment for the Advanced Analytics team
Lead the design of complex and large-scale datasets to be used for statistical modeling and data mining.
Slice and dice through the database and come up with actionable analytical insights
Facility with one or more quantitative data analysis languages such as R, SciPy, NumPy, SQL, Python, SAS, SPSS
Experience with relational database management systems (Oracle, Teradata, SQL Server, DB2..)
Works with key stakeholders to generate and test hypotheses
Experience with contemporary big data technologies (Hadoop, HIVE, PIG, MapReduce)
Facility with one or more data analytical methods such as regression, decision trees, experimental designs, support vector machines, machine learning and text mining
Proficiency with Microsoft Office Suite
Work in a dynamic and fast-paced environment without compromising the quality
Conduct explanatory data analysis and prepare data sources to be analyzed.
Excellent domain knowledge on US Healthcare is must
Qualifications we seek in you
Minimum qualifications
Bachelors or Master’s degree with specialization in statistics, applied mathematics, economics, finance, computer science or Information systems/science; Preference given to candidates with demonstrated academic achievement in core subjects and proficiency in quantitative subject matter (Advanced Statistics coursework, Predictive Modeling projects). Familiarity with PBM or Healthcare industry.
Relevant Healthcare domain experience
Preferred qualifications
Solid communication skills with exposure to direct client communication is preferred

Genpact is an Equal Opportunity Employer and considers applicants for all positions without regard to race, color, religion or belief, sex, age, national origin, citizenship status, marital status, military/veteran status, genetic information, sexual orientation, gender identity, physical or mental disability or any other characteristic protected by applicable laws. Genpact is committed to creating a dynamic work environment that values diversity and inclusion, respect and integrity, customer focus, and innovation. For more information, visit www.genpact.com. Follow us on Twitter, Facebook, LinkedIn, and YouTube.",3.6,"Genpact
3.6",Gurgaon,"New York, NY",10000+ employees,1997,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"Accenture, IBM, Capgemini"
242,Senior Applied Data Scientist,"dunnhumby is looking for
a talented Senior
Applied Data Scientist!

You will lead and execute projects to distil complex problems into compelling
insights, using the best of dunnhumby science and make recommendations that
resonate with clients and lead them to action.

What you'll be doing:
Build
strong relationships with internal contacts & external clients to ensure
full understanding of client challenges, growth strategy and agreed measures of
success for the project.
Investigate
and implement the most appropriate analytical technique for each project, role
modeling the re-use & further development of global solutions or code
written by others.
Deploy,
and mentor the team to deploy, data science algorithms and market products on
chosen tech stack for efficient and cost-effective delivery.
Lead
and execute projects that distil complex problems into compelling insights that
resonate with clients and lead them to action.
Spot
opportunities to grow client engagement by proactively solving client’s
strategic questions, using a mix of products and advanced data science
techniques that support executive decision making and call to action.
Participate
in client meetings as required to present methodology and solutions through
effective story telling techniques.
Work
closely with global products team to provide market feedback for enhancing an
existing product offering or augmenting the catalogue with a market-based
product that can become global offering.
Ensure
smooth running of your projects and support junior team members with their
projects.
Lead
by example by following dunnhumby Quality Assurance processes, ways of working
and coding standards.
Provide
advice and support to colleagues to resolve challenges and support code
reviews.
Who you’ll get to work with:

Within dunnhumby you’ll
work with
Applied and Research Data Scientist teams
Client / Commercial teams
Global Capability teams
Data Science Engineering teams
Externally, you’ll
frequently be in contact with:
Senior Retail/Customer Packaged Goods Analysts and Insights
contacts
What you'll need:
Bachelor’s degree or equivalent in
Mathematics, Economics, Applied Statistics, Computer Science, Physics,
Engineering or related field.
Experience focussing on
the practical & pragmatic use of data and a passion for connecting your
work directly to the customer experience, making a real and tangible impact.
Experience with handling
large data volumes with modern data processing tools, e.g. by using Hadoop /
Spark / SQL / Python.
Analytical Techniques
Analytical Technology
Desk Research
Prototyping
Quality Assurance and
Testing
Statistical Modelling
Programming (Python,
SQL, R, …)
Data Interpretation/
Insight Analysis
Data Visualisation
Insight Storytelling
Client relationship
building and management
Presentation skills
A plus if you also have:
Master’s degree or equivalent in in Computer Science, Artificial Intelligence,
Machine Learning, Applied Statistics, Physics, Engineering or related field.
Programming experience
on any standard data mining and modelling packages such as Python and R.
Experience of applying advanced statistical
models and machine learning algorithms to solve a variety of",3.6,"dunnhumby
3.6",Gurgaon,"Hammersmith, United Kingdom",1001 to 5000 employees,1989,Company - Private,Consulting,Business Services,₹50 to ₹100 billion (INR),-1
243,Program Manager - Data Science,"Microsoft Teams is changing the way people and organizations work and is quickly becoming the default tool for business collaboration around the world. It is the fastest growing business product in Microsoft’s history and will continue to be a major driver of growth across all customer segments in the coming years

This is your opportunity to help take Teams reach a billion users by identifying growth opportunities. Join our diverse global engineering team and help us revolutionize how people and teams collaborate and work together. We’re building an amazing platform to conduct meetings, share information, integrate commercial and LOB apps, services, and bots. We’re also building specialized solutions for firstline workers, retail, education, health care, financial services and more.

To drive both customer acquisition and usage of Teams we need to ensure that we have the right understanding of Teams performance, usage and engagement. To this end, we are looking for a dedicated Data Scientist to help design, develop and deliver data powered solutions including problem definition, data acquisition, data exploration and visualization and to build tools for this process.

Success in this role will depend on ability to translate business requirements into data-driven analytical projects and experiments. It will also depend on the ability to synthesize findings and effectively communicate the findings through visualizations. The data scientist needs to be comfortable working with data from diverse structured and unstructured sources in a variety of formats.

Responsibilities


As a member of the team you will,
Partner with data engineering teams, business analysts to develop valuable insights that will influence product and business decisions
Mine large datasets for identifying opportunities, stitch data from multiple sources, and create connected datasets
Design and implement models for optimization, segmentation, predictive and propensity analysis to gain insights into the quality and health of products
Build models to identify leading indicators of user engagement and retention
Manage multiple concurrent projects and drive initiatives in a cross functional environment
Qualifications


Required Qualifications
2-3 years of Data Science experience in driving experiments, anomaly detection, predictive analysis, exploratory data analysis preferred
Technical data analysis/modeling experience using Excel/R/Power BI/SAS/STATA or similar platforms and familiarity with one or more programming or scripting languages such as Python, R, SQL
Proven skills and experience in gathering, analyzing and reporting on telemetry data (experience with Microsoft product, data telemetry systems is a plus)
Strong interpersonal skills with demonstrated ability to communicate technical content to general audiences
Able to lead with curiosity and a strong growth mindset
Bachelor’s degree in computer science, engineering, statistics, economics or equivalent field required, and Masters preferred
Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.",4.3,"Microsoft
4.3",Bengaluru,"Redmond, WA",10000+ employees,1975,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Google, Amazon, Apple"
244,AI Scientist,"An AI scientist at Wadhwani AI will build research-driven solutions to bring AI to the benefit of the underserved billions across the developing world.

ABOUT US

The Wadhwani Institute for Artificial Intelligence (Wadhwani AI) is the world’s first independent nonprofit research institute developing AI solutions for social good. Our mission is to develop AI solutions to overcome challenges of societal importance in domains such as health, agriculture, financial inclusion, and infrastructure.

Our team consists of world-renowned scientists, innovators, and entrepreneurs from Stanford, Yale, Cornell, and the IITs, with experience at companies like Microsoft, Google, Amazon, and DE Shaw. We have research collaborations with Stanford University, Carnegie Mellon University, New York University, University of Southern California, and the University of Washington.

ROLES AND RESPONSIBILITIES

As an AI scientist, you will be responsible for building machine learning solutions to problems of societal importance, and mentoring other team members in this effort. You will participate in problem definitions and the development and execution of algorithms and solutions to the problems.

In order to apply machine learning and related technologies for social good, you will need to understand user challenges and their context, curate and transform data, train and validate models, run simulations and broadly derive insights from data. In doing so, you will work in cross-functional teams spanning research, engineering, product and program management, and designers. You will also work closely with social sector organizations, and are encouraged to collaborate with researchers across the world.

You will be encouraged to drive fundamental advances to the technology domains themselves as part of the efforts towards their application, present your work in technical and other forums of interest, and publish in leading conferences and journals.

At Wadhwani AI, excellence as an individual contributor goes hand-in-hand with good teamwork and collaboration. You will mentor junior researchers, post-docs and interns, and participate in recruiting and hiring activities. You will also be expected to interact with external partners of Wadhwani AI when required, and to make periodic visits to the communities from where challenges are derived and where the solutions will be deployed.

REQUIREMENTS

We are looking for AI scientists with experience applying AI, machine learning and data science to real world problems. Ideal candidates should have a strong research background and be adept at a variety of data mining/analysis methods and tools, building and implementing models, visualizing data, creating/using algorithms and running simulations.

Candidates should be comfortable working with cross-functional teams, must have excellent communication skills and a track record of driving projects to completion.

Candidates should care about using their technical skills to solve large societally important problems.",4.0,"Wadhwani AI
4.0",Mumbai,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
245,Lead Data Scientist,"We are looking for a Lead Data Scientist who will support our product teams with insights gained from analyzing company data. The ideal candidate has background in a quantitative or technical field, is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. You are focused on results, a self-starter, and have demonstrated success for using analytics to drive the understanding, growth, and success of a product.

Responsibilities:
Designing and deploying deep learning algorithms and predictive models
Develop custom data models and algorithms to apply to data sets
Assess the effectiveness and accuracy of new data sources and data gathering techniques
Develop processes and tools to monitor and analyze model performance and data accuracy
Collaborate with data and subject matter experts throughout the organization to identify opportunities for leveraging data to drive business solutions
Qualifications:
7+ year of experience with BS or MS or PhD in Computer Science, Electrical Engineering, Statistics, or equivalent fields. Specialization in machine learning preferred
Experience of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Experience of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
Applied experience with Deep Learning algorithms such as Convolutional Neural Networks, Recurrent Neural Networks and LSTM etc.
Familiarity with Deep Learning frameworks such as TensorFlow and PyTorch, and strong experience in at least one of those
Experience with data cleansing, data quality assessment, and using analytics for data assessment
Excellent programming skills in languages such as Python and R. Experience with Java and Scala is a plus.
Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Flink, Spark, Cassandra, etc.
Experience visualizing/presenting data for stakeholders using: Periscope, D3, ggplot, etc.
Ability to drive a project and work both independently and in a team",3.0,"Qualys
3.0",Pune,"Foster City, CA",501 to 1000 employees,1999,Company - Public,Computer Hardware & Software,Information Technology,₹10 to ₹50 billion (INR),"NortonLifeLock, McAfee, Verisign"
246,Senior Data Scientist,"We are building a world-class language-related product that has the potential to positively transform lives worldwide. We have a passionate team of data scientists, coders, and linguists who have been working on it. We are looking for a Senior Data Scientist who will lead the team from the technology standpoint. You will identify and implement the best data-driven methodologies considering the product requirements and guide the team in delivering meaningful results. As a Senior Data Scientist, you will serve as the technology leader driving the vision of the product.

Work location: Mumbai

If this opportunity sounds exciting, APPLY NOW!!",3.2,"Crimson Interactive
3.2",Mumbai,"Mumbai, India",201 to 500 employees,2005,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
247,Tech Lead - Data Scientist (NLP),"AI team at Ultria is working on state of the art Natural Language Processing technologies including document structure detection, domain specific neural embeddings, deep neural network architectures for extraction and classification tasks etc. We are looking for a passionate data scientist to develop new statistical models for delivering high-quality NLP products.

RESPONSIBILITIES:
Identify new opportunities to apply Machine Learning to different parts of the product
Develop advanced algorithms to solve problems of high dimensionality in a computationally efficient and statistically effective manner
Have responsibility for the creation and development of our Text Analytics strategy and software
Take end to end ownership of Machine Learning products
Partner with other teams such as Data, Design and Product to collaborate on projects across the company
Work with the engineering management team to develop new initiatives and improve existing processes across the entire engineering team
Implement small and large scale projects in Advanced Analytics to help derive business insights for measurable success
Evaluate emerging datasets and technologies that may contribute to our products
Requirements
3 -7 years of strong Python development experience
3+ years of experience in Machine Learning/Deep Learning, specifically in NLP and text analytics domain including:
Extracting, cleaning and embedding text data
Text classification
Entity extraction/NER
Text summarization
Similarity and sentiment analysis
Topic modelling
Research experience in machine learning or natural language processing
Experience in deploying ML projects in production environment
Strong statistical analysis skills and demonstrated experience in deriving insights from unstructured data
Ability to run experiments scientifically and analyze results
Good understanding of ML tools/libraries like: Tensorflow, Keras, Pandas, Spacy, Pytorch, NLTK, SkLearn etc
Knowledge of big data technologies like Hadoop, Hive, Scala or Spark is preferred
Strong collaborative mindset
Excellent critical thinking and problem solving skills
Benefits

About Ultria

Ultria offers end-to-end, SaaS-deployed, Contract Lifecycle Management solution for the Enterprise—Ultria CLM. It is a market-proven solution with a legacy of successful deployments over more than seven years. With a workflow based authoring and approval tool, and a comprehensive repository of contracts and clauses, Ultria CLM helps companies across the spectrum derive greater value from their contracts. By connecting with eSignature and CRM solutions, Ultria CLM seamlessly streamlines the quote to contract conversion process. Its post-signoff contract management capabilities empower the enterprise to extract the maximum value out of contracts, mitigate risks, and ensure regulatory compliance.

Our Products are built around an intuitive user experience, leveraging a comprehensive knowledge base, robust Artificial Intelligence technology, encapsulates industry's best-of-breed processes and methodologies.

Several of Fortune 500 companies have chosen Ultria solutions for the following reasons:
In-depth industry and domain expertise with a robust implementation methodology
Ability to ensure semantic and structural data integrity and quality
End-to-end solution for Data Governance renowned by leading market Analysts
To know more, you can visit our website: www.ultria.com",4.0,"Ultria
4.0",Bengaluru,"Princeton, NJ",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
248,Hiring for Sr/Jr Data Scientist in Chennai,"Role Description
Role involves a combination of hands-on contribution, customer engagement and technical team management.
Lead data science aspects of client engagements on their own end to end, effortlessly switching between roles of an Individual Contributor, team member and data science manager as demanded by each project
Work closely with project team, Customer stakeholders and internal Business Units in devising creative analytical approaches to solve business problems
Developing and enhancing algorithms and models to solve business problem
Maintaining all models along with developing and updating code and process documentation
Demonstrated analytic, quantitative, and programming skills
Proficiency in a structured programming language is a must - knowledge of one of statistical/general purpose scripting languages software such as R, python is mandatory.
Strong SQL, Microsoft Excel, PowerPoint skills
Experience in designing data science solution approaches to unstructured problems, conducting quantitative analyses and interpreting results
Excellent written and verbal communication skills
Organized, structured and reliable while being an effective problem solver
Proficiency in data science approaches, machine learning algorithms and statistical methods.Â
Qualification and Experience
8+ years exp of which 5 years of relevant data science experience including hands-on programming in one (or more) of the above languages. Minimum 5 years spent with Analytics teams of reputed consultants and IT/ITES companies doing statistical modelling using above tools
B.Tech from Tier-1 college (IITs, NITs, IIITs etc.)
M.S or M.Tech is preferred
00-11.00 Years
Masters in Technology (M.Tech/M.E/M.Sc), Bachelor Of Technology (B.Tech/B.E)",-1,Avenues Consulting,Bengaluru,"Mumbai, India",1 to 50 employees,-1,Unknown,-1,-1,Unknown / Non-Applicable,-1
249,Data Scientist-Analytics-Python+Machine Learning (3-9yrs),"A highly challenging role where you will be a part of a vision-Led team that will be extensively involved in developing technology related to Artificial Intelligence and Machine Learning. Hence, a highly exciting opportunity for those with a strong background in advanced math and excellent understanding of algorithms so you can drive your passion to solve business problems and excel in your career as a Data Scientist!

Location: Mumbai

Your Future Employer:
A leading, global group with billions of assets under management providing comprehensive financial services serving millions of customers.

Responsiblities:
Developing Models on AI/ML.
Collecting and integrating data from various data sources to be used for building the models (writing crawlers, connecting to databases for extracting data for training algorithms, creating features that support hypothesis.)
Training and Testing different ML/DL algorithms, performing iterative experiments with different techniques to discover the best performing algorithm.
Creating frameworks to monitor algorithm performance.
Performing data analysis from unstructured data to find meaningful business insights.
Working as a product owner and holding end to end responsibility for NLP based solutions.
The Successful Candidate:
Hands-on experience in Machine Learning, Deep Learning, NLP and Image matching algorithms using PySpark, Scikit-learn, and Tensor Flow, Neural Networks etc.
Strong Background in advanced mathematical concepts and an excellent understanding of algorithms.
Hands-on experience in NLP, AI, Machine Learning, Deep Learning as a Data Scientist (3-9 yrs.)
Strong familiarity with Deep Learning methods for text analytics is highly desired - RNN, LSTM, word2vec and other embeddings, Keras/Tensor flow.
Knowledge of Chatbot platforms and development and deployment of at least 1 NLP based Chatbot or other AI, machine learning, or NLP technologies
A passion to solve business problems across the value chain.
What is in it for you:
An opportunity to work with a blue- chip firm in a high visibility role as a part of lean team.
Work in a dynamic environment for an established brand.
Reach Us:
If you think this role will add value to your career, kindly write me an email along with your updated CV on kirti.bakshi@crescendogroup.in for a confidential discussion on the role.
Reference Number: 1095
Contact Details: kirtibakshi@crescendogroup.in
Profession: Analytics > All
Company: Client of Crescendo Global
Date Posted: 19/05/2020",4.6,"Crescendo Global Services
4.6",Maharashtra,"Gurgaon, India",1 to 50 employees,2014,Company - Private,Staffing & Outsourcing,Business Services,₹100 to ₹500 million (INR),"PageGroup, Hays, Russell Reynolds"
250,Sr Advanced Data Scientist,"Join a team recognized for leadership, innovation and diversity


YOU MUST HAVE
Bachelors in Computer Science, Data Science or Engineering fields
6+ years of IT experience in solution architect / data scientist / software development for large corporate/organizations
3+ years of experience in building and deploying Machine Learning solutions using various supervised/unsupervised ML algorithms such as Linear/Logistic Regression, Support Vector Machines, (Deep) Neural Networks, Random Forest, etc
3+ years of hands-on experience with Python and/or R programming and statistical packages, and ML libraries such as scikit-learn, Keras, TensorFlow, PyTorch, MXNet, etc, and/or natural language processing using NLTK, spaCy, Gensim, etc.
2+ years of experience in building IT use cases / solutions especially around AI/ML cognitive services, based on Cloud infrastructure and services such as AWS and/or Azure cloud platforms.
Excellent understanding of Machine Learning techniques and proficiency in feature analysis, algorithm selection and model hyperparameter tuning.
WE VALUE
Bachelors Degree in computer science, Data Science or Engineering fields
Work experience / education in data science, data engineering and analytics
Project experience with NLP/NLG, AI Conversational Agent (Chatbot), OCR
Experience with Domino Data Lab, Hadoop, PySpark, Hive, SQL, NiFi, Airflow, etc.
Development experience in RPA Tools & Platform & Implementations: Examples - UiPath, Automation Anywhere and other leading RPA platform vendors
Experience in Web Service/Restful API Integration
Experience in ERP platform integration, preferably with SAP
Working Experience in an Agile/Scrum/Scaled Agile and DevOps based team environment
Certifications AI / ML and Cloud platforms
Great communication skills
Additional Information
JOB ID: req234051
Category: Engineering
Location: Devarabisanahalli Village, KR Varturhobli,,East Taluk - Phase I,Bangalore,KARNATAKA,560103,India
Exempt
Software (GLOBAL)",3.8,"Honeywell
3.8",Bengaluru,"Charlotte, NC",10000+ employees,1885,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"GE, Johnson Controls, United Technologies"
251,DATA SCIENTIST,"Profile Brief/ Responsibilities
Keep up-to-date with latest technology trends.
Work closely with Project/Business/Research teams for identifying the best model for a given problem
Research and build highly efficient and state-of-the art models
Selecting features, building and optimizing models using machine learning techniques.
Requirements
2-5 years of relevant industrial experience in Machine Learning and Deep Learning with: Strong working knowledge in Python, C, C++, Linux.
Excellent understanding of Machine Learning Techniques and Algorithms.
Excellent understanding of Text Analytics concepts and methodologies - Named Entity Recognition, Text Classification, Event Detection, Sentiment Analysis, POS Tagging, Bag of Words.
Hands-on experience with Neural Networks (CNN/, RNN,/ DNN, /BNN,/LSTM, SSD, etc), Support Vector Machine, Conditional Random Field etc.
Experience with GPU/DSP/ISP/SoC architecture and system software
Python, Tensorflow/Caffe/CUDA/Keras
Ability to see big picture, think innovative and suggest out of box solutions.
Ability to write high performance structured code.
Exposure to recent developments in Deep Learning domain",4.3,"Innefu Labs Pvt. Ltd.
4.3",New Delhi,"New Delhi, India",51 to 200 employees,2010,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
252,DATA SCIENTIST IN BANGALORE,Urgently looking for an experienced Data Scientist in Bangalore Job Details * Utilizing artificial intelligence and machine learning concepts to solve challenging business problems* Work on problems from various domains like NLP Recommendation engine computer vision* Should participate in complete project cycle i e understanding a problem statement data gathering analyzing data implementing ML AI solutions* Should be able to learn new tools languages quickly and continue expanding knowledge on latest advances in ML AI* Managing project timing client expectations and meeting deadlines* Publishing research articles papers and blogsJob Requirements * IT Skills * Minimum one year experience is required * Bachelors degree Holder * Good Communication Skills,-1,Cleareye.ai solutions,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
253,DATA SCIENTIST IN BANGALORE,Urgently looking for an experienced Data Scientist in Bangalore Job Details * Utilizing artificial intelligence and machine learning concepts to solve challenging business problems* Work on problems from various domains like NLP Recommendation engine computer vision* Should participate in complete project cycle i e understanding a problem statement data gathering analyzing data implementing ML AI solutions* Should be able to learn new tools languages quickly and continue expanding knowledge on latest advances in ML AI* Managing project timing client expectations and meeting deadlines* Publishing research articles papers and blogsJob Requirements * IT Skills * Minimum one year experience is required * Bachelors degree Holder * Good Communication Skills,-1,Cleareye.ai solutions,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
254,DATA SCIENTIST IN BANGALORE,Urgently looking for an experienced Data Scientist in Bangalore Job Details * Utilizing artificial intelligence and machine learning concepts to solve challenging business problems* Work on problems from various domains like NLP Recommendation engine computer vision* Should participate in complete project cycle i e understanding a problem statement data gathering analyzing data implementing ML AI solutions* Should be able to learn new tools languages quickly and continue expanding knowledge on latest advances in ML AI* Managing project timing client expectations and meeting deadlines* Publishing research articles papers and blogsJob Requirements * IT Skills * Minimum one year experience is required * Bachelors degree Holder * Good Communication Skills,-1,Cleareye.ai solutions,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
255,Senior Data Scientist,"What would a VISA/Mastercard payments network look like if designed ground up? Simpl is focused on re-imagining the payments stack that have not changed for decades . We believe that payments data, if harnessed the right way, can accelerate formal credit distribution in a market like India, while unlocking precision marketing opportunities.

Its first product is a micro credit based payment mode that provides greater than 99% success rate, instant refunds within seconds, tokenized security flow combined with the convenience of all the transactions getting added into a single bill, payable on the 1st and 16th of every month. To power our micro credit line, Simpl uses alternate data ( Multiple millions of data pings everyday) provided by merchants to underwrite users at internet scale.

Simpl was founded in 2015 by Nityanand Sharma and Chaitra Chidanand, and went live in 2016

Major responsibilities include:
· Helping to build production systems that take inputs from multiple models and make decisions in real time.
· Deliver ML / DL projects from beginning to end, including understanding the business need, aggregating data, exploring data, building & validating predictive models, and deploying completed models to deliver business impact to the organization.
· Utilizing effectively data to work with terabytes of data.

Basic Qualifications

· Bachelors in quantitative field (Computer Science, Mathematics, Machine Learning, AI, Statistics, or equivalent)
· 4+ years of industry experience in predictive modeling, data science and analysis
· Previous experience in a ML or data scientist role and a track record of building ML or DL models
· Experience using Python and/or R
· Knowledge of SparkML
· Able to write production level code, which is well-written and explainable
· Experience using ML libraries, such as scikit-learn
· Experience working with GPUs to develop models
· Experience handling terabyte size datasets
· Track record of diving into data to discover hidden patterns
· Familiarity with using data visualization tools
· Knowledge and experience of writing and tuning SQL
· Past and current experience writing and speaking about complex technical concepts to broad audiences in a simplified format
· Experience giving data presentations
· Strong written and verbal communication skills",4.3,"Hewlett Packard Enterprise
4.2",Bengaluru,"Bengaluru, India",51 to 200 employees,2015,Company - Private,Financial Transaction Processing,Finance,Unknown / Non-Applicable,-1
256,Data Analyst,"The position is full-time and would be based at the company’s Chennai office. The successful applicant would have 1 - 2 years' relevant experience and be responsible for collection, validation & analysis of Mutual fund data.

Key Areas of Responsibility
Collection, validation, analysis of mutual fund information.
Updating the mutual fund information into our databases in a timely manner.
Perform quality checks.
Communicate with UK and Offshore asset management companies via email/telephone.
Provide clarifications to clients’ queries based on priority and urgency levels.
Extract and provide various project-related reports as required by the manager.
Key Skills

Key Technical Skills
Possess basic knowledge of Mutual funds and/or of the financial sector.
Proficient in MS Office (including MS Outlook)
Key Behavioural Skills
Very good written and spoken English communication skills.
Good Analytical and Problem solving skills.
Ability to work independently and come up with ideas to enhance the process.
Ability to achieve the defined SLA standards with regard to Turn Around Time, Work accuracy etc. and maintain them throughout one’s tenure in the department.
Ability to quickly learn new concepts relating to Mutual funds and be able to apply them in the work.
How to Apply

To apply for this job, click here

If you have any questions regarding this job, please feel free to email india.jobs@financialexpress.net",4.1,"FE UK
4.1",Chennai,"Woking, United Kingdom",501 to 1000 employees,1996,Company - Private,Financial Analytics & Research,Finance,Unknown / Non-Applicable,-1
257,Analytics Scientist,"Designation: Analytics Scientist
Experience: 1- 3 Years
Location: Bangalore
Commitment: Full-Time
Functional Team: Analytics
Number of opening: 1

Job Description:
Coming up with data driven solutions to control risk and collections
Finding opportunities to acquire more customers by modifying/optimizing existing rules
Doing periodic upgrades of the underwriting strategy based on business requirements
Evaluating 3rd party solutions for predicting/controlling risk of the portfolio
Running periodic controlled tests to optimize underwriting
Monitoring key portfolio metrics and take data driven actions based on the performance
Building models to predict risk and other key metrics
Do You Know? (Technical Skills and Experience)
1 – 2 years of experience in Financial Services/Analytics Industry
Strong Analytical aptitude and logical reasoning ability
Knowledge of analytical tools such as R/Python
Dexterity with SQL/MySQL, MS Excel
Strong presentation and communication skills.
Understanding of the financial services business
Established competency in statistics
Experience in handling complex data sources and working on advanced machine learning techniques

If you’re interested in applying for this position, please mail your resume to Careers@oyefin.com",4.8,"OYE Loans
4.8",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
258,Data Science Intern,"ABOUT SHIPSY


Driven by a team of computer scientists and electrical engineers from IIT Delhi and IIT Madras, Shipsy aims to create platforms for data-driven decision making with the vision of bringing visibility and operational efficiency to the Supply Chain industry.
Most of our paying clients are in the Supply Chain industry and we are enabling new business models, swifter operations using algorithms and machine learning. We are processing ~10 million transactions per month through our system.

ROLE

The Data Science Intern will leverage our wealth of data to work on machine learning and statistics projects that improve care. The Data Science Intern will receive hands-on mentoring in Unix, python, data management, machine learning, and statistical analysis. We are looking for a data scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high-quality prediction systems integrated with our products.

RESPONSIBILITIES:

Develop machine learning algorithms.
Perform statistical analyses.
Query data sources.
Clean and format data.
Meet with clinical experts and end users.
Perform other duties as required.
Must read, understand, and adhere to all HCA/HealthONE policies and procedures
Practice and adhere to the Code of Conduct and Mission and Value Statement.
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending the company’s data with third-party sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Doing the ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance.
improve and extend the features used by our existing classifier
build system for automated fraud detection


TEAM


Our current team has 50 people from top institutes across the country like IITs, IIITs, NITs with experience in Big Data, Software Architecture, ML, AI, Robotics, Blockchain. Our founding team has CS/Elec folks from IIT Delhi and IIT Madras.


PERKS


- Free breakfast, dinner, and snacks at the office
- Monthly team outings, e.g., laser tag, paintball, football, trampoline etc.
- Quarterly team parties and annual offsite
- Company sponsored enrollment worth 40K annually to online learning resources like Coursera, edX etc.
- International trip vouchers for top performers
- Company sponsored asset purchase worth 50K
- Games in office - Mini golf, pool, foosball
- Regular tech seminars with pizza and beer",3.9,"Shipsy
3.9",Gurgaon,"Gurgaon, India",1 to 50 employees,2015,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
259,DATA SCIENTIST,"DATA SCIENTIST (Analytics & Technology)

Experience : 7+ yrs.

Location : Gurgaon & Bangalore

Qualification :Masters (preferred) or Bachelors Honors in Statistics, Economics, Computer Science, Engineering, Mathematics preferred

Technical expertise: Provide expertise in Statistics, Mathematical modeling and simulation, Numerical Analysis and Differential Equation.
Curiosity: a desire to go beneath the stated client needs and discover and distill a problem down into a very clear set of hypotheses that can be tested.
Problem solver: Ability to work with adhoc/ unstructured data and arrive at a potential business proposition and hence, be able to define and design customized business solution.
Storytelling: the ability to use data to tell a business-outcome impacting story and to be able to communicate it effectively.
Cleverness: the ability to look at a problem in different, creative ways.
Experienced in mathematical modeling and programming, statistical analysis, forecasting/predictive modeling, simulations, optimization, visualizations, machine learning, data mining, etc.
Proficiency in one or more statistical programming language, like R, SAS, WEKA or Python, and a database querying language like SQL.
Demonstrated ability of thought leadership and to work with ambiguous problem definitions, recognize dependencies and deliver impactful solutions through logical problem solving and technical ideations.
Ability to learn new analytical methods, technologies and apply in practical business problems.
Strong communication and interpersonal skills: Ability to communicate clearly and confidently with clients/stakeholders. Ability to tell a clear, concise, actionable story with data. Ability to work with multiple teams with different backgrounds.
Attitude to work in a fast paced and continuously changing environment.
Understanding of Big Data Technologies like Map Reduce and Hadoop.
Proficiency with any general purpose programming language Java/Python/C/C++.",2.8,"Melstar Information Technologies Limited
2.8",Bengaluru,"Mumbai, India",201 to 500 employees,-1,Company - Private,IT Services,Information Technology,₹10 to ₹50 billion (INR),-1
260,Data Engineer,"Work in the fascinating world of Markets IT within Data Engineering & Data Analytics. Help us counteract financial crime by utilizing the latest technologies to detect and uncover unusual activity in trading data.

We are at the start of a journey. We want to create a Centre of Excellence in India. Do you have what it takes to join the journey with us?

Are you passionate about data engineering and big data technologies: Hadoop, Spark, Hive, Airflow, Elastic Search, Docker, Kubernetes, Scala, Python, and Functional Programming?

Do you have a strong interest in Data Science and Financial Markets?

Are you keen to be a key player at the start of something transformative within Danske?

We are seeking skilled Data/Software Engineers to join our team.

Our goal is to create the next generation of analytics tooling focused on the world of fraud, regulatory compliance, and Financial Crime.

Enjoy vibrant and exciting work with challenging tasks, trending technology and all the flexibility you expect of a modern IT organization.

You will work in a team of highly skilled engineers in Bengaluru.

We work closely with our business, regulatory compliance, 3rd party vendors as well as our fellow engineers in Copenhagen and London.

We believe in software development organizations where our engineers are trusted and empowered to take full responsibility for their stack.

We would expect the right person to be competent with:
Scala but we will also consider highly skilled Java Engineers that have a good understanding of functional programming
Python
Experience of building data processing pipelines for use in production batch systems, including either traditional ETL pipelines and/or analytics pipelines
Experience in manipulating data through cleansing, parsing, standardizing, etc, especially in relation to improving data quality/integrity
Test-Driven Development & Automated testing
Experience with large scalable system development and deployment
Working within a Scrum team
Solid understanding of the JVM
Data Structures & Concurrency
Linux

Programming experience:
Scala
Java
Python
Tools and infrastructure experience:
Hadoop
Apache Spark (Scala)
Apache Airflow (Python)
Elastic Search
Bamboo, Go.CD, other CI/CD pipelining tools
Git
Linux
REST and JSON
Gradle",2.6,"Danske IT and Support Services
2.6",Bengaluru,"Copenhagen, Denmark",1001 to 5000 employees,2012,Subsidiary or Business Segment,IT Services,Information Technology,Unknown / Non-Applicable,-1
261,Principal Data Scientist - BLR,"As a Data Scientist at Noodle.ai, you will collaborate with our Enterprise Services team,Software Engineers, Designers, and industry-specific experts from our customers. You willvbuild a deep understanding of the business problems our customers are tackling and then develop, test, and deploy advanced machine learning algorithms. As we grow, you will also develop reusable IP to help us move faster, dive deeper, and work more efficiently by generalizing the algorithms, methodologies, and supporting infrastructure that you build. As one of the early hires to join the Noodle.ai team, you will have a significant impact on the future of Enterprise Artificial Intelligence.

Job responsibilities:
Implement a breadth of different modeling approaches/ techniques in machine learning

Manipulate and prepare large, heterogeneous data sets to support advanced analytics

Iteratively conceptualize, design and build data-driven analytical models

Develop processes and tools to monitor and analyze model performance and data accuracy

Translate deep mathematical concepts and practices into language that non-experts can understand and build upon. And conversely, translate business needs and user needs into language and concepts that other data scientists can understand and work with.

Productionalizing machine learning code and interfacing with industry standardmsoftware systems

Understand and manipulate unstructured data from different platforms.

Demonstrate proficiency at real-world modeling problems/DS problems - getting to a result that demonstrably generate business value

Qualifications:Required:
Graduate degree in a relevant field (Computer Science, Operations Research, Statistics, Applied Math...) or Bachelors degree and 2-4 years applying advanced AI techniques to real-world problems

Good to have:
7+years of experience applying advanced AI techniques to real-world problems

Experience tackling data science problems characterized as high-dimension, low sample size (i.e., lots of potentially predictive features and highly diverse but low quality or highly sparse data.)

Knowledge & understanding of a functional area of focus (i.e. Experience applying advanced analytics to supply chain optimization, demand forecasting, and/or revenue management)

Knowledge & understanding of an industry area of focus (i.e. retail, manufacturing,CPG, 3PL, travel...)

Skills and Competencies:
Experience with common analysis tools (SQL, R, and Python).

Demonstrable familiarity with code and programming concepts.

Knowledge of Spark and/or Hadoop

Knowledge of machine learning areas and techniques - Supervised machine learning,Unsupervised machine learning, Time series, Natural language processing, Outlier detection, Computer vision, Recommendation engines, Survival analysis,
Reinforcement learning, and Adversarial learning

Knowledge of data visualization tools - ggplot, d3.js and Matplottlib, and Tableau

Strong problem solving skills with an emphasis on product development

Focus on delivering value and building lasting relationships through collaboration in an open and respectful working style

Passion for learning and a desire to grow",4.5,"Noodle.ai
4.5",Bengaluru,"San Francisco, CA",201 to 500 employees,2016,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹1 to ₹5 billion (INR),-1
262,Data Engineer (AI/ML),"Mavenir is purpose-built to redefine mobile network economics for Communication Service Providers (CSPs). Our innovative solutions pave the way to 5G with 100% software-based, end-to-end, Cloud Native network solutions. Leveraging industry-leading firsts in VoLTE, VoWiFi, Advanced Messaging (RCS), Multi-ID, vEPC and Cloud RAN, Mavenir accelerates network transformation for more than 250+ CSP customers in over 130 countries, serving over 50% of the world’s subscribers

Role Summary

Data Scientist will provide expert consultancy in developing the AI/ML algorithms in creation of the AI products and solutions for Mavenir.

Key Responsibilities

Define and implement data preparation and feature extraction for network data
Define and implement machine learning algorithms for network optimization
Participate in cross functional team discussions in use case definition, requirement gathering
Investigate algorithms and ML frameworks to pick per use case
Perform feature engineering, hyper parameter tuning and model optimization
Gather feedback from users of the solution and fine tune it
Create product specific content
Create design and functional requirements

Job Requirements

3-5 years experience with AI / ML algorithms and implementation
Knowledge of PyTorch, Tensorflow, Kubeflow, Spark, and ElasticSearch
Python, R, C++, SciKit-Learn, Numpy, Pandas, Keras
SparkMLlib, RLlib, BOTorch/Ax, PyTorch, Tensorflow, MxNet
ElasticSearch, Kibana, Grafana, Kafka/Avro

Accessibility

Mavenir is committed to working with and providing reasonable accommodation to individuals with physical and mental disabilities. If you require any assistance, please state in your application or contact your recruiter.

Mavenir is an Equal Employment Opportunity (EEO) employer and welcomes qualified applicants from around the world, regardless of their ethnicity, gender, religion, nationality, age, disability, or other legally protected status.",3.2,"Mavenir
3.2",Bengaluru,"Richardson, TX",501 to 1000 employees,2005,Company - Private,Telecommunications Services,Telecommunications,₹10 to ₹50 billion (INR),"Alcatel-Lucent, Cisco Systems"
263,Machine Learning Engineer - Engineering Function (Bengaluru / Remote),"Following a year of rapid growth in our open-source ML projects and winning top tier customers across sectors to support strategic AI platform initiatives, Seldon expanding to find our first technical hire in Bengaluru, India!

We're looking for our first technical base on the ground to help solidify our India operation from day zero. Seldon is looking for a Machine Learning Engineer to join our Solutions Team.

About Seldon
Seldon is a London based scale-up that builds open source and enterprise machine learning frameworks that power massive scale deployments of production AI systems. Our open source frameworks benefits from over 200,000 installations, and power our enterprise product Seldon Deploy, which is currently being used by some of the leading global organisations across industries such as automotive, pharma, finance, etc.

About the role
Your role at Seldon will primarily involve:
Supporting production systems at scale based on our open source and enterprise machine learning products in Kubernetes
Triaging production client deployments to ensure success for large scale production machine learning systems in critical environments
Submit bugs and patches to our open source and enterprise products to resolve issues
Contributing to our open source projects to extend their functionality
Architecting solutions for critical industry machine learning systems
Identifying & documenting best practices for ML Engineering
Optimising the performance of machine learning systems
Designing and delivering high impact solutions with top tier organisations
Contributing to global open source projects and technology conferences
Growing within a scaling startup crafting a role of your own
Required skills:
A degree or higher level academic background in a scientific or engineering subject.
Strong computer science foundations.
Strong System architecture knowledge/experience.
Familiarity with linux based development.
Experience architecting/applying technology to solve real world challenges.
Experience delivering production-level client-facing projects.

Nice-to-have skills:
Experience with Kubernetes and the ecosystem of Cloud Native tools.
Experience using machine learning tools in production.

Benefits:
Share options to align you with the long-term success of the company.
Exciting phase of fast-paced start-up challenges with an ambitious team and unlimited potential for professional growth.
Access to discounted lunches, gyms, shopping and cinema tickets.
Healthcare benefits.
Flexible work-from-home policy.

About our tech stack
Some of our high profile technical projects:
We are core authors and maintainers of Seldon Core, the most popular Open Source model serving solution in the Cloud Native (Kubernetes) ecosystem
We built and maintain the black box model explainability tool Alibi
We are co-founders of the KFServing project, and collaborate with Microsoft, Google, IBM, etc on extending the project
We are core contributors of the Kubeflow project and meet on several workstreams with Google, Microsoft, RedHat, etc on a weekly basis
We are part of the SIG-MLOps Kubernetes open source working group, where we contribute through examples and prototypes around ML serving
We run the largest Tensorflow meetup in London
And much more

Some of the technologies we use in our day-to-day:
Go is our primary language for all-things backend infrastructure including our Kubernetes Operator, and our new GoLang Microservice Orchestrator)
Python is our primary language for machine learning, and powers our most popular Seldon Core Microservices wrapper, as well as our Explainability Toolbox Alibi
We leverage the Elastic Stack to provide full data provenance on inputs and outputs for thousands of models in production clusters
Metrics from our models collected using Prometheus, with custom Grafana integrations for visualisation and monitoring
Our primary service mesh backend leverages the Envoy Proxy, fully integrated with Istio, but also with an option for Ambassador
We leverage gRPC protobufs to standardise our schemas and reach unprecedented processing speeds through complex inference graphs
We use React.js for our all our enterprise user products and interfaces
Kubernetes and Docker to schedule and run our services (Oliver,our Head of Engineering, gave a great talk at KubeCon on how we use these technologies)
AWS for most of our infrastructure
React for internal web dashboards
We also have two physical datacenter sites with actual cables to connect to various third parties

Logistics
Our interview process is normally a phone interview, a coding task, and 2-3 hours of onsite interviews. We promise not to ask you any brain teasers or trick questions. We might design a system together on a whiteboard, the same way we often work together, but we won’t make you write code on one. Our recruitment process has an average length of 3 weeks.",5.0,"Seldon
5.0",Bagalur,"Shoreditch, United Kingdom",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
264,Distributed Computing/Data Analytics developer,"Distributed Computing/Data Analytics developer

Job Description:

Experience - 8 to 12 years

Title - Distributed Computing/Data Analytics developer

The Company

Interset Software uses big data and advanced behavioral analytics to detect and prevent the theft of intellectual property...simply put, WE CATCH BAD GUYS WITH MATH!!!

Part of the Micro Focus group of companies, we are a fast-paced, all-hands-on-deck kind of environment where you are respected and listened to from day one. We have a start-up feel within the stability and structure of a large global company.

We are currently looking to fill a development position focussed on extending the existing analytics platform and related capabilities to add unprecedented analytics flexibility for our customers. This will include enabling Data Scientists to manipulate and combine events and models to extend and customize the analytics in ways that provide unique value for each customer.

Were looking for a software developer whos passionate about what they do, takes a creative approach to problem solving and will be the champion for creating innovative machine learning hooks that deliver real value and perform in big data environments.

If youre passionate about true machine learning and want to be part of a company building solutions that leverage the latest in big data technology, we want to talk to you!!

What you'll do:
Implement model data flows to support running cutting-edge machine learning techniques on massive amounts of data
Work with product managers and data scientists to turn new features and algorithms into beautiful, battle-tested code
Work with the technologies we use to analyze and identify cyber-security threats for our customers (Elasticsearch, Spark, HBase, Kafka, Vertica, NiFi, using Java and Scala)
Work side by side with some of the smartest minds in the fields of machine learning and behavioural analytics
Create efficient and robust cloud-based solutions, leveraging the best in cloud technologies.
Who you are:
Undergraduate or Masters degree in Computer Science or equivalent engineering experience
Strong interest in software design, distributed computing, and databases
Experience developing in a JVM environment (Java, Scala, Clojure)
At least two years of experience developing with or using Big Data & Analytics stacks/tools such as Hadoop, HBase, Spark, Presto and Vertica.
Experience implementing and using streaming platforms such as SparkSQL, Flink, Kafka, Storm, etc.
Experience with Kubernetes, Docker, Ansible or any other infrastructure or containerization management/automation platform.
Familiarity leveraging AWS EMR, Azure, GCP cloud technologies best practices to enable the distribution and analysis of big data on the cloud would be considered an asset.
Nice to haves:
Familiarity with data science or machine learning packages (pandas, R, TensorFlow, etc...)
Familiarity with virtualization technologies (VMWare ESX, Docker)
Contributions to open source software (code, docs or mailing list posts)
Interest in understanding and analyzing diverse types of data

Job:

Engineering

Micro Focus is proud to be an Equal Opportunity Employer. Prospective employees will receive consideration without discrimination because of race, colour, religion, creed, gender, national origin, age, disability, marital or veteran status, sexual orientation, genetic information, citizenship or any other legally protected status",3.2,"Micro Focus
3.2",Bengaluru,"Newbury, United Kingdom",10000+ employees,1976,Company - Public,Computer Hardware & Software,Information Technology,₹100 to ₹500 billion (INR),"SAP, Oracle"
265,Principal Data Scientist,"Position – Principal Data Scientist

Location – Bangalore

About Us

upGrad is an online education platform building the careers of tomorrow by offering the most industry-relevant programs in an immersive learning experience. Our mission is to create a new digital-first learning experience to deliver tangible career impact to individuals at scale. upGrad currently offers programs in Data Science, Machine Learning, Product Management, Digital Marketing, and Entrepreneurship, etc.

upGrad is looking for people passionate about management and education to help design learning programs for working professionals to stay sharp and stay relevant and help build the careers of tomorrow.
upGrad was awarded the Best Tech for Education by IAMAI for 2018-19
upGrad was also ranked as one of the LinkedIn Top Startups 2018: The 25 most sought-after startups in India
upGrad was earlier selected as one of the top ten most innovativecompanies in India by FastCompany.
We were also coveredby the Financial Times along with other disruptors in Ed-Tech
upGrad is the official education partnerfor Government of India - Startup India program
Our program with IIIT B has been ranked #1 programin the country in the domain of Artificial Intelligence and Machine Learning
About the Role

A seasoned leader who has experience in executing Data Science projects and bringing them to production to solve complex business problems. Passionate about using data to predict trends and aid in the decision making process. Hands on with leading teams and technical contributions.

Role and Responsibilities
Collaborate with business stakeholders to identify and solve business problems using AL/ML/Data Analytics with clearly defined metrics to measure success.
Build a small but highly skilled and focused team to solve data driven problems.
Own research and prototyping of solutions; data and requirements gathering; solution scoping and architecture; development, deployment, and maintenance of solutions.
Provide timelines and own end to end delivery of projects.
Prioritize to manage ad-hoc requests in parallel with ongoing projects.
The role is 75% technical (involves coding and implementation of solutions and models) and 25% delivery management of projects including external stakeholder management.
Deliver AI/ML/Data Analytics based solutions around a range of domains and problems, with some of them being: Propensity Modelling, Churn Modelling, Lifetime Value Estimation, Forecasting, Recommender Systems, Modelling Response to Incentives, Marketing Mix Optimization, Price Optimization, Learner profiling and clustering.
Skills/Experience
A highly talented technical leader with 8+ years of hands-on experience in building AI/ML and data analytics applications from exploration to production
2+ years of experience in a responsible senior or team lead role managing a team of data scientists and engineers who develop, deploy, and maintain robust machine learning models
Strong knowledge of Python, databases (SQL and NoSQL) , advanced analytics/statistical techniques such as general linear model, ANOVA, decision trees, linear regression, Bayesian, tree-based learners, SVM, RF, XGBOOST, etc. Hands-on coding experience will be required to code regularly.
Experience in deep learning techniques and has worked with TensorFlow, PyTorch. Basic NLU/NLP experience is preferred.
Experience building scalable solutions, feedback loops for model evolution, and end to end automation of model generation and deployment.
Experience with presenting complex data science processes/information to non-data scientists
Basic knowledge of software architecture design, docker, and microservices concepts.
Basic knowledge of cloud computing and AWS services.
Qualification – B.Tech/M.Tech/MCA(IT/Computer Science)

Years of Exp – 8-10+",3.5,"upGrad Education Private Limited
3.5",Bengaluru,"Mumbai, India",501 to 1000 employees,2015,Company - Private,Education Training Services,Education,₹1 to ₹5 billion (INR),"Udacity, General Assembly, Springboard"
266,Manager - Data Scientist,"Company overview
Leading Semiconductor company - Product based industry
Years of Experience: Minimum 10 - 16 years
Responsibilities:
Lead Application Development and Data Science Project Teams. Hands-On Experience in Advance Analytics and Application Development
Deliver Rapid Prototypes, Experiments, Hypothesis testing and Adhoc Analysis to support business with data driven decision making.
Provide technical leadership to BI team building architecture for tracking daily, weekly, monthly, quarterly reporting of metrics
Work with Global and local IT and Cross-functional business teams
Develop generic analytics infrastructure and master library based on MS SQL database that can be used for reporting across functions
Deliver adhoc requests for information from established data sources, such as SAP, SQL databases, QuickBase applications & 3PL Portals
Review data and develop visual representations of data to support management decision making
Develop incremental reporting requirements and maintain and manage data in line with the data architect’s roadmap
Support the development and implementation of best known methods with respect to data analytics
Responsible for developing and deploying analytical & business applications, AI application. Also, Responsible for Business Process Automation and Digital Transformation Projects
Lead strategic design and maintenance of business intelligence and intelligent applications
Mandatory Skills required to perform the job:
Must have lead Global BI/Data science team and building corporate level architecture.
Hands on experience and must be up-to-date with skills in Data Warehousing, Business Objects, ETL, Business analytics & query building in MS SQL
Working knowledge in Web Application Development and at a minimum understanding of HTML 5.0, CSS 3.0, and Java Script./Desirable (RPA,Quickbase,Fury,win.net
Application development exposure with .NET, Cloud Computing (Azure, AWS), ASP.NET MVC/ Angular JS/node.js.
People management of 3-6 years is mandatory.
Working Experience on Agile Methodologies, User Stories and adoption of Agile Culture
Requirements
Data Scientist - Manager

Additional information
Supply Chain or Manufacturing domain is preferred or any other domain.",3.7,"RGF Professional Recruitment
3.7",Bengaluru,"Tokyo, Japan",10000+ employees,1963,Company - Public,Internet,Information Technology,Unknown / Non-Applicable,-1
267,CIEL/STF/2137: Data Scientist,"Strong problem-solving skills with an emphasis on data transformation.
Work Experience of 3-6 years
Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.
Experience working with and creating data architectures.
Knowledge of a variety of machine learning techniques (clustering, decision tree learning) and their real-world advantages/drawbacks.
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage) and experience with applications.
Excellent written and verbal communication skills for coordinating across teams.",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
268,Sr. Data Scientist,"Job Description:
Work with business partners and stake holders to understand the business, formulate the problems, come up with the solutions and communicate them back effectively to non-technical audience
Analyze data to identify trends, perform root cause analysis and test hypotheses
Design A/B testing experiment set ups and measure their performance across product platform & marketing
Work with large volumes of data; extract, manipulate & visualize large datasets using standard tools such as SQL, Python, R & Tableau
Lead complex, multifunctional data science projects
Communicate complex concepts and the results of the models and analyses to technical and non-technical audience
Design, develop and implement real-time, highly automated solutions to solve credit business problems and improve existing monitoring capabilitie
Qualification:
Advance degree (MS or PhD) in science or engineering field with 6+ years of relevant experience
Strong problem-solving and communication skills
Ability to deal with large amount of data and fluency with SQL or SQL-like tools
Proven track record of building and implementing automated advanced analytical solutions
Experience in leading cross-functional, highly complex Data Science projects
Data Mining experience in Python, R.
Familiar with various Machine Learning algorithms and Statistical methods
Have a passion for working on big data and professional experience in data mining, statistical analysis, predictive modeling and data manipulation
Financial services or eCommerce experience a big plus",3.6,"PayPal
3.6",Chennai,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple"
269,Data Scientist III,"General Mills is seeking a Data Scientist to join a new data science team in the Global Business Solutions (shared services organization) that is tasked with collaborating with and enabling existing functional data science and analytics teams. This team also provides data science expertise and services to advance initiatives around demand forecasting, text classification, operational analytics, and machine learning to name just a few. It is also responsible for curating a community of practice to determine the best standards and practices around data science at General Mills
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation, Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions\
Experienced in proposing ROI based solutions to business",3.9,"General Mills
3.9",Mumbai,"Minneapolis, MN",10000+ employees,1866,Company - Public,Food & Drink Manufacturing,Manufacturing,₹500+ billion (INR),-1
270,Lead Data Scientist,"Experience Required: 8+ year experience in Software development, having BE/BTech degree.
Deep understanding of statistics and ML algorithms work internally with proficiency in at least 2 supervised and unsupervised algorithms in each bucket.
Supervised algorithms : Regression [linear/polynomial], Decision Tree, Random Forest or classification [Logistic Regression, Naïve Bayes, SVM etc]
- Model design and implementation : Experience in deriving feature sets, model training and testing

- Preferred tools and programming languages: TensorFlow/Keras, Python

- Exposure to Deep Learning and NLP is an added advantage.",3.6,"PayPal
3.6",Bengaluru,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple"
271,DATA SCIENTIST,"Job Title: Data Scientist
Location: Koramangla, Bangalore
Experience: 2-4 Years
Immediate Joiner

QUALIFICATIONS:
ïƒ˜ Undergraduate degree in Economics, Business, Statistics, Mathematics, Operations Research, Engineering, Quantitative Analysis, or Computer Science
ïƒ˜ 2 â€“ 4 years of experience working in Data sciences field
ïƒ˜ Strong verbal and written communication skills
ïƒ˜ Strong problem solving skills
ïƒ˜ Strong statistical and quantitative analysis skills
ïƒ˜ Well-organized, capable of handling several projects at a time while meeting deadlines
ïƒ˜ Proficiency with Python (pandas, Scikit, numpy packages) & SQL a must
ïƒ˜ Experience working with Google BigQuery a plus
ïƒ˜ Skilled at Microsoft Office, particularly Excel and PowerPoint

RESPONSIBILITIES:
ïƒ˜ Work on customized advanced analytics solutions like Linear/Logistic Regression, PCA, Factor Analysis, Segmentation techniques as per the business problem
ïƒ˜ Communicate with the end client on a regular basis, set expectations, responsible for final deliverables (PowerPoint, Excel)
ïƒ˜ Draw insights from the data, develop business knowledge over time
00-4.00 Years
Bachelor Of Technology (B.Tech/B.E)",3.5,"Winfoglobal Technologies Private Limited
3.5",Bengaluru,"BENGALURU, India",1 to 50 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
272,Senior Data Scientist,"Aktana is looking for an experienced Data Scientist or Senior Data Scientist to join our Data Science team. The Data Science team builds mathematical and behavioral economics models underpinning Aktana's core solutions for actionable analytics and behavioral intelligence. The set of problems that we tackle is incredibly diverse and complex. They cut across optimization, prediction, modeling, inference, and behavioral science. We research and develop the algorithms and models that make our solution intelligent, as well as implementing, scaling and maintaining the code that powers our production systems.

The ideal candidate is a critical thinker with experience and background in commercial life science domain, passionate about solving mathematical and behavioral problems with data, and is excited about working in a fast-paced, innovative and collaborative environment.

LOCATION


RESPONSIBILITIES
Work with Data Scientists, Product Managers, Customer Success and Services teams to frame a problem, both mathematically and within the business context
Write production-level code; collaborate with Engineering team to implement algorithms in production and productize common solutions
Perform exploratory data analysis to gain a deeper understanding of the problem
Construct and fit statistical, machine learning and optimization models
Utilize commonly used computing and database environments to get the data that you need and implement a working prototype of the formulated model.
Learn and apply new methodologies in the intersection of applied math/ probability/statistics/machine learning/computer science.
Make intelligent approximations to the model if required to make it scalable.
Analyze experimental and observational data; communicate findings; facilitate launch decisions
Identify data sources that could be used to test assumptions
REQUIRED SKILLS/EXPERIENCES
5 years+ of Data Science experience
Proven track record of developing algorithms for production-ready recommendation or prediction systems using languages and big data platforms such as Scala, Python, R, Java, Spark, Cassandra, and Hadoop
Experience working in an agile software development environment
Passion for solving unstructured and non-standard mathematical and behavioral problems
End-to-end experience with data, including querying, aggregation, analysis, and visualization
Experience implementing machine learning algorithms
Experience with analytics for commercial life science and pharma-specific analyses a big plus
Excellent communication and presentation skills, being able to explain complex problems and the solutions applied, feeling comfortable in being part of the sales process, supporting the sales team, engaging with customers and presenting technical solutions to a nontechnical audience
Experience in data science and data analytics for life science industry especially in GTM strategy and execution a big plus
High-energy self-starter with a passion for your work, attention to detail, and a positive attitude
Great team player, willingness to collaborate and communicate with others to solve a problem.
EDUCATION


M.S. or Ph.D. in Statistics, Operations Research, Mathematics, Computer Science, or other quantitative disciplines with at least 2 years of experience

About Aktana

Committed to customer success and innovation, Aktana is at the forefront of transforming how life sciences companies share information with healthcare providers (HCPs). Our proprietary platform harnesses machine learning algorithms to enable marketing and sales teams to seamlessly coordinate and optimize multichannel engagement with HCPs. Today, more than half of the top 20 global pharma companies are using Aktana for intelligent engagement.

Aktana is growing fast and looking for exceptional talent to join our team. We value hard work, transparency, and collaboration and we like to have fun too! We are Great Place to Work Certified, an honor given based on validated feedback from employees who report a consistently positive experience working at Aktana.

Headquartered in San Francisco, we also have offices in Philadelphia, London, Barcelona, Tokyo, Osaka, Shanghai, Beijing, Sydney, and Sao Paulo.",4.8,"Aktana
4.8",Pune,"San Francisco, CA",201 to 500 employees,2008,Company - Private,Computer Hardware & Software,Information Technology,₹1 to ₹5 billion (INR),-1
273,CIEL/SEL/1882: Data scientist,"Experience in
Python
&
R
programming
Â· Experience in
Machine Learning / Deep Learning
Â· Experience with common data science packages such as
NumPy, MatLab, Keras, Tensorflow, PyTorch, scikit learn
etc
Â· Should proactively fetch information from various sources and analyze it for better understanding and build AI tools that automate certain processes.
Â· The primary focus will be in applying data mining techniques, doing statistical analysis, and building high-quality prediction systems integrated within the products",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
274,Data Science (Jupyter/Azure ML/MatLab),"Accenture Technology powers our clients businesses with innovative technologiesestablished and emergingchanging the way their people and customers experience work, life and entertainment. Join Accenture Technology and youll translate the operational needs of the worlds governments and leading businesses into the innovative technical solutions that will enable them to better serve their customersyour friends, family and neighbors.Youll deliver everything from point solutions for a single business function to large, long-term outsourcing services, to complex systems integration installations spanning multiple businesses and functions. Youll create custom-designed solutions or integrate our technology platforms with their operations.

Role :Digital Data Engineering Practitioner
Role Description :Develop analytics based solutions that produce quantitative and qualitative business insights. Work with partners as necessary to integrate systems and data quickly and effectively, regardless of technical challenges or business environments.
Must Have Skills :Data Science (Jupyter/Azure ML/MatLab)
Good To Have Skills :Python Scripting,R Programming,Spark Programming
Job Requirements : Role: Data Scientist
Must Have:
1 Exp in Data science frameworks Jupyter notebook, AWS Sagemaker etc
2 Exp querying databases and using statistical computer languages: R, Python, SLQ, etc
3 Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis,
4 Exp with distributed data/computing tools: Map/Reduce, Flume, Drill, Hadoop, Hive, Spark, Gurobi, MySQL

Good to Have:
1 Coding knowledge and experience with several languages: C, C, Java, JavaScript, NodeJS
2 Experience using cloud services: RDS, Athena, Redshift, Kinesis, S3, AWS glue
3 Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks
4 Exp in visualizing/presenting data for stakeholders using: AWS Quicksight, Tableau, Periscope, Business Objects, D3, ggplot",3.9,"Accenture
3.9",Hyderabad,"Dublin, Ireland",10000+ employees,1989,Company - Public,Consulting,Business Services,₹500+ billion (INR),"Cognizant Technology Solutions, EY, McKinsey & Company"
275,Senior Data Scientist,"Your Day-to-day Will Involve
Using modeling and analytics to understand how business decisions impact our bottom line. This may include assessing risks of new products, determining fraud policies, or identifying inefficiencies in existing operations.
Ensuring the team is delivering on our KPIs by using various data mining and data visualization tools to monitor portfolio performance and identify improvement opportunities
Developing hypotheses and set up your own problem frameworks to test for the best solutions. You will also scope the operational feasibility, lead implementation efforts, and monitor the success of your solutions.
Leveraging data analysis tools and technologies. For example, using machine learning to determine how we identify fraud.
Creating new solutions rooted in empathy and research that assist all customers as they work to better manage their finances.
Collaborating in a team environment. As part of our crew, you will learn to energetically rally diverse groups in pursuit of a common goal.

The Ideal Candidate Is
Innovative & Curious - You have the desire and ability to connect and empathize with our customers. You have an entrepreneurial spirit and get excited about creating new businesses and reinventing current ones. You ask why, explore, and bring your unique perspective to the table.
Analytical& Action-Oriented - You are data driven and outcome focused. You grow comfortable with ambiguity, fueled by a hunger to learn and constantly seeking out new challenges. You have a desire to take action, try new things, and sometimes fail. You persevere but know when to change course and are up for juggling multiple deliverables.
Collaborative & Team-Oriented- You always keep the people around you in the loop and are excited to communicate complex ideas clearly to make sure your co-workers understand the why behind their work and their key priorities.
Inclusive- You will empathize with those around you and care about their success, as you bring people together around whats possible.
Basic Qualifications
Bachelors degree or higher in a quantitative field (Business, Math, Economics, Finance, Statistics, Science, Engineering)
At least 1 year of work experience in analysis or consulting
Experience with or willingness to learn tools such as SQL, R, Python, Tableau
We're a purpose-driven company whose beliefs are the foundation for how we conduct business every day. We hold ourselves to our One Team Behaviors, which demand that we hold the highest ethical standards, to empower an open and diverse workplace, and strive to treat everyone who is touched by our business with dignity and respect. Our employees challenge the status quo, ask questions, and find solutions. We want to break down barriers to financial empowerment. Join us as we change the way the world defines financial freedom.
PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities.",3.6,"PayPal
3.6",Bengaluru,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple"
276,Sr Data Scientist - DNA,"Neustar, Inc. is a leading global information services provider driving the connected world forward with trusted, holistic identity resolution. More information is available at https://www.home.neustar.

Job Requisition:

R-1661 Sr Data Scientist - DNA (Open)

Primary Location:

BANGALORE

Job Description:

The Data and Analytics organization at Neustar is the DNA of the company. The DNA encodes the essence of existence and character that drives continuous innovation with data, contin­uous insights with analytics and continuous evolution with cutting-edge data products and services. Our vision is to be the trailblazer in Connection Science driven information services that create meaningful value for our customers. Our mission is to enable cutting-edge data products & services delivered through superior data, unique insights and top-of-the-class technology solutions. We believe in developing a Collaborative, Creative, yet Competitive, Customer Centric culture. We are shaping the present and the future at Neustar and are seeking “TENXERS” who share the same DNA.

Job Description:

The Data Scientist will work on challenging problems extracting actionable information out of the many data sources available to Neustar, particularly geospatial data. They will assist in developing accurate and precise models of user behavior based on this geospatial data using various analytical tools, including data curation, data visualization, supervised, and unsupervised machine learning. The data sets under analysis are large, and growing larger still, and so the data scientist must be proficient in the design and development of CPU and memory efficient algorithms.

Application areas include Identity Resolution, Marketing Analytics Security and Fraud and other Business Solutions supported by our or our client’s data.

Data Scientists create prototypes of new algorithms and support Engineering teams in productizing these capabilities. Data Scientists work closely with various teams including data acquisition, data products, data sciences and various business units including marketing, security, and internet of things to ensure implementation of capabilities that enable the organization’s vision. The role is based out of India at the Neustar's offices in either Bangalore or Hyderabad.

Responsibilities:
Algorithm Development: Develop a deep understanding of all the data relevant to the problem to be addressed. Establish deterministic and probabilistic linkages between data sources and develop ways to extract and summarize the sought information in the data using a wide variety of statistical, data mining and machine learning techniques.
Prototyping: Create prototypes of productizable ways to perform the analysis at scale, provide documentation and help educate your colleagues in different function about the solution
Support Implementation: Closely work with product, engineering and client teams to incorporate Data Science capabilities into Neustar’s products and services
Skills and Experience:
Masters’s degree in Data Science, Statistics or a related field (we will consider applicants with a Bachelor’s degree and relevant work experience as well)
Solid understanding of fundamental data mining and statistics concepts and familiarity with real-world applications of these techniques
Solid knowledge of SQL in its various forms for traditional databases and distributed computing environments
Experience working with commercial and/or open source statistics and data mining packages
Experience working on large distributed datasets using HiveSQL, Spark, Python
Strong written and oral communication skills
Strong inter-personal collaboration skills. Being able to both work in groups or as an individual contributor
General curiosity, a willingness to experiment, pragmatism and the ability to handle ambiguity
Why work with us?
Because you love to build beautiful, innovative solutions that wow the customer
Because you believe in changing the status quo and are up for the challenge of your life
Because you know you can make a difference to people, places and things!
About Us

Every day, the world generates roughly 2.5 quadrillion bits of data. Neustar isolates certain elements and analyzes, simplifies and edits them to make precise and valuable decisions that drive results. As one of the few companies capable of knowing with certainty who is on the other end of every interaction, we’re trusted by the world’s great brands to make critical decisions some 20 billion times a day.

Neustar does not accept unsolicited resumes from external firms or agencies. Neustar will not be responsible for placement fees associated with unsolicited resumes.

DIVERSITY
Diversity, inclusion and teamwork are second nature to Neustar; and these values permeate our entire business structure. Neustar is committed to creating an environment where a wide spectrum of opinions and beliefs are actively sought, listened to and respected. Further, our talented workforce draws from the many geographic areas and markets in which Neustar operates worldwide, which represents a distinct competitive advantage. The rich and varied personal and professional backgrounds of our employees make Neustar a dynamic and rewarding company at which to build a career. We invite you to join us.

EOE of Minorities/Females/Vets/Disability
Neustar, Inc. considers all applicants for employment without regard to race, color, religion, sex, national origin, age, disability, sexual orientation, or status as a Vietnam-era or special disabled veteran in accordance with federal law and other state and local requirements. Neustar, Inc., complies with applicable state and local laws prohibiting discrimination in employment and provides reasonable accommodation to qualified individuals with disabilities in accordance with the American with Disabilities Act (ADA) and applicable state and local laws.",3.7,"Neustar
3.7",Bengaluru,"Sterling, VA",1001 to 5000 employees,1996,Company - Private,Internet,Information Technology,₹50 to ₹100 billion (INR),"Adobe, Akamai, Oracle"
277,Machine Learning Engineer,"ML Practice forms the core of our platform. If solving a problem of unstructured data and building trainable trends is what your forte is, lets talk. The scope of the structure data will be overplayed on subject of Talent Attraction and Engagement.",4.0,"Uncap Research Labs
4.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2018,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
278,Data Analyst,"Our Team

PharmEasy was founded in 2015 with the sole purpose to make healthcare easily available, accessible and affordable to all through the extensive use of new-age cutting-edge technology. Today, we are one of India's largest healthcare aggregators connecting lakhs of patients to licensed pharmacies & diagnostic centres online for all their medical needs. We are particularly catering to the chronic-care segment, and offer a range of services including medicine delivery, tele-consultation, sample collection for diagnostic tests as well as subscription-based services for all these categories.

Our highly efficient and technology led Consumer and Supply-chain platforms ensure that medicines are delivered from a licensed pharmacy within six hours of the validation of prescriptions submitted by our customers. And such customer promises are improving with the increasing scale of our business, and continuous product innovation.

By extensively leveraging the latest in hardware and software technology, we are also committed to eradicate fake medicines from the Pharma ecosystem that contribute to roughly 30% of drug volumes in India. Our product innovations have allowed for complete data transparency in the entire Pharma supply-chain to empower even the end-users to validate the authenticity and genuineness of the medicines for every medicine sold, using constructs such as unique barcoding of information like expiry dates, origination of drugs etc.

With our scalable technology and processes, we are now reliably delivering healthcare services and medicines to every single pin code in the country.

Analytics @ Pharmeasy:
Pharmeasy wants to enable data driven decision-making for achieving the core business objective of the company to make healthcare accessible & affordable to everyone. This would essentially require rigorous efforts being put into all domains of analytics from data collection to data extraction to data cleaning to data wrangling to descriptive analytics and eventually drawing business insights and communicate the same to the relevant business teams. We want to make analytics an integral part of every decision making at Pharmeasy because in today’s world subjectivity is something that is limited to academia and data can answer most of the questions.

Responsibilities :
A Data Analyst would be responsible for supporting the Business Teams for any kind of Data Reporting and Adhoc Data Analysis. The role would include extraction, cleaning, reporting, analysis and visualization of data.

Creating Dashboards/Reports and communicating the same to business team

Identification, Reporting & Tracking of Key Business Metrics at hourly, daily, weekly, monthly frequency

Coordination with Business Teams to identify new reporting requests and enhancing the existing one, business users to be communicated and explained the details if need arises

Testing all new reports/deliverables and periodically reviewing them for maintaining data quality

Data validation and attention to detail is required as the individual will be accountable for quality of all the numbers delivered through dashboards or otherwise

What are we looking for ?

1 to 3 years of work experience in the relevant field, preferably in a consumer facing company

Well versed in MS Excel (vlookup, hlookup, if-else, index, match, countif, sumifs, string operations, Pivot Table & Pivot Table Chart etc.)

Proficient in writing SQL queries and the candidate should be able to handle complex queries

Structured thought process and problem solving skills are a must have

Prioritization of tasks, organised work ethics, high work efficiency are expected

VBA, Macros are an advantage and good-to-have",3.9,"PharmEasy
3.9",Bengaluru,"Mumbai, India",1001 to 5000 employees,2015,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
279,Full Stack Data Scientist,"Description of Duties

The Automotive Supply Chain and Technology team at IHS Markit is in search of a Data Scientist to support its global team's ongoing research and analysis efforts. The research team produces granular forecast dataset and written analyses on the supply chain of parts supplied to automakers with technology, supplier and logistic information. The team generate forecasts on technology trends through multiple research channels and by using many connected and disconnected data sources to drive the forecast.

The position covers an array of critical data-centric activities aimed at enhancing the efficiency of our 70+ strong research team, sustaining the increasing data complexity as well as supporting new product development at one of IHS Markit's fastest growing product lines. The position is based in Gurgaon or Bangalore, India and reports to our U.K.-based Data and Platform operations lead.

Responsibilities and duties
Developing of front-end website architecture
Develop and manage well-functioning back-end databases and applications
Creation of workflows in data science platforms such as KNIME
Data restructuring and transformation for large inter-connected data sets
Harness machine learning and statistical modelling with a view to enhance automation, reduce manual data interaction from research team and develop new insightful products
Identifying, assembling, and enriching a wide range of structured and unstructured data to support new automotive forecasts and analysis
Creation of logical and physical data models as well as conducting quantitative research
Data wrangling and data mining to support product innovation and model creation
Exploring new data acquisition techniques (e.g. Scraping)
Build/maintain ETL infrastructure
Qualifications and skills
3+ years experience as a data scientist or full stack developer with data science touchpoints
At minimum, a Degree in Computer Science, Statistics, Applied Math or related quantitative field with proven work experience in the data operations/scientist field
Familiarity with data science platforms such as KNIME is a must
Familiarity with JavaScript and Python web frameworks critical
Knowledge of API creation and maintenance
Proven experience with SQL and NoSQL databases like Oracle DB, SQL Server, MongoDB, MySQL, Hadoop, Spark, AWS (EC2 and S3)
Proven experience with one or more programming/scripting languages (e.g. Python, R) is highly desirable
Familiar with techniques to manage large databases, including partitioning, compression and indexes as well as data mining
Ability to build models (e.g. Linear regression, logistic, Markov models) and use one or more machine learning library/frameworks (e.g. Scikit-learn) with a view to solve complex high dimensional data
Knowledge of OLAP and ETL processes
Established MS Office skills (including VBA and Access)
Good communication skills, collaborative team spirit, curiosity to constantly keep thinking of unique approaches and solutions.
Ability to work independently.
Experience committing to deadlines whilst multi-tasking
-----------------------------------------------
IHS Markit is committed to providing equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by the laws and regulations in any of our locations.

We are proud to provide reasonable accommodations to applicants with disabilities. If you are interested in applying for employment with IHS Markit and need special assistance or an accommodation to use our website or to apply for a position, please contact or call +1 212 849 0399. Determination on requests for reasonable accommodation are considered on a case-by-case basis. This contact information (email and phone) is intended for application assistance and accommodation requests only. We are unable to accept resumes or provide information about application status through the phone number or email address above. Resumes are only accepted through the online application process, and only qualified candidates will receive consideration and follow-up.

IHS Markit maintains a substance-free workplace; employees may be asked to submit to a drug test (where permitted by law). In addition, as a federal contractor in the United States, the company participates in the E-Verify Program to confirm eligibility to work.

For information please click on the following links:

IHS Markit Business Code of Conduct
Right to Work
EEO is the Law
EEO is the Law Supplement
Pay Transparency Statement

-----------------------------------------------

Current Colleagues

If you are currently employed by IHS Markit, please apply internally via the Workday internal careers site.",3.5,"IHS Markit
3.5",Bengaluru,"London, United Kingdom",10000+ employees,2016,Company - Public,Consulting,Business Services,₹100 to ₹500 billion (INR),"Thomson Reuters, International Data Group"
280,Data Analyst,"We are looking for talented engineers to shape unique, user-centric product experiences. The ideal candidate should have the ability to work with agile teams of developers, designers and customers.

The Job location is Pune, India. The candidate is required to work closely with the development teams in India and the UK.

About GivingForce

GivingForce is a software product company headquartered in London, UK. This software is used by global corporations to engage employees with charitable activities. GivingForce aims at identifying and removing barriers that would otherwise prevent corporations from engaging in corporate responsibility programmes. We have pioneered the development of a system by bringing all giving back activities to one place including volunteering, payroll giving, company matching and corporate donations amongst others. So far we have processed over 1.25 million volunteer hours and 250 million pounds in donations.

Main responsibilities:
Filter and “clean” data by reviewing pre-existing reports to locate and correct code problems
Support initiatives for data integrity and optimisation
Interpret data, analyse results using statistical techniques and help developing reports and analysis
Troubleshoot database environment and reports
Evaluate changes and updates to production systems/databases
Training end-users on new reports and dashboards
Providing technical expertise in data storage structures, data mining, and data cleansing
Identify, analyse, and interpret trends or patterns in complex data sets
Work with management to prioritise business and information needs
Locate and define new process improvement opportunities
Collaborate with other team members and stakeholders

Education and experience:
Degree in Mathematics, Information Management or Statistics, Computer Science, Engineering or a related subject having first-class
5+ years of experience as Data Analyst

The candidate must have the following technical skills:
Proven working experience as a data analyst or business data analyst
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Technical expertise regarding data models, data mining and segmentation techniques
Strong knowledge of and experience with data analytics and reporting platforms (e.g. Tableau, Looker BI, Power BI or other similar platforms), databases (MySQL, Oracle, SQL Server etc)
Demonstrated experience in handling large data sets and relational databases
Ability to translate technical requirements into non-technical, lay terms
Creative approach to problem-solving with the ability to focus on details while maintaining the “big picture” view
Open for learning new technologies and domain
Strong verbal and written communication skills, analytical skills and the ability to learn quickly
Time management skills and the ability to work under serious deadlines

We offer:
Great learning environment
Flexible work hours
Work from home option
Health Insurance
Opportunity for progression in the firm
Salary no bar for the right candidate

If you’re interested, we look forward to hearing from you!

Please apply or send any questions to careers.india@givingforce.com",1.3,"GivingForce Limited
1.3",India,"Pune, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
281,Data Analyst,"Data Analyst

Corporate Solutions

What this job involves

Delivery of Client Satisfaction

Establish the vision and strategy of the account plan ensuring there is alignment with the client objectives and interests

Directing all transportation activities and developing client relationships

Should be responsible for personnel, monitoring their progress and being their first point of contact should a problem arise making communication skills vital. These communication skills are also vital in the development of customer relationships, managing questions and complaints calmly and decisively

Drive the account plan to deliver high quality results, which exceed the client’s expectations

Become a reference for best in class service delivery that can be leveraged to expand Jones Lang LaSalle’s business

Recognizes opportunities for account growth then articulate the value proposition and ensures its implementation across the platform

Must also be involved in strategic development and the maintaining of any administrative records, regularly communicating with the delivery manager to ensure smooth operation

Must also be aware of all transport legislation and procedures to ensure company compliance

Directs the client team, and leverages experts within the broader organization, to ensure exceptional results are delivered to the client, exceeding key performance indicators

Proactively solicits and responds to feedback and input from client

Establishes and maintains effective relationships with customers and gains their trust and respect

Confronting climate change issues by implementing transport strategies and monitoring an organisation’s carbon footprint

Is responsible for organising and overseeing all health and safety checks and routine vehicle checks and adhering to both company and statutory requirements

Dealing with the effects of congestion

Builds and Manages High Performing Teams

Ensures the best qualified candidate is hired for all roles on the account

Thoroughly and critically assesses direct reports (and directs directs)

For every direct report, build actionable and measurable career development plans; direct report in consistent conversations regarding progress

Advances the firm’s diversity and inclusion priorities by focusing on talent moves, i.e. hiring, rotation and promotion

Provides point in time coaching to elevate performance

Achieve Financial Result

Manages account financials to ensure plan is met or exceeded in both growth and profitability

Retain all current business lines and expand the book of business with the client to extend beyond existing product lines or geography

Mitigates risk for the organization by ensuring A/R is maintained below 60 days payable

Putting best practices in place

Do you like sharing ideas to improve the work process? As our Data Analyst you’ll contribute to the creation of facilities service delivery standards. You’ll also help in the planning, implementation and review of site-specific processes and protocols.

Teamwork should also be one of your strongest points, as you’ll work with a team to ensure that all performance targets set out in the contract are being met. To do this, you’ll develop tools that help measure the technical team’s performance on a quarterly or annual basis.

Sound like you? To apply, you need to be:

A technical hands on expert

An ideal candidate would have a university degree or professional qualification in engineering or facilities management, and over four years’ experience in facilities operation. A strong background in troubleshooting processes is a big plus.

Good communicator

Do you have an excellent command of spoken and written English language? Can you communicate technical issues to less able colleagues, clients and vendors? If you said yes to these, bring your ambition and explore our world of possibility.

What we can do for you:

At JLL, we make sure that you become the best version of yourself by helping you realise your full potential in an entrepreneurial and inclusive work environment. We will empower your ambitions through our dedicated Total Rewards Program, competitive pay and benefits package.

Apply today!

JLL Privacy Notice

Jones Lang LaSalle (JLL), together with its subsidiaries and affiliates, is a leading global provider of real estate and investment management services. We take our responsibility to protect the personal information provided to us seriously. Generally the personal information we collect from you are for the purposes of processing in connection with JLL’s recruitment process. We endeavour to keep your personal information secure with appropriate level of security and keep for as long as we need it for legitimate business or legal reasons. We will then delete it safely and securely.

For more information about how JLL processes your personal data, please view our Candidate Privacy Statement.

For additional details please see our career site pages for each country.

For employees in the United States, please see a fully copy of our Equal Employment Opportunity and Affirmative Action policy here.

Jones Lang LaSalle (“JLL”) is an Equal Opportunity Employer and is committed to working with and providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process – including the online application and/or overall selection process – you may email us at Accommodation.Reques@am.jll.com. This email is only to request an accommodation. Please direct any other general recruiting inquiries to our Contact Us page > I want to work for JLL.",4.0,"JLL
4.0",Bengaluru,"Chicago, IL",10000+ employees,-1,Company - Public,Real Estate,Real Estate,₹500+ billion (INR),"CBRE, Cushman & Wakefield"
282,Senior Data Scientist,"We required Senior Data Scientist who will work as leader, set the direction for the team, deciding on the best methodology to address complex business problem, generating models pipelines and pulling useful insights to make decisions.
One will be an expert in data science, machine learning and statistics, with extensive hands-on experience and the ability to balance technical and business considerations to make the right decisions. They will be a self-starter, with strong attention to detail, an ability to work in a fast-paced and ever-changing environment. They will have excellent oral and written communication skills to communicate effectively with both technical and non-technical stakeholders.

Responsibilities
Work closely with business of Finance, Retail, Automotive etc. to understand requirements effectively
Applying Statistical, Data Science, Machine Learning or other innovative methods to specific business problems and data
Provide technical leadership, research new machine learning approaches to drive continued scientific innovation.
Working with other engineers to solve technical problems.
Skills and Experience
M.S. or Bachelor in Computer Science, Machine Learning, Statistics, Applied Mathematics or related discipline
PhD in quantitative field (Computer Science, Mathematics, Machine Learning, AI, Math, Statistics, or equivalent) is big plus
Extensive knowledge and practical experience in machine learning, statistics, NLP, deep learning, information retrieval
Good communication skills and ability to work with a team
Ability to manage and quantify improvement in customer experience or value for the business resulting from research outcomes
Are you ready ?

What are you waiting for, if above mentioned job details match to skills, send us your updated resume at hello@crossml.com",-1,CrossML,Chandigarh,-1,-1,-1,-1,-1,-1,-1,-1
283,Senior Data Scientist - AWS Professional Services,"Excited by using massive amounts of data to develop Machine Learning (ML) and Deep Learning (DL) models? Want to help the largest global enterprises derive business value through the adoption of Artificial Intelligence (AI)? Eager to learn from many different enterprises use cases of AWS ML and DL? Thrilled to be key part of Amazon, who has been investing in Machine Learning for decades, pioneering and shaping the worlds AI technology?
At Amazon Web Services (AWS), we are helping large enterprises build ML and DL models on the AWS Cloud. We are applying predictive technology to large volumes of data and against a wide spectrum of problems. Our Professional Services organization works together with our AWS customers to address their business needs using AI.

AWS Professional Services is a unique consulting team. We pride ourselves on being customer obsessed and highly focused on the AI enablement of our customers. If you have experience with AI, including building ML or DL models, wed like to have you join our team. You will get to work with an innovative company, with great teammates, and have a lot of fun helping our customers.

If you do not live in a market where we have an open Data Scientist position, please feel free to apply. Our Data Scientists can live in any location where we have a Professional Service office.

A successful candidate will be a person who enjoys diving deep into data, doing analysis, discovering root causes, and designing long-term solutions. It will be a person who likes to have fun, loves to learn, and wants to innovate in the world of AI. Major responsibilities include:
· Understand the customers business need and guide them to a solution using our AWS AI Services, AWS AI Platforms, AWS AI Frameworks, and AWS AI EC2 Instances .
· Assist customers by being able to deliver a ML / DL project from beginning to end, including understanding the business need, aggregating data, exploring data, building & validating predictive models, and deploying completed models to deliver business impact to the organization.
· Use Deep Learning frameworks like MXNet, Caffe 2, Tensorflow, Theano, CNTK, and Keras to help our customers build DL models.
· Use SparkML and Amazon Machine Learning (AML) to help our customers build ML models.
· Work with our Professional Services Big Data consultants to analyze, extract, normalize, and label relevant data.
· Work with our Professional Services DevOps consultants to help our customers operationalize models after they are built.
· Assist customers with identifying model drift and retraining models.
· Research and implement novel ML and DL approaches, including using FPGA.

This role is open for Mumbai/Pune/Bangalore/Chennai/Hyderabad/Delhi/Pune.


Basic Qualifications

· A Bachelor or Masters Degree in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.) or equivalent experience
· 10+ years of industry experience in predictive modeling, data science and analysis
· Previous experience in a ML or data scientist role and a track record of building ML or DL models
· Experience using Python and/or R
· Knowledge of SparkML
· Able to write production level code, which is well-written and explainable
· Experience using ML libraries, such as scikit-learn, caret, mlr, mllib
· Experience working with GPUs to develop models
· Experience handling terabyte size datasets
· Track record of diving into data to discover hidden patterns
· Familiarity with using data visualization tools
· Knowledge and experience of writing and tuning SQL
· Past and current experience writing and speaking about complex technical concepts to broad audiences in a simplified format
· Experience giving data presentations
· Extended travel to customer locations may be required to deliver professional services, as needed
· Strong written and verbal communication skills

Preferred Qualifications

·
· PhD in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.)
· 12+ years of industry experience in predictive modeling and analysis
· Good skills with programming languages, such as Java or C/C++
· Ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations
· Consulting experience and track record of helping customers with their AI needs
· Publications or presentation in recognized Machine Learning, Deep Learning and Data Mining journals/conferences
· Experience with AWS technologies like Redshift, S3, EC2, Data Pipeline, & EMR
· Combination of deep technical skills and business savvy enough to interface with all levels and disciplines within our customers organization
· Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment",4.2,"Amazon
4.2",India,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
284,Data Analyst,"We're looking for a
Data Analyst (Pune, India)


Role: Data Analyst (Pune, India)

We are seeking a data analyst with exceptional bookkeeping, accounting, and financial variance analysis skills. This position will help to drive the success of the business by providing detailed department level expense data in real-time (using NetSuite). This role will report to the manager of the Company's finance and accounting team in India and would be supporting various functions within the Finance department, with the FP&A team being the primary customer. Additionally, the person will also have to liaise closely with the US/Canada based Accounting team, as well as operations managers in the various functional areas (R&D, Sales & Marketing, G&A). We are looking for a fast learner who is focused, intelligent, dependable, detail-oriented and possesses a “can-do” attitude. We provide an attractive environment for career advancement in a fast growing, dynamic technology company.

In this role you will…

· Develop a thorough understanding of the business and conduct detailed investigation of expenses booked in the general ledger daily.

· For major categories of expenses that appear in the G/L without adequate “expense purpose” description fields being populated, you will investigate and populate these data fields with standardized inputs that add more color to the expenses incurred.

· Gain a deep understanding of departmental budgets, as well as perform analytics on Coups purchase orders to support the FP&A team.

· Assist in the ongoing preparation of monthly, quarterly, and annual (multi-year) US GAAP forecasts, including budget to actual variance analysis, scenario/sensitivity analysis, rolling forecasts, etc.

· Assist in preparation of monthly reports; including sales analysis, bookings analysis, P&L, Balance Sheet, Cash Flow, and supporting schedules, as needed.

· Provide support and assist with ad-hoc requests and special projects to support business initiatives.

· Analyze current internal business processes and improve efficiency.

You’ve got what it takes if you have…

· Bachelor’s degree in Accounting, Finance, Business Administration, Economics, or equivalent working experience

· 2+ years’ work experience in accounting, corporate finance, financial planning & analysis, or other related fields.

· Strong working knowledge of Excel

· Formulas and Functions, including: Pivot tables, Vlookups, Nested IF statements, Logic statements, etc. are a major plus.

· Experience in cash flow reporting, financial close processes, and accounting principles in computer software or related industries.

· Strong research, analytical skills, pro-active problem-solving skills, and self-motivation to perform tasks above and beyond responsibility, in a timely manner.

· Must be capable of working in fast-paced and changing environment; be self-directed; and work well as a team player.

· Excellent written and verbal communication skills in English

Extra Dose of Awesome if you have…

· Ready to work in EMEA Shifts

· Netsuite Experience

· Coupa and Salesforce.com knowledge

· An interest in working for a technology company and are familiar with the SaaS business model

· Experience in a start-up environment

· Financial modeling experience in Excel

#LI-GC1

Our Culture:

Our mission is to empower people, businesses and communities. A culture created less by what we do and more by who we are. When people are asked to describe the team, the answer is always the same: smart, cool, dependable, and visionary. We are not a typical tech company (paid sabbaticals, generous stock units, education reimbursement, and 100% paid employee health coverage), because, well, our employees aren't your typical techies...
We're always on the lookout for new, curious and capable people who can help us achieve our goal. So if you want to work for a friendly, global and innovative company, we'd love to meet you!

What We Do:

Cornerstone OnDemand (NASDAQ: CSOD) was founded with a passion for empowering people through learning and a conviction that people should be your organization’s greatest competitive advantage. Cornerstone is a global human capital management (HCM) leader with a core belief that companies thrive when they help their employees to realize their potential. Putting this belief into practice, Cornerstone offers solutions to help companies strategically manage and continuously develop their talent throughout the entire employee lifecycle.

Cornerstone’s HCM platform is successfully used by more than 75 million people in 180+ countries and in 40+ languages.

Check us out on Linkedin, The Muse, Glassdoor, and Facebook!",3.9,"Cornerstone OnDemand
3.9",Pune,"Santa Monica, CA",1001 to 5000 employees,1999,Company - Public,Enterprise Software & Network Solutions,Information Technology,₹50 to ₹100 billion (INR),"SAP, Oracle, Workday"
285,Data Scientist - Trainer,"We are looking for a experienced Data scientist to join our growing team. The one who is passionate for teaching and having the ability to deliver high quality training on the mentioned areas are welcome.

Roles and Responsibilities
Conduct classroom training sessions by providing practical use cases and assignments.
Mine and analyze data from company databases to drive optimization and improvement of product development.
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
Design and make the trainees develop mini or major real time projects for practical exposure.
Skills Required
Professional experience in training students in Data Science project.
Highly proficient in SQL with ability to write efficient queries and taking data from multiple data-sets as and when required.
Should have a strong working knowledge in Excel and proficiency in either R or Python for automation purposes.
At least 1 year of experience in Data Science and Programming skills in Python, R, SQL programming with the ability to quickly create prototype and debug solutions.
Qualifications
Educational qualification – (Bachelors/ Masters) in Computer Science/ IT,Engineering, Information Systems, Math’s/Statistics or Equivalent.
Positive, people-oriented, and energetic attitude.
Analytical, creative, and innovative approach to solving problems.
Strong written and verbal communication.
Experience - (6 months - 2 yrs)

Job Type: Full-time

Salary: ₹15,000.00 to ₹25,000.00 /month

Experience:
total work: 1 year (Preferred)
Education:
Bachelor's (Preferred)",-1,ACUWIN INNOVATIONS Pvt Ltd.,Thiruvananthapuram,-1,-1,-1,-1,-1,-1,-1,-1
286,Data Analyst,"Job Title: Data Analyst
Location: Chennai

This role will be responsible for the data analysis, requirement capture, stakeholder management and IMCC mailing.
What will you be doing?
Support / manage the design and development of process solutions to meet the agreed business requirements including management information requirements and mitigation of risks (via appropriate controls / reconciliations) within the technology / process solutions
Proficiency and Experience in Teradata/SQL is mandatory
HADOOP Experience preferably in Hive, Impala and Spark is required.
Support Customer Targeting manager to deliver data discovery and participate in data walkthroughs
Contribute to create Risk Assessments on activity to support in the mitigation of known risks.
Create / Develop Data Dictionaries working with campaign delivery managers to support testing and build of letter though OTX (include testing scenarios & validation)
Help define improvements for the bank in terms of Products & Customer / Colleague experience
Ability to work across different lines of business in Barclays and interact with a spectrum of people
Ability to map business requirements to tools / technology stacks
Provision of business analysis skills
Production and review of functional and non-functional specifications
Providing data analysis to support the delivery of the strategy, propositions & plans in order to maximise the functions knowledge & intelligence.

What were looking for:
Strong Knowledge in Data warehousing.
Strong Knowledge and Hands on Experience in Teradata.
Unix expertise
Meticulous attention to detail

Skills that will help you in the role:
Knowledge and Hands on Experience in HADOOP - HDFS File System
Knowledge and Hands on experience in tools like Ab Initio, SAS

Where will you be working?
Chennai

Be More at Barclays
At Barclays, each day is about being more as a professional, and as a person. Be More @ Barclays represents our core promise to all current and future employees. Its the characteristic that we want to be associated with as an employer, and at the heart of every employee experience. We empower our colleagues to Be More Globally Connected, working on international projects that improve the way millions of customers handle their finances. Be More Inspired by working alongside the most talented people in the industry, and delivering imaginative new solutions that are redefining the future of finance. Be More Impactful by having the opportunity to work on cutting-edge projects, and Be More Valued for who you are.
Interested and want to know more about Barclays? Visit home.barclays/who-we-are/ for more details.

Our Values
Everything we do is shaped by the five values of Respect, Integrity, Service, Excellence and Stewardship. Our values inform the foundations of our relationships with customers and clients, but they also shape how we measure and reward the performance of our colleagues. Simply put, success is not just about what you achieve, but about how you achieve it.
Our Diversity
We aim to foster a culture where individuals of all backgrounds feel confident in bringing their whole selves to work, feel included and their talents are nurtured, empowering them to contribute fully to our vision and goals.
Our Benefits
Our customers are unique. The same goes for our colleagues. That's why at Barclays we offer a range of benefits, allowing every colleague to choose the best options for their personal circumstances. These include a competitive salary and pension, health care and all the tools, technology and support to help you become the very best you can be. We are proud of our dynamic working options for colleagues. If you have a need for flexibility, then please discuss this with us.",3.9,"Barclays
3.9",Chennai,"London, United Kingdom",10000+ employees,1690,Company - Public,Banks & Building Societies,Finance,₹500+ billion (INR),"Deutsche Bank, HSBC Holdings, Royal Bank of Scotland"
287,CIEL/SEL/1942: Jr data scientist,"Job Description

Specific Job Experience or Skills Needed

Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desirable.
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model

Responsibilities
:
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
:• Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
288,Data Analyst / Data Scientist | Internship | Tech-Savvy|,"Job role:

As a data analyst, you will be responsible for compiling actionable insights from data and assisting program, sales and marketing managers build data-driven processes. Your role will involve driving initiatives to optimize for operational excellence and revenue.

Job Location: Indore | Full-Time Internship | Stipend - Performance Based |

About the company:

Anaxee Digital Runners is building India's largest last-mile verification & data collection network of Digital Runners (shared feet-on-street, tech-enabled) to help Businesses & Consumers reach remotest parts of India, on-demand. KYC | Field Verification | Data Collection | eSign | Tier-2, 3 & 4

Sounds like a moonshot? It is. We want to make REACH across India (remotest places), as easy as ordering pizza, on-demand. Already serving 11000 pin codes (57% of India) | Website: www.anaxee.com

Important: Check out our company pitch (6 min video) to understand this goal - https://www.youtube.com/watch?v=7QnyJsKedz8

Responsibilities:
Ensure that data flows smoothly from source to destination so that it can be processed
Utilize strong database skills to work with large, complex data sets to extract insights
Filter and cleanse unstructured (or ambiguous) data into usable data sets that can be analyzed to extract insights and improve business processes
Identify new internal and external data sources to support analytics initiatives and work with appropriate partners to absorb the data into new or existing data infrastructure
Build tools for automating repetitive tasks so that bandwidth can be freed for analytics
Collaborate with program managers and business analysts to help them come up with actionable, high-impact insights across product lines and functions
Work closely with top management to prioritize information and analytic needs
Requirements:
Bachelors or Masters (Pursuing or Graduated) in a quantitative field (such as Engineering, Statistics, Math, Economics, or Computer Science with Modeling/Data Science), preferably with work experience of over [X] years.
Ability to program in any high-level language is required. Familiarity with R and statistical packages are preferred.
Proven problem solving and debugging skills.
Familiar with database technologies and tools (SQL/R/SAS/JMP etc.), data warehousing, transformation, and processing. Work experience with real data for customer insights, business, and market analysis will be advantageous.
Experience with text analytics, data mining and social media analytics.
Statistical knowledge in standard techniques: Logistic Regression, Classification models, Cluster Analysis, Neural Networks, Random Forests, Ensembles, etc.",4.0,"Anaxee Digital Runners Pvt Ltd
4.0",Indore,"Indore, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
289,Data Science Optimization,"COMPANY OVERVIEW
Tata Group is an Indian multinational conglomerate company headquartered in Mumbai, India. It encompasses seven business sectors: communications and information technology, engineering, materials, services, energy, consumer products and chemicals. Tata Group was founded in 1868 by Jamsetji Tata as a trading company. It has operations in more than 80 countries across six continents. Tata Group has over 100 operating companies with each of them operating independently.
Tata Sons is the promoter of all key Tata companies and holds the bulk of shareholding in these companies.

BACKGROUND The Tata companies together serve over million consumer and commercial customers today across several products and services. In order for the Tata companies to better understand customer and client needs and preferences, action life stages, needs, value, and potential, and enhance value and experience; the Tata companies need to develop robust data and information management capability and customer analytics. The vision is to eventually create the best in-house capability for data analytics amongst any large corporate. To achieve the above aims, it has been decided to establish an independent Tata company focused on building a common data analytics platform and help Tata Group companies. This company is being incubated in the initial phase as a division of Tata Industries and will subsequently be structured as a separate company to build Big Data Analytics and Data Science capabilities catering to but not limited to the ‘Consumer’ brands of the group.

Tata Insights and Quants – Journey to Date
Company: Tata - Insights and Quants – A Newly started division by Tata Industries.
http://www.livemint.com/Companies/PCgvCZILuJKV68UKVHZRJO/With-new-analytics-arm-Tata-aims-to-make-better-sense-of-da.html
Employer Brand: Tata iQ in 18 months of its inception was recognized in the list of Analytics India Magazine’s (AIM)
Top 10 most desirable Analytics Indian Firms to work for in 2016:
http://analyticsindiamag.com/top-10-analytics-firm-wish-worked-2016/
Generating Value for Customer: Fourteen Tata companies are partnering Tata Insights and Quants (Tata iQ), a Big Data firm, to analyse data collected from users, consumers and make sense of it to put changes in place
http://www.livemint.com/Companies/5om8ebrv6p02jGCcRB3j3K/Tata-companies-use-Big-Data-to-craft-strategies.html

Contributing to Community through big data:
In line with the Tata group’s philosophy of giving back more to the society than what it takes, Tata iQ, Tata group’s big data and decision Sciences Company.
Okhai partners with Tata iQ to deliver big impact through big data

Company : Tata Insights and Quants
Role : Data Science Optimization
Level : Analyst – Associate - Senior Associate
Role Type : Individual Contributor
Location : Mumbai | Bangalore | Jamshedpur | Kalinga Nagar – All Options open

Key Responsibilities:
Apply Optimization/ Simulation algorithms using a variety of tools to improve process efficiency across business functions
Perform detailed analysis of business problems and technical environments in designing the solution
Conversion (Formulation) of business problem into a mathematical model using Linear/Mixed Integer Programing technique
Apply Optimization/ Simulation algorithm:

o Simplex
o Interior Point
o Cutting Plain
o Dynamic Program
o Linear/ Mixed Integer Program
o Agent Based Simulation
o Discrete Event Simulation
o Column Generation

Apply Optimization/ Simulation:

o Logistics/ Inventory planning
o Job Scheduling
o Stock Cutting
o Network Optimization
Build mathematical optimization models using tools, such as AIMMS, CPLEX, GLPK, to model business problems in support of decision-making
Lead and manage Proof of Concepts and demonstrate the outcomes quickly
Document use cases, solutions and recommendations
Work analytically in a problem-solving environment
Work in a fast-paced agile development environment
Coordinate with different functional teams to implement models and monitor outcomes
Work with stakeholders throughout the organization to identify opportunities for leveraging organization data and apply Optimization/ Simulation techniques to improve process efficiency across business functions - Operations, Products, Sales, Marketing, HR and Finance teams
Help program and project managers in the design, planning and governance of implementing Optimization/ Simulation solutions
Experience and Skills:
Experience in Manufacturing, Aviation and Logistics
3+ year of work experience in optimization, simulation and data science
Experience using AIMMS, CPLEX, GLPK, GUROBI etc.
Experience in building Predictive models (Regression, Classification and Clustering) and Forecast models will be an added advantage
Experience in Python and R will be an added advantage
>Education qualification:
Bachelors/ Master degree in Operations Research, (Applied) Mathematics, (Applied) Statistics, Industrial Engineering or other disciplines with significant experience in mathematical optimization
Reach us on careers@tataiq.com",4.0,"Tata Insights and Quants
4.0",Mumbai,"Zug, Switzerland",10000+ employees,1980,Unknown,Architectural & Engineering Services,Business Services,Unknown / Non-Applicable,-1
290,Senior Data Scientist,"Experience : 7-9 years of experience of which at least 6-7 must be hands on in DataScience related work
Location: Bangalore

Desired Skills and Experience

Expert understanding and demonstrated skills of using ""R"". Exposure to SAS, Python, SPSS,Julia etc also an advantage.
Excellent ability to assimilate multi-disciplinary problems across industries, createhypotheses and craft solutions using data science skills and techniques.
Bring together different technologies to solve a problem.
Strong understanding of databases, file systems (big data stores, especially) anddatabase/SQL languages.
Very strong articulation skills. Articulation skills are both oratory and written.

Responsibilities

The individual will be a designer of solutions that address specific business outcomes. These will be across industries and functions and must be designed generically to handle reuse. Sometimes the questions will be unknown, which theindividual must creatively discover and solve.
Solutions will be complete packages of BI and advanced data science related models in ""R"".
The individual will understand the nanobi platform and lead the integration of the models and deliver the solutions on the nanobi platform for client deployment.
Work very closely with sales, pre-sales and consulting to understand customer problem specifics and solve them for wider application. In this, the individual mayhave to spend time closely at customer locations.
Must provide direction and leadership to Jr. Data Scientist in their model development.
Will also have to work with functional experts in other teams to build out businessrepresentations of the data science Work.",3.0,"Nanobi
3.0",Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
291,Data Analyst (Commercial Pharma),"Data Analyst (Commercial Pharma)
Greetings from P360!!
The Analyst will support Sales Force Effectiveness and/or Marketing Science business unit by taking a lead role on projects, as well as mentoring junior staff development with minimal supervision from manager or senior staff.
Location: Remote Location/Work from Home.
Job Title: Data Analyst
Experience: 4-6 years of relevant work experience
Key responsibilities:
Work with clients to understand their analytics and business needs for developing and delivering solutions that will provide critical insights through sophisticated quantitative analyses and data modelling.
Deliver operational analytics, sales operations or business technology oriented projects for sales operations teams within the Life Science industry.
Projects will be primarily related to (but not limited to) incentive compensation, customer targeting, and call planning (response model based), sales force design, promotion evaluation, ad-hoc analysis and reporting.
Apply advanced statistical, econometric and optimization models and algorithms to real-world business problems.
Work hands-on with client business teams with limited or no supervision.
Make presentations and recommendations to clients on optimal customers, sales, and marketing strategies and tactics.
Design project plans and manage client expectations and communication plans for project delivery.
Create documents such as business requirements, functional requirements, business rules, analytics plans, quality checklists, etc. for use by both internal and external customers.
Contribute in business development efforts by creating sales pitches, case studies, solutions for business problems
Mentor junior staff

Qualifications:
Education/Experience
BE/BS Degree or equivalent experience required in Statistics, Computer Science, Information Technology, or any other healthcare related major with quantitative background is preferred. Advanced degree in a relevant area is desirable but not necessary.
3+ years of related experience in Sales/Brand analytics, commercial operations
Sales Operations experience directly in life sciences is significantly valuable.
Skills:
Knowledge of various data source such as Xponent, APLD, DDD, HCOS (from IMS or Symphony), Specialty Data, Calls, Sample, Claims, etc.
Analytical problem solving skills, able to identify and link patterns among data sets, analyze and extrapolate market trends and patterns, and to distill large data sets into meaningful information
In-depth understanding of purpose and process of certain areas in Sales Force Effectiveness and Market Sizing, as well as of the linkage between other business areas. Must be able to assess the impact of other areas and provide business and technical solutions.
Strong presentation skills, good at developing and presenting findings and recommendations from analysis and reporting to key internal and external customers.
Effective oral and written communication skills that enable personal impact with senior-level decision makers
Able to manage multiple projects, priorities, resources and timeline
Strong attention to detail, with a quality-focused mindset
Experience working with US pharma/Bio-Pharma Clients
Promotes and generates innovation and cooperation within and cross teams (onsite-offsite) to achieve a collective outcome.
P360
P360 is a Microsoft Gold Partner and leading provider of technical solutions for the life sciences industry. At P360, our team leverages over 25 years of industry expertise to guide life science companies in defining and executing commercial and clinical strategy. Built on Microsoft’s cloud platform to facilitate a successful digital transition to Pharma 3.0—a patient-centric, high-capability commercial business strategy. When companies partner with P360, organizations access a vast array of cutting-edge, business-enhancing solutions and services that drive your capabilities far beyond your competitors in the marketplace.",4.8,"P360
4.8",Mumbai,"Piscataway, NJ",51 to 200 employees,2015,Company - Private,IT Services,Information Technology,₹500 million to ₹1 billion (INR),-1
292,Data Scientist- AI,"Description:
Lymbyc is the first and currently the only player, in the predictive engine-based self-service analytics product space for end business users. We have created the world’s first data scientist, Leni, capable of understanding plain English queries from user, and autonomously being able to take decisions ranging from data selection to algorithm selection and finally visualisation and narratives, without any human intervention. And now we are embarking on bringing explainable component to our AI based solutions, to make the business decisions simpler, easier and adaptable to larger stakeholders.

By way of our acquisition, we at Lymbyc now are working full tilt with LTI’s global reach to take Leni to the world’s major businesses.

Descriptions

We need ace data scientists who can develop best in class predictive models, machine learning models and deep learning models and at the same time they should be able to explain the decisions taken by the models automatically through plain simple English language. The explainable elements should not be limited to the numbers and formulas, there must be a bit of personalization also to understand the context of the problem.

Roles and Responsibilities:
Passion for learning new technologies and be up to date with the scientific research community.
Work in technical teams in development, deployment, and application of machine learning solutions, leveraging technical components and explaining the modelling decisions
Take responsibility for insights, reports and explanability of the decisions taken by predictive models
Responsible for taking an idea from concept to production thoroughly with feedback from all stakeholders.

Qualification:
Masters’ in Computer Science/M. tech/PhD/Statistics/Econometrics/Applied Mathematics/Applied Statistics/Operations Research is a must
Hands on Experience with data mining or machine learning, deep learning, computer vision, natural language processing
Hands on Experience in developing deep learning models and explaining the results of deep learning models in a business-friendly manner

Skills Required:
Must have minimum of 3-5 years of industry experience in developing data science models.
Deep understanding and experience in the field of Machine Learning, Deep Learning and statistical learning
The person should be excellent at Classification (logistic regression, svm, decision tree, random forest, neural network), Regression (linear regression, decision tree, random forest, neural network), Classical optimisation (gradient descent, newton rapshon, etc), Graph theory (network analytics), Heuristic optimisation (genetic algorithm, swarm theory)
Should be strong at Deep leaning (CNN, LSTM, RNN, Bi-LSTM)
Must have thorough mathematical knowledge of correlation/causation, decision trees, classification and regression models, recommenders, probability and stochastic processes, distributions, priors and posteriors.
Skilled at scientific programming languages such as Python, R, Matlab and writing deployable code into production.
Understand the model lifecycle of cleansing/standardizing raw data, feature creation/selection, writing complex transformation logic to generate independent and dependent variables, model selection, tuning, A/B testing and generating production ready code.
Knowledge of Numerical optimization, Linear/Non-linear/Integer programming, Statistics, Combinatorial optimization is a plus.
Familiarity with R, Apache Spark (Scala, Python), PyMC3/theano/tensorflow/Keras and other scientific python/R modules is a must.
AI skillsets – hands-on Machine learning and Deep Learning algorithms and platforms, neural networks in any, or all the following areas, specifically, in Data & Analytics use cases
Language – Natural Language Processing, machine translation, emotion detection, language detection, classification
Vision – computer vision, object recognition/tracking, face/gender/age/emotion recognition, OCR/handwriting recognition
Knowledge and experience in some of the key AI platforms will be important, e.g. IBM Watson, Microsoft Azure, Google Api.Ai, Facebook Wit.Ai, Chatbots using Microsoft Bot Framework
Knowledge and experience of key machine learning and deep learning framework, e.g. Keras, TensorFlow, Caffe, CNTK, Jiraffe, MXNet and PyTorch commercial technologies/platforms, etc",3.5,"Lymbyc Solutions
3.5",Bengaluru,"Bengaluru, India",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
293,Data Engineer,"requirements
You have at least 1 year of experience working and scaling with data pipelines and warehouses.
You have good understanding of at least 1 programming language.
You have worked on problem statements including batch-processing.
You know the basics and internal workings of at least one database/data warehouse/data lake and understood the workings in depth.
You have a knack to deep-dive into the use-cases of data, not just the technical aspects.

Bonus Requirements

Knowledge about AWS Redshift data warehouse
Understanding of AWS resources and serverless computing
Knowledge on Kubernetes (preferable Amazon EKS)
Exposure to any orchestration tool (preferably Airflow)
description

Postman leads the way in the API-first universe. Postmanâ€™s API Development Environment is used by 10+ million developers and more than 500,000 companies to access 250+ million APIs every month.

We are looking for a Data Engineer in data team to help us scale the existing infrastructure and in parallel work on next generation data tools including data scrapping, machine learning infrastructure and data validation systems.

Data team at Postman acts as a central function, catering to the needs of the overall organisation. More than half of the organisation is currently active on our data tools, hence data engineers and data analysts work together to cater to these forever increasing needs. We are a lean team which works autonomously by delegating and trusting every member to take things to completion.

Responsibilities

Be an amazing learner on a day-to-day basis.
Communicate effectively with data consumers to fine-tune data platform systems (existing or new).
Contribute to existing EL (extract & load) data pipelines while building new systems in parallel.
Own and deliver high performing systems (not just pipelines) and help the team scale them up, to endure ever increasing traffic.
Become a product owner (not just a system owner) over-time by understanding the end results of building systems.
benefits

We offer a competitive salary and excellent benefits. What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world. Be a part of something big.",4.4,"Postdot Technologies
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
294,Machine Learning Engineer,"Our team is made of highly talented engineers with passion for innovation who turn wildly disruptive ideas into products that impact industry at large. We are building Cisco’s next-generation technological innovation by combining machine learning and distributed software with best-in-class networking technologies.

We are looking for agile, pragmatic and talented engineers with deep expertise and hands-on experience in machine learning, software engineering and data science. If technology and innovation is your passion, Cisco is the place for you.

Your role and responsibilities


You will have a multi-faceted role: starting from real use cases, you will cover the full product development cycle from first investigation to the development of novel and scalable prototypes based on machine learning algorithms until the release of the product, interfacing with a wide range of experts in the field. You thrive in a fast-paced, dynamic environment requires a unique blend of innovation and speed of execution.

The role is for highly technical machine learning engineers who combine outstanding oral and written communication skills, an ability to quickly code up prototypes using a large range of tools, algorithms and languages and, most importantly, an ability to autonomously plan and organize their work assignments based on high-level team goals.

We’re building large scale data processing and machine learning pipelines, both batch and streaming. Our technology stack includes Python, Java, Go as well as a wide range of internal tools built on top of Apache Spark, Beam, PostgreSQL and the Hadoop ecosystem.

Desired qualifications
Background in classical machine learning is a must, preferably with more than 2 years of industrial experience.
Hands-on experience of Linux and Shell scripting, ability to manipulate large-scale structured datasets.
Strong programming skills in Python, Java or Scala and demonstrable experience with cluster computing (Apache Spark, Apache Hadoop, etc.).
Knowledge of deep learning, reinforcement learning and natural language processing is a plus.
Excellent English spoken and written skills (C1 level) is a must.
Why Cisco


At Cisco, each person brings their own unique talents to work as a team and make a difference.

Yes, our technology changes the way the world works, lives, plays and learns, but our edge comes from our people.
We connect everything – people, process, data and things – and we use those connections to change our world for the better.
We innovate everywhere - From launching a new era of networking that adapts, learns and protects, to building Cisco Services that accelerate businesses and business results. Our technology powers entertainment, retail, healthcare, education and more – from Smart Cities to your everyday devices.
We benefit everyone - We do all of this while striving for a culture that empowers every person to be the difference, at work and in our communities.",4.3,"Cisco Systems
4.3",Bengaluru,"San Jose, CA",10000+ employees,1984,Company - Private,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Alcatel-Lucent, Juniper Networks"
295,Data Analyst/Scientist,"We are looking for a Data Analyst/Scientist to analyze large amounts of raw information to find patterns/outliers that will help improve our company. We will rely on you to build data products to extract valuable business insights. In this role, you should be highly analytical with a knack for analysis, math, and statistics. Critical thinking and problem-solving skills are essential for interpreting data. We also want to see a passion for machine-learning and research. Your goal will be to help our company analyze trends to make better decisions.

Responsibilities

Identify valuable data sources and automate collection processes
Undertake preprocessing of structured and unstructured data
Analyze large amounts of information to discover trends and patterns
Build predictive models and machine-learning algorithms
Combine models through ensemble modeling
Present information using data visualization techniques
Propose solutions and strategies to business challenges
Collaborate with engineering and product development teams

Requirements

5+ years of experience
Proven experience as a Data Scientist or Data Analyst
Experience in data mining
Understanding of machine-learning and operations research
Working knowledge of Machine Learning algorithms ( GLM, GBM, XGBoost)
Knowledge of deep learning models and frameworks
Knowledge of SQL and Python; familiarity with Scala, Java or C++ is an asset
Experience using business intelligence tools (e.g. Tableau, Data Studio) and data frameworks (e.g. Hadoop, Spark)
Familiarity with Python libraries (Pandas, Celery, MultiProcessing)
Familiarity with machine learning frameworks (like H2O, scikit-learn)
Analytical mind and business acumen
Strong math skills (e.g. statistics, algebra)
Problem-solving aptitude
Excellent communication and presentation skills
BSc/BA in Computer Science, Engineering or relevant field; graduate degree in Data Science or other quantitative field is preferred",-1,hudsondata.com,Gurgaon,-1,-1,-1,-1,-1,-1,-1,-1
296,Data Scientist DA4AD,"Responsibilities
Selecting features, building and optimizing classifiers using machine learning and Deep Learning techniques
Data mining using state-of-the-art methods
Extending company’s data with third party sources of information when needed
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance

Skills
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, CNNs, etc.
Very good experience with common data science toolkits of Python like numpy, pandas, pyTorch. Excellence in at least one of these is highly desirable
Great communication skills
Experience with data visualisation tools like matplotlib, Tableau
Proficiency in using query languages such as SQL
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Data-oriented personality

Responsibilities
Selecting features, building and optimizing classifiers using machine learning and Deep Learning techniques
Data mining using state-of-the-art methods
Extending company’s data with third party sources of information when needed
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance

Skills
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, CNNs, etc.
Very good experience with common data science toolkits of Python like numpy, pandas, pyTorch. Excellence in at least one of these is highly desirable
Great communication skills
Experience with data visualisation tools like matplotlib, Tableau
Proficiency in using query languages such as SQL
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Data-oriented personality",4.2,"Daimler
4.2",Bengaluru,"Stuttgart, Germany",10000+ employees,1886,Company - Public,Transportation Equipment Manufacturing,Manufacturing,₹500+ billion (INR),"Audi, Porsche, BMW"
297,Data Scientist (1-3 yrs),"Role & Expectations
Data scientists who are good with knowledge of statistics & programming in R/Python, transforming the business problem to analytics framework and weaving final results into actionable items for customers. Share your resume at [email protected]

Requirements and General Skills
Leading and managing analytics engagements
Coordinate daily interaction with the client and in-house analytics team
Propose and finalize modeling techniques relevant to a business problem
Drawing managerial insights through Statistical Techniques and Predictive Modelling
Managing client satisfaction, feedback process, managing/tracking workflow
Drawing actionable recommendations from data for senior management
Build sales and marketing collateral for prospects
Qualifications & Technical Skills
2 – 4 years of experience in Advanced Analytics within consulting environment
Hands-on with R & Python with application of varied machine learning algorithms i.e. Random Forests, Decision Trees, SVM, Neural Networks, Linear/Logistic Regression, Clustering, NLP
Demonstrated experience in translating business problems into analytics frameworks and translating analytics results back to final results for client consumption. Able to decide modeling techniques that can be applied to solve business problems effectively.
Consulting Skills: Ability to impact business decisions through analytics and research
We are an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",4.0,"Valiance Solutions
4.0",Noida,"Noida, India",1 to 50 employees,2014,Company - Private,IT Services,Information Technology,₹100 to ₹500 million (INR),-1
298,AI/NLP Scientist (P.hd / MS must),"Expert in developing code in Python
Strong programming skills with proven experience crafting, prototyping, and delivering advanced algorithmic solutions
A passion for making ML methods robust and scalable
Experience in extraction from structured/unstructured text (knowledge or statistics based)
Experience in one or more of the following areas: entity/relation extraction, normalization, text summarization, semantic search, word/paragraph/document embedding, ranking etc.
NLP algorithm implementation experience as well as the ability to modify standard algorithms (e.g. change objectives, work-out the math and implement)
Experience in deep learning approaches to NLP: word/paragraph embedding, representation learning, text/sentiment classification, ambiguity disambiguation
Experience with neural networks and deep learning frameworks (such as Keras, tensorflow, torch)
Familiarity with database queries and data analysis processes (SQL, Python, Java)
Background /Education
PhD/MS in Computer Science with focus on Natural Language Processing
Self starter who can be productive from the first day",5.0,"Sequoia Applied Technologies Inc.
5.0",Thiruvananthapuram,"Sunnyvale, CA",1 to 50 employees,2016,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,Altran Americas
299,Data Scientist - PhD,"Company Description

About Affine

Affine is a Data Sciences & AI services provider, offering capabilities across the analytical value chain from data engineering to analytical modelling and business intelligence to solve strategic & day to day business challenges of organizations worldwide. They empower their clients to make informed decisions & to take proactive actions through impeccable technology-based development & business acumen.

They develop solutions for multiple verticals such as Retail, CPG, E-commerce, High-Technology, BFSI, Media & Entertainment, Manufacturing among others and are respected as one of the Marquee names in the “Consultancies for Transformation” space.

Affine is headquartered in Bengaluru, India with other offices in New York & Seattle, United States and Singapore.

Job Description

Experience: 0 – 4 years
Education requirement: PhD in Machine Learning/Deep Learning/Artificial Intelligence/Image
processing/Statistics/Computer Science/ Mathematics

Responsibilities
Utilizing artificial intelligence and machine learning concepts to solve challenging business problems
Work on problems from various domains like NLP, Recommendation engine, computer vision
Should participate in complete project cycle i.e. understanding a problem statement, data gathering,
analyzing data, implementing ML/AI solutions
Should be able to learn new tools/languages quickly and continue expanding knowledge on latest
advances in ML/AI
Managing project timing, client expectations and meeting deadlines
Publishing research articles, papers and blogs
Desired skills and experience:
Strong experience in machine learning/artificial intelligence in academics or academics plus
industry
Expert level in at least one programming language. Preferably R or Python
Knowledge of statistics and machine learning (Probability theory, parametric and non-parametric
models, supervised and unsupervised ML techniques, etc.)
Knowledge of deep learning algorithms (CNN, RNN, autoencoders, etc.)
Knowledge in databases preferable
Qualifications

null

Additional Information

All your information will be kept confidential according to EEO guidelines.",3.7,"Affine Analytics
3.7",Bengaluru,"Bengaluru, India",201 to 500 employees,2011,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
300,Senior Data Scientist,"Strong background in statistics and machine learning, with direct experience in machine learning-related field (e.g., information retrieval, deep learning, natural language processing, computer vision, analytics, etc.).

Hands-on experience applying advanced statistical learning techniques to different types of data.

Strong programming skills in at least two languages: DotNet, Python, R, Scala

Experience with large data sets in a distributed computing environment such as Hadoop or Spark.

Ability to lead discussion with the business teams, understand the business problem, identify the key challenges, formalize problem algorithmically, and prototype solutions.

Analyze, advise and recommend various models with reasoning and predictable outcomes

Consistent track record of documenting, synthesizing, and communicating results.

Overall Experience of 7-10 years in which at least 3-5 years of experience with machine learning, Data Science, Information retrieval, deep learning, Natural Language Processing, Text Mining, Data Mining, Regression, Classification, etc.

May need to work frequently during US- MT hours for business discussions

Proactiveness and leadership skills are essential for this individual contributor role.

Relevant technical and delivery experience within, or working as a consultant/advisor to, hospitality industry will be an added advantage.

Education: Ph.D with Bachelors/ master’s in computers/Statistics/Mathematics.

Technologies: Azure ML studio/AI, SQL server

Contact Details

Email: careers@evoketechnologies.com
Phone: 040-33509000

To apply for this position, send your resume to careers@evoketechnologies.com mentioning the job code ‘SDS01’.",3.9,"Evoke Technologies
3.9",Hyderabad,"Dayton, OH",501 to 1000 employees,2003,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
301,Data Engineer,"Because you belong at Twilio.

The Who, What, Why and Where

Twilio is growing rapidly and seeking Data Engineers at multiple levels to be a key member of the Consumer Trust Team in Bangalore, India. You will be joining one of the first teams of engineers in our new Bangalore office, with an opportunity to help define our technical and team culture in India. You will also help us build solutions that prevent fraud and abuse, ensuring that Twilio is the leader in trusted communications. A successful candidate will be a self-starter, embody a growth mindset, collaborate effectively, can mentor junior engineers and operate highly resilient services.

Who?

Twilio is looking for a strong data engineer who lives the Twilio Magic and has a demonstrated track record of working with data, specifically; sourcing and integrating data from multiple disparate backend data sources, developing reporting infrastructures and applying a deep analytics background to assess business performance and deliver actionable insights to improve efficiency and increase productivity. You should also have::
BA/BS in Computer Science, Engineering or related field
Relevant work experience in a role requiring application of analytic skills to integrate data into operational planning/business planning
Knowledge and expertise with database modeling and data warehousing principles
Fluent in writing and optimizing SQL, data mining using SQL with demonstrated strength in writing complex, high-optimized queries across large data sets,
Familiar with AWS services, especially S3, Redshift, big data services and DevOps tools
Hands on experience with Lucene / SOLR / ElasticSearch, Kafka, Google Big Query
Proficiency in at least one scripting language, Python, R, or similar.
Advanced ability to draw insights from data and clearly communicate them (verbal/written) to the stakeholders and senior management as required
Demonstrated ability to manage and prioritize workload and roadmaps
Excellent problem solving, critical thinking, and communication skills.
Strong belief in automation over toil.
Nice to have:
Hands-on experience with Big Data technologies (e.g Hadoop, Hive, Spark) is a big plus
Extensive knowledge of BI and Visualization platforms i.e. Tableau and AWS Quicksight
Strong expertise in troubleshooting complex production issues.
What?

As a Data Engineer you will:
Design, develop, and maintain data pipelines, warehouses, and reporting systems to support Twilio's products, including fraud and abuse detection systems/ tools.
Design, develop, and maintain data pipelines, warehouses, and reporting systems to support Twilio's product engineering operational data: incidents, deployments, performance, utilization, defects, change failure rate, test data, infrastructure costs.
Build the data products that technical users will depend on for business intelligence and ad-hoc access.
Build scalable solutions and self-serve platforms that will provide data and KPIs to inform business decision making.
Identify, develop, manage, and execute analyses to uncover areas of opportunity and present written business recommendations that will help improve the controllership and help achieve the goals of the team.
Develop and maintain documentation relating to all assigned systems and projects
Develop high-trust relationships and processes with partner teams and stakeholders to identify and address insight requirements
Participate in workstreams planning process including inception, technical design, development, testing and delivery of BI solutions.
Be able to adapt to prioritizing multiple issues in a high-pressure environment.
Be able to understand complex architectures and be comfortable working with multiple teams.
Why?

Twilio has democratized communications channels like voice, text, chat, and video by virtualizing the world's telecommunications infrastructure through APIs that are simple enough for any developer to use, yet robust enough to power the world's most demanding applications.

The Consumer Trust Team is central to Twilio's continued growth. Our mission is to prevent consumer harm by offering products and services that protect our customers and help them authenticate their users. We also ensure that every call, email and message that is made using our service is wanted, safe and legal. To do this we need to continue to develop and evolve our products and services and ensure they are able to scale; driving Twilio to new heights of scale.

Twilio is a company that is empowering the world's developers with modern communication in order to build better applications. Twilio is truly unique; we are a company committed to your growth, your learning, your development, and your entire employee experience. We only win when our employees succeed and we're dedicated to helping you develop your strengths. We have a cultural foundation built on diversity, inclusion, and innovation and we want you and your ideas to thrive at Twilio.

Where?

This position will be located in our office in Bangalore, India. You will enjoy our office perks: catered meals, snacks, game room, ergonomic desks, massages, bi-weekly All Hands and more. What you will also get to experience is a company that believes in small teams for maximum impact; seeks well-rounded talent to ensure a full perspective on our customers' experience, understands that this is a marathon, not a sprint; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves.

About Us

Millions of developers around the world have used Twilio to unlock the magic of communications to improve any human experience. Twilio has democratized communications channels like voice, text, chat, video and email by virtualizing the world's communications infrastructure through APIs that are simple enough for any developer to use, yet robust enough to power the world's most demanding applications. By making communications a part of every software developer's toolkit, Twilio is enabling innovators across every industry — from emerging leaders to the world's largest organizations — to reinvent how companies engage with their customers.",3.9,"Twilio
3.9",Bengaluru,"San Francisco, CA",1001 to 5000 employees,2008,Company - Public,Internet,Information Technology,₹100 to ₹500 billion (INR),-1
302,Senior Data Analyst,"Responsibilities:
We are looking to add a Data Analyst who will partner with teams across the entire organization to ensure the highest quality of data across all workflows and to derive insights from this data to take our product to the next level. Do you have strong SQL skills and an excellent attention to detail? Are you passionate about adding product value through data discovery? If so, then this may be the role for you!

As a Data Analyst, you will directly support the growth and development of the products that our customers use every day. Daily we are aggregating billions of events from our data partners and from our customers for whom we are building world-class sales and marketing insights.

You'll work closely with the Data Science so that our modeling process has optimal data inputs, our Technical Success team to optimize customer on-boarding quality, with the Product team while building additional datasets that can be leveraged in new features and offerings, and collaborate with the Engineering team while building out and optimizing data pipelines.

You will work in a challenging, dynamic, fast paced environment with a mindset to contribute beyond basic responsibilities and constantly look for better ways to deliver top quality insights and solutions. Other responsibilities include:
• Working with different teams at 6sense to build reporting to gain deeper insights into our data

• Diving into and discovering new potential for existing data

• Providing recommendations and solutions on how to deal with problem data inputs

• Building out new methods/testing procedures for improving and ensuring data quality

Qualifications:
• 5+ years of data analysis experience

• You know SQL in and out, window functions and all

• Have worked with BI tools like Tableau, Domo, Qlikview, etc.

• You love to tell data driven stories

• Able to prioritize and execute tasks in a high-pressure, constantly changing environment

Good to have:
• Experience working Presto

• Experience with the Hadoop ecosystem including Hive

• Development experiences with various databases and DBMSs

• Proficient with data processing flowcharting techniques",4.9,"6sense
4.9",Pune,"San Francisco, CA",51 to 200 employees,2013,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
303,Data Scientist - R/Python,"Location: Chandigarh
Experience Level: 1 year
Vacancies: 2

We are looking for a Data Scientist who will support our product, sales, and leadership and marketing teams with insights gained from analyzing company data. The ideal candidate is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations.

Responsibilities for Data Scientist

Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
Develop testing framework and test model quality.
Coordinate with different functional teams to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.

Qualifications for Data Scientist

Strong problem solving skills with an emphasis on product development.
Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.
Experience working with and creating data architectures.
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
A drive to learn and master new technologies and techniques.
We’re looking for someone with 2-5 years of experience manipulating data sets and building statistical models or another quantitative field, and is familiar with the following software/tools:
Coding knowledge and experience with several languages: C, C++, Java,
JavaScript, etc.
Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.
Experience querying databases and using statistical computer languages: R, Python, SLQ, etc.
Experience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Core metrics, Ad words, Crimson Hexagon, Facebook Insights, etc.
Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.

Job Type: Full-time",4.4,"Prepladder
4.4",Chandigarh,"Chandigarh, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
304,Junior Data Scientist,"Junior Data Scientist
Job Description


The ITS Data Scientist is responsible for integrating business, information, and technology into analytical models that help drive business performance and competitive advantage and providing the business with answers to questions. The role collaborates with Business, IT Functional Engineers and Platform architects to create value from varied data sources. Creating value from data requires a range of talents: from data integration and preparation, to architecting specialized computing/database environments, to data mining and intelligent algorithm development.

Hiring Requirements

Job Details

Development of analytics to help drive competitive advantage from data with accountabilities across multiple functional and technical areas with wide range of complexity. The Data Scientist must understand medium/complex data types (integrate, manipulate, prepare), know advanced analytics (appropriate techniques, interpret data and diagnose models, meet business requirements), and focus on the business outcomes (goals, constraints, decisions while communicating outcomes via presentations). Develop models and algorithms that drive innovation throughout the organization. This may include marketing, supply chain, inventory planning and deployment, network planning, order routing, and order fulfillment and delivery Conduct advanced statistical analysis to provide actionable insights, identify trends, and measure performance Build learning systems that monitor data flows and react to changes in customer preferences, network constraints, and business objectives Collaborate with engineers to implement and deploy scalable solutions Provide thought leadership by researching best practices, conducting experiments, and collaborating with industry leaders Partners as a bridge between the business and the information management teams to make sure that the solution fits within the data management principals Coordinates data science implementations while leading design variances based upon business needs while ensuring artifacts and repositories are documented Manages engagements with vendors as they relate to evaluation, design and delivery of business capabilities Contributes to the evaluation and selection of software product standards Leader in industry representation, policy formation, User Groups, and strategic direction

Mentors others to complete Continuous Improvement (CI) initiatives; consults and shares knowledge across org; awareness of industry trends.

Education required/ preferred:
MS/PhD in computer science, statistics, or operations research or related technical discipline.
Experience:
2-3+ years of continuous experience in software engineering, software development, solution architecture
Knowledge of machine learning, statistics, optimization or related field
Experience with R, Python, Matlab is required
Experience building machine learning application in areas like time series forecasting, classification models, clustering models, multivariate regression models etc
Experience in Microsoft Azure Stack in the Cloud with focus on Data Factory, Data Bricks, BLOBs, Data Lake Storage, ML Studio, Azure Analysis Services, Azure Data Warehouse, Power BI etc
Experience working with large data sets and distributed computing tools a plus (Map/Reduce, Hadoop, Hive, Spark, Python, R, Gurobi, MySQL, etc.)
Excellent written and verbal communication skills along with strong desire to work in cross functional teams
Consumer products experience in an online and/or retail/manufacturing environment is preferred
Possess strong leadership skills and exhibit creative thinking to be able to come up with inventive solutions to solve business challenges
Provide thought leadership while keeping up with industry trends and disseminating information across the organization
Experience working with blended teams consisting of employees, vendors, and consultants with both onshore and offshore resources
Strong Technical leadership of advanced analytics teams and vendors
Extensive experience collaborating with Enterprise Architects and infrastructure engineers to identify, design, and implement highly complex, end-to-end solutions
Cultivates networking opportunities within the organization
Broad range of business and IT experiences; Has achieved technical and/or business certification(s).
Skills/Competencies:

Communication: Data scientists must communicate effectively up and down the data supply chain: first, to obtain access to the data they require; second, to work with those who understand the business meaning behind the data; and third, to articulate findings and implications to business leaders in language they understand. A data scientist must be able to use data to tell stories. Key components of these communication skills are those of persuasion and expectation management. The ability to insert themselves into core business functions and assert their ideas is therefore critical.

Collaboration: Working directly for business leaders and side-by-side with business unit personnel, they need to shed the introverted statistician stereotype. Increasingly, business professionals require access to analytic techniques beyond basic math and must be able to rely on the data scientist to work closely with them. The data scientist enables the broad consumerization of derivative result sets and analytics (if not the raw data). The data scientist must have the ability to juggle competing priorities and pressures.

Leadership. The role of the data scientist can incorporate data oversight responsibilities including directing the efforts of teams of consultant statisticians, data administration and integration professionals, and data visualization, reporting, and application integration developers.

Creativity. The work of the data scientist is very much an innovation-oriented exercise in solving open-ended conundrums. Data scientists are tasked with finding opportunities to optimize, expand or transform the business through the lens of information. Moreover, data scientists must be creative in sourcing data, modeling problems and employing a range of analytic techniques.

Discipline. Although creativity is critical, data scientists must remember that ""science"" is part of their directive. This means following established scientific methods, employing legitimate techniques, using valid data and embracing causality. Scientific methods demand that questions are well-defined, true data (observations) is collected, and hypotheses are formed, investigative methods are selected, data is analyzed and interpreted with yielding conclusions, and results are formally communicated and tested. Although rigid methodology is recommended, results perfection is not. Business opportunity costs in a fast-paced marketplace are too high to spend excessive time achieving incrementally better analyses. However, a data scientist — just as any good statistician or other analytics professional — must understand the differences between correlation and causality and between incidental and insightful patterns.

Passion: An obsession for information, solving insurmountable problems and finding unique ways to accelerate the business.

Consultancy: Manages provision of specialist knowledge over a range of topics in data science including the role of IT in the business; in own areas of expertise provides advice and guidance influencing the effectiveness of the organization’s business processes.

Data Design: Controls analytics data design practice within the enterprise. Influences industry-based models for the development of new technology applications. Develops effective implementation and procurement strategies, consistent with business needs.

Data Analysis: Sets standards for advanced analytics tool usage and techniques, advises on their application, and ensures compliance. Manages the investigation of corporate data requirements, and co-ordinates the application of data analysis and analytics techniques, based upon a detailed understanding of the corporate information requirements, in order to establish, modify or maintain analytical models and their associated components.

Autonomy: Has authority and responsibility for all aspects of data science, including policy formation and application. Is fully accountable for actions taken and decisions made, both by self and subordinates.

Influence: Makes decisions critical to organizational success. Influences developments within the IT industry at the highest levels. Advances the knowledge and/or exploitation of IT within one or more organizations. Develops long-term strategic relationships with customers, partners, industry leaders and government.

Complexity: Performs highly complex work activities covering technical, financial and quality aspects. Contributes to the formulation and implementation of IT strategy. Creatively applies a wide range of technical and/or management principles.

Business Skills Absorbs complex technical information and communicates effectively at all levels to both technical and non-technical audiences. Assesses and evaluates risk. Understands the implications of new technologies. Demonstrates clear leadership and the ability to influence and persuade. Has a broad understanding of all aspects of IT and deep understanding of own specialism(s). Understands and communicates the role and impact of IT in the employing organization and promotes compliance with relevant legislation. Takes the initiative to keep both own and subordinates' skills up to date and to maintain an awareness of developments in the IT industry.

Global VISA and Relocation Specifications:
K-C requires that an employee have authorization to work in the country in which the role is based. In the event an applicant does not have current work authorization, K-C will determine, in its sole discretion, whether to sponsor an individual for work authorization. However, based on immigration requirements, not all roles are suitable for sponsorship.
This role is available for local candidates already authorized to work in the role’s country only. K-C will not provide relocation support for this role.
Primary Location
IT Centre Bengaluru GDTC
Additional Locations
Worker Type
Employee
Worker Sub-Type
Regular
Time Type
Full time",3.9,"Kimberly-Clark
3.9",Bengaluru,"Irving, TX",10000+ employees,1872,Company - Public,Consumer Products Manufacturing,Manufacturing,₹500+ billion (INR),"Procter & Gamble, Georgia-Pacific, Unilever"
305,Data Scientist / Data Analyst,"This position will be responsible for Finance Analytics product offerings thereby generate Business Performance Improvement opportunities for the Stake Holders. Our Client is looking for an experienced Senior Data Scientist to join our talented engineering team. As our data guru, you’ll be responsible for analyzing the large data set and making recommendations that will impact major business decisions. They are looking for a proven technical leader that can excel in a fun, fast-moving startup environment and help them elevate their customer experience.

Job Responsibilities

Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.
Mine and analyze data from company databases to drive optimization and improvement of sales projections, processes, marketing techniques and business strategies.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modelling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
Develop A/B testing framework and test model quality.
Coordinate with different functional teams to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Develop algorithms and predictive models, create prototype systems and visualizations
Implement and keep models in optimal production state
Strong data & visual presentation skills and ability to explain insights using tools like tableau, D3 charts or other tools.
Experience working with big data tools such as MapReduce, Pig, Spark and NoSQL data will be an add-on
Must have end-end hands-on experience in delivering & implementing data analytics models in production. Must have skills, such as Synthesizing data, defining the problem, feature engineering, building the model, deploying the same in production.
Ability to work closely with others to execute projects rapidly in a multi-disciplinary environment
Demonstrated data science experience in the Sales & Marketing domain with at least 3 to 4 projects delivered end-to-end, Ability to collaborate business and data science.
Strong project management skills, a passion to drive task based processes to successful completion – organized, strong communicator, high-energy and takes initiative
Consultative and collaboration skills; able to influence complex stakeholder communities
Education : Bachelor’s degree in computer science, statistics, engineering and relevant fields,

Experience : with 6+ years of hands-on experience in the following:

Statistical analysis tools such as R, Python, SAS, etc.
Machine learning techniques for classification, regression, clustering, decision trees, text analytics, deep learning & time-series data etc.
Scripting languages such as Python, Perl, Ruby, etc.

Strong communicator written and oral; able to work effectively with remote, global project teams

What You Need for this Position

You should have knowledge of:
Data Science
Data Analyst
SQL
R
Python
SAS
Python
Perl
Ruby
MapReduce
Pig
Spark and NoSQL
Aditional
No. of Positions
3
Education level
Bachelor’s Degree in Computer Science
Career level
Experienced",4.8,"Bloom Consulting Services
4.8",Bengaluru,"Nagpur, India",1 to 50 employees,2015,Company - Private,IT Services,Information Technology,₹10 to ₹50 million (INR),-1
306,Machine Learning Engineer (f/m/d),"IMPACT DESCRIPTION
Are you a technology enthusiast and enjoy being challenged towards development of superior software using innovation? Have you been part of high performing teams delivering world-class products? Join us in our drive to make robust products with assured quality available to our customers.

You will be responsible for setting up the right code architecture, leveraging emerging tools and trends while keeping the vision of our product intact. You will be part of our core R&D team working in Pune, India.
YOUR PROFILE
WHAT YOU ALREADY KNOW

Strong fundamental understanding of machine learning algorithms, with good hold on under-the-hood mathematical and statistical concepts
Research oriented mindset : Should be able to review existing research publications for applicability in the current problem and also publish research papers at forums / events
Programming experience with Python
Experience with machine learning frameworks such as Tensorflow, Keras and commonly used python libraries
Able to build data pipelines to train and build your models
Able to deploy models in Docker containers
Able to do Linux shell scripting
Able to use at least one of the following database and data processing technologies such as MongoDB, Apache Hadoop and/or Apache Spark
Ability to provide a compelling story / narrative on work through dashboards and presentations

Experience:
2-3 Years
WHAT WE OFFER YOU
Beautiful Office Spaces
Our team has added a personal touch to our office spaces, which is a reflection of our work culture: unique, fresh and innovative.
A Young, global Team
We are employee driven. We have a diverse team, a flat structure and encourage a healthy balance between work and play.
Passion for Technology
We are enthusiastic about our work and go the extra mile. Jump headfirst into the deep end, ready to do what no one else has done.
We make a change
We clean up your code and get it to speed with the times, assuring good quality and robustness at all times.
We're empowering
We make your code visual and beautiful, making it easy to understand by anyone to make well informed decisions.
We love challenges
We revel in expectations and widening our horizons. We are always eager to learn, grow and trudge into new territories.
We have fun
We take pride in making work a place we look forward to coming to each day. We love our work and this shows in the work we do.
We are efficient
We do great work and utilize resources effectively, making our services accessible and affordable to our clients.
CONTACT US
Embold Software Pvt.Ltd
HR India
Office No. 302-303,
Third Floor, Pride House,
Pune University Road, Chattushringi,
Pune- 411016
India

E-Mail: hrindia@embold.io
ABOUT US
Our Vision is to change the Paradigm of Software Development by helping our users to create great software products.
We develop the infrastructure and tools that fuel the transformation of software development with the power of artificial intelligence and support our customers in dealing with complex challenges in their software development processes with our software analytics platform.",4.0,"Embold Technologies GmbH
4.0",Pune,"Frankfurt am Main, Germany",51 to 200 employees,2008,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
307,Machine Learning/Data Scientist,"Key Responsibilities:
Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities.
Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas.
Inspire and influence others for continous improvement in every aspect
Be hands on in development and execution of predictive analytics and machine learning.

Job Requirements :
Minimum two years of experience with Machine Learning technologies
Expert in building custom ML algorithms leveraging statistical concepts and ML tools
Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models.
Understanding & working knowledge in Natural Language Processing & Conceptual modelling.
Proficiency in statistical analysis tools (R, Python and SAS).
Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification).
Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra)
Awareness/Experience with big data tools (Hadoop, HDFS & Spark).
Experience on AWS/Google machine learning services is a plus.
Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)",3.7,"Forgeahead
3.7",Pune,"Pune, India",51 to 200 employees,1999,Company - Private,IT Services,Information Technology,₹100 to ₹500 million (INR),-1
308,Sr. Data Scientist,"Full Time
Nagpur, Hyderabad

The person should have overall 7-8 years of experience out of which 4-5 years of experience should be in Machine & Deep Machine learning. Especially using Convolution Neural Network (CNN), Image Analytics TensorFlow, Open CV etc.

With our fast-growing data scientist’s team, we are looking to hire self-motivated smart individuals who are willing to take challenges in the field of AI predictive image analytics & machine learning.

Responsibilities :
The Machine & Deep Machine Learning Software Engineer (Expertise in Computer Vision) will be an early member of a growing team with responsibilities for designing and developing highly scalable machine learning solutions that impact many areas of our business.
The individual in this role will help in the design and development of Neural Network (especially Convolution Neural Networks) & ML solutions based on our reference architecture which is underpinned by big data & cloud technology, micro-service architecture and high performing compute infrastructure.
Typical daily activities include contributing to all phases of algorithm development including ideation, prototyping, design, and development production implementation.

Required Skills :
An ideal candidate will have background in software engineering and data science with expertise in machine learning algorithms, statistical analysis tools, and distributed systems.
Experience in building machine learning applications, and broad knowledge of machine learning APIs, tools, and open source libraries
Strong coding skills and fundamentals in data structures, predictive modelling and big data concepts
Experience in designing full stack ML solutions in a distributed compute environment
Experience working with Python, Tensor Flow, Kera’s, Sci-kit, pandas, NumPy, AZURE, AWS GPU
Excellent communication skills with multiple levels of the organization",-1,Claim Genius,Nagpur,"Iselin, NJ",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
309,Sr. Data Scientist,"Sr. Data Scientist
Slack is looking for experienced data scientists to join our Product Analytics team and help drive the understanding, growth, and success of Slack. You'll have deep technical skills and a real passion for helping Slack make data-informed decisions. You'll be fearless, independent, and excited about having a big impact in a growing team.

You will partner closely with our Product and Engineering team to craft narratives, find insights, and provide recommendations. Data scientists are embedded in our Product teams to drive data-informed product development, and to work closely with other cross-functional teams such as Data Engineering & Business Intelligence.

Slack has a positive, diverse, and supportive culture—we look for people who are curious, inventive, and work to be a little better every single day. In our work together we aim to be smart, humble, hardworking and, above all, collaborative. If this sounds like a good fit for you, why not say hello?

What You Will Be Doing

● Use data to influence the direction of team roadmaps and inform business decisions

● Deepen our understanding of our product, our users, and our business through data

● Work with partner teams to define goals and identify metrics that describe our product through data

● Inspire self-serve data use by building dashboards and reports to drive awareness and understanding of metrics

● Partner with Data Engineering and IT to author and develop core data sets that empower operational and exploratory analyses

● Work cross-functionally to develop common practices and team playbooks for data science at Slack

What You Should Have

● 6+ years of professional industry experience doing quantitative analysis

● A proven track record of using analysis to impact key business or product decisions

● The ability to clearly and effectively communicate the results of complex analyses

● Experience writing production datasets in SQL/Hive OR building internal/production data tools for ETL, experimentation, or exploration in a scripting language (Python, R, etc.)

● A deep understanding of basic statistical applications and methods (experimentation, probabilities, regression)

● Experience in software engineering, data engineering, consulting, or academic research a plus

Slack is a layer of the business technology stack that brings together people, data, and applications – a single place where people can effectively work together, find important information, and access hundreds of thousands of critical applications and services to do their best work. From global Fortune 100 companies to corner markets, businesses and teams of all kinds use Slack to bring the right people together with all the right information. Slack is headquartered in San Francisco, CA and has offices around the world. For more information on how Slack makes teams better connected, visit slack.com.

Ensuring a diverse and inclusive workplace where we learn from each other is core to Slack’s values. We welcome people of different backgrounds, experiences, abilities and perspectives. We are an equal opportunity employer and a pleasant and supportive place to work.

Come do the best work of your life here at Slack.",4.5,"Slack
4.5",Pune,"San Francisco, CA",1001 to 5000 employees,2014,Company - Public,Internet,Information Technology,Unknown / Non-Applicable,"Microsoft, Atlassian, Facebook"
310,Senior Data Scientist,"Our startup is working to revolutionize ways people can access and view real estate data in the US. As a result, we are looking for an independent and talented data scientist that can work remotely to build new data models and test new technologies.

Your knowledge and experience in Data Science methodologies will be applied to solve challenging real-world problems as part of a highly dynamic and global team. You will work in a highly collaborative environment where you communicate and plan tasks and ideas.

If you ever wanted to create new models from scratch and test out new technologies, this is your dream job! Develop new models that will predict property values and purchasing demand, work with new models (like Turing-NGL) to build new and exciting solutions.

Responsibilities:
Lead multiple AI/ML projects for a specific product/business
Manage communication, planning, collaboration, and feedback loops with business stakeholders.
Identify the model monitoring strategy.
Define the Data sourcing strategy and works with stakeholders to procure data.
Required knowledge/qualifications:
Bachelor/Masters/Ph.D. in Computer Science, Data Science, Artificial Intelligence, Machine Learning, Electrical Engineering, or related disciplines from any of the reputed institutes. First Class, preferably with Distinction.
Applied experience: 8+ years of ML and/or AI production level experience; and overall industry experience of about 15+ years.
Proven skills in implementing a variety of Machine Learning techniques
Strong Programming skills (R/Python) with proficiency in at least one
A firm grounding in mathematics, probability, statistics needed for data analysis and experiments
Proven ability to lead AI/ML projects end-to-end with complete ownership
Experience in building models using semi-structured and unstructured data
Able to develop and deploy AI models into production with a focus on scaling, monitoring, and performance
Knowledge of designing data pipelines and flow strategies
Excellent communication skills in written and spoken English
Great team worker and collaborator
Creativity and ability to formulate problems and solve them independently
Self-driven and ability to work through abstraction
Ability to build and nurture internal and external communities
Work location:
Remote
Job Type: Full-time

Salary: ₹1,400,000.00 to ₹1,800,000.00 /year

Experience:
ML/AI work: 8 years (Required)
Education:
Bachelor's (Required)
Language:
English (Required)
Work Remotely:
Yes",2.5,"Rentpay
2.5",Bengaluru,"Walnut Creek, CA",201 to 500 employees,1999,Company - Private,Financial Transaction Processing,Finance,₹10 to ₹50 billion (INR),"Stripe, Braintree, Adyen"
311,"QA Lead for Machine Learning( Engineer,Sr Staff/Mgr)","Job Id
E1981981
Job Title QA Lead for Machine Learning( Engineer,Sr Staff/Mgr)

Post Date 05/04/2020

Company
Qualcomm Technologies, Inc.

Job Area Engineering - Software

Location India - Hyderabad

Job Overview Join a new and growing team at Qualcomm focused on advancing state-of-the-art in Machine Learning. The team uses Qualcomm chips extensive heterogeneous computing capabilities and engineers them to allow the running of trained neural networks on device without a need for connection to the cloud. Our inference engine is designed to help developers run neural network models trained in a variety of frameworks on Snapdragon platforms at blazing speeds while still sipping the smallest amount of power. See your work directly impact billions of mobile devices around the world.
In this position, you will lead 20+ member strong technical team and responsible for the QA (test development and execution) and CI/CD infrastructure of Qualcomm ML Software. You will work with neural network frameworks like Caffe, Caffe2 and TensorFlow and develop the validation framework to gauge functionality, performance, precision and power of SNPE (Snapdragon Neural Processing Engine). You will work with the latest and greatest DNNs emerging from the research community. You will also have to keep up with the fast pace development happening in the industry and academia to continuously enhance our benchmarking and validation infrastructure from software engineering as well as machine learning standpoint. In addition, youd be responsible to ensure to setup the CI/CD infrastructure that integrates/validates/releases all the changes for a smooth nightly quality assurance. The team strives to minimize manual interventions and looks to use state of the art in the field of DevOps to achieve the most resilient and reliable infrastructure for this. Youll be required to not only maintain/enhance the existing infrastructure but also bring in your ideas to remove any inefficiencies in the process. You are responsible for SNPE, ANN (Android Neural Network) and other product releases from Qualcomm across multiple chipsets.

Minimum Qualifications Experience with at least one machine learning framework like TensorFlow, Caffe, Pytorch, etc.
Well versed in version control tools, CI tools like git, repo, Jenkins
Expert in DevOps fundamentals, lives by Infrastructure-as-code principles
Strong understanding of Deep Learning fundamentals
Strong development skills in Python
Excellent communication skills (verbal, presentation, written)
Ability to collaborate across a globally diverse team and with stakeholders/ leads across geographies
12 to 14 years of relevant work experience in software test development and DevOps
3 to 4 years of experience in leading the teams technically and handling line management responsibilities

"" id=""hdnMinimumQualifications"">Live and breathe quality software development with excellent analytical, and debugging skills
Experience with at least one machine learning framework like TensorFlow, Caffe, Pytorch, etc.
Well versed in version control tools, CI tools like git, repo, Jenkins
Expert in DevOps fundamentals, lives by Infrastructure-as-code principles
Strong understanding of Deep Learning fundamentals
Strong development skills in Python
Excellent communication skills (verbal, presentation, written)
Ability to collaborate across a globally diverse team and with stakeholders/ leads across geographies
12 to 14 years of relevant work experience in software test development and DevOps
3 to 4 years of experience in leading the teams technically and handling line management responsibilities

Preferred Qualifications Experience with ML Application development
Experience with Docker and orchestration frameworks like ansible, chef etc..
Experience in Android(AOSP) or embedded Linux application development
Development experience in C++

Education Requirements Bachelors/Masters",3.9,"Qualcomm
3.9",Hyderabad,"San Diego, CA",10000+ employees,1985,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Intel Corporation, MediaTek, Broadcom"
312,Lead- Data Scientist,"Designation: Lead Data Scientist -

Work Experience: 3+ Years

Place of Posting: Sector 63, Noida

Salary: To Match the Best in Industry

Work Schedule: Flexible with 5 days a Week

What are we looking for:

We are looking for Lead Data Engineers with competencies to understand client requirements, develop and deliver analytical solutions as per the defined scope.

The role requires passion for building large scale data processing systems to help manage the ever-growing information needs of our clients with sound business understanding, knowledge of statistical modeling, and problem-solving skills. Individual may have to lead team as per the project requirement.

Key Role & Responsibilities:
Create complex data processing pipelines, as part of diverse, high energy teams.
Design scalable implementation of models developed by our Data Scientists.
Hands-on programming in Python/ Scala usually in a pair programming environment.
Deploy data pipelines in production based on Continuous Delivery practices.
Advise clients on the usage of different distributed storage and computing technologies from the abundance of options available in ecosystem.
Desired Education, Experience & Competencies:
BE/ B.Tech/ MCA, 3+ year experience in building and deploying large scale data processing pipelines in a production environment and hands-on programming in Python, Scala preferably in a pair programming.
Experience building data pipelines and data centric applications using distributed storage platforms like HDFS, S3, NoSql databases such as Hbase, Cassandra, etc and distributed processing platforms like Hadoop, Spark, Hive, Oozie, Airflow, etc in a production setting.
Hands on experience in MapR, Cloudera, Hortonworks and/or Cloud such as AWS EMR, Azure HDInsights, Qubole etc. based Hadoop distributions.
Experience working with, or an interest in Agile Methodologies, such as Extreme Programming (XP) and Scrum.
Strong communication and client-facing skills with ability to work in a consulting environment.
Senior developers with 6+ year experience is expected to be the Architect for small and large enterprise projects.
For larger projects, the selected candidate will be expected to work closely with the fellow architects to come up with the architecture and take it forward.
Desire to contribute to the wider technical community through collaboration, coaching, and mentoring of other technologists.
Why Join Taazaa?
Our team exploits the agile development methodology and latest technologies like .Net Core, Angular, AngularJS, NodeJS, MVC etc. to provide clear fit to our client software product requirements.
Track Record of On-Time Salary (i.e. 1st of every month)
Cafeteria with unlimited snacks and drinks
Organising Events on every occasion (whether it’s Month-End or any festival)
Fun Gaming Zone
Competitive Salary with Medical Benefits
Flexible working hours
Young and Energetic Team
Key Skills:

Create & Deploy Data Processing Pipelines, Scalable Implementation, Python/ Scala Programming, Distributed Storage, HDFS, S3, NoSql, Hbase, Hadoop, Spark, Hive, MapR, Cloudera, Hortonworks, Cloud, AWS EMR, Azure HDInsights, Qubole, Architecture,

About Company Profile:

Taazaa Tech HQ in USA is a progressive fast-growing company with presence in various domains including blockchain, exchange platform, healthcare, transport, travel and education etc. We explore latest technologies, trends and practices to provide clear fit to our client needs.

Taazaa Tech is a technology consulting company focusing on software product development and cloud computing infrastructure. We work primarily on challenging web and mobile applications to design and develop apps for most major mobile platforms including Web, iPhone, iPad, Android and Windows 8. Be it mobile strategy, application design or end-to-end mobile solution, we carry the competencies to provide value added and competitive advantage to our clients by tailoring software.

We carry expertise ranging from CMS to CRM, with industry specific software application development to transform ideas and concepts into amazing software solutions.

The company provides customized web application development, including website design and development, software consulting, and application integration.",4.5,"Taazaa
4.5",Noida,"Kent, OH",51 to 200 employees,2007,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
313,Senior Data Scientist,"Company Overview

Fanatics is the global leader in licensed sports merchandise and changing the way fans purchase their favorite team apparel and jerseys. Through an innovative, tech-infused approach to making and selling fan gear in today's on-demand culture, Fanatics operates more than 300 online and offline stores, including the e-commerce business for all major professional sports leagues (NFL, MLB, NBA, NHL, NASCAR, MLS, PGA), major media brands (NBC Sports, CBS Sports, FOX Sports) and more than 200 collegiate and professional team properties, which include several of the biggest global soccer clubs (Manchester United, Real Madrid, Chelsea, Manchester City). Fanatics offers the largest collection of timeless and timely merchandise whether shopping online, on your phone, in stores, in stadiums or on-site at the world's biggest sporting events.

About the Team

Fanatics is first and foremost a technology company. We are powered by cutting-edge tech created by our small agile teams using the latest tools and technologies under our highly analytical, forward thinking, and open-minded leadership. As the global leader in licensed sports merchandise, we challenge ourselves by improving our new fully responsive NodeJS cloud commerce platform, Elasticsearch engine, and deep data science capabilities while building the best-in-class retail manufacturing and supply chain technologies. Our tech teams work together to revolutionize data science and engineering initiatives, provide highly scalable real-time and streaming platforms, and create secure e-commerce and in-stadium fan experience products. Our own e-commerce platform transacts in over 190 countries, 17 languages, and 14 currencies. Our motto is “#GSD”—get stuff done—and we do just that. If you want to be at the nexus of sports, commerce, and technology, come be a part of our industry-leading team here at Fanatics Tech.

About the Team and Role:
Fanatics data science group is a young supply chain research and development team. Our focus is on growing the Fanatics business by providing supply chain knowledge and data-driven solutions using state-of-art AI/ML and deep learning algorithms. The primary engagement is building production scale data-science modules. Our team is looking for strong and enthusiastic data scientist with domain knowledge of supply chain process to join us. The responsibility of the Data Scientist may also be including implementation and deployment of production scale time series models. The individual should be capable of carrying research and development work using active research areas in time series forecasting (Bayesian Forecasting, Deep learning Methods). The person will be responsible for building technical and business reports on daily/weekly basis. Team is backed by strong business leaders in supply chain research & development, thus a foundational mentorship will be provided. Based on past experience the individual may also be engaging in business meetings and coordinate cross-functional technical discussions.
What You’ll Do:
• Create data-science and machine learning products in supply-chain and inventory space,
• Build & deploy production scale models on large-scale datasets using machine learning (or) deep learning technologies for Supply Chain research,
• Work with cross-functional teams to implement and deploy data science products,
• Leverage large scale data processing such as Spark, Hive into the data-science products,
• Provide analysis using mathematical modeling tools to improve business processes and decisions,
• Define creative solutions to business problems using advanced mathematical algorithms,
• Communicate with senior management and cross-functional teams, and
• Facilitate deep technical discussions with end-users and partners.
What You’ll Need:
1. Masters (or) PhD in Computer Science, Statistics, Operations Research, Economics, or other quantitative discipline strongly preferred,
2. Experience in research and development. Conference papers at reputed AI/ML platforms (ICML, NIPS, AAAI) will be a big plus,
3. Experience in Time series modeling (classical methods like ARIMA, STL Forecast). Understanding and implementing active research in Time series forecasting (Bayesian Forecasting, Hierarchical Forecasting),
4. Hands on experience in implementing Deep learning models with textual data/ time series data (CNN, LSTM’s) will be a great plus,
5. Expertise in SCALA (or) functional programming paradigm/ Python / R,
6. Experience in big data technologies like Spark, Hive, Hadoop,
7. Experience in understanding business needs and translating to a data-science problem,
8. Knowledge of the supply chain process – demand forecasting, inventory optimization, sell-through, reorder quantity, recommended buy, and allocation process,
9. Great communication skills, organized, able to multitask and be a team player, and
10. Excellent written and oral communication skills on both technical and non-technical topics.
Tryouts are open at Fanatics! Our team is passionate, talented, unified, and charged with creating the fan experience of tomorrow. The ball is in your court now.",3.3,"Fanatics
3.3",Hyderabad,"Jacksonville, FL",5001 to 10000 employees,1996,Company - Private,Sporting Goods Shops,Retail,₹100 to ₹500 billion (INR),"Lids, Amazon, Under Armour"
314,Research Data Scientist,"KEY RESPONSIBILITIES

Contribute to the strategic development of AQ analytics and create blueprints.
Design and deliver innovative, state-of-the-art machine learning products and platforms in-line with AQ’s go-to-market strategy.
Research new or adapt existing machine learning approaches to provide decision support to some of the leading marketers in the world.
Be involved across all the different stages: from data discovery/generation and feature engineering to model building and prototype design.
Partner with various stakeholders (within AQ as well as the larger Kantar organization) to innovatively answer key business questions.
Empower the growing AQ community to generate value from existing data assets.
Frame optimal analytical solutions to business problems by leveraging the latest developments in Machine Learning.
Be a thought-leader, keeping up with the academic and industry trends.

ESSENTIAL SKILLS & QUALITIES

Excellent theoretical understanding of machine learning concepts and practice.
Experience in various statistical and machine learning models.
Strong expertise in one of the following - Bayesian Modelling, Classification Models, Cluster Analysis, Neural Networks, Non-parametric Methods, Timeseries Models, Stochastic/ Markov Models, NLP etc.
Proficiency in statistical and other tools/languages – preferably R/ Python.
Knowledge of numerical optimisation methods.
Knowledge of NLP and related solutions.

QUALIFICATIONS

Graduate degree in Applied Statistics, Mathematics, or Computer Science from a premier institute.
4 years of experience building cutting edge analytic solutions from scratch.

SALARY & OTHER DETAILS

Salary including benefits will be based on prior experience & qualifications and will match industry standards.
To apply, please write to careers@aqinsights.com, stating the job ID you are applying for along with your resume.",3.7,"Analytics Quotient
3.7",Bengaluru,"Bengaluru, India",201 to 500 employees,2008,Company - Private,Consulting,Business Services,₹1 to ₹5 billion (INR),-1
315,Data Analyst,"The thrill of working at a start-up that is starting to scale massively is something else.

Simpl (getsimpl.com) was formed in 2015 by Nitya Sharma, an investment banker from Wall Street and Chaitra Chidanand, a tech executive from the Valley, when they teamed up with a very clear mission - to make money simple, so that people can live well and do amazing things. Simpl is the payment platform for the mobile-first world, and we’re backed by some of the best names in fintech globally (folks who have invested in Visa, Square and Transferwise), and has Joe Saunders, Ex Chairman and CEO of Visa as a board member.

Everyone at Simpl is an internal entrepreneur who is given a lot of bandwidth and resources to create the next breakthrough towards the long term vision of “making money Simpl”. Our first product is a payment platform that lets people buy instantly, anywhere online, and pay later. In the background, Simpl uses big data for credit underwriting, risk and fraud modelling, all without any paperwork, and enables Banks and Non-Bank Financial Companies to access a whole new consumer market.

We are looking to hire a data analyst (Can be considered for a lead role depending on fit) who can work closely with product, investment, operations and marketing team on analytics.

The candidate would be a business aware self-starter responsible for enabling data driven decisions by setting up a reporting framework for daily/weekly metrics, helping with ad-hoc analysis and any fundamental research exercise.

This Role Requires Applicant To
Have passion for sourcing, manipulating and visualizing data
Apply direction and confidence to design qualitative and quantitative analysis
Stand before stakeholders, including senior leaders to clearly communicate strategic findings and recommendations
Partner with key members from technical and non-technical teams to build and enable high quality decisions
Prioritize and manage multiple priorities simultaneously
Advocate for working backwards from the customer
All basic qualifications, plus the following:
Degree in Computer Science, Engineering, Statistics, Mathematics, Statistics or a related field
SQL, Python/R (EDA experience), Visualisation tools (Qlik/Tableau) is must
Experience with AWS solutions
Experience working in very large data warehouse environments
Experience conducting large scale data, regression, and predictive analysis to support business decision making
Strong verbal/written communication and data visualization skills, including an ability to effectively communicate with both business and technical teams
We promise a culture of ownership coupled with competitive compensation and generous equity",4.3,"Simpl
4.3",Bengaluru,"Bengaluru, India",51 to 200 employees,2015,Company - Private,Financial Transaction Processing,Finance,Unknown / Non-Applicable,-1
316,Research Scientist,"Company Description

FireEye is the leader in intelligence-led security-as-a-service. Working as a seamless, scalable extension of customer security operations, FireEye offers a single platform that blends innovative security technologies, nation-state grade threat intelligence, and world-renowned Mandiant® consulting. With this approach, FireEye eliminates the complexity and burden of cyber security for organizations struggling to prepare for, prevent, and respond to cyber attacks. FireEye has over 7,500 customers across 67 countries, including more than 50 percent of the Forbes Global 2000.
Job Description

The Role:

We are looking for a Research Engineer to help us build next generation detection of FireEye
Appliances. The ideal candidate is someone who is passionate about solving real problems by turning cutting edge research into operational production solutions. The Staff Researcher will drive email research, analysis (data-mining) and generate content for use in our products that enhance FireEye’s security content infrastructure, process workflow, and the malware intelligence portal. They will work with team at headquarters and other locations to support research and detection efforts.

Responsibilities:
Build and drive Roadmap for detection efficacy and email research operation
Perform data analysis to measure efficacy and continuously thrive to improve developed solutions.
Forward Looking Research – Researcher will have the opportunity to develop leading edge prototypes to solve emerging challenges.
Threat Analytics – Leveraging threat intelligence from different sources, identify patterns to corelate and establish the origin and flow of attacks.
Dissect and Reverse Engineer advanced malware and cyber attacks
Develop and maintain relationships with the research community
Evangelize the deliverables to the partners, leadership, and stakeholders
Qualifications
At least three years direct or equivalent experience in areas of email, advanced threats, spam and other aspects of cyber-attacks discovery.
Specialist in programming primarily C/C++ and Python
Candidate should have good communication skills to respond to the support/customer queries.
Able to work independently and be available at times during non-business hours to handle critical
customer issues/malware outbreak.
Experience in big data infrastructure is a definite plus
Knowledge in Security and Malware detection technologies
Preferred: Hands-on reverse engineering and knowledge of operating system internals.
Experience working in fast-paced development environments
Additional Qualifications:
Excellent inter-personal and teamwork skills
Public speaking skills and experience
BS/MS in computer science or equivalent experience
Above all, the right passion and attitude to solve new challenges",3.3,"FireEye, Inc.
3.3",Bengaluru,"Milpitas, CA",1001 to 5000 employees,2004,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Palo Alto Networks, Tanium"
317,Data Analytics Engineering Intern,"Job ID: JR0134172

Job Category: Intern/Student

Primary Location: Bangalore, KA IN

Other Locations:
Job Type: Intern

Data Analytics Engineering Intern

Job Description
• Job Description:

Uses predictive modeling, statistics, Machine Learning, Data Mining, and other data analysis techniques to collect, explore, and extract insights from structure and unstructured data. Develop software, algorithms and applications to apply mathematics to data, perform large scale experimentation and build data driven apps to translate data into intelligence, solve a variety of business problems and enable business strategy. Assists business with casual inferences & observations with finding patterns, relationships in data.

Qualifications

• Qualifications:
Must have a MS in Industrial Engineering, Mathematics, or Computer Science and expect the required degree
Technical knowledge
Typically requires expertise in relational database structures, research methods, machine learning, Cloud based technologies, Big Data technologies i.e.
Hadoop , HBase, Lucene/Solr, analytics packages i.e. R, Mahout, Octave, Weka
Scripting languages i.e. Python, Perl, R
Programing languages i.e. Java, C/C++, SQL.
Data Scientist Toolkit - including time series models, machine learning, simulation/optimization, ability to develop models with structured/unstructured/big data
• Behavioral traits: Strong written & communication, analytical, action-orientation, project management, and problem-solving skills.

• Experience: Obtained through internships or academic coursework

Inside this Business Group

As the world's largest chip manufacturer, Intel strives to make every facet of semiconductor manufacturing state-of-the-art -- from semiconductor process development and manufacturing, through yield improvement to packaging, final test and optimization, and world class Supply Chain and facilities support. Employees in the Technology and Manufacturing Group are part of a worldwide network of design, development, manufacturing, and assembly/test facilities, all focused on utilizing the power of Moore’s Law to bring smart, connected devices to every person on Earth

Legal Disclaimer:

Intel prohibits discrimination based on race, color, religion, gender, national origin, age, disability, veteran status, marital status, pregnancy, gender expression or identity, sexual orientation or any other legally protected status.

It has come to our notice that some people have received fake job interview letters ostensibly issued by Intel, inviting them to attend interviews in Intel’s offices for various positions and further requiring them to deposit money to be eligible for the interviews. We wish to bring to your notice that these letters are not issued by Intel or any of its authorized representatives. Hiring at Intel is based purely on merit and Intel does not ask or require candidates to deposit any money. We would urge people interested in working for Intel, to apply directly at www.jobs.intel.comand not fall prey to unscrupulous elements.
INInternJR0134172Bangalore",4.0,"Intel Corporation
4.0",Bengaluru,"Santa Clara, CA",10000+ employees,1968,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),-1
318,Senior Data Scientist,"Job Responsibilities :
To help designing, innovating and building our next generation ML architecture
6-8 years of full time programming experience within an operations or technical department.
Identify valuable data sources and automate collection processes
Undertake preprocessing of structured and unstructured data
Analyze large amounts of information to discover trends and patterns
Build predictive models and machine-learning algorithms
Combine models through ensemble modelling
Present information using data visualization techniques
Propose solutions and strategies to business challenges
Collaborate with engineering and product development teams
Teach and mentor others in the use of AI/Machine Learning
Keyskills :

Programming, Machine Learning, Artificial Intelligence, Data Science, Business Analytics, Product engineering, Requirement gathering, Problem formulation, quick POCs

Must Have :
Experience in data mining

- Strong math skills (e.g. statistics, algebra)

- Strong programming skills in: R, Python and familiarity with Java, Scala, C++
DB/NoSql - MongoDB, Neo4J, MySql. Cassandra, DynamoDB, Redshift

- Experience on Hadoop Map reduce, Pig, Hive, Mahout and Apache Spark, H20

- Strong experience in Data warehousing, ETL, BI (e.g. Tableau, Power BI) and Data Visualization tools (matplotlib, D3.js, Plotly.js, Shiny etc)

- Experience in neural networks, regression, classification and clustering

- Think big & scale
Good to have :
Experience with Deep Learning tools - Tensorflow, Theano, Caffe etc.

- Elastic Search, NLP background and Machine Learning Platforms

- Experienced in deployment of High performance, Scalable Big Data Hadoop clusters and Web applications on cloud infrastructure (Azure, AWS, Bluemix etc)",4.1,"Netcore Solutions
4.1",Mumbai,"Mumbai, India",501 to 1000 employees,1998,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
319,Senior Data Scientist,"Responsibilities
Graduate in a quantitative subject (engineering, maths, statistics, econometrics, management etc.) and from a good institute.
At least 6 to 8 years of hands-on experience in the analytics and machine learning domain.
Ability to map business problems to analytics solutions and technique.
Ability to structure business problems into proper methodical analysis frameworks.
Can identify, develop and implement the appropriate statistical techniques, algorithms and data mining.
Good exposure to exploratory analysis and knack of deriving business insights & value. Comfortable with exploring large data sets.
Can innovate new modelling and machine learning approaches to come up with innovative products and features.
Has strong consultative skills in addition to quantitative (and statistical) ability to harness customer data in order to address business problems that materially impact business.
Can work under minimal supervision and display strong independent behaviour while leading the team in developing structured analysis.
Should have experience in at least one of the following areas – NLP, NLG, Image Classification/Computer Vision etc.
Prior experience in Forecasting & Optimization Techniques will be an added advantage.
Ability to provide solutions such as: Customer Segmentation & Targeting, Propensity Modeling, Churn Modeling, Lifetime Value Estimation, Recommender Systems, Modeling Response to Incentives, Marketing Mix Optimization, Regression.
Must have –Python, SQL & Excel.
Good to have – Scala, Julia, Java
Exposure to Big Data platforms like Hadoop and its eco-system (Hive, Pig, Sqoop, Mahout) is a plus.
Bonus points for implementation of Big Data and/or Streaming data analytics",-1,Tenzai,Karnataka,-1,-1,-1,-1,-1,-1,-1,-1
320,Machine Learning Engineer,"Roles &Responsibilities

A Machine Learning Engineer train machine learning and deep
learning models on a computing cluster to perform real time analytics, machine
diagnostics, manufacturing process analytics etc.
Work
on the data science roadmap for our flagship Industrial IoT product
Product
design & implement ML/AI solutions and integrate them with various Big
Data platforms and architectures
Creating
and Maintain Machine Learning pipelines that are scale-able, robust, and
ready for production
Troubleshoot
ML/DL model issues, including recommendations for retrain, re-validate,
and improvements/optimization
Train and deploy robust, scalable, state-of-the art Machine Learning and Deep learning solutions in production for Industrial IoT use-cases.


Requirements


Skills
& Qualifications
Bachelors or Masters in Computer Science/Engineering Degree or Maths Stats from
a reputed college
3+ years of experience in solving data science problems that has driven value to
customers data
Strong working knowledge of ML/DL algorithms
Fluent proficiency in Python, SQL, (Scala or C++) for developing solutions in production (Mandate)
Hands-on proficiency with at least 1 major ML/DL framework
(PyTorch/TensorFlow/MxNet/Keras/Gluon)
Excellent problem-solving approach; Communication and articulation skills;
Inclination and ability to pick up new techniques/technologies
Preferred Qualifications <b",-1,Machstatz,Bengaluru,"Bengaluru, India",1 to 50 employees,2017,Company - Private,IT Services,Information Technology,₹10 to ₹50 million (INR),-1
321,Data Engineer,"Nokia is a global leader in the technologies that connect people and things. With state-of-the-art software, hardware and services for any type of network, Nokia is uniquely positioned to help communication service providers, governments, and large enterprises deliver on the promise of 5G, the Cloud and the Internet of Things.

Serving customers in over 100 countries, our research scientists and engineers continue to invent and accelerate new technologies that will increasingly transform the way people and things communicate and connect.

Nokia is an equal opportunity employer that is commited to diversity and inclusion.

At Nokia, employment decisions are made regardless of race, color, national or ethnic origin, religion, gender, sexual orientation, gender identity or expression, age, marital status, disability, protected veteran status or other characteristics protected by law.

Nokia is undertaking a large-scale service analytics and big data platform initiative called AVA and serving thousands to tens of thousands of internal and external users. This platform will enable Nokia and its customers to build the next generation of services for telecommunications and beyond, including transport, connected health and broader IOT. You will be joining a very dynamic and growing team of talented individuals, setting up state-of-the-art solutions for outstanding customer experience.

General Purpose

The Data Engineer is responsible for the development of analytics big data transformation flows on a large-scale service analytics platform for various customers across the globe. Responsibility includes delivery of high quality use case Data Pipeline ready for use and deployment towards customers, meeting the business requirements and aligning with the solution vision and strategy.
As the primary interface of the Solution Owner, the Data Engineer will report to the Head of Data Engineering. The Data Engineer will have a strong influence on the technical design, and be expected to have a deep understanding of business and solution development context.

Data Engineer Responsibilities and Duties
Understand the customer’s business context, objectives and requirements.
Involvement in Requirement Analysis, Design, Development, Unit Testing, System Integration Testing and other facets of testing for example but not limited to Performance Testing :
Convert functional specifications from business requirements into programming instructions for technical development of analytics data pipelines.
Break down major requirements in to small incremental value-add features and prioritize with Solution Owner.
Prototype creative analytics data pipeline mock-ups, and be able to collaborate with others in crafting and implementing your technical vision.
Develop industrialized solutions leveraging Agile and DevOps methodologies.
Review, analyze, and modify programming systems, including encoding, testing, debugging and installing for a large-scale environment.
Monitor operating efficiency and optimize solution execution performance.
Support Solution Owner through the delivery process to customers :
Execute the analytics solution development plan, resolves or escalates problems timely.
Foster the Analytics Competence Center in developing enablement and e2e solution consultancy across Use Cases.
Work harmoniously in a large cross-functional team including managers, supervisors, business analysts, systems personnel, network staff, and other developers.
Qualifications
Bachelor’s Degree in Computer Science, Software Development, or a business-related field.
4 to 10 years experience in a comparable role.
Fully conversant with analytics and new technologies, strong knowledge of industry trends knowledge including products and services on Nokia’s core business.
Strong experience in building fast, robust, effective and efficient analytics data pipelines with modern cloud development technologies covering data collection, transformation, storage and exposure :
Advanced development skills and experience in Scala language (or having a particularly deep expertise in one of the field below) is a must.
Big data distributed environment development and optimization experience with Spark.
NoSQL technology experience with Apache Cassandra or Parquet Files hosted on S3, designing relevant data models dealing with high data velocity and/or volume while ensuring integrity.
Streamlined data collection and transformation flow experience with Kafka considered a plus.
Experience consuming enterprise web-services (REST, JSON/XML, MySQL/PostgreSQL) and also expose own services to help design the next generation of back-end APIs and functionality.
Experience in containerization/ dockerization of developed solutions.
Experience with Apache NiFi considered a plus.
Understanding of Java Development tools (IntelliJ IDEA), Zeppelin notebook considered a plus.
Modern software development methodologies such as Agile, Scrum, etc. including Test Driven Design and other testing methodologies.
Use Git to manage source code and Artifactory to publish.
Sound methodical skills with attention to detail and process requirements.
Capability to multi-task and prioritize to ensure timely deliveries.
Comfortable with working with multiple stakeholders in a multi-cultural environment of a global matrix organization with sensitivity and partnering.
High energy, initiative, enthusiasm and persistence. English mandatory.

Apply now.",4.1,"Nokia
4.1",Noida,"Nokia, Finland",10000+ employees,1865,Company - Public,Telecommunications Services,Telecommunications,₹500+ billion (INR),"Ericsson-Worldwide, Huawei Technologies, Microsoft"
322,Data Analyst,"Parity Computing, a unit of RELX/Elsevier, is inviting applications for data analyst positions for its OrgDB product to curate organization metadata and name variants to help produce excellent organization publication profiles. The work involves investigating research organizations and their structure to extract and normalize data, interpreting the metadata policies, deciding the best approach to curate the data, and analyzing the impact of curation on organization publication profiles. We are looking for individuals who can conduct excellent research, work independently, and pay attention to detail. Premium is placed on those individuals who can produce a high-quality content.

Parity’s OrgDB product is the leading authoritative database of the world’s research producing organizations. OrgDB powers STM industry applications for characterizing organizations and accurately attributing their research works.

Required skills

Able to think analytically, use a systematic and logical approach to analyze data, problems and situations.,

Familiarity with scientific research, publications, universities and research organizations,

Ability to perform independent research on topics related to the structure of and relationships among universities and research organizations,

Ability to think abstractly and collect and classify entities such as person and organization names, organizational structure, scientific expertise, and related entities,

Ability to interpret policies, follow them consistently, develop positive and negative examples for each policy, and assist in fine tuning policies

Ability to assess the quality, completeness, and other characteristics of the content

Preferred qualifications

Post Graduation

· Outstanding oral and written communication skills

· Skills in working with databases, software tools, and modeling languages such as XML.

· Demonstrated ability to meet deadlines

· Excellent planning, organizational, and time management skills.

· Ability to work under pressure and meet deadlines

Elsevier is an equal opportunity employer: qualified applicants are considered for and treated during employment without regard to race, color, creed, religion, sex, national origin, citizenship status, disability status, protected veteran status, age, marital status, sexual orientation, gender identity, genetic information, or any other characteristic protected by law. If a qualified individual with a disability or disabled veteran needs a reasonable accommodation to use or access our online system, that individual should please contact 1.877.734.1938 or accommodations@relx.com.

Elsevier is a global information analytics business that helps institutions and professionals progress science, advance healthcare and improve performance for the benefit of humanity. We help researchers make new discoveries, collaborate with their colleagues, and give them the knowledge they need to find funding. We help governments and universities evaluate and improve their research strategies. We help doctors save lives, providing insight for physicians to find the right clinical answers, and we support nurses and other healthcare professionals throughout their careers.Elsevier provides digital solutions and tools in the areas of strategic research management, R&D performance, clinical decision support, and professional education; including ScienceDirect, Scopus, SciVal, ClinicalKey and Sherpath. Elsevier publishes over 2,500 digitized journals, including The Lancetand Cell, more than 35,000 e-book titles and many iconic reference works, including Gray?s Anatomy. Elsevier is part of RELX Group, a global provider of information and analytics for professionals and business customers across industries. Elsevier employs over 7,000 people in more than 70 offices worldwide. We are an employer of choice, attracting and developing talented and creative people who thrive in a challenging and fast-paced environment. We offer an excellent compensation and benefits package as well as a real opportunity for career growth in a growing organization.",4.4,"Elsevier
4.4",Bengaluru,"Amsterdam, Netherlands",5001 to 10000 employees,1880,Subsidiary or Business Segment,Publishing,Media,₹100 to ₹500 billion (INR),"Clarivate Analytics, Springer Nature, Thomson Reuters"
323,Data Science Engineer - Image Database,"Senior Data Architect

Summary

We are looking for a technical lead who will design, build and maintain the data pipeline for creating training datasets for our AI research engineers. Additionally he or she will be responsible for automating the large dataset creation process. The ideal candidate should have 6-10 years of industrial experience in related field as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence/Data/DW Engineer, Data Scientist etc.) and 1-2 years of experience in leading a team.


Responsibilities
Lead the data pipeline setup, operation and maintenance.
Assemble large, complex data sets that are analysis/training ready for the machine learning engineers/researchers
Design and build scalable and reliable data pipeline that collects, transforms, loads and curates data from internal systems. Ensure high data quality for pipelines you build and make them auditable. Support design and deployment of distributed data store that will be central source of truth across the group.
Develop, customize, configure automation scripts/tools that help engineers to extract and analyze data from our internal data store. Develop reporting and data visualization solutions, as well as looking to build out a dynamic platform
Evaluate new technologies and build prototypes for continuous improvements in data engineering. Creation of new capabilities and modules in our data pipeline. Develop and maintain expertise in advanced and/or emerging data management and analytical information technologies such as data warehouse, data lake and Big Data
Build data connections to company's internal IT systems
Design, implement and continuously optimize the group’s data strategy. Provide thought leadership and lead efforts to design data integration and implement extract, transform and load (ETL) jobs/processes, detailed data warehouse models and data mappings. Provide consultation on best practices and standard practices to internal team members
Perform performance optimization and tuning on new and/or existing data warehouse implementations.
Requirements
5 years of hands on industry experience with a track record of manipulating, processing, and extracting value from large data sets.
Demonstrated ability in building data pipelines, data modeling, ETL development and familiarity with design principles. Experience building data products incrementally, integrating, and managing data sets from multiple sources. Knowledge of data warehouse technologies and relevant data modeling best practices. Experience with a DW technology (Redshift, SQL Server, etc.) and relevant data modeling. Experience processing large amounts of data, in various formats and processing data in batch mode and streaming mode
Excellent SQL skills. Proficiency in a scripting language (Python, Ruby, Perl etc.) and/or a major programming language (C , Java etc.). Knowledge of R is a plus.
Experience with working in Spark/Hadoop and/or other distributed computing frameworks is required
Experience working in a multi-layered distributed architecture is essential. Experience with scalable service architecture and design
Exposure and knowledge of Data Security and Governance. Awareness of best practices to secure data and processes from unauthorized access.
Knowledge and direct experience using business intelligence reporting tools (Tableau, PowerBI etc.) is a plus.
Understanding of data science, machine learning, and AI is a plus.
Strong analytical and problem solving skills (data analysis and requirement documentation)
Excellent project management skills and ability to prioritize issues
Excellent oral and written communication, organizational and client facing skills.
Academic Qualification Profile:


B.E. / B. Tech in Computer Science

Certification or Masters in Big Data Science",4.2,"Daimler
4.2",Bengaluru,"Stuttgart, Germany",10000+ employees,1886,Company - Public,Transportation Equipment Manufacturing,Manufacturing,₹500+ billion (INR),"Audi, Porsche, BMW"
324,Data Analyst/Scientist,"Founded in 1987 and listed on NASDAQ, our client is headquartered in the USA and has an annual turnover of over USD 2+ Billion. They are a leading provider of technology solutions for small, medium, enterprises throughout the North America, Europe and Asia. Their comprehensive expertise and proven experience in advanced technologies and consulting & implementation services makes them the preferred partner for many global MNC customers

As a Data Analyst/ Scientist you will be responsible for reviewing, analysing and for gaining insights from the data stored in the BI data cubes as well as position BI for future uses such as machine learning and predictive analytics of sales behaviors.

Ket Responsibilities and Qualifications/Skills
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending company’s data with third party sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance
Excellent understanding of machine learning techniques and algorithms, etc.
Experience with common data science toolkits
Great communication skills
Experience with data visualization tools such as Power BI
Experience with MS SQL databases and Analytics / OLAP Cube Development (Microsoft SSAS and MDX)
Proficiency in using query languages such as SQL
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Data-oriented personality
Location: Gurgaon, India

Employment Term: Dedicated & Full Time",5.0,"itForte
5.0",Gurgaon,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
325,Data Analyst / SME,"Join a team recognized for leadership, innovation and diversity


As a Procurement Project Management Specialist, you will have a strong understanding of project management activities, including the end to end project management process in a fast paced, complex business environment. You will work within a team of collaborative colleagues, working on high-impact projects that move the business forward. You will help your team meet deadlines, track, monitor and summarize progress of projects, and prepare reports for senior leadership regarding the status and project of the project.

Key Responsibilities
Oversees and coordinates the operational and strategy creation aspects of sourcing projects
Partners with Category and Commodity leaders to create strategy and drive projects to completion
Reviews status of projects and budgets; manages schedules and prepares status reports
Assesses project issues and develops resolutions to meet productivity, quality, and customers satisfaction goals and objectives
Develops mechanisms for monitoring project progress and for intervention and problem solving with project managers, line managers, and customers
YOU MUST HAVE
Undergraduate degree and some experience in Supply Management / Sourcing / Procurement and leading projects
WE VALUE
Strong analytical and innovative mindset to handle multiple projects and meet deadlines
Excellent written and oral communication skills
Able to articulate points of view with senior leaders, but execute plans when directed
Demonstrate actionable results by delivering against targets for financial performance business impact
Strong project management skills including the ability to manage priorities and workflow
Demonstrated ability to think strategically but detailed oriented to support ideology with facts
Additional Information
JOB ID: HRD95375
Category: Procurement
Location: HW Camp II,Bldgs 9A&9B,Plot C2,RMZ Ecoworld,Varturhobli,Sarjapur Marathahalli Outer Ring Road,Bangalore,KARNATAKA,560103,India
Exempt
Early Career (ALL)",3.8,"Honeywell
3.8",Bengaluru,"Charlotte, NC",10000+ employees,1885,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"GE, Johnson Controls, United Technologies"
326,Data Scientist/5 yrs/,"About Authbridge Authbridge is a risk assessment firm that provides tech-enabled solutions and platforms. We are currently Indias’s leading BGV company with more than 500 clients including companies like Infosys, E&Y, Wipro, Axis Bank etc. with delivery capacity in more than 140 countries. Purpose of the role To help the organization in Big Data transformation, analysis and translation Prior Work Experience Should have a minimum of 5 years of experience as a Data Scientist with experience in ML models or statistical models in R or Python Should have built demonstrable ML-based engines such as recommendation, fraud detection, image/pattern recognition Experience in working with Linux computing environment

Utilize Data mining using open source toolkits Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Develop insights from a vast amount of data

Good scripting and programming skills in Python / R Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc. Proficiency in MYSQL, ElasticSearch/Solr, and SPARK frameworks Working in Linux Computing Environment

Client has shared the below list of premium colleges, candidate has to be from one of the below. They want Senior Data Scientist with 5 to 7 Yrs experience (Relevant can be min 2 Yrs) with OCR and Image Processing hands on experience.

List of Premium Colleges as below –

Indian Institute of Technology Madras
Indian Institute of Technology Bombay
Indian Institute of Technology Delhi
Indian Institute of Technology Kharagpur
Indian Institute of Technology Kanpur
Indian Institute of Technology Roorkee
Indian Institute of Technology Guwahati
Anna University Chennai Tamil Nadu
Indian Institute of Technology Hyderabad
Institute of Chemical Technology Mumbai Maharashtra
National Institute of Technology Tiruchirappalli
Jadavpur University Kolkata West Bengal
Indian Institute of Technology (Indian School of Mines) Dhanbad
Indian Institute of Technology Indore Indore Madhya Pradesh
National Institute of Technology Rourkela Rourkela
Vellore Institute of Technology Vellore Tamil Nadu
Birla Institute of Technology & Science Pilani Rajasthan
Indian Institute of Technology Bhubaneswar Bhubaneswar
Indian Institute of Technology (Banaras Hindu University) Varanasi
Thapar Institute of Engineering and Technology Patiala
National Institute of Technology Surathkal Surathkal
Indian Institute of Technology Ropar Rupnagar Punjab
Indian Institute of Space Science and Technology Thiruvananthapuram
Indian Institute of Technology Patna Patna Bihar
National Institute of Technology Warangal Warangal Telangana
Birla Instituteu of Technology Ranchi

About PROLIM Corporation

PROLIM is a leading provider of end-to-end IT, PLM and Engineering Services and Solutions for Global 1000 companies. They understand business as much as technology, and help their customers improve their profitability and efficiency by providing high-value technology consulting, staffing, and project management outsourcing services.

Their IT and PLM consulting offerings include; Advisory, PLM Software/Services, Program Management, Solution Architecture Training/Staffing, Cloud Solutions, Servers/Networking, Infrastructure, ERP Practices and QA Services. Engineering services include Data Translation, CAD/CAM/CAE, Process & Product Engineering, Prototyping, and Testing/Validation within a wide range of markets and industries.",3.4,"PROLIM Corporation
3.4",Gurgaon,"Farmington Hills, MI",201 to 500 employees,2005,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹1 to ₹5 billion (INR),"Arena, HCL Technologies, PTC"
327,Analyst - Data Science,"Responsibilities :
Data Scientist with Machine Learning, Python & R Programming Experience.
Good Attitude and Communication skills, SQL, Excel Macros.
Good to have exposure Reports and Risk analysis.
Strong hands on SQL (RDBMS)- Data mining.

Required Skills :
Experienced in Data Science and Data Analysis.
Hands on R Programming/ Basic SQL.
Knowledge on Investment Banking Domain (BFSI) added Advantage.
Good knowledge into reporting.
Good knowledge in Excel/PIVOT/MACROS/ Excel functions.

Primary Skills :
Data Science
Machine Learning
Python & R programming

Good to have :
SQL Seam framework
Excel Macros
BFSI Vertical knowledge
Experience 3 to 6 Years
Industry Type IT Software, Software Services
Role Software Developer/Senior Software Developer
Functional Area Application Programming, Maintenance
Education UG – Any Graduate – Any Specialization PG – Any PG Course – Any Specialization
Location Bangalore
Email referral@nuware.com
Website www.nuware.com",3.6,"Nuware Systems
3.6",Bengaluru,"Iselin, NJ",51 to 200 employees,1994,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
328,Data Scientist Intern,"Internship Cohort Team Size : 3

Apply Via Naukiri Posting

https://www.naukri.com/job-listings-Data-Scientist-Intern-zBliss-Technologies-Pvt-Ltd-Bengaluru-Bangalore-Chennai-0-to-1-years-110520000083

Apply only if you can work full time at least for Five Months

and

Only if you can demonstrate the Skills listed below through Previous projects, College Projects, or self-learning exercises reflected in your resume

Skills:
Python
Thorough understanding of Pandas, Tensorflow 2, Keras and other related modules
Experience in managing datasets with millions of rows and multiple features
Strong understanding and subject expertise in Artificial Neural Network (ANN) and Recurrent Neural Network (RNN)
RNN and ANN Modeling using TensorFlow 2 and Keras
Diligence and accuracy in coding and data analysis
Conscientiousness, and Professional approach towards team work, project management, coding, and product development
Education: Students pursuing Data Science related graduate, post graduate, Doctoral, and integrated courses.

Internship Duration: The internship will be for six to nine months. We cannot accommodate internship period less than three months

Internship Project: Development and implementation of AI algorithms in Healthcare. You will be guided and coached extensively. You will need to perform and contribute positively to the project on a daily basis

This is a full time PAID Internship for six to nine months.

Location: Chennai, or Work From Home because of the COVID19 Lockdown

Application Process:
Apply through this web page.

After reviewing your resume we will send you a pre-interview Programming Assessment Exercise to test your skills in Python, Data Management and Machine Learning. You will have to complete this exercise within five days of receipt of the Exercise and send the completed Exercise back to us.

We will review your submission and if we consider your skills to match our expectations, we will do a phone interview and if possible an in-person interview. Upon successful completion of the interview process you will be given an internship offer.

Job Features
Job Category Data Scientist Intern",-1,zBliss Technologies,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
329,Data Engineer,"We’re hiring a talented Data Engineer and Big Data enthusiast to work in our platform to help ensure that our data quality is flawless. As a company, we have millions of new data points every day that come into our system. You will be working with a passionate team of engineers to solve challenging problems and ensure that we can deliver the best data to our customers, on-time. You will be using the latest cloud data warehouse technology to build robust and reliable data pipelines.

Duties/Responsibilities Include:
Develop expertise in the different upstream data stores and systems across Numerator.
Design, develop and maintain data integration pipelines for Numerators growing data sets and product offerings.
Build testing and QA plans for data pipelines.
Build data validation testing frameworks to ensure high data quality and integrity.
Write and maintain documentation on data pipelines and schemas
Requirements:
BS or MS in Computer Science or related field of study
3 + years of experience in the data warehouse space
Expert in SQL, including advanced analytical queries
Proficiency in Python (data structures, algorithms, object oriented programming, using API’s)
Experience working with a cloud data warehouse (Redshift, Snowflake, Vertica)
Experience with a data pipeline scheduling framework (Airflow)
Experience with schema design and data modeling
Exceptional candidates will have:
Amazon Web Services (EC2, DMS, RDS) experience
Terraform and/or ansible (or similar) for infrastructure deployment
Airflow -- Experience building and monitoring DAGs, developing custom operators, using script templating solutions.
Experience supporting production systems in an on-call environment",4.0,"Numerator
4.0",Pune,"Chicago, IL",1001 to 5000 employees,2004,Company - Private,IT Services,Information Technology,₹10 to ₹50 billion (INR),"Nielsen, Kantar, IRI"
330,Associate Architect - Data Science,"Icertis, the leading enterprise contract management platform in the cloud, solves the hardest contract management problems on the easiest to use platform. With Icertis, companies accelerate their business by increasing contract velocity, protect against risk by ensuring regulatory and policy compliance, and optimize their commercial relationships by maximizing revenue and reducing costs. The AI-infused Icertis Contract Management (ICM) platform is used by companies like Airbus, Cognizant, Daimler, Microsoft and Sanofi to manage 6.5 million contracts in 40+ languages across 90+ countries.

Responsibilities:
· Partner with Business Stakeholders to translate business objectives into clearly defined analytical Projects
· Own the end-end process, from recognizing the problem to implementing the solution.
· Identify opportunities for text analytics and NLP to enhance core product platform, select best ML technique to the specific business problem and then build model to solve the problem
· Define the variables and their inter-relationships and extract the data from our data repositories, leveraging infrastructure including Cloud computing solutions and relational database environments.
· Build predictive models that are accurate and robust and that help our customers to utilize the core platform to the maximum extent.
· Guide and mentor team members on the technical activities of the project

Skills and Qualifications:
· 8+ years of experience.
· An advanced degree in predictive analytics, machine learning, artificial intelligence; or a degree in programming and significant experience with text analytics/NLP. He shall have a strong background in machine learning (unsupervised and supervised techniques). In particular, excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, logistic regression, MLPs, RNNs, etc.
· Experience with text mining, parsing, and classification using state-of-the-art techniques.
· Experience with information retrieval, Natural Language Processing, Natural Language Understanding and Neural Language Modeling.
· Ability to evaluate quality of ML models and to define the right performance metrics for models in accordance with the requirements of the core platform.
· Experience in the Python data science ecosystem: Pandas, NumPy, SciPy, scikit-learn, NLTK, Gensim, etc.
· Excellent verbal and written communication skills, particularly possessing the ability to share technical results and recommendations to both technical and non-technical audiences.
· Ability to perform high-level work both independently and collaboratively as a project member or leader on multiple projects.
· Ability to own solutions for design and architecture and negotiate requirements with global customers
· Experience with Enterprise Software Design is a plus
Icertis is not open to 3rd party solicitation or resumes for our posted FTE positions. Resumes received from 3rd party agencies that are unsolicited will be considered complimentary.

Icertis, Inc. provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, gender, sexual orientation, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. Icertis, Inc. complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities.",4.2,"Icertis
4.2",Pune,"Bellevue, WA",1001 to 5000 employees,2009,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,"Selectica, SAP Ariba"
331,Data Analyst,"About Swiss Re

Swiss Re is one of the world’s leading providers of reinsurance, insurance and other forms of insurance-based risk transfer, working to make the world more resilient. We anticipate and manage a wide variety of risks, from natural catastrophes and climate change to cybercrime.

At Swiss Re we combine experience with creative thinking and cutting-edge expertise to create new opportunities and solutions for our clients. This is possible thanks to the collaboration of our 15,000 employees across the world.

We offer a flexible working environment where curious and adaptable people thrive. Are you interested in joining us?

About the role:
Provide data analysis, transformation and technical support needed by L&H Products Americas Actuarial team to support L&H pricing initiatives, analysis of reinsured lives business, new product development initiatives.
Support and develop processes to deliver quantitative studies of internal mortality and lapse data.
Provide high quality and timely technical support to the L&H Products Americas staff.
Coordinate workflow between data analysts and actuarial teams.
Follow established guidelines and best practices for internal and external data management processes, which includes appropriate documentation in support of business controls.
Create, maintain, and enhance guidelines and best practices when necessary.
Streamline current processes for efficiency when appropriate.

About the team:

US Experience Studies team is responsible for assisting in the development of client specific pricing assumptions & maintaining data set and study quality for all other purposes. The team is located in two main offices: Fort Wayne (US) and Bangalore (India).

About you:
2-3 years of experience related to technical processes necessary to support L&H Product's needs.
Experience with Microsoft Access, Microsoft Excel, SQL and client database tools, or others such as R, Python, SAS and Oracle.
1-2 yrs. of experience in insurance related fields, knowledge of insurance products & their administration is desired.
Cross cultural experience working with colleagues globally; experienced in managing data works handover processes between teams in different geographical locations.
Demonstrates strong oral and written English communication skills, along with strong interpersonal skills.
Shows initiative in identifying data related issues and supporting other team members, peers and senior stakeholders.
Strong creative problem solving and analytical skills.
Strong documentation skills.
Ability to work independently, accurately and deliver to deadlines.
Swiss Re",3.8,"Swiss Re
3.8",Bengaluru,"Zurich, Switzerland",10000+ employees,1863,Company - Public,Insurance Agencies & Brokerages,Insurance,₹500+ billion (INR),"Munich Re, Hannover RE, SCOR"
332,"Data Engineer, Platform (APAC)","MongoDB is growing rapidly and seeking a Data Engineer to be a key contributor to the overall internal data platform at MongoDB. You will design and build a scalable data driven platform to help drive MongoDB's growth as a product and as a company, while also taking on complex platform problems with the goal of making our platform more scalable, reliable, and robust.

Our ideal candidate has experience with
Several programming languages (Python, Scala, Java, etc.)
AWS services such as EMR, Lambda, S3, Athena, Glue, IAM, RDS, etc.
Orchestration tools such as Airflow, Luiji, Azkaban, Cask, etc.
Streaming data processing frameworks like Kafka, KSQ, and Spark Streaming
A diverse set of databases like MongoDB, Cassandra, Redshift, Postgres, etc.
Different storage formats such as Parquet, Avro, Arrow, and JSON
Data processing frameworks like Spark
Git and Github
CI/CD Pipelines
You might be an especially great fit if you
Constantly think of ways to squeeze better performance out of a data platform
Plan effective data storage, security, sharing, and publishing within an organization
Design boilerplate architecture that can abstract underlying technology from end users
Design, manage, and test disaster recovery procedures for a variety of data platforms
Value code simplicity and performance
Obsess over data: everything needs to be accounted for and be thoroughly tested
Build great things alone, but the greatest things in collaboration with others
Nice to haves
You are deeply familiar with Spark and/or Hive
You have expert experience with Airflow
You understand the intricacies between different storage formats like Parquet, Avro, Arrow, and JSON
You are familiar with deployment and configuration tools such as Kubernetes, Drone, and Terraform
You have experience building microservices
You've built an end-to-end production-grade data platform that runs on AWS
You have experience building a machine learning platform using tools like SparkML, Tensorflow, Scikit-Learn, etc.
Responsibilities

As a Data Engineer, Platform you will:
Build a large-scale batch and real-time platform that will make data pipelines seamless and scalable
Help drive best practices in continuous integration and delivery
Help drive optimization, testing, and tooling to improve data platform quality
Collaborate with other software engineers, machine learning experts, and stakeholders, taking learning and leadership opportunities that will arise every single day
Success Measures

In 3 months

you will have familiarized yourself with much of our data platform, be making regular contributions to our codebase, will be collaborating regularly with stakeholders to widen your knowledge and helping to resolve incidents and respond to user requests

6 Months

you will have successfully investigated, scoped, executed, and documented a small to medium sized project and worked with stakeholders to make sure their data needs are satisfied by implementing improvements to our platform

12 Months

You will have become the key person for several projects within the team and will have contributed to the data platform's roadmap. You will have made several sizable contributions to the project and are regularly looking to improve the overall stability and scalability of the architecture

Do you know, Why MongoDB is a fantastic place to work and build your career?
Disrupting a $64 Billion market
Top NoSQL database in the world
Largest Ecosystem and the fastest growing database in the world
Close to 17,000 customers in over 100 countries and over 90+ million downloads
>120% net ARR expansion rate over each of the last twenty quarters
Sequoia Capital and a number of other Top VC firms have invested in MongoDB. Sequoia Capital calls us out as one of their flagship portfolios; Sequoia has also invested in Apple, Google, Youtube, and WhatsApp
9-figure revenue company, with very high double-digit growth rates
Be a part of the company that's reinventing the database, focused on innovation and speed
Enjoy a fun, inspiring culture that is engineering focused
Work with talented people around the globe
Learn, contribute, and make an impact on the product and community.


Life at MongoDB

Our India office culture
180+ people, with teams in Sales, Engineering, HR, Finance, IT & Marketing
Regular group outings and opportunities to get to know your colleagues
Employee affinity groups


Our Benefits
Competitive salary and equity
Comprehensive Health cover, dental cover, travel insurance & Life Insurance.
Free lunch twice per week and a fully stocked kitchen with healthy and sweet treats.
Macbooks are company standard
26 weeks Maternity & 20 Paternity leave to spend time with new arrivals.",4.6,"MongoDB
4.6",Gurgaon,"New York, NY",1001 to 5000 employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
333,Principal Data Engineer (Python),"Requirements:

13+ years of relevant experience
Expert in Python, hands-on experience with at least one Python server-side frameworks like Django, Flask etc
Able to integrate multiple data sources and databases into one system
Understanding of the threading limitations of Python, and multi-process architecture
Knowledge of user authentication and authorization between multiple systems, servers, and environments
Understanding of fundamental design principles behind a scalable application
Understanding of and experience with real-time / event-driven data processing applications; knowledge of concepts, tools: message queues / brokers, pubsub model, lambda vs kappa architecture patterns, streaming data processing, etc
Familiarity with event-driven programming in Python

Supply Chain Nation

Our Values

If you want to know the heart of a company, take a look at their values. Ours unite us. They are what drive our success – and the success of our customers. Does your heart beat like ours? Find out here: Core Values

Check out Blue Yonder's blog - Supply Chain Nation - the platform for supply chain trends and innovations.",4.3,"Blue Yonder
4.3",Bengaluru,"Scottsdale, AZ",5001 to 10000 employees,1985,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 billion (INR),"SAP, Oracle, Manhattan Associates"
334,Data Scientist - Machine Learning/Artificial Intelligence/ Python -BFSI,"Experience 4 - 10 Years
Salary 8 LPA - 16 LPA
Job Location Bengaluru

Industry:
IT-Software / Software Services

Keywords:
Data Scientist

About Job:
Core Responsibility :
Strong experience in delivering projects in using Python.
Strong experience in developing models using Image Processing and Computer Vision algorithms
Designing, developing, and deploying deep learning models on AWS environment.
Experience and Skills :
4 - 6 years- experience in Designing and Deploying Deep Learning Solutions
Excellent knowledge of Deep Learning Architectures/Convolutional Neural Networks
Excellent knowledge of Supervised Learning, Adversarial Learning
Excellent Python Coding Skills with at least 4 years of Python coding
Robust working knowledge with deep learning frameworks (like Tensorflow, Keras, PyTorch)
Hands on experience on Image Processing and Computer Vision algorithms
Experience with GPU/CUDA programming
Deep knowledge of mathematics, probability, statistics and algorithms
Understanding of data structures, data modelling and software architecture
Excellent communication skills
Ability to work in a team
Outstanding analytical and problem-solving skills
Must Have :
Aware of the Software Development Life Cycle and Quality concepts
Excellent experience in Python programming language for data analysis.
Excellent verbal and written communications skills; Strong interpersonal skills
Managing available resources such as cloud services, data
Good to Have :
Experience with System Development Life Cycle methodologies (CMMI)",4.0,"Careerera
4.0",Bengaluru,"Wayland, MA",501 to 1000 employees,-1,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
335,Data Engineer,"Introduction
Software Developers at IBM are the backbone of our strategic initiatives to design, code, test, and provide industry-leading solutions that make the world run today - planes and trains take off on time, bank transactions complete in the blink of an eye and the world remains safe because of the work our software developers do. Whether you are working on projects internally or for a client, software development is critical to the success of IBM and our clients worldwide. At IBM, you will use the latest software development tools, techniques and approaches and work with leading minds in the industry to build solutions you can be proud of.

Your Role and Responsibilities
Fullstack architect is responsible for designing and implementing end-to-end modern applications within a Digital Transformation context.
Lead and guide a team on developing solutions that fully integrate and collaborate with existing IT systems to solve complex business solutions related to Systems of Engagement or Systems of Records.
Provide a holistic view of enterprise solutions, taking into consideration operational costs, security, performance engineering, UX, bimodal velocity, application development, and systems management.
Play different roles within the team, from lead architect to high-skilled developer and technical team leader to consultant and technical evangelist.
Demonstrate sound understanding of fullstack-technology architectures but also very good communication skills, with the ability to adapt them to different audiences
Required Technical and Professional Expertise
Minimum 7-8 years of development experience in building enterprise grade applications/product
Should be a self-starter and independent
Must be able to work independently and in a team setting
Be able to articulate implementation at all levels
Must be able to evaluate alternative solutions
Applicants with wide variety of technical experience are good candidates for this position
At least 3 years of experience in Single Page application development
At least 3 years of development experience in Unix/Linux/Solaris environment
Strong in Scala / Java
Strong in Java EE/Spring Web/Spring Boot
Strong in JavaScript, HTML, CSS
Strong in React/Angular
Must have worked with ORM tools like Hibernate
First-hand experience with Postgres and Oracle
Good in SQL/PSQL
Familiarity with Gradle/Maven
Good knowledge in GO language
Working knowledge in Micro Services Architecture is a must
Working knowledge with Application Servers like Jboss/Wildfly/Websphere Application Server
Preferred Technical and Professional Expertise
Kubernetes or Docker
Application packaging and deployment aspects
Familiar with Akka toolkit
Continuous Integration and Continuous Development knowledge
Working experience with Python
About Business Unit
At Global Technology Services (GTS), we help our clients envision the future by offering end-to-end IT and technology support services, supported by an unmatched global delivery network. It's a unique blend of bold new ideas and client-first thinking. If you can restlessly reinvent yourself and solve problems in new ways, work on both technology and business projects, and ask, ""What else is possible?"" GTS is the place for you!

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Gurgaon,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
336,Senior Data Scientist,"Job Location – Pune, India
Required experience – 3+ Years

About Innoplexus
Innoplexus offers Data as a Service and Continuous Analytics as a Service products, leveraging Artificial Intelligence and advanced analytics to help reduce the drug development time, from synthesis to approval, significantly.

Our products leverage proprietary algorithms and patent-pending technologies to help global Life Sciences and Pharmaceuticals organizations with access to relevant data, real-time intelligence & intuitive insights, across pre-clinical, clinical, regulatory and commercial stages of a drug.

We automate the collection, curation, aggregation, and analysis, of billions of data points from thousands of data sources, using machine learning, network analysis, ontologies, computer vision, and entity normalization.

Responsibilities

Develop new machine learning, deep learning & ontology-based modelling algorithms to take up unsolved industry challenges.
Lead and mentor a small team of data scientists in applying existing learning algorithms and develop new ones.
Cross-functional collaboration to support integration of finished algorithms and prototypes into products.
Create intellectual property for Innoplexus and write patent disclosures for them.
Support sales and business development teams to fine-tune client requirements, perform feasibility testing and proposing approach for solutions.
Demonstrate thought leadership by participating in national & international conferences represent Innoplexus and publishing blogs, white papers etc.

Required experience

Strong, demonstrable experience developing new deep learning models (NLP, Image Processing, Computer Vision, Speech Recognition) and machine learning over unstructured data.
Hands on experience of deploying Machine Learning or Deep Learning based solutions in production with large datasets.
Strong understanding of Python and Machine Learning libraries (NumPy, SciPy, sklearn, TensorFlow, PyTorch, Keras).
More than 3 years of relevant experience in industry with at least 1 year experience of leading a team.
Good writing skills demonstrated by patents, publications, blogs or personal pages.
Experience in domain of life sciences or financial services is a plus.

Required qualification

B.Tech or equivalent in Computer Science, Statistics, Applied Maths or related domain. Higher education will add on it.",4.1,"Innoplexus
4.1",Pune,"Frankfurt am Main, Germany",201 to 500 employees,2011,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),"Palantir Technologies, Mu Sigma, IQVIA"
337,Data Engineer,"We are building a world-class language-related product that has the potential to positively transform lives worldwide. We have a passionate team of data scientists, coders, and linguists who have been working on it.

We are looking for a Data Engineer who will identify and implement the best data-driven methodologies considering the product requirements.

Work location: Goregaon (West), Mumbai

Key responsibilities:

Create, build and design data management systems across an entire organization
Work with very large data sets (both structured and unstructured).
Help data scientist to easily retrieve the needed data for their evaluations and experiments.
Design, develop and implement R&D and pre-product prototype solutions
Must have strong engineering skills that will help engineering team to productivize NLP/ML algorithms
Implement scalable, maintainable, well documented and high-quality solutions.
Stay abreast of the new developments in Artificial Intelligence (AI)/Machine Learning (ML). Contribute to the research strategy and technical culture of the team


Skills Required:

BTech/MTech/ME/MCA from reputed Engineering college.
0-2 years of industry experience
Extremely curious and relentless at figuring out solutions to problems
Knowledge of Big Data platforms like Hadoop and its eco-system
Proficiency in programming languages like Java/C/C++/Python
Experience with cloud services
Exposure to NLP and its related services.
Experience with one or more visualization tools like Tableau, etc.
Experience with Docker, Kubernetes, Kafka, Elasticsearch, Lucene
Experience with relational or NoSQL databases such as MySQL, MongoDB, Redis, Neo4j.
Experience of handling various data types and structures: structured and unstructured data, validating and cleaning data, and measuring evaluation
Excellent understanding of machine learning techniques.",3.2,"Crimson Interactive
3.2",Mumbai,"Mumbai, India",201 to 500 employees,2005,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
338,Data Scientists,"Our Data Scientists are quantitative analysts who can extract meaningful insights from customer data, and leverage predictive models to optimize business performance. They support Risk management, Marketing, Capital Markets, Operations and Finance teams. This is a strategic role that sits at the heart of value creation by turning data into a long term competitive advantage.

As a Senior Data Scientist you will...
Drive the evolution of best in class Channel Analytics by:
Working with Tech & Data teams to define requirements and review solution builds
Applying insights from customer response data to build response and targeting models
Building Attribution Models and optimising offline and online Marketing Mix to drive growth
Developing and applying real time links between spend across channels and response patterns
Working with Tech and Operational teams to ensure identified wins are deliveredManaging and mentoring direct and indirect reports to deliver significant increases in productivity
Deliver cutting edge models using the latest techniques and upskill the team: Use advanced statistical analysis to design testing and predictive models whilst creating and improving on best practices to be used across the Funding Circle analytics community
Drive thought leadership across the business: Recommend optimal business strategies based on historical performance, predictive analytics and scenario analysis
Build global frameworks that are scalable across markets and help to drive business outcomes & portfolio performance
Work closely with partner teams across business and risk to ensure analytical outputs meet stakeholder expectations
Communicate effectively analytical outcomes to wide variety of internal and external constituents including senior stakeholders
Up to 20% travel
You’ve been there and done this:
Demonstrable strong Machine learning/AI experience along with proficiency in analytical tools like R and Python, Excel VBA, Tableau, SQL
Demonstrates strong knowledge of data architecture, modelling techniques, consumer behaviour patterns and the key drivers of marketing or credit performance optimization
Has exceptional analytical skills with an advanced degree in a quantitative field like mathematics, physics, computer science, statistics, economics, econometrics etc
Have strong experience in a channel or product analytics role in a major digital or financial services organization with demonstrated track record of data science delivery in channel analytics, marketing analytics and/or risk analytics
Possesses strong interpersonal skills and the ability to communicate effectively to technical and non-technical audiences
Identifies with our mission, “to build a better financial world”
For Data Scientist
Python-Anaconda (Framework)
Gradient boosting and random forest (Algorithms)
Data and Statistical modelling
AWS SageMaker (Machine learning)
What You Need for this Position

You should have knowledge of:
Python-Anaconda (Framework)
Gradient boosting and random forest (Algorithms)
Data and Statistical modelling
AWS SageMaker (Machine learning)
Aditional
No. of Positions
Education level
Career level
Experienced",4.8,"Bloom Consulting Services
4.8",Bengaluru,"Nagpur, India",1 to 50 employees,2015,Company - Private,IT Services,Information Technology,₹10 to ₹50 million (INR),-1
339,Analytical consultant/Data Scientist,"Analytics/Data Scientist


We at o9 Solutions...

We help enterprises to digitally transform their supply chain with a cloud-based platform that connects the supply chain end-to-end. We do this with the latest available technologies like AI/ML and NLP. Headquartered in Dallas, we have offices in Europe, Japan, Korea and one here, in Bangalore. In the past 18 months, we expanded our value-adding activities to amongst others Google, Nike, Walmart and Starbucks. The US/EMEA/India team is expanding rapidly and we look forward to having you on board and support our growing organization!


What you really do:

Design and operationalize various kinds of descriptive, predictive and prescriptive analytics relevant in the planning space.
While the analysis can happen in R, excel, SQL or o9’s tool, ensure the results are presented in a usable fashion for consumption in the o9 platform.


You will:

Ability to work with and as a true team
Ability to analyse problems by synthesizing complex information, evaluating alternate methods and articulating the result with the relevant assumptions/reasons
Knowledge of statistical and machine learning algorithms
Experience in using R and/or Python
Experience in implementing planning applications will be a plus
Knowledge of SQL, experience with ETL tools like Informatica/SSIS will be a plus
Having an educational background in Operations Research/Management will be a plus.

What is required by the position?

Experience of applied analytics in the field of Supply chain, like building Demand forecasting models, applied ML methods in improving Supply/Inventory planning etc.
Expertise at the juncture of planning and analytics for very diverse problems like recommending optimal assortments/pricing/inventory levels/forecasts, demand supply balancing etc.
SW tools: o9’s planning platform, R, SSIS, SQL, Excel.


What you get:

Flexible working schedule
Possibility to travel and work with clients
Exposure to the biggest brands in the world
A flat organization with a very strong entrepreneurial culture
A great team to support you and that you can support
Great people and unlimited fun at work
Possibility to really make a difference in a scale-up environment

Beer Fridays",3.2,"o9 Solutions, Inc.
3.2",Bengaluru,"Dallas, TX",201 to 500 employees,2009,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹1 to ₹5 billion (INR),-1
340,Lead Software Engineer - Data Scientist,"About Freshworks:-

Freshworks provides innovative customer engagement software for businesses of all sizes, making it easy for teams to acquire, close, and keep their customers for life. Freshworks Software-as-a-Service (SaaS) products provide a 360-degree view of the customer, are ready to go, easy to use, and offer a quick return on investment. Headquartered in San Mateo, USA, Freshworks 2,000+ team members work in offices throughout the world. Freshworks has global offices in India, Singapore, Australia, UK, Netherlands, France, and Germany. The company counts over 220,000 businesses in its customer-for-life community around the world including Honda, Bridgestone, Hugo Boss, University of Pennsylvania, Toshiba, Sling TV, and Cisco.

Freshworks’ suite of products that transform the way world-class organizations collaborate with customers and co-workers include Freshdesk (Omni-channel customer support), Freshservice (IT Service Desk), Freshsales (Intuitive fully-integrated CRM), Freshmarketer (Marketing Automation Suite), Freshteam (HR Management System for growing teams), Freshchat (Modern messaging software) and Freshcaller (Cloud PBX system).

Freshworks has received numerous accolades from analysts and media including making it to Forbes’ Cloud 100 list, Economic Times Startup of the Year, 2019 LinkedIn Top 25 Companies to work for in India and a listing on the Magic Quadrant for CRM Customer Engagement & IT Service Management. While Freshworks has had incredible organic growth over the last few years, the company also has made targeted acquisitions that add critical capabilities to the portfolio including Natural Language Processing, Chatbots, Machine Learning, Social and Messaging Transformation. Freshworks has raised over $250 million in the capital and is funded by Accel, CapitalG, Sequoia Capital and Tiger Global Management. More information is available at www.Freshworks.com.

Overview:

As a Lead Data Scientist at Freshworks, you will help identify the right business problems that will be more effectively solved with Machine Learning techniques. Then you will apply your algorithmic and statistical skills, knowledge of ML techniques, grasp of fundamental math, and familiarity with big data to solve the problem in the simplest possible way. You will also lead and mentor junior Data Scientists and engineers in ML projects.

Responsibilities:
Collaborate with product and business teams to understand all aspects of the problem
Define the right target metrics that best represent the end-user value
Apply knowledge of ML, statistics, and advanced mathematics to conceptualize, experiment and design an intelligent system
Work with engineers to build the system end-to-end including Big Data pipelines and ensure the serving system is scalable and highly performant.
Qualifications:
A Bachelor’s degree or a higher degree in Computer Science, Statistics, Mathematics or a related field.
Strong problem-solving and programming skills with a deep understanding of data structures and algorithms.
Solid understanding of mathematical underpinnings behind Machine Learning algorithms and proficiency in probability, statistics, linear algebra, calculus, and optimization.
Must have 2+ years of experience in ML with a proven record of successful ML projects with strong individual contribution
Experience with NLP, Distributed Systems, large scale computing, Big Data technologies like Hadoop and Spark are plus.
Submit Your Application

You have successfully applied

You have errors in applying

Apply With Resume


First Name


Middle Name

Last Name


Email


Mobile

Phone

Social Network and Web Links

Provide us with links to see some of your work (Git/ Dribble/ Behance/ Pinterest/ Blog/ Medium)

+

Cover Letter

Attach a file",4.3,"Freshworks
4.3",Chennai,"San Mateo, CA",1001 to 5000 employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Salesforce, Zendesk, ServiceNow"
341,Science Data Analyst ( Curriculum),"Who are Kïdo Education?

Kïdo are a network of innovative international nurseries.

We take elements from Montessori, Reggio Emilia and Waldorf Steiner, and combine them

with beautiful learning spaces and 21st century technology. Our customised experiences are

the most effective way for children to develop their cognitive, social, physical and creative

abilities.

Our vision is to create a truly modern Early Years environment that meets the needs of both

children and their parents.

We now have 24 schools across 4 countries (Hong Kong, Dubai, India and the UK) and

almost 400 employees which is a growing number! We are launching in the USA in 2020,

starting in Texas.

Roles and Responsibilities

Collect data regarding the learning process of children in different countries and analyse

the data.

● Prepare graphs and spreadsheets to portray results of the Curriculum Implementation

across different countries and levels (Learning results of the children, progression,

activities evaluation)

● Collect quantity and quality data for Curriculum result analysis from the Junior

Curriculum Developer.

● Create presentation slides and posters to help CAO present findings.

● Working closely with CAO to identify and drive through improvements to our

Curriculum.

● Unpack the Curriculum into its component parts (e.g. learning,

● teaching, knowledge, society, resources); evaluates how the parts fit together, say in

terms of focus and coherence; checks underlying beliefs and assumptions; And seeks

justification for curriculum choices and assumptions based on data.

● Analyse the activities across different countries to make an assessment of the curriculum

in order to improve it.

● Identify potential and actual problems as early as possible based on the analisis.

● Analyse and collect data to determine whether the goals have been met.

● identify strengths and successes in order to build on them; to examine whether

assumptions underlying the curriculum are valid and defensible.

● Create an assessments framework alongside with CAO based on the data collected.

● Collect Feedback from different Countries related to Curriculum quality.

● Develop research protocols for Kido based on the data collected.

Requirements

Great communication skills, excellent written and spoken English

● Well organised and able to work independently

● Ability to think outside of the box and be flexible regarding the design and development.

● High level of mathematical ability

● Programming languages, such as SQL, Oracle and Python.

● The ability to analyse, model and interpret data.

● Problem-solving skills.

● A methodical and logical approach.

● The ability to plan work and meet deadlines.

● Accuracy and attention to detail.

● Interpersonal skills.

● Team Working skills.

Qualifications

● Quantitative ability to draw data-driven insights using various tools including excel.

● Proven analysis experience.

● Science - Data Analyst Background.

Benefits
Competitive Salary
Working for a growing organisation",5.0,"Kïdo
5.0",Khar,"London, United Kingdom",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
342,Sr Data Scientist - Fraud,"Neustar, Inc. is a leading global information services provider driving the connected world forward with trusted, holistic identity resolution. More information is available at https://www.home.neustar.

Job Requisition:

R-1663 Sr Data Scientist - Fraud (Open)

Primary Location:

BANGALORE

Job Description:

Neustar, Inc. (NYSE: NSR) is a trusted, neutral provider of real-time information and analytics to the communications services, financial services, retail, educational, and media and advertising sectors. Neustar applies its advanced, secure technologies to help its clients promote and protect their businesses. More information is available at www.neustar.biz.

The Data and Analytics organization at Neustar is the DNA of the company. The DNA encodes the essence of existence and character that drives continuous innovation with data, continuous insights with analytics and continuous evolution with cutting-edge data products and services. Our vision is to be the trailblazer in Connection Science driven information services that create meaningful value for our customers. Our mission is to enable cutting-edge data products & services delivered through superior data, unique insights and top-of-the-class technology solutions. We believe in developing a Collaborative, Creative, yet Competitive, Customer Centric culture. We are shaping the present and the future at Neustar and are seeking “TENXERS” who share the same DNA.

Job Description:

The Sr. Data Scientist will lead a group of Data Scientists that works on challenging problems extracting actionable information out of the many data sources available to Neustar. They will focus on Security and Fraud, and their group will be involved in projects from end-to-end, including data ingestion and curation, hypothesis development, feature engineering, and model development and evaluation. The team will be integral to the development of an automated real time anomaly and fraud detection systems.

Apart from Security and Fraud, other application areas include Identity Resolution and other Business Solutions supported by our or our client’s data. The Sr. Data Scientist is expected to be working hands-on herself/himself while guiding the work of and mentoring junior team members.

Data Scientists create prototypes of new algorithms and support Engineering teams in productizing these capabilities. Data Scientists work closely with various teams including data acquisition, data products, data sciences and various business units including marketing, security, and internet of things to ensure implementation of capabilities that enable the organization’s vision. The role is based out of India at the Neustar's offices in either Bangalore or Hyderabad.

Responsibilities:
Group Leadership: Mentoring and supporting the career and capability growth of her/his team members. Setting and monitoring project schedules, communicating progress to the larger team. Provide technical leadership and foster a climate of open creative collaboration with his/her team and with other colleagues.
Algorithm Development: Develop a deep understanding of all the data relevant to the problem to be addressed. Establish deterministic and probabilistic linkages between data sources and develop ways to extract and summarize the sought information in the data using a wide variety of statistical, data mining and machine learning techniques.
Prototyping: Create prototypes of productizable ways to perform the analysis at scale, provide documentation and help educate your colleagues in different function about the solution
Support Implementation: Closely work with product, engineering and client teams to incorporate Data Science capabilities into Neustar’s products and services
Skills and Experience:
Masters’s degree in Data Science, Statistics or a related field
At least three years of experience working on data-intensive analytics solutions
Evidence of technical and team leadership in a previous position
Solid understanding of fundamental data mining and statistics concepts and familiarity with real-world applications of these techniques
Solid knowledge of SQL in its various forms for traditional databases and distributed computing environments
Experience working with commercial and/or open source statistics and data mining packages
Experience working on large distributed datasets using HiveSQL, Spark, Python
Strong written and oral communication skills
Strong inter-personal collaboration skills. Being able to both work in groups or as an individual contributor
General curiosity, a willingness to experiment, pragmatism and the ability to handle ambiguity
Why work with us?
Because you love to build beautiful, innovative solutions that wow the customer
Because you believe in changing the status quo and are up for the challenge of your life
Because you know you can make a difference to people, places and things!
About Us

Every day, the world generates roughly 2.5 quadrillion bits of data. Neustar isolates certain elements and analyzes, simplifies and edits them to make precise and valuable decisions that drive results. As one of the few companies capable of knowing with certainty who is on the other end of every interaction, we’re trusted by the world’s great brands to make critical decisions some 20 billion times a day.

Neustar does not accept unsolicited resumes from external firms or agencies. Neustar will not be responsible for placement fees associated with unsolicited resumes.

DIVERSITY
Diversity, inclusion and teamwork are second nature to Neustar; and these values permeate our entire business structure. Neustar is committed to creating an environment where a wide spectrum of opinions and beliefs are actively sought, listened to and respected. Further, our talented workforce draws from the many geographic areas and markets in which Neustar operates worldwide, which represents a distinct competitive advantage. The rich and varied personal and professional backgrounds of our employees make Neustar a dynamic and rewarding company at which to build a career. We invite you to join us.

EOE of Minorities/Females/Vets/Disability
Neustar, Inc. considers all applicants for employment without regard to race, color, religion, sex, national origin, age, disability, sexual orientation, or status as a Vietnam-era or special disabled veteran in accordance with federal law and other state and local requirements. Neustar, Inc., complies with applicable state and local laws prohibiting discrimination in employment and provides reasonable accommodation to qualified individuals with disabilities in accordance with the American with Disabilities Act (ADA) and applicable state and local laws.",3.7,"Neustar
3.7",Bengaluru,"Sterling, VA",1001 to 5000 employees,1996,Company - Private,Internet,Information Technology,₹50 to ₹100 billion (INR),"Adobe, Akamai, Oracle"
343,Senior Producer-Analytics and Data Science,"Senior Producer – Senior Project Manager, Analytics and Data Science


Zynga is looking for a highly motivated PROJECT MANAGER to help evolve our execution processes and take on project management for our analytics and data science team. He or she will work closely with analytics leadership, product management, engineering leadership, other project managers and game teams to balance a set of commitments and milestones to predictable execution, facilitating tough trade offs along the way. Tactical enough dive deep on daily execution, proactively spot areas for improvement, then energetically drive those improvements broadly, resulting in all peers feeling collaboratively led into changes that solve confusion, miscommunication and differing expectations.

Responsibilities:
Take on project management responsibility for machine learning, data science and analytics projects
Define scope, determine resources required, develop schedule and milestones in collaboration with engineering leadership and product management
Passionately articulate goals and team principles to help form a stimulating and fun work environment and culture
Ensure that the project deliverables are timely, within budget and at the required level of quality
Lead technical scrums and agile project implementation, evolve the project management methodology to align with work-product of analytics teams
Monitor and report progress weekly, oversee risks and mitigations and aggressively work to remove blockers; deliver bi-weekly, monthly and quarterly summary of project delivery; extract analytics on execution, and deliver a data-driven evolution of execution and prioritization
Identify process pain points and collaborate with analytics leadership, engineering leaders, product managers and other project managers to motivate change that improves both quality and transparency to external groups
Initiate, develop, maintain and lead others toward positive working relationships with internal and external organizations critical to both current and future development process
Collaborate with other project managers in the central data organization to deliver and evolve a consistent project management methodology
Required skills:

5+ years experience working in multi-functional development teams.
At least 3 years experience as a Project Manager within the tech industry, games preferred
Experience working in an agile environment and implementing processes for agile development
Outstanding written and verbal communication skills
Ability to work in a team environment with maturity and leadership
Preferred skills:

3+ years experience as a technical project manager
Experience working in the advertising and/or mobile gaming sectors
Familiarity with analytics, data science, machine learning and AI
Computer science, statistics or technical degree
Scrum Master or Agile Coach certification
WHAT WE OFFER YOU:

Work in a studio that has complete P&L ownership of games
Competitive salary, discretionary annual bonus scheme and Zynga RSUs
Full medical, accident as well as life insurance benefits
Catered breakfast, lunch and evening snacks
Child care facilities for women employees and discounted facilities for male employees
Well stocked pantry
Generous Paid Maternity/Paternity leave
Employee Assistance Programs
Active Employee Resource Groups – Women at Zynga
Frequent employee events
Additional leave options for most employees
Flexible working hours on many teams
Work with cool people and impact millions of daily players!",4.0,"Zynga
4.0",Bengaluru,"San Francisco, CA",1001 to 5000 employees,2007,Company - Public,Video Games,Media,₹50 to ₹100 billion (INR),-1
344,Data Analyst,"1. Part of Paytm wallet web/app/customer analytics team
2. Responsible to Analyze raw data, Manipulate, Cleanse and Process data using Hive/Sql/R/Python and throw insights on effectiveness of campaigns running on Paytm marketplace.
3. Responsible for performing data driven growth analytics for building topline and optimizing marketing spends
Key technical skills (not all are mandatory)
1. Expertise in Excel, SQL, R/Python
2. Experience with Big Data technologies preferably Hive, Spark
3. Familiarity with visualization tools like Tableau, Grafana
3. Familiarity with basic statistical techniques for prediction and optimization

Desired experience:
1. 1-3 years in analytics firm or analytics divisions of e-commerce firms
2. Ability to work under high pressure
3. Structured problem solving",3.4,"Paytm
3.4",Noida,"Noida, India",1001 to 5000 employees,2010,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
345,"Associate Analytics consultant, Analytics consultant, Senior Analytics consultant (DS)","If you are interested, please email your resume to us at recruitment@quantzig.com
Job Location: Bangalore

Experience: 1+ years

Key Skills: Data science, machine learning, SQL, python, RR / Python. Master-level skills in SQL and query languages Sound knowledge of the fundamentals of machine learning statistics

Roles & Responsibilities:
Individuals who are passionate to make an impact with high degree of work ownership and are self-driven.
You should be creative and passionately curious about exploring data to deliver impactful business insights
Experience in delivery and client facing roles from major analytics service providers in the industry are preferred
You should possess customer-centric thought process and is able to understand client’s business processes with ease, identify problems with precision and develop customized, accurate analytical solutions

Desired Profile:
Should have 4+ years of experience in executing analytics assignments across industries
Be a consultant to our clients. Think out-of-the-box and develop visualization solutions which help clients in solving their business problems
Tremendous passion towards learning is a must. You must be able to merge the art of consulting and the science of Design in visualization
Drive and energy to work hard and achieve success in an entrepreneurial environment
Should have hands-on experience in delivering projects across multiple industries and analytics areas (e.g. Supply chain analytics, Marketing Analytics, Customer Analytics, Digital Analytics, Pricing Analytics etc.)
Deep understanding of analytics/statistical models, tool kits and visualization tools. Should have working knowledge of a variety of classification and predictive models (Lasso regression, Ridge regression, decision trees, gradient descent models, etc
Strong communication, storyboarding and presentation skills
Understand the statistical mechanics behind modeling techniques
Understand efficient coding standards and has a knack to plan for QC checks before coding.
Added advantage if you understand Cloud hosting, customizing visualization tools using DAX, data integration with analytical data-streams",4.7,"Quantzig
4.7",Bengaluru,"London, United Kingdom",Unknown,-1,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
346,Decision Scientist - Malayalam Speaker,"Job Description

Are you passionate about Decision Science?

We are seeking a Decision Scientist to help us study and build the processes to develop services related to modern families. This includes the building the processes with expert analysis to help the end-users to make data-driven decisions to build a better human experience in the future.

As a Decision Scientist, you will be responsible for using the latest developments in statistics, methodologies to understand the customers’ in-depth, support and challenge strategic options, build state-of-the-art techniques and processes, and improve our future service developments.

Your Key Responsibilities

In your role, you will have a primary focus on decision science and decision modelling. Your focus will be on the application of analytics, operational research and modelling techniques across different families and problem types. You are resourceful, know how to solve problems. Your work will provide in-depth insights and inform the strategic decision-making of our customers on their key capital investment. This will allow you to develop and maintain positive, productive and professional advisory relationships with clients and stakeholders.

Here is what you’ll be doing:
Working cross-functionally with the Service team to analyze usage and uncovering key, actionable insights about customer behavior
Running statistical analysis and create predictive models based on past user data and behavior
Designing and measuring controlled experiments to determine the potential impact of new approaches
Being involved with product discussions about high impact features
Help with various data analysis and modeling projects
Data visualizations for use in both internal and external capacities
Understanding and reporting current trends and performances in detail and identifying opportunities for improving the human experience.
Developing algorithms for personalizing users experiences
Placing actionable data points and trends in context for leadership to understand actual performance and uncover opportunities.
Here is what we’re looking for:
Anyone with Social Intelligence.
Experience working on consumer-facing products
Potential data wrangling, statistics, and analytical skills
Ability to think creatively and provide thoughtful insights that drive action
0-3 years in data/decision science
Excellent communication skills, ability to understand customer needs and provide valuable recommendations
Able to effectively synthesize, visualize, and communicate your ideas to others
Familiar with key psychology concepts
Good model building skills combined with an ability to connect these with real world strategic alternatives, decisions and applications
Intellectual curiosity, strong problem solving abilities and a commercial mindset
Excellent analytical, communication and teamwork skills
Ability to develop, visualize, analyze, and communicate learning to leadership
Experience in data analysis.
Have an in-depth understanding of decision making best practices for complex systems.
Have a team-player mindset with strong interpersonal and influencing skills
Possess strong written and oral communication skills with a track record of high quality publications and public speaking engagements – effective in a large audience or small group setting.
Have excellent problem solving skills even when problems are messy and unstructured.
Have the proven capability to resolve ambiguity, spark creativity, and manage complexity
Ability to own larger projects end-to-end
Practical experience in analyzing millennials and families.
Ability to work collaboratively throughout the organization to drive towards common goals
Any Degree or Diploma in Psychology may be preferred.
You’ll need to thrive in picking up new skills and talents as you go, so natural curiosity, a lot of questions and the confidence to speak up when you see something that could be improved are essential.
In these positions you will be asked to manipulate and utilize data in order to inform key business decisions and model various market conditions. These positions are ideal for someone with a passion for data science or decision science and are entrepreneurial in nature. These positions are an exciting way for someone to break into data science or decision science and start building a career at organizations ranging from established tech companies to growing

This posting is just an outline of the basic responsibilities and requirements for the position, there is more to being a member of the team, so just keep in mind that this is not a comprehensive list of everything the job will entail. Your duties, responsibilities and activities may change as per business/market requirements.

Please refrain from applying if your profile is not exact match for this role.

Whilst we will endeavor to contact you following your application, due to the high volume of applications if you have not had notification from us within 24 hours please take your application as not being successful this time, we will keep your details in the database for future opportunities.

NB: Please note that, not getting shortlisted for a role is no reflection on your skills or qualifications; it simply means that the hiring manager is giving more priority to many other specific factors other than expertise or experience which are relevant to this position based on their current business/market requirements/customer demographics.*

We give interview status but not feedback for following reasons:
We do not give interview feedback for Idiosyncratic Rater Effect and it’s not feasible to fix such systematic errors behind it.
Feedback is interviewer’s truth, not candidate’s.
It’s a time consuming procedure to structure a legally apt constructive feedback and to deliver it.
Accepting critical feedback is a rare skill.
* Please note that candidates are NOT selected merely based on expertise or experience. We urge majority of the Hiring Managers who work with us to use Talent Analytics that check various factors based on their previous hires, including Nature of the job, Suitability to team/company culture, Possible duration a candidate sticks with the company, Nature of client-pool, Work locations/timings, Market Knowledge and many other factors that add value to business/customers. The hiring decisions are taken to run the business at low-risk in steady, optimized, efficient manner.

Job Type: Full-time

Education:
Bachelor's (Preferred)",4.2,"MAC Group - India
4.2",Kochi,"Panaji, India",51 to 200 employees,-1,Company - Private,Hotel & Resorts,Travel & Tourism,Unknown / Non-Applicable,-1
347,Data Engineer,"Driving Infinite Possibilities Within A Diversified, Global Organization


The future is what you make it.

When you join Honeywell, you become a member of our global team of thinkers, innovators, dreamers and doers who make the things that make the future. That means changing the way we fly, fueling jets in an eco-friendly way, keeping buildings smart and safe and even making it possible to breathe on Mars.
Working at Honeywell isnt just about developing cool things. Thats why all our employees enjoy access to dynamic career opportunities across different fields and industries.

Are you ready to help us make the future?

Join a company that is transforming from a traditional industrial company to a contemporary digital industrial business, harnessing the power of cloud, big data, analytics, Internet of Things, and design thinking.

You will lead change that brings value to our customers, partners, and shareholders through the creation of innovative software and data-driven products and services. You will work with customers to identify their high value business questions and work through their data to search for answers. You will be responsible for working within Honeywell to identify opportunities for new growth and efficiency based on data analysis.

JOB ACTIVITIES

As a Data Engineer, you will be part of a team that delivers contemporary analytics solutions for the Data Management & Analytics function at Honeywell. You will build strong relationships with leadership to effectively deliver contemporary data analytics solutions and contribute directly to business success. You will develop solutions on various Database systems viz. Hive, Hadoop, SnowFlake, etc.

You will identify and implement process improvements and if you dont like to do the same thing twice, you will automate where possible. You are always keeping an eye on scalability, optimization, and process. You have worked with Big Data before, IoT data, SQL, Azure, AWS, SnowFlake

You will work on a team including scrum masters, product owners, data architects, data engineers, data scientists and DevOps. You and your team collaborate to build products from the idea phase through launch and beyond. The software you write makes it to production in sprints. Your team will be working on creating a new platform using your experience of APIs, microservices, and platform developmentYOU MUST HAVE
Bachelor's degree in Computer Science, Engineering, Applied Mathematics
4 years of data engineering experience
2 years in supply chain, materials planning, logistics/distribution, procurement, finance and/or order management.
WE VALUE
Should have developed and deployed complex big data ingestion jobs in Talend/Informatica BDM bringing prototypes to production on Hadoop/NoSQL/MPP platforms.
Should have minimum 4 years of hands on experience with MapReduce, Pig/Hive, Spark, etc. and automation of data flow using NiFi and Airflow/Oozie.
Minimum 3 years of experience in developing and building applications to process very large amounts of data (structured and unstructured), including streaming real-time data (Spark, R/Python, Scala, Kafka, Spark streaming or other such tools).
Minimum 2 years of experience in working with at least one NoSQL system (HBase, Cassandra, MongoDB etc.). In-depth knowledge of schema design to effectively tackle the requirement.
Experience in writing complex SQL statements
Additional Information
JOB ID: req233792
Category: Information Technology
Location: Devarabisanahalli Village, KR Varturhobli,,East Taluk - Phase I,Bangalore,KARNATAKA,560103,India
Exempt
Business Services",3.8,"Honeywell
3.8",Bengaluru,"Charlotte, NC",10000+ employees,1885,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"GE, Johnson Controls, United Technologies"
348,AI Scientist 2,"IQVIA™ is the leading human data science company focused on helping healthcare clients find unparalleled insights and better solutions for patients. Formed through the merger of IMS Health and Quintiles, IQVIA offers a broad range of solutions that harness the power of healthcare data, domain expertise, transformative technology, and advanced analytics to drive healthcare forward.

AI Scientist II Role

PURPOSE

The AI Scientist II will be part of a new stealth group building the next generation of smart machine cloud-based solutions. This provides an opportunity to get in on the ground floor level of something new and exciting for an industry working with the latest and greatest technologies.

RESPONSIBILITIES
• Participate in cutting edge research using tools such as Machine Learning, Natural Language Processing, Robotic Process Automation and Blockchain amongst other capabilities.
• Help develop software and algorithms and build new cognitive computing platforms for areas such as sensors and tracking systems, deep learning algorithms and models, workflow and automation through to new areas such as virtual assistants and AI in IoT to enhance our Artificial Intelligence functionality.
• Define and drive the analytical scope and method for projects, including formulating and shaping the capabilities through a full software development life cycle.
• Help the research and development of a local AI team, deliver practical AI components to be used within clinical processes.
• Work on world-class cutting-edge technologies in related fields, including but not limited to the following: deep learning, large-scale machine learning and machine learning platforms, Natural Language processing and Semantic Ontology, Robotic Process Automation and Blockchain.
REQUIRED KNOWLEDGE, SKILLS, AND ABILITIES
• Experience in some of the following areas:
o Optical Character Recognition – utilizing character recognition tools to convert images, PDFs and other document types into digitally recognized structure with meta-tagging;
o Machine Learning - deep learning, online learning, transfer learning, reinforcement learning, structured/unstructured learning;
o Natural language processing - NLTK/OpenNLP, StanfordNLP, Translation, Semantic Ontology, Natural Language understanding/generation;
o Robotic Process Automation – virtual worker process builds, script generation utilizing AI tool sets;
o Blockchain – smart contracts, supply chain programming, encryption programming.
• Strong research and innovation skills and ability to solve difficult machine vision and learning problems and transferring business problems into AI use cases and requirements.
• Excellent prototyping skills in open-source with some examples of practical application.
• Excellent programming skills in languages such as Java, C#/C++, Spark, Flink, Tensorflow and Python.
• Hands-on experience with large-scale real-time machine learning/AI and with full software development life cycle.
• Excellent communication and teamwork skills.
• Flexibility and adaptability to work in a growing dynamic team in a highly visible role.
• Preferred pharmaceutical experience in research projects and teams.

MINIMUM REQUIRED EDUCATION AND EXPERIENCE

Master’s degree in Computer Science, Applied Statistics, Engineering, Mathematics, Physics or other qualitative discipline with specialization and experience in Artificial Intelligence, Machine Learning, Natural Language Processing, Cognitive Science, Deep Learning or other related fields.

A minimum of three years of professional post-academic work experience with a Master’s or additional years of experience at BSc level will be considered. Strong mathematical/computing science background with strong knowledge in at least one of the following fields: Cognitive Science, Advanced Semantic Design, Information Extraction, Information retrieval, Probabilistic Decision Marking, or similar.

DESIRED ADDITIONAL SKILLS AND ABILITIES
• Someone who is passionate about AI and can show examples of their skills utilizing open-source capabilities that they can show as part of that passion;
• The freedom to use your talent and background to help us make noise in the industry quickly.

EEO Minorities/Females/Protected Veterans/Disabled

Join Us

Making a positive impact on human health takes insight, curiosity, and intellectual courage. It takes brave minds, pushing the boundaries to transform healthcare. Regardless of your role, you will have the opportunity to play an important part in helping our clients drive healthcare forward and ultimately improve outcomes for patients.

Forge a career with greater purpose, make an impact, and never stop learning.

Apply Now!",3.6,"IQVIA
3.6",Bengaluru,"Durham, NC",10000+ employees,2017,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹100 to ₹500 billion (INR),"PPD, INC Research, PRA Health Sciences"
349,AI Scientist 2,"Department Overview The role exists in the reporting and analytics function of the EGS strategy team. The strategy team is involved in building frameworks for smooth execution of EGS strategy, provide MIS & Analytics capability for functional data and be the insight provider in achieving the functional goals. The team is involved in building the yearly roadmap, defining performance measurement framework and monitor & measure performance in consultation with the EGS functions. The scope of this departments work will be to align the reports and dashboards with the transactional, tactical and strategic data elements of the associated functions. About the Role The Analytics Consultant role will be responsible for delivering analytic, reporting and insight artifacts. This artifacts includes dashboards, Adhoc data analysis and deep dives, development of quantitative models and performance summaries. The scope of this reports and dashboards are transactional, tactical and strategic data elements of the associated functions. The reporting will involve audience who are functional and at leadership level and the role will also involve customizing the reporting artifacts based on the audience. Responsibilities: Performing data analysis of functional and operating data and identifies trends, patterns and issues Developing solutions to reporting and data needs through various means including dashboards, Adhoc dep dives and quantitative models Build apt reports and visualization to present complex KPIs and number for meaningful interpretations Independently performs ad hoc data analysis and is able to turn the analysis into meaningful, actionable information Excellent ability to summarize key data for management. Ensures adherence to compliance and risk management activities related work efforts Essential Skills: Bachelors / Masters Degree, any field 5+yrs of professional experience in working in a shared service or back office operation of any US/UK based company 4+yrs in working data analytics and reporting teams involving dashboards creation, visualization development & data management Expert knowledge of data visualization skills in either of Tableau, Quick view & PowerBI with 3+yrs hand on experience in building and maintaining visualization in the above tools Expert in Advanced excel with ability to write/edit/debug Macros Hands on experience in SQL & should be able to write complex queries for data management using SQL Strong interpersonal and influencing skills, with the ability to establish credibility and strong partnership with business partners and other support functions Must be a great team player with a high degree of flexibility, prepared to work in a deadline-driven and fast-paced environment Desired Skills: Post graduate or an advanced degree (or equivalent experience) preferred in either of Quantitative or management discipline preferred Knowledge of statistics and quantitative modelling will be an added advantage Knowledge of R or Python will be a big plus Experience in story boarding and understanding of design thinking will be an added advantage 49558",3.6,"IQVIA
3.6",Bengaluru,"San Francisco, CA",10000+ employees,1852,Company - Public,Banks & Building Societies,Finance,₹500+ billion (INR),-1
350,R&D Software Engineer (Data Science),"Job Code : DQ319-01
Posted on : September 1, 2019
Job Location : Bangalore
Industry : Healthcare/Lifesciences
Discipline : Product Development

Description:
We are looking for a talented software engineer who can join our R&D team and work on problems of diverse complexity and scope within the Healthcare and Life Sciences industries.

Responsibilities:
Mine data using modern tools and programming languages
Define and implement models to uncover patterns and predictions creating business value and innovation
Effectively tells stories with the data using visualisation tools/methods to demonstrate insight impact and business value
Implement data-driven solutions based on advanced machine learning (ML) and optimisation algorithms to address business problems
Partner with engineering teams to build scalable, efficient, automated ML-based pipelines (training/evaluation/monitoring)
Deploy, maintain, and debug ML/decision models in production environment
Maintains proficiency within the data science domain by keeping up with technology and trend shifts.

Requirements:
Bachelor’s or Master’s degree in Computer Science, Statistics or similar quantitative field.
1-3 years of experience
Fluent coding skills in Python
Good understanding of the foundations of machine learning methods
Familiarity with data visualisation tools
Strong analytical and problem-solving skills
Ability to create models to pull valuable insights from data
Familiarity with machine learning frameworks (like Tensorflow or PyTorch) and libraries (like scikit-learn)

To apply for the above position, please send your word resumes to careers@vitrana.com by specifying the Job Code.",4.9,"Vitrana
4.9",Bengaluru,"Cranbury, NJ",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
351,DATA ANALYST,"The Data Analyst is part of the consulting and data science team of the organization and will be responsible for project delivery on data science and data analysis projects and solutions specific to the manufacturing industry. The Data Analyst will be expected to be skilled in the retrieval, preparation and analysis of data of various kinds. The Data Team offers high-impact work with diverse opportunities for data analysts to grow skills in the areas of data science, advanced analytics and related areas.
Hands on programming skills in one interpreted programming language and one compiled programming language are required for this role.

Key Skills and Experience

Good working knowledge of interpreted object-oriented programming in languages such as Python or R is required
Working knowledge of one compiled programming language, such as Java or C++ is desired
Good working knowledge of SQL data transformations is required. Exposure to data visualization, data summarization, aggregations, filters and other data transformations is desired
A working level understanding of machine learning techniques is required. Those with strong fundamentals in the underlying mathematics - linear algebra, optimization or statistics of machine learning will be considered favorably.
Knowledge of statistical data analysis or signal processing as applied to continual improvement, engineering system design, evaluation and testing are good to have
Exposure to topics such as large scale data management, cloud based compute and storage technologies are good to have
Good interpersonal, presentation and written communication skills .

Education and Work Experience Requirements

Bachelor’s degree in electrical/electronics, mechanical, industrial or computer science/engineering
Prior work experience or internships in industries such as engineering, power, construction, manufacturing or oil and gas will be considered favorably
Master’s degree in any engineering field is considered a plus
Freshers and those with less than 2 years of experience in the industry
Relevant certifications in data science, statistics, machine learning and deep learning are good to have.",4.2,"The Data Team
4.2",Bengaluru,"Singapore, Singapore",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
352,Data Engineer,"Designation : Data Engineer
Qualification : B.E/B.Tech/M.Tech/MCA
Experience : 2-6Yrs
Salary : 6-15 LPA
Industry : IT System & Technology
Location :Mumbai
Skills Require : Paython, Elastic Search

Job Role & Responsibilities:
Candidate should have experience on Python. Additionally Java and Scala will do.
Worked on Big Data technologies (Hadoop, Kafka, Reddis, Mongo, Elastic Search, SolaR, HBase, Cassandra and Spark) and NoSql
Knowledge on Data Structure and Algorithms.
This can be tested asking them to mention their rank from any websites (Hackerrank, Hackerearth,Codechef etc) which run code based competitions
Experience of working in a startup will be additional advantage

Working Days : 5 Days a Week (11:00 AM to 8:30 PM)",-1,smart4talent,Mumbai,"Faridabad, India",1 to 50 employees,2009,Company - Private,Staffing & Outsourcing,Business Services,₹10 to ₹50 million (INR),-1
353,Senior Data Scientist- AI,"Description:
Background:
Lymbyc is the first and currently the only player, in the predictive engine-based self-service analytics product space for end business users. We have created the world’s first data scientist, Leni, capable of understanding plain English queries from user, and autonomously being able to take decisions ranging from data selection to algorithm selection and finally visualisation and narratives, without any human intervention. And now we are embarking on bringing explainable component to our AI based solutions, to make the business decisions simpler, easier and adaptable to larger stakeholders.

By way of our acquisition, we at Lymbyc now are working full tilt with LTI’s global reach to take Leni to the world’s major businesses.

Description:
We need ace data scientists who can develop best in class predictive models, machine learning models and deep learning models and at the same time they should be able to explain the decisions taken by the models automatically through plain simple English language. The explainable elements should not be limited to the numbers and formulas, there must be a bit of personalization also to understand the context of the problem.

Roles and Responsibilities:
Passion for learning new technologies and be up to date with the scientific research community.
Work in technical teams in development, deployment, and application of machine learning solutions, leveraging technical components and explaining the modelling decisions
Take responsibility for insights, reports and explanability of the decisions taken by predictive models
Responsible for taking an idea from concept to production thoroughly with feedback from all stakeholders.

Qualification:
Masters’ in Computer Science/M. tech/PhD/Statistics/Econometrics/Applied Mathematics/Applied Statistics/Operations Research is a must
Hands on Experience with data mining or machine learning, deep learning, computer vision, natural language processing
Hands on Experience in developing deep learning models and explaining the results of deep learning models in a business-friendly manner

Skills Required:
Must have minimum of 5-7 years of industry experience in developing data science models.
Deep understanding and experience in the field of Machine Learning, Deep Learning and statistical learning
The person should be excellent at Classification (logistic regression, svm, decision tree, random forest, neural network), Regression (linear regression, decision tree, random forest, neural network), Classical optimisation (gradient descent, newton rapshon, etc), Graph theory (network analytics), Heuristic optimisation (genetic algorithm, swarm theory)
Should be strong at Deep leaning (CNN, LSTM, RNN, Bi-LSTM)
Must have thorough mathematical knowledge of correlation/causation, decision trees, classification and regression models, recommenders, probability and stochastic processes, distributions, priors and posteriors.
Skilled at scientific programming languages such as Python, R, Matlab and writing deployable code into production.
Understand the model lifecycle of cleansing/standardizing raw data, feature creation/selection, writing complex transformation logic to generate independent and dependent variables, model selection, tuning, A/B testing and generating production ready code.
Knowledge of Numerical optimization, Linear/Non-linear/Integer programming, Statistics, Combinatorial optimization is a plus.
Familiarity with R, Apache Spark (Scala, Python), PyMC3/theano/tensorflow/Keras and other scientific python/R modules is a must.
AI skillsets – hands-on Machine learning and Deep Learning algorithms and platforms, neural networks in any, or all the following areas, specifically, in Data & Analytics use cases
Language – Natural Language Processing, machine translation, emotion detection, language detection, classification
Vision – computer vision, object recognition/tracking, face/gender/age/emotion recognition, OCR/handwriting recognition
Knowledge and experience in some of the key AI platforms will be important, e.g. IBM Watson, Microsoft Azure, Google Api.Ai, Facebook Wit.Ai, Chatbots using Microsoft Bot Framework
Knowledge and experience of key machine learning and deep learning framework, e.g. Keras, TensorFlow, Caffe, CNTK, Jiraffe, MXNet and PyTorch commercial technologies/platforms, etc",3.5,"Lymbyc Solutions
3.5",Bengaluru,"Bengaluru, India",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
354,Machine Learning Engineer,"This is not a project-based position. This is a full-time, long-term position with the opportunity to travel to the client’s office in Silicon Valley two times per year.

You will be responsible for implementing machine learning and predictive modeling techniques that will have a major impact on the company.

This is an excellent opportunity for smart machine learning engineers who want autonomy and the freedom to turn their big data ideas into reality.

What You’ll Be Doing

Implement machine learning and predictive modeling techniques (e.g. recommending content to users & ranking content to users based on multiple variables).

Tune SQL queries for Redshift/Hadoop.

Analyze data and performance of data products.

Implementing machine learning and predictive modeling techniques (e.g. recommending content to users & ranking content to users based on multiple variables).

Who You Are (Experience & Skills)

Commercial machine learning experience, not just academic or research experience.

Experienced in machine learning techniques.

Experience with a variety of Big Data tech, distributed machine learning and computing frameworks (S3, Spark, Hadoop, Elasticsearch, etc.)

Experienced in creating high-performance algorithms, prototypes and predictive models.

Experience with deploying solutions in AWS

Experience with Python data science ecosystem - Pandas, SciPy, scikit-learn, NLTK, Gensim, etc.Experience with full-stack development, building large distributed systems and large scale data pipelines

What We Offer

Competitive salary.

Challenging work on complex and very innovative projects.

Work in an international environment.

Generous benefits package with all kinds of great stuff.

Trainings accustomed to your needs.

Flexible working environment.

Cozy and friendly atmosphere.

How To Apply

To apply email your resume to sid.baker@whizzystack.com with the subject line “Machine Learning”.

When applying please provide a resume and any links to your technical blog, github/bitbucket and other reviewable code examples.",4.7,"Whizzystack
4.7",Noida,"Jersey City, NJ",1 to 50 employees,-1,Unknown,-1,-1,Unknown / Non-Applicable,-1
355,Data Scientist Intern,"Location: Bangalore, India.

Dasceq: Data – Science – Equilibrium
Transforming Collections with AI/ML and Big Data
In the digital age, businesses have access to more data than ever before, and this data can be leveraged to drive decision-making for improved growth and seamless consumer experience including collections. Since being founded in 2017, our team of data scientists and domain experts at Dasceq (Data – Science – Equilibrium) have created a AI platform to boost collections efficiency and amount collected. We are leading edge AI Startup converging Machine learning, AI with deep collection and servicing experience leveraging AI/ML and Big Data to create a unique platform for Collections. Our next generation product is enabling clients to improve consumer experience and ROI. Dasceq’s next-gen SaaS AI platform optimizes collections with data-driven insights.

We experiment and innovate leveraging the latest technologies to engineer breakthrough AI product, customer experiences, and bring simplicity and humanity to collections. At Dasceq Center for Artificial Intelligence and Innovation, you’ll be part of an elite team accelerating adoption of AI, ML and Big Data for Fortune enterprises in USA.

Do you have it in you to join Dasceq? We are a committed and passionate team of hard working individuals who are making a difference for our clients, our industry and our team members. We are looking for passionate individuals who are great performers and willing to be part of team passionate about building production-quality applications using cutting-edge machine learning algorithms? They must be Self Starter, Hard Workers, Great Team Spirit and a willing to become experts in their domain? If the answer is YES then APPLY

We are looking for a Data Scientist who will work in our AI/Data Science Innovation Team and will leverage data to gain insights by analyzing company data. The ideal candidate is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action.
They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations.
They must have a proven ability to drive business results with their data-based insights. They must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.
Responsibilities for Data Scientist:
Data mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
Develop company A/B testing framework and test model quality.
Coordinate with different functional teams to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Qualifications for Data Scientist
Has a bachelor’s degree in Computer Science, Economics, Statistics or another quantitative field, and is familiar with data science algorithms.
Strong problem-solving skills with an emphasis on product development.
Experience using statistical computer languages (R, Python, SQL, etc.) to manipulate data and draw insights from large data sets and experience working with and creating data architectures.
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
Excellent written and verbal communication skills for coordinating across teams.
A drive to learn and master new technologies and techniques.
We’re looking for someone of experience manipulating data sets and building statistical models, has a master’s or PHD in Statistics, Mathematics, Computer Science or another quantitative field, and is familiar with the following software/tools:
Coding knowledge and experience with several language C++, python, R, SQL.
Experience querying databases and using statistical computer languages: R, Python, SQL, etc.
Experience visualizing/presenting data for stakeholders using: BI tools.
Only those candidates can apply who for internship:
Have a great attitude, willing to learn and work hard and excel in career.
Are available for full time (in-office) internship at our Jaynagar Office in Bengaluru
can start the internship between 1st March19 and 15th Mar’19
are available for duration of 6 months
have relevant skills and interests
Other requirements:
Should have an ability to work in a team with good communication skills
Should have the ability to meet routine production deadlines
Should be well versed with computer concepts of the internet, networking, browser, website, apps, MS Office, etc.
Should have basic knowledge of Excel, Word, Presentation, Google Sheets, and Google Docs
Should have a strong attitude to learn and logical reasoning
Open to work long hours and weekend as needed (one to two weekend a month).
Perks:
Certificate
Letter of recommendation
Job offer (On successful conversion to a permanent employee, the candidate can expect a salary of Rs. 2 to 3 Lac/annum)
Daily Lunch and Snacks Provided
Bi-Weekly Team Events and Office Party.

Required for Interview:
Current and past jobs pay slip and appointment letter (pdf)
All diploma and certificate copies (pdf)
Three References
* Women willing to start/restart their career can also apply",2.0,"Dasceq
2.0",Bengaluru,"Irving, TX",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
356,Data Engineer (ETL),"We are looking for a Data Engineer who will work on the collecting, storing, processing, and analyzing of huge sets of data (ETL). The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.

Roles & Responsibilties
Design, develop and support data platform with large dataset for realtime and batch processing.
Implement ELT/ETL processes from a wide variety of data sources using best practices while working with other technology teams
Work with business and product teams to understand their data needs, gather requirements and delivering dataset
Work on automating/improving existing data sets, ETL/ELF pipelines
Identify the opportunities to improve data storage and query performance and implement them
Basic Qualifications

• Comprehensive knowledge of the Data Collection, Transformation, Storage and Query technologies' landscape.

• Hands on expert experience with at least a few of these systems.

• 2-4 years of strong hands-on development experience

• 1+ years experience of hands-on big data experience

• Should be able to write high quality code - preferably in Java/Python/Ruby

• Should have excellent written and verbal communication skills

• Data modelling, SQL and Databases knowledge

• Good understanding of HDFS, Hive, Spark, Kafka

Good to Have

• Exposure to Amazon Web Services

• Exposure of BI tools like Tableau/Qliksense/Superset

• Experience of building applications with streams and complex event processing

• Should be able to prioritize in fast-moving complex environment and produce solutions despite complex requirements",3.7,"Doubtnut
3.7",Gurgaon,"Gurgaon, India",51 to 200 employees,2016,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
357,Lead Data Scientist,"Position Description

This position is in the data science team under the Advertising Technology organization. The mission of the Advertising Technology organization is to advance Walmart eCommerce by driving higher value for our customers and vendor partners. Walmart is investing in building a world class advertising platform and the Ads team is responsible for defining and performance advertising products that drive discovery, sales and profits.

We are a highly motivated group of Big Data Geeks, Data Scientists and Applications Engineers, working in small agile group to solve sophisticated and high impact problems. We are building smart data systems that ingest, model and analyse massive flow of data from online and offline user activity. We use cutting edge machine learning, data mining and optimization algorithms on ad relevance, ranking and campaign optimization.

The senior data scientist of ad targeting will be leading a team of data scientists and machine learning engineers to build the next generation ad targeting and scoring solution. Join us if you want to be spending your time on:

• Working with product and other business stakeholders to define our roadmap to drive advertiser value and enhance customer experience;

• Leading a team of data scientists and machine learning engineers to develop, implement, and test scalable solutions for improving ad targeting; interacting with other teams to define interfaces and resolving dependencies;

• Researching and implementing methodologies to measure the impact of the technologies;

• Initiating and proposing unique and promising modelling projects, developing new and innovative algorithms and technologies, pursuing patents where appropriate;

• Staying current on published data mining, machine learning and modelling techniques and competing technologies and sharing these findings with scientists and engineers in the organization;

• Maintaining world-class academic credentials through publications, presentations, external collaborations and service to the research community.

Minimum Qualifications

Bachelors or equivalent degree in a computational science with 10+ years OR Masters or equivalent degree in a computational science with 6+ years of experience in Machine Learning/Statistics/Data Science;

Experience with traditional as well as modern machine learning/statistical techniques, including Regression, Classification, Ensemble Methods, Deep Learning and Reinforcement Learning;

Strong implementation experience with high-level languages, such as Python, R, Scala or similar scripting language, and familiarity with Linux/Unix/Shell environments;

Strong hands-on skills in sourcing, cleaning, manipulating and analysing large volumes of data using distributed computing platform;

2+ years of experience mentoring junior data scientists;

Strong written and oral communication skills.

Preferred Qualifications

Ph.D. in a computational science with an emphasis in Machine Learning;

Experience in online advertising, recommender system, ecommerce or relevant areas;

Experience with end-to-end modelling projects emerging from research efforts;

Excellent academic or industrial track record of proposing, conducting and reporting results of original research, plus collaborative research with publications;

2+ years of experience managing a data science/modelling team.",3.3,"Walmart
3.3",Bengaluru,"Bentonville, AR",1001 to 5000 employees,1962,Company - Public,"Department, Clothing, & Shoe Shops",Retail,₹500+ billion (INR),"Target, Costco Wholesale, Amazon"
358,DATA SCIENTIST,"About You:
You are a passionate Data Scientist who wants to drive business results with your data-based insights. You have a strong data science background and understands the use of a variety of data mining and data analysis methods to build and implement models, algorithms, and simulations. From day one, you must be able to hit the ground running and bring all your experience to the team to ensure our business stays ahead of the industry. Most importantly, you have a positive “can do” attitude and a passion for delivering technical solutions in a fast-paced startup environment.

Your Impact:
Key Responsibilities:
Use analytical rigor and statistical methods, programming, data modeling, simulation, and advanced mathematics to analyze large amounts of data, recognizing patterns, identifying opportunities, posing business questions, and making valuable discoveries.
Identify/develop appropriate machine learning/data mining/text mining techniques to enable better business outcomes.
Understand and analyze data sources including sampling biases, accuracy, and coverage.
Break apart problems scientifically, providing insight into your recommendations and findings to both technical and non-technical partners.
Research new ways for modeling and predictive behavior for large scale projects.
Generate and test hypotheses, designing experiments to answer targeted questions of advanced complexity.
Document projects including business objective, data gathering and processes, leading approaches, final algorithm, and detailed set of results and analytical metrics.
Validate score performance.
Document and present model process and performance.
What will you need?

Required Skills:
Advanced degree in Machine Learning, Computer Science, Electrical Engineering, Physics, Statistics, Applied Math, or other quantitative fields.
0 – 3 years of working experience in analytics, data mining, and/or predictive modeling, and data interpretation.
Proven track record in modifying and applying advanced algorithms to address practical problems.
Deep understanding of algorithms, machine learning and data science.
Confident interacting with business peers to understand and identify use case, with a strong ability to articulate solutions and present them to business partners.
Strong coding skills in one of the following: Python, R, or PySpark.
Experience with Hadoop and NoSQL or related technologies.
Knowledge of NLP/Text mining techniques and related open source tools.
Outstanding collaboration and communication skills. Ability to effectively collaborate with distributed team.
Understand and practice agile development methodology.
Prior experience working in a security software product company.

Nice to Have:
Understanding of DevOps, microservices architecture and container/Docker technologies.
Hands-on experience implementing machine learning and security intelligence solutions.",-1,Britive,Bengaluru,"Glendale, CA",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
359,Data Analyst,"Position Overview

Replicon is seeking Data Technicians, who will become familiar with Replicon’s sales/marketing operational workflows and marketing data dictionary, in order to perform close scrutiny of and investigate Salesforce data records (lead, account, contact, opportunity), identify errors, inconsistencies, and perform audit of general hygiene condition of data-field values, and cleanup bad/erroneous data that is identified.

Responsibilities:
Explore historical and current Salesforce marketing (and some sales) generated data in order to investigate discrepancies, and errors
Perform data cleanup based on the investigation above by formatting the data set with corrected values
Coordinate with extended marketing teams to ensure that clean data is being generated/created/recorded in Salesforce
Perform checklist-based tasks, and document everything that is being worked on and corrected
Correlate disparately recorded data to create account-based narrative when required

Qualifications:
Around 2+ years of experience in a sales and marketing data management roles, preferably with a technology company
Good understanding of sales marketing data hierarchy and data hygiene principles
Excellent knowledge of Salesforce and MS Excel; knowledge of marketing data and analytics platform would be an advantage
High level of organization and communication skills, attention to detail, and ‘hands-on’ approach
Ability to consistently deliver high quality work in a dynamic, deadline-driven environment
Ability to quickly learn new tools, and adapt to new processes",4.3,"Replicon
4.3",Bengaluru,"Calgary, Canada",201 to 500 employees,1996,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹1 to ₹5 billion (INR),"Kronos Incorporated, TSheets, Workday"
360,Data Engineer - Internship,"Esper is an inventive startup, and the industry’s first DevOps platform designed to provide a simple, safe and secure way for engineering and DevOps teams to release applications and manage smart Android devices in production. At Esper we believe that customers get the most out of their Android fleet when they can focus more on their business-critical applications and their key workflows--as opposed to spending dollars to create and maintain systems to deploy and maintain applications. We believe tailoring, and regularly updating Android devices to meet the purpose set by the customer brings about an unprecedented level of security to the fleet along with lighting up superior and delightful experiences. Using Esper, customers can control the quality of their deployments, and automatically roll back failed ones, saving time and reducing the need for managing devices individually with manual oversight. Esper allows its customers to control every aspect of their device-fleet and go as far as real-time debugging of applications on a remote device when required. Come join us in our Device Engineering team to disrupt this field!

About the internship

Selected candidates will work on command frameworks, moving and processing data generated by millions of devices across multiple platforms in Esper. Our data generation is in the order of petabytes, originating from multi-stack multi-tenant deployments across the globe connected to devices deployed across multiple industries including but not limited to retail, healthcare, manufacturing transportation etc.
Requirements
Strong at core concepts in data structures, big data and massively parallel computing.
Excited about cutting edge data platforms and frameworks.
Ability to perceive data pipelines at scale. Analytical thinking.
Skills
Scala
Python
Java
Terraform
Kubernetes
Only those candidates can apply who
Are recently graduated or graduating in 2020.
Are available for full time (in-office) internship.
Can start the internship between 15th Jun'20 and 6th Jul'20.
Are available for duration of 3 months and post which full time employment.
Have relevant skills and interests.
What we think makes us special

Bet on by leading VC firms including Madrona Venture Partners. Intense ownership, and therefore accountability. Flexible vacation time. Competent co-workers. We only hire capable veterans so we avoid the drama and trust in each other’s work. A worldwide footprint mixing different cultures for a unique experience. A team that really enjoys what we do and enjoys your input. We don’t hire just to fill a spot, we want you to make an impact. Fun company and team outings because we play just as hard as we work.",4.7,"Esper
4.7",Bengaluru,"Menlo Park, CA",1 to 50 employees,2017,Company - Private,IT Services,Information Technology,₹100 to ₹500 million (INR),-1
361,Machine Learning Engineer,"Proficiency with a deep learning framework such as TensorFlow or Keras.

Experience: 2-6 Years
Location: Gurgaon

Responsibilities:
Understanding business objectives and developing models that help to achieve them, along with metrics to track their progress
Managing available resources such as hardware, data, and personnel so that deadlines are met
Develop and Analyze the ML algorithms that could be used to solve a given problem and ranking them by their success probability
Exploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real world
Verifying data quality, and/or ensuring it via data cleaning
Finding available datasets online that could be used for training
Defining validation strategies
Defining the preprocessing or feature engineering to be done on a given dataset
Defining data augmentation pipelines
Training models and tuning their hyperparameters
Analyzing the errors of the model and designing strategies to overcome them
Deploying models to production
Full Stack development for Production Systems

Skills:
Proficiency with a deep learning framework such as TensorFlow or Keras
Proficiency with Python and basic libraries for machine learning such as scikit-learn and pandas
Expertise in visualizing and manipulating big datasets
Proficiency with OpenCV
Familiarity with Linux
Ability to select hardware to run an ML model with the required latency
Proficiency in Full Stack Web Development",-1,Amantya Technologies,Gurgaon,"Newark, DE",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
362,data scientist,"candidate should have experience in Analytics
NLP
ML
Python/SQL/R
Building models
random forest, decision trees, regression
EXperience- 3 to 12 years
relevant exp should be minimum 2 years max 12 years
NP- 60 0r less than 60 days ( no 90 days candidate)
location - bangalore
00-13.00 Years",5.0,"Novotree Minds Consulting Private Limited
5.0",Bengaluru,"Bengaluru, India",1 to 50 employees,2010,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
363,"Data Scientist, Advanced Analytics","ICL Systems is the leading provider of systems solutions designed for the demands and challenges of the finished vehicle supply chain. Only ICL Systems offers seamless integration and total visibility in all segments of the finished vehicle pre-delivery and transportation process. ICL Systems has approximately 50% market share in North America in this niche industry.

ICL is growing our team in India and we offer:

· Great company culture, collaborative team, and casual work environment.

· Incredible benefit package, paid vacation, paid holidays, paid personal/sick days.

· Stocked kitchen with food and beverages.

· Weekly company provided lunch.

· Flexible hours with an emphasis on work/life balance.

· Brand new office space in desirable location of Time Tower right near the MG Metro Station.

Job Requirements

· Develop teams capabilities in data science and machine learning and apply them to create new data driven insights such at ETA and network optimization.

· Design, conduct, and report results from prototype or proof of concept research project that focus on new tools, methods or algorithms and new scientific domains or application areas and new data sets or sources.

· Work with Product Managers to frame problems, both mathematically and within business context

· Deploy validated algorithms to our systems and develop techniques for monitoring and visualizing performance of all deployed algorithms

· Knowledge of one or more open-source Machine Learning framework

· Develop prototypes and validate results

· Apply data science and machine learning methods to help dirve new ETA and network optimization efforts

· Evaluate data analysis models and procedures
Participate in company s cross-training program
Experience Required
PhD in Mathematics or related field
5+ years of relevant experience
Experience working with R, Python and TensorFlow is required
· Knowledge of developing and debugging in Java is desirable
Data visualization
Detail Oriented, outstanding interpersonal skills, and self-motivated personality
Strong organizational skills and ability to multi task
Strong follow-through on tasks and projects
Willingness to learn new information and concepts
Ability to take initiative
Experience working in high stress situations",4.7,"ICL Systems
4.7",Gurgaon,"Irvine, CA",1 to 50 employees,1992,Company - Private,Consumer Products Manufacturing,Manufacturing,₹100 to ₹500 million (INR),-1
364,Sr Systems and Data Analyst,"We are Silicon Labs. We are the leading provider of silicon, software and solutions for a smarter, more connected world.


We hire the most innovative talent in the world to solve the industrys toughest problems, providing our customers with significant advantages in performance, energy savings, connectivity and design simplicity. Silicon Labs software and mixed signal engineering teams create solutions for customers in diverse markets including the Internet of Things, (IoT), internet infrastructure, TV tuners, as well as automotive and consumer radios. Our solutions are in products from the market leaders in home automation, electric vehicles, green technology, smart TVs and home voice control automation. We take pride in our products and in our people, and thats one of the many reasons we continue to be awarded Most Respected Public Semiconductor Company by the Global Semiconductor Alliance.

The team

The HR Global Operations team supports critical on-going activities affecting our workforce through several platforms, spanning SuccessFactors, ADP, JobVite and related connected applications and integrations. Our goal is to plan, design and implement technical solutions for organizational scale via process automation, workflows, integrations and optimization of existing platforms as well implement new ones.

The opportunity

Silicon Labs is seeking an experienced, highly motivated Senior Systems and Data Analyst to support the administration/management of critical business processes and programs hosted on and driven by our current suite of applications. You will work in collaboration with HR leaders, developers, business owners, and other technology teams in support of end to end business processes. Using both technical and process expertise, you will provide application support and resolve functional system issues. You will perform analysis to identify enhancements aimed at reducing support issues, perform configuration changes and work with development team and various stakeholders to implement enhancements. The successful candidate must have a proven track record of planning and executing functional requests within known technological and practical constraints to achieve and align team and corporate goals respectively.

Three reasons to apply
You will have the opportunity to influence and shape the future global HR systems architecture
You will be part of an incredible and passionate HR Operations team
You will have the ability to design and improve global processes that will impact the entire company
Responsibilities
Possesses a deep understanding of system configuration and functional capabilities and their relationship to HR processes and talent goals aligning with overall Company Strategy
Present design and implementation strategies that meet business requirements and the architectural guidelines of current systems considering downstream implications
Be the point of contact and data subject matter expert for HR business partners and employees during program roll outs like Merit, Promotions or Performance Reviews
Create or manage existing reports and aggregations in SuccessFactors or downstream data repository
Comply with written security policies, SOX procedures, and change management controls
Provide day to day production support of SuccessFactors platform, including user and security management
Qualifications
Bachelor's Degree in Computer Science, Software Engineering, MIS, or equivalent work experience
8+ years working with HCM systems (SuccessFactors, Workday, Oracle EBS, Oracle HCM Cloud, PeopleSoft)
Advanced SuccessFactors or Workday administrator skills
Working knowledge and understanding of SQL, data structures and HR data relationships
Self-motivated to keep knowledge and skills in line with latest product features and best practice
Self-starter with the ability to work independently and take initiative as needed
Nice to have skills
SuccessFactors HCM Certifications
Workday Benefits, Comp, Advanced Comp certifications
Advanced Administrator Certification in Oracle EBS, Oracle HCM or PeopleSoft
Advanced knowledge of SQL, REST, APIs, Excel
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",4.5,"Silicon Labs
4.5",Hyderabad,"Austin, TX",1001 to 5000 employees,1996,Company - Public,Electrical & Electronic Manufacturing,Manufacturing,₹50 to ₹100 billion (INR),"Cirrus Logic, NXP Semiconductors, Texas Instruments"
365,MASTER DATA SCIENTIST,"The Data Scientist will be part of the Core Data Scientist Team. This team identifies and develops advanced analytics statistical model, machine learning methods and solutions for our clients to improve various business outcomes.

The objective of the team is to:
Successfully develop, conceptualize and test various statistical models.Integrate the outcomes as real time analytics to create value for clients in areas and through means not immediately apparent to clients.

Job location:
Bangalore. Candidate should be flexible to travel & open for onsite positions within India & outside India for short-durations of 4 to 6 months.

Industry Focus:
Manufacturing, Financial Services, Investment Banking

Experience:
4 to 7 years of research experience in Statistical and Machine Learning Models. PhD freshers can also apply (Thesis submitted).

Qualifications:
Masters in a quantitative discipline such as Mathematics, Statistics & Machine Learning
Hands-on experience in running various methods in Supervised & Unsupervised ML like Regression, Classification, Clustering Random forest, k-NN, k-means, boosted trees, SVM, Neural Network, dimension reduction, model optimization, text mining, statistical modeling, data mining, exploratory data analysis, hypothesis testing & descriptive statistics.
Compelling communication and influencing skills. Should be able to communicate results and key findings to the stakeholders in a clear, concise and business friendly manner.
Ability to think creatively in solving problems real time.
Experience in diagnosis and prognosis of machines for early detection of signs of failure using ML techniques, using sensor data to analyze trend & patterns for industrial problems will be an added advantage.",-1,Inference Labs,Bengaluru,"Bengaluru, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
366,Senior Data Scientist,"Senior Data Scientist
If you are visionary and a statistical mastermind and are keen to make a difference in a unique way, then we are looking for you….

We are looking for highly passionate and enthusiastic players for solving problems in medical data analysis using a combination of image processing, machine learning, and deep learning.

As a Senior Computer Scientist at SigTuple you will have the onus of creating and leveraging the state-of-the-art algorithms in machine learning, image processing and AI which will impact billions of people across the world by creating healthcare solutions that are accurate and affordable. You will collaborate with our current team of super awesome geeks in cracking super complex problems in a simple way by creating experiments, algorithms and prototypes that not only yield high-accuracy but are also designed and engineered to scale. We believe in innovation – needless to say that you will be part of creating intellectual properties like patents and contributing to the research communities by publishing papers – it is something that we value the most.

What we are looking for:
Hands on experience along with a strong understanding of foundational algorithms in either machine learning, computer vision or deep learning. Prior experience of applying these techniques on images and videos would be good-to-have.
Hands on experience in building and implementing advanced statistical analysis and machine learning and data mining algorithms.
Programming experience in C, C++, Python
What should you have:
3 – 5 years of relevant experience in solving problems using machine learning or computer vision
Bachelor degree or Master degree or PhD in computer science or related fields.
Be an innovative and creative thinker, somebody who is not afraid to try something new and inspire others to do so.
Thrive in a fast-paced and fun environment.
Work with a bunch of data scientist geeks and disruptors striving for a big cause.",2.8,"SigTuple
2.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
367,"Data Scientist (Only from IIT, NIT,IIIT,IIM,VIT,BIT)","About Zycus :

Headquartered in Princeton, U.S. in 1998, Zycus has grown every day to be established as an organization which now is a leading global provider of complete Source-to-Pay suite of procurement performance solutions.

We develop cloud-based (SaaS) Source-to-Pay solutions for large global enterprises, and have successfully deployed about 200 solutions to over 1000 Global clients. We are proud to have as our clients, some of the best-of- breed companies across verticals like Manufacturing, Automotives, Banking and Finance, Oil and Gas, Food Processing, Electronics, Telecommunications, Chemicals, Health and Pharma, Education and more.

With a team of 1000+employees, we are present in India with 3 development centers at Bengaluru, Mumbai & Pune and offices in the U.S., U.K., Australia, Dubai, Netherlands and Singapore.

Know more about the LEADER of: Gartner’s 2013, 2015 & 2017 Magic Quadrant for Strategic Sourcing Application Suites and The Forrester Wave™: eProcurement, Q2 2017

We are in process of launching Merlin A.I. Studio™.

The artificial intelligence (AI)-based platform will allow procurement teams to to build and deploy bots across the source-to-pay process.

The bots will be used by firms leveraging more than 1,100 APIs from Zycus’ solution suite.

“By deploying the intelligent bots from Merlin A.I. Studio™, procurement can put themselves in cruise control mode as the bots work towards accomplishing tasks with zero human intervention,” The Fortune 500-serving firm explained in its press release

“Be it running an RFI event, discovering contract risks, negotiating with suppliers or transnational procurement; all one needs to do is launch the bot and see the magic unfold.”

“It will empower procurement to transform their routine, repetitive & mundane procurement tasks, so that time, effort & resources can be optimized towards more strategic initiatives.”Exp : 1 to 10 Years

Role : Data Scientist

Location : Bangalore

Drive Timings : 9 AM to 2.00 PM

Education : Any Engineering From IIT ,NIT , IIIT ,VIT , BITS Pilani

Venue Details :

ZYCUS INFOTECH PRIVATE LIMITED

SEZ UNIT,6TH FLOOR,GARNET Building,

Bagmane Developers Pvt Ltd SEZ II,

Bagmane World Technology Centre SEZ,

Mahadevapura,Outer ring Road,

KR Puram Hobli, Bengaluru (Bangalore) Urban,

Karnataka, 560048

Contact Person : Priyanka

Contact Number : 7899408877

Please carry your original ID proof along with Hard Copy of Resume

Requirements

We are especially looking for applicants with a strong background in Analytics and Data mining (Web, Social and Big data), Machine Learning and Pattern Recognition, Natural Language Processing and Computational Linguistics, Statistical Modelling and Inferencing, Information Retrieval, Large Scale Distributed Systems and Cloud Computing, Econometrics and Quantitative Marketing, Applied Game Theory and Mechanism Design, Operations Research and Optimization, Human Computer Interaction and Information Visualization. Applicants with a background in other quantitative areas are also encouraged to apply. If you are passionate about research and developing innovative technologies of interest to Zycus and the research community at large, the BigData Experience Lab may be the right place for you.

All successful candidates are expected to dive deep into problem areas of Zycus’s interest and invent technology solutions to not only advance the current products, but also to generate new product options that can strategically advantage Zycus

Skills
Master’s or Ph.D. in statistics, mathematics, or computer science
Only from Tier 1 Colleges
Experience using statistical computer languages such as R, Python, SQL, etc.
Experience in statistical and data mining techniques, including generalized linear model/regression, random forest, boosting, trees, text mining, social network analysis
Experience working with and creating data architectures
Knowledge of machine learning techniques such as clustering, decision tree learning, and artificial neural networks
Knowledge of advanced statistical techniques and concepts, including regression, properties of distributions, and statistical tests
1- 10 years of experience manipulating data sets and building statistical models
Experience using web services: Redshift, S3, Spark, DigitalOcean, etc.
Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.
Experience visualizing/presenting data.
Data Scientist will report in to Director Engineering - Data Scentist & the roles & responsibilities are as below:
Work as the data strategist, identifying and integrating new datasets that can be leveraged through our product capabilities and work closely with the engineering team to strategize and execute the development of data products
Execute analytical experiments methodically to help solve various problems and make a true impact across various domains and industries
Identify relevant data sources and sets to mine for client business needs, and collect large structured and unstructured datasets and variables
Devise and utilize algorithms and models to mine big data stores, perform data and error analysis to improve models, and clean and validate data for uniformity and accuracy
Analyze data for trends and patterns, and Interpret data with a clear objective in mind
Implement analytical models into production by collaborating with software developers and machine learning engineers.
Communicate analytic solutions to stakeholders and implement improvements as needed to operational systems
Benefits

Along with a competitive compensation structure, Zycus believes in an open culture learning environment, where everyone gets a chance to share their ideas and deliver par excellence. Here's a sneak peek to our life at Zycus.",3.3,"Zycus
3.3",Bengaluru,"Princeton, NJ",501 to 1000 employees,1998,Company - Private,Computer Hardware & Software,Information Technology,₹500 million to ₹1 billion (INR),"SAP Ariba, GEP, Coupa Software Inc"
368,AI / ML Data Scientist – Democratize commerce through Technology!,"The focus of our data science team is to work on highly scalable data-driven products that have massive impact on business. If you are passionate about finding patterns in big data and developing prediction models, this is the place for you. We encourage our team to be creative in building products, learning continuously, and solving interesting problems. We foster a culture where we enjoy raising the bar constantly for ourselves and others, and that strongly supports the freedom to explore and innovate.

The role holder will be an expert in his AI/ML domain to support the team in different data science projects. He/she is expected to deliver solid implementation of different AI/ML algorithms to meet production standards.

Key Responsibilities:
Develop robust machine learning models.
Extract huge volumes of data from multiple internal and external sources.
Develop data pipelines and infrastructure to scale and automate the analyses that enable rapid product iteration.
Maintain team’s best research and engineering practice.
Work closely with Data Analysts, Software Engineers, and Product Owners to deliver insights and impactful products for the company.
Devise data mining process and architecture.
Read research papers / article to create the best model / system architecture available.
Explore and examine data from a variety of angles to determine hidden weaknesses, trends, and/or opportunities.
Employ sophisticated analytics programs, machine learning, and statistical methods to prepare data for use in predictive & prescriptive modeling.

Qualifications:
Minimum Master’s degree in data science field, e.g. Math, Physics, and Computer Science.
2+ years of experience in applying analytical modeling to solve business problems.
Strong problem-solving skills with good analytical approach and logical thinking.
Proficiency in at least one programming language, i.e.: Python, Go, C/C++, etc.
Good understanding of different AI/ML models/algorithms.
Familiarity with at least one Deep Learning framework.
NLP, image processing knowledge is a plus.
Good communication skills.
A humble team player.
Experience with Google Cloud Platform is a plus.
If this sounds like the kind of opportunity you’ve been looking for, then we’re going to need your resume of course, but more importantly include a short note giving us a sense of why you think you are absolutely the right person for this job. Write to deepa.m@careerxperts.com to get in touch!

Location: Noida",-1,CareerXperts,India,"Bangalore, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
369,Principal Data Engineer - Product Development (Global AI Accelerator,"Date: Apr 22, 2020

Ericsson is one of the leading providers of Information and Communication Technology (ICT) to service providers. We enable the full value of connectivity by creating game-changing technology and services that are easy to use, adopt, and scale, making our customers successful in a fully connected world. Headquartered in Stockholm, Sweden, Ericsson is proud of its global presence across 100+ countries and market areas. With a strong focus on innovation, we possess 49 thousand registered patents and a global strength of over 95 thousand competent professionals. We also take pride in supporting networks that cater to a capacity of 40 percent of the world’s mobile traffic, thereby connecting more than 2.5 billion subscribers and counting. We are a world leader in the rapidly changing environment of communications technology – by providing hardware, software, and services to enable the full value of connectivity.

Ericsson Overview:

Ericsson is worlds leading provider of communications technology and services. Our offerings include services, consulting, software and infrastructure within Information and Communications Technology.

Using innovation to empower people, business and society, Ericsson is working towards the Networked Society: a world connected in real time that will open up opportunities to create freedom, transform society and drive solutions to some of our planets greatest challenges.

We are truly a global company, operating across borders in over 180 countries, offering a diverse, performance-driven culture and an innovative and engaging environment. As an Ericsson employee, you will have freedom to think big and the support to turn ideas into achievements. Continuous learning and growth opportunities allow you to acquire the knowledge and skills necessary to progress and reach your career goals. We invite you to join our team.

Exciting Opportunity:

It will be practically impossible for human brains to understand how to run and optimize next generation of wireless networks, i.e., 5G network with distributed edge compute, that will drive economic and social transformation for all aspects of society. Machine Learning (ML) and other Artificial Intelligence (AI) technologies will be vital for us to handle this opportunity. We are setting up a Global AI Accelerator (GAIA) in the US, Sweden and India, with 300 experts, to fast-track our strategy execution.

Machine Intelligence, the combination of Machine Learning and other Artificial Intelligence technologies is what Ericsson uses to drive thought leadership to automate and transform Ericsson offerings and operations. MI is also a key competence for to enable new and emerging business. This includes development of models, frameworks and infrastructure where we in our advancements push the technology frontiers. We engage in both academic and industry collaborations and drive the digitalization of Ericsson and the Industry by developing state of the art solutions that simplify and automate processes in our products and services and build new value through data insights.

Ericsson is now looking for Principal Data Engineers to significantly expand its global team for AI acceleration for our group in Bangalore and Chennai.

Role Summary:

As a Principal Data Engineer, you shall be leading efforts for AI model deployment at scale, involving edge interfacing, data pipeline and design of monitoring and alerting systems for ML models. You shall work with business stakeholders to define and formulate the right business problem.

You are an expert data pipeline builder and data wrangler who enjoys optimizing data systems and evolving them. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data and models devOps (dataOps) architecture is consistent throughout ongoing projects. You are self-directed and comfortable supporting the dataOps needs of multiple teams, systems and products. You will also be responsible for integrating them with the architecture used across the company. The right candidate will be excited by the prospect of optimizing or even re-designing our companys dataOps architecture to support our existing and next generation of MI-driven products and solutions initiatives.

Key Responsibilities:
Lead multiple Data Engineering projects within a certain product/business.
Manage communication, planning, collaboration and feedback loops with business
Lead Data Engineering features/enhancements within a certain business area.
Define the business metrics of success for DE projects and translates them into performance or scalability metrics.
Capacity planning, Performance monitoring.
Design solutions for Massive Parallel Processing (MPP) problems
Design and implement the data platform; and build a reporting and analytics engine/platform
Create and maintain optimal data and model data Ops pipeline architecture
Design and Adopt the right data engineering platform for AI/ML problems.
Contribute to IP creation for Ericsson in AI/ML
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and cloud-based big data technologies from AWS, Azure and others.
Define the Data Sourcing Strategy and Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep data separated and secure across national boundaries through multiple data centers and strategic customers/partners.
Create tool-chains for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and machine learning experts to strive for greater functionality in our data and model life cycle management systems.
Support data Ops competence build-up in Ericsson Businesses and Customer Serving Units
Key Qualifications:
Bachelors/Masters/Ph.D. in Computer Science, Information Systems, Data Science, Artificial Intelligence, Machine Learning, Electrical Engineering or related disciplines from any of the reputed institutes. First Class, preferably with Distinction.
Overall industry experience of around 15+ years, at least 8 years experience as a Data Engineer.
5+ years of experience in the following:
Software/tools: Hadoop, Spark, Kafka, etc.
Relational SQL and NoSQL databases, including Postgres and Cassandra.
Data and Model pipeline and workflow management tools: Azkaban, Luigi, Airflow, Dataiku, etc.
Stream-processing systems: Storm, Spark-Streaming, etc.
Object-oriented/object function scripting languages: Python, Java, Scala (Advanced level in one language, at least)
Experience building and optimizing big data data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and seek opportunities for improvement.
Experience in Data warehouse design and dimensional modeling
Strong analytic skills related to working with unstructured datasets.
Experience building processes supporting data transformation, data structures, metadata, dependency and workload management.
Good understanding of model validation techniques/metrics
Design APIs for AI/ML models with focus on business, modularity and versioning
Advanced SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of other databases/date-sources.
Working knowledge of message queuing, stream processing, and highly scalable big data stores.
Experience with Docker containers, orchestration systems (e.g. Kubernetes), continuous integration and job schedulers.
Familiar with functional programming and scripting languages such as JavaScript or GO
Knowledge of server-less architectures (e.g. Lambda, Kinesis, Glue).
Experience with cloud native technologies, microservices design and REST APIs.
Familiar with agile development and lean principles.
Contributor or owner of GitHub repo.
Strong project management and interpersonal skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
Soft Skills:
Good communication skills in written and spoken English
Creativity and ability to formulate problems and solve them independently
Ability to build and nurture internal and external communities
Experience in writing and presenting white papers, journal articles and technical blogs on the results
Additional Requirements:
Applications/Domain-knowledge in Telecommunication and/or IoT, a plus.
Experience with data visualization and dashboard creation is a plus
Ability to work independently with high energy, enthusiasm and persistence
Experience in partnering and collaborative co-creation, i.e., working with complex multiple stakeholder business units, global customers, technology and other ecosystem partners in a multi-culture, global matrix organization with sensitivity and persistence
Ericsson provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetics. Ericsson complies with applicable country, state and all local laws governing nondiscrimination in employment in every location across the world in which the company has facilities. In addition, Ericsson supports the UN Guiding Principles for Business and Human Rights and the United Nations Global Compact. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, training and development. Ericsson expressly prohibits any form of workplace harassment based on race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetic information.",3.9,"Ericsson-Worldwide
3.9",Bengaluru,"Stockholm, Sweden",10000+ employees,1876,Company - Public,Telecommunications Services,Telecommunications,₹500+ billion (INR),"Huawei Technologies, IBM, Cisco Systems"
370,Senior Data Scientist,"Responsibilities:
A keen desire to solve business problems, and to find patterns and insights within structured and unstructured data
Ability to work independently
Excellent written and verbal communication skills for coordinating across teams
A drive to learn and master new technologies and techniques
Strong ability to formulate business problems mathematically and strong problem-solving skills
Proven data manipulation skills
Have been active in the community in terms of articles / blogs / speaking engagements at conferences
Must Have:
At least 4+ years of experience in Data analysis and Hadoop stack development using various database technologies with recent 2+ years associated in Data science
Experience in Python or Scala, Spark, Linear Regression Modelling, Algorithms, Predictive Modelling, Statistical Model development.
Experience in implementing analytical solutions using programming languages, such as R, Python, Spark, Java and more, for solving analytical problems within engineering
Experience with data visualization tools and spatial analytics
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks/ANN, RNN, CNN, Deep learning techniques, Image & Text processing, NLP etc.) and their real-world advantages/drawbacks.
Strong problem solving skills with an emphasis on domain usecase
Excellent written and verbal communication skills for coordinating across teams
Experience in use case related to Retail ,Telecom ,Banking",4.2,"TO THE NEW
4.2",Noida,"Noida, India",1001 to 5000 employees,2008,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
371,Data Test Engineer,"Position Title
Data Test Engineer

08-May-2020

Job ID
295426BR

Job Description
As part of the Analytics team, perform manual and automated testing of data applications (data warehouse, data lakes), visualization applications and web applications. Work with business users, data stewards, data engineers, data scientists, systems engineers and report designers to make sure data quality and integrity is maintained in the Alcon data and analytics platform. The position requires strong QA experience with a focus on data, knowledge of data pipelines from raw data to reporting, and demonstrable SQL skills. The position will also act as a representative for testing in scrum meetings, and work alongside product management to address how to provide better quality coverage for the applications supported.

•Perform manual and automated testing of data applications (data warehouse, data lakes), visualization applications and web applications •Work with architects and developers to define test approach, prepare test data, develop manual or automated test scripts using automated testing tools and frameworks, and validate that software meets requirements / acceptance criteria. •Develop and execute automated regression testing, validation testing •Perform data profiling on downstream data for the purposes of finding field anomalies and possible data quality and reconciliation issues. •Mange validation testing and post deployment smoke testing •Support production application - perform data quality checks; investigate production inquiries and issues. •Responsible for defect management and testing •Maintain documentation of test plans, historical analysis, anomalies, issues, and resolutions. Use tools and automation to manage •Work on sprint team in agile, rapid development and deployment environment. •Communicate status to product owners, scrum masters. •Follow the agile methodology to document and coordinate tasks and issues in Gitlab.

Minimum requirements
•Education: Bachelor’s degree or equivalent years of applicable experience The ability to fluently read, write, understand and communicate in English. 3+ years of software automation testing experience. 2+ years in Data and Analytics domain, especially on data validation and reconciliation. •Experienced with automated/manual testing of data based applications (data lakes, data warehouses) on a AWS landscape •Experienced with automated/manual testing of dashboards and visualizations •Experienced in testing GxP applications •Experience with one or more programming languages:, Java, Python, SQL, Scala, AWS SDK •Strong SQL experience, with knowledge of AWS Redshift, Snowflake, or columnar databases. Knowledge of analytical functions a plus. oExperience with verifying data in databases through SQL, or a scripting language (Python, Java, shell scripting, etc.) •Experience with reporting or analytics tools like Tableau. •Experience with one or more automation testing platforms •Experience in working with agile teams on two week release cycles.

Job Type
Full Time

Country
India

Work Location
Bangalore

Functional Area
Information Technology

Division
ALCON

Business Unit
NON-NVS AL INFORMATION TECHNOLOGY

Employment Type
Regular

Company/Legal Entity
Alcon Ind

Shift Work
Yes",3.6,"Alcon
3.6",Bengaluru,"Fort Worth, TX",10000+ employees,1945,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),Allergan
372,Data Scientist - Pune,"Opening For Data Scientist – Pune location
3 - 7 Years
Mumbai, Pune, Navi Mumbai, Mumbai Suburbs
Apply

Job Description
Proven experience as a Data Scientist or Data Analyst
Experience in data mining
Understanding of machine-learning and operations research
Knowledge of R, SQL and Python; familiarity with Scala, Java or C++ is an asset
Experience using business intelligence tools (e.g. Tableau) and data frameworks (e.g. Hadoop)
Analytical mind and business acumen
Strong math skills (e.g. statistics, algebra)
Problem-solving aptitude

Salary: Not Disclosed by Recruiter

Industry:IT-Software / Software Services

Functional Area:IT Software - Application Programming, Maintenance

Role Category:Programming & Design

Role:Software Developer
Keyskills
JavaRCHadoopSCALAData AnalysisData MiningTableauSQLPython
Desired Candidate Profile
Please refer to the Job description above
Company Profile
Harjai Computers Pvt Ltd
Harjai Computers Pvt. Ltd. is a 25 year young ISO 9001:2015 certified IT consulting company. We provide IT subcontracting/outsourcing services to the top IT and Multinational companies all over India and around the world and are the preferred partners to most of our customers. Over the years, we've assisted our numerous clients, scale new heights by deploying top professionals.",4.4,"Harjai Computers
4.4",Mumbai,"Mumbai, India",201 to 500 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
373,Data Engineer,"Location: Bangalore- India
Job ID: 19WD35705

Position Overview
As a Data Engineer, you will be responsible for building the data foundations that enable data driven marketing at Autodesk

Responsibilities
Build ETLs and data processing workflows for various projects
Setup reliable data ingestion pipelines for new data sources and integrate them with other data sets
Provide engineering support to investigate, identify and setup new tools and processes for data warehousing, data quality, reporting, business intelligence, data governance and data cataloging
Build data quality tracking mechanisms and address inevitable disruptions in data ingestion and processing
Assist in building a comprehensive data catalog and implement data governance strategies, as required by the business
Address questions and concerns from downstream data consumers
Continue to adapt to changes based on emergence of new technologies, new competitors, artificial intelligence and alternative sources of data
Qualifications
Bachelors or master’s degree in Computer Science, Engineering, Statistics, Informatics, Information Systems or in another quantitative fields
2 years of experience in data engineering or data warehousing
Intermediate to advanced SQL skills
Excellent programming skills in Python, Java, or Scala. (Python preferred)
Experience working with relational databases, query authoring as well as working familiarity with a variety of databases
Optional Experience building products in a cloud-based environment, especially AWS and its services like EC2, Lambda, API Gateway, S3, EMR, RDS, Cloudwatch etc
Optional Experience working on or integrating a diverse set of in-house or acquired technologies
Optional Experience working on Spark or a similar distributed processing platform
Optional Experience working on orchestration tools like Airflow
Optional Working knowledge of the Agile development process
The Ideal Candidate
Strong technical aptitude and strong interest to learn best of class technologies around data warehousing, data wrangling, data quality and data governance
Excellent problem solving and analysis skills
Excellent written and verbal communication skills, empathy, initiative and ownership
Superb analytical skills, technical aptitude, influencing skills and attention to detail
Eager to learn new things and passionate about technology
Flexible and be able to embrace change effectively
Ability to work effectively in teams
Process focused",4.0,"Autodesk
4.0",Bengaluru,"San Rafael, CA",5001 to 10000 employees,1982,Company - Public,Computer Hardware & Software,Information Technology,₹100 to ₹500 billion (INR),-1
374,Data Analyst,"x
Data Analyst

Designation : Senior Data Scientist
Experience : 7-9 years of experience of which at least 6-7 must be hands on in DataScience related work
Location: Bangalore

Desired Skills and Experience

Expert understanding and demonstrated skills of using ""R"". Exposure to SAS, Python, SPSS,Julia etc also an advantage.
Excellent ability to assimilate multi-disciplinary problems across industries, createhypotheses and craft solutions using data science skills and techniques.
Bring together different technologies to solve a problem.
Strong understanding of databases, file systems (big data stores, especially) anddatabase/SQL languages.
Very strong articulation skills. Articulation skills are both oratory and written.

Responsibilities

The individual will be a designer of solutions that address specific business outcomes. These will be across industries and functions and must be designed generically to handle reuse. Sometimes the questions will be unknown, which theindividual must creatively discover and solve.
Solutions will be complete packages of BI and advanced data science related models in ""R"".
The individual will understand the nanobi platform and lead the integration of the models and deliver the solutions on the nanobi platform for client deployment.
Work very closely with sales, pre-sales and consulting to understand customer problem specifics and solve them for wider application. In this, the individual mayhave to spend time closely at customer locations.
Must provide direction and leadership to Jr. Data Scientist in their model development.
Will also have to work with functional experts in other teams to build out businessrepresentations of the data science Work.",3.0,"Nanobi Data & Analytics
3.0",Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
375,CIEL/SEL/13651: Data Scientist,"Job Description
Key points about the position are as below;
Hadoop - working knowledge

PL SQL
Python or R
Inferential Statistics
ML - must have implemented at least one algorithm
Visualisation - Tableau preferred, BI, Spotfire
Service Delivery, communication skills
Statistical education background
Production model experience using ML with any algorithm. Worked on real time projects

Job Responsibilities
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions
Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desiable.
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Skill Name Mandatory Expert Intermediate Basic Comments
Databases Yes
SQL, Oracle, Any RDBMS Yes Yes Should have working knowledge of atleast one database
Hadoop - Hive, Impala No Only Know how
PL/SQL Yes Yes
Programming Languages
R, Python Yes (Any One) Yes
Inferential Statistics Yes Yes Hypothesis, p-value, R2, RMSE, MAPE etc",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
376,"Research Scientist, Google Research","Due to the current health crisis related to COVID-19 and the escalating visa/travel restrictions in place, we're currently unable to extend offers to anyone who cannot work from India due to lockdown visa/travel restrictions, or other restrictive measures until further notice. Consequently, we will be prioritizing candidates who can start in this location by set date as expected. We're keeping the situation under review and would adjust our position should the restrictive measures be removed later on.

Minimum qualifications:
PhD in Computer Science, related technical field, or equivalent practical experience
Experience in Machine Learning, NLP/NLU, Computer Vision, Optimization, Game Theory, Computer Systems, Market Algorithms
Experience with general purpose programming languages e.g., C/C++ or Python
Contributions to research communities including publishing in top forums (e.g: NeurIPS, ICML, ACL, CVPR, KDD, AAMAS)
Preferred qualifications:
Relevant work experience, including full time industry experience or as a researcher in a lab.
Strong publication record
Ability to design and execute on research agenda.
About the job


As an organization, Google maintains a portfolio of research projects driven by fundamental research, new product innovation, product contribution and infrastructure goals, while providing individuals and teams the freedom to emphasize specific types of work. As a Research Scientist, you'll set up large-scale experiments and deploy promising ideas quickly and broadly, managing deadlines and deliverables while applying the latest theories to develop new and improved products, processes, or technologies. From creating experiments and prototyping implementations to designing new architectures, our research scientists work on real-world problems that span the breadth of computer science, such as machine (and deep) learning, data mining, natural language processing, hardware and software performance analysis, improving compilers for mobile platforms, as well as core search and much more.

As a Research Scientist, you'll also actively contribute to the wider research community by sharing and publishing your findings, with ideas inspired by internal projects as well as from collaborations with research programs at partner universities and technical institutes all over the world.

Our mission at Google Research India is to contribute to fundamental advances in AI and apply our research to solve big problems and deliver impact for Google, India and communities around the world.

The lab in Bangalore is a part of Google’s global network of researchers: participating in conferences, publishing research in scientific papers, and collaborating closely with one another. We are also establishing partnerships with the scientific research community and academic institutions both in India and around the world to support collaborative research programs.
Responsibilities
Undertake cutting edge research in the above mentioned areas.
Develop solutions for real-world, large-scale problems.

Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form.",4.4,"Google
4.4",Bengaluru,"Mountain View, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Microsoft, Apple, Facebook"
377,Data Engineer,"Summary:

You have experience with client projects and in handling vast amounts of data working on database design and development, data integration and ingestion, designing ETL architectures using a variety of ETL tools and techniques. You are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled Analytics team. Play a key role on projects from a data engineering perspective, working with our Architects and clients to model the data landscape, obtain data extracts and define secure data exchange approaches.
Plan and execute secure, good practice data integration strategies and approaches
Acquire, ingest, and process data from multiple sources and systems into Big Data platforms
Create and manage data environments in the Cloud
Collaborate with our business analysts and data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Have a strong understanding of Information Security principles to ensure compliant handling and management of client data
This is a fantastic opportunity to be involved in end-to-end data management for cutting edge Advanced Analytics and Data Science
Qualifications:
Experience on client-facing projects, including working in close-knit teams
Experience and interest in Big Data technologies (Hadoop / Spark / NoSQL DBs)
Experience or familiarity with real-time ingestion and streaming frameworks is a plus
Experience and desire to work with open source and branded open source frameworks
Experience working on projects within the cloud ideally AWS or Azure
Experience with NLP, Machine Learning, etc. is a plus
Experience working on lively projects and a consulting setting, often working on different and multiple projects at the same time
Strong development background with experience in at least two scripting, object oriented or functional programming language, etc. SQL, Python, Java, Scala, C#, R
Data Warehousing experience, building operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models
Excellent interpersonal skills when interacting with clients in a clear, timely, and professional manner.
A deep personal motivation to always produce outstanding work for your clients and colleagues
Excel in team collaboration and working with others from diverse skill-sets and backgrounds
Cervello is a dynamic technology company that is focused on business analytics and planning. We take an innovative approach to making complex solutions simple so our clients can focus on running their businesses. Our services and applications enable our clients to gain the benefits of a world-class analytics and planning capability without the headaches.

Powered by JazzHR",4.1,"Cervello Inc
4.1",Bengaluru,"Boston, MA",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
378,Senior Data Scientist,"Job Description

Cerner is growing and currently looking for a Senior Data Scientist. As a Senior Data Scientist, you will lead feasibility studies to identify data availability, quality, and modeling requirements and dependencies. Your responsibilities will be to create recommendation or propose modern data storage, movement, and transformation architectures and techniques to extract and engineer features from any scale structured or unstructured data in health, IT system, business process, or external data. In this role, you will have to explore and develop innovative, scientifically valid processes for exploring and visualizing data, and for engineering explanatory features in any collection of data. You will be expected to establish or recommend scalable, efficient, and automated processes and/or ecosystems for conducting data analysis, to include rapid data visualization, exploration, and transformation, as well as model development, validation, and deployment. Additionally, you will have to communicate implications, limitations, dependencies, and other deployment guidelines of a model or data analysis result at all levels (executive decision maker, end user, and technical audiences), and as appropriate, to external audiences. Also, you will have to serve as a content expert for areas such as at-scale data ingestion and management, feature engineering, statistical program languages and techniques, or data visualization.
Qualifications

Basic Qualifications:

• Bachelor’s or Master’s Degree in Statistics, Computer Science, Analytics, Biostatistics, Applied Mathematics, Software Engineering, or equivalent relevant work experience.
• At least 8 years of data mining, quantitative analysis, and/or statistical predictive performance and algorithm optimization work experience.
• At least 5 years of experience programming in multiple languages (ideally Python and/or R)
• Working knowledge of Big Data (Hadoop, Spark, MapReduce, Hive etc.)
• Strong Technical and Technology expertise in AI / ML modelling along with implementation experience using open source technologies.
• Strong technical knowledge of statistics, Machine Learning and Deep Learning algorithms, and neural networks.
• Expertise in image and video analytics.
• Strong vizualization skills (e.g. Tableau, d3.JS etc.)
• Expertise in classification and regression techniques (SVM, Decision tree, ANN, Linear regression, Logistic regression).
• Expertise in Image Analytics techniques (CNN, pre-trained models).
• Implemented unsupervised learning techniques (Kmeans, Hierarchical, Density based clustering).
• Understanding of dimensionality reduction techniques (PCA, SVD).
• Worked on forecasting techniques (Arima, RNN, Holt winters, ETS).
• Worked on SQL, Big Data.

Preferred Qualifications:

• Working knowlege of API development and model deployment.
• Hands-on experience in Architecting and solving multiple complex business problems using advanced data analytics methodologies.
• Experience with agile software development methodologies.
• Hands on experience on NLP techniques.",3.6,"Cerner
3.6",Bengaluru,"Kansas City, MO",10000+ employees,1979,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"McKesson, GE Healthcare, Epic"
379,Data Scientist 2,"? Must be able to handle periods of high stress.
? Strong analytical and problem solving skills.
? Excellent interpersonal and communication skills to effectively handle any business need.
? Knowledgeable in software development processes & lifecy
data science, data scientist, deep learning, machine learning, AI",2.9,"Genius Consultants
2.9",Mumbai,"Kolkata, India",201 to 500 employees,1993,Company - Private,Staffing & Outsourcing,Business Services,₹5 to ₹10 billion (INR),"Adecco, Ikya Human Capital Solutions, TeamLease Staffing Solutions"
380,Looking for Data Scientists: Spark ML Experience + Tensorflow,"Data Scientists: Spark ML Experience + Tensorflow
â€¢ Work with the team to create new deep learning and ML algorithms and applications. Drive technical vision and strategy to make DL and ML a must-have capability in delivering consumer services
â€¢ Help to define and improve large scale Machine Learning platform that powers our big data products to develop personalization, recommendation, and content discovery services for various Huawei Mobiles Services.
â€¢ Define metrics, conduct A/B testing, and oversee statistical measurement of new algorithms and approaches.
â€¢ Use Big Data technologies (such as Hadoop, Spark, Storm) to build large scale data mining pipelines for recommendation and search.
â€¢ Apply Natural Language Processing to understand text from forum reviews, description and interactions between users
â€¢ Working with engineering to build machine learning platform that covers data processing, feature engineering and monitoring
â€¢ Design and develop effective models, features, and algorithms involving user activities and interests, blogs and posts, social graphs, etc.
â€¢ Knowledge of natural language processing techniques and neural networks
â€¢ Experience in implement and validate big data algorithms and models
â€¢ Able to lead a team in developing and executing your technical vision, including planning, technical decision-making, and project management
â€¢ Versed in the process of building effective learning systems (data collection, training, evaluation, making iterative improvements)
â€¢ Experience with (un)supervised learning algorithms
â€¢ Experience with Caffe/TensorFlow/Torch or similar deep learning frameworks
â€¢ Programming experience with R/Scala/C++/Python
00-10.00 Years",3.5,"Sellcraft Global Solutions Private Limited
3.5",Bengaluru,"Pune, India",1001 to 5000 employees,1987,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
381,Senior Data Scientist,"Senior Data Scientist Responsibilities:
Formulating, suggesting, and managing data-driven projects which are geared at furthering the business's interests.
Collating and cleaning data from various entities for later use by Junior Data Scientists.
Delegating tasks to Junior Data Scientists in order to realize the successful completion of projects.
Monitoring the performance of Junior Data Scientists and providing them with practical guidance, as needed.
Selecting and employing advanced statistical procedures to obtain actionable insights.
Cross-validating models to ensure their generalizability.
Producing and disseminating non-technical reports that detail the successes and limitations of each project.
Suggesting ways in which insights obtained might be used to inform business strategies.
Staying informed about developments in Data Science and adjacent fields to ensure that outputs are always relevant.

Senior Data Scientist Requirements:
Advanced degree in Data Science, Statistics, Computer Science, or similar.
Extensive experience as a Data Scientist.
Proficiency in R or Python, where the former is preferred.
In-depth understanding of SQL.
Competent in machine learning principles and techniques.
Demonstrable history of devising and overseeing data-centered projects.
Ability to relay insights in layman's terms, such that these can be used to inform business decisions.
Outstanding supervision and mentorship abilities.
Capacity to foster a healthy, stimulating work environment that frequently harnesses teamwork.
Compliance with prevailing ethical standards.

Job Type: Full-time

Salary: ₹1,851,245.00 to ₹2,464,910.00 /year

Experience:
technical experience: 1 year (Preferred)
total work: 2 years (Preferred)",-1,Futurious Technologies,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
382,Analytics Consultant,"CAREERS

Analytics Consultant

Bengaluru, India
JOB DESCRIPTION

As an Analytics Consultant with Tredence you will work in a challenging environment with smart peer group. In your role, you will work hands on and provide thought leadership to real life business problems using analytical thinking and by applying complex mathematical techniques.
THE IDEAL CANDIDATE WILL

Solve business problems which involves:
Brainstorming with clients/onsite and internal teams to define a problem
Translate the business problem into an analytical problem
Identify internal and external data requirements for solving the analytical problem
Solving the analytical problem using concepts from mathematics, statistics, Artificial Intelligence and Machine learning
Translate the solution to a business solution and create artefacts that can help communicate the solution to clients like dashboards, power point slides, excel sheets etc.
Understand challenges faced by our clients in the context of their business and industry
Work hands on and provide thought leadership to real life business problem
Use analytical thinking and apply complex mathematical techniques
Work in a challenging environment with smart peer group
ELIGIBILITY CRITERIA

Bachelors in Engineering or Masters in Statistics/Economics
At least 5 years of working experience in analytics
Experience in statistical techniques such as Regression, Clustering & Time Series Forecasting, etc.
Strong analytical/logical thinking and communication skills
Proficient in:
SQL, R and/or Python
Visualization tools like Tableau or SpotFire
Send your CV to careers@tredence.com",3.5,"Tredence
3.5",Bengaluru,"San Jose, CA",501 to 1000 employees,2013,Company - Private,Consulting,Business Services,₹1 to ₹5 billion (INR),-1
383,Data Analyst,"Unacademy is India’s largest, online learning platform. It allows educators to create courses on various subjects. Our vision is to get the best minds of the country to share knowledge in an easily comprehensible form. You can find out more about our journey in this YourStory article.

Headquartered in Bengaluru, the platform brings expert educators together with millions of students in need of quality education. With a growing network of 10,000 registered educators and 3 million learners, Unacademy is changing the way India learns. The company has raised Series D funding from prominent investors such as Sequoia India, SAIF Partners, Nexus Venture Partners and Blume Ventures.

Roles and Responsibilities:
●Interpret data, analyze results using statistical techniques and provide ongoing reports

●Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality.

●Acquire data from primary or secondary data sources and maintain databases/data systems.

●Identify, analyze, and interpret trends or patterns in complex data sets.

●Filter and “clean” data.

●Work with management to prioritize business and information needs.

●Locate and define new process improvement opportunities.


Eligibility:
Any Graduate / Post Graduate with 1 to 5 years of relevant experience.
Preferrably worked in Data reporting, Data Insights, Data Analysis role for minimum of 1 year.",4.2,"Unacademy
4.2",Bengaluru,"Bengaluru, India",51 to 200 employees,2015,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
384,Data Scientist (Risk Analytics & Modeling),"Data Scientist (Risk Analytics & Modeling)


Nov. 2, 2017

Experience:
Minimum 2 years of experience in implementing statistical/machine learning algorithms (regression, decision trees, SVM) and statistical programming tools (R/Matlab/Octave/Weka)
Proficiency in programming: R/Python/VBA
Strong background in statistics and probability
Experience in handling large structured and unstructured dataset
Knowledge and experience in structured finance products (securitization structures) would be a plus
Excellent writing, oral communication and presentation skills
Qualification: PGDM/Masters degree in Maths/Statistics/Econometrics/Economics/Finance/Engineering /other quantitative disciplines. Also Actuaries/FRM/CFA/CQF/PRM certification would be a plus.

Job Description: Lead the Business Analytics for Credit portfolio Analysis of Loan Pools of NBFC & Micro Finance Companies

Primary Responsibilities:
Develop and implement new (maintain and use existing) statistical/machine learning models to identify performance and risk drivers in the credit portfolio
Develop and implement new (maintain and use existing) risk and performance assessment models to measure risk and performance in the portfolio
Manage large loan level and borrower level data used for risk and learning models
Measure the risk and performance indicators for debt and structured finance products using existing and new models
Perform qualitative and quantitative analysis of various performance metrics for structured transactions
Document the analysis methodology and findings in report and present the analysis to the internal and external stakeholders/platforms (model notes, white papers, working papers, etc.)
Contribute towards other risk management work done by the risk management function
Travel not more than 20% of the time to meet partners and understand the lending models",-1,LoanXpress,Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
385,Manager Data Science,"Job Responsibilities :
Specify, design, and implement new data science applications,
methodologies,models,and algorithms
Help analyze business cases, formulate the problems and provide
practical solutions
Design and implement large scale predictive analytics machine
learning algorithms
4. Develop code with high-level languages and technologies: R, Python,
Java/Scala, SQL, Map Reduce
Help analyze business cases, formulate the problems and provide
Quantify and measure impacts of solutions
Understand, categorize, organize, and interpret heterogeneous data
sets8. Design experiments, test hypotheses,and build prototypes and
models
Be involved in the transition from prototyping to production
Education Requirement :
B.E./B.Tech/M.E/M.Tech/MS

Experience Requirement :
Maximum 5 Years & above

Skills & Competencies :
Expertise in providing an end to end BI solution by configuring
metadata and building Analytics Repository,dimensional modeling design,
building business models,generating reports and creating dashboards
using Analytics
Strong technical knowledge of Pentaho and related BI Applications,
including approach to implementing, extending and supporting using third
party modules
Strong technical understanding of data structures generated by mobile
applications and networks, and how they relate to establishing data
warehousing, data management and analytic architectures

Location Map : Jio Ads,Bengaluru Avana Building,Karnataka, Jio Ads,Bengaluru,Karnataka",3.6,"Reliance Jio Infocomm Limited
3.6",Bengaluru,"Mumbai, India",5001 to 10000 employees,2010,Company - Private,"Cable, Internet & Telephone Providers",Telecommunications,Unknown / Non-Applicable,-1
386,Data Engineer,"Company profile

Morgan Stanley is a leading global financial services firm providing a wide range of investment banking, securities, investment management and wealth management services. The Firm's employees serve clients worldwide including corporations, governments and individuals from more than 1,200 offices in 43 countries.
As a market leader, the talent and passion of our people is critical to our success. Together, we share a common set of values rooted in integrity, excellence and strong team ethic. Morgan Stanley can provide a superior foundation for building a professional career - a place for people to learn, to achieve and grow. A philosophy that balances personal lifestyles, perspectives and needs is an important part of our culture.

Overview on Wealth Management
Wealth Management Technology (WMIMT) is responsible for the design, development, delivery, and support of the technical platform behind the products and services used by the Business. Morgan Stanley Wealth Management (WM) is a product of the acquisition of Smith Barney from Citigroup, which was completed in June ‘13. Its core client base is individual investors, small- to medium-size businesses and institutions, and high net worth families and individuals. In the second half of ‘14, WM reached a milestone, with its business having surpassed $2 trillion in total client assets
We are seeking a Data Engineer with expertise in uncovering insights and identifying patterns using Hive, Spark and Python within the HDFS ecosystem. The position is for the role in AI and Knowledge Management team, which is part of Analytics, Intelligence and Data Technology group for Wealth Management. This team is comprised of members located in NY-United States and Bangalore-India. The team partners with various businesses and IT groups within firm and develops analytical solutions aimed at product opportunity mining, revenue & AUM growth and risk control. The team accumulates data from a variety of internal and external upstream systems in order to provide business partners with statistics, dashboards and metrics to provide insights into business problems.

Role & Responsibilities
Candidate will work with the Machine Learning & Advanced Analytics team, based out of Bangalore, working on various deliveries. This candidate will be reporting to the Local Analytics lead in Bangalore and work in collaboration with rest of the team in India & NY. Candidate will be working hands-on on Analytics driven applications and be responsible for project delivery, execution and support. Candidate should be able to work in a dynamic environment with limited or no supervision and should be able to motivate junior team members. Should be comfortable and manage time working with global team on multiple initiatives. Candidate would be developing data pipelines and ML engineering solutions as batch as well as real time using Hadoop and Spark. Main role and responsibilities include:
Job Responsibilities:
Design and Build distributed, scalable, and reliable data pipelines that ingest and process data at scale and in real-time
Explore new data sources and data from new domains
Oversee the Machine Learning Platform on which several ML based solutions would be deployed
Evaluate big data technologies and prototype solutions to improve our data processing architecture

Primary Skills / Must have
Experience in designing and architecting components of Hadoop ecosystem and experience in applying them to practical problems – Hive/Impala/Spark/MR/Kafka/HBase.
Experience in Real time/ Batch and near real time architectures in Spark and other Hadoop ecosystem components
Experience in building large scale distributed data processing systems/applications
Create architectural designs, detailed implementation plans and low level technical designs
Flair for data, schema, data model, how to bring efficiency in big data related life cycle
Ability to acquire, compute, store and process various types of datasets in Hadoop platform
Excellent written and verbal communication skills
Secondary Skills / Desired skills
Experience with Python will be a big plus.
Experience in building data pipelines that ingest and process data at scale and in real-time.
Experienced professional with 4-7 years of experience working in Hadoop/Spark
Strong Software abilities in Scala/Python
Strong and proven experience in writing complex and optimized SQL
Ability to work in fast paced and dynamic environment.
Good Understanding of Machine Learning Algorithms and Statistics
Experience in Finance Industry

Apply Now",3.8,"Morgan Stanley
3.8",Bengaluru,"New York, NY",10000+ employees,1935,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
387,Data Science,Data Science,3.3,"Sage IT India
3.3",Bengaluru,"Frisco, TX",501 to 1000 employees,2003,Company - Private,IT Services,Information Technology,₹100 to ₹500 billion (INR),-1
388,Data Scientist III,":

General Mills is reshaping the future of food. We believe food makes us better. It nourishes our bodies, brings us joy and connects us to each other. As one of the world's leading food companies, General Mills operates in more than 100 countries and markets more than 100 consumer brands, including Cheerios, Nature Valley, Betty Crocker, Yoplait, Annie's Homegrown, Old El Paso, Epic Provisions, Blue Buffalo and more. Are you passionate about the future of food? You've come to the right table. We want the very best talent to help lead something big.

:

General Mills is seeking a Data Scientist to join a new data science team in the Global Business Solutions (shared services organization) that is tasked with collaborating with and enabling existing functional data science and analytics teams. This team also provides data science expertise and services to advance initiatives around demand forecasting, text classification, operational analytics, and machine learning to name just a few. It is also responsible for curating a community of practice to determine the best standards and practices around data science at General Mills

:

Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation, Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions\
Experienced in proposing ROI based solutions to business

:

Qualification: Any Graduate (Preferred Statistical background)

Experience - 6+ yrs

Statistical analysis, modeling, clustering and data mining techniques to identify trends and insights
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning a plus
Experience with data visualization tools
Experience writing complex SQL queries
Experience with Python & R, comfortable working with DataFrames
Strong communication and collaboration skills to understand customer needs and deliver solutions in alignment with business needs",-1,"General Mills Services, Inc.",Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
389,Senior Data Scientist,"We are looking for a strong Senior Analyst/Senior Data Scientist, who will guide model development. The person will be part of data science team that continuously interacts with underwriting analysts and developers that drive solutions to the complex business problems, in credit and risk domains.

Roles and Responsibilities:
In addition to the responsibility of analyst/Data Scientist, additional responsibilities:

Good understanding of the underlying business and workings of cross functional teams for successful execution.
Good written and oral communication, and ability to convey technical details to teams working across multiple time zones.
Mentor a small team of analysts.

Qualification & Experience:
4+ years of experience in the field of credit rist analytics, marketing analytics backgrounds
Proven experience working in teams with end to end real time implementation
Strong with programming languages like Python and data processing using SQL or equivalent and ability to experiment with newer open source tools
Strong with analytical and statistical packages like R, Python Scikit-Learn
Familiarity with deep learning, xgboost, scikit, apache spark, GPU based machine learning
Good communication skills and ability to articulate complex scientific and technical matters to the business group
Ability to successfully interact with business and software teams for execution
Experience in newer machine learning algorithms
Experience with NoSQL and distributed data processing technologies such as Hadoop is also desirable
Experience in risk and credit score domains are a big plus
Bachelor or Master in Operations Research, Computer Engineering or in closely related Quantitative Disciplines from a premier institution.
Interested? Please send your resume to careersindia@applieddatafinance.com.",4.5,"Applied Data Finance
4.5",Chennai,"San Diego, CA",51 to 200 employees,2014,Company - Private,Lending,Finance,Unknown / Non-Applicable,Avant
390,Data analyst,"Through the Amazon Marketplace, Amazon provides individuals or enterprises the opportunity to sell their goods on the Amazon platform. Worldwide, more than a million sellers use this Marketplace and thereby contribute to the success of Amazon. Amazon is growing its Marketplace aggressively worldwide. In this context, Amazon India Seller Services is setting up a new service to help with driving selection improvement on Amazon.

In order to drive improvement in the Amazon selection, this program will contribute in identification and on-boarding of new selection and drive efficiency of the existing selection.

About the Role: We are looking for a hands-on, detail oriented and highly motivated data analyst to help create data backed insights that will drive selection improvement . The candidate should be comfortable interfacing with technology systems and be able to analyze data and gather actionable conclusions. Operating in a rapidly changing environment will require the candidate to be adept at dealing with ambiguous, new and challenging situations. The candidate will be comfortable in executing repeatable processes.

Basic Qualifications


· Bachelor's degree in Computer Science, Engineering, Operations Research, Math, or related discipline.
· Minimum 2+ years of experience as an Analyst role preferred.
· Highly proficient in Microsoft Office and Windows based applications.
· SQL Knowledge and Hands-on experience is a must.
· Demonstrated Analytical ability, results-oriented environment with external customer interaction.
· Excellent written and verbal communication and presentation skills and the ability to express thoughts logically and succinctly.
· Entrepreneurial drive and demonstrated ability to achieve stretch goals in an innovative and fast-paced environment.



Preferred Qualifications

· Experience with E-Commerce, Retail and Business Analytics would be an advantage.
· Understanding of data warehousing, data modeling concept and building new DW tables
· Advanced SQL skills, fluent in R and/or Python, advanced Microsoft Office skills, particularly Excel and analytical platforms",4.2,"Amazon
4.2",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
391,Data Analyst,"Technical functions:
Shouldhave experience in an engineering industry
Experienceof 2-3 years of analysing data & identifying trends & reportingsuggestions.
Candidatewith readiness to learn in engineering / manufacturing company.
Createand implement data archive systems.
Dataanalysts must prepare and present reports to various departments andexecutives.
Dataanalysts often work with various departments to establish statistical methodologyand reporting standards
Qualifications:
Must : Should be graduate in statistics with minimum firstclass;
Desired :
Age : 25-30 years",3.5,"Engineering manufacturing company
3.5",Vadodara,"East Hartford, CT",51 to 200 employees,1946,Company - Private,Transportation Equipment Manufacturing,Manufacturing,Unknown / Non-Applicable,-1
392,SENIOR DATA SCIENTIST,"Data Scientist
About Happiest Minds Technologies

Happiest Minds, the Mindful IT Company, applies agile methodologies to enable digital transformation for enterprises and technology providers by delivering seamless customer experience, business efficiency and actionable insights. We leverage a spectrum of disruptive technologies such as: Big Data Analytics, AI & Cognitive Computing, Internet of Things, Cloud, Security, SDN-NFV, RPA, Blockchain, etc. Positioned as Born Digital . Born Agile, our capabilities spans across product engineering, digital business solutions, infrastructure management and security services. We deliver these services across industry sectors such as retail, consumer packaged goods, edutech, e-commerce, banking, insurance, hi-tech, engineering R&D, manufacturing, automotive and travel/transportation/hospitality.

Headquartered in Bangalore, India; Happiest Minds has operations in USA, UK, The Netherlands, Australia and Middle East.

Skills

Required Skills: Data Science, Machine Learning, Deep Learning, Python, Computer Vision

Desired Skills:

Roles and responsibilities

· Experience in Data Modelling, R, Python, SQL, Data Science, Machine Learning, Deep Learning, Computer vision, Statistics

· Have ability to solve Business problems using Data

· Should possess extensive knowledge of and experience in applying data mining and machine learning techniques on large amount of datasets

· High level of proficiency in statistical tools like R, Python

· Candidate will be expected to communicate analytical results in a way that is meaningful for business stakeholders and provides actionable insights.

· Have the ability to discover new opportunities where advanced analytical techniques can be leveraged for solving business problems

Good to Have

· Expertise in programming languages like Java/C/C++/Python

· Experience with relational databases and SQL is good to have

· Experience in audio and video analytics

· Relevant experience in Big Data platforms like Hadoop eco-system

· Come up with innovative algorithms and solutions",4.1,"Happiest Minds Technologies
4.1",Bengaluru,"Bengaluru, India",1001 to 5000 employees,2011,Company - Public,IT Services,Information Technology,₹5 to ₹10 billion (INR),-1
393,"Data Scientist, Analytics","Full Time HyderabadPositions: 3

This position is a generalist role and could involve analytics, modeling, business operations and/or partnerships among other things. You must have flexibility to adapt to changing priorities, business and organizational needs. In addition, you must have the ability to operate independently in a fast-paced, small but growing environment and work proactively with various teams across the organization, including engineering, product, business, customer support, human resources, finance and legal.

Responsibilities
Apply your expertise in quantitative analysis, data mining, and the presentation of data to see beyond the numbers and understand how our users interact with our core/business products
Partner with Product and Engineering teams to solve problems and identify trends and opportunities
Inform, influence, support, and execute our product decisions and product launches.
The Data Scientist Analytics role has work across the following four areas:
Data Infrastructure
Working in hadoop and hive primarily, sometimes mysql, oracle, and vertica
Authoring pipelines via SQL and python based ETL framework
Building key data sets to empower operational and exploratory analysis
Automating analyses
Product Operations
Setting goals
Designing and evaluating experiments monitoring key product metrics, understanding root causes of changes in metrics
Building and analyzing dashboards and reports
Exploratory Analysis
Proposing what to build in the next roadmap
Understanding ecosystems, user behaviors, and long-term trends
Identifying levers to help move key metrics
Evaluating and defining metrics
Building models of user behaviors for analysis or to power production systems
Product Leadership
Influencing product teams through presentation of work
Communicating of state of business, experiment results, etc to product teams
Spreading best practices to analytics and product teams
Requirements
4+ years’ experience doing quantitative analysis.
BA/BS in Computer Science, Math, Physics, Engineering, Statistics or other technical field. Advanced degrees preferred.
Experience in SQL or other programming languages.
Development experience in at least one scripting language (PHP, Python, Perl, etc.).
Ability to initiate and drive projects to completion with minimal guidance
Ability to communicate the results of analyses in a clear and effective manner
Basic understanding of statistical analysis.
Experience with a statistical package such as R, MATLAB, SPSS, SAS, Stata, etc.
Experience with an Internet-based company.
Experience with data sets and distributed computing (Hive/Hadoop).
Minimum Qualification
4+ years’ experience doing quantitative analysis.
BA/BS in Computer Science, Math, Physics, Engineering, Statistics or other technical field. Advanced degrees preferred.
Experience in SQL or other programming languages.
Development experience in at least one scripting language (PHP, Python, Perl, etc.).
Ability to initiate and drive projects to completion with minimal guidance
Ability to communicate the results of analyses in a clear and effective manner
Basic understanding of statistical analysis.
Experience with a statistical package such as R, MATLAB, SPSS, SAS, Stata, etc.
Experience with an Internet-based company.
Experience with data sets and distributed computing (Hive/Hadoop).",-1,Dotbits,Hyderabad,"Sunnyvale, CA",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
394,Data Engineer,"As a Data Engineer, you will work on cutting edge, petabyte scale Hadoop eco system to ingest raw data and transform it, in to a usable and consumable information for various operational and advanced analytics purpose.

You will ...
Build, test & maintain enterprise data lake and data pipelines
Work with analytics partners to deploy scalable data pipelines for analytical needs
Adher to the plan and quality needs of data solutions to various business problems
‪Explore and establish new technologies, tools and new ways of solving problems
Adapt to competing demands and step outside comfort zone
You will have
Engineering degree in Computer Science or related technical field, or equivalent practical experience.
3-5 years of DW/BI/Analytics/IT experience with 2+ years of experience in building data processing applications using Hadoop, Spark and NoSQL DB and Hadoop streaming.
Experience in one or more programming languages like Java, Scala or Python and in unix scripting.
Experence in using query languages/tools such as SQL, Hive, Sqoop and SparkSQL.
Experience in using tools like Jenkins for CI, Git for version Control and Jira for planning and execution.
Good understanding of data modelling & ETL concepts.
Exposure to cloud based bigdata environments will be a plus
Strong problem-solving, communication and articulation skills
Job Types: Full-time, Temporary

Experience:
total work: 3 years (Required)
Work Remotely:
Yes",3.9,"Infometry Inc.
3.9",Bengaluru,"Fremont, CA",51 to 200 employees,2010,Company - Private,IT Services,Information Technology,₹100 to ₹500 million (INR),-1
395,Team Lead/ Sr.Master Data Analyst,"Verdantis project implementation and delivery team is responsible for end to end life-cycle of complex material master data management projects. Our diversely experienced team of engineers is backed by our industry leading data management applications. We deliver to our client the best of automated data processing combined with machine learning added by our data analysts. We are looking for candidates who are passionate about technical know how from the world of engineering combined with mindset of a data analyst.

Job Responsibilities:
Processing and analyzing material master data as per project parameters such as timelines and quality assurance
Identification of product/material from textual descriptions for categorization
Identification of technical specifications for standard MRO categories e.g. Motors, Pumps, Bearings, Gears, etc.
Data modelling of Verdantis data management applications as per clients master data
Quality check automated results and make corrections to meet overall quality assurance
Tracking project progress with various project management methods such as Daily Status Meetings, 1-1 meetings with managers, Daily/Weekly/Monthly Targets, Problem Solving/Brainstorming Sessions, etc.
Documentation of key decisions and communications with meeting minutes and status reports
Perform in collaborative organizational structure ensuring right authority is updated with accurate status on timely manner
Identify opportunities to enhance process efficiency and automation
Evaluate/recommend emerging technologies that may contribute to our analytical platform
Understand and resolve client issues on material data, structure or processes
Requirements
BE: Mechanical /Production /Electrical/ Electronics & Telecommunication
3years -5years of industry experience
Basic technical knowledge from engineering background
Thoroughness with previous job - Knew what he/she did?
Good communication skills - written and spoken
Well versed in his/her area of interest
Strong collaborative mindset
Good presentation skills
Flexible to perform under dynamic project requirements
Problem solving and analytical skills
Well versed with common computer programs such as Word, Excel, PowerPoint, etc.
Taking initiatives and ownership
Company Profile

Website – http://www.verdantis.com

Email ID – careers@verdantis.com

Benefits

Benefits

About Verdantis

Headquartered in Princeton, NJ, Verdantis is the first to offer Master Data Management solutions that bring true ROI and Business value by focusing on the business use and application of organizational Master Data. Verdantis uniquely offers end-to-end automated ERP MDM solutions driven by our suite of Artificial Intelligence (AI) based software solutions. Our easy to use solutions are easily configured to fit enterprise requirements for Fortune 500 companies.

Our Products are built around an intuitive user experience, leveraging a comprehensive knowledge base, robust Artificial Intelligence technology, encapsulates industry's best-of-breed processes and methodologies.

Several of Fortune 500 companies have chosen Verdantis’ solutions for the following reasons:
In-depth industry and domain expertise with a robust implementation methodology
Ability to ensure semantic and structural data integrity and quality
End-to-end solution for Data Governance renowned by leading market Analysts",4.0,"Ultria
4.0",Mumbai,"Princeton, NJ",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
396,Machine Learning Engineer,"Bachelor's degree in Computer Science/IT/ or higher

Minimum of 1.5 years of professional experience in Machine Learning/Data Science is required

Experience should include all areas of Data Science/Machine Learning like Data Analysis, building models for prediction, NLP, Deep Learning and Image Processing

Experience of programming languages Like Python, C++,MySQL is required

Knowledge of data base systems is required

Problem solving, Analytical, programming, debugging, and design skills are desired

Knowledge of modern machine learning algorithms must

Should be able to work in any area of machine learning like regression modelling, NLP, Image, Deep Learning.

Job Type: Full-time

Salary: ₹200,000.00 to ₹300,000.00 /year",5.0,"eInvenSys
5.0",Ahmedabad,"Milpitas, CA",1 to 50 employees,-1,Other Organisation,-1,-1,Unknown / Non-Applicable,-1
397,Risk Analytics - Machine Learning Engineer,"About this Opportunity

The incumbent will be responsible for studying data, discovering the information hidden and help making smarter and better decisions for the Business. The primary focus of the role will be on applying text and data mining techniques, doing statistical analysis and building high quality and high-performance prediction systems integrated with the Risk applications. They will also have proven experience in data analysis, modeling and implementing solutions along with sound understanding of capital markets and financial risk domain to be able to recommend the best-fit model and solution approach.

Business Unit: Global Chief Risk OfficeOur Risk Management teams work to protect the safety and soundness of our systems and are responsible for identifying, managing, measuring and mitigating a spectrum of key risk types including credit, market, liquidity, systemic, operational and technology in all existing and new products, activities, processes and systems.


What You'll Do
Collaborate with cross functional teams to collate data
Enhancing data collection procedures to include information that is relevant for building analytical solutions
Analyze, extract and understand meaningful patterns from the large volumes / dimensions of historical data by utilizing analytics techniques and SMEs’ inputs
Design, develop, evaluate and implement high quality innovative predictive/prescriptive models using open source tools such as R, Python, or similar scripting within Apache Spark/AWS cloud based big data environment
Support the team in creating/executing novel approaches to solve challenging problems by leveraging AI/ ML/NLP and Big Data/Cloud technologies
Collaborate closely with Business Partners/Analysts, Data Analysts, Application Development and other Data Scientists to integrate innovations and algorithms into useable data products
Doing ad-hoc analysis and presenting results in a clear manner
Aligns risk and control processes into day to day responsibilities to monitor and mitigate risk; escalates appropriately

Sound Like You?
Minimum of 6 years of related experience
Bachelor's degree preferred with Masters or equivalent experience
Additional Qualifications
Minimum of 3-5 years of related experience in Data analysis, Data Science, Modeling
Experience with SQL, Python, Big Data and Machine Learning Algorithms
Strong analytical and problem-solving skills
Great communication skills
Experience in Financial industry with focus on Risk Management is preferred
Experience in Data Visualization tools and AWS is a plus
Leadership Competencies
Accountability - Demonstrates reliability by taking necessary actions to continuously meet required deadlines and goals.
Global Collaboration - Applies global perspective when working within a team by being aware of own style and ensuring all relevant parties are involved in key team tasks and decisions.
Communication - Articulates information clearly and presents information effectively and confidently when working with others.
Innovation and Creativity - Thinks boldly and out of the box, generates new ideas and processes, and confidently pursues challenges as new avenues of opportunity.
Who We Are

With over 45 years of experience, DTCC is the premier post-trade market infrastructure for the global financial services industry. From operating facilities, data centers and offices in 16 countries, DTCC, through its subsidiaries, automates, centralizes and standardizes the processing of financial transactions, mitigating risk, increasing transparency and driving efficiency for thousands of broker/dealers, custodian banks and asset managers. Industry owned and governed, the firm simplifies the complexities of clearing, settlement, asset servicing, data management, data reporting and information services across asset classes, bringing increased security and soundness to financial markets. In 2018, DTCC’s subsidiaries processed securities transactions valued at more than U.S. $1.85 quadrillion. Its depository provides custody and asset servicing for securities issues from 170 countries and territories valued at U.S. $52.2 trillion. DTCC’s Global Trade Repository service, through locally registered, licensed, or approved trade repositories, processes over 14 billion messages annually. To learn more, please visit us at www.dtcc.com or connect with us on LinkedIn, Twitter, YouTube and Facebook.",3.4,"DTCC
3.4",Chennai,"New York, NY",1001 to 5000 employees,1973,Company - Private,Brokerage Services,Finance,₹50 to ₹100 billion (INR),-1
398,Machine Learning Engineer,"We are looking for an expert in machine learning to help us extract value from our data. You will lead all the processes from data collection, cleaning, and preprocessing, to training models and deploying them to production. The ideal candidate will be passionate about artificial intelligence and stay up-to-date with the latest developments in the field, and know how to program in C++ (we rarely use Python).

Requirements
B.Tech./ B.E / MCA degree in Computer Science, Engineering or a related stream.
3+ years of machine learning experience.
Proficiency with a deep learning framework such as TensorFlow or TensorRT.
Expertise in visualizing and manipulating big datasets.
Proficiency with Linux, C++, OpenCL, OpenMP and OpenCV (we have no use of Python in deployments).
Ability to determine hardware requirements to run an ML model with the required latency.
Extremely good understanding of embeddings, and how to play with them.
Extremely good understanding of CNN, LSTM, GANs, Attention Models, Advanced Loss Functions, Hyper-convergence and batch processing.
What we Expect from you?
Analyzing the ML algorithms that could be used to solve a given problem and ranking them by their success probability.
Exploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real world.
Verifying data quality, and/or ensuring it via data cleaning.
Supervising the data acquisition process if more data is needed.
Defining validation strategies.
Defining the preprocessing or feature engineering to be done on a given dataset.
Defining data augmentation pipelines.
Training models with hyper-convergence strategies and tuning their hyperparameters.
Analyzing the errors of the model and designing strategies to overcome them.
Deploying models to production in C++.
Understanding business objectives and developing models that help to achieve them, along with metrics to track their progress.",4.1,"Inkers
4.1",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
399,Data Analyst,"No. of Positions : 1

Total Relevant Experience : Fresher - 3 Years

Education : BE (Computers / IT), MCA, M.Sc. or any equivalent degree

Job Description :
• Interpret data and analyse results using statistical techniques and algorithms.

• Understand the business requirements and provide proper solution.

• Perform basic pre-processing of data.

• Extract data and provide solution for implementing transformation and manipulation of data.

• Develop and provide support to various reporting processes.

• Create dashboards, graphs and visualizations from data.

• Should have ability to acquire knowledge on new things, especially about technological developments.",2.5,"Insigno Quipment
2.5",Ahmedabad,"Ahmedabad, India",51 to 200 employees,2002,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
400,DATA SCIENTIST,"DATA SCIENTIST

Be part of a small but rapidly growing, tier 1 VC-backed startup, and work on a product your friends are using.

Hinge is growing our data science and analytics team in our Manhattan office.

Examples of what the job entails

› For now, this is a very hands-dirty, engineering-flavored, product-driven position; the largest part of the job is helping to build a production recommender system at scale and in real time

› Constant investment in improving match quality on Hinge. Use all the tools in your toolbelt, the ideas in your head, academic and industry research, and ongoing experimentation to continually attack the problem of “Who do we match today?”

› Provide data-driven insights to help shape product, business and marketing direction

› Work closely with the rest of the engineering team to experiment with and build new features

› Analyze the influence of social connectedness on compatibility

› Design and maintain data ingest, cleaning, storage, and query systems

Our offer

› Work within a fast growing company with a young and informal culture.

› Flexible hours, an attractive salary with nice toppings.

› An awesome team of talented people to learn, work and play with.

› Thanks to well-defined, transparent wage and function trajectories you know what to expect of you career

› Kick-ass projects & international clients (we work with the big boys around here).

› Opportunities to grow together with the company, led by an ambitious team of directors.

› Space for personal growth with a personal budget for you to boost that growth.

› Fresh and varied meals every day, made by our very own chef ‘Tante Hilde’

Requirements:
› Are an expert in using standard development frameworks like Angular JS, Bootstrap, etc.

› You are proficient in using CI tools

› You are proficient in using load testing, functional testing, link testing and regression tools

You will stand out if

› You have a strong sense of what makes a good UI/UX

› You have experience with developing HIPAA compliant sites

› You have worked with FB and Google APIs

› You have experience with DevOps/SRE (though this is not going to be a part of your job)

› You have worked in an agile development environment and you follow agile development principles when you write code

› You have prior start-up experience -- particularly the ability to find one’s bearings in a fast-paced and fast-changing environment

How To Apply

Send an e-mail to jobs@venturew.com with your resume. We will get back to you as soon as possible.",2.6,"VentureWise
2.6",Hyderabad,"Madhāpur, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
401,Machine Learning Engineer - Customer Engagement,"Because you belong at Twilio.

The Who, What, Why and Where

Twilio seeks a Machine Learning Engineer to be a key leader in defining a new product offering at Twilio in the customer engagement space. The person in this role will be critical in shaping Twilio's data and intelligence strategy, which will empower our customers to create highly personalized communications and experiences for their contacts. Come be part of a team that's building a set of ML-driven APIs that deliver intelligent audience and personalization recommendations.

Who?

You have:
Personal traits: Curious, humble, team player
Professionally: Passionate, customer-obsessed, gets things done, highly collaborative, excellent communicator, and very comfortable with rapid change and uncertainty
You have hands on experience developing, deploying and monitoring a large scale machine learning model in production
Ph.D. or MS in Computer Science, Statistics, or related field
4+ years of applied ML experience in statistical and mathematical modeling such as supervised and unsupervised machine learning, deep learning, and/or reinforcement learning
You are familiar with concepts related to testing and maintaining models in production such as A/B testing, retraining, monitoring model performance
You've explored modern data storage, messaging, and processing tools (Kafka, Spark, Hadoop, Cassandra, etc.) and demonstrated experience designing and coding in big-data components such as DynamoDB or similar
You have a deep understanding of frameworks like - PyTorch, TensorFlow, or Keras, why and how these frameworks do what they do
Proficiency in Python is preferred. We will also consider strong quantitative candidates with a background in other programming languages
Experience working in an agile team environment
Big plus: Experience in AWS cloud computing
What?

You live the Twilio Magic values:
EMPOWER OTHERS: Be part of a small, high-impact and multi-talented engineering team. Show strong engagement in the team setting
WEAR THE CUSTOMER'S SHOES: Passion for and demonstrated track record of executing product opportunities deeply grounded in customer needs
DRAW THE OWL: Self-starter who can see the big picture and prioritize work to make the largest impact
BE BOLD: Help us take one of the world's most extensive communication data sets and transform it into leading-edge AI applications and products that solve meaningful customer problems
BE INCLUSIVE: Collaborating and brainstorming product ideas with product managers, data scientists and engineers
DON'T SETTLE: Experienced working at a massive scale with distributed, scalable systems, including making tradeoffs for consistency/availability
NO SHENANIGANS: Experience successfully applying machine learning to real-world problems
Why?

Today, Twilio powers the delivery of billions of the world's communications. Increasingly, we're hearing from our B2C customers that they're struggling to harness the massive amounts of valuable data they generate, much of which stems from the communications we help them send. We seek to uncover how Twilio can help customers utilize their valuable data to create unique, individualized experiences that their competitors can't replicate. We want to help them become more proactive (outcome-driven) than reactive (event-driven) in their customer engagements. We are a new initiative and team at Twilio that will function much like an internal start-up. If you want to shape the future of B2C Customer Engagement and Twilio, this project is for you!

Twilio is a company that is empowering the world's developers with modern communication in order to build better applications. Twilio is truly unique; we are a company committed to your growth, your learning, your development, and your entire employee experience. We only win when our employees succeed and we're dedicated to helping you develop your strengths. We have a cultural foundation built on diversity, inclusion, and innovation and we want you and your ideas to thrive at Twilio.

Where?

This position will be located in our office in Bangalore, India. You will enjoy our office perks: catered meals, snacks, game room, ergonomic desks, massages, Wednesday dinners, bi-weekly All Hands, and more. What you will also get to experience is a company that believes in small teams for maximum impact; seeks well-rounded talent to ensure a full perspective on our customers' experience, understands that this is a marathon, not a sprint; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves.

About us:

Millions of developers around the world have used Twilio to unlock the magic of communications to improve any human experience. Twilio has democratized communications channels like voice, text, chat, video and email by virtualizing the world's communications infrastructure through APIs that are simple enough for any developer to use, yet robust enough to power the world's most demanding applications. By making communications a part of every software developer's toolkit, Twilio is enabling innovators across every industry — from emerging leaders to the world's largest organizations — to reinvent how companies engage with their customers.",3.9,"Twilio
3.9",Bengaluru,"San Francisco, CA",1001 to 5000 employees,2008,Company - Public,Internet,Information Technology,₹100 to ₹500 billion (INR),-1
402,Principle Data Scientist - Business Consultant,"Profile Required

1. Should have good hands-on experience on Hyperion, SQL query, and RStudio

2.

Data manipulation and handling using Data Science and Machine Learning techniques

3. In-depth knowledge of SR 11-7 (US) and TRIM (Europe) guideline

4.

Whole-and-sole responsibility of Model ownership and review

5. Able to communicate independently with stakeholders

6.

Able to articulate model documentation and results complaint with SR 11-7 and TRIM guidelines

7. Experience in auto-generating codes and scripts to run models on regular interval

8.

He should be able to review the models

9. Should have experience in models like arima, linier regression, machine learning

10.

Should have good mentoring skills.

11. Hands on experience in back testing of models.

Why Join Us

“We are committed to creating a diverse environment and are proud to be an equal opportunity employer. All qualified applicants receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status”

Business Insight

Societe Generale Global Solution Centre (SG GSC), a 100% owned subsidiary of European banking major Societe Generale (SG), Our role and purpose is to enable the strategic vision of Societe Generale Group. We are doing this by pioneering cutting edge innovation from Design Thinking to Smart Automation & Artificial Intelligence, and applying it to banking.

SG Global Solution Centre provides services in the areas of Application Development and Maintenance, Infrastructure Management, Business Process Management, and Knowledge Process Management, to Societe Generale's business lines around the world.",3.5,"Société Générale
3.5",Bengaluru,"Paris, France",10000+ employees,1864,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"BNP Paribas, Natixis, Calyon Securities USA"
403,DATA SCIENTIST - Machine Learning / Artificial Intelligence (PhD Degree),"We are seeking a Data Scientist for one of the top reputed firms in Trivandrum/Thiruvananthapuram, who is smart and passionate, so should you be!

We are not looking for Ninjas but we are keen on hearing from you, who is settled to make a Great Mark in Career.

Our Client will help you achieve your Goals of Continuous Professional Development and Regular Career Progression sessions.

We think you fit the best, If :
You hold a PhD Degree (Ph.D / Doctor of Philosophy)
You have 1-8 years of solid experience in Machine Learning / Artificial Intelligence
You have strong hands-on experience in Computer Vision algorithms and Image/text/voice Processing
You can effectively multitask and operate problem in a team environment
You have the capability to interact with tremendous communication skills.
When you are onboard,
You will be responsible for Developing Technical and Functional Solutions for business ideas & concepts.
You will participate in every aspect of building and deploying creative new automation and machine learning algorithm for advanced text, voice, data analytics, knowledge graph creation.
You will be responsible to deliver significant and tangible results through innovative thinking and in-depth sector expertise.
Our Client embraces diversity and equal opportunity in a serious way. They are committed to building a team that represents a variety of backgrounds, perspectives, and skills.",3.7,"Roljobs Technology Services Pvt Ltd
3.7",Thiruvananthapuram,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
404,DATA ANALYST,"The Data Analyst needs to analyze technology trends to identify markets for future scientific product development or help in increasing sales through predictive analysis. He or she creates compelling reports using database-stored procedures and triggers. In addition, the Data Analyst needs to coordinate and communicate with the internal and external stakeholders. He or she also needs to understand the complete requirement of the project and document as per the company’s requirement.

Job Description:
The roles and responsibilities of the Data Analyst include the following:
Building SQL pivots and developing/manipulating data cubes
Interacting with different stakeholders
Performing requirement analysis to strategize further action points
Analyzing information to determine, recommend, and plan installation of a new system or modification of an existing system
Adhering to compliance procedures and internal/operational risk controls in accordance with any and all applicable regulatory standards, requirements, and policies
Desired Skills and Experience:
Education—BCA/MCA/BTech/BE
Experience—2-5 years of experience in data analysis and data mining
Experience in developing stored procedures, triggers, and complex SQL queries
Exposure to VB and .Net is mandatory, as the role involves building an engine to read data from MS Excel files and create SQL queries dynamically
Exposure to data warehousing/ETL
Should be a self-starter and capable of operating on minimal management oversight
Ability to work under pressure to meet agreed deadlines
Passion, energy, and enthusiasm to drive results",3.6,"Indegene
3.6",Bengaluru,"Bengaluru, India",1001 to 5000 employees,1998,Company - Private,Healthcare Services & Hospitals,Healthcare,₹10 to ₹50 billion (INR),"Accenture, Cognizant Technology Solutions, Tata Consultancy Services"
405,Applied Scientist Intern,"Excited by Big Data, Machine Learning and Predictive Software? Interested in creating new state-of-the-art solutions using Machine Learning and Data Mining techniques on Terabytes of Data?
At Amazon, we are developing state-of-the-art large-scale Machine Learning Services and Applications on the Cloud involving Terabytes of data. We work on applying predictive technology to a wide spectrum of problems in areas such as Amazon Retail, Seller Services, Customer Service, Alexa, Chatbots and so on. We are looking for talented and experienced Machine Learning Scientists (Masters/Ph.D. in a related area preferred) who can apply innovative Machine Learning techniques to real-world e-Commerce problems. You will get to work in a team dedicated to advancing Machine Learning technology at Amazon and converting it to business-impacting solutions.
Major responsibilities
- Use machine learning, data mining and statistical techniques to create new, scalable solutions for business problems
- Analyze and extract relevant information from large amounts of Amazons historical business data to help automate and optimize key processes
- Design, develop and evaluate highly innovative models for predictive learning
- Establish scalable, efficient, automated processes for large scale data analyses model development, model validation and model implementation
- Research and implement novel machine learning and statistical approaches




Basic Qualifications

- A Masters and/or PhD in Computer Science, Machine Learning, Operational research, Statistics or in a highly quantitative field
- Experience in predictive modelling and analysis, predictive software development
- Strong problem-solving ability
- Good skills with Java/Scala or C++, Perl/Python (or similar scripting language)
- Experience in using R, Matlab, or any other statistical software
- Strong communication and data presentation skills



Preferred Qualifications

- Experience handling gigabyte and terabyte size datasets
- Experience working with distributed systems and grid computing
- Knowledge of the latest and state of the art ML technology
- Publications or presentation in recognized Machine Learning and Data Mining journals/conferences",4.2,"Amazon
4.2",Hyderabad,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
406,Senior Data Engineer - ETL,"A professional at this position, works with the business users, technologists, analyzes systems, and gathers how data is used in them. Determines methods and procedures to analyze source data, extract - transform - load (ETL) the data into downstream environment, improve data quality, and make the data usable for consumption. Researches, designs, develops, configures, integrates, tests and maintains existing and new data and analytical solutions including databases through integration of technical and business requirements. Data and analytical solutions include ERP systems, open source software, custom home-grown systems, and 3rd party software. Provides required documentation and participates in architecture reviews to ensure that the solutions comply with standards and use approved technologies. Typical customers are HP Enterprise's end users and various functional areas such as Supply Chain, Research and Development, Marketing, Finance, a business, or the company.

Responsibilities:
Participates as a senior member of data development team or cross functional teams; and may lead a project/ program development team; Performs analysis of functional and business requirements.
Completes data analysis, ETL, batch and real-time integration codes to implement solutions.
Develops data integration and exploratory data analysis codes independently; participates and leads code reviews.
Works with business and system teams to design, prepare and automate test cases.
Applies in-depth or broad technical knowledge to maintain data engineering function. Performs solution design. Applies the company, open source, and 3rd party technologies to highly complex infrastructure and software solutions.
Education and Experience Required:
Technical Bachelor's degree or equivalent experience and a minimum of 6 years related experience or a Master's degree and a minimum of 4 years of experience.
Knowledge and Skills:
3 or more years of experience in data integration in batch and real-time environments
3 or more years of experience writing SQL and ETL code(such as Informatica/ IBM; and databases like SqlServer/ Oracle; and data quality tools.
Knowledge of open source software development tools such as Kafka and Python.
Experience of multiple full release cycles. Understanding of modern software development methodologies.
Understanding of Software Test methodologies, and testing tools.
General Project Management.
Customer/ Vendor Management.
Good verbal and written communication skills; ability to work effectively in a team of data and analytics technologists and business users
#GlobalITIN

1066616",4.2,"Hewlett Packard Enterprise
4.2",Bengaluru,"Palo Alto, CA",10000+ employees,2015,Company - Public,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,"Oracle, Accenture"
407,Principal Data Scientist - Product Development (Global AI Accelerator,"Date: Mar 30, 2020

Ericsson Overview:

Ericsson is worlds leading provider of communications technology and services. Our offerings include services, consulting, software and infrastructure within Information and Communications Technology.

Using innovation to empower people, business and society, Ericsson is working towards the Networked Society: a world connected in real time that will open up opportunities to create freedom, transform society and drive solutions to some of our planets greatest challenges.

We are truly a global company, operating across borders in over 180 countries, offering a diverse, performance-driven culture and an innovative and engaging environment. As an Ericsson employee, you will have freedom to think big and the support to turn ideas into achievements. Continuous learning and growth opportunities allow you to acquire the knowledge and skills necessary to progress and reach your career goals. We invite you to join our team.

Exciting Opportunity:

It will be practically impossible for human brains to understand how to run and optimize next generation of wireless networks, i.e., 5G network with distributed edge compute, that will drive economic and social transformation for all aspects of society. Machine Learning (ML) and other Artificial Intelligence (AI) technologies will be vital for us to handle this opportunity. We are setting up a Global AI Accelerator (GAIA) in the US, Sweden and India, with 300 experts, to fast-track our strategy execution.

Machine Intelligence, the combination of Machine Learning and other Artificial Intelligence technologies is what Ericsson uses to drive thought leadership to automate and transform Ericsson offerings and operations. MI is also a key competence for to enable new and emerging business. This includes development of models, frameworks and infrastructure where we in our advancements push the technology frontiers. We engage in both academic and industry collaborations and drive the digitalization of Ericsson and the Industry by developing state of the art solutions that simplify and automate processes in our products and services and build new value through data insights.

Ericsson is now looking for Principal Data Scientists to significantly expand its global team for AI acceleration for our group in Bangalore and Chennai.

Do you have in depth understanding of Machine Learning and AI technologies?

Do you want to apply and extend those skills to solve real complex problems with high societal impact; going beyond ML/AI for consumption and advertising?

Then, you do want to join Ericssons global team of Engineers/Scientists pushing the technology frontiers to automate, simplify and add new value through large and complex data.

Role Summary:

As a Principal Data Scientist, you shall build and deploy AI models into production with focus on scaling, monitoring and performance. You shall build effective AI models using stacking/ensemble techniques; and provide prediction explainability and prescriptive capability in ML models. You shall work with business stakeholders to define and formulate the right business problem.

Your knowledge and experience in Data Science methodologies will be applied to solve challenging real-world problems as part of a highly dynamic and global team. You will work in a highly collaborative environment where you communicate and plan tasks and ideas. You will be working on high impact initiatives with other DS in Machine Intelligence to drive growth and economic profitability for Ericsson and its customers by accelerating current Ericsson offerings. Your contribution will also help to create new offerings in the areas of MI driven 4G and 5G network, distributed cloud, IoT and other emerging businesses.

Key Responsibilities:
Lead multiple AI/ML projects for a certain product/business
Manage communication, planning, collaboration and feedback loops with business stakeholders.
Work with huge datasets including petabytes of 4G/5G-networks, IoT and exogenous data
Identify the model monitoring strategy in prod and retraining plan.
Define data sourcing, access and pipeline design. Identify and plan for sourcing external data.
Model the business problem statement into AI/ML problem.
Define the Data sourcing strategy and works with stakeholders to procure data. Contribute to IP creation for Ericsson in AI/ML
Define/Design data storage and retrieval strategies from various kind of data sources such as NOSQL Databases. Design data pipelines and flow strategies.
Design APIs for AI/ML models with focus on business, modularity and versioning; and build standard/canonical data models by combining multiple data sources.
Lead functional and technical analysis within Ericsson businesses and for strategic customers to understand MI-driven business needs and opportunities
Contribute to rapid and iterative development of validated minimum viable solutions addressing these needs. This includes working with petabytes of 4G/5G-networks, IoT and exogenous data, and proposing/selecting/testing predictive models, recommendation engines, anomaly detection systems, statistical models, deep learning, reinforcement learning and other machine learning systems
Lead studies and creative usage of new and/or existing data sources. Work with Data Architects to leverage existing data models and build new ones as needed.
Collaborate with product development teams and partners in Ericsson Businesses to industrialize machine learning models and solutions as part of Ericsson offerings including providing source code, workflows and documents
Work with new technologies and be the ambassador for them in MI Communities within Ericsson, nurturing the communities and mentoring junior data scientists.
Provide MI Competence build-up in Ericsson Businesses and Customer Serving Units
Develop new and apply/extend existing, concepts, methodologies, techniques for cross functional initiatives
Engage with external ecosystem (academia, technology leaders, open source etc.) to develop the skills and technology portfolio for MIs needs
Present and be prominent in MI related forums and conferences, e.g., publishing patents, presenting papers, organizing sessions etc.
Key Qualifications:
Bachelors/Masters/Ph.D. in Computer Science, Data Science, Artificial Intelligence, Machine Learning, Electrical Engineering or related disciplines from any of the reputed institutes. First Class, preferably with Distinction.
Applied experience: 8+ years of ML and/or AI production level experience; and an overall industry experience of about 15+ years.
Proven skills of implementing a variety of Machine Learning techniques
Strong Programming skills (R/Python) with proficiency in at least one
Strong grounding in mathematics, probability, statistics needed for data analysis and experiments
Proven ability of leading AI/ML projects end-to-end with complete ownership
Proven skills in building AI/ML based solutions using a variety of frameworks such as Python, R, H2O, Keras, TensorFlow, Spark ML etc.
Experience in implementing new algorithms and methodologies from leading open source initiatives and research papers
Extensive experience in model development and life-cycle-management in one or more industry/application domain
Experience in building models using semi-structured and unstructured data
Hands-on experience in designing and building AI models using Deep Neural Networks for applicable scenarios
Experience in using ensembles and stacking techniques to solve complex ML problems
Able to build and deploy AI models into production with focus on scaling, monitoring and performance
Knowledge of building explainable models (XAI) and prescriptive analytics
Experience with working in Big Data technologies such as Hadoop, Cassandra etc.
Able to Define/Design data storage and retrieval strategies from various kind of data sources such as NOSQL DBs
Knowledge of designing data pipelines and flow strategies
Familiarity with data pipelining frameworks such as Air Flow, AWS Sagemaker, etc. would be a plus
Able to design APIs for AI/ML models with focus on business, modularity and versioning
Experience in writing and presenting white papers, journal articles and technical blogs on the results
Soft Skills:
Good communication skills in written and spoken English
Great Team worker and collaborator
Creativity and ability to formulate problems and solve them independently
Self-driven and ability to work through abstraction
Ability to build and nurture internal and external communities
Additional Requirements:
Certifying MI MOOCS, a plus
Applications/Domain-knowledge in Telecommunication and/or IoT, a plus.
Experience with data visualization and dashboard creation is a plus
Knowledge of Cognitive models is a plus
Ability to work independently with high energy, enthusiasm and persistence
Experience in partnering and collaborative co-creation, i.e., working with complex multiple stakeholder business units, global customers, technology and other ecosystem partners in a multi-culture, global matrix organization with sensitivity and persistence
Ericsson provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetics.

Ericsson complies with applicable country, state and all local laws governing nondiscrimination in employment in every location across the world in which the company has facilities. In addition, Ericsson supports the UN Guiding Principles for Business and Human Rights and the United Nations Global Compact.

This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, training and development.

Ericsson expressly prohibits any form of workplace harassment based on race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetic information.

Primary country and city: India (IN) || || Bangalore || R&D",3.9,"Ericsson-Worldwide
3.9",Bengaluru,"Stockholm, Sweden",10000+ employees,1876,Company - Public,Telecommunications Services,Telecommunications,₹500+ billion (INR),"Huawei Technologies, IBM, Cisco Systems"
408,Senior Data Scientist,"Location : Pune
AlgoAnalytics is looking for a Senior Data Scientist who has the passion for hardcore ML and AI work. Minimum 3 years of experience in AI/MI including Deep Learning is required. Deep understanding & proficiency in developing Deep Learning models will be an added advantage. The candidate is expected to manage multiple data science projects from technical as well delivery perspective.

Role and Responsibility :
Transform business problems into data problems and identify relevant and meaningful solutions
Prepare proposals for client projects: detailed description about technical aspects of the proposals such as approaches/algorithms to be tried out as a solution, describing input/output interfaces, tools and technologies to be used/explored, efforts estimation, etc.
Attending client calls in the initial phase of the projects: to understand the problem and discuss approaches, data availability, issues/questions from our side, etc.
Creating PPTs (e.g. to include technical contents)
Designing a solution (for internal or client projects) from technology and algorithm perspective
Research and build machine-learning models
Understanding and implementing recent research work/papers in deep learning
Contribute to the development of research that is based on key insights and findings from the studies
Project management (both client-facing as well as team-facing)
Troubleshooting for any project (related to machine learning / programming / technology) whenever required
Identifying resources for various tasks like mentoring, hiring, initiatives, tech support, project management, skill management, etc.
Provide guidance and training to team members and less experienced data scientists
Participate in management level efforts if and when required
Qualifications :
3+ years of experience in Machine Learning
Bachelors/Masters in Computer Engineering/Science.
Bachelors/Masters in Engineering/Mathematics/Statistics with sound knowledge of programming and computer concepts.
Skills :
Strong Python/ programming skills
Good conceptual understanding of Machine Learning/Deep Learning/Natural Language Processing
Strong verbal and written communication skills.
Should be able to manage team, meet project deadlines and interface with clients.
Should be able to work across different domains and quickly ramp up the business processes & flows & translate business problems into the data solutions
If you have the above skills, desire to keep learning, and would like to grow in a dynamic environment, drop your cv to hr@algoanalytics.com",4.3,"ALGOANALYTICS
4.3",Pune,"Pune, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
409,Data Scientist II,"Company Description

ISO, a Verisk business, has been a leading source of information about property/casualty insurance risk since 1971. For a broad spectrum of commercial and personal lines of insurance, ISO provides statistical, actuarial, underwriting, and claims information and analytics; compliance and fraud identification tools; policy language; information about specific locations; and technical services. ISO serves insurers, reinsurers, agents and brokers, insurance regulators, risk managers, and other participants in the property/casualty insurance marketplace. To learn more about ISO please visit us at: www.verisk.com/iso. We are proud to be a part of the Verisk family of companies!

At the heart of what we do is help clients manage risk. Verisk (Nasdaq: VRSK) provides data and insights to our customers in insurance, energy and the financial services markets so they can make faster and more informed decisions.

Our global team uses AI, machine learning, automation, and other emerging technologies to collect and analyze billions of records. We provide advanced decision-support to prevent credit, lending, and cyber risks. In addition, we monitor and advise companies on complex global matters such as climate change, catastrophes, and geopolitical issues.

But why we do our work is what sets us apart. It stems from a commitment to making the world better, safer and stronger.

It’s the reason Verisk is part of the UN Global Compact sustainability initiative. It’s why we made a commitment to balancing 100 percent of our carbon emissions. It’s the aim of our “returnship” program for experienced professionals rejoining the workforce after time away. And, it’s what drives our annual Innovation Day, where we identify our next first-to-market innovations to solve our customers’ problems.

At its core, Verisk uses data to minimize risk and maximize value. But far bigger, is why we do what we do.

At Verisk you can build an exciting career with meaningful work; create positive and lasting impact on business; and find the support, coaching, and training you need to advance your career. We’ve been recognized by Forbes as a World’s Best Employer and a Best Employer for Women, testaments to our culture of engagement and the value we place on an inclusive and diverse workforce.

Job Description

Develop and maintain a data model in Cloud that contains the major entities and attributes which represent the ideal state of content and structure for insurance claims.
Our focus would be on any transformed/engineered/normalized views that would create efficiencies and provide value added transformed attributes for data science teams to consume.
Identify new or existing raw sources of information to better populate our conceptual data model.
Enhance data assets by applying new methods and algorithms to raw data.
Develop expertise in each data asset to become the go-to resource for data consumers/users on both raw data and transformed data.
Explore and deploy right tools for exploratory, Metadata and Master Data Management, data quality and reporting and data process flow management.
Creating data pipelines to support analytic products in both development and deployment.
Create highly reusable code modules and packages that can be leveraged across the data pipelines.
Develop and maintain data dictionaries for governance of published data sources.
Commercialize enhanced data assets.

Qualifications

Experience in columnar relational data stores and NoSQL technologies.
Experience with big data tools such as Spark etc. as well as strong SQL skills.
Experience delivering data pipelines and managing resulting data stores using managed cloud services. (like AWS Services)
Proficient understanding of distributed computing principles.
Experience with modern data pipelines, data streaming, and real time analytics using tools such as Apache Kafka, AWS kinesis, Spark Streaming, ElasticSearch, or similar tools,
ETL or Pipeline design/implementation with Large Distributed Databases. (Spark/Scala preferred)
Outstanding interpersonal skills.
BS/MS/PhD in Computer Science or a related field. (ideal)
Strong CS fundamentals, problem-solving skills and software engineering skills.
6+ years industry experience in data engineering and/or software development.
Experience in a hands-on, data centric role with data engineering, streaming, or warehousing.
Ability to communicate effectively with stakeholders.
A strong ability to understand and organize data from various sources.
Ability to identify and resolve performance and data quality issues.

Additional Information

Verisk Analytics is an equal opportunity employer.

All members of the Verisk Analytics family of companies are equal opportunity employers. We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and/or expression, sexual orientation, veteran's status, age or disability.

http://www.verisk.com/careers.html

Unsolicited resumes sent to Verisk, including unsolicited resumes sent to a Verisk business mailing address, fax machine or email address, or directly to Verisk employees, will be considered Verisk property. Verisk will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.

Consumer Privacy Notice",4.3,"ISO
4.3",Hyderabad,"Geneva, Switzerland",51 to 200 employees,1946,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
410,Senior Data Scientist (Text Mining),"Title Senior Data Scientist (Text Mining)

Category IT

Education Graduate or Post Graduate

Experience Relevant Work experience of 3 to 5 Years

Location Bangalore


Details

3 – 5 years of industry or research experience in text mining.

Lead and engage a team of engineers and curators to deliver text mining solutions to external or internal customers.

Lead internal R&D projects to envisage the development of new products and services.

Experience or thorough understanding of named entity recognition, semantic indexing and retrieval, text classification, relationship extraction, and sentiment analysis.

Keep up-to-date with scientific and business developments in the market.

Experience in working with text and data analytic platforms such as OpenNLP, LingPipe, UIMA, Solr, Lucene, MALLET, KNIME and WEKA.

Exposure to text mining and AI APIs like Alchemy, TensorFlow and Google Cloud Natural Language AP.

Experience or thorough understanding of applications of machine learning techniques such as CRFs, SVM.

Exposure to Semantic Web standards from W3C: RDF, RDFS, OWL, SPARQL etc.,

Large scale data visualizations on the lines of d3js, Graphviz.

Good understanding of biomedical databases, ontologies, and controlled vocabularies is a plus.

Good communication, writing and presentation skills.

Qualification

Post-Doc, PhD or Masters in Computer Science, Biomedical Informatics, Natural Language Processing, Bioinformatics, Artificial Intelligence or related disciplines.

Please submit your application for the above opening(s) to hiring.technology@molecularconnections.com.",2.9,"Molecular Connections
2.9",Bengaluru,"Bengaluru, India",1001 to 5000 employees,2001,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
411,Machine Learning Engineer,"Job Profile:
Work with Business Analysts and SMEs to develop analytics across domains
Work with CTO and define the optimal software architecture for the ML models, and their integration with the rest of the enterprise architecture
Hands-on implementation of the ML models, using Python as the primary language
Lead junior ML Developers if needed
Interaction with internal as well as external stakeholders

Job Location: Pune

Education:
Consistent and good academics
BE / BTech / ME / MTech – preferably in Computer Science
MSc Maths / Stats can also be considered

Experience: 5 – 8 years

Desired Skills:
Minimum 2 years’ experience with machine learning models and algorithms (linear and non-linear regressions, known and unknown correlations etc.)
Minimum 2 years’ experience with Python
Exposure to modern web stacks such as NoSQL, REST etc.
Experience of working on Agile
Excellent communication skills
Pratiti Technologies

Pratiti was founded in 2015 to help global customers realize their innovations faster. Cloud technology, Artificial Intelligence, IoT and Mobility technologies driving disruptions in all businesses globally. Pratiti is becoming a partner of choice for technology partnership for outsourced product development (OPD) for Startups as well as Enterprises.",4.1,"Pratiti Technologies
4.1",Pune,"Pune, India",1 to 50 employees,2015,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
412,Data Engineering - Partner,"We, at TheMathCompany, enable data analytics transformations for Fortune 500 organizations across the world. We enable our clients to build core capabilities that set them on a path to achieve analytics self-sufficiency.
Over the last three years, we have been consistently doubling in size year-on-year with 300 (and counting…) Data Scientists & Engineers, Consultants and Visualization experts
TheMathCompany has won multiple awards recognizing us as a global Data and Analytics firm – We ranked #23 in the Deloitte Technology Fast 500™ Asia Pacific 2019 and #2 in Deloitte Technology Fast 50™ India 2019.
35+ Fortune 500 Companies, from almost 10 different industries and countries, trust us to power their analytical transformation.
WHAT’S IN IT FOR YOU:

An exciting opportunity to be a part of the growth journey of one of the fastest growing AI & ML firms – scope for experimentation, the big & small victories, the learnings and everything in between
Our in-house learning and development cell - Co.ach, run by world-class data analytics experts, enables our folks to stay up to date with the latest trends and technologies
At TheMathCompany, we insist on a culture that provides us all with enough flexibility to accommodate our personal lives without compromising on the dream of building a great company
We are changing the way companies go about executing enterprise-wide data engineering and data science initiatives, and we’d love to have you grow with us on this journey


ROLE DESCRIPTION

As a data engineer, you’ll have an opportunity to work on the universe of data and solve some very interesting problems by creating and maintaining scalable data pipelines dealing with petabytes of data. All our projects entail working on cutting edge technologies, petabyte scale data processing systems, data warehouses and data lakes to help manage the ever-growing information needs of our customers.

The responsibilities are detailed as below:
Experience in understanding and translating data, analytic requirements and functional needs into technical requirements while working with global customers
Build and maintain data pipelines to support large scale data management in alignment with data strategy and data processing standards
Experience in Database programming using multiple flavor of SQL
Deploy scalable data pipelines for analytical needs
Experience in Big Data ecosystem - on-prem (Hortonworks/MapR) or Cloud (Dataproc/EMR/HDInsight)
Worked on query languages/tools such as Hadoop, Pig, SQL, Hive, Sqoop and SparkSQL.
Experience in any orchestration tool such as Airflow/Oozie for scheduling pipelines
Exposure to latest cloud ETL tools such as Glue/ADF/Dataflow
Understand and execute IN memory distributed computing frameworks like Spark (and/or DataBricks) and its parameter tuning, writing optimized queries in Spark
Hands-on experience in using Spark Streaming, Kafka and Hbase
Experience in latest cloud ETL tools such as Glue/ADF/Dataflow
Experience in any orchestration tool such as Airflow/Oozie
Experience working in an Agile/Scrum development process
REQUIRED QUALIFICATIONS

We are looking for individuals who are curious, excited about learning, and navigating through the uncertainties and complexities that are associated with growing a company. Some qualifications that we think would help you thrive in this role are:
BE/BS/MTech/MS in computer science or equivalent work experience.
8+ years of experience in building data processing applications using Hadoop, Spark and NoSQL DB and Hadoop streaming
PREFERRED QUALIFICATIONS

Expertise in data structures, distributed computing, manipulating and analyzing complex high-volume data from variety of internal and external sources
Experience in developing ETL designs and data models for structured/ unstructured and streaming data sources
Experience in building large scale data pipelines in batch and real time mode
Experience in data migration to cloud (AWS/GCP/Azure)
Proficient in programming language such as Python/Scala
Good understanding of in relational/dimensional modelling and ETL concepts
Good understanding of data analysis techniques
Solid working knowledge of SQL and scripting
Understanding of any reporting tools such as Tableau, Qlikview or PowerBI",4.2,"TheMathCompany
4.2",Bengaluru,"Bengaluru, India",201 to 500 employees,2016,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
413,Sr Data Analyst-ETL,"Join a team recognized for leadership, innovation and diversity


Sr Data Analyst - ETL

JOB DETAILS:

Position: Sr Data Analyst - ETL

Experience: 8+ years

Key Job Responsibilities

· Lead large Data Management implementations for full SDLC lifecycle using Informatica Power Center, IDQ etc.,

· Provide Subject Matter Expertise on data architecture and data integration implementation for Enterprise Architecture

· Design and Architect Data Integration solutions for Enterprise systems including but not limited to Oracle, SAP, HANA, Snowflake, SQL Server, Hive, Flat files, Teradata, PostgreSQL, IBM DB2

· Point of Contact for Data management ETL strategy, Process, Design, Architecture and the implementation plan

· Participate in requirements elicitation, Performance tuning of Application Database and Data Management platform

· Collaborate with various technical teams and business users for Development, QA and Operations Support

· System development and defining architectural framework standards processes in the ETL functions

· Architecture selection criteria (Alternate design, parameter selection, evaluation methods etc.)

· Deliver business value through Right and Fast partnership

· Join a high-performing team and distinguished talent pipeline

· Build strong relationships with leadership to effectively deliver contemporary data analytics solutions and contribute directly to business success

· Implement error and exception handling, auditing, data purging and restoration in ETL jobs.

· Assisting deployment teams with migrating ETL jobs to higher environments.

· Partners with Business/Requirement and Analyst Lead

· Understand overall enterprise architecture and technical requirements for building up a data management platform.

Must have

· Overall IT experience of 8+ years in the capacity of ETL Architect, implementation and technical responsibilities

· Very strong implementation experience in Data Integration tools specialized with Informatica Power Center and IDQ suite of tools

· Experience delivering Robust and Scalable Enterprise ETL solutions

· Good Knowledge of ETL and Data Quality Concepts, knowledge of basic concepts of Java PL SQL. Awareness of MDM trends MDM Concepts and other MDM tools

· Ability to create and analyze unit and system test cases. To be able to debug ETL workflows, SQL code snippets and defect fixing.

· Must possess a strong background in database systems like Oracle, SQL Server, DB2 or Teradata with SQL scripting.

· Deep knowledge in Data Integration, Data Quality, Metadata Management and Data Governance.

· Experience in Requirement Analysis. Strong ability to analyze user requirements into technical solutions as per the specifications.

· Knowledge on Data Modeling / Architecture

· Proven experience working with Service Oriented and Event Driven Architectures SOA EDA JMS messaging SOAP and RESTful services

· Ability to predict and quantify technical risks in the project

· Analytical and communication skills (both verbal and written)

· Ability to architect and design, define standards and follow industry best practices for ETL development.

· Hands-on experience in Informatica Power Center, Big Data technologies and Cloud implementations.

· Experience in creating ETL jobs with delta detection, SCD implementations, bulk loads, real-time integration.

We Value

· B.E in Computer Science or equivalent

· Expertise in the concepts of data warehousing and dimensional modeling.

· Critical Thinking, excellent Communication, Detail Oriented, Creative and Adaptive.

· Ability to work independently and in a team with good analytical, debugging and problem solving skills

· Strong communication skills, both oral and written, with the ability to convey thoughts and ideas clearly.

· Good experience and knowledge on Agile methodology.

· Excellent communication and interpersonal skills.

""CORPIT2020""

""

Additional Information
JOB ID: HRD94073
Category: Information Technology
Location: Devarabisanahalli Village, KR Varturhobli,,East Taluk - Phase I,Bangalore,KARNATAKA,560103,India
Exempt
Business Services",3.8,"Honeywell
3.8",Bengaluru,"Charlotte, NC",10000+ employees,1885,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"GE, Johnson Controls, United Technologies"
414,Data Scientist & Business Development,"We are looking for individuals who can turn data into information, information into insights and insights into business decisions.

Key Responsibilities:
You will be working on unique data consisting of around 1000 events per day. You will continuously drive data culture and evangelize use of data science in all possible aspects of business.
You will make sure that product is having end to end data points for partners and all stake holders to required information to grow the business.
Researching and developing algorithms/ models/ strategies for personalizing the product. Make sure developed algorithms drive significant lift in reality and refine as required
Help building ML/predictive framework to draw insights at scale for different aspects of business, for example understanding drivers of various customer behaviour or understanding points of failure
Develop strategies for effective data analysis and reporting
Help build and enhance sophisticated algorithms and various analytical tools to transform raw data into actionable business insight
Preparation and analysis of performance reports
Monitor the success of the clients and advise them by applying industry knowledge to interpret data and improve performance
Keep abreast of industry news and trends

Knowledge, Skills & Experience:
Excellent problem solving skills, with ability to communicate even complex ideas in succinct manner
Proven experience as a data scientist or data analyst
Strong work ethics like sense of collaboration and ownership, result orientation, being team player
Understanding of Python, Tableau, Power Bi, related tools used from data handling to modelling to implementation is preferred
Master’ or equivalent degree in Computer Science, Mathematics, Statistics and Information Systems.
Knowledge in SQL & Java script is a huge plus
Ability to display complex quantitative data in a simple, intuitive format and to present findings in a clear and concise manner
Understanding in machine learning, general statistics and data science principles",4.7,"Grid Logic Software Private Limited
4.7",Hyderabad,"Gurgaon, India",501 to 1000 employees,2010,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
415,Data Scientist II,"Company Description

ISO, a Verisk business, has been a leading source of information about property/casualty insurance risk since 1971. For a broad spectrum of commercial and personal lines of insurance, ISO provides statistical, actuarial, underwriting, and claims information and analytics; compliance and fraud identification tools; policy language; information about specific locations; and technical services. ISO serves insurers, reinsurers, agents and brokers, insurance regulators, risk managers, and other participants in the property/casualty insurance marketplace. To learn more about ISO please visit us at: www.verisk.com/iso. We are proud to be a part of the Verisk family of companies!

At the heart of what we do is help clients manage risk. Verisk (Nasdaq: VRSK) provides data and insights to our customers in insurance, energy and the financial services markets so they can make faster and more informed decisions.

Our global team uses AI, machine learning, automation, and other emerging technologies to collect and analyze billions of records. We provide advanced decision-support to prevent credit, lending, and cyber risks. In addition, we monitor and advise companies on complex global matters such as climate change, catastrophes, and geopolitical issues.

But why we do our work is what sets us apart. It stems from a commitment to making the world better, safer and stronger.

It’s the reason Verisk is part of the UN Global Compact sustainability initiative. It’s why we made a commitment to balancing 100 percent of our carbon emissions. It’s the aim of our “returnship” program for experienced professionals rejoining the workforce after time away. And, it’s what drives our annual Innovation Day, where we identify our next first-to-market innovations to solve our customers’ problems.

At its core, Verisk uses data to minimize risk and maximize value. But far bigger, is why we do what we do.

At Verisk you can build an exciting career with meaningful work; create positive and lasting impact on business; and find the support, coaching, and training you need to advance your career. We’ve been recognized by Forbes as a World’s Best Employer and a Best Employer for Women, testaments to our culture of engagement and the value we place on an inclusive and diverse workforce.

Job Description
Develop and maintain a data model in Cloud that contains the major entities and attributes which represent the ideal state of content and structure for insurance claims.
Our focus would be on any transformed/engineered/normalized views that would create efficiencies and provide value added transformed attributes for data science teams to consume.
Identify new or existing raw sources of information to better populate our conceptual data model.
Enhance data assets by applying new methods and algorithms to raw data.
Develop expertise in each data asset to become the go-to resource for data consumers/users on both raw data and transformed data.
Explore and deploy right tools for exploratory, Metadata and Master Data Management, data quality and reporting and data process flow management.
Creating data pipelines to support analytic products in both development and deployment.
Create highly reusable code modules and packages that can be leveraged across the data pipelines.
Develop and maintain data dictionaries for governance of published data sources.
Commercialize enhanced data assets.
Qualifications
Experience in columnar relational data stores and NoSQL technologies.
Experience with big data tools such as Spark etc. as well as strong SQL skills.
Experience delivering data pipelines and managing resulting data stores using managed cloud services. (like AWS Services)
Proficient understanding of distributed computing principles.
Experience with modern data pipelines, data streaming, and real time analytics using tools such as Apache Kafka, AWS kinesis, Spark Streaming, ElasticSearch, or similar tools,
ETL or Pipeline design/implementation with Large Distributed Databases. (Spark/Scala preferred)
Outstanding interpersonal skills.
BS/MS/PhD in Computer Science or a related field. (ideal)
Strong CS fundamentals, problem-solving skills and software engineering skills.
6+ years industry experience in data engineering and/or software development.
Experience in a hands-on, data centric role with data engineering, streaming, or warehousing.
Ability to communicate effectively with stakeholders.
A strong ability to understand and organize data from various sources.
Ability to identify and resolve performance and data quality issues.
Additional Information

Verisk Analytics is an equal opportunity employer.

All members of the Verisk Analytics family of companies are equal opportunity employers. We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and/or expression, sexual orientation, veteran's status, age or disability.

http://www.verisk.com/careers.html

Unsolicited resumes sent to Verisk, including unsolicited resumes sent to a Verisk business mailing address, fax machine or email address, or directly to Verisk employees, will be considered Verisk property. Verisk will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.

Consumer Privacy Notice",3.4,"Insurance Services Office
3.4",Hyderabad,"Jersey City, NJ",5001 to 10000 employees,1971,Subsidiary or Business Segment,Insurance Operators,Insurance,₹50 to ₹100 billion (INR),LexisNexis Risk Solutions
416,Data Science Engineer,"Designation : Data Science Engineer

Experience : 3-6 yrs

Location : Bangalore

Why should you join us?

Work in an exciting start-up that builds top notch product and services

Accelerate your career in a fast-paced, open, non-hierarchical working environment

In addition to building a career in Testing you will ideally obtain in-depth understanding of relevant areas such as technology platforms, engineering, network, machine learning, analytics and/or data mining

What you will be doing?

Responsible for all engineering aspects of building large scale data science-based solutions and their deployment and productionization

Work closely with data scientists, platform engineers, architects, PMs and other stakeholders who would be involved in all stages of the development cycle in defining data management strategy to support building of solutions to business problems. You would be required to identify data sources, create a plan for data collection, storage, and consumption. Work with different stakeholders, participate in design and provide insights and guidance on database technology and data modeling best practices

Required to work with heterogeneous data sources, have knowledge of big data and distributed technologies like Hadoop, Spark etc. and cloud infrastructures like AWS and the like. Involved in building the necessary data pipelines to make the data available for downstream use

Required to develop, deploy and operate large scale data storage and processing solutions using different distributed and cloud-based platforms for storing data (e.g. Data Lakes, Hadoop, Hbase, Cassandra, MongoDB, DynamoDB, others)

Build data warehouse solutions, work with data models, and build large scale data pipelines, required to design, build and operate relational and non-relational databases (SQL/NoSQL), graph databases, integrate them with modern data warehouse solutions and ensure effective ETL, OLTP, and OLAP for large datasets

Responsible for the performance and scaling of data science algorithms, packaging of data science solutions and their deployment to production. This includes pre-deployment activities like version control, code reviews, and software engineering practices. Also includes deployment related engineering skills required to make the model available in the engineering platform. Knowledge of services, containers, docker, Sagemaker and other related technologies. Also involves building of pipelines for continuous model monitoring - model evaluation - model retraining

You would also have opportunity and would be encouraged for thought leadership and contributing your work to the external technical and research communities

Who are we looking for?

MS/M.Tech or BE with 3+years of experience in Data engineering, ML engineering, Big data, cloud technologies like AWS, distributed technologies like Spark

Good knowledge of Big Data stack: Spark, Cassandra, Map-Reduce, S3

Experience of working with diverse data sources and building data pipelines

Experience of working on production-grade machine learningbased solutions would be a plus

Experience with graph data modelling and graph databases like Neo4j would be plus

Broad knowledge of data science and machine learning and experience with scaling up machine learning algorithms

Experience with building services, docker images, and technologies like Sagemaker and MLFlow

Good communication skills and ability to work with stakeholders across business, PM, and Engineering

Excitement & curiosity around data in general. “Hacker” attitude with “go-getter” mind-set

Very good coding skills in any of these languages: Python, Java, C and machine learning libraries like scipy, numpy, pyspark, tensorflow etc.
Ready to join Clustr?
If you fit the bill, email your resume to careers@clustr.co.in with the position name in subject line",4.5,"Clustr
4.5",Bengaluru,"Bengaluru, India",1 to 50 employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
417,Technology & Cloud _ Data Engineer - Senior Associate,"Line of Service

Advisory

Industry/Sector

Not Applicable

Specialism

Application & Emerging Technology

Management Level

Senior Associate

Job Description & Summary

A career in our Advisory Acceleration Centre is the natural extension of PwC’s leading class global delivery capabilities. We provide premium, cost effective, high quality services that support process quality and delivery capability in support for client engagements.

To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be an authentic and inclusive leader, at all grades/levels and in all lines of service. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.

As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:
Use feedback and reflection to develop self awareness, personal strengths and address development areas.
Delegate to others to provide stretch opportunities and coach to help deliver results.
Develop new ideas and propose innovative solutions to problems.
Use a broad range of tools and techniques to extract insights from from current trends in business area.
Review your work and that of others for quality, accuracy and relevance.
Share relevant thought leadership.
Use straightforward communication, in a structured way, when influencing others.
Able to read situations and modify behavior to build quality, diverse relationships.
Uphold the firm's code of ethics and business conduct.
New Business Ventures - Data Engineer - Senior Associate level 1

Work Experience : 5 - 8 years

Work Location : Bangalore, India

Job Description

Summary

A career in our Data & Analytics practice, within New Business Ventures, will provide you with the opportunity to invest in new business models that leverage our knowledge and build solutions for the growing digital market. New Business Ventures identifies, develops, and commercializes technology-enabled solutions that deliver PwC value, knowledge, and experience to our clients. Each new solution focuses on data-driven platforms or other intellectual property based solutions that leverage emerging technologies and new business models. Through the process of building new solutions, we foster a culture of innovation within PwC, extend brand relevance in the market, and generate new revenue.

Our team focuses on the process of collecting, cleansing, transforming and modeling data for the purposes of drawing critical insights and conclusions that support decision making.

Job Description

To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be an authentic and inclusive leader, at all grades/levels and in all lines of service. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.

As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:
Use feedback and reflection to develop self awareness, personal strengths and address development areas.
Delegate to others to provide stretch opportunities and coach to help deliver results.
Develop new ideas and propose innovative solutions to problems.
Use a broad range of tools and techniques to extract insights from from current trends in business area.
Review your work and that of others for quality, accuracy and relevance.
Share relevant thought leadership.
Use straightforward communication, in a structured way, when influencing others.
Able to read situations and modify behavior to build quality, diverse relationships.
Uphold the firm's code of ethics and business conduct.
Minimum Degree Required:
Bachelor Degree

Required Knowledge and Skills:

Demonstrates thorough abilities and/or a proven record of success in the following areas:
SQL
Java/Scala
Database Architectures
Database Management Systems
Real time processing frameworks
Education (if blank, degree and/or field of study not specified)

Degrees/Field of Study required:Degrees/Field of Study preferred:

Certifications (if blank, certifications not specified)

Desired Languages (If blank, desired languages not specified)

Travel Requirements

Available for Work Visa Sponsorship?

Government Clearance Required?

Job Posting End Date",3.8,"PwC
3.8",Bengaluru,"New York, NY",10000+ employees,1998,Company - Private,Accounting,Accounting & Legal,₹500+ billion (INR),-1
418,Data Scientist-ONWARD,"Data Scientist-ONWARD
Job Description


At Kimberly Clark, we believe in a truly diverse and inclusive culture and towards this end a brand new initiative – ONWARD, Career Restart Program has been recently launched .

The vision of the program is to broaden and diversify candidate talent pools by empowering experienced professionals to restart their careers, following a hiatus, with Kimberly Clark. Seasoned professionals (often women) with a career break are highly skilled and are an untapped pool of experienced talent. Through this program we will provide a road to re entry, strengthening our workforce diversity and maximizing women’s workforce participation.

If you think you qualify for this program and have the skills, check out the following open job with us-

IT Data Scientist -ONWARD

Job Description Summary

The ITS Data Scientist is responsible for integrating business, information, and technology into analytical models that help drive business performance and competitive advantage and providing the business with answers to questions. The role collaborates with Business, IT Functional Engineers and Platform architects to create value from varied data sources. Creating value from data requires a range of talents: from data integration and preparation, to architecting specialized computing/database environments, to data mining and intelligent algorithm development.

This role is viewed as an expert in making sense of complex data environments, encompassing both business data and process understanding and technical expertise. Leads in developing innovative, technical solutions to important, highly complex strategic and operating problems. Has strong knowledge in business and technical functions that are touch points with their area of expertise. Provides technical consulting on complex projects. Acts as a source of direction, training and guidance for other team members. Is knowledgeable in industry best practices in their area of expertise and uses resources outside of KC to deliver solutions.

Duties and Responsibilities:Job Details
Development of advanced analytics to help drive competitive advantage from data with accountabilities across multiple functional and technical areas with wide range of complexity.
The Data Scientist must understand complex data types (integrate, manipulate, prepare), know advanced analytics (appropriate techniques, interpret data and diagnose models, meet business requirements), and focus on the business outcomes (goals, constraints, decisions while communicating outcomes via presentations).
Develop models and algorithms that drive innovation throughout the organization. This may include marketing, supply chain, inventory planning and deployment, network planning, order routing, and order fulfillment and delivery.
Conduct advanced statistical analysis to provide actionable insights, identify trends, and measure performance.
Build learning systems that monitor data flows and react to changes in customer preferences, network constraints, and business objectives Collaborate with engineers to implement and deploy scalable solutions.
Provide thought leadership by researching best practices, conducting experiments, and collaborating with industry leaders.
Partners as a bridge between the business and the information management teams to make sure that the solution fits within the data management principals.
Coordinates data science implementations while leading design variances based upon business needs while ensuring artifacts and repositories are documented.
Manages engagements with vendors as they relate to evaluation, design and delivery of business capabilities.
Contributes to the evaluation and selection of software product standards Leader in industry representation, policy formation, User Groups, and strategic direction
Mentors others to complete Continuous Improvement (CI) initiatives; consults and shares knowledge across org; awareness of industry trends.
Education required/ preferred:
B.A. or B.S. in Information Technology, Data Science, or related field.
At least 8 years of IT experience and at least 4 years or more of work experience in data scientist discipline.
Deep knowledge of machine learning, statistics, optimization or related field.
Experience with R, Python, Matlab is required.
Experience building machine learning application in areas like time series forecasting, classification models, clustering models, multivariate regression models etc.
Experience in Microsoft Azure Stack in the Cloud with focus on Data Factory, Data Bricks, BLOBs, Data Lake Storage, ML Studio, Azure Analysis Services, Azure Data Warehouse, Power BI etc.
Experience working with large data sets and distributed computing tools a plus (Map/Reduce, Hadoop, Hive, Spark, Python, R, Gurobi, MySQL, etc.).
Excellent written and verbal communication skills along with strong desire to work in cross functional teams.
Consumer products experience in an online and/or retail/manufacturing environment is preferred.
Possess strong leadership skills and exhibit creative thinking to be able to come up with inventive solutions to solve business challenges.
Provide thought leadership while keeping up with industry trends and disseminating information across the organization.
Experience working with blended teams consisting of employees, vendors, and consultants with both onshore and offshore resources.
Strong Technical leadership of advanced analytics teams and vendors.
Extensive experience collaborating with Enterprise Architects and infrastructure engineers to identify, design, and implement highly complex, end-to-end solutions
Cultivates networking opportunities within the organization
Broad range of business and IT experiences; Has achieved technical and/or business certification(s).
Travel may include less than 10% of work time. Travel may also include travel via aircrafts and motor vehicles to various locations, if applicable. Varying working conditions may include prolonged sitting, typing and viewing computer/laptop screens, along with occasional bending, reaching, lifting, carrying, climbing, twisting, stooping, walking and standing.

Global VISA and Relocation Specifications:
K-C requires that an employee have authorization to work in the country in which the role is based. In the event an applicant does not have current work authorization, K-C will determine, in its sole discretion, whether to sponsor an individual for work authorization. However, based on immigration requirements, not all roles are suitable for sponsorship.
This role is available for local candidates already authorized to work in the role’s country only. K-C will not provide relocation support for this role.
Primary Location
IT Centre Bangalore GDTC
Additional Locations
Worker Type
Employee
Worker Sub-Type
Regular
Time Type
Full time",3.9,"Kimberly-Clark
3.9",Bengaluru,"Irving, TX",10000+ employees,1872,Company - Public,Consumer Products Manufacturing,Manufacturing,₹500+ billion (INR),"Procter & Gamble, Georgia-Pacific, Unilever"
419,Technical Team Member Distributed Data Science & Machine Learning,"Position: Technical Team Member – Distributed Data Science & Machine Learning (Full Time)
Location: Kolkata, India
Status: Open

Overview
Agnik, is a global connected car technology company (www.agnik.com) operating in 38 countries headquartered in USA with major consumer brands like Vyncs (https://www.vyncs.com) and several B2B products. Agnik is looking for several full-time members of its Technical Team for Distributed Data Science and Machine Learning in its New Town, Kolkata office. If you want to join a top notch technical team that develops novel algorithms/systems and very well familiar with statistics, machine learning, image analysis, and distributed systems then send a copy of your complete resume to jobs@agnik.com with a subject line “Technical Team Member - Distributed Data Science & Machine Learning”.

Responsibilities
As an employee of Agnik’s Distributed Data Science & Machine Learning Technical team Member, the primary focus of this position would be to design, develop, and implement novel data analysis and machine learning algorithms for connected car and mobility applications. Successful candidates must be knowledgeable and passionate about latest developments in field of machine learning and data science, should be a hands on developer. The position does not require extensive travel.

Duties Include
Develop real-time and off-line data analysis and machine learning algorithms/systems for embedded systems, mobile platforms, and cloud-based distributed environments.
Dealing with big data management problems in real-time applications.
Writing and reviewing code using Java/C#/C language for embedded and in-cloud environments for predictive modeling, control, and scene analysis.
Developing geo-spatial data management and analysis software.

Required Qualifications

B.Tech/BS/M.Tech/MS/PhD. from a reputed University in Computer Science, Electrical/Electronic engineering (or other engineering/Science) with relevant experience.
1 – 5 years of experience in building data analysis, signal processing, and machine learning applications using Java/C/Python language, web-services in dot net environment, relational/non-relational databases, and developing distributed systems.
Ability to communicate in fluent English. Effective communications skills and strong interpersonal skills, both orally and in written form.
Distributed data management environments such as Hadoop and Spark.
Ability to juggle multiple projects simultaneously.
Attention to details, ability to prioritize and meet aggressive deadlines.

Salary

Commensurate with qualifications. Benefits, possible overseas trip.

Location

New Town, Kolkata",4.8,"Agnik
4.8",Kolkata,"Columbia, MD",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,₹10 to ₹50 million (INR),-1
420,Data Analyst,"Website
AstegicInc Astegic


Full Time
Jaipur
Posted on January 21, 2020

Description:


We are looking for a Data Analyst to join our data team. This is a hands-on technical role. Experience with Shell Script and SQL (T-SQL/PostgreSQL/OracleSQL) is essential. The data analyst will follow an agile iterative development methodology with a focus on innovation, data quality, user value, and robust data analysis.

Job Responsibilities:


Build and test metrics using SQL data-stores.
Build, test and deploy reports and interactive dashboard, leveraging the same metrics.
Focus on visualization for effective report generation, revealing a clear data story.
Process, cleanse, and verify data-integrity for analysis.
Work closely with the USA team to collect and process data on the web crawler software.
Build analysis reports for various tests and production runs on the web crawler software.
Interpret data and analyze results using statistical techniques, and provide ongoing reports.
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality.
Acquire data from primary or secondary data sources and maintain databases/data systems.
Identify, analyze, and interpret trends or patterns in complex data sets.
Filter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems.
Work with management to prioritize business and information needs.
Locate and define new process improvement opportunities.
Job Requirements:


Strong T-SQL OR PostgreSQL OR Oracle SQL Skills.
Strong Microsoft Office Skills especially Word and Excel
Experience with scripting Language: Shell
Skilled at queries, report writing and presenting findings.
Strong analytical skills with the ability to collect, organize, analyze, and disseminate a significant amount of information with attention to detail and accuracy.
Ability to write comprehensive reports.
Processing confidential data and information according to guidelines.
Supporting the data warehouse in identifying and revising reporting requirements.
Supporting initiatives for data integrity and normalization.
Providing technical expertise in data storage structures, data mining, and data cleansing.
Identify areas to increase the efficiency and automation of processes.
Monitor and audit data quality.
Ability to deal with high-volume data under tight deadlines.
Create data dashboards, graphs, and visualizations.
Strong verbal and written communication skills.
Ability to work with little or no supervision.
Ability to work calmly under pressure.
Ability to work as a strong team player
Education & Experience:


Bachelor’s Degree in Computer Science or related field.
Minimum 3-5 years of work experience as a Data Analyst.
Other Attributes:


Knowledge of data processing, database programming, and data analytics.
Robust data analysis domain knowledge.
Ability to understand various data structures and common methods in data transformation.
Knowledge of scripting languages such as Python, Shell/Sed/Awk.
Exceptional problem solving and data analysis skills.
A high degree of reliability, flexibility, and adaptability while working under pressure.
Strong verbal and written communication skills.
Detail-oriented with excellent follow-up skills.
Job Location: Jaipur

About Astegic:


Astegic, founded in 2003, is a woman-owned SBA certified 8a firm that has successfully achieved both SEO CMMI ML2 and ISO-9001-2008 certifications. Astegic provides enterprise-level technology solutions and integrations, meeting enterprise business challenges with cutting-edge technology, for both government and commercial sectors. Our knowledgeable staff of over 150 software engineers, management consultants, IT specialists, and analysts is armed with the technology and expertise to improve and extend your existing enterprise solutions.

Full Name * (optional)
Email Address * (optional)
Phone Number * (optional)
Upload CV * (optional)
Upload your CV/resume. Max. file size: 5 MB.

Cover Letter (optional)


Services

Mobile Solutions
Mobile Strategy
Mobile Application Development
Mobile Web Development
Mobile Architecture
Mobile Security
Mobile Design & UX
Mobile Quality Assurance & Control
Mobile Device Management
Enterprise Integration

Enterprise IT Solutions
Software Development
Program Management Offering (PMO)
System Integration
Quality Assurance
IT Automation & Infrastructure Virtualization
Cloud Migration & Optimization/Scalability
Database Management
Enterprise Resource Planning (ERP)
Network & Server Management
Server Administration

UX & Design
User Research
Information Architecture
Interaction Design
Visual Design
Usability

Products
m-Conference
m-Custodial
m-Inspector
mforms

About
Portfolio & Clients
GSA 8(A) STARS II
Careers


Contact

Services
Products
Portfolio
About
Contact

© 2020 Astegic Inc. All rights reserved.

Terms of Use
Privacy Policy",4.1,"Astegic
4.1",Jaipur,"Falls Church, VA",51 to 200 employees,2003,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
421,Data Engineer,"Due to the current health crisis related to COVID-19 and the escalating visa/travel restrictions in place, we're currently unable to extend offers to anyone who cannot work from India due to lockdown visa/travel restrictions, or other restrictive measures until further notice. Consequently, we will be prioritizing candidates who can start in this location by set date as expected. We're keeping the situation under review and would adjust our position should the restrictive measures be removed later on.

Minimum qualifications:
Bachelor's degree in Computer Science or related technical field, or equivalent practical experience.
3 years of industry experience in software development, data engineering, business intelligence, data science, or related field with experience in manipulating, processing, and extracting value from datasets.
Preferred qualifications:
Master's degree in Computer Science, or related field.
Understanding of Big Data technologies and solutions (Spark, Hadoop, Hive, MapReduce) and multiple scripting and languages (YAML, Python).
Understanding of Google Cloud Platform (GCP) technologies in the big data and data warehousing space (BigQuery, Cloud Data Fusion, Dataproc, Dataflow, Data Catalog).
Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment.
Excellent verbal and written communication skills with the ability to effectively advocate technical solutions to research scientists, engineering teams and business audiences.
About the job


At Google, we work at lightning speed. So when things get in the way of progress, the Business Systems Integration team steps in to remove those roadblocks. The team identifies time-consuming internal processes and then builds solutions that are reliable and scalable enough to work within the size and scope of the company. You listen to and translate Googler needs into high-level technical specifications, design and develop recommended systems and consult with Google executives to ensure smooth implementation. Whether battling large system processes or leveraging our homegrown suite of Google products for Googlers themselves, you help Googlers work faster and more efficiently.

Data Engineers understand internal processes and what it takes to run Google at speed with its ever growing scale. As a Data Engineer, you'll focus on solving problems and creating value for Googlers by building solutions that are reliable and scalable to work with the size and scope of the company.

You will play a major role in developing, deploying, and supporting Google’s internal business applications. You will be tasked with creating custom-built software on google stack, and you will be part of teams that implement vendor sourced enterprise software, configuring that software, customizing it, and integrating with other internal systems.

Behind everything our users see online is the architecture built by the Technical Infrastructure team to keep it running. From developing and maintaining our data centers to building the next generation of Google platforms, we make Google's product portfolio possible. We're proud to be our engineers' engineers and love voiding warranties by taking things apart so we can rebuild them. We keep our networks up and running, ensuring our users have the best and fastest experience possible.
Responsibilities
Design, build and deploy internal applications to support our technology life cycle, collaboration and spaces, service delivery management, data and business intelligence among others.
Work closely with analysts and business process owners to translate business requirements into technical solutions.
Build internal solutions, with custom front ends (web, mobile) and backend services that automate business processes.
Maintain highest levels of development practices including: technical design, solution development, systems configuration, test documentation/execution, issue identification and resolution, writing clean, modular and self-sustaining code, with repeatable quality and predictability.

Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form.",4.4,"Google
4.4",Bengaluru,"Mountain View, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Microsoft, Apple, Facebook"
422,Data Analyst,"Graduate in the analytical fields with strong academic credentials
Excellent written and verbal communication skills
Should have worked on excel and advance excel, MS Office
Please send your CV to:careers@q-dat.com",5.0,"Q-Dat IT Solutions
5.0",Bengaluru,"RajajiNagar, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
423,Principal Data Scientist,"Principal Data Scientist will architect and drive technical excellence in GoFood Search solutions from a data sciences perspective.

Responsibilities:
Design and lead the development of various machine learning initiatives for improving search relevance and personalized ranking that drive product metrics
Understand the user and their behavior and continuously contribute to making their experience better with each release
Lead the experimentation strategy with measurement frameworks
Partner with various business stakeholders and product leads to build the future of search for various products within Gojek
Define and execute an iterative search maturity improvement roadmap
Identify ways to better leverage our content and improve its quality and attributes, to improve the overall search experience
Requirements:
10+ years of experience in leading high-performance data science teams
Familiarity with state-of-the-art search personalization, relevance and ranking models.
Have hands-on experience with search engines like Solr, Elasticsearch.
Hands on experience in NLP
Experience in designing and validating search relevance and ranking algorithms.
Ability to design and implement low latency ML models handling scale
Familiarity with ML infrastructure needs and best practices
Review data scientists’ work and mentor them to improve their search domain maturity and DS skills
Experience working with cross-functional teams including product, design, engineering, mobile to deliver product outcomes using data science
Hands on NLP and expertise in solving semantic search problems
Gojek is an equal opportunity workplace that is committed to diversity and inclusion. At Gojek we celebrate our differences, because we believe that diversity not only creates a healthier work environment for our employees, but also helps our business thrive.

About us

Gojek is a technology startup based in Jakarta, Indonesia. Specialising in ride-hailing and logistics, we are also the only company in Southeast Asia to be part of Fortune's 50 Companies That Changed the World (2017).

Gojek is a Super App: one app with over 20 services including food delivery, commuting, digital payments, shopping, hyper-local delivery, massages, and many more.

Gojek is Indonesia’s first and fastest growing unicorn building an on-demand empire. Our total of 2,000,000 driver-partners collectively travel 16.5 million KM daily – making us Indonesia’s de-facto transportation choice.

Gojek is a verb! Gojek is a way of life!",4.0,"GO-JEK
4.0",Bengaluru,"Jakarta, Indonesia",1001 to 5000 employees,2010,Company - Private,Transportation Management,Transportation & Logistics,Unknown / Non-Applicable,-1
424,Lead Data Scientist,"<
Lead Data Scientist - Computer Vision

About the job :
Experience: 5-10 Years.
Job Type: Full-time.
Location: Chennai or Mumbai.

Duties & Responsibilities:
Responsibilities include Identify, develop and implement the appropriate Computer Vision algorithms and Deep learning / ML Models to create new, scalable solutions that address business challenges across industry domains , as well as provide actionable insights with a clear impact on ROI. Define and develop, maintain and evolve data models, tools and capabilities. Communicate your findings to the appropriate teams through visualisations. Collaborate and communicate findings to diverse stakeholders. Ability to build, train and lead a team of data scientists.

Preferred Qualification:
Bachelors/ Masters/ PhD degree in Math, Computer Science, Information Systems, Machine Learning, Statistics or related technical degree with ability to break complex business problems.
5-10 years total experience with minimum of 2 years of experience in a related position, as a
data scientist building computer vision solutions for various types of business problems.
Advanced knowledge of statistical techniques, machine learning algorithms and deep
learning frameworks like Tensorflow, Keras, Pytorch.
Minimum 3 years of Programming background and expertise in building models using at
least one of the following languages: Python, R ,Java, C,C++.
Implementation of deep learning based models for image classification, Document
classification models, object detection, logo detection, Object tracking.
Strong individual planning and project management skills, able to juggle multiple tasks and
priorities Self-motivated and driven to deliver agreed results on-time.
Strong storytelling & articulation skills - ability to convert analytical output into clear,
concise, and persuasive insights & recommendations for technical & non-technical audience.
Strong influence and relationship management skills; comfortable interacting with all
management levels; Prior experience in providing strategic analysis and consulting.
Track record of delivering strong business results.

If you think you fit in with the above requirements we'd love to talk to you about working in our organization.

Location :
Blackstraw.ai , Chennai, 4th floor, Tower C, Ratha Tek Meadows Rd, Elcot Sez, Sholinganallur, Chennai, Tamil Nadu 600119, India",4.6,"Blackstraw
4.6",Chennai,"Tampa, FL",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
425,Senior Decision Scientist,"PayPals Next-Generation Platforms Consumer Risk team is responsible for assessing and managing buyer-side financial risk exposures for this $8 billion portfolio (including identity theft, stolen financials, account takeover, and credit risk), as well as developing and implementing the policies, treatments, and experiences related to the management of these exposures. The team is also responsible for partnering with the corresponding Business Units to align with and influence their strategic priorities, educate business partners about Risk management principles, and collaboratively optimize the Risk treatments and experiences for these unique products and partners.

Each Decision Scientist on this team has full ownership of a portfolio of merchants and is responsible for end-to-end management of loss and decline rates. Day-to-day duties include data analysis, monitoring and forecasting, creating the logic for and implementing risk rules and strategies, providing requirements to data scientists and technology teams on attribute, model and platform requirements, and communicating with global stakeholders to ensure we deliver the best possible customer experience while meeting loss rate targets.

Scope of responsibility:
Work is generally self-directed with minimum supervision. Review is normally after the fact and may be developmental in nature.
Works on assignments that are of intermediate complexity with multiple steps in execution, and guided by generally defined processes and project requirements
Focuses primarily on completing short-term goals of a project efficiently and effectively
Job Requirements:
Strong analytical skills -- ability to build quick estimates using back-of-the-envelope analysis, structure (and, if needed, execute) more complex analyses, pull together business cases and forecasts to navigate through multi-dimensional sets of tradeoffs.
Enthusiasm for data-driven problem solving within a fast-paced environment is a must. In addition, experience with Microsoft Excel or statistical software, working knowledge of SQL or other relational database languages, and hands-on experience in data analysis involving large data sets are strongly desired.
Polished communication and influence skills risk decision scientists need to collaborate cross-functionally with product managers, data scientists, business owners, and customers to learn from subject-matter experts, present findings in a clear and concise manner, and reach alignment on how to execute risk strategies. Demonstrated ability to influence groups and effectively resolve conflicts is required.
An innate intellectual curiosity, and a willingness to build awareness of current payments industry and risk management best practices. PayPal is constantly innovating by introducing new products and entering new markets, so successful risk analysts on this team must quickly get up speed on new content areas. You will be expected to become an expert in your specific domain
Can-do attitude, team player, energetic personality, ability to work well under pressure in a fast-paced and constantly changing environment to meet deadlines. The successful risk analyst is a self-starter who has the resilience to learn from their mistakes and reach their true potential.
Identify glitches in processes and tools and develop and execute solutions to overcome general issues and obstacles with little supervision.
Learning in-depth analysis of alternatives and applying specialized knowledge
Impact of decision has moderate reach
Seeks improvement within defined tasks. Understands, evaluates, and executes improvement ideas from supervisors
BS/BA degree with 5+ years of experience or masters degree with 3+ years of experience.",3.6,"PayPal
3.6",Bengaluru,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple"
426,Data Science Associate,"At ZoomRx, we impact healthcare through data and innovation. We are pushing the boundaries of technology by redefining healthcare market research and data analytics. In this quest, we are building a Data Science team to design leading-edge solutions to help the world’s biggest biopharma organizations answer questions no one else can. We provide market intelligence that helps them launch new therapies, optimize promotional efforts, defend against competitive pressure, shape marketing strategies, make acquisition decisions, and much more.

What does your day look like as an Associate at ZoomRx?
Ability to interpret large amounts of data and to multi-task across projects
Conduct secondary research in healthcare and life-sciences for building working prototypes from ideas
Strong problem-solving skills and willingness to roll up one’s sleeves to get the job done
Expected to be extremely motivated, independent, agile and must possess high-quality standards
Excellent written and verbal communication skills to collaborate with vendors and with the internal teams
Experience and proficiency in MS Office
Prefer candidates with prior experience in Python / R and SQL
What makes your role at ZoomRx unique?
You will develop deep expertise in a wide range of topics within life sciences by drawing on existing knowledge bases while building new ones
You will work with smart, grounded peers who are experts in their own right and thrive on the camaraderie of working in high-performance, intelligent, impactful teams
You will have wide-reaching creative control and the power to make impactful decisions. At ZoomRx, we favor collaboration over hierarchy
If you love finding creative solutions to challenging and complex problems, building direct and meaningful relationships with colleagues, and working in a collaborative team environment, we want to hear from you!

Location
41/1, Vasantha Avenue, MRC Nagar, RA Puram, Chennai 600 028.",4.2,"ZoomRx
4.2",Chennai,"Cambridge, MA",51 to 200 employees,2009,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
427,Principal Data Scientist,"Come work at a place where innovation and teamwork come together to support the most exciting missions in the world!

Position Summary

Are you passionate about working with smart people on challenging problems in an environment that values hard work, integrity and teamwork? F5 Networks A Market leader in Application Delivery Controllers and Security platforms is hiring for its Centre of Excellence office in Hyderabad, India. Join our team of super smart engineers working in a fun, fast-paced, and highly technical environment where your dreams can become reality.

As a Data scientist, you will be responsible for the design and development of platform for telemetry and predictive analytics and build a system based on real-time events. Also ensure that the platform is scalable to support the machine learning. You’ll work with architects, Product Management, cross-functional teams, and other stakeholders to help define and implement solutions.

Mandatory Skills:
Strong analytic / trouble-shooting skills.
Experience using data transformation technologies (e.g., Spark, Kafka, Storm, Cassandra)
Experience in developing algorithms using Java, Node.JS, Python or Scala in one or more of the

following fields: machine learning, data analytics, information retrieval.

Experience in utilizing machine learning libraries and algorithms
Strong grasp of multi-threading and resource management

Good to Have skills:
Knowledge of docker containers, kubernetes
REST based webservices development and microservices
Experience in building products from scratch using machine learning in early startup
Applied statistics knowledge, such as distributions, statistical testing, regression, etc.
Automation using Python, and other automation systems like Ansible, Chef, or Puppet
Agile based software development methodologies like SCRUM.

Qualifications

Requires a minimum of 2 to 4 years of related experience with PhD in Computers and Data science.
Excellent organizational agility and interpersonal skills throughout the organization.
Ability to work flexible hours for better collaboration with International teams.

F5 Networks, Inc. is an equal opportunity employer and strongly supports diversity in the workplace. The Job Description is intended to be a general representation of the responsibilities and requirements of the job. However, the description may not be all-inclusive, and responsibilities and requirements are subject to change.

The Job Description is intended to be a general representation of the responsibilities and requirements of the job. However, the description may not be all-inclusive, and responsibilities and requirements are subject to change.

Equal Employment Opportunity

It is the policy of F5 to provide equal employment opportunities to all employees and employment applicants without regard to unlawful considerations of race, religion, color, national origin, sex, sexual orientation, gender identity or expression, age, sensory, physical, or mental disability, marital status, veteran or military status, genetic information, or any other classification protected by applicable local, state, or federal laws. This policy applies to all aspects of employment, including, but not limited to, hiring, job assignment, compensation, promotion, benefits, training, discipline, and termination. Reasonable accommodation is available for qualified individuals with disabilities, upon request.",3.8,"f5
3.8",Hyderabad,"Seattle, WA",5001 to 10000 employees,1996,Company - Public,Computer Hardware & Software,Information Technology,₹100 to ₹500 billion (INR),"Citrix, VMware, Juniper Networks"
428,Data Engineer,"Job Type: Permanent

Job Description:
We are looking for energetic, self-motivated and exceptional Data Engineer to work on extraordinary enterprise products based on AI and Big Data engineering. He/she will work with star team of Architects, Data Scientists/AI Specialists, Data Engineers, Integration Specialists and UX developers.

Role and Responsibilities:
Create and maintain optimal data pipeline architecture.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and Azure ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Support software developers, database architects, data analysts and data scientists on data initiatives and ensure optimal data delivery architecture throughout projects.

Essential Skills and Qualifications:
Advanced working SQL knowledge and experience working with relational databases, query
authoring (SQL) as well as working familiarity with a variety of databases.
Mandatory experience in one of the programming languages – Python/Java with strong preference for Python
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’
data stores.
Experience supporting and working with cross-functional teams in a dynamic environment.
Experience in building Data-Ingestion and ETL/ELT Pipelines
Overall 6+ years of experience with 3+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Information Systems or another quantitative field. Should have experience using the following software/tools:
Strong working experience in Microsoft Azure Cloud offerings especially for data engineering work (vis. MS Azure Data Factory, Data Warehouse, Azure batch, Data Lake Analytics, HDInsight, Data factory, SQL Server)
Experience with relational SQL and NoSQL databases
Experience with data pipeline and workflow management tools
Good to have: Experience with big data tools: Hadoop, Spark, Kafka, etc.
Hands-on working experience in Linux & Windows environment
Hands-on working experience in bash scripting
Good to have: Experience in stream processing architecture
Good to have: Experience in Webapp Development (Flask/Django in Python)

Desired Qualifications:
Must be a good team player
Recognizes and respects the strengths of others in the organization
Takes ownership for responsibilities
Demonstrates a high degree of reliability, integrity, and trustworthiness
Demonstrates strong negotiation, communication & presentation skills
Ability to manage time and meet or exceed all deadlines
Exhibits appropriate sense of urgency in managing responsibilities
Ability to accurately process high volumes of work within established deadlines
Self-motivates to achieve positive results
Bring a culture of operational excellence and enhancements
Experience of working across one or more geographic territories or regions",3.8,"Symphony SUMMIT
3.8",Bengaluru,"Bangalore, India",1 to 50 employees,-1,Subsidiary or Business Segment,IT Services,Information Technology,Unknown / Non-Applicable,-1
429,Data Analyst II,"Business Title
Data Analyst II

04-May-2020

Requisition Number
25081BR

Job Description and Requirements
At Synopsys, we’re at the heart of the innovations that change the way we work and play. Self-driving cars. Artificial Intelligence. The cloud. 5G. The Internet of Things. These breakthroughs are ushering in the Era of Smart Everything. And we’re powering it all with the world’s most advanced technologies for chip design and software security. If you share our passion for innovation, we want to meet you.

Our Software Security and Quality business is all about building secure software—faster. That starts with our static analysis, software composition analysis, and dynamic analysis. So our customers can build security and quality into the DNA of their code at any stage of the software development lifecycle and across the supply chain. All while minimizing risks and maximizing speed of application development.

Data Analyst

We’re looking for a Data Analyst to join the team.

Does this sound like a good role for you?

In this role, the Data analyst need to gather and understand the business requirements using appropriate tools and techniques. You would need to carry out data quality control and validations. The data analyst needs to prepare reports for internal and external stakeholders using business analytics and tools.

Responsibilities include but not limited to the following:
Liaise with internal and external stakeholders to understand data content and develop and support reporting processes
Identify areas to increase efficiency and automation of processes
Set up and maintain automated data processes
Design and carry out surveys and analyze survey data
Create data dashboards, graphs and visualizations
Analyze large datasets, draw valid inferences and present them successfully to management using a reporting tool.
Key Qualification
Bachelor’s degree in Mathematics / Statistics / Computer Engineering
3+ Years in data analyst role
Strong verbal and written communication skills
Preferred Experience
Excellent numerical and analytical skills
Understanding of IT services and management reporting
Experience of data analysis techniques and statistical models
Ability to produce clear graphical representations and data visualizations
Knowledge and advanced skills in Excel, VBA, XML, PPT
Familiarity with Tableau, APIs and programming skills for data and analytics
Inclusion and Diversity are important to us. Synopsys considers all applicants for employment without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, military veteran status, or disability.

Hiring Location
INDIA - Bangalore, INDIA - India

Hire Type
Employee

Job Category
Business Development

Country
India",4.1,"Synopsys
4.1",Bengaluru,"Mountain View, CA",10000+ employees,1986,Company - Public,Computer Hardware & Software,Information Technology,₹100 to ₹500 billion (INR),"Cadence Design Systems, Mentor Graphics, Ansys"
430,Data Analyst,"Minimum 3 yrs of experience on DW projects in analysis & design
Knowledge of banking products in this space would be useful
good communication skills.
experience in banking environment will be a plus",-1,Novacom Technologies,Mumbai,"Thāne, India",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
431,"Lead Data Scientist – Machine Learning, Investment Bank","Worlds largest investment bank is looking to setup team of model development in India to reduce regional cost hence looking to hire senior Data Scientist to lead and manage specialized team of Machine learning.

Some of the key responsibilities will include:
Team is responsible to run adhoc scenarios in enterprise risk management team.
Capability to run adhoc scenarios with short turn-around-times has been developed using a big data platform and machine learning
Capability to run Adhoc scenarios with short turn-around-times has been developed using a big data platform and machine learning

To be eligible for this role you will require:
Qualified degree with 6 + years of experience in any of these advanced machine learning, e.g. juypter notebooks, sklearn, pandas, dask, spark, shap, another other packages in the python ecosystem.
Subject matter expertise in at least one specific risk – stressed revenue, credit risk for lending, market risk and so on.

Please contact Shashikant Bomma on +91 22 42369769 or email your cv directly in word format with job reference number JO0000004097 to banking-India@theedgeinasia.com

Please note that due to the high number of applications only shortlisted candidates will be contacted. If you do not hear from us in the next 5 business days we regret to inform you that your application for this position was unsuccessful.",4.0,"The Edge Asia
4.0",Mumbai,"Hong Kong, Hong Kong",1 to 50 employees,2013,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
432,Data Engineer,"Data Engineer:

Pluto7 is a services and solutions company focused on building ML, Ai, Analytics, solutions to accelerate business transformation. We are a Premier Google Cloud Partner, servicing Retail, Manufacturing, Healthcare, and Hi-Tech industries and Pluto7 has been awarded as ""2019 Google Cloud Specialization Partner of the Year for Data and Analytics"" . Were seeking passionate people to work with us to change the way data is captured, accessed and processed, to make data-driven insightful decisions.

Must have skills :
Hands-on experience in database systems (Structured and Unstructured).
Programming in Python, R, SAS.
Overall knowledge and exposure on how to architect solutions in cloud platforms like GCP, AWS, Microsoft Azure.
Develop and maintain scalable data pipelines, with a focus on writing clean, fault-tolerant code.
Hands-on experience in data model design, developing BigQuery/SQL (any variant) stored.
Optimize data structures for efficient querying of those systems.
Collaborate with internal and external data sources to ensure integrations are accurate, scalable and maintainable.
Collaborate with business intelligence/analytics teams on data mart optimizations, query tuning and database design.
Execute proof of concepts to assess strategic opportunities and future data extraction and integration capabilities..
Data extraction, Data cleansing and transformation.
Strong knowledge on REST APIs, Http Server, MVC architecture.
Knowledge on continuous integration/continuous deployment.
Preferred but not required:
Machine learning and Deep learning experience
Certification on any cloud platform is preferred.
Experience of data migration from On-Prem to Cloud environment.
Exceptional analytical, quantitative, problem-solving, and critical thinking skills
Excellent verbal and written communication skills
Work Location: Bangalore",3.9,"Pluto7
3.9",Bengaluru,"Milpitas, CA",51 to 200 employees,2015,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
433,Data Analyst 2,"Scope of responsibility:
Proficiency to complete assignment with multiple steps, guided by defined processes and project requirements.
Focuses primarily on completing short-term goals of a project efficiently and effectively
Functional Skills
Solid technical / data mining skills and ability to work with large volumes of data; extract and manipulate large datasets using tools such as SQL, SAS, Hadoop or other programming/scripting languages (Perl, R, Java/C/C++, etc.) to translate data into business decisions/results
Intermediate statistical skills, proficiency in experimental design, and ability to forecast real-world performance based on samples, simulations and user behavior analytics
Solid knowledge in rule writing systems, development and implementation of complex decision frameworks by coding action rules and decision tables using BAL (Business Action Language), variables creation, RADD files design, regular expression proficiency (see examples in the last tab)
Intermediate capability to create/revamp innovative and technical solutions that require the processing of large datasets across different platforms. Collaborate with other analysts to achieve the optimal level of system automation decisions and minimize human intervention
Intermediate capability to create and own ""Standard Operation Procedures"" and clearly articulate methods and principles of account review and user facing interaction
Strong analytical skills -- ability to build quick estimates using back-of-the-envelope analysis, structure (and, if needed, execute) more complex analyses, pull together business cases and forecasts to navigate through multi-dimensional sets of tradeoffs.
Enthusiasm for data-driven problem solving within a fast-paced environment is a must. In addition, experience with Microsoft Excel or statistical software, working knowledge of SQL or other relational database languages, and hands-on experience in data analysis involving large data sets are strongly desired but not absolutely required.
communication skills risk analysts need to collaborate cross-functionally with product managers, data scientists, business owners, and customers to learn from subject-matter experts, present findings in a clear and concise manner, and reach alignment on how to execute risk strategies.
Can-do attitude, team player, energetic personality, ability to work well under pressure in a fast-paced and constantly changing environment to meet deadlines. The successful risk analyst is a self-starter who has the resilience to learn from their mistakes and reach their true potential.
An innate intellectual curiosity, and a willingness to build awareness of current payments industry and risk management best practices. PayPal is constantly innovating by introducing new products and entering new markets, so successful risk analysts on this team must quickly get up speed on new content areas.
BS/BA degree with 2+ years of experience, MS degree with 1+ year of experience",3.6,"PayPal
3.6",Bengaluru,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple"
434,Quantitative Analyst,"Quantitative Analyst

Company Profile

Founded in 1997, Calypso’s mission to pioneer innovative technology solutions that reimagine capital markets, making them more efficient, accessible and transparent has been attainable due to our outstanding employees. To continue our track record of growth we need the best talent from across the globe - those who desire to take the initiative, are self-directed learners and have a passion for solving our customers’ problems. We offer challenging opportunities to join a uniquely innovative, highly successful company that straddles the worlds of technology and finance.

Job Description Overview

We are looking for a Quantitative Analyst with a strong mathematical and computing background to develop robust quantitative analytics as part of our Financial Engineering team. This is a front office role and will involve developing and implementing production-grade analytics to be used by Calypso clients across the Front Office.

Skills & Requirements:
5+ years experience working as a quantitative analyst in derivatives analytics, all asset classes will be considered.
High performer with strong collaboration skills that can work well with the rest of our talented team.
Strong computing skills including experience in C++ or Java.
A craftsman-like approach to building analytics code that is used by our many clients. Comfortable with agile development, code reviews, unit testing and continuous integration.
Superb problem-solving ability and willingness to tackle complex client issues.
Why should you apply?

With over 20 offices worldwide, market leading products and a customer base of the world’s top banks, asset managers, hedge funds and insurers, our team thrives on stimulating challenges and a global and diverse working environment. We offer excellent health and welfare benefits, fitness reimbursement, regular team and office events and a variety of career paths.

If you have the drive, a winning attitude and a desire to make a difference then we invite you to apply today! Check out our open jobs here and connect with us on LinkedIn, Twitter and Facebook.

Calypso Technology is an equal opportunity employer (EOE) and strongly supports diversity in the workforce. Calypso only accepts resumes from approved agencies who have a valid executed Non-Exclusive Master Staffing Agency Agreement on file. Please do not forward resumes to our applicant tracking system, Calypso employees, or send to any Calypso location. Calypso is not responsible for any fees or claims related to receipt of unsolicited resumes.
Back
Share",3.5,"Calypso Technology
3.5",Mumbai,"San Francisco, CA",501 to 1000 employees,1997,Company - Private,Financial Transaction Processing,Finance,₹10 to ₹50 billion (INR),-1
435,Sr. Business Intelligence Analyst,"At Amazon, we are working to be the most customer-centric company on earth. To get there, we need exceptionally talented, bright and driven people. Are you relentless? Are you passionate about leveraging data to deliver actionable insights that could impact the daily business decisions at Amazon India? Does the prospect of dealing with massive volumes of data excite you? Do you love using data to answer challenging product and customer behavior questions? Would you like to be part of the next big thing while its still day one?

This role is with the Direct Fulfillment team of Amazon. We are looking for a Business Intelligence Analyst to drive important data driven decisions for the team.

you will used advanced analytical techniques to develop solutions that answer business questions related to selection performance and customer experience. Specific responsibilities include:
· Analyse large data sets to build a channel allocation model for new or existing selection on DF. This would require building recommendation models for new selection while looking at speed & profitability of similar selection. May also require collaborating with ML team to build ground truth data and productize the model
· Interface with business groups to gather data and metrics requirements
· Develop automated, scalable analytical solutions for large-scale, business-critical problems. For eg: building a self-service tool for category managers to assess health of DF business
· Translate analytic insights into concrete, actionable recommendations for business or product improvements. Work with several internal teams to drive action on recommendations. The individual will not just own the analysis but also driving adoption and results through stakeholder collaboration.
· Support strategic data analysis requests, prioritizing based on business needs






Basic Qualifications

· Bachelor's degree in Business, Engineering or a related field
· 5+ years of professional experience in analytics, business analysis or comparable consumer analytics position
· Advanced working knowledge of data mining using SQL, ETL, data warehouse as well as Excel
· Excellent communication (verbal and written) and interpersonal skills and an ability to effectively communicate with both business and technical teams.
· High business accumen, problem solving skills, project management skills, attention to detail, and exceptional organizational skills
· Ability to deal with ambiguity and competing objectives in a fast paced environment
· Ability to display complex quantitative data in a simple, intuitive format and to present findings in a clear and concise manner
· Excellent organizational skills including prioritizing, scheduling, time management, and meeting deadlines
· A self starter, who proactively converts gaps into opportunities

Preferred Qualifications

· 7+ years of relevant experience in a business analyst, data analyst or statistical analysis role
· Advanced technical or business degree (MS or MBA)
· Experience in developing requirements and formulating business metrics for reporting, familiarity with data visualization tools, e.g. Tableau, PowerBI, Quicksight",4.2,"Amazon
4.2",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
436,Looking for Lead Data Scientist,"Qualifications:
A Computer Science Degree (Bachelors or Masters), Mathematics or Statistics (Masters)

Total of 8-12 years of Big Data, Business Intelligence, Data warehousing, Artificial Intelligence and Machine Learning experience

At least 2 years of experience in data science in rolling out production grade solutions to end customers

Technical Skills:
Experience in designing and deploying Analytical Systems, End to end.

Excellent problem-solving skills

Strong verbal and written communication skills

Strong hands-on programming experience with R or Python or Java

Hands-on experience with any of the data science platforms such as RapidMiner, SAS and IBM

Sound understanding of machine learning algorithms, including classification, clustering, association and recommendation generation

Familiarity with Open Source Machine Learning (R, Python), NLP toolkits and deep learning frameworks (TensorFlow, Keras, H2O etc.)

Working experience with statistical inference

Experience with BI (Tableau, Oracle, IBM, Microsoft), Data Science (RapidMiner/ SAS/ IBM), NoSQL (MongoDB, Cassandra, Hadoop, Spark), RDBMS (Oracle, SQL Server) tools

Experience using cloud computing and storage frameworks such as Amazon AWS (EC2, S3, Redshift, RDS) and Microsoft Azure Storage",4.1,"Anblicks
4.1",Hyderabad,"Dallas, TX",51 to 200 employees,-1,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
437,Business Analyst - Data Science,"Business Analyst - Data Science - HEA002764
With a startup spirit and 90,000+ curious and courageous minds, we have the expertise to go deep with the world’s biggest brands—and we have fun doing it. Now, we’re calling all you rule-breakers and risk-takers who see the world differently and are bold enough to reinvent it. Come, transform with us.

Inviting applications for the role of MT, Data Science

In this role, we are looking for a commerce graduate / Postgraduate in Finance with prior data handling experience. In this role, you will be expected to work on strict deadlines, in a high-pressure business environment while being a standout colleague.

Prior Commercial Analytics in sales / orders reporting / MIS experience in the BPO Industry with Access skills experience will be preferred

Responsibilities
Technical expertise : Provide expertise in Statistics, Mathematical modeling and simulation, Numerical Analysis and Differential Equation
Curiosity : a desire to go beneath the stated client needs and discover and distill a problem down into a very clear set of hypotheses that can be tested.
Cleverness: the ability to look at a problem in different, creative ways.
Should be able to Handle large data sets, Compute and Calculate Sales Incentives with multiple slice and dice of the Sales data.
Should be able to identify automation opportunities, handle customer queries and issues and process log variations, exceptions, output errors for traceability
Ensure client satisfaction and successful external & internal audits
Qualifications


Minimum qualifications
MBA / M.Sc. Statistics / M.Sc. Operations Research
Meaningful work experience
Preferred qualifications
Relevant work experience in Reporting and handling large data sets and databases
Flexibility to adapt to a variety of engagement types, working hours and work environments and locations
Very good written and verbal communication skills
Proficient in MS Office applications, especially in MS excel, R, Python
Good analytical and problem-solving skills and ability to handle team and client discussions
Genpact is an Equal Opportunity Employer and considers applicants for all positions without regard to race, color, religion or belief, sex, age, national origin, citizenship status, marital status, military/veteran status, genetic information, sexual orientation, gender identity, physical or mental disability or any other characteristic protected by applicable laws. Genpact is committed to building a dynamic work environment that values diversity and inclusion, respect and integrity, customer focus, and innovation. For more information, visit www.genpact.com. Follow us on Twitter, Facebook, LinkedIn, and YouTube.

Job
Business Analyst
Primary Location
India-Noida
Education Level
Bachelor's / Graduation / Equivalent
Job Posting
Feb 17, 2020, 7:14:49 AM
Unposting Date
Ongoing
Master Skills List Operations
Job Category Full Time",3.6,"Genpact
3.6",Noida,"New York, NY",10000+ employees,1997,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"Accenture, IBM, Capgemini"
438,Data Analyst,"Who are we?

LIDO is an ed-tech company revolutionizing the formal classroom education through a unique and immersive online classroom for every child in India. With our exciting and fun online classes for our students, we are building the Lido experience: cutting edge content like animated videos and interactive games, a personalized platform for homework, tests, challenges, and inspiring teachers.

Why to be a part of Lido?

Lido’s goal is to inspire and empower every child for the future. In order to achieve this goal, we invite you to be a part of our ever-growing LIDO family. Grab the opportunity to work with passionate individuals, from Stanford, Duke, IIT and BITS, as we open the door to engaging and impactful learning!

Job Description:

We are looking for a data analyst to help us make better business decisions using information from our available data. Your task is to gather and prepare data from multiple sources, run statistical analyses, and communicate your findings in a clear and objective way.

Responsibilities:
Understanding the business requirements so as to formulate the problems to solve and restrict the slice of data to be explored.
Collecting data from various sources.
Performing cleansing, processing, and validation on the data subject to analyze, in order to ensure its quality.
Exploring and visualizing data.
Performing statistical analysis and experiments to derive business insights.
Clearly communicating the findings from the analysis to turn information into something actionable through reports, dashboards, and/or presentations.
Skills:
Experience solving problems in the edtech domain or consumer analytics.
Experience with data integration from multiple sources.
Proficiency in SQL.
Experience with popular statistical and machine learning techniques, such as clustering, linear regression, KNN, decision trees, etc.
Good scripting skills with python or R
Proficiency in at least one data visualization tool, such as Matplotlib, Plotly, D3.js, ggplot, etc.
Experience with BI tools such as Tableau, Metabase and Power BI.
Great communication skills.
Analytics Stack: (stackshare link):

Amazon Kinesis, PostgreSQL, Salesforce, Metabase, Amazon SageMaker",3.9,"Lido Learning
3.9",Mumbai,"Mumbai, India",501 to 1000 employees,2019,Company - Private,Primary & Secondary Education,Education,Unknown / Non-Applicable,-1
439,Data Engineer,"42481

Job Summary
You will be part of Enterprise Data & Analytics team responsible for identifying analytical needs, exploring new technologies, and applying data sciences/machine learning concepts to maximize value from data assets. Senior Data Engineer will work closely with key stakeholders both IT and Business to turn data into critical information and knowledge that can be used to make sound business decisions. The individual must have an in-depth understanding of the business environment, an interest in going beyond the obvious, aptitude for new tools/technologies, and obsession for customer success

Essential Functions
Organize, lead, and facilitate multiple teams on highly complex, cross-functional, enterprise data and analytics initiatives
Develop and maintain scalable data pipelines and build out new integrations to support continuing increases in demand for various types of data
Collaborate with key stakeholders to define KPI and build data metrics to measure KPI’s
Define and develop cognitive solutions for business needs, incorporating technologies in Machine Learning, AI, and Analytics
Identify, evaluate and suggest new technology opportunities (including open source) that will have an impact on the enterprise-wide BI systems, machine learning, and predictive analytics
Work with vendors to provide cost estimates and general project management guidance
Job Requirements
Must possess strong subject matter expertise in at least two domains of Sales, Marketing, Install Base, Finance, and Customer Support areas.
Data modeling experience in Enterprise Data Warehouse and DataMart
Hands-on experience in SQL, Python, NoSQL, JSON, XML, SSL, RESTful APIs, and other related standards
Hands-on emphasis with a proven track record of building and evaluating data pipes, and delivering systems for final production
Exposure to Big Data Analytics (data and technologies), Data Sciences, predictive analytics, modelling, machine learning, in-memory applications
Experience with various data systems like Oracle Data Warehouse, SAP HANA, Hadoop/Hive, Vertica, Redshift, Presto, Mangodb
Strong understanding devops, on-premise, and cloud deployments - AWS, Google, Azure
Education
Minimum of 8 to 12 years of experience with Bachelor of Science Degree in Computer Science, Management Information Systems, or Business, or related field is required

Job Segment:
Database, Developer, Warehouse, Oracle, ERP, Technology, Manufacturing

Apply now »",4.1,"NetApp
4.1",Bengaluru,"Sunnyvale, CA",10000+ employees,1992,Company - Public,Enterprise Software & Network Solutions,Information Technology,₹500+ billion (INR),"Nimble Storage, Pure Storage"
440,"Data Scientist, Data Engineer, Deep Learning,","Opening for Data Scientist At Bangalore (Hebbal )

Experience- Min 2 Years
Location - Bangalore (Hebbal )

Role & Responcibility -

2 - 4 years of experience applying ML / Deep Learning algorithms and techniques to real-world data sets
Expert knowledge of Core Python
Proficiency in Machine learning algorithms (SVM, Decision Trees, PCA, Clustering etc.)
Knowledge and Experience of Deep Learning Algorithms (CNN, RNN, LSTM etc.)
Major ML frameworks: TensorFlow, PyTorch, Keras, Scikit-Learn
Strong analytical thinking
Designs scalable processes to collect, manipulate, present, and analyze large datasets in a production-ready environment
Strong written and oral skills (in English)
Demonstrated participation on platforms like Kaggle is a plus
Prefer great appreciation or expertise in Security products such as End point detection, protection and response, Managed detection and response etc
Kindly revert your Opinion
00-6.00 Years",-1,TechPro HR Consultancy,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
441,Creative/ Data Analytics Manager,"Will be responsible for understanding various types of content that is created for a client, and data points that originate from that content (impressions / views / clicks) and help relate what content works and what does not work. Will be responsible for leading, developing and managing all aspects of Creative Analytics. This person will need to provide an overview into what content is critical, what is performing and what is under performing to senior management. They will need to be able to explain data findings and answer questions in a clear and comprehensive manner. This person will need to explain data at an aggregate level as well as at a granular level. The Manager will work with a variety of data sources to continually monitor, evaluate and report against appropriate KPIs across campaign types for multiple clients. The Manager is responsible for working with internal and external teams. Will need to provide recommendations to inform creative decisions and drive the business forward.

KEY RESPONSIBILITIES
Decipher meaningful differences in performance between creative variations, accounting for variables such as audience segments and impression volumes
Provide creative-level analysis to complement the placement-level analysis (performed by media teams) in order to generate a holistic view of campaign performance.
Provide regular and timely marketing performance analysis against communication plans.
Understand client's business goals and requirements, design and develop analytic approaches tailored to needs.
Develop client tools and services, such as dashboard development and decision aids to support programs, creative and recommended solutions.
Formulate specific and actionable insights
Recommend data strategies (e. g. what we should capture, how we should capture it, and the triggers/actions as a result, etc.).
skills and knowledge required
Understands the implications and analytic approaches with dynamically-served creative and auto-optimization platforms
Must have a firm grasp of reporting for Web site, online advertising, social media and mobile.
Proficiency with programming languages, SQL, Python or R a plus.
Familiarity platforms like Adobe Analytics, Crimson Hexagon, Sprinklr, Excel, Tableau etc
Understands creative analytics best practices.
Understands the creative process that generates content to powerfully engage customers.
Possesses well-developed analytical ability to extract insight from data and translate into creative directions
Strong attention to detail.
EDUCATION/EXPERIENCE REQUIREMENTS

5+ years of experience in marketing analytics or business intelligence (focused in analytics
Experience working for a Creative Media/Advertising agency in an analytics role or a business analyst from a top-tier strategy consulting firm.",4.0,"Mirum Digital Pvt. Ltd.
4.0",Mumbai,"San Diego, CA",1001 to 5000 employees,2014,Company - Public,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
442,CIEL/STF/12950: Data Scientist,"JOB Title: Data Scientist
Experience: 2.5 years - 5 years
Type of position: Contract
Location: Chennai
Shifts: Regular
Notice Period: Immediate to 30 days
Mandatory Skills: SAS, Python, R, SPSS, Spark. Python is mandatory, while having knowledge on R/SAS is preferred.
Mode of Interview: F2F Discussion.
About the Company: It is a data engineering company that offers marketing, supply chain and business analytics solutions.

Job Description:Responsibilities :
Define and develop, maintain and evolve data models, tools and capabilities for
predicting
Provide solutions but not limited to: Customer Segmentation & Targeting,
Propensity Modeling, Churn Modeling, Lifetime Value Estimation, Forecasting,
Recommender Systems, Modeling Response to Incentives, Marketing Mix
Optimization, Price Optimization
Would have exposure in applying different machine learning algorithms and
statistical techniques to domain specific problems.
Identify, develop and implement appropriate statistical techniques, algorithms and
data mining analysis to create new, scalable solutions that address business
challenges across the organization, as well as provide actionable insights with a
clear impact on ROI
Perform extensive exploratory data analysis and use optimal techniques for
preprocessing data
Innovate new modelling and machine learning approaches
Communicate findings through relevant visualizations using tools such Tableau,
QlikView
Collaborate and communicate findings to diverse stakeholders
Requirements :
3+ years- experience in a related position, as a data scientist or business analyst
building predictive analytics solutions for various types of business problems
Programming background and expertise in building models using languages such
as: SAS, Python, R, SPSS, Spark. Python is mandatory, while having knowledge
on R/SAS is preferred.
Strong expertise in handling, manipulating, aggregating/transforming data using
SQL
Advanced knowledge of statistical techniques, machine learning algorithms, data
mining, text mining
Strong story-telling & articulation skills - ability to convert analytical output into
clear, concise, and persuasive insights & recommendations for technical & non-
technical audience
Exposure to Big Data platforms like Hadoop and its eco-system (Hive, Pig,
Sqoop, Mahout) would be a plus

Why do you have to apply:
Its leading global analytics firm.They have trusted partners to enterprises worldwide,
including more than two dozen fortune 500 companies in the retail, cpg, financial, technology and healthcare sectors.

About CIEL HR:
CIEL is a new-age HR Firm, offers Talent Acquisition solutions to its clients leveraging on technology and analytics framework.
Having pioneered several vistas in HR since 1992, the Founders of Ma Foi diversified successfully into the areas of Analytics and Strategy consulting.
The founders along with industry veterans have started their 2nd venture in the HR services market to bring new meanings to the industry through
""Ciel HR Services"" strongly anchored on technology and Analytics.",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
443,Senior Data Scientist / Algorithms Specialist,"Job Description:
Should possess strong design and architecture skills.
Deliver solutions for Fortune 100 customers using an Agile Development model
Understanding and working to come up with solutions to problems, design and architect, Building and collaborating with business and technical teams to deliver software.
Positions : 10

Skillset:
At least 4+ years of solid experience in the software industry
Experience working in / Understanding of Big data a technologies – worked in Hadoop, MapR and Map/Reduce, Pig, Hive
Played pivotal roles as an engineer and architect across domains
Understanding of Big data a technologies – Hadoop, MapR and Map/Reduce, Pig, Hive
NoSQL solutions like Hbase, Cassandra, MongoDB, CouchDB, and be comfortable with commercial solutions too
Expertise in SQL databases (e.g. MySQL or Oracle), Analytics platforms (e.g. Pentaho, BO or similar) and OLAP technologies
Solid technology stack in J2EE and .Net (desirable but not essential)
Be very comfortable with Agile methodologies in order to be able to arrive at difficult engineering decisions quickly.
Good to have experience with MPP databases like Netezza, ETL tools like Informatica, and BI tools like SAS etc.
Good to have knowledge of web Analytics and exposure working with data sources clickstream data etc.
Proven ability to lead a team of engineers

Other Skillset:
Passion for technology and willingness to learn is required
Have ability to work in a fast paced and dynamic work environment and be able to produce efficient and robust solution
High energy, confidence, and agility to drive a team.
A creative thinker who can bring in new ideas and innovations to the company.
Job Type: Full-time

Required experience:
Hadoop, MapR : 2 years

Required education:
Bachelor’s",4.3,"AmyLogic
4.3",Bengaluru,"Jaipur, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
444,Data Analyst,"Roles and Responsibilities:
Analyse complex data sets and convert them into the information which drives business decisions
Design and develop ETL workflows and datasets to be used by Leni
Write Complex SQL queries on multiple tables using complex joins
Perform end to end Data validation
Interact with business users, Data Scientists and understand their requirements

Skills Required:
2+ years of experience in writing high quality, maintainable SQL, NoSQL queries on large datasets
Solid experience in data transformation, analysis, data preparation using tools like Alteryx, Wrangler, Paxata, Datameer etc;
Good understanding of Star, Snowflake Schema and data models in existing data warehouse
Experience with cloud data warehouses like Redshift, Azure SQL DW, Snowflake, Google Big Query
Knowledge in BI tools like Tableau, Qlik, Power BI etc;
Ability to write code in Python, R
Exposure in Big data Technologies (hadoop, spark, etc.)
Knowledge in Elasticsearch & Kibana, REST APIs
Certifications in Data and Analytics software, Database, Business Intelligence will be good to have",3.5,"Lymbyc Solutions
3.5",Bengaluru,"Bengaluru, India",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
445,"Data Scientist (Bangalore, India)","CORESIGHT RESEARCH::
The Coresight Research team, based in New York, London, Hong Kong, and India is a think tank that follows emerging retail and tech trends, specializing in the ways retail and technology intersect, and builds collaborative communities. The team, led by Deborah Weinswig, an award-winning retail and technology analyst, delivers cutting-edge research on topics such as the evolving retail landscape, changing consumer behavior, disruptive retail technologies and the future of supply chains in sectors such as apparel, beauty, grocery, and furniture. More information can be found at Coresight.com.

POSITION OVERVIEW::
The team focuses on leveraging data and analytics to innovatively bring better products to our clients in the retail and technology industries. Based in Mangalore / Hyderabad and reporting into the Head of India and the Head of Data, the Data Scientist will be responsible for developing data dashboards and maintaining reports using various technologies.

RESPONSIBILITIES::
Demonstrate a deep knowledge of and ability to operationalize, leading data technologies and best practices (via various mechanisms: SQL reports, CSV / Excel extracts, Tableau, PowerBI).
Responsible for developing algorithms to automate collection process and adding new features to the current database.
Establish methodologies for quickly rolling out new data analysis capabilities for standalone data-driven products and service to support our associates.
Build architecture and dashboards to support team’s data collection and presentation process
Formulate best practices for the data team; work close with data strategy head to identify areas for performance and improvement.
Identify avenues and methods for relevant data extraction and communicate to stakeholders
Should have experience in using data languages such as R / Python and have experience in web scrapping / writing web crawler.
Have end-to-end responsibility for leading projects focused on well-written documentation, extracting, merging, analyzing and managing large sets of data across multiple, disparate databases.
Develop a proficiency in the retrieval and manipulation of data from spreadsheets, a data warehouse or database environment.
Make decisions independently on analytical problems and methods and able to transform unstructured raw data in to formats suitable for modeling.
Responsible for building up the data science team in India and training those junior data analysts.
Be able to work in teams and collaborate with stakeholders to define requirements
Be able to identify and suggest novel areas of future work for themselves or the team
REQUIREMENTS::
Bachelors Degree/Masters Degree (preferably from a computer application background)
5+ years of experience in similar role
Candidate with Machine Learning and Data Analytics experience
Candidate with programming experience of automating data collection process will be a plus
Strong analytical skills and data modelling skills
Strong writing and oral communication skills
Strong investigative skills - specialists require tenacity and patience to thoroughly review digital assets and have sharp intuitions about data architecture, website layouts, design and functionality
Ability to seamlessly navigate various programs and tools utilized as part of the collection process
The ability to think and work through gaps of knowledge, by being comfortable approaching researchers and managers and asking informed questions whenever there are ambiguities during collection assignments
Impeccable attention to detail as the specificity of data points and high volume of data being collected requires collectors to be meticulous and precise
Extremely detail-oriented/self-motivated/strong time management skills
Ability to work with team members located in different time zones
Open to receive and act on constructive criticism.
Excellent self-organization skills.
Ability to work collaboratively in an open team environment.
A positive attitude and a commitment to bringing fresh ideas to the team.
Coresight Research offers a competitive salary, an entrepreneurial work environment, and realistic growth potential. We value a culture of inclusion and diversity within our workforce. We are committed to maintaining a workplace free from prohibited employment conduct, including discrimination or harassment on the basis of race, color, national origin, sex, age, religion, disability, genetic information, sexual orientation, gender identity or expression, marriage and civil partnership, pregnancy and maternity and any other characteristic protected by law. Coresight Research is an equal opportunity employer.",2.9,"Coresight Research, Inc.
2.9",Mangalore,"New York, NY",1 to 50 employees,2018,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
446,Applied Scientist II,"Do you want to join an innovative team of scientists who use machine learning and statistical techniques to create state-of-the-art solutions for providing better value to Amazons customers? Do you want to build and deploy advanced algorithmic systems that help optimize millions of transactions every day? Are you excited by the prospect of analyzing and modeling terabytes of data to solve real world problems? Do you like to own end-to-end business problems/metrics and directly impact the profitability of the company? Do you like to innovate and simplify? If yes, then you may be a great fit to join the Machine Learning and Data Sciences team for India Consumer Businesses.
If you have an entrepreneurial spirit, know how to deliver, love to work with data, are deeply technical, highly innovative and long for the opportunity to build solutions to challenging problems that directly impact the company's bottom-line, we want to talk to you.
Major responsibilities

·
· Use machine learning and analytical techniques to create scalable solutions for business problems
·
· Analyze and extract relevant information from large amounts of Amazons historical business data to help automate and optimize key processes
·
· Design, development, evaluate and deploy innovative and highly scalable models for predictive learning
·
· Research and implement novel machine learning and statistical approaches
·
· Work closely with software engineering teams to drive real-time model implementations and new feature creations
·
· Work closely with business owners and operations staff to optimize various business operations
·
· Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation
·
· Mentor other scientists and engineers in the use of ML techniques

Basic Qualifications

· A MS or PhD in Computer Science or Machine learning or Operational research or Statistics or in a highly quantitative field
· 5+ years of hands-on experience in applied Machine Learning and Big data.
· Strong grasp of machine learning, data mining and data analytics techniques
· Strong Problem solving ability
· Comfortable using Java or C++/C.
· Good knowledge of scientific programming in scripting languages like R/Python

Preferred Qualifications

· PHD in any of the following disciplines - Computer Science, Machine Learning, Data Mining, Statistics, Operational Research
· Experience with distributed algorithms
· Experience with Hadoop, Hive, Pig, Spark
· Superior verbal and written communication skills, ability to convey rigorous mathematical concepts and considerations to non-experts.
· Experience with Oracle in a Linux or UNIX environment",4.2,"Amazon
4.2",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
447,Senior Data Scientist - Natural Language Processing (NLP),"At LYNK, we connect people with time-sensitive and business-critical questions to a curated community of 500,000+ experts. Our vetted experts span a comprehensive range of sectors and geographies and include world-class analysts, technologists, seasoned C-level executives and experienced consultants. Equally, we are committed to democratising access to knowledge for entrepreneurs, start-ups and the wider communities we operate in. In doing so, we empower our experts to bolster their credentials amongst a broader audience, while gaining access to challenging new projects and opportunities.

Join us, and tackle some of the most challenging problems in natural language processing and large scale applied machine learning. You will build cutting edge natural language understanding technologies and deploy them on a global scale.

What You’ll Do
Deliver data-driven products, insights and inferences employing methodologies in the Data Science and primarily Machine Learning domains
Maintain knowledge of and concurrency with cutting-edge but commercially-viable (resilient and scalable) methodologies in the Data Science and primarily Machine Learning domains
Translate complex and embryonic ideas into tangible data-driven deliverables; iterate; test; and sensibly promote or demise solutions to our customers
Design and implement Semantic-enabled systems, enterprise data lakes and semantic search applications in the intersection of Semantic web and ontology, knowledge graph and domain model, NoSQL and graph database, NLP, Solr/Lucene, text mining and machine learning
Lead and develop ontological knowledge graphs to capture knowledge in domain models and metadata
Build semantic master/ systems to automate data analytics and services using AWS EC2, S3 (distributed data lake), Elastic Map Reduce (computation cluster), Data Pipeline (job management in Spark (Scala) on Hadoop, using Avro and Parquet) and Redshift (columnar data warehouse), and Google Big Query and CloudStorage.
Design domain-driven event models and event sourcing paradigm for a real-time Web-scale ""event"" processing platforms
What Expertise You’ll Add To The Team
Top-notch expertise in Knowledge Representation and Discovery, Semantic Web, Ontology and Knowledge Graph, NLP and text mining
Ideally PhD in a STEM subject directly leveraging the application of Machine Learning to a level where critique of algorithms’ operations/principles comes naturally to you. Extensive experience in lieu of a PhD may be considered
Advanced expertise in at least:
Python,
R,
ML tooling from Cloud providers (ideally AWS)
The ability to train elementary machine learning models such as logistic regression and random forests, to select the right tool or the right task and to judge when a model is good enough for a particular purpose
Experience with a core ML domain sub-speciality such as:
(Deep) Neural Networks,
Natural Language Processing (NLP),
Conditional Random Fields,
Mechanism Design,
Latent Dirichlet Allocation.
Proven track record of implementing a real-world Recommender or Ranking system
Strong experience with Agile delivery methods
Experience in API creation is a strong plus
Solid experience in implementing multi-core/distributed software
Experienced in solving real problems using machine learning techniques and with statistical rigor
Excellent communication skills; the ability to convey complex analysis results clearly and with conviction to all stakeholder levels
Why join Lynk?
Lynk is a VC- AND revenue-backed, product-driven startup working with leading institutional clients, top level experts and thought leaders globally
We operate in a high-octane environment where our people think about the big picture and always strive to “make it happen”
Our team, spread across five countries today (and growing!), is multinational, multilingual and multicultural. Our clients have likened us to a mini United Nations.
You will be constantly challenged with new problems to solve every day.
We are here to realize big dreams and have a firm belief in our core mission – to democratize access to knowledge.
Bonus Attributes
Strong passion for business and enthusiastic about taking part in shaping Lynk’s growth
Function well in a very fast-paced startup environment
Track record of excelling in small teams
Team players who thrive in uncertainty and like to “make things happen”!
What We Commit To You
Competitive remuneration package in a rapidly-expanding startup
Work in a collaborative, co-creation hub in the heart of the city - with amazing facilities
Comprehensive medical insurance coverage, including dental
Generous leave policy, including a ‘work remote policy’
The opportunity to travel and work around the globe with our international clients and growing number of offices (Hong Kong, Shanghai, Singapore, Mumbai, Hyderabad, New York City)
The opportunity to be a part of something impactful.
Notes:

- LYNK employees are prohibited from trading Restricted Securities (defined as any security whose performance is linked to a single company) for any Personal Trading Account.

- All future new joiners are required to undergo a background check.",2.1,"The Straits Network
2.1",Hyderabad,"Hong Kong, Hong Kong",51 to 200 employees,2015,Company - Private,Financial Analytics & Research,Finance,Unknown / Non-Applicable,-1
448,Data Analyst,"Data Analyst, Operational Data Intelligence


The Who, What, Why and Where

Twilio is growing rapidly and seeking a Data Analyst to be a key member of the Observability organization's Operational Intelligence Engineering team in Bangalore, India. You will be joining one of the first teams of engineers in our new Bangalore office and as the first Data Analyst, with an opportunity to help define our technical and team culture in India. You will also help us build solutions that deliver actionable intelligence from a number of mission-critical systems, ensuring that Twilio is the leader in trusted communications. A successful candidate will be a self-starter, embody a growth mindset, collaborate effectively, can mentor junior engineers and operate highly resilient services.

Who?

Twilio is looking for a strong data analyst who lives the Twilio Magic and has a demonstrated track record of working with data, specifically; sourcing and integrating data from multiple disparate backend data sources, developing business intelligence solutions and applying a deep analytics background to assess business performance and deliver actionable insights to improve efficiency and increase productivity. You should also have:
You have 3+ years experience in a data analyst role and have proficiency in statistical tools to do descriptive, predictive and diagnostic analyses
You have 3+ years experience creating complex SQL statements.
You have 3+ years experience in custom ETL design, implementation and maintenance.
You have 3+ years experience working with BI tools like Looker, Tableau.
You have 3+ years of experience working with Hive, Presto, Redshift, Snowflake etc.
You have 3+ years experience with schema design and dimensional data modeling.
You are proficient in at least one major language such as Python, Scala, or Java.
You have strong analytical skills with the ability to collect, organise, analyse, and disseminate significant amounts of information with attention to detail and accuracy
You have strong communication skills, and can effectively partner with analysts, product managers, engineers from across the business (Finance, Sales, Marketing, etc.)
What?

As a Data Analyst on the Operational Data Intelligence team, you will:
Work directly with the business (primarily GMs, engineers and product managers) to define the datasets, reports, dashboards they need to run their product engineering organizations
Build and launch robust data processing pipelines and integrations, while simultaneously optimizing for performance and stakeholder requirements.
Build data sets that provide trends and insights into engineering operational data: quality, performance, defects, deployment velocity, etc
Ensure uptime and performance of data warehouse system.
Why?

Twilio has democratized communications channels like voice, text, chat, and video by virtualizing the world's telecommunications infrastructure through APIs that are simple enough for any developer to use, yet robust enough to power the world's most demanding applications.

The Operational Intelligence Engineering team is central to Twilio's continued growth. Our mission is to provide actionable insights from a vast number of different systems leveraged by product engineering teams to build, deliver, and operate their globally distributed services, arming them with the knowledge they need to continuously improve their quality, security, velocity, and efficiency. To do this we need to continue to develop and evolve our products and services and ensure they are able to scale; driving Twilio to new heights of scale.

Twilio is a company that is empowering the world's developers with modern communication in order to build better applications. Twilio is truly unique; we are a company committed to your growth, your learning, your development, and your entire employee experience. We only win when our employees succeed and we're dedicated to helping you develop your strengths. We have a cultural foundation built on diversity, inclusion, and innovation and we want you and your ideas to thrive at Twilio.

Where?

This position will be located in our office in Bangalore, India. You will enjoy our office perks: catered meals, snacks, game room, ergonomic desks, massages, bi-weekly All Hands and more. What you will also get to experience is a company that believes in small teams for maximum impact; seeks well-rounded talent to ensure a full perspective on our customers' experience, understands that this is a marathon, not a sprint; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves.

About Us

Millions of developers around the world have used Twilio to unlock the magic of communications to improve any human experience. Twilio has democratized communications channels like voice, text, chat, video and email by virtualizing the world's communications infrastructure through APIs that are simple enough for any developer to use, yet robust enough to power the world's most demanding applications. By making communications a part of every software developer's toolkit, Twilio is enabling innovators across every industry — from emerging leaders to the world's largest organizations — to reinvent how companies engage with their customers.",3.9,"Twilio
3.9",Bengaluru,"San Francisco, CA",1001 to 5000 employees,2008,Company - Public,Internet,Information Technology,₹100 to ₹500 billion (INR),-1
449,Data Analyst,"Data Analyst

Corporate Overview

QuinStreet makes the digital media channel affordable at scale for marketing clients. We match high-intent consumers in one of the nation’s largest media networks to the right solution and the right client.

Our industry leading segmentation & matching technology platform allows marketing clients to target and reach “research & compare” customer prospects, segment by segment. Our databases and optimization algorithms are built from almost 20 years and billions of dollars of online media experience.

We believe in the direct measurability of digital media. We believe in performance marketing. (We pioneered it.) And we believe in the advantages of technology. We bring all of this together to deliver truly great results for our clients in the world’s biggest channel.

Data Analyst

QuinStreet makes the digital media channel affordable at scale for marketing clients. We match high-intent consumers in one of the nation’s largest media networks to the right solution and the right client.

Our industry-leading segmentation & matching technology platform allows marketing clients to target and reach “research & compare” customer prospects, segment by segment. Our databases and optimization algorithms are built from almost 20 years and billions of dollars of online media experience.

We believe in the direct measurability of digital media. We believe in performance marketing. (We pioneered it.) And we believe in the advantages of technology. We bring all of this together to deliver truly great results for our clients in the world’s biggest channel.

Job Category

We are looking for an incredibly smart, dynamic and strategic Data Analyst to develop data-driven insights that enable QuinStreet’s Marketing and Media teams maximize profitability while improving customer relationships. Create and execute product reporting to B2B vendor clients on a daily basis. This role will create and execute reports for various product lines – Leads, eSeminars, Display and Clicks – as well as keeping detailed records on campaign delivery and updating/tracking monthly delivery numbers. This person will be extremely detailed oriented, client focused, with the ability to time manage to ensure all reporting is delivered on time and accurately. You will use data mining and statistical methods to extract valuable insights from our data that lead to maximizing ROI.

Responsibilities

Data diagnostics – extracting, scrubbing and patching very large sets of data together from a variety of internal and external sources

Reporting – summarizing data and automating reports around campaign performance, which will be utilized frequently in client interactions

Forecasting – creating predictive models for new and existing clients relating to site traffic, conversion and pricing

Campaign Optimization – creating hypothesis tests and regression models to continuously calibrate campaign attributes to achieve maximum client spend and ROI

Effectively communicating your insights and findings to other members of our Marketing and Media teams

Qualifications

B.S. degree in quantitative major like Statistics, Mathematics, Operations Research, Physics, Computer Science or related

M.S. degree strongly preferred in one of the majors mentioned above

3+ years of experience in an analytical role, applying statistical methods

Strong applied analytics: proven business and analysis skills

Strong and persuasive communication skills: exceptional visualization, verbal and written communication skills that have helped expand your analytical influence

Outstanding problem solving skills: you’re not just repeating a playbook, you’re looking at every problem with fresh eyes, and digging deep for insights and solutions

Independence and proactivity: self-starter with demonstrated experience in leading and delivering impactful solutions to large business problems

Interpersonal and presentation skills: you are able to confidently communicate and present insights and recommendations to senior management

Proficiency in MS Excel and familiarity with database systems (Oracle, SQL Server, etc)

Tableau and SQL experience is a plus

“#LI-DNI”",3.3,"QuinStreet
3.3",Pune,"Foster City, CA",501 to 1000 employees,1999,Company - Public,Advertising & Marketing,Business Services,₹10 to ₹50 billion (INR),-1
450,CIEL/SEL/13974: Data Scientist,"Manage a team of data scientists, machine learning engineers and big data specialists
Lead data mining and collection procedures
Proven experience as a Data Scientist or similar role
Solid understanding of machine learning
Knowledge of data management and visualization techniques
A knack for statistical analysis and predictive modeling
Good knowledge of R, Python and MATLAB
Experience with SQL and NoSQL databases
Strong organizational and leadership skills
Excellent communication skills
A business mindset
Ensure data quality and integrity
Interpret and analyze data problems
Conceive, plan and prioritize data projects
Build analytic systems and predictive models
Test performance of data-driven products
Visualize data and create reports
Experiment with new models and techniques
Align data projects with organizational goals
Degree in Computer Science, Data Science, Mathematics or similar field",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
451,Senior Data Scientist,"At Aera, we deliver the cognitive technology that enables the Self-Driving Enterprise™: a Cognitive Operating System™ that connects you with your business and autonomously orchestrates your operations. Aera's Cognitive OS leverages the best of artificial intelligence, machine learning, natural language processing, big data, and enterprise domain expertise to deliver Cognitive Automation at scale for some of the world's largest companies.

Aera Technology is looking for an expert Senior Data Scientist based in Pune, India. You will be working on new and challenging data science problems. This is the chance to be part of Aera's growing Data Science team, led by one of Aera's longest-tenured Engineering leaders!
Responsibilities
You will be responsible for designing, implementing, monitoring and maintaining our machine learning systems that powers the Aera platform
You will be working in a highly-collaborative environment with other experts in data science and engineering
Transform business problems into data problems
Research and build statistical/machine-learning models
Perform Exploratory Data Analysis and Statistical Analysis; clearly present the results of an analysis to customers and management
Collaborate with other team members to build data-science products and services using the Aera platform
About You
Master’s Degree in Computer Science, Mathematics, Statistics or a related quantitative field with a focus on Machine Learning or Deep Learning. Ph.D. preferred
7+ years of professional experience as a Machine Learning Engineer/Data Scientist; in a product development setting
Hands-on experience with software development, including translating ML models into scalable production services
Good intuitive understanding of machine learning algorithms and practical experience building models with incremental/iterative approach
Strong in Python
Experience in Full-Cycle Data Science projects
Experience in implementing machine learning algorithms using APIs/libraries from scikit-learn, H2O, MLlib and TensorFlow
Hands-on experience with software development, including translating ML models into scalable production services
Experience in working with large data sets and pipelines, distributed systems for machine learning using frameworks such as Apache Spark
Excellent verbal and written communication skills
You take complete ownership of your work and are self-driven
At Aera, we're on a mission to solve the biggest, most intractable challenges in the world of enterprise software. We envision the rise of the Self-Driving Enterprise: a more autonomously functioning business with a central operating system that connects and orchestrates business operations. Our Cognitive Operating System is increasingly used by the world's largest companies to fundamentally transform their organizations and how work is done.

If you share our passion for building the next generation of enterprise software, and deploying it for the most sophisticated customers in the world, you’ve met your match. Headquartered in Mountain View, California, we're growing fast, with teams in Mountain View and San Francisco (California), Bucharest and Cluj-Napoca (Romania), Paris (France), Munich (Germany), London (UK), Pune and Bangalore (India), Sydney (Australia) and Singapore. So join us, and let’s build the future of work together!",3.5,"Aera Technology
3.5",Pune,"Mountain View, CA",201 to 500 employees,2017,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,"Elementum, Qlik"
452,Jr. Data Scientist,"About i3systems
I3systems is a market leader in Speciality Artificial Intelligence Products. It is well-known among
Insurance companies in India for its first two products. Its first product called DataMD is used for
medical underwriting automation while its second product i3claim is used for medical claim
processing automation.
We are backed by Industry Leaders and Unitus Ventures which is an Impact Venture Capital
Fund. It is driven by a technically strong team from IIT and backed by Insurance experts.
I3systems is looking for professionals who have a knack for Analytical thinking and Creative
problem solving, to develop leading Artificial intelligence products for Large scale Insurance
companies and Financial Services companies in India and abroad. We believe in solving Clients
problem using modern technologies, hence special interest and commitment towards Data
Science is a must.
Day-to-day Responsibilities:
We expect you to work on complex, cross-functional analytical and research-oriented
projects using advanced computational, machine learning and deep learning algorithms.
You will perform data aggregation and preprocessing of large amount of structured and
unstructured data in the form of images, text, documents etc.
You will participate in prototype development for specific Business use cases from the
Insurance, Healthcare or Financial services industry using modern machine learning
methods.
You will perform statistical and conceptual error analysis of the outputs/ predictions from
machine learning models or data processing techniques
You will devise statistical validation methods for ensuring the right kind of data flow into the
AI models and the User-interface.
You will test the infrastructure requirement and processing speed of the models to make it
suitable for real-time processing environment
You will build sophisticated visualisation for model output which can then be integrated into
the processing pipeline.
You will also get a chance to present your solutions and brainstorm on the business use
cases with our Enterprise partners in the Insurance industry.
Requirements
Undergraduate degree in Engineering from premier institutions such as IIT, BITS, NIT, State-
Boards etc. is preferred but not necessary.
Strong inclination for first principles thinking and sound knowledge of mathematics
fundamentals is a must.
Basic knowledge of machine learning algorithms such as Random Forests, SVM, Neural
Networks, LSTM, Deep-learning etc. is sufficient.
1-3 years of experience working in the software industry, preferably as a Fullstack or a
Backend developer using Python/Django/MySQl/AngularJS stack.
Practical experience in using Python for performing both data-analysis is necessary; and
building production level code for processing pipe-line is preferred
Familiarity with algorithms in recommendation systems, chatbots or utilisation of Natural
Language processing techniques for identification/extraction of key features of a model; will
be a plus over other candidates
Knowledge of Relational database (MySQL) is required and any exposure to specialised data
frame-works such as Django or Hadoop/Spark or Elasticsearch/Neo4js is a big plus.
Knowledge of collaboration tools like Asana/Git/Docs/Slack/etc. is a plus
Perks : How fast you grow within the company is only dependent on your performance and
commitment:
Be a part of rapidly growing AI technology company, in a client facing role
Build your knowledge and experience in the niche area of building AI products for
Financial services industry
Work from the heart of startup ecosystem in Mumbai, the evergreen Powai Valley
All employees are rewarded with above market-rate salary
Job Types: Full-time, Walk-In
Salary: ₹600,000.00 to ₹1,000,000.00 /year
Experience:
work: 1 year (Preferred)
3: 1 year (Preferred)
Education:
Bachelor's (Preferred)",4.0,"i3Systems
4.0",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
453,Deputy Manager - Data Scientist,"Job Summary

Experience:
6 - 9 Years

Location:
Mumbai

Designation:
Deputy Manager - Data Scientist

Degree:
BE-Comp/IT, BE-Other, BTech-Comp/IT, BTech-Other, ME-Comp/IT, ME-Other, MTech-Comp/IT, MTech-Other, PG-Other, PhD-Comp/IT

Educational Level:
Graduate/Bachelors

Industrial Type:
IT-Software/Software Services

Functional Area:
IT Software - Application Programming / Maintenance

Key Skills:
Data Scientist

Job Post Date:
Wednesday, April 15, 2020

Company Description

We are capability centre based in Mumbai, initially started as a back-office operational support to the UK business unit.

However, over the recent years, we have significantly increased the breadth and depth of our capabilities and offerings to keep pace with the changing needs of the Group. These include Digital & Knowledge Services, Finance and Actuarial, Information Technology (IT), Customer Service, Risk and Audit.

Our core purpose is to be a strategic partner to company, enabling growth by delivering change and driving synergies through a highly capable and agile workforce.

With our diversified service offerings we provide our people with exciting opportunities to grow personally and professionally.

Company is a leading savings and investments business serving around 5.5 million retail customers and more than 800 institutional clients.

It-s innovative asset management and customer solutions are supported by extensive investment capabilities, an international distribution network and two strong brands.

Job Description

6 – 9 years’ experience as Data Scientist
Must have deep experience in Machine Learning
Excellent Python skills
Exposure to advanced deep learning techniques such as LSTM. CNN, Dense neural networks as well as neural networks design and implementation through tools like tensorflow, keras, pytorch, deepai or equivalent.
Experience of working in multiple text mining / NLP solution
Should have experience of deploying and putting into production ML based solution
Good SQL expertise",3.8,"Sampoorna Computer People
3.8",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
454,Data engineer,"People come to work at Parallel Wireless because we are building the future of telecom. They stay, because they are challenged and driven by an incredible product and team. We take pride in our commitment to employee development, and our culture fosters an atmosphere of empowerment, trust, respect, and communication. Learn more about our mission, vision and values.

We are looking for Data Engineer with goood hands on Data engineering and Advanced Analytics experience
What you will do :
As a Data Engineer you will a part of the Data Engineering and Advanced Analytics team; building fast and reliable data pipelines to collect data from thousands of remote wireless devices in distributed cloud
Develop code in Python, Golang and Scala to perform stream analytics, log analytics, monitoring and store data in NoSQL databases for analytics model development
Deploy containers in Kubernetes clusters to collect and analyze data
Follow software engineering best practices by estimating, documenting, and developing work products
Work in a fast-paced development environment applying advanced tools and technologies solving hard data engineering problems
What you will have:
Experienced in developing distributed data processing pipelines in Pandas, Kafka, for 2-3 years
Strong skills in writing code using Golang, Python, C/C++ or Java or Scala with unit tests
Proficiency in time-series databases and/or big-data data management: Prometheus, Influxdb, TSDB, Hadoop, Cassandra, Hbase, Hive
Familiarity with DevOps environment using tools, Jira, Git, Jenkins and CICD
Knowledge of packaging code as Micro-services and containers in Docker, Kubernetes
Additional skills:
Experienced working in teams responsible for monitoring solutions using time-series analysis
Experience in developing UI with charts and graphs
Familiarity with other pieces of our technical stack (Prometheus, Grafana, HAProxy, Elasticsearch, Airflow)
Understanding of Linux and distributed computing
Education:
Bachelor or Master degree in CS or Math or Engg

Parallel Wireless is the leading U.S.-based company challenging the world’s legacy vendors with the industry’s only unified ALL G (5G/4G/3G/2G) software-enabled OpenRAN solutions. Its cloud-native OpenRAN and network architectures redefine network economics for global mobile operators in both coverage and capacity deployments, while also paving the way to 5G. Through open collaboration with the OpenRAN ecosystem partners, Parallel Wireless has created the world’s first and largest fully-compliant OpenRAN ecosystem that is capable of delivering next generation wireless infrastructure at a dramatically lower cost, ensuring more equal access to 5G across the globe. The company’s OpenRAN portfolio is designed to help customers modernize their networks, reduce deployment costs and complexity, increase operational efficiency, enable interoperability, find new revenue streams, and start deploying multi-vendor 5G networks today. The company’s customers include over 60 global mobile operators, as well as private and public industries and governments that use their software-defined network portfolio to reimagine their networks. Parallel Wireless's innovation and excellence in multi-technology, open virtualized RAN solutions have been recognized with 65+ industry awards. Please visit www.parallelwireless.com for more information.",3.0,"Parallel Wireless
3.0",Bengaluru,"Nashua, NH",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
455,Data Engineer: Enterprise Content Management,"Introduction
At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. To lead in this new era of technology and solve some of the world's most challenging problems.

Your Role and Responsibilities
As an OpenText Solution Architect, you will work in large-scale and complex business and technical environments, experienced in managing complex structured and unstructured content solutions or initiatives.
Responsibilities:
Define the technical strategy and plan for modeling the Enterprise Content Management (ECM) to enable the development of high value solutions with business needs
Collaborate with Analysts and Partners on requirements and solution design
Design code based on development standards and approaches
Perform development quality checks while providing guidance and mentorship to junior developers
Develop new applications, forms, reports, workflows leveraging different Open Text products in the landscape
Support with code build and deployment process
Coordinate communications, issue resolution, implementation and testing plans, training plans and successful transition to support and maintenance teams of architecture and operations activities
Responsible for guiding and reviewing the development of solutions specified in technical design
If you thrive in a dynamic, collaborative workplace, IBM provides an environment where you will be challenged and inspired every single day. And if you relish the freedom to bring creative, thoughtful solutions to the table, there's no limit to what you can accomplish here

Required Technical and Professional Expertise
Minimum 5+ years of experience SAP OpenText ECM, OpenText Archiving and Document Access and OpenText Data Archiving for SAP Solutions
Experience integrating Open Text solutions with SAP S/4 HANA
Experience in working on OpenText Content Server/Livelink and other related OpenText products
Experience working with various module integrations with OpenText
Ability to prioritize and manage work while proactively monitoring and communicating for timely escalation of issues
Proven experience on the OpenText Content Server platform (using Content Server Web Services, REST APIs, OScript)
Hands on development experience with HTML, CSS, JavaScript, XML/XSL and SQL
Experience working with Workflows, CS Widgets, Workspaces, Connected Workspaces, Web Reports, Web Forms, Templates in Livelink/Content Server Java or NET development experience with good knowledge of Object oriented programming concepts and Service Oriented Architecture
Preferred Technical and Professional Expertise
Good understanding of the overall ECM processes and concepts (Capture, Manage, Store, Preserve, Deliver)
Experience working with other OpenText products like Archive Server, OTDS, Enterprise Scan, Enterprise Connect, Document Pipeline, Rendition Server, Capture Center, InfoFusion, OTMM, EPS, Process Suite, Output Center is preferred
You love collaborative environments that use agile methodologies to encourage creative design thinking and find innovative ways to develop with cutting edge technologies
Ambitious individual who can work under their own direction towards agreed targets/goals and with creative approach to work
Intuitive individual with an ability to manage change and proven time management
Proven interpersonal skills while contributing to team effort by accomplishing related results as needed
Up-to-date technical knowledge by attending educational workshops, reviewing publications
About Business Unit
IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter business by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world. What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Kolkata,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
456,Machine Learning Engineer,"Position: Machine Learning Engineer
Location: Chennai
Experience Required: 0 to 4 years

Skillsets:
Programming knowledge - Must be good in C++ (oops, machine vision libraries)
Technical knowledge - Should have a good understanding of the following
Knowing SLAM is an added advantage
Linear algebra and Matrix manipulations
Image related concepts like segmentation, feature detection, matching, 2D and 3D transformation, stereo correspondence, and matching, etc
ROS concepts, along with other open-source vision algorithms",3.2,"e-con Systems
3.2",Chennai,"Chennai, India",201 to 500 employees,2003,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
457,Data Science Engineer,"Job Description :


Minimum qualifications :
Prototype ideas, research and develop statistical models, and run experiments
Iterate in order to design data-driven solutions that help solve critical business problems
Better understand company needs and contribute innovative ideas to enhance or develop products using new or existing data streams
Improve and support existing data science products
Develop custom data models and algorithms
Build tools and processes that help monitor and analyse performance and data accuracy
Leverage predictive modeling to optimize targeting, revenue generation, customer experiences, and more
High-level of proficiency in SQL
Experience in data mining techniques
Knowledge of advanced statistical methods and concepts
Extensive knowledge of predictive modelling algorithms and frameworks
Experience working with machine learning techniques (for example, artificial neural networks, clustering, and decision tree learning)
Experience developing automated workflows (Python or R)
Must be able to visualize data with the aid of data visualization tools such as ggplot, d3.js and Matlab, and Tableau etc.
Must be able to discern which problems are important to solve for the business is critical, in addition to identifying new ways the business should be leveraging its data.
Should focus on delivering value and building lasting relationships through communication.
Preferred qualifications:
Candidate needs to be proficient in one or more analytic software tools or languages (e.g., R, Python, Hadoop) with at least 1.5+ Years of work on live projects.
Experience in applying data mining and machine learning techniques
Strong programming knowledge in Python is preferred.
Key Job Attributes :


data mining
data modeling

Educational Qualifications :


B.E/B,Tech

Key Skills :


R
Python
Hadoop
SAS

Contact Details :


Email Id : anbu@handigital.com",3.6,"Han Digital Solution
3.6",Bengaluru,"Bengaluru, India",51 to 200 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
458,Data Analyst,"You will be working closely with the Product Team to share data driven insights on user experience, user journey and strategic issues in the game.

RESPONSIBILITIES
Create models for dynamic data analysis
Execute quantitative data analysis to draw actionable insights
Provide data driven decision making support on product features
Understanding data to decode patterns and develop user behaviour insights
Monitoring and performance analysis of product features
Opportunities to learn new things as we move along in our journey
REQUIREMENTS
Experience in analyzing data and creating meaningful insights
Hands on knowledge of SQL, R/Python is a big plus
Passion for gaming and development
Technical expertise regarding data models, database design development, data mining and segmentation techniques
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Preference for working without a handbook, with a love for doing what’s never been done before
To Apply, please submit your Resume along with your LinkedIn profile to: joinus@hitwicket.com",4.3,"Hitwicket
4.3",Hyderabad,"Hyderābād, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
459,Sr Data Analyst,"Join a team recognized for leadership, innovation and diversity


Sr Data Analyst - MDM

JOB DETAILS:

Position: Sr Data Analyst - MDM

Experience: 8+ years

Key Job Responsibilities

· Very strong implementation experience in Master Data Management tools specialized in the areas like Customer, Vendor, Locations, Product, Materials etc.,

· Lead large MDM implementation for full SDLC lifecycle using Informatica MDM

· Provide Subject Matter Expertise on data architecture and data integration implementation for Enterprise Architecture

· Perform review of Informatica MDM low level design configuration monitoring deployment and implementation of Informatica MDM Platform Version 10.x

· Point of Contact for MDM strategy Process, Design high level MDM architecture requirement and the implementation plan

· Participate in requirements elicitation, Performance tuning of Application Database and Informatica MDM platform

· Collaborate with various technical teams and business users for Development, QA and Operations Support

· Responsible for overall MDM solution with proven system development experience in defining architectural framework standards processes in the master data functions

· Architecture selection criteria (Alternate design, parameter selection, evaluation methods etc.)

· Deliver business value through Right and Fast partnership

· Join a high-performing team and distinguished talent pipeline

· Build strong relationships with leadership to effectively deliver contemporary data analytics solutions and contribute directly to business success

· Implement error and exception handling, auditing, data purging and restoration in ETL jobs.

· Assisting deployment teams with migrating ETL jobs to higher environments.

· Partners with Business/Requirement and Analyst Lead

· Understand overall enterprise architecture and technical requirements for building up a data management platform.

Must have

· Overall IT experience of over 10 years with a minimum of 5 years in the capacity of master data management implementation and technical responsibilities

· Very strong implementation experience in Master Data Management tools specialized with Informatica MDM and suite of tools

· Good knowledge of Informatica MDM, Exits Match HM IDD E360 BES SIF

· Expert in SIP calls and MDM API for create, search and CRUD functionalities

· Good Knowledge of ETL and Data Quality Concepts, knowledge of basic concepts of Java PL SQL. Awareness of MDM trends MDM Concepts and other MDM tools

· Ability to create and analyze unit and system test cases. To be able to debug ETL workflows, SQL code snippets and defect fixing.

· Must possess a strong background in database systems like Oracle, SQL Server, DB2 or Teradata with SQL scripting.

· Deep knowledge in Data Integration, Data Quality, Metadata Management and Data Governance.

· Experience in Requirement Analysis. Strong ability to analyze user requirements into technical solutions as per the specifications.

· Ability to design the System, Data and ETL architecture based upon the requirements

· Knowledge on Data Modeling / Architecture

· Proven experience working with Service Oriented and Event Driven Architectures SOA EDA JMS messaging SOAP and RESTful services

· Ability to predict and quantify technical risks in the project

· Analytical and communication skills (both verbal and written)

· Ability to architect and design, define standards and follow industry best practices for ETL development.

· Experience in creating ETL jobs with delta detection, SCD implementations, bulk loads, real-time integration.

We Value

· B.E in Computer Science or equivalent

· Expertise in the concepts of data warehousing and dimensional modeling.

· Critical Thinking, excellent Communication, Detail Oriented, Creative and Adaptive.

· Ability to work independently and in a team with good analytical, debugging and problem solving skills

· Strong communication skills, both oral and written, with the ability to convey thoughts and ideas clearly.

· Good experience and knowledge on Agile methodology.

· Excellent communication and interpersonal skills.

· Hands-on experience in Informatica Power Center, Big Data technologies and Cloud implementations.

""CORPIT2020""

Additional Information
JOB ID: HRD94067
Category: Information Technology
Location: Devarabisanahalli Village, KR Varturhobli,,East Taluk - Phase I,Bangalore,KARNATAKA,560103,India
Exempt
Business Services",3.8,"Honeywell
3.8",Bengaluru,"Charlotte, NC",10000+ employees,1885,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"GE, Johnson Controls, United Technologies"
460,Data Analyst,"Job: Technology
Primary Location: ASEAN & South Asia-India-Bangalore
Schedule: Full-time
Employee Status: Permanent
Posting Date: 05/Jun/2020
Unposting Date: 10/Jun/2020

About Standard Chartered
We are a leading international bank focused on helping people and companies prosper across Asia, Africa and the Middle East.

To us, good performance is about much more than turning a profit. It's about showing how you embody our valued behaviours - do the right thing, better together and never settle - as well as our brand promise, Here for good.

We're committed to promoting equality in the workplace and creating an inclusive and flexible culture - one where everyone can realise their full potential and make a positive contribution to our organisation. This in turn helps us to provide better support to our broad client base.

The Role Responsibilities

A Data Analyst interprets data and helps turn it into information that enables or improves a business process, thus affecting business decisions. Data Analysts gather information from various sources and interpret patterns and trends to make it digestible for others. They must have strong analytical skills, but above all have a burning curiosity to understand, and make sense of, data. They will work closely with:

Data Managers, who define the team's business requirements, objectives, strategy and priorities
Data Engineers, who design and implement the processes by which data is collected and generated
Data Quality Analysts, who define data quality control requirements and oversee these on a day to day basis to ensure constant system health
Upstream data teams, who provide the data that the analyst is sourcing
Downstream Process Owners, who depend on the data to perform their business function

Data Analysts spend much of their time working with stakeholders to define data requirements, data transformation logic and supporting the delivery of these requirements from start to finish. They are experts in profiling data to understand its contents and will also have a working understanding of the business process or product that generated it in the first place. Data Analysts are the entry point to the FCC Data Team for most external stakeholders and as such will have a broad, but still detailed, understanding of all the data available and constantly seek opportunities for innovation and expansion. They are the primary liaison between up- and downstream teams.

Define clear, concise and detailed business requirements for FCC Data that clearly document the data elements and formats that are needed, outline detailed transformation expectations and list the critical data elements that will enable downstream processes to operate effectively
Create and maintain documentation that articulates the process by which data is extracted, transformed and loaded in FCC that can be shared and understood by others
Work with downstream FCC business process owners to constantly improve, refine and expand the datasets to improve the quality and effectiveness of those processes, as well as help them to make sense of the data, providing training where required, and derive meaningful BI / MI
Conduct detailed analysis of upstream changes that impact FCC data – for example the introduction of a new products – to ensure that requirements remain up to date and define any new ones as necessary
Identify areas of overlap or data gaps that can lead to increased value, either by eliminating redundant processes or expanding existing data models
Produce accurate and insightful dashboards and reports detailing the health, content and insights available from the data, making that actionable for stakeholders and meaningful for management decision making.
Regulatory & Business Conduct

Display exemplary conduct and live by the Group’s Values and Code of Conduct.

Take personal responsibility for embedding the highest standards of ethics, including regulatory and business conduct, across Standard Chartered Bank. This includes understanding and ensuring compliance with, in letter and spirit, all applicable laws, regulations, guidelines and the Group Code of Conduct.

Effectively and collaboratively identify, escalate, mitigate and resolve risk, conduct and compliance matters.

Our Ideal Candidate
Minimum 5+ years of professional experience as business change analyst in financial markets related banking products
Degree (or similar) in Engineering and MBA is preferred
Able to seamlessly move and translate between detailed functional data requirements and non-technical general terms
The ability to write clear, concise and detailed business requirements that can be understood by data engineers and developers as well as business stakeholders
Competence with data profiling tools and methodologies (SQL at a minimum), with a preference for dedicated and sophisticated tools such as Paxata or Tableau
Familiar with data documentation, delivery workflow and defect tracking tools – JIRA and Confluence in particular
Demonstrated experience in handling and understanding large datasets and relational databases
Experience in analytical roles with a large technical component, although not necessarily from a purely data perspective (e.g. they may have prior working knowledge of upstream or downstream processes that is relevant from a data perspective)
Evidenced ability to execute and enhance a process to maintain data transformation requirements over time and constantly seek to improve these
High quality written and verbal communication skills, with the ability to focus on multiple initiatives and data subjects (types of data or varying sources of data) at the same time
Evidence a very strong attention to detail, reflecting the very low tolerance for error in FCC data

Apply now to join the Bank for those with big career ambitions.",3.7,"Standard Chartered
3.7",Bengaluru,"London, United Kingdom",10000+ employees,-1,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
461,Data Engineer,"Overview


INBE is a Bangalore-based technology startup that’s building a retail platform — Paisool — for Kirana stores, small retailers and neighbourhood supermarkets. This is our attempt at reimagining the urban grocery retail space. Paisool, with its super simple Point of Sale device, uses distributed learning systems to understand buying behaviour of households and localities. This knowledge is used to help stock the stores with hyper-targeted inventory from our curated marketplace of products and suppliers — thus, offering a superior selection for consumers while optimising inventory & cash flow for stores. Our platform is live in 15 pilot stores, with plans to add another 85 stores by 31st March 2018.

Paisool Data Platform collects, store, analyse and visualize data to better business insights on urban grocery consumption space. Developers use that information to identify problems and generally make our platform and app ecosystem more awesome. To build data-driven features, and foster a data-informed culture. We need your help!

As a Data Engineer at Paisool, you work on the Paisool data platform, that collects the purchase data, Peer networked Paisool platform data pipeline that share and store data, and the tools that enable developers to analyse and visualize the data.

About You


We are seeking an experienced technologist in building trusted data management, data tools and data analytics services. If you are the engineer we are looking for, these next statements will resonate with you. You are someone who can build maintain and mature our data services as a whole, bringing robust, secure and scalable solutions to Paisool. You enjoy solving complex problems, making data more accessible and delivering high-quality service.

What You’ll do :
You will implement and operate data systems to meet the needs of the organization by synthesizing organizational requirements and identifying the best method of presenting the data for business decisions.
Develop, recommend and implement process and procedure changes to systematically improve data integrity.
You will collaborate with cross-functional teams across disciplines such as product, engineering, operations, and marketing to design existing and new features and build data sets for efficient analysis.
You will contribute to Paisool’s data platform and data-driven decision-making by architecting, building, installing, testing, monitoring and maintaining data handling and data management systems.
You will pay attention to industry trends in data science and engineering, evaluating and learning new technologies
You will work with product managers, engineers and data scientists to experiment and build features into Paisool platforms driven by data and algorithms
You will build & deploy machine learning algorithms and statistical models in multidimensional problem spaces.
You will design experiments and interpret the results to draw detailed and actionable conclusions

What you'll need :


A logical mindset is a must, ideally combined with a strong engineering or mathematics background
Deep understanding of experimental design and the scientific method.
2+ years of relevant experience in a software development or programming role.
Demonstrated authority in one, or proficiency in more than one, programming language (Python or R ...)
A strong foundation in database systems (non-relational and SQL); experience working with large datasets is a plus
Good theoretical understanding and previous work experience with relevant algorithms
Ability to deliver on tight timelines and move quickly while maintaining attention to detail
Collaborate closely with cross-functional teams to execute decisions
Self-driven and proactive with the ability to work in a self-guided manner
Excellent communication and organization skills

Bonus Points


Our team requires skills in a variety of domains. You should ideally have experience with some of the areas listed below, and be interested in learning new things. We’re excited to see:
Understanding of distributed systems.
A strong background in statistical foundations of experimental or observational data
Experience with tools and technologies we’re using: Python, Twisted, React Native, CoffeeScript, Polymer, Cordova, WebSockets, WebRTC etc
Experience with product analytics
Experience with machine learning
Working knowledge of web development technologies: HTML, Javascript, CSS
Experience in open-source development and contribution to open-source technology.
If you’re deeply interested in working on Data Engineer post at Paisool and have relevant skills and experience, please consider applying even if your background doesn’t perfectly match our ideal credentials. If you have different experiences and skills from the ones listed above but have something else to contribute, please contact us

hiring@inbe.com",5.0,"Paisool
5.0",Bengaluru,"Bengaluru, India",1 to 50 employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
462,Data Analyst - Intern,"Our Organization is the worlds first integrated enterprise solutions provider; our latest offerings are Social Marketing Suite for agencies, Social Contact Center for BPOs and Social Command Centre for Enterprises. We enable businesses to perform Online Reputation Management, Customer Service, Community Management, Social Media Research & Brand Auditing; Online Sales Lead Generation, and Consumer Sentiment Analysis.

We have already provided solutions through our tool for industry leaders like Tech Mahindra, Wipro, Coffee Day, Star TV, Mahindra Retail and ITC Foods. Simplify360 is also the only company to work with the top media agency groups in the world like WPP and Publicis. It also operates directly or through partners in the US, Malaysia, Korea, South Africa, Saudi Arabia and the Netherlands to name a few. The companys products and services are sold in over 100 countries.

Job Responsibilities:
Positions: Data Analyst

Responsibilities:
$ Detailed qualitative and quantitative assessment of Social Media Data

$ Prepare a detailed report with matrices and findings

$ Using the proprietary Platform in conjunction with other tools to create various Ad-hoc reports

$ Creating Report Dashboards using Excel, SQL, Powerpoint

$ Manula Data Analysing and Data Clensing

Requirements

Skills required:
Mandatory

$ Experience with Advanced Excel and PowerPoint

$ Understanding of social media

$ Highly organized, details orientated and good coordination skill

$ Strong verbal, written and presentation skills

Optional ( Added advantage)

$ SQL & Google Sheet Scripts

$ Excel macros

$ Python

$ Good analytical skill, data analysis and reporting",4.4,"Simplify360
4.4",Bengaluru,"Carrollton, TX",1 to 50 employees,2009,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,"Salesforce, Lithium Technologies, Sprinklr"
463,Data Science Engineer,"Roles and Responsibilities:
Extracting and transforming data from systems like Hadoop and SQL, using tools such as Pig, Scalding, Hive, Presto
Exploring and visualizing data to drive insights
Applying machine learning techniques for a variety of modeling and relevance problems involving users, their relationships, their Tweets and their interests.
Designing and implementing metrics that help teams focus on what to optimize for
Transforming complicated problems into simpler, tractable ones
Requirements:
Experience with one or more object oriented languages like Scala, Java
Experience with scripting languages like Python or Ruby etc.
Experience with statistical programming environments like R or Matlab
Experience with algorithms like pattern matching (fuzzy matching algorithm), pattern generation, distance matching algorithms
Experience with large datasets and Map Reduce architectures like Hadoop and open source data mining and machine learning projects
What You Need for this Position

You should have knowledge of:
Hadoop
SQL
Pig
Scalding
Hive
Presto
Python
Ruby
Scala
Java
Aditional
No. of Positions
Education level
Career level
Experienced",4.8,"Bloom Consulting Services
4.8",Bengaluru,"Nagpur, India",1 to 50 employees,2015,Company - Private,IT Services,Information Technology,₹10 to ₹50 million (INR),-1
464,Data Science Engineer,"Experience : 2 to 4 years
Location : Mumbai

Role Requirement :
Building advanced ML models for statement processing and transaction data processing on top of existing technology stack for understanding Customers better and development of Advanced Credit decisioning tool
Working experience in Consumer businesses or fintech is crucial
Should have built production-level models using NLP (Must), machine learning, deep learning, and other newer statistical techniques, should have worked on Python
Don’t disappoint yourself by not finding your type of job requirement. If you feel you have the talent and you can contribute to our growth, mail your resume and write to us the areas where you can contribute at careers@mystro.in",-1,Mystro,Mumbai,"San Francisco, CA",1 to 50 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
465,"Associate Analytics consultant, Analytics consultant, Senior Analytics consultant (BI)","If you are interested, please email your resume to us at recruitment@quantzig.com
Job Location: Bangalore

Experience: 1+ years

Key Skills: Tableau, PowerBi, SQL, SAS, Spotfire R / Python, Master-level skills in SQL and query languages Excellent written and verbal communication skills

Roles & Responsibilities:
If you are creative, understand design ideas, are detail oriented and know to make amazing visuals, you are the person we are looking for
You should be passionate to make an impact with high degree of work ownership and are self-driven.
You should be creative and passionately curious about exploring data to deliver impactful business insights
Experience in delivery and client facing roles from major analytics service providers in the industry are preferred
You should possess customer-centric thought process and is able to understand client’s business processes with ease, identify problems with precision and develop customized, accurate analytical solutions
Understand efficient coding standards and has a knack to plan for QC checks
Added advantage if you understand Cloud hosting, customizing visualization tools using DAX, data integration with analytical data-streams

Desired Profile:
Be a consultant to our clients. Think out-of-the-box and develop visualization solutions which help clients in solving their business problems
Tremendous passion towards learning is a must. You must be able to merge the art of consulting and the science of Design in visualization
Drive and energy to work hard and achieve success in an entrepreneurial environment
Should have hands-on experience in delivering projects across multiple industries and analytics areas (e.g. Supply chain analytics, Marketing Analytics, Customer Analytics, Digital Analytics, Pricing Analytics etc.)
Deep understanding of at least one tool
Strong communication, storyboarding and presentation skills",4.7,"Quantzig
4.7",Bengaluru,"London, United Kingdom",Unknown,-1,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
466,Associate Data Scientist/ Data Scientist/ Lead Data Scientist,"Job Description
:

Looking for talented individuals to join the Analytics department based out of the Headquarters in Pune – to join colleagues with passion towards data alongside focus on execution through mathematical intuition, curiosity and a positive outlook

Depending on immediate skillsets and role, one will be an essential part of the Analytics team working on
Scorecard Development and Statistical Analysis
Development and deployment of end to end ML/DL/AI driven products and solutions
Machine Learning based data Products development
One will be involved in many industry first data solutions working in a start-up mode. We’re all about creative, self-starting talent who are excited by the very thought of changing an entire industry for the better

We’re all about creative, self-starters who are excited by the very thought of changing an entire insurance industry by caring for our citizens in the best possible and granular way leveraging data and analytics. We continue to accelerate our progress in creation of an Machine Learning driven advanced Analytics function that will integrate ML, Deep Learning, Bayesian or Behavioural Science into software applications to drive operational efficiencies and create business value while delivering a best-in-class experience with all stakeholders and customers.

Working with business stakeholders to understand their most complex business challenges and develop precise and fine-grained problem statements.
Developing high-level solution architectures and working with our team of data engineers and decision science analysts to build, test and assess models that predict and optimize business outcomes based on client’s success criteria.
Develop sophisticated yet simple interpretations and communicate insights to business stakeholders that lead to quantifiable business impact.
Building deep relationship with business stakeholders by understanding their stated but more importantly, latent needs

Programming Skills (across all levels): Proficiency of 8+ (in a scale of 10) in al-least one of Python, R or Java.

Department
:

HO

Open Positions
:

1

Skills Required
:

Proficiency of 8+ (in a scale of 10) in al-least one of Python, R or Java

Role
:

Associate Data Scientist/ Data Scientist/ Lead Data Scientist (2-7 yrs. exp)

Developing high-level solution architectures and working data engineers and decision science analysts to build, test and assess models that predict and optimize business outcomes based on business success criteria.
Work unsupervised with internal and external teams to respond to business requirements.
End-to-end responsibility for model development, including data exploration, training data, feature extraction and model development, validation and scoring.
Convincingly communicate with our stakeholders at all levels, including pairing with other Data Scientists.
An experienced data scientist and math nerd with a passion for ML/AI.
People who love innovation, playing with AI/DL/ML, and challenging the status quo.
One will be responsible for exciting innovations around Vision, Sound, NLP or data-based solutions or product development on Risk, Fraud, NLP, ML and prediction problems.
Comfortable writing own library
Knows hand-on development, implementation and integration of ML based models with system applications- Experience working on high-scale, production-grade projects.
AWS/Azure experience is must.
Working knowledge of data engineering – building ML pipelines.
Statistics, Computer Science or Mathematics degree and is fluent in Python, R, and has knowledge of relational and NoSQL databases.

Additional details:
Experience in TensorFlow, Keras, Pytorch, NLTK etc.
Be a go- to resource for key complex systems and services, working closely with engineers to deliver high quality software on time.
Define long term design and build reliable, scalable fast- performance consumer- grade geo- related services and solutions, end- to- end. Fully understand non- functional requirements, system interdependencies and limitations
Strong background in at least one specific machine learning area*

Deep learning, re-enforcement learning, CNN, RNN, LSTM, Natural language processing: sequence segmentation, labeling and parsing, language modeling, machine translation, question answering and dialog systems, knowledge extraction, representation and reasoning, Graph DB, Computer vision: large scale image classification, detection, face recognition, scene understanding, metric learning, image search, etc.

Location
:

Pune, Maharashtra, India

Education/Qualification
:

B.Tech/M.Tech/ M.S. in Statistics, Computer Science or Mathematics or equivalent technical degree with strong programming skills

Years Of Exp
:

5 to 7 Years

Posted On
:
19-May-2020
Designation
:

Associate Data Scientist/ Data Scientist/ Lead Data Scientist",3.9,"Bajaj Allianz General Insurance Company
3.9",Pune,"Pune, India",1001 to 5000 employees,-1,Company - Private,Insurance Operators,Insurance,₹500+ billion (INR),-1
467,Data Engineer- Bangalore,"Description

6sense is a Predictive Intelligence Engine that is reimagining how B2B companies do sales and marketing. It works with big data at scale, advanced machine learning and predictive modeling to find buyers and predict what they will purchase, when and how much.

6sense helps B2B marketing and sales organizations fully understand the complex ABM buyer journey. By combining intent signals from every channel with the industry's most advanced AI predictive capabilities, it is finally possible to predict account demand and optimize demand generation in an ABM world. Equipped with the power of AI and the 6sense Demand Platform™, marketing and sales professionals can uncover, prioritize and engage buyers to drive more revenue.

6sense is seeking a Data Engineer to become part of a team designing, developing, and deploying its customer centric applications.

A Data Engineer at 6sense will have the opportunity to
Create, validate and maintain optimal data pipelines, assemble large, complex data sets that meet functional / non-functional business requirements.
Improving our current data pipelines i.e. improve their performance, remove redundancy, and figure out a way to test before v/s after to roll out.
Debug any issues that arise from data pipelines especially performance issues.
Experiment with new tools and new versions of hive/presto etc. etc.
Required qualifications and must have skills
BE/BTech/BS or equivalent
Excellent analytical and problem-solving skills
6+ years work experience showing growth as a Data Engineer.
Strong hands-on experience with Big Data Platforms like Hadoop / Hive / Spark / Presto
Experience with writing Hive / Presto UDFs in Java
String experience in writing complex, optimized SQL queries across large data sets
Experience with optimizing queries and underlying storage
Comfortable with Unix / Linux command line
Nice to have Skills
Used Key Value stores or noSQL databases
Good understanding of docker and container platforms like Mesos and Kubernetes
Security-first architecture approach
Application benchmarking and optimization
Interpersonal Attributes
You can work independently as well as part of a team
You take ownership of projects and drive them to conclusion
You're a good communicator and are capable of not just doing the work, but teaching others and explaining the ""why"" behind complicated technical decisions
You aren't afraid to roll up your sleeves: This role will evolve over time, and we'll want you to evolve with it!",4.9,"6sense
4.9",Bengaluru,"San Francisco, CA",51 to 200 employees,2013,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
468,Data Analyst,"Essential qualification & experience :
Qualification: Any undergraduate / postgraduate degree or equivalent

Experience: Minimum 5 years of experience

Responsibilities:
Interpret data, analyze results using statistical techniques and provide ongoing reports
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality
Acquire data from primary or secondary data sources and maintain databases/data systems
Identify, analyze, and interpret trends or patterns in complex data sets
Filter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems
Work with management to prioritize business and information needs
Locate and define new process improvement opportunities

Requirements:
Proven working experience as a data analyst or business data analyst
Technical expertise regarding data models, database design development, data mining and segmentation techniques
Strong knowledge of and experience with reporting packages (Business Objects etc), databases (SQL etc), programming (XML, Javascript, or ETL frameworks)
Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc)
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Adept at queries, report writing and presenting findings",3.4,"Alliance University
3.4",Bengaluru,"Bangalore, India",501 to 1000 employees,-1,Company - Private,Colleges & Universities,Education,Unknown / Non-Applicable,-1
469,Data Analyst Executive,"Roles and Responsibilities:
Accurate timely generation of reports.
Keeping the report data bank ready for any requests received from time to time.
Coordinating with sales and marketing team for the data.
Knowledge of Google Sheets advance.
Data Collection, Analysis, and Updation.

What’s In It For You?

Be part of a fast growing Startup that is part of ATDC, a Georgia Institute of Technology, based startup incubator in Atlanta GA USA.
Work in exciting latest mobile/IOT/Wearable technologies and in the most happening Supply Chain domain
Ability to be promoted at a fast pace as the company grows.
Company provided MacBook Pro & free snacks.
Results Only Work Environment.",4.7,"SMART GLADIATOR
4.7",Chennai,"Atlanta, GA",1 to 50 employees,2013,Company - Private,Computer Hardware & Software,Information Technology,₹100 to ₹500 million (INR),-1
470,Data Scientist (4+ Years) for an Online Ecommerce Company,"We are looking for a “Data Scientist” for one of our esteemed Clients for Bangalore ,India Location.

Job Requirement:
Understand problem statement/product requirement.
Work with Data Engineers to get required data.
Analyse the data and identify statistical/machine learning models.
Build POCs to demonstrate success/failure of the hypotheses.
Post that, work with ML and Data Engineers to implement your models on existing production systems and big data platform.

Must Have:
Qualification – Masters or Ph.D. in Statistics, Math, CompSci, Econ, Physics, Engineering or related scientific disciplines; preferably from a premier scientific institute like ISI or IISC.
Work experience – At least 4 years in Tech, with 2 years as a Data Scientist or equivalent position.
Statistical knowledge – Proven experience in statistical methods like Markov Models, Stochastic models, Bayesian Models, Classification Models, Cluster Analysis, Multivariate Stats, Regression Models.
Machine Learning – Prior work experience in one or more of these knowledge areas (domain agnostic): Price Modelling, Demand Forecasting, Recommender Systems, User Profiling, Fraud Detectors.
Technologies – Proficiency in Python (must have) and any other prog. language; Specific libraries may include – TensorFlow, Keras, Torch, Caffe, Theano, etc;
Experience with Kaggle is a bonus.",3.7,"zyoin
3.7",Bengaluru,"BENGALURU, India",51 to 200 employees,2005,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
471,Machine Learning Engineer - Remote for a UK AI Startup,"Company Description

We are disrupting the Artificial Intelligence & Engineering talent industry with our groundbreaking solutions and business ideas. At AI-Adam we focus on Intelligent and efficient sourcing by using Predictive Analytics to Improve Sourcing and help you secure the best talent in the industry.

Job Description

We're hiring for two Machine Learning Engineer to be the first technical base on the ground to help solidify our clients India operation from day zero. As the first two Machine Learning Engineers you will be supporting production systems at scale based on open source and enterprise machine learning products in Kubernetes.

You will be triaging production client deployments to ensure success for large scale production machine learning systems in critical environments and contributing to open source projects to extend their functionality.

Qualifications

Required skills:
A degree or higher level academic background in a scientific or engineering subject.
Strong computer science foundations.
Strong System architecture knowledge/experience.
Familiarity with linux based development.
Experience architecting/applying technology to solve real world challenges.
Experience delivering production-level client-facing projects.",4.0,"AI-Adam
4.0","India, India","San Francisco, CA",1 to 50 employees,-1,Unknown,-1,-1,Unknown / Non-Applicable,-1
472,Sr. Applied Scientist,"The Outbound Marketing Automation (OMA) is looking for a smart and motivated applied scientist to join the Lumos team. We are a high-energy and innovative group that deliver highly relevant, personalized communications on various automated channel like email to Amazon customers worldwide. We utilize the data footprint on Amazon to generate messages to bring best-in-class engagement with our customers.

As a member of our team you will interact closely with other automated advertising technology and retail customer experience teams. You will be involved with the development and launch of large-scale ML systems involving large data processing pipelines modeling customer data.

In OMA, we look for experienced leaders who possess a wide variety of skills. As the successful applicant for this role, you will solve varied complex problems across Amazon (including business prioritization, technical challenges in optimization, large-scale computing, distributed systems, web applications, scalability, security, machine learning, and algorithms, to name just a few), you will drive multiple programs in parallel, you will work with business stakeholders and partner technical teams across Europe, India and the USA, and you will support the growth and development of a high-performing engineering team. OMA is composed of many clever and generally awesome people (if we say so ourselves!), so you'll learn a huge amount - and have a lot of fun - in the process!



Basic Qualifications

· PhD in Computer Science, Mathematics, Statistics, or other quantitative field with exposure to statistical modeling and machine learning
· 6+ years of applying machine learning for solving real-world problems in industry
· Proficiency in C/C++, Java, or Python
· Proficiency with at least one machine learning or statistical modeling library (R, Matlab, Scikit-learn)
· Past delivery of large-scale ML solutions for complex business problems
· Outstanding written and verbal communication skills

Preferred Qualifications

· Publications in top ML conferences or journals
· Experience with a popular deep learning toolkit (TensorFlow, MXNet, PyTorch, Caffe etc)",4.2,"Amazon
4.2",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
473,Senior Data Scientist,"LocationIndia / US / EuropeExperience5 YearsAcademic Qualification:B.E., B.Tech/MBA from top-tier Engineering /B-School ORMasters in Statistics/Economics from leading UniversityOverviewContinuous, growth opportunities for career progression and personal developmentProfessional, stimulating, continuous learning, work environment based on camaraderie, individual mentorship, on-the-job and corporate trainingCompetitive and performance-oriented compensation and employee benefits packageIndustry benchmarked HR policies and practices, particularly in areas such as Performance Management, Learning and Professional Development, Career Planning and Compensation and Rewards.Roles and responsibilitiesWill involve teamwork as well as work in which individual contribution will be neededWork directly with multinational clients, using advanced analytics to solve real-world business problems.The role will require a sound understanding of business functions, statistical concepts and algorithm design/implementation skills.Core responsibilities include leveraging data science to solve business cases, training other team members, and contributing to pre-sales through quick execution of PoCs. Typical activities will include:Interacting with business stake holders for gathering requirementsAnalysing data to develop key insights on business trends and performanceApplying statistical/mathematical algorithms as needed to address specific business problemsStrategizing and proposing creative solutions based on data insightsBe a brand ambassador for the company and represent the company in seminars and other public events related to data sciencePreferred experience of working in some of the following data science techniques: Descriptive Statistics, Predictive Modelling, Linear regression, Logistic Regression, Tests of Hypothesis, Pattern Recognition, Clustering, Decision Tree, Time Series, Principal Component Analysis, Neural Networks, SVM, k-NN, etcLeading Analytics consulting projectsAdditional Skills (preferred)Will involve teamwork as well as work in which individual contribution will be needed.Intermediate querying and scripting skills in SQLExperience in relevant field such as Statistics, Computer Science or Applied Math.SPOCBuddhadeb BhattacharjeeMail toBuddhadeb.bhattacharjee@tcg-digital.com",3.0,"TCG Digital
3.0",India,"Somerset, NJ",201 to 500 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
474,Data Scientist/Senior Data Scientist - Deep Learning,"Danaher Corporation

Danaher is a global science and technology innovator with more than 59,000 associates committed to helping our customers solve complex challenges and improve quality of life around the world. Our world class brands have unparalleled leadership positions in some of the most demanding and attractive industries and our technologies address a broad range of societal needs:
Protecting the global water supply and ensuring environmental stewardship
Protecting the world's food supply and verifying pharmaceutical dosages and authenticity
Leading scientific research and advancing patient health with the highest diagnostic confidence
Improving dental outcomes and promoting access to comfortable patient care around the world
Danaher generates over $20 billion USD of annual revenue from business segments: Life Sciences, Diagnostics, Water Quality, and Product Identification.

For additional company details, see www.danaher.com.

Danaher Digital

Danaher Digital is our digital innovation and acceleration center where were bringing together the leading strategic product and business leaders, technologists and data scientists for the common purpose of accelerating development and commercialization of disruptive and transformative digital solutions into the marketplace.

We accelerate Danahers digital innovation journey by partnering with Danaher operating companies (OPCOs) to monetize and commercialize the potential of emerging digital trends.

Located in Silicon Valley, the heart of global innovation, Danaher Digital is ideally situated to capitalize on the digital mega trends transforming our world, including IoT, Data, AI, cloud, mobile, Augmented Reality (AR), Blockchain and other Digital frontiers.

Position Description


This position reports to Director of Data & Analytics and is responsible for leading the vision, design and development of scalable Machine Learning (ML) solutions for Danahers IoT and Analytics (ML) initiatives. You will work with other Data Scientists, Software engineers and business groups and lead the development of innovative ML models for Danahers big data from health sciences, medical diagnostics, industrial and other markets. You will use your Agile experience to work collaboratively with other Product Managers/Owners in geographically distributed teams.

Responsibilities
Understand business challenges and propose new modeling and algorithmic solutions that leverages the latest in statistical and machine learning techniques.
Study new data sources and find insights/correlation to investigate how data can be used to solve new business challenges. Create prototypes with data sets and provide guidance on leveraging and combining new data sources for new business insights.
Apply statistical analysis and modeling techniques on small and large datasets to solve specific business problems in diverse industrial domains.
Provide strategic leadership in selection of platform, tools, techniques and processes in the practice of Data Science discipline.
Work collaboratively with other Product Owners/Product Managers from other business units and/or customers to translate business requirements in to technical requirements that can be answered with statistical and machine learning techniques. Guide and work with engineers and domain owners to produce the required data if not available.
Provide mentorship to other Data Scientists in the team.
Own and drive contemporary best practices in applying and deploying data science at scale.
Requirements
Advanced degree (Ph.D. preferred) in Engineering, Science, Mathematics, or related
Expert knowledge of statistical programming languages such as R, Python, and SQL.
Expert knowledge of probability, statistics and machine learning theory including experience in: Deep Learning, Clustering, Decision Trees, Logistic Regression, Dimensionality Reduction, and Random Forests for prediction and recommendations.
Must have delivered data science components as part of a commercial solution at scale.
Readiness to work with engineering teams to develop a prototypes of software products leveraging exploratory data analytics.
Desirable: Consultative experience providing technology and solution consultation to customers/clients.
Expert knowledge of data visualization, using tools such as Tableau or PowerBI.
Experience working with the cloud computing, including AWS and/or Azure
Experience working with distributed data storage and computing, including Hadoop, Spark, Cassandra, and so forth
Experience working with traditional databases, such as MS SQL, Teradata, MySQL, and Postgres.
Expert knowledge of Experimental Design and Statistical Decision Theory
Agile mindset to jump in to a diverse set of projects.
Ability to summarize results from analysis to a diverse set of audiences with varying background and technical skills.
Willingness to travel up to 25% required.
Experience


Required:
7+ years working with business stakeholders as a trusted adviser in Data Science and Monetization
7+ years communicating effectively with project and business stakeholders about Data Science and data science projects
5+ years building production-ready image or video analysis models using Deep Learning techniques such as CNN and RNN.
3+ years leveraging tools such as TensorFlow or Theano.
5+ years providing mentorship, education, and thought leadership to organizational stakeholders regarding best practices in data science
5+ years translating business requirements into data science problem statements and execution tasks
5+ years leading the organization towards adoption of a data-driven culture
3+ years mentoring and supporting junior team members
Desired:
7+ years building operations analytics models, including demand forecasting, inventory optimization in manufacturing or related industries.
7+ years building IoT analytics models, including failure diagnosis and failure prediction
7+ years executing customer advanced analytics, including marketing mix analysis, segmentation, retention modeling, targeted marketing, basket analysis, next product recommendation, and so forth.
5+ years executing data science in the fields of life sciences, medical diagnosis, biostatistics, and so forth.
Danaher Corporation and all Danaher Companies are equal opportunity employers that evaluate qualified applicants without regard to race, color, national origin, religion, sex, age, marital status, disability, veteran status, sexual orientation, gender identity, or other characteristics protected by law. The EEO is the Law poster is available here.",-1,Danaher Digital,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
475,Senior Data Scientist,"Salary
DOE
Number of positions
1
Description
A senior data scientist will assist customers by being able to deliver a ML / DL project from beginning to end, including understanding the business need. And, use Deep Learning frameworks like MXNet, Caffe 2, Tensorflow, Theano, CNTK, and Keras to help customers build DL models.
Minimum Qualification
A Bachelor or Masters Degree in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.)
7+ years of industry experience in predictive modelling, data science and analysis.
Technical Skills
Experience using Python and/or R and SparkML.
Experience using ML libraries, such as scikit-learn, caret, mlr, mllib
Experience working with GPUs to develop models.
SQL
Responsibilities
Experience giving data presentations.",5.0,"TCPWave
5.0",Hyderabad,"Princeton, NJ",1 to 50 employees,-1,Company - Private,IT Services,Information Technology,₹50 to ₹100 million (INR),-1
476,Data Analyst,"We are looking for a passionate Data Analyst. The successful candidate will turn data into information, information into insight and insight into business decisions.

Job Description:
Proven working experience as a data analyst or business data analyst between 1 to 2 years
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Adept at queries, report writing and presenting findings
Understanding of utility value chain
Energy domain experience
Billing/Invoicing Background Preferably knowledge of energy market
Good Communication skills
Good with the numbers
Good Email writing skills
Immediate Joiners preferred",4.8,"Proziod Analytics
4.8",Bengaluru,"Bengaluru, India",1 to 50 employees,2016,Company - Private,IT Services,Information Technology,₹10 to ₹50 million (INR),-1
477,CIEL/SEL/2317: Data Scientist Machine Learning,"Data Scientist Machine Learning/Python/C#
3+ years in a data processing & machine learning role with demonstrable experience with Cognitive computing, data integration, data mining, Natural Language Processing, Hadoop platforms, and automating machine learning components.
Min. 1 year of experience with below technologies is mandatory.
a. Python
b. R
c. Spark
d. SAS
e. HDInsights
f. Databricks
Strong Knowledge in Machine learning like Spark and Azure ML.
Strong experience in Azure Big Data Technologies like Azure Data Lake, HDInsights etc.
Strong experience in any database technology (SQL Server / Azure Cosmos DB)
Strong experience in at least one programming language (i.e. C#, Python, R).
Experience implementing and automating models created by data science teams (i.e. Spark, Scala, Hive, Python, R, etc.)
Experience with data modeling and normalization concepts.
Experience with data visualizations tools like SSRS, PowerBI& Tableau.
Experience architecting and building data marts, warehouses, etc.
Experience working with different query languages (i.e. PL-SQL, T-SQL).
Understanding and experience working with cloud infrastructure services like Azure, Amazon Web Services & Google Cloud. Azure preferred.
Experience working with code repositories and continuous integration (i.e. Git, Jenkins, etc.)
Understanding of development and project methodologies.
Ability to work collaboratively in teams with other specialized individuals.
Able to work in a fast-paced, technical environment",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
478,Data Science Lead,"Bachelors / Masters
Experience

5-10 years

Required Skills
5-10 years of professional experience is required
Degree in applied math, statistics, machine learning or computer science. PhD/ MS is preferred
Deep understanding of statistics and experience with machine learning algorithms/techniques
Proven programming skillsin particular C++ and Python, strong experience with DL frameworks such as TensorFlow, Theano and others
Scientific expertise and real-world experience in deep learning (convolutional neural networks, restricted Boltzmann machines, and deep neural networks)
Passion for solving challenging analytical problems
Ability to quickly, qualitatively and quantitatively assess a problem
Ability to work productively with team members, identify and resolve tough issues in a collaborative manner.
Experience in applying machine learning techniques to real-world problems in a production environment
Roles & Responsibilities
Design, develop and deliver AI/machine learning enabled solutions for our industry specific data analytics platform
Build scalable, availableand supportable processes to collect, manipulate, present, and analyze large datasets in a production environment
Articulate problem definition and work on all aspects of data including acquisition, exploration/visualization, feature engineering, experimentation with machine learning algorithms and deploying models
Develop working prototypes of algorithms, evaluate and compare metrics based on the real-world data sets
Provide design input specifications, requirements and guidance to software engineers for algorithm implementation for solution/product development",4.5,"D Cube Analytics
4.5",Bengaluru,"Bengaluru, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
479,Sr NLP & Text Mining Data Scientist,"Analytics

Sr NLP & Text Mining Data Scientist

Pune, Maharashtra, India
APPLY

Job title

Sr NLP & Text Mining Data Scientist
Department

Analytics & Data Science
Report To

Deepthi Devarakonda / Simhan Ramakrishnan
No of yrs. of exp

7+ years
Work Location

Pune, MH, India
No of Positions

1
Assigned Recruiter
Talent Partner

Version Control
Version No.

Date

Remark

Updated by
1.0

5/4/2020

Initial Version

SR

It’s Time For A Change…

Your Future Evolves Here

Evolent Health has a bold mission to change the health of the nation by changing the way health care is delivered. Our pursuit of this mission is the driving force that brings us to work each day. We believe in embracing new ideas, challenging ourselves and failing forward. We respect and celebrate individual talents and team wins. We have fun while working hard and Evolenteers often make a difference in everything from scrubs to jeans.

Are we growing? Absolutely—56.7% in year-over-year revenue growth in 2016. Are we recognized? Definitely. We have been named one of “Becker’s 150 Great Places to Work in Healthcare” in 2016 and 2017, and one of the “50 Great Places to Work” in 2017 by Washingtonian, and our CEO was number one on Glassdoor’s 2015 Highest-Rated CEOs for Small and Medium Companies. If you’re looking for a place where your work can be personally and professionally rewarding, don’t just join a company with a mission. Join a mission with a company behind it.

Position summary

The Sr. NLP and Text Mining scientist will support building of AI products in Agile fashion that empower healthcare payers, providers and members to quickly process medical data to making informed decisions and overall reduce health care costs. As a research scientist/engineer part of Data Science and Artificial Intelligence team you will be working primarily on unstructured text data to build machine learning models for information retrieval applications. These applications include but are not limited to optical character recognition, understanding the contents of the medical documents using natural language processing, and integrating processes into the overall AI pipeline to mine healthcare and medical information with high recall and other relevant metrics. We ingest claims, medical charts, etc. from providers containing unstructured data which will be transformed into structured data to support automated entry into our storage layers for downstream applications. The results will be used dually for real-time operational processes with both automated and human-based decision making as well as contribute to reducing healthcare administrative costs. We work with all major cloud and big data vendors offerings including but not limited to (Azure, AWS, Google, IBM, etc.) to achieve AI goals in healthcare and support Evolent business.

Essential functions

The Sr. NLP Text Mining Scientist / Engineer will have the opportunity to lead a team, shape team culture and operating norms as a result of the fast-paced nature of a new, high-growth organization.
7+ years of Industry experience primarily related to Unstructured Text Data and NLP (PhD work and internships will be considered if they are related to unstructured text in lieu of industry experience but not more than 2 years will be accounted towards industry experience)
Develop Natural Language Medical/Healthcare documents comprehension related products to support Evolent Health business objectives, products and improve processing efficiency, reducing overall healthcare costs
Gather external data sets; build synthetic data and label data sets as per the needs for NLP/NLR/NLU
Apply expert software engineering skills to build Natural Language products to improve automation and improve user experiences leveraging unstructured data storage, Entity Recognition, POS Tagging, ontologies, taxonomies, data mining, information retrieval techniques, machine learning approach, distributed and cloud computing platforms
Own the Natural Language and Text Mining products — from platforms to systems for model training, versioning, deploying, storage and testing models with creating real time feedback loops to fully automated services
Work closely and collaborate with Data Scientists, Machine Learning engineers, IT teams and Business stakeholders spread out across various locations in US and India to achieve business goals
Provide mentoring to other Data Scientist and Machine Learning Engineers
Strong understanding of mathematical concepts including but not limited to linear algebra, Advanced calculus, partial differential equations and statistics including Bayesian approaches
Strong programming experience including understanding of concepts in data structures, algorithms, compression techniques, high performance computing, distributed computing, and various computer architecture
Good understanding and experience with traditional data science approaches like sampling techniques, feature engineering, classification and regressions, SVM, trees, model evaluations
Additional course work, projects, research participation and/or publications in Natural Language processing, reasoning and understanding, information retrieval, text mining, search, computational linguistics, ontologies, semantics
Experience with developing and deploying products in production with experience in two or more of the following languages (Python, C++, Java, Scala)
Strong Unix/Linux background and experience with at least one of the following cloud vendors like AWS, Azure, and Google for 2+ years
Hands on experience with one or more of high-performance computing and distributed computing like Spark, Dask, Hadoop, CUDA distributed GPU (2+ years)
Thorough understanding of deep learning architectures and hands on experience with one or more frameworks like tensorflow, pytorch, keras (2+ years)
Hands on experience with libraries and tools like Spacy, NLTK, Stanford core NLP, Genism, johnsnowlabs for 5+ years
Understanding business use cases and be able to translate them to team with a vision on how to implement
Identify enhancements and build best practices that can help to improve the productivity of the team.


Nice to Have
Medical concepts with codes from standard ontologies (SNOMED CT, LOINC, RxNorm, ICD, etc.)
Lucene, Solr, Elastic Search experience
Experience with Kubernetes and dockers
Experience building REST API’s for AI work and knowledge of microservices architecture
Participation in open source community projects
Academic Qualification:
Master’s degree or above in Computer Science, Computational linguistics, Mathematics, Physics or electrical engineering with research experience from a strong academic program along with thesis (No Post Graduate diplomas and undergraduate degrees)
Completion of thesis/research is required as part of graduation in computer science, artificial intelligence, Mathematics, Physics, Electrical Engineering or statistics
A PhD degree in Computer Science, Artificial Intelligence, Computational Linguistics, Machine Learning, or related technical field is preferred from a strong academic program
Publication record in top NLP conferences (NIPS, ICLR, ACL, NAACL, EMNLP, SIGIR, WWW etc) is preferred

APPLY",2.8,"Evolent Health
2.8",Pune,"Arlington, VA",1001 to 5000 employees,2011,Company - Public,Healthcare Services & Hospitals,Healthcare,₹1 to ₹5 billion (INR),-1
480,Data Science Analyst,"DESCRIPTION

Should be a Senior Data Scientist with 8+ years in Solutioning, advanced statistical modeling expertise in various scenario
Masters, or equivalent experience in a quantitative field (Computer Science, Mathematics, Engineering, Artificial Intelligence, etc.)
7+ years’ experience leading and scaling teams of data scientists
Expertise in Advanced Analytics (Predictive modelling, ML, DL and AI)
Certified Data Analytics professional with certification in Machine Learning
Expertise on delivering Machine learning models for various clients in BFSI
Solution Architect for AI Implementations
Experience in at least the following 2 programming languages: Python and R
Job Type - Permanant
Location - India, Hyderabad
Experience - 7 Years
Qualification - Bachelors
Salary - Negotiable",-1,Talent Arabia,Hyderabad,-1,-1,-1,-1,-1,-1,-1,-1
481,Satellite Data Analyst,"Company Description

Robert Bosch Engineering and Business Solutions Private Limited (RBEI) is a 100% owned subsidiary of Robert Bosch GmbH. We are one of the world’s leading global suppliers of technology and services, offering end-to-end Engineering, IT, and Business Solutions.

With a global footprint and presence in US, Europe, Japan, China, and the Asia Pacific region, we are at the forefront of designing, developing, and executing IoT ecosystems through our all-encompassing capability within the 3 aspects of IoT – Sensors, Software, and Services.

We have always focused on improving the quality of the life of people, providing newer revenue-generating opportunities, and improving operational efficiencies for enterprises through an array of solutions. With our unique ability to offer end-to-end solutions that connect Sensors, Software, and Services, we enable businesses to move from the traditional to digital, or improve businesses by introducing a digital element in their products and processes.

Job Description

· Experience in image processing, time series analysis and predictive analytics

· Creation of geospatial AI algorithms and its automation

· Experience with Python machine learning and deep learning libraries such as Scikit-learn, Pandas, PyTorch/FastAI, or TensorFlow/Keras

· Experience in implementation of algorithms in cloud platforms

· Understanding of machine learning as well as deep learning techniques and algorithms such as k-NN, Naive Bayes, SVM, Random Forests, CNNs, RNNs, LSTMs.

· Ability to design and implement deep learning models for object detection, semantic and instance segmentation, GANs.

· Experience in data visualization in Jupyter Notebooks using matplotlib and other libraries.

· Experience with Hyper parameter-tuning and training models to a high level of accuracy.

· Ability to perform data extraction, transformation, loading from multiple data sources and sinks.

· Develop and train deep learning models for computer vision problems such as object detection, image classification, tree detection, building footprint segmentation, and 3D point cloud segmentation.

· Validate deep learning and geospatial analysis models, tools, and Python APIs

Qualifications

· Masters/Ph.D degree in Computer Science and Data science

· Able to implement and write processing scripts in R or Python.

· Strong knowledge and work experience on different types of models like Static, Statistical, Mechanistic, Deterministic, Stochastic, Descriptive, Explanatory Dynamic Simulation models and apply them for crop modeling to analyze the outcomes.

· Result-oriented mid-career scientist with at least 6-8 years of relevant working experience.

Additional Information

1. Personal Characteristics

· Confident, flexible, solution driven.

· An inquisitive mind that is not afraid to explore new roads and take initiative.

· Good analytical and problem solving skills, with eye for detail.

· Ability to work independently and work well in a multi-disciplinary and international team.

· Well organized, keeping to deadlines, pro-active and responsible.",4.1,"Bosch Group
4.1",Bengaluru,"Farmington Hills, MI",10000+ employees,1886,Company - Private,Miscellaneous Manufacturing,Manufacturing,₹500+ billion (INR),"Continental, FCA Fiat Chrysler Automobiles"
482,Data Engineer I,"The TRON team is an initiative which partners with the Amazon Robotics team to remotely handle exceptions in the Amazon Robotic Fulfillment Centers in North America. The TRON technology enables the human supervisory control of automated tasks. In the TRON system, a remote associate provides supervisory control when automated tasks fail for any reason. This allows us to avoid falling into the 90/10 trap where a task can be 90% automated but requires 90% of the time for the last 10% of functionality. Our strategy is to employ a human-as-sensor model and allow humans to perform just those portions of a task that require higher order cognitive ability.
TRON team is looking for a Data Engineer. As a Data Engineer on TRON team your responsibilities will include

Responsibilities include:
· Apply broad knowledge of technology options, technology platforms, design techniques and approaches across the Data Engineering ecosystem to design systems that meet business needs.
· Play a leading role in building systems and datasets using software engineering best practices, data management fundamentals, data storage principles, recent advances in distributed systems, and operational excellence best practices.
· Play a leading role in architecture design and implementation of next generation BI solutions using Big Data and AWS Services.
· Analyze source systems, define underlying data sources and transformation requirements, design suitable data models and document the design/specifications.
· Demonstrate passion for quality and productivity by use of efficient development techniques, standards and guidelines.
· Effectively communicate with various teams and stakeholders, escalate technical and managerial issues at the right time and resolve conflicts.
· Peer review work. Actively mentor more junior members of the team, improving their skills, their knowledge of our systems and their ability to get things done.
Manage AWS resources including EC2, RDS, Redshift, Kinesis, EMR, Lambda etc.

Basic Qualifications

· 1+ years of experience as a Data Engineer or in a similar role
· Experience with data warehousing, and building ETL pipelines
· Experience in SQL
· Bachelor's degree or higher in a quantitative/technical field (e.g. Computer Science, Statistics, Engineering).
· 3+ years of relevant experience in one of the following areas: Data engineering, database engineering, business intelligence or business analytics.
· 3+ years of hands-on experience in writing complex, highly-optimized SQL queries across large data sets.
· 2+ years of experience in scripting languages like Python etc.
· Demonstrated strength in data modeling, ETL development, and Data warehousing.
· Experience with AWS services including S3, Redshift, EMR and RDS.
· Experience with Big Data Technologies (Hadoop, Hive, Hbase, Pig, Spark, etc.)
· Experience in working and delivering end-to-end projects independently.
· Knowledge of distributed systems as it pertains to data storage and computing


Preferred Qualifications

· Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy
· Experience providing technical leadership and mentoring other engineers for best practices on data engineering
· Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations

Amazon is an equal opportunities employer. We believe passionately that employing a diverse workforce is central to our success. We make recruiting decisions based on your experience and skills. We value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief

·",4.2,"Amazon
4.2",Hyderabad,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
483,Data Scientist (Premium College),"About Zycus :

Headquartered in Princeton, U.S. in 1998, Zycus has grown every day to be established as an organization which now is a leading global provider of complete Source-to-Pay suite of procurement performance solutions.

We develop cloud-based (SaaS) Source-to-Pay solutions for large global enterprises, and have successfully deployed about 200 solutions to over 1000 Global clients. We are proud to have as our clients, some of the best-of- breed companies across verticals like Manufacturing, Automotives, Banking and Finance, Oil and Gas, Food Processing, Electronics, Telecommunications, Chemicals, Health and Pharma, Education and more.

With a team of 1000+employees, we are present in India with 3 development centers at Bengaluru, Mumbai & Pune and offices in the U.S., U.K., Australia, Dubai, Netherlands and Singapore.

Know more about the LEADER of: Gartner’s 2013, 2015 & 2017 Magic Quadrant for Strategic Sourcing Application Suites and The Forrester Wave™: eProcurement, Q2 2017

We are in process of launching Merlin A.I. Studio™.

The artificial intelligence (AI)-based platform will allow procurement teams to to build and deploy bots across the source-to-pay process.

The bots will be used by firms leveraging more than 1,100 APIs from Zycus’ solution suite.

“By deploying the intelligent bots from Merlin A.I. Studio™, procurement can put themselves in cruise control mode as the bots work towards accomplishing tasks with zero human intervention,” The Fortune 500-serving firm explained in its press release

“Be it running an RFI event, discovering contract risks, negotiating with suppliers or transnational procurement; all one needs to do is launch the bot and see the magic unfold.”

“It will empower procurement to transform their routine, repetitive & mundane procurement tasks, so that time, effort & resources can be optimized towards more strategic initiatives.”Exp : 1 to 10 Years

Role : Data Scientist

Location : Bangalore

Drive Timings : 9 AM to 2.00 PM

Education : Any Engineering From IIT ,NIT , IIIT ,VIT , BITS Pilani

Venue Details :

ZYCUS INFOTECH PRIVATE LIMITED

SEZ UNIT,6TH FLOOR,GARNET Building,

Bagmane Developers Pvt Ltd SEZ II,

Bagmane World Technology Centre SEZ,

Mahadevapura,Outer ring Road,

KR Puram Hobli, Bengaluru (Bangalore) Urban,

Karnataka, 560048

Contact Person : Priyanka

Contact Number : 7899408877

Please carry your original ID proof along with Hard Copy of Resume

Requirements

We are especially looking for applicants with a strong background in Analytics and Data mining (Web, Social and Big data), Machine Learning and Pattern Recognition, Natural Language Processing and Computational Linguistics, Statistical Modelling and Inferencing, Information Retrieval, Large Scale Distributed Systems and Cloud Computing, Econometrics and Quantitative Marketing, Applied Game Theory and Mechanism Design, Operations Research and Optimization, Human Computer Interaction and Information Visualization. Applicants with a background in other quantitative areas are also encouraged to apply. If you are passionate about research and developing innovative technologies of interest to Zycus and the research community at large, the BigData Experience Lab may be the right place for you.

All successful candidates are expected to dive deep into problem areas of Zycus’s interest and invent technology solutions to not only advance the current products, but also to generate new product options that can strategically advantage Zycus

Skills
Master’s or Ph.D. in statistics, mathematics, or computer science
Only from Tier 1 Colleges
Experience using statistical computer languages such as R, Python, SQL, etc.
Experience in statistical and data mining techniques, including generalized linear model/regression, random forest, boosting, trees, text mining, social network analysis
Experience working with and creating data architectures
Knowledge of machine learning techniques such as clustering, decision tree learning, and artificial neural networks
Knowledge of advanced statistical techniques and concepts, including regression, properties of distributions, and statistical tests
1- 10 years of experience manipulating data sets and building statistical models
Experience using web services: Redshift, S3, Spark, DigitalOcean, etc.
Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.
Experience visualizing/presenting data.
Data Scientist will report in to Director Engineering - Data Scentist & the roles & responsibilities are as below:
Work as the data strategist, identifying and integrating new datasets that can be leveraged through our product capabilities and work closely with the engineering team to strategize and execute the development of data products
Execute analytical experiments methodically to help solve various problems and make a true impact across various domains and industries
Identify relevant data sources and sets to mine for client business needs, and collect large structured and unstructured datasets and variables
Devise and utilize algorithms and models to mine big data stores, perform data and error analysis to improve models, and clean and validate data for uniformity and accuracy
Analyze data for trends and patterns, and Interpret data with a clear objective in mind
Implement analytical models into production by collaborating with software developers and machine learning engineers.
Communicate analytic solutions to stakeholders and implement improvements as needed to operational systems
Benefits

Along with a competitive compensation structure, Zycus believes in an open culture learning environment, where everyone gets a chance to share their ideas and deliver par excellence. Here's a sneak peek to our life at Zycus.",3.3,"Zycus
3.3",Bengaluru,"Princeton, NJ",501 to 1000 employees,1998,Company - Private,Computer Hardware & Software,Information Technology,₹500 million to ₹1 billion (INR),"SAP Ariba, GEP, Coupa Software Inc"
484,Distributed computing & Data Analytics Developer,"Distributed computing & Data Analytics Developer

Job Description:

Job Experience - 12 to 16 years

Job Title - Distributed Computing/ Data Analytics developer

The Company

Interset Software uses big data and advanced behavioral analytics to detect and prevent the theft of intellectual property...simply put, WE CATCH BAD GUYS WITH MATH!!!

Part of the Micro Focus group of companies, we are a fast-paced, all-hands-on-deck kind of environment where you are respected and listened to from day one. We have a start-up feel within the stability and structure of a large global company.

We are currently looking to fill a development position focussed on extending the existing analytics platform and related capabilities to add unprecedented analytics flexibility for our customers. This will include enabling Data Scientists to manipulate and combine events and models to extend and customize the analytics in ways that provide unique value for each customer.

Were looking for a software developer whos passionate about what they do, takes a creative approach to problem solving and will be the champion for creating innovative machine learning hooks that deliver real value and perform in big data environments.

If youre passionate about true machine learning and want to be part of a company building solutions that leverage the latest in big data technology, we want to talk to you!!

What you'll do:
Implement model data flows to support running cutting-edge machine learning techniques on massive amounts of data
Work with product managers and data scientists to turn new features and algorithms into beautiful, battle-tested code
Work with the technologies we use to analyze and identify cyber-security threats for our customers (Elasticsearch, Spark, HBase, Kafka, Vertica, NiFi, using Java and Scala)
Work side by side with some of the smartest minds in the fields of machine learning and behavioural analytics
Create efficient and robust cloud-based solutions, leveraging the best in cloud technologies.
Who you are:
Undergraduate or Masters degree in Computer Science or equivalent engineering experience
Strong interest in software design, distributed computing, and databases
Experience developing in a JVM environment (Java, Scala, Clojure)
At least two years of experience developing with or using Big Data & Analytics stacks/tools such as Hadoop, HBase, Spark, Presto and Vertica.
Experience implementing and using streaming platforms such as SparkSQL, Flink, Kafka, Storm, etc.
Experience with Kubernetes, Docker, Ansible or any other infrastructure or containerization management/automation platform.
Familiarity leveraging AWS EMR, Azure, GCP cloud technologies best practices to enable the distribution and analysis of big data on the cloud would be considered an asset.
Nice to haves:
Familiarity with data science or machine learning packages (pandas, R, TensorFlow, etc...)
Familiarity with virtualization technologies (VMWare ESX, Docker)
Contributions to open source software (code, docs or mailing list posts)
Interest in understanding and analyzing diverse types of data
Job:

Engineering

Micro Focus is proud to be an Equal Opportunity Employer. Prospective employees will receive consideration without discrimination because of race, colour, religion, creed, gender, national origin, age, disability, marital or veteran status, sexual orientation, genetic information, citizenship or any other legally protected status",3.2,"Micro Focus
3.2",Bengaluru,"Newbury, United Kingdom",10000+ employees,1976,Company - Public,Computer Hardware & Software,Information Technology,₹100 to ₹500 billion (INR),"SAP, Oracle"
485,Data Scientist - R Modeling,"As a modeling expert you will be involve in creating & modifying statistical models to meet client as well as organization needs. The statistical model will be on identifying anomalies in the data & provide insights to drive business outcomes You will assist onshore and offshore teams, and client team by providing them tactical support including Data Validation, Preparing current state analysis presentations, preparing future state analysis documents, monitoring progress of the project and publishing reports Responsibilities: Responsible to generate models based on business requirements Should work closely with the data scientist, onshore and offshore team to understand different business scenario, automate and create models in ?R? Should be able to identify anomalies in data using different statistical tool Suggest model change based on the change in business dynamic & data trends Responsible to document all the changes made in the models & business requirements Leverage root causes identified during Problem Resolution process to create new rules to automate emerging issue detection Observe emerging Issue detection process and look for ways to continuously improve it Support ad-hoc complex analysis Leverage multiple ?R? tools to conduct more complex warranty analysis: ?R? Enterprise Guide, ?R? Enterprise Miner, ?R? Text Miner, ?R? Base programming. Automate ad-hoc complex analysis proven useful to enable junior analyst to use them on a recurrent basis. Train Junior Analyst on new ad-hoc analysis developed by Analyst Experts. Explore new root cause analysis methodologies with warranty expert analysts and reliability engineers as a way to continuously improve the warranty analytics team capabilities Monitor and interpret process KPI?s
Additional Information

JOB CODE:
GO/JC/12392/2020

EXPERIENCE:
6 - 11

LOCATION:
Mumbai

EDUCATION:
Any Graduates

VERTICAL:
Pharma

FUNCTIONAL AREA:
IT-Software

INDUSTRY:
ITES/BPO/KPO

CONTACT PERSON NAME:
VarshaWadhwa

CONTACT EMAIL:
varsha@gojobs.biz",3.9,"Golden Opportunities
3.9",Mumbai,"Hallandale Beach, FL",51 to 200 employees,-1,Company - Private,Metal Brokerages,Mining & Metals,Unknown / Non-Applicable,-1
486,Data Scientist _ Dell _ Bangalore,"Hi,

Please see the below requirement & let us know your comfort level ASAP

Pay roll: Team Lease (Permanent)
Client: Dell 23
Work Location : Bangalore , Bellandur
Mode of Interview: F2F Interview on the weekdays
Experience : 10+ Years

Data Scientist

10+ years of overall IT experience
â€ 2â€5 years AI work experience
â€ Experience in designing, building or implementing AI business solutions is essential
This role is all about delivering practical AI pilots in a business environment and is less about developing the
theory
â€ 2+ years of experience with Machine Learning, Statistical Models, and Natural Language Processing
â€ Experience with Python, TensorFlow, Keras, StackStorm
â€ Solid understanding of Data Structures, Algorithms & Objectâ€Oriented design concepts

Interested candidates can share their resumes or references to suryanarayana.murthy@teamlease.com
00-15.00 Years",3.6,"Teamlease Digital Private Limited
3.6",Bengaluru,"Bengaluru, India",1001 to 5000 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,₹500+ billion (INR),"Adecco, Randstad"
487,Data Engineer,"At Rockstar Games, we create the games we would want to play ourselves.

A career at Rockstar is about being part of a team working on some of the most creatively rewarding, large-scale projects to be found in any entertainment medium. You would be welcomed to a friendly, inclusive environment where you can learn, and collaborate with some of the most talented people in the industry.

Rockstar India is on the lookout for talented Data Engineers who possess a passion for Game Analytics. This is a full-time permanent position based out of Rockstar's unique game development studio in Bangalore, India.

WHAT WE DO
The Rockstar Analytics team provides insights and actionable results to a wide variety of stakeholders across the organization in support of their decision making.
We work together with a number of departments to design and implement data and pipelines.
We collaborate as a global team to develop cutting-edge data pipelines, data products, data models, reports, analyses and machine learning applications.
RESPONSIBILITIES
Resolve operational issues as they occur to maintain the team's SLAs.
Implement and support big data tools and frameworks such as HDFS, Hive, and Impala.
Implement and support data models using Spark and Spark-ML.
Assist in the development of deployment automation and operational support strategies on Hadoop and Snowflake.
Deliver near-real time and non-near-real-time data and applications to a team of analysts and data scientists who create insights and analytics applications for our stakeholders.
Maintain and extend our CI/CD processes and documentation.
QUALIFICATIONS
5+ years of work experience with ETL, Data Modeling, and Business Intelligence Big Data Architectures.
5+ years of experience with the Hadoop ecosystem (Map Reduce, Spark, Spark-ML, Oozie, Hive, Impala, etc.) and big data ecosystems (Kafka, Cassandra, etc.).
Experience developing and managing data warehouses on a terabyte or petabyte scale.
Experience developing Machine Learning pipelines and data models.
Strong experience in massively parallel processing & columnar databases.
Experience with Python and shell scripting.
Experience working in a Linux environment.
Deep understanding of advanced data warehousing concepts and track record of applying these concepts on the job.
SKILLS
Expert in at least one SQL language such as T-SQL or PL/SQL.
Good communication skills.
Dynamic team player.
A passion for technology - we are looking for someone who is keen to leverage their existing skills and seek out new skills and solutions.
PLUSES


Please note that these are desirable skills and are not required to apply for the position.
Experience in real-time analytics applications.
Experience in Lambda architecture and On-Premise Clusters.
Experience with Java or Scala programming languages.
Experience with CI/CD.
Knowledge of RestAPI and Artifactories.
Knowledge of the video game industry.
HOW TO APPLY


Please apply with a CV and cover-letter demonstrating how you meet the skills above. If we would like to move forward with your application, a Rockstar recruiter will reach out to you to explain next steps and guide you through the process.

Rockstar is proud to be an equal opportunity employer, and we are committed to hiring, promoting, and compensating employees based on their qualifications and demonstrated ability to perform job responsibilities.

If you've got the right skills for the job, we want to hear from you. We encourage applications from all suitable candidates regardless of age, disability, gender identity, sexual orientation, religion, belief, or race.",3.8,"Rockstar Games
3.8",Bengaluru,"New York, NY",1001 to 5000 employees,1998,Subsidiary or Business Segment,Video Games,Media,₹1 to ₹5 billion (INR),-1
488,Senior Data Scientist,"About Dasceq
Dasceq is transforming collection industry in USA using AI/ML and Big Data. We are focused to build a best in class Collection AI SaaS Product and have already established our product for $320billion Auto and Short Term Industry. We are expanding our team and looking for next generations data scientist with experience to lead high end AI Product Development. We don’t do lip service and we are committed to solve a $1.6 Trillion collection problem and looking to expand our amazing Data Science team. If you would like to build something high end and push boundaries contact us today!

Job codes: DASDS2

Qualifications :
Masters in Data Science ; Econometrics ; Statistics ; Math; Computer Science preferred with 2 to 3 years experience in Product Experience or Financial Services Experience or Marketing Modelling

Preferred Institutes:
ISI; Delhi School of Economics ; Madras School of Economics; Calcutta University; IITs/ IISc/ NIT’s – Relevant Tier 1 Colleges or Top Tier 2 colleges

Job Description :
The prospective hire would be part of a data Science Implementation team and be able to support independently client requirements, historical retro scoring, benefit analysis and other core financial lending and collections ; Knowledge of product development and implementation is a must for the role ; Prior experience in Lead roles will help , along with client facing experience.

Pay:
As per experience and market standards

Apply at: ritu@dasceq.com

Please send: Latest resume with current Salary and Bonus components mentioned",2.0,"Dasceq
2.0",India,"Irving, TX",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
489,Senior Data Analyst,"Position Purpose & Summary:

Cargill Transportation & Logistics (CTL) develops world-class transportation & logistics capabilities for our customers around the world. We accomplish this by leveraging and optimizing processes, data, and technology innovation to partner with customers, driving mutual growth and profitability. We consist of more than 1,400 professionals in Global Operations, individual Business Units, and Mode Teams including Rail & Barge, Container Freight, Truck, Storage, and Real Estate.

The CTL Data & Analytics Team drives the digitization, data governance, analysis, and expression of everything Cargill ships, receives, or stores around the world. We are adding a quantitatively talented professional to our team. The strongest candidate will have the opportunity to work with a global team of highly qualified professionals while making great things happen for our global CTL team using cutting edge big data technology. We look forward to meeting you if youre insatiably curious, creative, driven, quantitatively talented, and enjoy working with people in a fast-paced, hands-on workplace.

Principal Accountabilities:

40%:
Build strong partnerships within our business, monitor pertinent market conditions, and provide periodic executive summaries that enhance our market view with quantitative facts from a global intermodal perspective.
Perform ad-hoc / discovery analytics with an emphasis on identification of insightful facts and potential causal relationships e.g. seasonal impact on capacity demand, macroeconomic indicators, and other market factors.
Seize opportunities to rapidly build prototype models to test theories.
Express findings for business partners pro-actively at an appropriate level of detail to quantitatively enhance our forward market view and inform contract negotiation.
Differentiate between useful one-time analytic products and those that should be repeated via automation.


30%:
Investigate our business and constantly seek opportunities to drive digitization and analytic innovation.
Propose and execute opportunities to drive digitization and quantitative innovation and insight.
Partner with CTL Analytics teammates and Cargill Global IT to ingest required data into our Hadoop cluster.
Leverage quantitative skills to analyze data and express highly interpretable business insight.


20% - Finalisation of the shipment execution:
Promote repeatable analytic products to teammates and IT to coordinate reliable high-quality product delivery via automation technology.
Coordinate with teammates and business stakeholders to establish transparent quality indicators for model data, integrity, and reliability.


10% - Other adhoc task:
Provide and maintain deep subject matter expertise in at least one key skillset.
Teach / help teammates and business partners up their analytics game whenever possible to promote a high performing team culture of learning.
Tirelessly focus on learning new skills and perspectives.
Required Education & Experience:
Bachelors Degree in a quantitative subject e.g. business, finance, economics, mathematics, engineering, or physical science.
5+ Years of experience working in a business environment
3+ years of experience performing exploratory and summary analytics
3+ years of experience using specialized tools and / or programming languages for batch and ad-hoc data analysis
3+ years of experience implementing traditional data Extract, Transform, and Load (ETL) processes
3+ years of experience querying database management systems
Experience creating and tuning predictive models
Must possess deep subject matter expertise in at least one key area e.g. Machine Learning, Big Data, Mathematics, Statistics, Programming, Transportation, Logistics, etc.
Commercial acumen to understand and define the business significance of various parcels of data and analysis
Must have significant demonstrated track record in analytics and be able to talk through examples of experience
Must have demonstrated team working capability
Expertise in advanced modeling methods e.g. linear regression, support vector machines, splines, decision trees, time series, etc.
Understanding of dataset and feature selection tools e.g. stepwise regression, lasso, cross-validation, cross-correlation, etc.
Python programming skills expertise using mapping, lambda functions, comprehensions and native data structures e.g. lists, dictionaries, arrays, etc.
Expertise with statistical programming languages and tools e.g. Statistica, R, Python libraries (numpy, scipy, pandas, scikit-learn), etc.
Strong SQL skills
Expression software expertise using modern tools e.g. Tableau, PowerBI, Spotfire, Python libraries (bokeh, seaborn), etc.
Strong quantitative skillset
Must have strong communication skills (fluent spoken English, visual presentation skills, effective written communication skills)
Must have excellent interpersonal skills, ability to work in team and communicate with business stakeholders sand other analysts
Preferred Skills & Experience:
Degree in Business Related Field, or MBA.
Able to communicate in English and Mandarin as there will be frequent liaison with senior business stakeholders in China.
Experience in a multinational company.
Ability to work in a fast-paced trading / financial environment.
Strong background in business process design and implementation in a dynamic commodity trading business.
Experience in implementing IT processes, systems and organisational changes.
Demonstrated proficiency in utilising change management tools and processes to initiate or support change.
Strong negotiation, communication and interpersonal skills.
Able to work independently and under high pressure.
Strong interpersonal agility and cultivates networks with people across the organization.",3.9,"Cargill
3.9",India,"Wayzata, MN",10000+ employees,1865,Company - Private,Food Production,Agriculture & Forestry,₹500+ billion (INR),-1
490,Data Analyst/C11,"Roles and Responsibilities
Interpreting data and analyzing results using statistical techniques to identify trends or patterns in complex data sets
Identifying and documenting Critical Data Elements used in Surveillances, Research and Analysis etc.
Providing Level 3 support as required to resolve data issues and gaps
Specification
Bachelors degree (in science, computers, information technology or engineering)
Person with overall 3-5 years of experience, working in similar roles across banking or services technology;
Well versed with SDLC life cycle having exposure to various Phases
Experience as a data analyst in financial markets (Trading, Market Data or Compliance)
Knowledge of and experience with databases, SQL and analytical tools like Business Objects, Micro strategy etc.
Strong analytical skills with ability to collect, analyze and disseminate large volumes of data with attention to detail, accuracy, and data quality
Experience working with relational DBMSs like Sybase, Oracle, SQL Server, Sybase, SQL etc.
Good understanding of database validations, constraints, syntax and data types.
Ability to communicate clearly and concisely, both orally and in writing with business and technology stakeholders
Ability to multitask and work effectively with little supervision
Technical / Functional Proficiency:
Min. 3-5 years of working experience as Senior Data Analyst in Finance and Banking
Comfortable working with large data volumes and be able to demonstrate a firm understanding of logical data structures and analysis techniques
Experience in RDMS and No SQL databases
Knowledge of agile development methodologies
Leadership Skills:
Excellent communication skills. Clearly articulating and documenting technical and functional specifications is a key requirement
Proactive problem-solver
Relationship builder and a very good team player
Good analytical and business skills
-------------------------------------------------

Grade :All Job Level - All Job FunctionsAll Job Level - All Job Functions - IN

------------------------------------------------------

Time Type :

------------------------------------------------------

Citi is an equal opportunity and affirmative action employer.
Minority/Female/Veteran/Individuals with Disabilities/Sexual Orientation/Gender Identity.

Citigroup Inc. and its subsidiaries (""Citi) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity CLICK HERE.

To view the ""EEO is the Law"" poster CLICK HERE. To view the EEO is the Law Supplement CLICK HERE.
To view the EEO Policy Statement CLICK HERE.
To view the Pay Transparency Posting CLICK HERE.",3.7,"Citi
3.7",Pune,"New York, NY",10000+ employees,1812,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
491,Sr.Business Research Scientist,"About Amazon.com:
Amazon.com strives to be Earth's most customer-centric company where people can find and discover virtually anything they want to buy online. By giving customers more of what they want - low prices, vast selection, and convenience - Amazon.com continues to grow and evolve as a world-class e-commerce platform. Amazon's evolution from Web site to e-commerce partner to development platform is driven by the spirit of innovation that is part of the company's DNA. The world's brightest technology minds come to Amazon.com to research and develop technology that improves the lives of shoppers and sellers around the world.


About Team
The RBS is an integral part of Amazon online product lifecycle and buying operations. The team is designed to ensure Amazon remains competitive in the online retail space with the best price, wide selection and good product information. The teams primary role is to create and enhance retail selection on the worldwide Amazon online catalog. The tasks handled by this group have a direct impact on customer buying decisions and online user experience.

Overview of the role
This is a Senior leadership role in RBS with primary responsibility to build an ecosystem that will enable Research Analysts at RBS to leverage Data Sciences, ML and DL to solve business problems at scale. The leader will play a significant part in helping RBS meet its Top line and bottom line goals. You will collaborate with global Business and Tech teams on several of these goals. You will constantly stretch the boundaries of Data analytics to derive the business insights and entitlement for business problems. If you are customer obsessed, self-driven, tenacious and analytical, you will have fun solving our business problems of unprecedented scale. As an experienced research analyst, you will help/mentor other research analyst and develop new algorithms leveraging both classical and deep learning techniques.

Key Responsibilities for this Role:-
· Take ownership of a complex problem statement and define solution strategy to holistically solve that problem for RBS. Scoping, driving and delivering complex projects across multiple teams.
· Big data analysis to identify the defects patterns/process gaps and come up with long term solutions to eliminate the defects/issues.
· Build ecosystem for research analyst and scalable platform for RBS along with cross functional team
· Should be able to communicate effectively with business teams, tech teams as well as scientists from different groups
· Reviews and Makes recommendations that impact development schedules and the success for a product or project.
· Coordinates design effort between internal team and External team to develop optimal solutions for their part of project for Amazons network.
· Supports identification of down-stream problems (i.e. system incompatibility, resource unavailability) and escalate them to the appropriate level before they become project-threatening.
· Performs supporting research, conduct analysis of the bigger part of the projects and effectively interpret reports to identify opportunities, optimize processes, and implement changes within their part of project.
· Influence all level either to gather data and information or to execute and implement according to the plan.
· Ability to deal with ambiguity and problem solver
· Communicate ideas effectively and with influence (both verbally and in writing), within and outside the team.

Key Performance Areas:
· Solve large and complex business problems by aligning multiple teams together.
· Data analytics and Data Sciences
· Machine learning (Deep Learning)

Basic Qualifications

· Masters degree or higher in Engineering or Business.
· Thorough knowledge of Statistics, Data Sciences and Machine Learning.
· 5+ years of experience in using machine learning to solve business problems and building ML services
· Expert level competency in Python and its packages.

Preferred Qualifications

· Master degree / MBA
· Experience on product development
· Expertise in Python and Data Analytics
· Expertise in Text mining
· Expertise in Deep learning models",4.2,"Amazon
4.2",Chennai,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
492,Scientist- Fermentation,"Position: Scientist- Fermentation

Location: Bangalore, India

Contact: Please email admin@stringbio.com

No of Openings: 1

Fermentation scientist will play a significant role in the upstream process development. Core responsibilities include executing bench-scale fermentation with the goal of maximizing yields. Scientist will be responsible for evaluating fermentation performance of new strains. The ideal candidate will also possess a strong background in computational science and bacterial physiology.

POSITION RESPONSIBILITIES

Design, execute, and analyze scientific experiments for production of small molecules using fermentation and other techniques.

Reliable execution and management of fermentation runs as per company SOPs
Develop and optimize fermentation processes using DOE/Statistical analysis.
Seek and qualify new technologies that are enabling for accomplishing project objectives.
Collaborate with research teams for maximizing strain performance and enabling process scale up
Leverage computational modeling for developing algorithms for clustering and ranking unit operations and predicting performance
Implement Design-of-Experiment & Statistical Process Control principles for efficiently studying response variables and assessing data quality
Test product designs using models and computer-aided design technology
Possess knowledge on leveraging computational fluid dynamics for design of efficient bioprocesses
Identify new systems and processes to drive quality, efficiency and save costs
Maintain accurate and timely records of laboratory work. Evaluate data, prepare technical reports and make scientific presentations.
Be a conscientious laboratory citizen, adhere to EH&S standards, and use knowledge of laboratory procedures to advance projects.
The position is full-time. Work schedule may occasionally include weekend.

CANDIDATE PROFILE

EDUCATION AND EXPERIENCE

Advanced degree in Biotechnology/Chemical Engineering or Mechanical engineering field.
PhD plus a minimum of 2 years of experience in a scientific or engineering discipline
MTech in chemical/Mechanical Engineering/Biotechnology Engineering discipline with 5 years of experience
Proven ability to work with colleagues of diverse training, background, and experience level
Effectiveness as both a team player and while working independently
Capacity to organize and manage multiple tasks and relationships simultaneously
Keen problem-solving skills and a strong work ethic
Ability to align technical work plans with business and customer objectives.
Digital fluency, including experience with MS Office, statistical analysis and DOE and CFD tools.
Schedule flexibility necessary to support occasional problem-solving during off-hours
Readiness to shoulder responsibility
Demonstrated ability to deliver results in a fast-paced and dynamic environment

PERSONAL QUALITIES

Driven, dedicated team player with attention for detail

Ability to work independently and deliver on project objectives

Capacity to be proactive and take initiatives

Good organizational skills

Effective interpersonal skills

Strong oral and written communication skills

Creative, out of the box thinker with strong analytical and problem-solving capabilities

Ability to adapt to changing drivers",4.7,"String Bio
4.7",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
493,Data Engineer,"Locations: Bangalore, New York

Alphonso data platform processes hundreds of millions of data-points about tv and adviewership data from the entire country. We plan to continue to invest in drawing deep insights from this vast pool of tv data. You will be responsible for developing scalable data models, machine learning algorithms to unlock new insights from TV data, innovate on targeting algorithms and data graphs to drive the business value further.

Requirements:
PhD in Computer Science or equivalent.
8+ years in handling high volume (hundreds of millions of records) data sets
Proficiency in one or more of Python, Java or JavaScript
Experience with machine learning algorithms and/or statistical modeling
Familiarity with Big data technologies like Hadoop, Map/Reduce, Spark, Hive etc. is a plus",4.1,"Alphonso
4.1",Bengaluru,"Mountain View, CA",51 to 200 employees,2012,Company - Private,TV Broadcasting & Cable Networks,Media,Unknown / Non-Applicable,-1
494,Senior Data Analyst,"Share

Job Description:

This role requires you to own the analytics space for a given Cleartrip product. You would be responsible for all the data & analysis requirement related to this product. You would work closely with & across the business team, product managers & functional teams to make significant impact to this product by informing decisions using analytics & data intelligence. The data analyst would be an integral part of the product-engineering- design-business- marketing pod for that particular product. The data analyst would report all the key metrics for the product, and bring in an unbiased understanding of the causality for movement of the same. Additionally, you will be expected to identify, develop and deliver key projects which contribute to the business & product goals.
As a requirement, the candidate needs to be excellent in handling & integrating data from different sources/ platforms in order to meet the analytic requirements on his/her projects.

Skills and capabilities:

(i) Understanding of key aspects of a typical product line: product, marketing, operations and finance

(ii) Excellent analytical abilities: data driven and understanding of key analytical techniques

(iii) Strong background & hands-on experience on analytical tools like R, SQL, Excel, Python (plus) etc.

(iv) People skills: Ability to interact across team & drive ideas (& execution to an extent)

Education: B.Tech/B.E./M.Tech. graduate from premier institutes

Experience: 4-7 years",3.3,"Cleartrip
3.3",Bengaluru,"Mumbai, India",501 to 1000 employees,2006,Company - Private,Travel Agencies,Travel & Tourism,Unknown / Non-Applicable,-1
495,Associate Data Analyst,"Combine two of the fastest-growing fields on the planet with a culture of performance, collaboration and opportunity and this is what you get. Leading edge technology in an industry that's improving the lives of millions. Here, innovation isn't about another gadget, it's about making health care data available wherever and whenever people need it, safely and reliably. There's no room for error. Join us and start doing your life's best work.(sm)",3.3,"UnitedHealth Group
3.3",Hyderabad,"Minnetonka, MN",10000+ employees,1977,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"Aetna, Humana, WellPoint"
496,Drug Safety Scientist,"Essential Duties and Responsibilities:

As a Team Lead:
Supervision and coordination of following activities:
Lead and manage the projects
Supervise all project related activities.
Communicate between the Project Manager and the team.
Record, maintain and track the metrics for both team members and project performance.
Review and evaluate AE case information to determine required action based on and following internal policies and procedures.
Process current incoming cases in order to meet timelines.
Provide guidance for Data entry.
Following up with sites regarding outstanding queries.
Follow-up on reconciliation discrepancies.
Follow departmental AE workflow procedures.
Train and mentor new team members as per requirements of the project.
Delegate tasks and responsibilities to appropriate personnel
Identify and resolve issues and conflicts within the project team
Act as guide, coach and counselor for the team

Other responsibilities:
Following up with sites regarding outstanding queries and reconciliation of discrepancies
Closure and deletion of cases
Follow departmental AE workflow procedures
Oversee, mentor and guide the activities of the Drug Safety and Senior Drug Safety Associates
High level of proficiency at all workflow tasks
Perform any other drug safety related activities as assigned
Years of Experience: 3 to 4 Years of industry related experience

Education: MBBS / MD or B pharm / M pharm / MBA

Experience: More than 3 years of experience in Pharmacovigilance /Pharmaceutical / Clinical research professional.

Specialized Knowledge and Skills:
Subject Matter Expertise in Safety database
Must have good presentation skills and the ability to give presentations.
Knowledge of the Life Sciences Industry a plus.
Experience in entire drug development life cycle.
Relevant product and industry knowledge
Experience with relevant safety databases and software applications

Communication skills:
Requires a proactive approach and excellent written/oral communication and interpersonal skills.
Strong interpersonal skills required to interact with clients, management, and peers effectively.
Effective cross-department communication.
Ability to document and communicate problem/resolution and information/action plans.

Technical Skills:
Person should be familiar with MS Office tools/Data base and other applicable software.
Ability to educate/ train the team members as needed.
Maintaining Pharmacovigilance systems including global safety database.

Other Skills:

The ability to contribute to a team environment with a high degree of professionalism and skill. Demonstrated flexibility within a dynamic, fast-paced, cross-functional team. Demonstrated ability to complete multiple tasks concurrently and deliver results in a fast-paced environment. Ability to perform under stringent timelines.

Compliance:

Awareness of organizational policies & procedures governing his/her job responsibilities. Awareness and compliance of QMS & ISMS policies & procedures and their impact at his/her job level. Should understand escalation matrix and escalate to the next level whenever incidents happen which are not in compliance with organizational, QMS & ISMS policies and procedures.

Working Conditions: Normal office environment.

Hours:

Standard Hours 40 hours per week, one hour lunch, Monday – Friday. Additional hours as needed.

Willing to work in shifts as and when needed",3.5,"Bioclinica
3.5",Mysore,"Princeton, NJ",1001 to 5000 employees,1990,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,"PPD, DATATRAK International"
497,Machine Learning Engineer,"Title
Machine Learning Engineer

01-Jun-2020

Job Description
Job Description
Machine Learning Developer responsibilities include creating machine learning models and retraining systems. To do this job successfully, you need exceptional skills in statistics and programming

Responsibilities
· Study and transform data science prototypes
· Design machine learning systems
· Research and implement appropriate ML algorithms and tools
· Develop machine learning applications according to requirements
· Select appropriate datasets and data representation methods
· Run machine learning tests and experiments
· Perform statistical analysis and fine-tuning using test results
· Train and retrain systems when necessary
· Extend existing ML libraries and frameworks
· Keep abreast of developments in the field
· Analysis of huge data set
· Application of statistical methods for problem solving /analysis
· Predictive modelling and supervise learning
· Operational Research

Requirements
· Proven experience as a Machine Learning Engineer or similar role
· Understanding of data structures, data modeling and software architecture
· Deep knowledge of math, probability, statistics and algorithms
· Ability to write robust code in Python, Java and R
· Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)
· Excellent communication skills
· Ability to work in a team
· Outstanding analytical and problem-solving skills
· Graduation/ Master’s degree in Mathematics or similar field is a plus

Auto req ID
16577BR

Job Type
Full Time-Regular

Assignment Country
India

Total Years of Exp
4+

Education Type
BE

Assignment State
Telangana

Assignment Location
Hyderabad

Experience Level
Senior Level",3.1,"QuEST Global
3.1",Hyderabad,"Singapore, Singapore",10000+ employees,1997,Company - Private,Aerospace & Defence,Aerospace & Defence,₹10 to ₹50 billion (INR),-1
498,Machine Learning Engineer,"Ref.No. 3719 | Location: Chennai / Bangalore

Machine Learning Engineer

our öffer
Design and develop solutions using Machine Learning and other advanced AI technologies to solve a variety of problems
Translate user stories and business requirements to technical solutions by building quick prototypes or proof of concepts with several business and technical stakeholder groups in both internal and external organizations
Convert the proof of concepts to production-grade solutions that can scale for hundreds of thousands of users
Be hands-on where required and lead by following best practices in development and CI/CD methods

yöu
4+ years of experience in software development for high-tech products or services
2+ years of hands-on experience delivering products or solutions that utilized Machine Learning, Natural Language Processing or other forms of AI solutions like machine vision
Highly skilled in Python and preferably in one or more programming languages like C++, Java, Go, etc
Strong hands-on experience in one or more of the Machine Learning tools like TensorFlow, Keras, Theano, or Caffe and have solved several real-life problems using these
Experience in one or more NLP libraries (i.e. spaCy, NLTK, etc) is a plus
Experience with handling Big Data (Spark, HBase, Kafka, etc) is a plus
You are confident in expressing your point of view from a position of knowledge and experience. You are also
receptive to feedback and open to revising your plans when appropriate

top 5 reasöns
An entrepreneurial environment with immediate responsibility and a chance to make a difference from the word go
Innovative projects with big name clients and exposure to future, cutting edge technologies
Unlimited individual growth opportunities and the ability to create a personalised career path
Access to a global network with opportunities to live and work abroad
All the support, training and coaching you need to further your career
and extra on top: A team spirit and family-like culture as exciting and colourful as our gradient coloured coffee marshmallows

cöntact

Karthick Raja M
Manager- Talant Acquisition

careers_in@umlaut.com

üs

umlaut is a 4500 people strong global full
service cross industry end-to-end partner that applies its
deep-running interdisciplinary, collaborative advisory and
fulfilment capabilities to change its clients fortunes for the
better and - on top of that - add value, quality and focus to their
organisations and produce.",3.9,"Umlaut
3.9",Chennai,"Aachen, Germany",1001 to 5000 employees,1996,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
499,Data Analyst,"We are looking to hire a Data Analyst to join our data team. Your responsibility would include for developing reports, and troubleshooting data issues. To do well in this role you need a very fine eye for detail, experience as a data analyst, and deep understanding of the popular data analysis tools and databases.

Role & Responsibilities:
Graduate or Post Graduate in Computer Science
Work experience: 3+ as a data analyst or in related field.
Experience with SQL
Ability to understand and analyze SQL queries.
Should have prior experience with executing SQL.
Should have the ability to prepare sample test data for testing
Should have the ability to implement business logic requirements via SQL and test the code developed by Development team.
Understands Data model and have ability to build data model
Understands Entity relationship based on data entities.
Experience of BFS domain and knowledge of domain terminology is added plus

Job Location: Pune
To apply for this exciting opportunity, please email us your profile on careers@hexanika.com",4.3,"Hexanika
4.3",Pune,"New York, NY",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
500,Data Analyst,"A NEW SOCIAL FUTURE ��‍��‍


How is it that in a world that's evolving so quickly that social products still feel the same? Strangely enough, we're still using products that were invented in the 2G era. There seems to be an emptiness with the current experience and today's products are built to force humanity to be superficial.

We'd like to change that.

With the advancements in technology, so much more is possible today that wasn't even possible, just a few years ago. We believe the timing couldn't be better.

6 PRINCIPLES ��


We’re thoughtful about why we do things and here are 6 principles guiding our thinking:
Advancements in Tech & AI: Allowing more bits to be pushed to users in real-time and thus allowing far richer, more personalised experiences.
Bits Cheaper than Atoms: Today, bringing rich, luxurious experiences to the masses is faster, more efficient and cheaper online than it is offline.
Self Worth Moving Online: 40% of people's waking life is now spent on their smartphones. The next generation is far more comfortable online than offline.
Vertical Communities: We don't live our lives in one massive community. We're specific in the activities we engage in (art, gaming, fitness etc).
New Business Models: Putting customer at the centre. These won't be ad-driven in the traditional sense. Think micro-transactions, subscriptions and more.
Consumers as Owners: It's a bit strange that consumers aren't part of the value chain. Turning customers into owners is a fascinating thought.

BUILD MAGICAL THINGS ��


It’s so clear to us that technology evolves but people stay the same. We’re solving for a core human need - social connection and with all the evolution in technology, today we can solve for that in brand new ways.

At our core, we’re a creative company. Ideas and pixels is where we live and we love building magical products that make our users feel ‘wow’ inside. It’s not just about features, it’s also about how they make people feel. We build at the intersection of the scientific and the romantic.

And it all starts with people, the right team that cares deeply about our mission, values and our users. At hike, you'll have the chance to do the best work of your life.

Come join us and shape the future of social.

THE HIKE CODE


We’re on a journey to build something new, something different and making anything innovative & new requires the ability to surrender to the unknown. The Hike Code is our value system. It is our guide to navigate through the unknown to build incredible products. Here they are:
Top Talent in Every Role: We look for people with an incredible intellect. Both skills and values are important to us.
Pro-Sports Team: Strengths based, results driven with a ""team-first"" attitude
Customer at the Centre: Everything we do is inspired by how can we better solve for our customer.
Constant Innovation: It's our DNA to walk into the unknown in search of having meaningful impact.
Act Like Owners: We own the output of what we do, even if it's explicitly not our job.
Thoughtful Decision Making: Clear Mind + Obsession to Simplify + Data Driven. We strive to be thoughtful.
Always be Hustling: We understand that success is not one big leap but tiny gains compounding over time #ABH.
Be Open Minded & Coachable: We have a quest to continuously #RiseUp to be the best version of ourselves.

ROLE & REQUIREMENTS ��


If you’ve made it till here, then you’re probably interested in the role :)

Key Day to Day Responsibilities:
Perform quantitative analyses that translate data into actionable insights and provide analytical, data-driven decision-making support for key projects.
Provide reporting and performance monitoring to product teams using data drawn from diverse sources.
Own and evangelize data-driven experimentation in the team to improve the product offerings, and document it.
Enable product reviews, deep dives and analyses through the effective use of data and communicate and report insights and recommendations to shape product strategy.
Ensure that any data required for carrying out the other responsibilities for the product/features you’re working on is properly instrumented and logged.
SOUND LIKE YOU? ����


We’re looking for someone dynamic and you’ll need to have the below in generous quantities to succeed in this role.
You have a Bachelor’s degree in Math, Statistics, Comp Science, Engineering, or other technical field required; advanced degrees strongly preferred.
You are hands on with Python/ Java Programming language.
You have a very good understanding of mobile and Internet products, growth strategies and business dynamics.
You are comfortable manipulating, transforming, and analysing complex, high-volume, high-dimensionality data from varying sources.
You have 3+ years experience performing quantitative analysis, preferably for an Internet or technology company.
You have hands-on working experience on SQL queries.
You have experience in reporting and dashboards involving very large datasets and multiple data sources, with the ability to interpret data and produce meaningful insights.
You have good understanding of statistical analysis, data warehousing, data modelling.
You have experience with statistical packages such as SPSS, SAS etc. and BI/visualisation tools such as Tableau, Google Analytics etc.
You have ability to execute research projects and craft actionable recommendations.
You have proven ability to work in a fast-paced environment, meet changing deadlines and priorities on multiple simultaneous projects.
You have excellent organisational, communication, presentation and interpersonal skills.
You enjoy working in both individual and team settings.

BENEFITS ��
A flat and transparent culture
Flexible working hours - No fixed Checkin/Checkout
Unlimited Snacks, food, and drinks on the house
Tools of the trade - MacBook, Latest Softwares
Monthly Communication Reimbursement
Best learning and development opportunities
A chance to have a big impact early in your career
At Hike, we value diversity. We are an equal opportunity employer: we do not discriminate on the basis of race, color, religion, gender, ethnicity or disability status.",4.3,"Hike
4.3",New Delhi,"New Delhi, India",51 to 200 employees,2012,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,"Facebook, Google, WhatsApp"
501,Lead AI Scientist - Statistics/ML/Pricing/Optimization,"Description:

JOIN TARGET AS A LEAD AI SCIENTIST DEMAND FORECASTING AND PRICING

As a Lead A.I. Scientist on the Pricing and Demand Forecasting team with Target AI in Bangalore youll develop artificial intelligence models and algorithms for our retail business. You will work closely with partner team data scientists and Merch business partners to continuously learn more about our business and particularly develop an understanding of the various processes we have in play. You will partner with engineers and applied scientists on partner teams to build solutions for our business needs including development, deployment, and maintenance of algorithms and models at scale!

Our team oversees the creation and development of the Demand Forecasting quantitative platform, building the key components which allow us to evaluate the demand and prices of our products and proprietary new ventures products. We aim to develop these tools to be more efficient and precise, whilst also making them directly available to our business team users, hence allowing us to quickly respond to our Guests needs in store and online.

In this role at Target as a Lead AI Scientist, you'll:
Change the way demand forecasting and pricing is originated in retail and at Target.
Create our next generation demand and pricing platform at a Fortune 30 company.
Write code for math/stats models to evaluate demand for millions of items and compute prices.
Partner with business users and other scientists / engineers to build a framework allowing us to develop a new platform to more efficiently estimate demand and price on the fly.
Impact our business by improving our ability to serve our Guests and by directly reducing compute cost through more efficient algorithms.
Coordinate the analysis, troubleshooting, and resolution of issues in our software and the broader infrastructure.
Collaborate with engineering teams so that the data science products are embedded in production systems.
Understands interrelationships and impacts of data and technology upon the Target environment
Identifies and escalates issues and, when necessary, pulls appropriate teams together to solve challenge/issue, etc
Encourages team members to deep dive into analytical problems.
Participates in internal & external technology & analytical forums and discussions
Prioritize workload, ensure high quality of solutions that adhere to standards and best practices are delivered in timely fashion.
What we're looking for:
B.Tech (+6 years of relevant exp), M.Tech, M.Sc. (+5 years of relevant exp), Ph.D. (+3 years of relevant experience) in Engineering, Operation Research, Mathematics, Engineering, Statistics preferred
Experienced in building machine learning models, AI models, optimization algorithms or equivalent experience
Experienced in Optimization, data analysis, data mining, mathematical modeling and programming, statistical analysis, forecasting/predictive modeling, simulations, visualizations etc.
Demonstrated ability to work with ambiguous problem definitions, recognize dependencies and deliver impactful solutions through logical problem solving and technical ideations
Ability to learn new analytical methods and technologies and apply in practical business problems
Ability to work independently with little supervision to research and test innovative solutions.
Proficient in one or more of Python, C++, Java, Scala or equivalent programming language
Deployed large scale models/algorithms in prior experience
Bonus Points:
Strong quantitative skills including specific experience with Statistical Inference, Generalized Linear Models, Markov Decision Processes
Experience working with large event-driven distributed systems and multi-threaded applications.
Why grow your career with Target AI?
You will work directly on the AI problems that have the most impact on Target's entire supply chain, forecasting and merchandising teams.
We value diversity. We believe that diversity and inclusion is core importance when try to create positive in-store experiences for our guests, and we think it is also critically important when building our team.Read more about our commitment to diversity and inclusion
We love open source! Many of our team members contribute to open source communities and get to do it during work time. We try to contribute back to our communities where we can and are grateful to be able to open source some of our own projects!
Benefits
Eligible team members will receive market competitive package including competitive pay, health, accidental and life insurance coverage, gratuity and provident fund, training and development and other perks and benefits. Target is an Equal Employment Opportunity Employer and is a drug-free workplace.
About Target®
Minneapolis-based Target Corporation serves guests at stores nationwide and at Target.com. Target is committed to providing a fun and convenient shopping experience with access to unique and highly differentiated products at affordable prices. Since 1946, the corporation has given 5 percent of its income through community grants and programs like Take Charge of Education®.
Level:
6
Qualifications:",3.9,"Target
3.9",Bengaluru,"Minneapolis, MN",10000+ employees,1962,Company - Public,General Merchandise & Superstores,Retail,₹500+ billion (INR),-1
502,Data Modeler | 6 to 9 years | Bengaluru,"Job Description
Responsible for creating data models defining information requirements for large size management for Insurance domain Needed Extensive analysis experience and skilled at facilitating data analysis and Data Vault Modeling
Should be able to create information management framework for new business system in Insurance domain
Should be well versed with ETL technology and understand reporting platform to build cubes standard tools and techniques & Experience in generating data definition language DDL used to create the database schema
Expertise in synchronizing models to ensure that database structures match models and analyzing different source systems
Responsible for creating conceptual logical and physical data models defining information requirements for Extensive analysis experience and skilled at facilitating data modeling sessions
Should be able to create information management framework for new business system in Insurance domain
Should have created enterprise logical models EDM containing all entities and their relationships and a complete set of documentation using industry standard tools and techniques
Experience in generating data definition language DDL used to create the database schema
Expertise in synchronizing models to ensure that database structures match models
Primary Skills
Data Modeling
Erwin
Secondary Skills
SQL
Insurance Domain experience",3.8,"Capgemini
3.8",Bengaluru,"Paris, France",10000+ employees,1967,Company - Public,Enterprise Software & Network Solutions,Information Technology,₹500+ billion (INR),"Accenture, CGI, Sopra Steria"
503,Lead Data Scientist/Manager Data Scientist,"You will be primarily responsible for the design, development, and operationalization of data science applications. Lead discovery processes with the client to identify the value objectives and the technical business requirements. He/she will work closely with the client, data science and cross-functional teams to develop and execute to fulfill customer requirements.

MINIMUM QUALIFICATIONS AND REQUIREMENTS:
Bachelor’s Degree in a technology or technical related field (e.g., Computer Science, Industrial Engineering, Applied Math/Statistics). Post-graduation preferred
7+ years of analytics/data science experience
5+years of hands-on experience in using Business Intelligence tools such as SAS for analytical modeling and data management (or) 5+ years of experience in programming languages: R, SQL, Python, SAS in developing analytical solutions and data processing.
Knowledge of Cloud technologies like GCP, AWS, Azure is preferred
Strong understanding gained through experience in advanced analytics (forecasting, data mining, optimization, and reporting) techniques
Knowledge in Machine Learning Concepts around NLP/Information retrieval / Recommendation systems is preferred
Demonstrated experience in effectively communicating with senior leaders and executives
Exceptional organizational, analytical and problem-solving skills
Excellent leadership, communication, and presentation skills both written and oral
Able to work effectively in global teams and willing to travel to global client locations
In-depth domain knowledge in either of retail, manufacturing, financial services or telecom preferred to engage with enterprise-level clients/customers
Possesses a unique blend of business and technical savvy: a big-picture view, and technical credibility to define enterprise-class solutions
Track record of ownership and delivery of large, complicated projects on time and within the scope
Certifications such as Python, SAS, GCP preferred and willingness to learn new technologies including cloud platforms
We highly value experience in contributions to data science blogs, white papers in Data Science forums

PRINCIPAL DUTIES AND RESPONSIBILITIES:
Lead data science projects from conceptualization through launch: project discovery phase through requirement gathering, design and implement analytical solutions to address key client business problem and deliver value using SAS / R / Python
Develop implementation guidelines, process enhancement, quality control procedures, coding best practices and documentation for projects
Manage and inspire associates and developers towards seamless execution and successful project delivery
Manage different analytical work-streams including reporting, visualization, automation, data science methods, and machine learning techniques
Cultivate a deep understanding of the customer and work together to provide an enriching experience
Write tech blogs, white papers in the field of Data Science and guide the associates
Take lead in proposing and implementing Data Science practice initiatives

SKILLS:
Programming Skills – SAS, Python, SQL, R
Analytics – Forecasting, Optimization, Customer Analytics, Machine Learning, Deep Learning
Data Visualization – Tableau, SAS Visual Analytics, Google Data Studio
Problem Solving Skills
Project Management
Presentation Skills
Stakeholder Management",4.2,"CoreCompete
4.2",Hyderabad,"Durham, NC",201 to 500 employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
504,Data Analyst,"Experience
1 to 3 years

No.Of.Positions
4

Location
Chennai

(willing to relocate to Hyderabad down the line )

Notice Period
Immediate – 15 days

Job Description:
Passion for problem solving by gathering descriptive insights through data extraction, slicing and dicing the data
Experienced in writing complex SQL select queries
Strong in querying logic and data interpretation
Individual contributor
Responsibilities

Understand the real-time business problem, create insightful reports and build story via insights
Look at the data from different databases in different dimensions and think out of the box to find solutions
Connect different datasets to find new information, that presents implementable tactics and actions

Skills:
SQL, one of the Visualisation toolset like PowerBI, Tableau, Qlikview
Database concepts
Business understanding
Good Communication skills, should be able to hold a conversation with client on a solution for 30 minutes",4.0,"Indium Software
4.0",Chennai,"Cupertino, CA",501 to 1000 employees,1999,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
505,Senior Manager – Data Scientist and Business Intelligence (9 – 15 years),"A leadership role with expertise in the arena of business intelligence, statistics, analytics, data science, bid data and data visualization. A tenured analytics professional who has managed a team of at least 50 members. A BI leader strategizing solutions in product analytics, web analytics and supply chain. A continuous effort in process improvement with upgrading and scalable machine learning techniques; effective team management

LOCATION: -Gurgaon

YOUR FUTURE EMPLOYER:
A leading global analytics products & services firm providing marketing and customer analytics and big data analytics.

YOU WILL BE RESPONSIBLE FOR:
Engage with leadership and diversified stakeholder groups to understand their data and analytics needs and recommend BI or ML solutions
Partner with the Data Engineering teams to define the data elements and data structure that the team should leverage to enable analytical capabilities
Own the design, development, and maintenance of ongoing performance metrics, reports, analyses, dashboards, etc. to drive key business decisions
Work with Data Engineering, Machine learning, and Software Development teams to drive capture and storage of key data points, and on implementation of new dashboards/analyses

THE SUCCESSFUL CANDIDATE:
9+ years of experience in analytics or data science and business intelligence space with exposure to technology.
Deep exposure to AWS/ cloud architecture.
Expertise in big data technologies like spark, pyspark, sparkR etc. and natural language processing·
Advanced proficiency in SQL, data modeling, and working with “Big Data”
Experience with data visualization using Tableau or similar tools
Experience with statistical modeling and analyzing large data sets
Experience in managing and prioritizing a project backlog
Strong exposure to client management, product development, proposal creation etc.
Exposure in implementing data science solutions in production environments,
5 years of experience in analytics or data science space with exposure to technology.
Engineering, mathematical or statistical background
Expert in ML algorithms
Extensively worked on R/Python and SQL
Deep exposure to AWS/ cloud architecture.
Expertise in big data technologies like spark, pyspark, sparkR etc. and natural language processing
Strong exposure to client management, product development, proposal creation etc.
Exposure in implementing data science solutions in production environments

WHAT IS IN FOR YOU: -
An opportunity to define, lead and co-ordinate the technical functions of the company.
Liaise extensively with stakeholders.
A meritocratic culture with great career progression.
REACH US:- If you think this role will add value to your career, kindly write me an email along with your updated CV on nikita.sharma@crescendogroup.in or connect on 7087413515 for a confidential discussion on the role.
Reference Number: 1390
Contact Details: Nikita Sharma
Profession: Analytics > All
Company: client of crescendo global
Date Posted: 4/06/2020",4.6,"Crescendo Global Services
4.6",Karnataka,"Gurgaon, India",1 to 50 employees,2014,Company - Private,Staffing & Outsourcing,Business Services,₹100 to ₹500 million (INR),"PageGroup, Hays, Russell Reynolds"
506,Data Scientist/Analytics Engineer - Machine Learning/Predictive Modeling,"Job Profile:
This role is for SunTec’s Data Analytics Division.Responsible for contributing to the design, implementation and maintenance of new software algorithms of our platform.
The ideal candidate is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. He/she will help transform our clients' data into tangible business value by analysing information, communicating outcomes and collaborating on product development.

Responsibilities:
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Define technical roadmap and work on cutting edge technology in predictive modelling, machine learning and neural networks.
Implement efficient data structures to enable faster machine learning models.
Participate actively in detailed design, code reviews, bug/issue triage with feature teams and support well informed decisions towards engineering, customer and business goals.
Handle end to end project/product techno-functional solutions independently and provide guidance to other team members
Proven communication skills in in English and solid writing, MIS, communication, time management and multi-tasking skills
Tell engaging and insightful stories with data, effectively demonstrating knowledge, expertise and real world applications.
Analyse Open-source data and associated web-scraping techniques.
Collaborating with engineering teams to develop prototypes and software products that can be deployed across varied environments (e.g.: cloud, on-premises, devices, etc.)
Perform high-level analysis of any new requirements/change requests to the solution from a technical standpoint.

Role Requirements:
5+ Years' experience on Artificial Intelligence/ Machine Learning /Deep Learning
Hands on experience with Tableau, Anaconda, Sublime text & Eclipse
Hands on experience with AWS and Google cloud, Jenkins, and setting up continuous integration / continuous deployment.
Experience working in predictive models, data models, financial models, and machine learning models.
Experience with B2B business data analysis, B2B financial data analysis and demographic data analytics.
Experience with developing software in R, and Python.
Experience in working on live Data Science projects.
Have strong contributions in development communities, open source projects, or forums.
Proven interpersonal skills while contributing to team effort by accomplishing related results as needed",3.7,"Suntec Web Services
3.7",New Delhi,"New Delhi, India",501 to 1000 employees,1999,Company - Private,Advertising & Marketing,Business Services,₹1 to ₹5 billion (INR),"Flatworld Solutions, Unisoftdata, DataEntryOutsourced"
507,Data Analyst,"Welcome to Thrillophilia ! 1.5 Million users come every month to plan their trips on Thrillophilia . We are your one stop solution to book your tours, activities, staycations and much more.

At Thrillophilia, we’re proud to stand at the forefront of the Big Data revolution. Using the latest analytic tools and processes, we’re able to maximize our offerings and deliver unparalleled service and support. To help carry us even further, we’re searching for an experienced data analyst to join our team. The ideal candidate should be highly skilled in all aspects of data analytics, including mining, generation, and visualization. Additionally, you should be committed to transforming data into readable, goal-driven reports for continued innovation and growth.

Responsibilities

Interpret data, analyze results using statistical techniques and provide ongoing reports

Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality

Acquire data from primary or secondary data sources and maintain databases/data systems

Identify, analyze, and interpret trends or patterns in complex data sets

Locate and define new process improvement opportunities

Use data to create models that depict trends in the customer base and the consumer population as a whole

Develop, implement, and maintain leading-edge analytic systems, taking complicated problems and building simple frameworks

Identify trends and opportunities for growth through analysis of complex data sets

Evaluate organizational methods and provide source-to-target mappings and information-model specification documents for data sets

Create best-practice reports based on data mining, analysis, and visualization

Requirements

Proven 1-year experience as a data analyst.

Technical expertise regarding data models, database design development, data mining and segmentation techniques

Strong knowledge of and experience with reporting packages (Business Objects etc), databases (SQL etc)

Strong Knowledge of Excel, Python, r language

Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy

Adept at queries, report writing and presenting findings",4.5,"Thrillophilia
4.5",Jaipur,"Bengaluru, India",51 to 200 employees,2009,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
508,Sr. Machine Learning Engineer,"We are looking for a machine learning engineer with experience in machine learning and time-series forecasting algorithms. If you want to work on classification, regression and time-series algorithms, Mate Labs welcomes you.

Mate Labs has built ""Mateverse"" for Data Analysts so that they can build customized machine learning and data science models for a quick prediction like sales forecasting without writing even a single line of code. At Mate Labs, we are solving a unique problem of Algorithm & Hyperparameter selection in the field of Artificial Intelligence.

Machine Learning has transformed industries and is ready to revolutionize the way you live, work and commute. It has created millions of new job opportunities and will continue to do so. This industry is going through a very exciting phase and at Mate Labs, we want to be at the forefront of this revolution. If it sounds exciting and you want to be a part of this revolution, join Mate Labs. Apply Now.

Roles and responsibilities:

* Will work on a wide range of machine learning algorithms in classification, regression and time-series forecasting areas
Will work on algorithm selection, hyperparameter optimization, and various model search methods
Will work on research paper implementations and writing our own algorithms from scratch
Will work with libraries like Scikit-learn, Pandas, Dask, PyTables, Numpy, Statsmodels, Prophet, XGBoost, LightGBM, CatBoost, and other machine learning libraries
Will work on time-series algorithms like ARIMA, SARIMAX, Prophet, Holtwinters, Exponential Smoothing, and other popular algorithms
Will work on client projects and handling the deliverables.

Skills required:

* 5 to 7 years of experience
Machine Learning Algorithms (Classification, Regression, Time-series, and Clustering)
Experience with time-series algorithms like ARIMA, Prophet, Holtwinters and Exponential Smoothing
Hyperparameter optimization algorithms for time-series algorithms
Frameworks - Scikit-learn, Pandas, Dask, PyTables, Numpy, statsmodels, XGBoost, LightGBM, CatBoost, FBProphet
Time-series - Multivariate time-series forecasting
Good communication skills

Benefits:

*Startup culture(immense scope to learn and grow).
Amazing team to work with.
Health Insurance for the employees.",-1,Matelabs Innovations Pvt. Ltd.,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
509,Data Analyst,"Job Purpose:

We are looking for a Data Analyst whose job duties include data research, data analysis.

Roles and Responsibilities:
Perform business analysis using various techniques such as statistical analysis, explanatory and predictive modeling, data mining.
Determine the best analytical model and approaches to present and explain solutions and options to business users.
Determine best practices and develop actionable insights and recommendations for the current business operations.
Provide support for a range of data cleansing and data modeling activities, as required by the business, using internal and external data sources.
Sense-check large lists of data.
Work with strategic market teams to ensure data is accurately aligned.
Work directly with internal and external clients to identify analytical requirements.
Produce ad-hoc data queries and reports to support and guide business decisions.
Assist in the evaluation, implementation and developmental of systems to capture business operation information and documentation of the system once delivered. Provide end-user training and vendor management for related systems, as necessary.
Provide backup support for Reporting and Data Warehouse solution, OBIEE, or other reporting systems.
Guide less experienced Business Data Analysts and end users on the Data and Decisions Support teams processes and objectives.
Desired Skills:
Bachelors Degree in Maths, Statistic and computer related
0 to 2 years related experience in IT data or business process related role
Languages: R, Python, HTML, Javascript, C/C++, SQL, Matlab, SAS
Experience with Database/Data Systems preferred: MS SQL, OBIEE, Oracle, ODI, MS Access, MS Power BI NO SQL, Data Lakes.
Machine Learning, Statistical Analysis, AI Tools, CRM system experience preferred
Strong math background
Strong Excel skills with the ability to manipulate large data spreadsheets
Excellent attention to detail and accuracy of work is essential
Ability to confidently interact and engage with stakeholders at all levels in the organization from graduates through to board level
IT savvy with a problem-solving nature
Ability to effectively prioritize and execute tasks in a high-pressure environment
Ability to conduct research into a wide range of data or systems issues as required.",4.3,"AMBC
4.3",Hyderabad,"Naperville, IL",1 to 50 employees,2001,Private Practice / Firm,IT Services,Information Technology,₹500 million to ₹1 billion (INR),-1
510,Senior Data Analyst,"Location:
Bangalore - India
Job Id: 20WD40634



Position Overview

As the Sr. Data
Analyst LC, you will be part of the License Compliance Analytics team
within Global License Compliance Sales. Our team is instrumental in supporting
the global organization by detecting and addressing incompliant usage of
Autodesk’s software. We are a strong partner for both the data science &
engineering team, as well as for the customer-facing LC sales teams; we build
the bridge between data and business. Our team has a lot of visibility and the
impact of our work can directly be related to business results. We value the
culture in our team and at Autodesk in general, we take pride in our diversity
in this global team and how we work and talk with another

In this role, your
primary focus is to analyze complex datasets and deliver meaningful insights
into customer behavior. You will explore large datasets, extract and transform
the necessary information and prepare the findings for an impactful
presentation. You will be partnering closely with other analysts, with data
engineers as well as sales managers. To be successful and impactful in the
role, you need to be able to understand business questions in the same way as
you understand data and analytical methods. You need to have a high degree of
accountability, pragmatism and adaptability. Many times, you will explore new
data sets and new platforms, so you also need to be able to find creative
solutions for challenging data-oriented questions. The position reports to the
Manager LC Business Analysis


Responsibilities
Explore, query and transform
large datasets of customer data and transactional data
Drive own projects and support
larger projects with data extracts and insights into which data can be
leveraged
Collect business requirements
for your analytics projects and plan the analytical approach
Summarize, visualize and
communicate your findings in clear and concise business language
Become a subject matter expert
of the relevant data and the big data platforms it’s hosted on
Collaborate with business analysts,
data engineers and data product owners to discuss the approach and to gain
understanding of the data
Contribute to defining standard
queries on our datasets so that the can be reused by other analysts in the
team


Minimum Qualifications
4 years with relevant experience
required as data analyst or business data analyst
Strong analytical skills with
the ability to collect, organize and analyze significant amounts of
information with attention to detail and accuracy
Advanced experience with
writing SQL scripts and at least one additional scripting language (e. g.
Python)
Experience working with
cloud-based data platforms such as Snowflake
Experience working with
business intelligence systems such as Looker or PowerBI
Proven experience with
independently solving problems in the field of business analytics
2 years’ experience working in
an international environment with a distributed team
Fluency in English language",4.0,"Autodesk
4.0",Bengaluru,"San Rafael, CA",5001 to 10000 employees,1982,Company - Public,Computer Hardware & Software,Information Technology,₹100 to ₹500 billion (INR),-1
511,Data Analyst,"Good Typing Skills

Good Communication Skills

Job Detail
Offerd Salary₹10,000- ₹15,000
ExperienceLess than 1 Year
GenderMale
QualificationB.Sc",5.0,"Inspire Global Solutions
5.0",Mysore,"Mysore, India",1 to 50 employees,-1,Company - Public,-1,-1,Unknown / Non-Applicable,-1
512,Research Associate/Research Scientist (Downstream Process),"Position: Research Associate/Research Scientist (Downstream Process)

Location: Bangalore, India

Contact: Please email admin@stringbio.com

No of Openings: 1

The candidate will be responsible for design, planning and execution of downstream processes. The employee will also be involved in compilation and interpretation of data from lab scale experiments. He/she will be responsible for inventory management which includes the amount and efficiency of product generation. He/she will be responsible for coordination of activities related to departmental audits, communicating with vendors for technical queries, preparation of BMR, SOP, technical presentations and data compilation. The candidate is someone who is enthusiastic about taking challenges and has an eagerness to learn new techniques.

POSITION RESPONSIBILITIES

Design, plan, test and improve downstream processing for a particular molecule.
Support and manage operations of separation, chromatography, TFF, filtration and drying systems.
Quantify, monitor and establish the yield and efficiency of unit operations
Optimize the process for specific target metrics
Monitor and support end to end execution at lab and pilot scale
Should be conversant with interpretation of analytical and process data and should be conversant with DSP scale-up principles.
Good communication skills.
Be a conscientious laboratory citizen.
Adhere to EH&S standards, and use knowledge of laboratory procedures to advance projects under shifting priorities and timelines.
The position is full-time.

CANDIDATE PROFILE

EDUCATION AND EXPERIENCE

M.Tech in Bio-Chemistry/Bio-Technology, MS/M.Sc(Science) in Biotechnology

>4 years’ work experience in downstream process

Experience in unit operations like separation, filtration, drying, centrifugation etc.

Proficiency with MS Office suite.

PERSONAL QUALITIES

Driven, dedicated team player with attention for detail

Ability to work independently and deliver on project objectives

Capacity to be proactive and take initiatives

Good organizational skills

Effective interpersonal skills

Strong oral and written communication skills

Creative, out of the box thinker with strong analytical and problem-solving capabilities

Ability to adapt to changing drivers.",4.7,"String Bio
4.7",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
513,Data Engineer II / Sr Data Engineer,"Relocation Assistance Offered Within Country
# 83461 - Mumbai, Maharashtra, India

We are looking for a savvy Data Engineer to join our growing team of analytics experts. Data Engineers will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoy optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Roles and Responsibility:
Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources
Assist with data-related technical issues and support their data infrastructure needs.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Experience
We are looking for a candidate with minimum 2 years of experience in a Data Engineer role
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Experience supporting and working with cross-functional teams in a dynamic environment.
They should also have experience using the following software/tools:
Experience with relational SQL and NoSQL databases: MongoDB, Neo4j, etc
Experience with cloud services: GCP, AWS, etc
Experience with object-oriented/object function scripting languages: Python, Java, etc.
Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with Data Flow, Data Pipeline and workflow management tools: Cloud Composer, Airflow, Luigi, etc.
Qualification & Competencies
Bachelor’s degree required, Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field is preferred
Working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Strong analytic skills related to working with unstructured datasets.
Strong problem solving skills with an emphasis on product development.
Strong experience with test driven development methodologies.
Strong oral & written communication skills with an ability to express complex technical concepts in business terms and business needs in technical specifications
A drive to learn and master new technologies and techniques.
Equal Opportunity Employer
Colgate is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity, sexual orientation, national origin, ethnicity, age, disability, marital status, veteran status (United States positions), or any other characteristic protected by law.

Are you interested in working for Colgate-Palmolive? You can apply online and attach all relevant documents such as a cover letter and resume or CV. Applications received by e-mail are not considered in the selection process. Become part of our team. We look forward to your application.

Colgate-Palmolive is a leading global consumer products company, tightly focused on Oral Care, Personal Care, Home Care and Pet Nutrition. Colgate sells its products in over 200 countries and territories around the world under such internationally recognized brand names as Colgate, Palmolive, elmex, Tom’s of Maine, Sorriso, Speed Stick, Lady Speed Stick, Softsoap, Irish Spring, Protex, Sanex, Elta MD, PCA Skin, Ajax, Axion, Fabuloso, Soupline and Suavitel, as well as Hill’s Science Diet and Hill’s Prescription Diet.

For more information about Colgate’s global business, visit the Company’s web site at http://www.colgatepalmolive.com. To learn more about Colgate Bright Smiles, Bright Futures® oral health education program, please visit http://www.colgatebsbf.com. To learn more about Hill's and the Hill’s Food, Shelter & Love program please visit http://www.hillspet.com. To learn more about Tom’s of Maine please visit http://www.tomsofmaine.com.

Reasonable accommodation during the application process is available for persons with disabilities. Please contact Application_Accommodation@colpal.com with the subject ""Accommodation Request"" should you require accommodation.",3.9,"Colgate-Palmolive
3.9",Mumbai,"New York, NY",10000+ employees,1806,Company - Public,Consumer Products Manufacturing,Manufacturing,₹500+ billion (INR),-1
514,Sr Data Scientist - Product Development,"Date: Mar 12, 2020

Ericsson enables communications service providers to capture the full value of connectivity. The companys portfolio spans Networks, Digital Services, Managed Services, and Emerging Business and is designed to help our customers go digital, increase efficiency, find new revenue streams, and create new user experiences. Ericssons investments in innovation have delivered the benefits of telephony and mobile broadband to billions of people around the world ensuring our solutions and our customers are at the forefront of innovation. We support networks that connect more than 2.5 billion subscribers. With over 90,000 employees and customers in 180 countries, we combine global scale with technology and service leadership. 40 percent of the worlds mobile traffic is carried over an Ericsson network. And, our Technology for Good and Connect to Learn programs include creating technology that makes it easier to save lives, feed societies, bring technology to emerging markets and connectivity to remote areas, and grow businesses and prosperity.

At Ericsson, we give our employees the freedom to think big and navigate their career, on a global scale. We create technology that helps others, from helping people enjoy their favourite content to helping people recover from natural disasters by enabling better communications between rescue workers. Your ideas and innovations can turn into achievements that impact society and change the world, creating new connections, new possibilities, and new capabilities. We find that Ericsson is at its best when we bring together the diverse skills of our people. Working across business areas, across cultures, across geographical borders, across technical disciplines. More often than not, across ground-breaking solutions. Next generation technology can be staggeringly complex. But the simpler it is to use; the more people benefit from it. Join us and help build technology that makes it simple to connect with information, business, societies, and each other.
Job Summary

As a Data Scientist, you will need to have strong programming skills and deep understanding of data science and Machine Learning tools. Have proven experience in Data Science methodologies and how to apply them to solve challenging real-world problems as part of a highly dynamic and global team. You have strong communication, collaboration and planning skills. You will be working on high impact initiatives with other specialists in Machine Intelligence to drive growth and economic profitability for Ericsson and its customers by accelerating current Ericsson offerings as well create new offerings in the areas of MI driven 4G and 5G network, distributed cloud, IoT and other emerging businesses.

Key Qualifiications
Education: Bachelor in Engineering (B.E/ B.Tech in IT, Telecom)
Minimum years of exp-12+years
Proven skills and track record (Github, open source etc.) in the use of current state of the art machine learning frameworks such as Keras, TensorFlow, Scikit-Learn, H2o, Spark etc. in developing ML/AI applications
Experience of data wrangling and data munging, using Big Data technologies
Strong analytical skills and ability to acquire new knowledge and apply it in the job
Programming skills in various languages (C++, Scala, Java, R) with proficiency in Python and/or C++
Good communication skills in written and spoken English
Creativity and ability to formulate problems and solve them independently
Ability to develop and drive new ways of working, to produce deliverables in a more efficient way
Key Responsibilities
Experience with data visualization and dashboard creation
Certifying MI MOOCS, a plus
Applications/Domain-knowledge in Telecommunication and/or IoT, a plus.
Ability to build and nurture internal and external communities
Experience in writing and presenting white papers, journal articles and technical blogs on the results
Ability to work in a collaborative environment, i.e., working with complex multiple stakeholder business units, global customers, technology and other ecosystem partners in a multi-culture, global matrix organization with sensitivity and persistence

Ericsson provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetics. Ericsson complies with applicable country, state and all local laws governing nondiscrimination in employment in every location across the world in which the company has facilities. In addition, Ericsson supports the UN Guiding Principles for Business and Human Rights and the United Nations Global Compact. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, training and development. Ericsson expressly prohibits any form of workplace harassment based on race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetic information.",3.9,"Ericsson-Worldwide
3.9",Chennai,"Stockholm, Sweden",10000+ employees,1876,Company - Public,Telecommunications Services,Telecommunications,₹500+ billion (INR),"Huawei Technologies, IBM, Cisco Systems"
515,SSE/TC - Data Engineer,"We are looking for an analytical, big picture thinker who is driven to enhance and further the mission of Tredence by delivering technology to internal business and functional stakeholders. You will serve as a leader to drive the IT strategy to create value across the organization. This Data Engineer will be empowered to lead the engagement to focus on implementing both low-level, innovative solutions, as well as the day-to-day tactics that drive efficiency, effectiveness and value

You will play a critical role in creating and analysing deliverables to provide critical content to enable fact-based decision making, facilitation and achievement of successful collaboration with the business stakeholders. You will analyse, design, and develop best practices business changes through technology solutions.

Technical Requirements
Have Implemented and Architected solutions on Google Cloud Platform using the components of GCP
Experience with Apache Beam/Google Dataflow/Apache Spark in creating end to end data pipelines.
Experience in some of the following: Python, Hadoop, Spark, SQL, Big Query, Big Table Cloud Storage, Datastore, Spanner, Cloud SQL, Machine Learning.
Experience programming in Java, Python, etc.
Expertise in at least two of these technologies: Relational Databases, Analytical Databases, NoSQL databases.
Certified in Google Professional Data Engineer/ Solution Architect is a major Advantage
Experience
4-7 years experience in IT or professional services experience in IT delivery or large-scale IT analytics projects
Candidates must have expertise knowledge of Google Cloud Platform; the other cloud platforms are nice to have.
Expert knowledge in SQL development.
Expertise in building data integration and preparation tools using cloud technologies (like Snaplogic, Google Dataflow, Cloud Dataprep, Python, etc).
Experience with Apache Beam/Google Dataflow/Apache Spark in creating end to end data pipelines.
Experience in some of the following: Python, Hadoop, Spark, SQL, Big Query, Big Table Cloud Storage, Datastore, Spanner, Cloud SQL, Machine Learning.
Experience programming in Java, Python, etc.
Identify downstream implications of data loads/migration (e.g., data quality, regulatory, etc.)
Implement data pipelines to automate the ingestion, transformation, and augmentation of data sources, and provide best practices for pipeline operations.
Capability to work in a rapidly changing business environment and to enable simplified user access to massive data by building scalable data solutions
Advanced SQL writing and experience in data mining (SQL, ETL, data warehouse, etc.) and using databases in a business environment with complex datasets.
About you:
You are self-motivated, collaborative, eager to learn, and hands on
You love trying out new apps, and find yourself coming up with ideas to improve them
You stay ahead with all the latest trends and technologies
You are particular about following industry best practices and have high standards regarding quality.",3.5,"Tredence
3.5",Bengaluru,"San Jose, CA",501 to 1000 employees,2013,Company - Private,Consulting,Business Services,₹1 to ₹5 billion (INR),-1
516,Senior Data Scientist (Mid-Senior Level),"ERM has an opportunity available for a Senior Consultant to join our global Digital Services business. This position will be based in India and will be a Data Scientist responsible for supporting our data analytics services. The ideal candidate must be adept in applying analytical methods on large datasets using a variety of data tools to discover information that can result in business process optimization or enhancements, or lead to actionable business decisions.

This position requires working closely with subject matter experts and technical leaders from within the business, across time zones, and as part of diverse teams that may be established for revenue delivery on project to project basis.

Responsibilities:
Assist in developing technology automation framework: Demonstrated capability in building Data Science platform that can handle Text, Video and other Big Data/Telemetry datasets and capability in developing/identifying an automation framework to run algorithms.

Training and Orientation Assistance: Lead focused Data Science Training and Orientation. Help set the coding standards and framework for algorithms. Build a guide for choosing a right algorithm for a given hypothesis.

Client Meetings: Attend and provide support for face-to-face/virtual client meetings, which will involve some travel.

Proposal Drafting: Work on proposals to provide Data Science inputs and where relevant, take ownership of proposal delivery.

Develop custom data models and algorithms to apply to data sets that drive better outcomes for the client and the organization.

Develop A/B testing framework and test model quality.

Perform ad-hoc analysis and present results in a clear manner.

Develop automated processes and tools to monitor and analyze model performance and data accuracy.

Requirements:
Degree in Mathematics, Computer Science, Statistics, Economics, or related quantitative field with 10 + years of professional experience

Ability to model data for analytical problem solving.

Knowledge of Data Science best practices and their implementation in project delivery.

Experience working in teams with ownership of delivery. Excellent written and verbal communication skills for coordinating teams across geography.

Skilled in visualizing/presenting data using BI tools e.g. PowerBI, Tableau, Plotly, D3.js, Datawrapper, etc. to visualize the Algorithm outputs.

Excellent coding skills in Python / R.

Comprehensive knowledge of cloud offerings from Azure / AWS for Data science algorithms.

Strong knowledge of building machine-learning algorithms using Azure machine learning SDK for python.

Experience working with external API to collect / process and transform data to support the Algorithms.

Professional experience with cloud MS Azure or AWS for building the ML algorithms.

Hands on experience in Image and Video processing using the Python Open CV libraries.

Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.

Skilled in drafting and developing hypothesis to support the business problem solving.

Who We Are:
As the world’s leading sustainability consulting firm, ERM is uniquely positioned to contribute to the environment and society through the expertise and energy of our employees worldwide. Sustainability is what we do, and is at the heart of both our service offerings and how we operate our business. ERM and our partners are driven by a dynamic vision: By 2021 we will be the clear leader in our chosen markets, we will double in value and we will deliver on our promises to our clients, our people and our investors. For our people, our vision means attracting, inspiring, developing and rewarding our people to work with the best clients and on the biggest challenges, thus creating valuable careers. We achieve our vision in a sustainable manner by maintaining and living our ERM values that include Accountability, Caring for our People, Client Focus, Collaboration, Empowerment, and Transparency.

Please submit your resume and brief cover letter.

ERM does not accept recruiting agency resumes. Please do not forward resumes to our jobs alias, ERM employees or any other company location. ERM is not responsible for any fees related to unsolicited resumes.

ERM is proud to be an Equal Employment Opportunity employer. We do not discriminate based upon race, religion, color, national origin, gender, sexual orientation, gender identity, age, marital status or disability status.

Thank you for your interest in ERM!",3.1,"ERM Group
3.1",Bengaluru,"London, United Kingdom",5001 to 10000 employees,1971,Company - Private,Consulting,Business Services,₹50 to ₹100 billion (INR),"AECOM, Golder Associates"
517,Research Scientist: Data Science,"About Dasceq
Dasceq is transforming collection industry in USA using AI/ML and Big Data. We are focused to build a best in class Collection AI SaaS Product and have already established our product for $320billion Auto and Short Term Industry. We are expanding our team and looking for next generations data scientist with experience to lead high end AI Product Development. We don’t do lip service and we are committed to solve a $1.6 Trillion collection problem and looking to expand our amazing Data Science team. If you would like to build something high end and push boundaries contact us today!

Job codes: DASRS1, DASRS2

Qualifications :
Ph.D in Econometrics ; Statistics ; Computer Science, Data Science

Preferred Institutes:
ISI, IITs, IISc, Madras School of Economics, Delhi School of Economics, BITS, NITs.

Job Description : DASRS1
The prospective hire would be part of a core R&D Team working along with other highly specialized Data Science researchers in developing new algorithms and be involved in deep problem solving; Prior experience of implementing projects in, or sound knowledge in consumer behaviour and utility theory would be extremely important for this profile.

Pay:
As per experience and market standards

Job Description : DASRS2
The prospective hire would be part of a core R&D Team working along with other highly specialized Data Science researchers in developing new algorithms and be involved in deep problem solving; Prior experience of implementing projects in, or sound knowledge in Deep Learning model implementations and Advanced machine Learning model developments would be extremely important for this profile.

Pay:
As per experience and market standards

Apply at: ritu@dasceq.com

Please send: Latest resume with current Salary and Bonus components mentioned",2.0,"Dasceq
2.0",India,"Irving, TX",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
518,User & Business Monetization - Associate Data Scientist,":

At Truecaller, we have an ocean of data to mine, we believe in working hard & smart, learning every day in this constantly evolving
space while adding value to our users and business.
We focus on measurable and impactful work and don’t forget have a lot of fun along the way. If this sounds like you, we want to talk to you!

Job Description:
We are looking for a data scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter
decisions to deliver even better products. translating a business problem to a DS problem, scope definition, data cleaning, explorations, feature engineering, feature selection, modelling, building prototype, documentation of an algorithm and insights, will
also help with data collection and algorithm quality monitoring.

Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems
integrated with our products.

Classifying based on a variety of data and meta data, anomaly detection systems, recommendation systems, internal A/B testing
procedures, improve and extend the features used by our existing classifiers.

Responsibilities :
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending company’s data with other sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems,Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner,Creating automated anomaly detection systems and constant
tracking of its performance

Communication between teams and ability to transfer knowledge in a readable/understandable manner for everyone.

Skills and Qualifications :
Good understanding of machine learning techniques and algorithms, such as Neural Networks, K-Means, k-NN, Naive
Bayes, SVM, Decision Forests, etc.
Experience with common data science toolkits, such as Spark, sklearn, GGplot, Advanced Excel, NumPy, MatLab, etc.
Great communication skills
Experience with data visualisation tools, such as tableau, Google Data Studio etc.
Proficiency in using query languages such as SQL, Hive, Spark, Cassandra
Experience with NoSQL databases, such as MongoDB, Cassandra, Hive, Hadoop
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Data-oriented personalityMaster’s/PGDDS in Computer Science, Statistics, Mathematics,
Engineering, Operations Research or related fields
1-3Y Exp in an Analytics/Data Science or similar roles, self- curated projects

Personality

Well-structured
Proactive
Team player
Polite and respectful
Honest and trustworthy
Never give up
Taking ownership
We offer

At Truecaller we have built a dynamic and diverse culture where we are keen to take ownership of what we are doing, learn and develop ourselves and are willing to share their knowledge with others. We love to experiment with new tools and technologies to push the envelope and be able to deliver the best product to our users and we believe that failure is halfway to success. At Truecaller you will find challenges and a team with passion for what we do.

Applying

This position is located in Bengaluru, India.

We only accept applications in English.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, or marital status.",-1,True Caller,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
519,Package Design Engineering Data Analyst,"Req. ID: 174382

Responsibilities
Collaborate with PIE, CEM, IT, Smart Manufacturing, MCT, Process Control, Equipment team to develop integrated monitoring tools to manage device yield and other critical care-about during development stage.
Extract, monitor, analyze inline data, test data and tools data to improve yield, throughput, performance, reliability, process margin and reduce costs.
Work cross-functionally with Design, Product Engineering, Modeling, Process, Equipment, Electrical and Physical Failure analysis teams, Defect Analysis, Param, and Quality teams to understand issues, targets, and priorities for development
Summarize complex problems, derive, explain data-driven actions taken to address them and drive team to execute with defined sub milestone
Periodically follow up with manager to ensure all type of goals are met and get assistance to remove obstacles. Use all available resources to manage the successful completion of goals, including resources outside of the area.
Demonstrate ability to give effective presentations to both small and large groups on project updates and new initiative proposals. Communicate in a timely manner and help drive to fix the issue where necessary.
Develop machine learning algorithm / predictive models and collaborate with engineering teams on improvement projects / case studies
Requirements:
B.S. Degree or higher in Mechanical, Electrical, Industrial, Computer Science or related field
Familiar / Had experience with Big Data, Data Warehousing or Business Intelligent technologies.
Good knowledge in some following programming or scripting languages like Java, Linux, Matlab, C#/C++, Python, Perl and/or R on Linux/Windows platforms.
Good data extraction, analysis, problem solving, reporting and presentation skills. Proven ability to troubleshoot and solve issues, and address root cause.
Good multi-tasking, verbal and written communication skills.
Strong interpersonal skills and customer/co-worker relationships. Successfully demonstrated teamwork skills with a strong focus on developing good team dynamics.
Good organizational capabilities and ability to work effectively with minimal supervision.
Ability to be flexible with job responsibilities and take the initiative to assume added responsibilities.
Knowledge in Semiconductor Device Physics, Fabrication, Assembly and Test is a bonus.
Good in Statistics, Probability and other Mathematical Models
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.

For US Sites Only: To request assistance with the application process and/or for reasonable accommodations, please contact Micron’s Human Resources Department at 1-800-336-8918 or 208-368-4748 and/or by completing our General Contact Form

Keywords: Hyderabad || Andhra Pradesh (IN-AP) || India (IN) || Backend Manufacturing || Experienced || Regular || Engineering || #LI-NB2 || Tier 4 ||",3.5,"Micron Technology
3.5",Hyderabad,"Boise, ID",10000+ employees,1978,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Samsung Electronics, SK hynix, Toshiba"
520,Digital - Associate Program Manager - Analytics Consultant,"About eClerx:
India’s leading process management and data analytics companies, eClerx provides critical business operations services to over fifty global Fortune 500 clients, including some of the world's leading companies across financial services, cable & telecom, retail, fashion, media & entertainment, travel & leisure, software and high-tech. A publicly traded company for 10+ years on India’s leading stock exchanges, our 9,500 employees work globally through delivery centres in India, Thailand, Italy, and US. With revenues of $200 million, eClerx is one the leading innovative business process management companies.

eClerx Digital:
The digital world is a continuously morphing landscape that is as exciting as it is limitless. And we’re here to add to its magic.

eClerx Digital is a global digital service provider partnering with the world's leading brands primarily in luxury & fashion, retail, high tech, financial services, automotive and travel industries. We deliver high impact consulting and value-based production resources to global clients looking to further their digital possibilities.

In an essence, eClerx Digital is a guild of 2500+ talented minds spread from Mumbai, Pune & Chandigarh to Verona and Phuket. Replete with a variety of strengths ranging from deep digital expertise to path-breaking support processes. We’re here to create value for our employees, customers, clients, shareholders and the world at large.

We’re looking to add to this talent pool an analytics consultant, who will help global brands make business-differentiating decisions on the back of the insight advantage.

The Ideal Experience Map:
Between 4 to 7 years of experience in advanced analytics and predictive modeling

The ideal candidate will have hands on prior experience in developing models and awareness in concepts that help define cross-sell and up-sell strategies, market segmentation, price optimization, time to event, survival analysis, churn and customer attrition, CLV [customer lifetime value] modeling, and price optimization, using tools like SAS and R.

Ideally, an attitude driven for complex project management, and an ability to display ownership and deliver data-driven projects and solutions with minimal direction.

Educational Qualifications: Preferably, Masters or a Post-graduate degree in statistics, mathematics, economics, engineering or an MBA from a reputed institute.

Roles and Responsibilities:
Display strong communication skills [written and spoken] with an ability to engage clients from the C-suite to marketing managers and understand business requirements and convert the same into technical / modeling problems for developing solutions, and deliver results in a time-bound fashion
Ability to articulate results of statistical models and complex technical concepts in business language
Demonstrate strong analytical and storytelling skills and the ability to find relevant insights from piles of reports, followed by interpretation of the analytical results, presentation and recommend next steps to client
Define project scope and deliverables that support business goals; collaborate with delivery team and analytics practice lead to deliver projects
Lead from the front by designing and developing innovative solutions to complex, challenging and first-of-its-kind problems
Create templates for reports and visual presentations
Audit deliverables to make sure that they are accurate and meet requirements by critically examining the data
Travel to client locations internationally, as per the requirements, for scoping, reviews, workshops and so on

Technical and Functional Skills:
Demonstrated knowledge of analytical and statistical techniques and their applications
Expertise on the applied statistical techniques including multi-variate regression, logistic regression, market-mix models, clustering, classification, survival, churn models and so on
Expert in handling large data, cleansing and preparation for modeling
Working knowledge of SAS, R, and / or SPSS and its respective libraries
Domain knowledge of at least one vertical amongst Retail, Cable, Technology

General skills that will boost your eligibility:
Knowledge of VBA / SQL
Knowledge of data visualization tools (Tableau, QlikView, etc.)
Prior experience in a consulting role",3.4,"Eclerx
3.4",Mumbai,"Mumbai, India",5001 to 10000 employees,2000,Company - Public,Consulting,Business Services,₹10 to ₹50 billion (INR),"Genpact, WNS, Convergys"
521,Lead Data Scientist,"About vPhrase

vPhrase helps make data easier to understand by explaining the insights in words, using AI. The company's patent pending platform, Phrazor, analyses data, derives insights and then communicates those insights, in words, in multiple languages.

Role Overview

As lead data scientist at vPhrase you would be responsible for developing, testing and maintaining our NLG engine as well as the analytical engine of our product Phrazor. These models would power analytical and decision modules of our product’s AI engine. The candidate is also expected to lead our independent applied research team.

Requirements
Phd./Masters/Bachelors in Statistics, Computer Science, Economics or a related field with at least 12 years of experience.
The candidate should have directly led an independent team of data scientists and NLP Engineers .
Proficiency making ML models work at scale in production environments. With comfort working with tools to manage large datasets.
Deep understanding of machine learning models, data analytics tools and deep learning frameworks.
Background in Natural Language Processing (NLP) and text analytics is preferred.
Ability to handle large and complex structured as-well-as unstructured datasets.
Ability to perform independent research across various domains of analytics.
Proficiency working with scripting languages like Python/R and Query languages SQL.
Experience working with B2B SaaS products in preferred.
Key Responsibility
The candidate is expected to lead the applied research team with focus on our core NLG engine.
Working closely with our product teams to power intelligence in our product.
Improving analytical engine, our domain agnostic decision models as well mining algorithms.
Managing and grooming a team of data scientists, NLP engineers and analysts.
Designing own experiments and developing new methodologies for analysis as per business goals.
Comfortable with finding possible problems, exploring different approaches and arriving at solutions that enhance our analytical modules.
Building data models and maintaining them in testing as well as production environments.
Impact

We are transforming the way people interpret data with our proprietary AI powered NLG(Natural Language Technology) engine that analyses, reasons and writes like a human being. We have filed several patents in this field and are leaders across the globe with only NLG product company in India.

Major BFSI, Health, Media organisations across the globe use our product Phrazor everyday to churn out millions of AI powered stories in real-time.

Benefits

Being part of a startup that’s turning out to be a game-changer, you will be blessed with:
A young and energetic workplace where new ideas are always welcome. The crazier, the better.
Freedom to try new things; failure is not censured.
Casual dress code
5 day work week. Yes, Sat-Sun off
No over-time, proper work-life balance
Take-it-when-you-need-it vacation
Above all, we as a team devote one day every month to volunteer for social causes close to our hearts.

Apply",-1,Meyrahkee,Pune,"Bengaluru, India",1 to 50 employees,2019,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
522,Data Science & Analytic,"Location : Delhi, NCR.

Experience :
1 to 2 years developing and implementing data analytics methodologies with good interpersonal with excellent communication skills

Technical Skills Required :
Python, Machine learning, Deep Learning, Data wrangling, Integration with Big Data Hadoop, Scoop, Impala, Hive, Pig & Spark R with Statistics, Data Wrangling, Models, Data mining, and Algorithms. Time series and forecasting, SQL, queries, Tableau Data Visualization.
Good Understanding with Hadoop, HBase, Hive, Pig, and Mapreduce, Python, R, Java, Apache spark, Impala, Hive, Pig, Machine Learning, Algorithms, Time series and forecasting, SQL, queries, Tableau Data Visualization.
Develop BigData/ Hadoop Technologies training content for Students, Working Professionals and Corporates.
Conduct online and classroom training sessions by providing practical use cases and assignments.
Design quality self-faced recorded training sessions on all latest BigData/ Hadoop development technologies for students, working professionals and corporates.
Continuously improve on teaching methodology to suite online model to lead to high student.
Work in small teams where each team member has a lot of ownership and each individual can make a big impact.
Design and make the trainees develop mini or major real time projects for practical exposure.
Work as a consultant or architect in development and training of real time BigData/ Hadoop Applications for corporates on part time or fulltime basis.

Hands on Knowledge on Tools :
Anaconda Navigator
Jupyter Notebook
Hadoop
Hive
Pig
Mapreduce
Mapreduce
Apache
Spark
Impala
SQL
Tableau",3.9,"CODEC Networks
3.9",New Delhi,"New Delhi, India",1 to 50 employees,2011,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
523,Data Science Engineer,"Overview:
Will be responsible for promoting data science topics through the local entities; helping entities in integrating data science in their organisation; industrialize data science projects focusing on production, maintenance, monitoring, availability, performance; and manage an innovative set of data science tools (Smart Data Studio), used by data scientists across the group.

Key responsibilities:
Follow and manage the engineering aspects of industrialised Data Science projects: platforms, production constraints, connections, factory compatibility
Advise and support Smart Data Studio users
Help users regarding level 2 and level 3 issues
Help users regarding industrialized data science good practices
Contribute to documentation creation and update (wikis, tutorials, …)
Contribute to tools upgrade
Support Data Science tools development and benchmarking
Help product owner and developers to define functionalities, and prioritise the Smart Data Studio roadmap
Contribute to data science tools benchmarking and evaluation
Contribute to data science tools enhancements and new functionalities

Key skills:
Must have knowledge of machine learning (scikit-learn, MLLib, vowpal wabbit), coding (Python, Scala, R), spark (Python and/or Scala), GNU/Linux, Hadoop (administration and/or development with PIG, HIVE)
Added advantage: Knowledge of H2O, Dato, Data Science challenges track record, Git, Jenkins
Passion for learning new tools, languages and frameworks
Ability to be creative and innovation-minded
Fast adaptation to changing requirements
To work with minimal direct guidance, self-motivated and proactive
Practical, hands on approach to get results
Willing and capacity to teach and transfer knowledge to the team
English - Fluent in speaking and writing
Ability to work in a multi-cultural environment
Strong oral and written communication skills
3-5 years of relevant experience
Experienced in working in an international environment and open to overseas travel",3.4,"AXA Business Services
3.4",Bengaluru,"Bengaluru, India",1001 to 5000 employees,1999,Company - Private,Insurance Operators,Insurance,Unknown / Non-Applicable,-1
524,Product Manager - Data Analysts,"The Elevator Pitch: Why will you enjoy this new opportunity?

CloudHealth by VMware is the global market leader in Cloud Cost Management and Optimization, and the most trusted software platform used to accelerate business transformation in the cloud. Youre looking for an opportunity to work for a company whose software is utilized by 350,000 enterprise and business customers (which includes 98% of Fortune 500) company and significantly impacts every industry. We are looking for a Product Manager to Interpret data, analyse results to define, build, and deliver a world-class cloud management platform used by enterprises all over the world. We value individuals with a desire to build great software products using data analytics, a passion for creating real value for customers, the ability to execute in an agile / startup environment, with a collaborative/independent spirit.

You have an analytical mind and a passion for the craft of software engineering. You want to understand how platform is being consumed by our customer , leading to understanding of market , build detailed requirements that align product solutions closely to customer needs, define phased, iterative execution of requirements, and answer questions as needed in an Agile environment. Youre excited to develop deep contextual understanding of our business, our customers, our users and their needs. You are excited to maintain deep knowledge, context, & ownership of the features/components you work on. Youre looking for a collaborative environment whose teams care about the product they are creating, how they create it, and the impact it has on customers business objectives. You are passionate to closely work with BizOps , Customer Success , UX Design function to ensure Superior customer experience sits at the center of your product requirements. Youre looking for an opportunity to be on the forefront of the cloud revolution and possess strong analytical skills and the ability to quickly ramp on new technologies in a client facing environment.

What is primary need, challenge, and/or problem you will be responsible for?

CloudHealth manages 11B USD of cloud infrastructure spend right now. Our goal is to double this. We need someone who can quickly build the context of the product, interpret data, analyze the data using statistical techniques and provide ongoing reports. You should develop and implement analytics strategies based on data to drive business goals. You should identify tools, come up with algorithms to drive efficiency. you should identify various data sets that interests customers and help customer success, partners to drive business. You as a great communicator should be able to communicate the Interpreted results with different stakeholders, executive management . You should be able to locate and define new process improvement opportunities

Success in the Role: What are the performance goals over the first 6-12 months you will work toward completing?
You will be expected to build business context, learn about our customers, understand the Cloud Health Platform.
You will be expected to learn various technologies to pull and analyze the data.
You will be expected to come out with presentations on Interpret results , driving the strategy
You will be expected to showcase a delivery of a project within the timeframe.
What type of work will you be doing? What assignments, requirements, or skills will you be performing on a regular basis?

As part of the platform team, you will:
Develop deep contextual understanding of our business, our customers, our users, and their needs
Maintain deep knowledge, context of data in platform.
Maintain context of how our platform is being consumed by Customers and partners.
Build & maintain a working understanding of the underlying architecture & designs supporting your primary areas of focus
Interlock tightly with Product Strategy function by providing the data analyses results and reports.
Work with Core Team(s) of engineers to provide market/customer context, build detailed requirements that align product solutions closely to customer needs, define phased, iterative execution of requirements, and answer questions as needed
Work closely with UX Design function to ensure superior customer experience sits at the center of your product requirements
Verify readiness of features for release to production, public beta or private beta
Work with Technical Documentation team to ensure relevant collateral is prepared to support release
The Ideal candidate has :
5+ years experience in a technology company
2+ years professional experience in a product role for a SaaS product
Experience with Amazon Web Services, Microsoft Azure, GCP or other major public cloud
Proven working experience as a data analyst or business data analyst
Technical expertise regarding data models, database design development, data mining and segmentation techniques
Strong knowledge of and experience with reporting packages (Business Objects etc), databases (SQL etc), programming (XML, Javascript, or ETL frameworks)
Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc)
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Ability to influence and work collaboratively with people in all roles/teams; technical skills that enable you to engage productively with technical teams
Ability to adapt to fast-changing nature of SaaS market, and can pivot and learn quickly
Ability to meet tight deadlines and prioritize workloads
Attention to detail and excellent listening/speaking skills
BS or BA degree, with a strong plus for computer science /engineering or Statistics
What is the leadership like for this role? What is the structure and culture of the team like?

The hiring manager for this role is Sriram Balasubramanian, Director R&D. Sriram has almost 2 decades of industry experience starting at Sun microsystems and working with VMware for the last 10 years. He has worked for CloudHealth by VMware for over 2 years. Prior to CloudHealth, Sriram led Cost management for vRealize Suite ( vROPS Costing and vRealize Business for Cloud).

Sriram currently leads our R&D Engineering team which consists of 45 engineers focused on multi-cloud financial management, platform and tactical engineering aspects of CloudHealth.

What are the benefits and perks of working at VMware?

You and your loved ones will be supported with a competitive and comprehensive benefits package. Below are some highlights, or you can view the complete benefits package by visiting www.benefits.vmware.com.
Employee Stock Purchase Plan
Medical Coverage, Retirement, and Parental Leave Plans for All Family Types
Generous Time Off Programs
40 hours of paid time to volunteer in your community
Rethink's Neurodiversity program to support parents raising children with learning or behavior challenges, or developmental disabilities
Financial contributions to your ongoing development (conference participation, trainings, course work, etc.)
Healthy and local inspired snacks in all our on-site pantries

Category : Marketing
Subcategory: Product Management
Experience: Manager and Professional
Full Time/ Part Time: Full Time
Posted Date: 2020-06-09

VMware Company Overview: At VMware, we believe that software has the power to unlock new opportunities for people and our planet. We look beyond the barriers of compromise to engineer new ways to make technologies work together seamlessly. Our cloud, mobility, and security software form a flexible, consistent digital foundation for securely delivering the apps, services and experiences that are transforming business innovation around the globe. At the core of what we do are our people who deeply value execution, passion, integrity, customers, and community. Shape whats possible today at http://careers.vmware.com.

Equal Employment Opportunity Statement: VMware is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any Kind: VMware is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at VMware are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. VMware will not tolerate discrimination or harassment based on any of these characteristics. VMware encourages applicants of all ages. Vmware will provide reasonable accommodation to employees who have protected disabilities consistent with local law.",4.3,"VMware
4.3",Bengaluru,"Palo Alto, CA",10000+ employees,1998,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),-1
525,Machine Learning Engineer (Data Science Engineer),"We are looking for Machine Learning Engineers/ Data Scientists to join our talented software team in building high performing, low latency, enterprise grade and cloud-based product suite. You will play a key role in building our innovative product pipeline. Using your deep understanding of modern web architectures and Cloud platforms, programming expertise and operational experience, you will help building successful SaaS products at Pype.

Please join our ML team and work together in breaking barriers and bringing AI to the construction software industry. Applicants should have a strong computer science background with good analytical, problem solving skills apart from good foundations in Machine learning with bent towards NLP/Image Understanding. Working proficiency with Python is mandatory. Knowledge of distributed systems like Hadoop/Spark is a plus.

Roles & Responsibilities

Formulate, code and evaluate machine learning models required for the product/application
Production deployment with required optimization, vectorization and system integration
Verification/validation and continuous integration of advanced variations
Identify/adopt feedback loops to maintain high fidelity data governance across the product portfolios

Qualifications:
Bachelor’s/Master’s degree in Computer Science or equivalent area from reputed institutes
Around 2-6 years of experience in applied or theoretical Machine learning roles in the industry or research institutes
Good grasp of Linear Algebra, Probability and Statistics
Working knowledge and inclination towards Statistical pattern recognition, Machine learning, Neural Nets, Image Processing
Experience with Python/Scikit-Learn/TensorFlow/OpenCV
Ability to work with a team in an Agile environment
To apply send your resume to hr-india@pype.io",4.0,"Pype
4.0",Bengaluru,"Herndon, VA",1 to 50 employees,2013,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
526,Data Analyst Intern,"Company Profile:

Lynkit specialises in track and trace solutions using IoT and blockchain technologies. One of Lynkit's GPS based tracking solutions has been recognized by Invest India as one of the most innovative, and its blockchain application has been featured by the Linux Foundation/ Hyperledger Global Showcase. For its cutting edge tech and innovative solutions, Lynkit has been recognized as a top start-up by Silicon India.

Lynkit has been on a fast growth track since its inception in February 2017 with rapidly expanding projects in RFID, GPS and blockchain, such as - www.lynkgrid.com, www.lynkit.io, www.lynktrac.io, www.humaratruck.com and www.pikmybox.com. We are seeking out candidates with a passion for working in a startup, high-growth environment, working in cutting-edge technologies, and making an impact.

Job Title: Data Analyst Intern

At Lynkit, we aim to incorporate data driven decision-making in every aspect of our operations. And given that we create and deploy IoT based supply chain solutions, we have a vast wealth of data to work with. As such, we are looking for passionate data science interns that will work with us and help us leverage all that data, look for underlying hidden trends, and help us make better decisions to create better products.

Location – Okhla, New Delhi

Job Description

About the Internship:

Selected intern's day-to-day responsibilities include:

· Work directly with management to prioritize business and information needs

· Interpret data, analyze results using statistical techniques and provide ongoing reports

· Establish scalable, efficient, automated processes for large scale data analyses model development, model validation and model implementation

· Acquire data from primary or secondary data sources and filter and “clean” data

· Maintain databases/data systems

· Identify, analyze, and interpret trends or patterns in complex data sets

Required Candidate Profile

· Pursuing degree in CS, statistics, mathematics or in a highly quantitative field

· Knowledge and experience with statistical packages for analyzing datasets such as Excel, R, Python etc.

· Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy

Who can apply:
Available for part-time (min. 20 hours per week commitment) or full-time internship
Have relevant skills and interests
Can start internship between 1st June'20 and 31st Aug'20
Available for a duration of 3 - 6 months
Recently graduated or are currently pursuing a degree
If interested, please share your resume to hr at lynkit.in

Job Types: Full-time, Part-time",5.0,"Lynkit
5.0",New Delhi,"New Delhi, India",1 to 50 employees,-1,Company - Public,-1,-1,Unknown / Non-Applicable,-1
527,Big Data Analyst,"TEG Analytics is committed to deliver on the promise of BIG DATA technologies and Machine Learning algorithms to solve complex business problems for our clients. The business problems range from BIG data problems to BIG-DATA problems. E.g. we are developing recommendation engines that offer the right medical plan for the right individual using vast amounts of publicly available healthcare data. We are also analyzing telematics data from thousands of tractors operating in various conditions throughout the US to predict exactly which part in which tractor is likely to fail in the next 72 hours
To meet the demands of Insights @ Speed of Business, we are in the process of re-engineering our entire Technology stack using open source which sometimes feels like a wild wild west.",3.1,"TEG Analytics
3.1",Bengaluru,"Bengaluru, India",51 to 200 employees,2008,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
528,Data Analyst,"Team Lead - CDM/PV

Qualification:
Graduate/Post Graduate/ Doctorate degree in life sciences/Pharmacy/Medical sciences/Registered Nurse

Responsibility:
Business/ Customer:
Minimal Customer interaction under guidance.
Understands Domain Process/sub process, functions, terminologies (such as SOP, QC checklists).

For PV/Complaints Management :
Individuals in this role perform data entry of data received from Source documents into the respective Clinical/Safety database While peroforming this activity the associate is responsible for meeting turnaround times and accuracy.
These associates are usually used to handle more critical/senitive transactions.
These associates also act as Subject Matter Expert.

CODING:
Perform coding activities on the assigned project with timelines and efficiency
Import uncoded terms in database and export coded medical terms from coding platform.
Query Management.
Create “New Term Request” and prioritize.
Perform Dictionary upversioning activity.
Send Coding (Consistency) Reports.
Participate in study related meetings as needed.
Provide feedback on quality related issues to other medical coders in timely manner.
Serve as an SME to Medical Reviewers regarding coding activities & guidelines.
Perform UAT for coding related applications.
Perform Operational QC.
Mentor Team Member.
Coordinate with CDM working on the same study.
Coordinate to resolve Rave specific issues.
CDM:
1 Execute Data Management Activities ie Data Cleaning, Executing Manual and System checks, Update relevant trackers, Discrepancy and query management, Issue resolution, Database lock activities.
2 Participate in innovation and process improvement initiatives.
3 Identify and develop action plan in coordination with the TL for activities not meeting the client SLAs.
4 Archive all necessary information for audit purposes according to quality and security requirements, to ensure reliable and timely retrieval of documentation and information.
5 Support multiple clinical trials, across diverse therapeutic areas, to successful conclusion and provide technical oversight when required.

Project / Process:
Attempts Complex problems (procedures/processes) and refers to Supervisor/Line Manager in rare cases.
Handle first level processing of transactions.
Adhere to quality requirements, achieve targets/volumes in given TAT(Turn around time).
Proactively identify issues.
Contribute to process improvement initiatives.
Identify and report process changes.
Adhere to the mandatory industry regulation and compliance requirements for the given process.

Knowledge Management:
Update Process documentation as appropriate for the process under guidance.
Participate in knowledge transfer.

People/Team Management:
Adhere to org hygiene and compliance needs in terms of.
a Personal Utilization & Time sheet submission.
b Personal and new hire Assimilation.
c Attendance.
d Team Initiatives.
Collate team performance metrics.
Manage break schedule/transport logistics for the team in the absence of his/her supervisor.

Must Have Skills

Customer Service
COTS Products(LS Mfg&SC)

Employee Status : Full Time Employee

Shift : Day Job

Travel : No

Job Posting : Apr 14 2020

About Cognizant

Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 193 on the Fortune 500 and is consistently listed among the most admired companies in the world.",3.7,"Cognizant
3.7",Mumbai,"Teaneck, NJ",10000+ employees,1994,Company - Public,-1,-1,₹500+ billion (INR),"Tata Consultancy Services, Accenture, Capgemini"
529,Data Engineer,"Position Title
Data Engineer

14-May-2020

Job ID
285126BR

Job Description
Purpose of the role is to build is to design and build solutions to ingest data from variety of sources in to Data and Analytics platforms at Alcon. As part of the Analytics team, work closely with Business stakeholders to understand Analytics needs, create, support or enhance Analytics products that align with Alcon’s Data and Analytics strategy and standards.

•As part of the Analytics sprint team before data engineering to ingest data from various sources into data lake solution on AWS Cloud as per the roadmap •Deliver business solution on Alcon’s analytics platform through end-to-end implementation that includes data security, governance, cataloging, preparation, automated testing, and data quality metrics. •Contribute towards building high performing platform/product DevOps agile teams •Automate, optimize, migrate and enhance existing solutions. •Perform data modeling, data analysis and providing insights using various tools.

Minimum requirements
Bachelor’s degree or equivalent years of applicable experience The ability to fluently read, write, understand and communicate in English. 5+ years of applicable experience in Data Warehousing and BI Solutions. 3+ years of experience in writing code in spark engine using python, scala or java

Job Type
Full Time

Country
India

Work Location
Bangalore

Functional Area
Information Technology

Division
ALCON

Business Unit
NON-NVS AL INFORMATION TECHNOLOGY

Employment Type
Regular

Company/Legal Entity
Alcon Ind",3.6,"Alcon
3.6",Bengaluru,"Fort Worth, TX",10000+ employees,1945,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),Allergan
530,Supervisor - Data Sciences and Advanced Analytics,"Job Description (Supervisor - Data Sciences and Advanced Analytics)

The Advanced Analytics and Data Sciences team is seeking a supervisor to lead a team of data scientists who loves working on complex problems and getting things done. The ideal candidate combines excellent business acumen and communication skills with outstanding analytical skills. If you are detail-oriented, enjoy solving complex data challenges, and are passionate about data, we want to hear from you. As a Senior member of the team you will work with data analysts, managers and engineers to: resolve ambiguity with data, play a crucial role in the iteration and optimization of software solutions, and support data-driven decision-making across the organization. You'll be working directly with an experienced (and fun) team of brilliant people in a dynamic environment to grow a new business that is revolutionizing the cloud computing world.

Responsibilities:
The Candidate would be tasked with solving a real-life business problem that requires processing/analysing TBs of data and handling variety of data sources
The work is organized as a project with clear deliverable and timeline
The Candidate would collaborate with other team members who would provide support and mentoring
The Candidate would proactively investigate, report, and where possible, address data quality issues
Track and manage daily proforma volumes; ensure sufficient cover provided across teams
People Management: hold regular one-to-one discussions with your direct reports, manage performance, provide mentoring and development support, assist with hiring and onboarding process
Assist with queries and escalations from team and other groups, acting as SME in various areas
Support the successful execution of Quarter-ends activities
Participate in projects and organizational initiatives to improve and streamline processes
Provide suggestions and ideas that enhance processes, partner experience and simplicity of operations
Deliver on ad-hoc assignments as business requires
Technical Skills:
Overall 5+ years of experience in advanced analytics and leading/mentoring team members
Proficient in either R/Python and SQL with minimum 2-3 years of hands on experience
Strong conceptual understanding of machine learning algorithms including linear regression, logistic regression, decision tree, random forest, topic models etc
Ability to work and execute projects on both structured and unstructured data in a big data environment
Experience of end to end implementation of predictive analytics projects for at least 1-3 years
Exposure to visualization tools
Experience of intent to learn software domain related to VMware products and the way virtualization software/hardware
Preferred Skills:
Business Acumen, ability to translate business needs into a set of workable, specific requirements
Well versed with MS PowerPoint/Visio
Ability to understand business requirements, KPIs and convert into analytical hypothesis in a structured and logical manner along with solution identification
Ability to handle multiple projects at a time in terms of multitasking, prioritization, allocation and team management
Ability to coordinate and work with in a multiple business unit from project management perspective
Ability to work across geographies and interact with global stakeholders
Prior experience working in Agile methodologies/JIRA would be a plus
Strong People Management skills
Understanding upstream and downstream processes
Ability and motivation to work efficiently and productively in a multi-task environment and with minimal direction
Ability to identify and analyse problems using sound judgment and determine solutions in order to effectively resolve issues
Strong task management and prioritization capabilities
Ability to initiate process improvement plans and work towards change
Flexible to changing priorities and to work outside of office hours as per business requirements.
Excellent written and verbal communication skills and interpersonal skills
Strong work ethic and sense of responsibility
What we are looking for:
BS/BE in Computer Sciences, Math, Statistics or related field. MBA preferred.
Proficient in SQL and experience with efficient processing of large data sets. Ability to write sophisticated and optimized queries against large databases
Proficient in data visualization tools such as Mode Analytics or Tableau
Proficient in Excel
Experience in statistical computing with Python/R
Ability to handle several concurrent activities with strong organizational skills and attention to detail
We're team players. You'll do well if you're one too.
Category : Engineering and Technology
Subcategory: Information Systems
Experience: Manager and Professional
Full Time/ Part Time: Full Time
Posted Date: 2020-06-09

VMware Company Overview: At VMware, we believe that software has the power to unlock new opportunities for people and our planet. We look beyond the barriers of compromise to engineer new ways to make technologies work together seamlessly. Our cloud, mobility, and security software form a flexible, consistent digital foundation for securely delivering the apps, services and experiences that are transforming business innovation around the globe. At the core of what we do are our people who deeply value execution, passion, integrity, customers, and community. Shape whats possible today at http://careers.vmware.com.

Equal Employment Opportunity Statement: VMware is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any Kind: VMware is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at VMware are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. VMware will not tolerate discrimination or harassment based on any of these characteristics. VMware encourages applicants of all ages. Vmware will provide reasonable accommodation to employees who have protected disabilities consistent with local law.",4.3,"VMware
4.3",Bengaluru,"Palo Alto, CA",10000+ employees,1998,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),-1
531,Data Analyst,"Job Overview
Search and Identify Companies and Decision Makers who are looking for Software developers (software vendors) from the US, UK.
Source and Verify contact details of such prospects and create excel databases.
Proficient in gathering contact data including phone numbers & emails for companies and/or their decision makers.
Proficient in Social media lead generation such as- LinkedIn, Factiva, Google, Yahoo, inside view etc.
Minimum Qualifications
Proven working experience as a data analyst.
Technical expertise regarding data models, database sources & data mining.
Adept at queries, report writing and presenting findings.
Expertise in B2B data mining.
Responsibilities
Interpret data, analyze results using statistical techniques and provide data on regular basis.
Develop and implement data collection systems and other strategies that optimize statistical efficiency and data quality.
Acquire data from primary or secondary data sources and maintain databases in CRM.
Locate and define new process improvement opportunities for data mining.
To be considered for this role, send your application, CV and earliest possible start date to career@credencys.com",3.4,"Credencys Solutions
3.4",India,"La Palma, CA",51 to 200 employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
532,Junior Data Analyst,"Key Requirements:
Engineering, Bachelor’s degree (Computer Science/IT) or MCA is a must
1-2 years of experience in Digital Marketing, fresh graduates are welcome
Strong communication, analytical, data-mining
Data Management – Data cleansing, and data enrichment techniques using Database Querying language like SQL
Scripting and statistical analysis platform – R, Python, SAS, etc
Visualization tools: Tableau, Power BI, Qlikview, etc
Good communication and Analysing skills
Roles and Responsibilities:
Work on exciting projects with Google Analytics & Digital Marketing/Measurement. Implementation with some of the largest brands in South-East Asia
Own the analysis of highly complex data sources, identifying trends and patterns in data and make recommendations based on analysis results
Perform root cause analysis on complex data anomalies and working closely data stewards to define best practice
Analyze data and generate insights in form of revenue/growth prediction, trends and anomalies, customer segmentation, DAU/MAU reports, conversion optimization, monthly reports, etc.
Experience working with Google Cloud Platform is a plus
Work closely with the Client Success team to drive delivery and engagement
What will make you stand out?
Where others see chaos, you see a solution
Strong foundation of digital marketing
A go-getter and the get-shit-done attitude",4.4,"Happy Marketer
4.4",Bengaluru,"Singapore, Singapore",1 to 50 employees,2009,Company - Private,Advertising & Marketing,Business Services,₹500 million to ₹1 billion (INR),-1
533,Data Science Intern,"Note: Its not work from home internship, If selected candidate must come to office
Roles and Responsibilities
1. Create a web application using Python, HTML, CSS, Bootstrap
2. Analyze data sets, finding patterns/trends and forecasting
3. Run machine learning algorithms, predict and classify data
4. Working on data science algorithms and AI concepts
5. Report results and compare them with real-time data
6. Work on solving complex problems using creative and innovative ideas
7. Work with the team to manage, optimize and customize multiple web applications
8. Maintain existing code with bugs resolution
9. Work on time series database
Preferred Skills and Qualifications
Python, R, SQL, HTML, CSS, Bootstrap, JSON/ XML, Data Science, deep learning, Machine learning
Duration of Internship - 2 months
Benefits
1.Certificate
2.Letter of recommendation
3.Informal dress code
4.5 days a week
5.Learn new things and enhance your knowledge
Stipend: Unpaid
Job Type: Internship
Experience:
work: 1 year (Preferred)
Education:
Bachelor's (Preferred)
Location:
Pune, Maharashtra (Required)
Work Remotely:
No",5.0,"UpTricks
5.0",Pune,"Pune, India",1 to 50 employees,2013,Self-employed,IT Services,Information Technology,₹500 million to ₹1 billion (INR),-1
534,Data Analysts,"Profile Required

Technical Skills:
Design, build, integrate data from various resources.
Data management expertise in defining Metadata, Quality and Lineage for critical data elements.
Expertise in tools that are used in Data Analytics. (Advanced Excel, Power BI, Business Objects, SQL)

Education:
Graduate in computer science or in finance. Certification courses in Data Science, ML/AI tools
Experience:
5+ years of experience, particularly in the banking business lines, risk or finance, credit risk business lines. The knowledge
Business Knowledge:
Experience working with Global Banks in their Risk & finance function.
Good understanding of the Wholesale/Retail banking focusing on Credit & Market portfolio of the bank and the risk governing the business.
Thorough knowledge on the functional and technical architecture of the information systems applicative to Credit data.
Good understanding on the Banking Standards & regulations pertaining Banking Data (BCBS239, GDPR)

Why Join Us

We are committed to creating a diverse environment and are proud to be an equal opportunity employer. All qualified applicants receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.

Business Insight

Context:

The Digital and Transformation Office (DTO) is an important transversal partner within the Risk division (second line of defense of the bank), providing oversight for transformation projects, simplifying processes and ensuring data quality.

Data management office (DMO) is one of the critical functions of DTO aiming at managing the data that is used by Risk analyst/experts and management for quantitative analysis and decision making.

DMO comprise Data Analysts who are responsible to identify the Data quality issues from upstream systems/databases, report those anomalies, perform root cause analysis (as per materiality), develop remediation plan along with IT teams & monitoring of the resolution through status dashboard.",3.5,"Société Générale
3.5",Bengaluru,"Paris, France",10000+ employees,1864,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"BNP Paribas, Natixis, Calyon Securities USA"
535,Data Analysts,"Senior Data Engineer for Technology (India)

No. of Positions: 1

Are you a high-energy thought leader with a passion for technology innovation? Are you an adaptable self-starter with strong communication skills? Are you willing to teach and coach others as well as continuously learn and grow in your own career?

We are recruiting for a hands-on leader who can inspire others and easily adapt to our dynamic marketplace, mentoring our young engineers and collaborating with other leaders in the business, in India and Australia.

About Rubicon Red: We believe digital technology provides the catalyst to reimagine what’s possible and continuously innovate to transform businesses. We are a boutique provider of custom cloud solutions and specialize in enterprise connectivity and intelligent automation, fundamental to achieving effortless digital experience. Our mission is to help our customers ‘cross the Rubicon’ by transforming the way digital solutions are delivered, to achieve rapid results through continuous innovation in a low risk and cost-effective way.

Rubicon Red is committed to our customer’s success, and to this end, we live by our Brand Promise of Innovation Leadership, Lean Delivery, and Effortless Partnership.

To be successful in this role, you will have:
At least 4+ years of experience in the Data Engineering domain
Extensive hands-on exposure to popular ETL tools such as Informatica, ODI, Pentaho, etc.
Extensive programming knowledge in Python or equivalent language
Good hands-on experience with Hadoop frameworks such as Spark, Hive, Hbase, Ganglia, Zeppelin.
Diverse experience working with various kinds of data sets such as structured, semi-structured and unstructured with file formats such as Parquet and ORC.
Expert knowledge in SQL and associated variants such as Spark SQL, PL / SQL, etc.
Decent understanding of modern data platforms such as data lakes, data warehouses, data marts, etc.
Deep knowledge in building data pipelines for cleansing, processing, curating and aggregating large data sets in the order of GBs and TBs
Decent exposure to at least one BI analytics tool such as Power BI, Tableau
Strong data modeling knowledge with an awareness of dimensional modeling techniques
Excellent communication and client representation skills
Knowledge in AWS data platform technologies such as S3, Glue, Athena, EMR is an added advantage
Knowledge in Data Warehouses such as Snowflake and Redshift is an added advantage",4.2,"Société Générale
3.5",Bengaluru,"Brisbane, Australia",51 to 200 employees,-1,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,-1
536,Chief Data Scientist.,"Job Purpose:
Provides deep technical Big Data and Machine Learning expertise to business vertical across the organization, governing the technical and methodology approach to solving Business Problems using Machine Learning.

Key Result Areas/Accountabilities:
This roll will be influencing and driving best practices to all the functions via vertical lead data scientists.
The person in the roll is expected to look at state of the art research available in the ML domain, and conduct pilots, before they are adopted by the verticals.
Will be the guardian of best practices, and help design interventions or process, that enable the teams to build robust scalable models for solving business problems.
Establish governance mechanisms, to ensure repeatable performance, and constantly oversee the quality of ML solutions built by the teams.
The person is expected to work on the difficult / challenging problems that has very high impact on business.
Develop workflows to process data and develop models for a problem, and ensure thatsuch workflows and learnt models are transferrable to other problems that are similar innature
Excellent credentials in working as a team or self-motivated individual contributorwilling to collaborate with colleagues locally and globally.
Core Competencies, Knowledge, Experience:
Working in Big Data analytics & deployment of models and algorithms from large volumes of structured and unstructured data in a commercial /consumer environment.
Turning complex (structured / unstructured /image / Voice) datasets into strategic insights for the business and communicate simply to non-technical audiences, visualizing results.
Developing Machine Learning solutions to solve real business problems, taking account of user needs, technology and operational landscape
Recognized as an expert in the community, mentoring and advising others on statistical techniques, algorithms and data sources
Hands On in Application of Big Data modeling and visualization tools (e.g. Hadoop, Spark, Python, D3.js, CartoDB, SciPy, GIS, NLTK, MLlib)
Experience on Machine Learning on Public Cloud platforms ( AWS / Microsoft, Google)
Experience in Deep Learning Frameworks Tensor flow, open-source libraries, e.g., Keras, and open-source distributed computing frameworks
Deep Expertise in Recommendation Engines, using data at petabyte scale.
Ability to test hypotheses from raw data sets, draw meaningful conclusions, and clearly communicate results
Expert in deep and broad statistical modelling
Familiarity with applications of deep learning, computer vision, and generalized artificial intelligence (e.g., convolutional neural networks, adversarial neural networks), to solving business problems
Ability to work cross functionally to translate business issues into potential analytics solutions
Strong communication skills with prior experience communicating analytics results to senior management
Ability to think critically, question assumptions and devise solutions to challenging technical problems.
Experience with very large datasets
Knowledge of applicable data privacy practices and laws
Experience in end-to-end development of the data science processes experimentation, segmentation and documentation.
Strong verbal and written communication skills.
Strong decision-making skills
Ability to accurately and effectively tell the story told by the data
Attention to detail, excellent organizational, planning and analytical skills.
Extensive knowledge attribution tracking technology or platforms
Highly analytical mindset, with the ability to interpret performance data
A drive to be updated as well as master new technologies and techniques, apply it for solving business problems.",-1,MAESTRO PLACEMENT CONSULTANCY SERVICES,Mumbai,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
537,Senior Data Scientist,"Extensive experience working with large complex data sets and big data platforms
Proficiency in programming in Python, R, SQL and familiarity with REST based API’s
Strong understanding of feature extraction and data cleansing
Strong background in applying statistical machine learning techniques to predictive modelling and experience with Machine Learning libraries (Python, R)
Strong written and communication skills",-1,Intellithink,Chennai,"Chennai, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
538,Lead Data Scientist,"Responsibilities

Lead & mentor the data analysts and data scientists to achieve business goals of BigTapp and its customers
Responsible for leading the development, validation and delivery of algorithms, statistical models and business analysis
Develops algorithms and statistical predictive models and determines analytical approaches and modeling techniques to evaluate scenarios and potential future outcomes
Lead and coach Data Science team members with latest machine learning algorithms including decision trees, probability networks, association rules, clustering, regression, and neural networks
Establish scalable, efficient, automated processes for large scale data analysis, model development, model validation, model implementation and model ops
Provide thought-leadership and dependable execution on diverse projects
Identify emergent trends and opportunities for future client growth and development

Education and Experience Requirement

Experience: 5 to 8 years’ experience in data sciences and should have handled a team of data engineers, analysts and scientists

Proven experience in:
Developing actionable insights and recommendations for business leaders
Presenting results and recommendations to non-technical business audience to drive the decision-making process
Deployed data science solutions with proven business benefits
Should have an educational background in statistics/data sciences/actuarial sciences. PhD will be an added advantage
Innovative and strong analytical and algorithmic problem solvers
Proficiency with open source analytical tools and one or more of Data Science Platforms (AWS Sagemaker/ Azure ML/ H2O.AI etc)
Subject Matter Expertise in effective machine learning tools and technologies including Tensorflow, Spark / Spark MLib, Flink, Mahout or any packaged cognitive solutions
Database programming in SQL
Proficiency with software development technologies (e.g. Python, Java)
Excellent critical thinking skills, combined with the ability to present your beliefs clearly and compellingly verbally and in written form
Domain expertise in any one or more of the following domains: Insurance, Banking, Manufacturing, Retail & FMCG
Experience and familiarity with common business use cases of analytics

Good To Have:
Experience with big data tools (e.g., Hadoop, HDFS, Cassandra, Storm)
Programming in NOSQL environments
Experience at data visualization and presentation using tools like Tableau, Qlik Sense & Power BI
Expertise in unstructured analytics: NLP, Computer Vision and Audio Analytics
Expertise in web scraping

Salary: Commensurate with experience and demonstrated competence
Contact: [email protected]",3.2,"BigTapp
3.2",Chennai,"Singapore, Singapore",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
539,Data Analyst,"Job Location
Hyderabad (SAL) ININD, Bangalore, KA
Job Posting Title
Data Analyst
The Challenge
Summary:

Systems Analyst is responsible for designing, developing and implementing enterprise-wide reporting and analytics solutions across the business processes such as manufacturing, supply chain and distribution, sales, and financials. The primary reporting platforms are Oracle Business Intelligence Applications (OBIA), Oracle Endeca Information discovery and Advanced planning command center, with OBIEE as the presentation layer and Oracle data integrator as the ETL tool. Functional knowledge of one of the enterprise processes Supply Chain, Order ship bill or Finance is desired.
What you will Do


Role Responsibilities:
System Analyst interacts with business users to understand the requirement and partner with various ERP+ teams. They are responsible for design, extend, customize ETL modules and develop technical solution components including interactive dashboards, Scorecards, adhoc queries, KPIs and reports independently. They are the point of contacts for their solutions and ensure that requirements are clear/executable, that solutions are built to technical standards and meet customer needs, and that solutions get built and launched per project schedules. Additionally, Systems Analyst is responsible for migrating solutions to support the project schedules and documenting the solutions after production launches. Systems Analyst participates in design discussions, generate design alternatives, provide development time estimates, and build solutions that match the given solution specifications. Systems analyst develops solutions independently or in collaboration with other team members for larger projects, and in both cases should ensure that solutions are built efficiently and with very high quality.
Key Role Responsibilities:
~ Interact directly with business users to understand the reporting requirements
~ Translate the business requirements to OBIA or Endeca reporting solutions
~ Document the design in the form of High level and low level designs
~ Understand ETL concepts and develop interfaces/mappings within ODI
~ Conduct performance analysis and optimize OBIEE reports and repository
~ Code, unit test, implement and support enterprise reporting solutions.
~ Provide accurate build estimates and timely development status updates.
~ Ensure solutions meet standards, get built on time
~ Follow OBIA development methodology, unit testing, documentation migration standards.
~ Obtain required sign-offs at each phase and own assigned solutions from start to finish.
~ Facilitate successful production launches

What you need to Succeed


Experience:
3+ IT experience, preferably in Business Intelligence area along with Bachelors in computer science or relevant field

Attributes:
• Strong verbal and written communication skills
• Collaborate with cross functional teams
• Independently interact with global business users
• Owns customer's experience and takes stake in customer's success
• Committed to helping customer win
• Listens to understand and challenges assumptions
• Thinks outside the box. Takes risks

GE Appliances is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law.",3.9,"GE Appliances
3.9",Hyderabad,"Louisville, KY",10000+ employees,2016,Subsidiary or Business Segment,Consumer Products Manufacturing,Manufacturing,₹500+ billion (INR),"Whirlpool Corporation, Electrolux, LG Electronics"
540,Data Analyst,"The Applications Development Senior Programmer Analyst is an intermediate level position responsible for participation in the establishment and implementation of new or revised application systems and programs in coordination with the Technology team. The overall objective of this role is to contribute to applications systems analysis and programming activities.

Responsibilities:
Conduct tasks related to feasibility studies, time and cost estimates, IT planning, risk technology, applications development, model development, and establish and implement new or revised applications systems and programs to meet specific business needs or user areas
Monitor and control all phases of development process and analysis, design, construction, testing, and implementation as well as provide user and operational support on applications to business users
Utilize in-depth specialty knowledge of applications development to analyze complex problems/issues, provide evaluation of business process, system process, and industry standards, and make evaluative judgement
Recommend and develop security measures in post implementation analysis of business usage to ensure successful system design and functionality
Consult with users/clients and other technology groups on issues, recommend advanced programming solutions, and install and assist customer exposure systems
Ensure essential procedures are followed and help define operating standards and processes
Serve as advisor or coach to new or lower level analysts
Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency.
Qualifications:
5-8 years of relevant experience
Experience in systems analysis and programming of software applications
Experience in managing and implementing successful projects
Working knowledge of consulting/project management techniques/methods
Ability to work under pressure and manage deadlines or unexpected changes in expectations or requirements
Education:
Bachelors degree/University degree or equivalent experience
This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required.
Experience in Equities Trading Flows, proficient cross- equities domain knowledge
Strong SQL experience, programming skills specific to data analysis and adhoc data extraction
Solid understanding of FIX/ FpML Knowledge of security, market data and reference data
Experience in client facing business management roles. Experience on running workshops with business and technology stakeholders
Proven Track record as business analyst performing requirements definition, functional design, preparation of test scripts, and implementation;
Preferable -Experience in message oriented/message driven applications and architectures
Excellent analytical and process-based skills, i.e. process flow diagrams, business modelling, and functional design;
Experience in order management systems
Familiarity with Listed Derivatives, Future/Options will be a plus
Proficient in using MS Excel to manipulate data and derive conclusions
Ability to own delivery/reported issues to completion.
Right attitude to gel well with the technology team locally/globally
The candidate should have the ability to work on multiple projects at any given time
Awareness of Project Management tools such as MS Project, Collabnet (Team forge)
Willingness to work in fast moving environment and deliver solid technical solutions
Desirable skills Development /coding experience with Python/R/Machine Learning.
-------------------------------------------------

Grade :All Job Level - All Job FunctionsAll Job Level - All Job Functions - IN

------------------------------------------------------

Time Type :

------------------------------------------------------

Citi is an equal opportunity and affirmative action employer.
Minority/Female/Veteran/Individuals with Disabilities/Sexual Orientation/Gender Identity.

Citigroup Inc. and its subsidiaries (""Citi) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity CLICK HERE.

To view the ""EEO is the Law"" poster CLICK HERE. To view the EEO is the Law Supplement CLICK HERE.
To view the EEO Policy Statement CLICK HERE.
To view the Pay Transparency Posting CLICK HERE.",3.7,"Citi
3.7",Pune,"New York, NY",10000+ employees,1812,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
541,Data Engineer,"Neustar is an information services and technology company and a leader in identity resolution providing the data and technology that enables trusted connections between companies and people at the moments that matter most. More information is available at https://www.home.neustar.

Job Requisition:

R-2927 Data Engineer (Open)

Primary Location:

BANGALORE

Job Description:

Data Engineer

Fueled by start-up energy, Neustar was literally born to manage large datasets. As the original administrator of the North American Numbering Plan (NANP), we were hip to big data long before it was cool. In managing this massive database of phone numbers, we learned the power of being a neutral steward of data by giving competing telephone companies equal access to everybody’s digits. In the following years, we built upon this foundation of data expertise.

As the first real-time provider of cloud-based information services and data analytics, we enable marketing and IT security professionals to promote and protect their businesses. With a commitment to privacy and neutrality, Neustar operates complex data registries and uses its expertise to deliver actionable, data-driven insights that help clients make high-value business decisions in real time, one customer interaction at a time. Our vision is to be the single most trusted source of commercial insight and analysis for our Clients.

More information is available at www.neustar.biz.

Neustar is a place where the entrepreneurial spirit is strong. We embrace innovation and encourage the development of bold new ideas. This is deeply rooted in our culture and comes through in everything we do. Our world-class technology, innovative solutions and experienced employee base have been catalysts for customer success for more than a decade – infusing voice, video and data transactions with true innovation and unparalleled performance.

Description

We’re looking for someone who wants the challenge of working on implementing solutions for on boarding large volumes of data feeding into the front end application.

Responsibilities/Key Tasks
Play a key role in end to end data on boarding and in creating a data pipeline for the end application.
In depth analysis of source data to provide insights for data mapping & business rules setup.
Develop , code & implement the data pipeline
Work closely with technical product managers, solution architects and other internal stakeholders to address issues in data pipeline and to make sure data is ingested accurately and on time.
Assist and shadow rest of the team members and accomplish the tasks in a timely manner
Work in a high paced and rewarding environment with bleeding edge technologies and innovative concepts
Qualifications/Educational Requirements
Bachelor’s Degree, with 3 - 5 years related IT experience.
Adept at data pre-processing & complex data transformations using Hive programming.
Experience in working with HiveQL and performance tuning of Hive queries.
Extensive experience on distributed systems frameworks like Hadoop including hands on experience on HDFS, MapReduce etc.
Proficient in working with large scale multi-node clusters with technologies like HDFS/ Hive etc.
Excellent SQL skills and in-depth understanding of relational databases.
Adept at working on UNIX environments and exposure to shell scripting.
Knowledge of database design principles like OLAP, OLTP and ETL.
Excellent understanding of Oracle and MySql relation databases.
Experience in Python and Java will be an advantage.
Familiarity with big data platforms like Qubole/AWS will be an advantage.
Experience in working with cloud based services like AWS.
Work with an innovative bend of mind to develop creative solutions for data on boarding
Interpersonal Skills
""Self-starter"" attitude
Ability to work closely with fellow Developers and Managers to understand requirements
An effective communicator, able to clearly articulate; clear, succinct and persuasive at all levels
Good written skills
Job Qualifications: (professional and/or technical certifications, education)
BE/B.TECH degree in Computer Science or equivalent
ME/M.TECH degree in Computer Science or equivalent
Neustar does not accept unsolicited resumes from external firms or agencies. Neustar will not be responsible for placement fees associated with unsolicited resumes.

DIVERSITY
Diversity, inclusion and teamwork are second nature to Neustar; and these values permeate our entire business structure. Neustar is committed to creating an environment where a wide spectrum of opinions and beliefs are actively sought, listened to and respected. Further, our talented workforce draws from the many geographic areas and markets in which Neustar operates worldwide, which represents a distinct competitive advantage. The rich and varied personal and professional backgrounds of our employees make Neustar a dynamic and rewarding company at which to build a career. We invite you to join us.

EOE of Minorities/Females/Vets/Disability
Neustar, Inc. considers all applicants for employment without regard to race, color, religion, sex, national origin, age, disability, sexual orientation, or status as a Vietnam-era or special disabled veteran in accordance with federal law and other state and local requirements. Neustar, Inc., complies with applicable state and local laws prohibiting discrimination in employment and provides reasonable accommodation to qualified individuals with disabilities in accordance with the American with Disabilities Act (ADA) and applicable state and local laws.",3.7,"Neustar
3.7",Bengaluru,"Sterling, VA",1001 to 5000 employees,1996,Company - Private,Internet,Information Technology,₹50 to ₹100 billion (INR),"Adobe, Akamai, Oracle"
542,Senior Lead - Data Scientist,"Job Description:


JOB TITLE

Senior Data Scientist

Fidelity Workplace Investing is seeking a Senior Data Science Practice Lead with extensive experience in Natural Language Processing (NLP), integrating Computational Linguistics, modern Deep Learning, and Computer Vision technologies.

This position will be based full time in Bangalore, KAR.

The Purpose of This Role

Fidelity Workplace Investing is seeking a top level NLP data scientist to join the Workplace Investing AI and Data Science Center of Excellence (CoE). Our CoE is a team of data scientists in the US and India employing a wide array of AI and data science techniques such as NLP, deep learning, machine learning, causal inference, predictive analytics, experimental design, and optimization to solve a wide variety of business problems ranging from business-to-consumer (B2C), business-to-business (B2B), to quality control, operations management, and automation.

This talented professional will collaborate closely with data engineers, data experts, quality engineers, and business stakeholders to solve challenging text analytics problems with innovative solutions. Candidate must be comfortable in a fast-paced, unpredictable and sometimes ambiguous environment working with current and emerging AI technologies. In addition to AI and NLP applications, the assignments will include providing analytic consulting to the business, identifying and gathering complex data from multiple sources, conducting experiments to test algorithms, monitoring model performance, interpretation of findings, business presentation to senior management, and guiding and training technical and non-technical audience.

The Value You Deliver
Build data science applications from inception to installation
Work on interdisciplinary teams, whose members will be data scientists, software developers, and data engineers
Design and build NLP models
Present project updates to both technical and business stakeholders
The Skills that are Key to this role
You need to demonstrate Advanced knowledge of Natural Language Processing, Computational Linguistics, Computer Vision, Optical Character Recognition (OCR), Machine Learning, Representation Learning, Autoencoder, and Deep Learning algorithms for unstructured data analysis including advanced applications of CNN, RNN, LSTM, GRU, ULMFiT, ELMO, ERNIE, BERT, RoBERTa, ALBERT, etc.
You need to have Knowledge of at least some of the following fields: Knowledge Graph, Reinforcement Learning, Question Answering/Conversational AI, Bayesian Analysis, and Design of Experiment
Your Expertise in computational tools and environment such as PyTorch, Keras, TensorFlow, SageMaker, and GPU Programming
You need to be able to translate research findings as well as quantitative analyses into accessible visuals for non-technical audiences, providing a clear view into interpreting data, and crisply communicating recommendations
You need to bring passion to your work and operate with a sense of purpose that inspires and motivates those you work with
You are expected to be intellectually curious, take initiative, and love learning new skills and capabilities
How Your Work Impacts the Organization

WI AI CoE is a team of data scientists in the US and India employing a wide array of AI and data science techniques such as NLP, deep learning, machine learning, causal inference, predictive analytics, experimental design, and optimization to solve a wide variety of workplace investing business problems ranging from business-to-consumer (B2C), business-to-business (B2B), to quality control, operations management, and Intelligent automation.

The Expertise Were Looking For
M.S/PhD in Computer Science (or equivalent) with extensive research papers on Natural Language Processing or similar discipline with 4-8 years relevant professional or research experience
Deep understanding with proven published research in the field of Natural Language Processing such as Information Extraction, Ontology, Machine Comprehension, Word Embedding, Information Retrieval, Attention Mechanism, and Transformers
External publications and presentations in your resume is a plus in the field of ML/DL/NLP/CV
Location : Bangalore - EGL

Shift timings: 11:00 am - 8:00pm

Certifications:
Category:
Business Analytics and Insights",4.0,"Fidelity Investments
4.0",Bengaluru,"Boston, MA",10000+ employees,1946,Company - Private,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Charles Schwab, Vanguard, Citi"
543,Data Science AI ML NLP Consultant,"“AI-ML-NLP-0519”

For one of our prestigious multinational clients, we are looking for AI/ML/NLP Professionals for immediate hiring. Our client is an established name in the space of software development and consultancy. This position is based at Gurgaon – Delhi NCR, India.

WHAT IS IN IT FOR YOU?

The company is known for software consulting services and is a respected name in the software industry. You will get to work in a very energetic environment with lot of dynamism. They cater to mainly US customers, and provide their services through onsite/offshore model. The work environment is conducive to innovation, and provides continuous growth opportunities.

JOB DESCRIPTION

Work on Data Science projects in the area of NLP, ML, and Cognitive analysis.

Key Responsibilities:
Understand Customer Problem and Data Requirements.
Translate Customer requirements into a Data Science Problem.
Propose a Data Science solution which may involve use of Machine Learning (Supervised & Unsupervised) and other algorithmic models
Prepare Data followed by Model development
Model Testing and Deployment
Qualifications and skills:
Engineering Degree is a MUST
2 to 4 years experience in AI/ML/NLP/Cognitive Analysis
Coding of Machine Learning models in R and/or Python language
Experience in extracting data from a variety of data sources
Proven expertise in analyzing & visualizing data
Experience in deploying on AWS, Google Cloud Platform or - Microsoft Azure will be preferred.
Quick learner of newer models, libraries and modeling techniques
Excellent communication and presentation skills
About the client

Our client is an established Software development and consultancy organization with its headquarters in US. They are a respected name in Insurance and Healthcare software and services. They have a large spectrum of customers all over US, and have development centers in India. They believe in hiring smart people and giving them a chance to grow at a rapid pace.

Come, be part of a winning team.",3.9,"ChampionsIT
3.9",Gurgaon,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
544,ANALYST-DATA SCIENCE-PYTHON,"Apply machine learning techniques to deliver actionable insights from large-scale, multi-structured datasets. Work with internal and external teams to develop models (ranging from data exploration to feature engineering and model development to validation and scoring.) and put them into production This is an individual contributor profile wherein the candidate is required to work in collaboration with the AMs and DMs Machine Learning techniques (recommendation engines, ensemble models such as random forests, bagging and boosting, support vector machines, dynamic optimization etc.) Design and build systems that mine massive datasets and structure/ engineer it to be usable for machine learning models
Salary Negotiable
Industry IT Software
SubIndustry Software Development
Functional Area IT Software Development
Specialization IT/Technical Content Developer
Role Manager / Sr. Manager Level
Keyskills
NLPText MiningMachine Learning
Desired Candidate Profile
Please refer on JD
Education
Highest Qualification
Graduation Any Graduate",5.0,"Fine Jobs
5.0",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
545,Big Data Analyst,"Job Description
R3coder powers our clients businesses with innovative technologies established and emerging changing the way their people and customers experience work, life and entertainment. Join R3coder and you ll translate the operational needs of the world s governments and leading businesses into the innovative technical solutions that will enable them to better serve their customers your friends, family and neighbors.You ll deliver everything from point solutions for a single business function to large, long- term outsourcing services, to complex systems integration installations spanning multiple businesses and functions. You ll create custom- designed solutions or integrate our technology platforms with their operations.

Role Description : Lead the effort to design, build and configure applications, acting as the primary point of contact.

Must Have Skills : Big Data Analytics

Good To Have Skills : Hadoop, Scala Programming Language, Spark Programming

Responsibilities
Excellent experience with the Hadoop eco- system viz Pig/ Hive, HDFS, MapReduce, Hbase and In- Memory data processing tools such as Storm/ Spark
Experience on cluster sizing Cloud/ on premise, infrastructure planning, installation and administration of Hadoop Cluster based on any of the available Hadoop Distributions like Hortonworks, Cloudera, MapR etc
Excellent knowledge on NoSQL platforms like MongoDB , Cassandra etc.
Strong knowledge of Hadoop Framework including HDFS, HIVE, PIG
Good knowledge of multithreaded programing
Strong knowledge of core java data structures
Other Skills
Excellent communication Oral/ Written skills, ability to articulate solution decisions to clients, internal stakeholders
Ability to lead teams, mentor developers
Problem solving Attitude
Ability to handle stakeholders and client facing
Experience
Big Data: 1+ years (Preferred)

Contact Us to Apply : (+91) 851 187 8094 info@r3coder.com",-1,R3coder,Ahmedabad,"Ahmedabad, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
546,Data Science Video/Voice Analytics Internship,"About the company:
We are at the forefront of implementing ML-driven solutions and combining intelligent decision-making algorithms. Our products have been built using the best algorithms combining advanced data mining techniques. Our approach includes the algorithms in detecting known and unknown with high accuracy, fewer training times, large datasets, and frequent re-tuning. We strive to become the platform of choice for aspiring developers and users of AI.

About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Building systems and algorithms to extract knowledge, finding patterns, generating insights and making predictions from diverse data for various applications and visualization 2. Working on various modeling algorithms, data mining tools, data analysis tools, and statistical packages 3. Applying predictive modeling techniques (model training, logistic regression, etc.) statistics and information retrieval methods to real-world data 4. Working on machine learning and statistical methods 5. Working on AI/ML techniques in the video domain

Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 28th May'20 and 2nd Jul'20
are available for duration of 6 months
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply

Other requirements:
Familiarity with image/video processing algorithms such as CNN, R-CNN, object detection algorithms, OpenCV, neural networks, etc. Ability to work independently and in a team to research innovative solutions to challenging business problems

Number of internships/jobs available: 2

Categories: Data Science",-1,CogniTensor Technology Private Limited,New Delhi,-1,-1,-1,-1,-1,-1,-1,-1
547,Data Science Video/Voice Analytics Internship,"About the company:
We are at the forefront of implementing ML-driven solutions and combining intelligent decision-making algorithms. Our products have been built using the best algorithms combining advanced data mining techniques. Our approach includes the algorithms in detecting known and unknown with high accuracy, fewer training times, large datasets, and frequent re-tuning. We strive to become the platform of choice for aspiring developers and users of AI.

About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Building systems and algorithms to extract knowledge, finding patterns, generating insights and making predictions from diverse data for various applications and visualization 2. Working on various modeling algorithms, data mining tools, data analysis tools, and statistical packages 3. Applying predictive modeling techniques (model training, logistic regression, etc.) statistics and information retrieval methods to real-world data 4. Working on machine learning and statistical methods 5. Working on AI/ML techniques in the video domain

Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 28th May'20 and 2nd Jul'20
are available for duration of 6 months
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply

Other requirements:
Familiarity with image/video processing algorithms such as CNN, R-CNN, object detection algorithms, OpenCV, neural networks, etc. Ability to work independently and in a team to research innovative solutions to challenging business problems

Number of internships/jobs available: 2

Categories: Data Science",4.3,CogniTensor Technology Private Limited,New Delhi,"Palo Alto, CA",10000+ employees,1998,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),-1
548,Data Analyst,"Job Overview:
Solve the data problem at scale. Build models that will power the future of logistics and transportation.
Execute analytics leveraging software such as MS Excel, SQL, Tableau, R, Python, etc. and a lot of common sense!
Deliver powerful visualization to stakeholders to make sense of data and let them make the critical decision with multi-crore impact.
In addition to solving the data problems, interact with the leading companies including logistics supply chain companies and the Fortune 500 to tell them how to use their data (once you are a senior wizard).
Understand the macro and micro picture of how the logistics industry will evolve, what trends the data shows and how can customers derive value from them.
Build trust, perform advanced analytics and impact a $100 billion+ logistics industry!

Responsibilities and Duties:
You need to be awesome!
Experience with data analytics: analyse mountains of data in minutes and live deadlines.
Advanced knowledge of statistical analysis which you can use while walking to office.
Ability to learn new tools and technologies fast.
Excellent communication skills as you will be talking to clients over time.
Resourcefulness and troubleshooting aptitude to find the answers when data is incomplete, inaccurate or both.
Accuracy, speed and attention to detail matters, as clients will make decisions based on your analysis.

Good to have:
Web development.
Familiarity with MS Excel, Tableau and other BI tools, SQL, R, Python etc.
A desire to change the world.",3.4,"LogisticsNow
3.4",Mumbai,"Mumbai, India",1 to 50 employees,2016,Company - Private,Logistics & Supply Chain,Transportation & Logistics,Unknown / Non-Applicable,-1
549,Research Associate / Scientist,"Position: Research Associate / Scientist

Location: Bangalore, India

Contact: Please email admin@stringbio.com

No of Openings: 1

The incumbent will be responsible for managing all scientific experiments related to plant growth, developmental trials, documentation, data analysis and product specs. Candidate with strong knowledge of the agricultural market are preferred. Candidate is someone who is enthusiastic about taking scale up challenges, exhibits meticulous attention to detail, and an eagerness to learn new techniques. The candidate will work very closely with the String team and outside partners/collaborators.

POSITION RESPONSIBILITIES

Design, set up, execution and analysis of experiments related to application of agricultural products in various crops.
Developing robust protocols for testing efficiency of different agricultural products for improving plant growth and productivity.
Optimizing agricultural products for performance and stability.
Plan and implement greenhouse/ field experiments.
Collaborate with interdisciplinary teams and work closely with multi-disciplinary teams/ along with project partners to assist in University trails or other field experiments.
Data collection, analysis and interpretation of data generated from field/ wet lab experiments.
Assist scientists/other team members in the various ongoing research activities.
Manage and deliver against project goals and timelines.
Maintain accurate and timely records of laboratory work. Evaluate data, prepare technical reports and make scientific presentations.
Be a conscientious laboratory citizen, adhere to EH&S standards, and use knowledge of laboratory procedures to advance projects under shifting priorities and timelines.
The position is full-time.

CANDIDATE PROFILE

EDUCATION AND EXPERIENCE

PhD in any stream of Agricultural Sciences/ Horticulture/ Plant Biotechnology or
MSc in Agricultural Sciences/ Horticulture/Biotechnology with minimum of at least 3-5 years relevant experience, preferably with a research and development organization implementing agriculture related projects.
Ability to independently plan and carry out research on various project and work towards attainment of project objectives.
Sound knowledge of experimental designs, statistical analysis, proficiency in computation skills for document processing, and preparing presentations.
Excellent communication, with fluency in written and spoken English, and the ability to work in a multi-cultural environment.

PERSONAL QUALITIES

Driven, dedicated team player with attention for detail.
Ability to work independently and deliver on project objectives.
Capacity to be proactive and take initiatives.
Good organizational skills.
Effective interpersonal skills.
Strong oral and written communication skills.
Creative, out of the box thinker with strong analytical and problem-solving capabilities.
Ability to adapt to changing drivers.",4.7,"String Bio
4.7",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
550,Computer Vision/Deep Learning Research Scientist,"Job Title : Computer Vision/Deep Learning Research Scientist
Job Location : Bangalore, India
Job Description :

- A world-class research lab that excels at novel product development through fundamental architecture research. -
Looking for highly qualified, dynamic researchers for path breaking research in Architectures for Computer Vision and Deep Learning.
Next generation image processing and associated real-time, low-power programmable/accelerator hardware architectures for Computer Vision and Deep Learning is the focus of this research thrust.
Optimized implementations of geometric methods in Computer Vision Multi view Geometry, SLAM, SfM etc, Inertial visual sensor fusion, real-time image-based rendering techniques, 3D reconstruction, Deep Learning based recognition methods in Computer Vision will all be explored. - This will be done in collaboration with teams across the globe evaluating, researching and co-developing new algorithms and hardware architectures for emerging new world applications like Augmented Reality AR, Virtual Reality VR and drones.
All Research Scientists will advance the state-of-the-art in deep collaboration with product architecture/design teams while also contributing to scientific literature/conferences and developing Intellectual Property.
Main responsibilities
Hardware-oriented Computer-Vision/Deep-Learning Research Scientists will be responsible for power/area/performance driven architecture, microarchitecture development and optimization.
Activities include Logic design, RTL-to-GDS synthesis, layout optimizations and FPGA emulation.
Algorithm/software-oriented Computer-Vision/Deep-Learning Research Scientists be responsible for research and development of new algorithms and their optimization for high performance and quality, and highly efficient mapping and implementation to hardware.
Qualification :

Candidate Should hold -
PhD or advanced MS in EE/CS
Research background
Job Posted : 2017-09-13",-1,Approgence,Bengaluru,"Irvine, CA",1 to 50 employees,2006,Company - Private,IT Services,Information Technology,₹500 million to ₹1 billion (INR),-1
551,Quantitative Analyst ? iRageCapital,"Functional Area Other
Industry Type Banking-Financial Services-Broking
Keywords Quantitative Analyst,Analytical,Email,Tools,high frequency trading,Financial markets,big data,Business Executive,Quant Analyst,Building

Quantitative Analyst iRageCapital Quantitative Analyst (0 - 2 yrs) Role Summary iRage is recruiting for its proprietary trading desk and is looking for a quantitative analyst.
You will be involved in analysing market behaviour from both micro and macro perspective; designing algorithmic high - frequency trading strategies for the option derivatives segment of the Indian market.
Apart from building new strategies , the job will involve analysing the performance of deployed strategies , and improving the efficiency of deployed strategies.
There would also be a need to enhance or build trading tools and trading platforms and innovating towards newer strategies.
Skills
Basic awareness of financial markets and fundamentals
Strong logical quantitative aptitude
Strong educational background with a focus on finance
Experience of working with big data analytical tools like R , etc. is preferred
Prior experience of trading is an advantage but not necessary
Previous experience with algorithmic trading platforms is an advantage but not necessary Please submit the required information and attach your resume

Job Role Quantitative Analyst

Desired Candidate Profile

Profile Description
NA

Under Graduate Qualification B .Com (Commerce)

PG Qualifications M.Com (Commerce)
Note: Candidate should have either UG or PG qualifications",3.8,"iRageCapital Advisory Private Limited
3.8",Mumbai,"Mumbai, India",1 to 50 employees,2009,Company - Private,Stock Exchanges,Finance,Unknown / Non-Applicable,-1
552,Data Science - Principal Software Engineer,"We believe work is not a place, but rather a thing you do. Our technology revolves around this core philosophy. We are relentlessly committed to helping people work and play from anywhere, on any device. Innovation, creativity and a passion for ever-improving performance drive our company and our people forward. We empower the original mobile device: YOU!

What we're looking for:


You will join a crack team of experienced and talented engineers, with years of history delivering high-quality Analytics products and Solutions, in a fast-paced business environment. You will be collaborating with fellow engineering teams across the globe

Business Overview:

Citrix is expanding its Advanced (Appsec) Analytics team with professionals in the ML/AI/Data Science domains.

Roles responsibilities
Research & develop Machine Learning models for security problems, in the areas of Application Security, Networking, Application & Data.
Suggest, collect and synthesize requirements, and create effective features.
Apply research methodologies to identify the Machine Learning models for the problem at hand.
Minimum Qualifications
Bachelors/Masters/PhD in CS/IT/EE/Mathematics and computing with 12+ years of experience
Experience in implementing and deploying Machine Learning solutions (using various models, such as Linear/Logistic Regression, Support Vector Machines, (Deep) Neural Networks, Hidden Markov Models, Conditional Random Fields, Topic Modeling, Game Theory, Mechanism Design, etc.)
Extensive background in statistical analysis and modeling (distributions, hypothesis testing, probability theory, etc.)
Strong hands-on experience with statistical packages and ML libraries (e.g. R, Python scikit learn, Spark MLlib, etc.)
Experience in effective data exploration and visualization (e.g. Excel, Power BI, Tableau, Qlik, etc.)
Experience in developing and debugging in one or more of the languages C/C++, Java, Scala, Python, or R
Ability to work in cross-functional teams
Excellent written and verbal communication skills in English; the ability to convey your message to team members and other stakeholders
Preferred Qualifications
Experience in Application Security Domain, AppFW, BOT, etc
Experience working with relational and NoSQL/Graph databases
Unsupervised & Deep Learning Experience
Familiar with Big Data frameworks (Hadoop or Spark) and cloud infrastructures
Experience in applying Machine Learning techniques
Ability and willingness to multi-task and learn new technologies quickly
What youre looking for:


Our technology is built on the idea that everyone should be able to work from anywhere, at any time, and on any device. Its a simple philosophy that guides everything we do including how we work. If youre an engineer, well give you plenty of ways to test your skills on cutting edge technology. We want employees to do what they do best, every day.

Be bold. Take risks. Imagine a better way to work. If this sounds like you then wed love to talk.

Functional Area:
Software Development
About us:


Citrix is a cloud company that enables mobile workstyles. We create a continuum between work and life by allowing people to work whenever, wherever, and however they choose. Flexibility and collaboration is what were all about. The Perks: We offer competitive compensation and a comprehensive benefits package. Youll enjoy our workstyle within an incredible culture. Well give you all the tools you need to succeed so you can grow and develop with us.

Citrix Systems, Inc. is firmly committed to Equal Employment Opportunity (EEO) and to compliance with all federal, state and local laws that prohibit employment discrimination on the basis of age, race, color, gender, sexual orientation, gender identity, ethnicity, national origin, citizenship, religion, genetic carrier status, disability, pregnancy, childbirth or related medical conditions, marital status, protected veteran status and other protected classifications.

Citrix uses applicant information consistent with the Citrix Recruitment Policy Notice at https://www.citrix.com/about/legal/privacy/citrix-recruitment-privacy-notice.html

Citrix welcomes and encourages applications from people with disabilities. Reasonable accommodations are available on request for candidates taking part in all aspects of the selection process. If you are an individual with a disability and require a reasonable accommodation to complete any part of the job application process, please contact us at (877) 924-8749 or email us at ASKHR@citrix.com for assistance.

If this is an evergreen requisition, by applying you are giving Citrix consent to be considered for future openings of other roles of similar qualifications.",4.0,"Citrix
4.0",Bengaluru,"Fort Lauderdale, FL",5001 to 10000 employees,1989,Company - Public,Computer Hardware & Software,Information Technology,₹100 to ₹500 billion (INR),"VMware, F5 Networks, Cisco Systems"
553,Data Analyst,"At Spice Money, we are about fun as much as we are about work. Being part of one of India’s biggest conglomerate, Spice Group, We have always known that only happy & motivated employees create great companies.Though great attention is focused on work, we ensure that employees enjoy their fair share of fun and frolic. Cultural events, sports and adventure activities, and a host of other initiatives are a part and parcel of life here.

We celebrate all festivals with great excitement & various onsite events /training etc. are organized from time to time. Latent talents are discovered at these meets and individuals and teams are given an equal opportunity to showcase and bring out their creative side.We have a dedicated club known as the ""Fun Committee"" that conducts various activities. The club is chaired and managed by the employees themselves & they have the power to decide what activities, event, etc. suit them best.
Data Analyst (Location: Mohali)
o
Qualification required: B.Tech / MCA
o
Experience required: 3 - 4 years
o
Create and develop reports, support in ETL process for the reports.
o
Exposure to Google BigQuery, Java, R Shiny, Tableau, Google Compute, Tableau, Python/ R, machine learning, dashboarding would be required.
o
Email us at human.resource@spicemoney.com
Growth

We are growing at a phenomenal
pace, grow with
us.

Benefits

We offer the best pay practices in the industry, great benefits and a safe working environment.

Training

Everyone is encouraged to avail the training sessions, to help enhance their personal and professional growth.

Family

We treat each other as family - we nurture, listen and help each other reach our true potential.

Committed

We are committed to the growth of
our employees, agents and
customers.",4.7,"Spice Money
4.7",SAS Nagar,"Noida, India",201 to 500 employees,-1,Company - Private,Financial Transaction Processing,Finance,Unknown / Non-Applicable,-1
554,Data Analyst,"By ruby7adminOn 22 Mar, 2020 0 Comments

Data Analyst


Social and mobile gaming studio Ruby Seven Studios is looking fora talented Data Analyst to work for our office situated in Kochi, India. This is your chance to get involved with a creative gaming studio, and to add to our ever-growing roster of games across Facebook, iOS, and Android.

You will be handling these responsibilities:
Consulting with internal customers (e.g., Marketing team, Game Producers) to develop analysis and frame actionable insights that helps the management in decision making
Wrangling data from multiple sources (including but not limited to): sales, product, player events, and customer/player databases, to create integrated views that can be used to drive decision making
Working with several large and complex SQL databases
Designing and building reports and analytical dashboards
Perform statistical analysis and A/B tests in events of new feature or content releases
Routinely keep an eye on anomalies in the game data and provide reasoning for the same
Qualifications:
Educational qualification – Degree (Bachelors/ Masters) in Computer Science/ IT; Engineering; Information Systems; Math’s/Statistics
Highly analytical data junkie who enjoys business analysis by using data interpretation skills
Positive, people-oriented, and energetic attitude
Self-starter and curious person who sees information as a tool to find answers to business questions
Analytical, creative, and innovative approach to solving problems
Strong written and verbal communication

Tech Skills:
Highly proficient in SQL with ability to write efficient queries and taking data from multiple data-sets as and when required
Should have a strong working knowledge in Excel and proficiency in either R or Python for automation purposes
Exposure to any visualization tool/ library (Tableau, ggplot, matplotlib, etc)
Machine learning algorithms – Individual who has exposure to ML modelling techniques will be an added advantage
Tools -Any Big data knowledge (e.g. Hadoop, Spark) will be an added advantage
How to apply:
Send the CV to careersindia@rubyseven.com",3.8,"Ruby Seven Studios
3.8",Kochi,"Reno, NV",51 to 200 employees,2012,Company - Private,Video Games,Media,Unknown / Non-Applicable,"WMS Gaming, IGT, Caesars Entertainment"
555,Data Scientist – The Household Finance Research Initiative,"Dvara Research

Organisation Profile:
Dvara Research (Dvara) is a not-for-profit company promoted by Dvara Trust. We are focused on the mission of
ensuring that every individual and every enterprise has complete access to financial services. Our mission is
motivated by a strong belief in the deeply transformative power of finance in unlocking the potential of low-income
households and enterprises. Our vision of the future of finance is one in which innovation helps people deal with the
increasing levels of complexities in their own lives. We believe that a good financial system, capable of such
innovation, is characterised by three pillars - high-quality origination, risk transmission and risk aggregation. Dvara's
overarching strategy is based on advocacy, research and strategic collaborations for strengthening the three key
pillars of the financial system.

Since 2008, when Dvara was founded, it has made several contributions to the Indian financial system. Dvara
Research has participated in several policy-making platforms such as the Reserve Bank of India’s Committee on
Comprehensive Financial Services for Small Businesses and Low-Income Households (CCFS), serving as the technical
secretariat to the Committee. Dvara has also worked with the Government of India’s High Power Expert Committee
on Urban Infrastructure and Services, and the Committee to Review Implementation of Informal Sector Pension.
Dvara has been closely involved in the evolution of the pension product for informal sector workers (NPS-
Swavalamban) and advises the Pension Fund Regulatory and Development Authority of India (PFRDA) on the same,
besides providing inputs to the RBI Household Finance Committee, the RBI Committee on Medium Term Path on
Financial Inclusion, and most recently the Committee of Experts on a Data Protection Framework for India, of the
Ministry of Electronics and Information Technology, and the Ministry of Finance.

Besides our work with regulators and policy makers, some of our research outputs pertain to identifying costs
inherent in various channels for rural credit delivery, our position on consumer protection, and our views on capital
market development and banking sector reform. Our past research on over-indebtedness focusses on the liabilities
side of household balance sheets, and identifies the risk of certain customer segments being over-leveraged.

About the Household Finance Research Initiative:
The Household Finance Research Initiative (the Initiative), housed under Dvara aims to rigorously understand the
financial choices and decisions of low-income individuals and households, and their relation to achieving households’
objectives. At the core of this Initiative is our intention to study financial inclusion not as an end in itself, but as a
means to enabling efficient household balance sheets and financial well-being for individuals and the household.
Keeping this focus in mind, the Initiative intends to nurture a research-based ecosystem that aspires to have deep
understanding of household finance and use such understanding to enable better market practice and policies. Dvara
believes that careful research and a comprehensive body of evidence can powerfully inform businesses that are
innovating on the delivery of financial products and services to previously untapped markets, as well as the design
of financial sector policy. Aligning with Dvara’s core strengths, we intend that this body of research contribute
tangible insights for healthy financial sector development including the design and availability of suitable financial
services for all, and the creation of a safe environment in which formerly excluded populations may fully experience
the benefits of the latest unprecedented developments in financial inclusion including digitization of various
components of the customer life cycle as well as the evolution of new channels of intermediation and delivery

About the Position – Data Scientist:
This position reports to the Executive Director – Dvara Research.

Tasks and Responsibilities to include:
Data resource management: Managing the data resources of Dvara Research as a whole, serving as the go-
to person for questions of internal and external data access, assisting the Executive Director with
monitoring external Data Sharing Agreements, updating datasets as required, creating effective
dissemination for both internal and external members regarding the datasets available for access.
Taking Ownership of Household Finance Tools: Ensuring that existing tools are regularly updated, working
with the communications team to ensure sustained interest in existing tools, working with members of the
team to create new tools that could be used by the household finance research community, overseeing
interns working with the tools on specific research questions.
Analysis and Visualisation: Serving as the primary resource for any data-based analysis to be done by the
team, helping team members in using statistical packages to generate analysis for general scoping as well
as specific research questions, using the data at your disposal to help come up with possible research
questions, working with the communications team to create a standardized template for visualisations
across Dvara Research’s workstreams.
Knowledge Management: Keeping oneself and the team updated on latest developments of interest to the
team, and to debate out issues to improve outcomes for oneself and for the team.

Skills
Strong mathematical and statistical foundations, with coursework or work experience covering advanced
econometric concepts.
A high degree of proficiency in at least one statistical package/language (R, STATA, python).
Prior experience working with ODBC and SQL (preferably SQL Server).
The capability to create clear, concise, and representative data visualisations using data visualization
software such as Tableau.
Sound analytical and critical thinking skills, with the ability to understand and analyse issues from first
principles and develop solutions that are theoretically sound with a clear pathway to implementation.
Ability to communicate (both orally and in the written format) analysis with clarity, precision, and
thoroughness, and be able to adapt different writing styles based on the intended outcome and audience.
A very high degree of integrity and honesty in one’s dealings, and an ability to consider and contribute to
team’s performance as being as important as one’s own performance.
A high degree of self-motivation to work in an unstructured environment and an innate flair for finding
constructive solutions to problems while working in team settings.

This position is based in Chennai. Remuneration will be competitive and commensurate with experience.

We are an equal opportunity employer and value diversity in our team. We do not discriminate on the basis of age,
disability status, ethnicity, gender, marital status or religion.

To apply for this position please send us your latest CV, a cover letter detailing your interest in this position and the
names of 2 references to jobs.research@dvara.com. Please include the words “Data Scientist - HFRI” in the subject
line of the email.",3.5,"Dvara Trust
3.5",Chennai,"Chennai, India",201 to 500 employees,2008,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
556,Analyst Data Scientist,"Build an in-depth understanding of the problem domain and available data assets
Research, design, implement, and evaluate machine learning approaches and models
Perform ad-hoc exploratory statistics /data mining tasks on diverse datasets - small scale to big data
Participate in data architecture and engineering decision-making to support analytics
Take initiative in evaluating and adapting new approaches from data science research
Investigate data visualization and summarization techniques for conveying key findings
Communicate findings and obstacles to stakeholders to help drive the delivery to market
Code your solutions (this is a hands-on position requiring strong programming skills)

Key Requirements:
Professional experience as a data scientist or a related software engineering role
Graduate degree (MS) in mathematics, computer science or other quantitative discipline
Thorough understanding of probability and statistics, Bayesian methods, time series analysis
Strong programming skills (in any language)
Great communication skills, team player, self-starter, demonstrated strong work ethic
Desire to use modern technologies as a disruptive influence within the Finance domain

Preferred:
Expertise in Statistics, Empirical Data Analysis, Machine Learning or Natural Language Processing
Experience and in-depth knowledge of Python and other modern programming languages
Experience in a specialized statistical computing environment, preferably R
Experience in practical data processing, data mining, text mining and information retrieval tasks
Experience in scalable data management tools - Relational and NoSQL databases
Knowledge of Big Data architectures a strong plus
Knowledge of Pythons data analysis and machine learning libraries a strong plus
Exp: 3 to 8 yrs

Location: Bangalore/Mumbai/Hyderabad/Chennai/Pune/NCR",4.1,"Camsdata
4.1",Mumbai,"Bengaluru, India",51 to 200 employees,2017,Company - Private,IT Services,Information Technology,₹10 to ₹50 million (INR),eTeam
557,Data Engineering - Senior Associate,"Data Engineering – Job Description Location: Bangalore

Responsibilities

• You will be responsible for maintaining large-scale data processing systems, data warehouses and data lakes to help manage the ever-growing information needs of our clients. • Your technical challenge will be to test and optimize systems that ingest, aggregate and visualize terabytes of data that solve business relevant problems of our customers.

• Work with business users to refine analytical requirements for quantitative data (view-through, clickstream, acquisition, product usage, transactions), qualitative data (survey, market research) and unstructured data (blog, social network). • Designing and developing schema definitions and support data warehouse/mart to enable integration of disparate data sources from within Client environment and outside, aggregate it and make it available for analysis. • As a key member of the team drive adoption of new technologies, tools, and process improvements to build world class analytical capabilities for web analytics, optimization, experimentation and personalization. • Develop high performance, scalable implementations of the statistical/machine learning models developed by our Data Scientists.

Qualifications

• BS/MS in computer science or equivalent work experience. • 6 to 8 years’ experience in developing Data Models, DB schemas, creating ETLs, and familiar with Hadoop Ecosystem • 2+ years experience with data ingestion through batch and streaming methodologies using open source or public tools like Kafka, Airflow, Azure Data Factory etc..

• Experience with databases both RDBMS and NoSQL (Vertica, Netezza or Oracle and AWS data services tech). Through understanding of SQL (any variant) • Good understanding of Data Ware House methodologies. • Hands on experience in any of the programming languages (Shell scripting, Python, Scala, Java, etc)

Good to have

• Knowledge of Big Data ecosystem like Hadoop M/R, Pig and Hive is a strong plus. • Understanding of IN memory distributed computing frameworks like Spark (and/or DataBricks) and its parameter tuning, writing optimized queries in Spark • Scheduling and Monitoring of Hadoop and Spark jobs • Good understanding of any reporting tools such as Tableau, Pentaho or Jasper is a big plus. • Experience in design, development and deployment of one or more tools - ETL (Informatica, OWB, ODI), reporting (Business Objects, QlikView, Tableau)",4.2,"TheMathCompany
4.2",Bengaluru,"Bengaluru, India",201 to 500 employees,2016,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
558,Breeding Design Scientist,"Job Description

PURPOSE:
Leads the design, development, implementation and execution of new innovative genomic and data science approaches for future product design strategy in alignment with product concept and portfolio need to deliver genetic gain in short and long term for multiple APAC pipeline across corn, Rice, Cotton, Pearl Millet and Mustard, valued at ~ $300M annual sales

Build a strong linkage with Pipeline Breeding, Discovery Breeding, Product Systems, Field Testing, APD, APC and Biotech functions to develop product concept driven future product design and robust analytics driven product advancement plan

WHAT YOU DO:
Exploration of haplotype data and germplasm to map haplotypes for key traits for different APAC markets
Working on haplotype explorer tools and identification of key haplotypes. Report preparation and sharing with pipeline breeders and discovery teams for use in breeding programs
Supporting pipeline breeding and discovery team to formulate plan to introgress key haplotypes in XDs and develop breeding populations
Understanding the global germplasm mining and GWAS strategy and develop a similar plan for Asia germplasm and allele mining
Working with discovery scientists to build a hap catalogue for Asia and tropical germplasm
GWS model accuracy review and action item planning with breeding and APD. Implementing plans to improve accuracy for all APAC pipelines
Data quality check
Periodic GWS model retraining plan implementation coordination with breeding and APD. Incorporation of negative selections for better model performance
Working with plant health, discovery and breeding teams to explore plant health native traits and plan to incorporate them in GWS model
Model performance review and execution to enhance selection efficiency
GWS fate analysis using historical selections and support pipeline breeders for decision making
Making GWS implementation plan and timeline mapping for rice in coordination with pipeline breeders, discovery and APD. Phenotypic data review, quality check. Model performance review and improvement planning
Planning and implementation APAC origin prediction model for different APAC pipelines
Coordination with pipeline breeders and APD to use appropriate data for origin prediction, review and quality check
Model performance review and performance analysis of SC2 and stage less models. Working with breeding and APD teams to improve model accuracy
Fate analysis and model performance review
Action item preparation for in time model retraining
Execution of long term predictive analytics strategy for Rice (cotton)

Required Candidate profile

PhD in quantitative/statistical genetics or plant breeding or animal breeding with expertise in the field of data science, analytics.
Working expertise in R programming language is desirable
3+ years of experience in data science, discovery breeding or related field
Handling of genetic marker data, large phenotypic data, haplotype database will be added advantage
Ability to deliver innovative and creative solutions to complex problems. Ability to think and develop innovative information systems.
Independent, self-motivated and assertive with a results orientation.

Salary: Not Disclosed by Recruiter

Industry:Agriculture / Dairy

Functional Area:Other

Keyskills
discovery breeding
haplotype
GWAS
germplasm
Genome - wide Association Study
haplotype database
Pipeline Breeding
statistical genetics
plant breeding
rice
data quality
breeding data science
data science
genomics
predictive analysis
R programming
Desired Candidate Profile
Please refer to the Job description above

Education-

UG:B.Sc - Other Specialization, Agriculture, Maths, Statistics

PG:MS/M.Sc(Science) - Statistics, Other, Agriculture, Biotechnology, Data Informatics

Company Profile

Bayer Group

Bayer CropScience Ltd.",3.5,"Bayer Group
3.5",Bengaluru,"Las Vegas, NV",201 to 500 employees,-1,Company - Public,Vehicle Dealers,Retail,₹5 to ₹10 billion (INR),-1
559,ACO Data Analyst,"Â·Â Â Â Â Â Â Â Â Â Extract weekly data for COMPANIES clients

Â·Â Â Â Â Â Â Â Â Â Make sure the data is placed in the right servers

Â·Â Â Â Â Â Â Â Â Â To Run scripts to covert the data into COMPANIES â€™s data warehouse format

Â·Â Â Â Â Â Â Â Â Â Make sure the data is correctly readable by Spotfire and all dashboards are up and running properly

Â·Â Â Â Â Â Â Â Â Â Analyze data extracted from Clients Servers, to check if the client is using the EHR correctly.

Â·Â Â Â Â Â Â Â Â Â Do gap analysis about where the Client is lacking in achieving his goals for incentive programs.

Â·Â Â Â Â Â Â Â Â Â Educate Client about the analysis

Â·Â Â Â Â Â Â Â Â Â Periodically contact Client to make sure that the Client is properly using the EHR, so that they donâ€™t miss on any of the incentive parameters.

Â·Â Â Â Â Â Â Â Â Â Interact with TL and other members of the team to improve the process.

Â·Â Â Â Â Â Â Â Â Â Report to TL, to get constant updates on the product and process.

Â Interested call us or walkin with friends directly Monday to Saturday 9-6pm

W h i t e H o r s eÂ M a n p o w e rÂ C o n s u l t a n c yÂ P vÂ tÂ Â L t d .

#11 Office156, 3rd Floor, Jumma Masjid Golden Complex, Jumma Masjid Rd, (Entrance of Commercial Street) Bangalore 560051.

Ph: 9972020040 , 9972020050, 9342431048

Â Free Recruitment
00-4.00 Years",2.6,"White Horse Manpower Private Limited
2.6",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
560,Data Analyst,"• Provide sustaining support for existing dashboards and semantic.

• Design, develop, and support dashboards and reports.

• Monitor FogBugz Ticketing system to address bugs, enhancements and adhoc data requests

for Operations stake holders.

• Drive deep data profiling and analysis for insights.

• Create and deploy robust, scalable audit framework for monitoring data quality and latency

for our semantic and dashboards.

• Drive automation wherever applicable for scale and efficiency.

Key Qualifications:

• Expertise with Tableau and data visualisation is a must

• Expertise in UI/UX is a must

• Experience presenting and sharing insights with various business functions

• Relational Database design and data architecture fundamentals;

• Experience with ETL tools used to automate manual processes

• Experience with Python a plus.

Individual must demonstrate:

• Sound critical thinking, work ethics and passion to go beyond what is expected ongoing.

• Possess a very high degree of natural curiosity to drive the next levels of business questions

and insights.

• Ability to manage and deliver assigned projects from start to finish within timelines, scope

and quality.

• Advanced knowledge of SQL is a plus

• Strong verbal and written communications.",4.8,"Thoucentric
4.8",Hyderabad,"Bengaluru, India",51 to 200 employees,2015,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
561,Senior Scientist – Fermentation Development,"Position: Senior Scientist – Fermentation Development

Location: Bangalore, India

Contact: Please email Subbiane@stringbio.com

No of Openings: 1

The Senior Scientist will be responsible for scaling up and optimization of fermentation processes. The candidate will have a strong command of fermentation development, scale up and plant operations.

POSITION RESPONSIBILITIES:
Design, execute, and analyze scientific experiments for production of small molecules using fermentation and other techniques.
Optimize the fermentation processes for maximizing production of value added products. Optimize product yield and minimize production cost.
Evaluate production processes, check its compatibility/configuration with respect to design and conduct follow-up experiments.
Develop statistical models of fermentation production for developing simulations of biochemical production.
Analyze and record process flow configurations, instrument specifications, instrumentation and piping diagrams required for systems design.
Utilize pilot process data for developing operational narratives.
Develop and execute scalable bioreactor control strategies.
Conduct detailed analysis, compile and report fermentation data.
Scale the fermentation process from demo through commercial scale.
Conduct routine maintenance of fermentation laboratory equipment.
Analyze batch records and monitor consistency of operations by using appropriate database and statistical tools.
Participate in techno-commercial evaluation of the projects to allow proper prioritization.
Lead trouble shooting in the plant for process and quality issues.
Serve as expert technical support to develop, implement and drive improvement in process safety.
Develop, review, update and implement process safety-related Standard Operating Procedures (SOPs) and guidelines as needed.
Track and report process safety indicators, key process safety metrics, action plans, and priority recommendations.
Assist in training of plant personnel.
Participate in identifying and implementing best practices for plant operations
Reliable execution and management of fermentation runs as per company SOPs.
Seek and qualify new technologies that are enabling for accomplishing project objectives.
Maintain accurate and timely records of laboratory work. Evaluate data, prepare technical reports and make scientific presentations.
Be a conscientious laboratory citizen, adhere to EH&S standards, and use knowledge of laboratory procedures to advance projects.

CANDIDATE PROFILE EDUCATION AND EXPERIENCE

PhD or MSc in Chemical Engineering, Biotechnology, Molecular Biology or a related field.
5-10 years’ work experience in in bio-industrial, pharma, life sciences or ethanol industry.
Experience with handling and managing fermentation equipment.
Experience with fermentation plant management is a plus.
Proficiency with MS Office suite.

PERSONAL QUALITIES

Creative, out of the box thinker with strong analytical and problem-solving capabilities.
Ability to work independently and deliver on project objectives.
Capacity to be proactive and take initiatives.
Good organizational skills.
Ability to adapt to changing drivers.
Effective interpersonal skills and a team player.
Good communication skills.
Good observation skills for paying attention to details.
Integrity, dependability, and persistence towards task accomplishment.
Innovation, cooperation and willingness to take on new responsibilities.
Strong leadership skills.",4.7,"String Bio
4.7",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
562,Data Engineer - Java Senior,"EY GDS – Data and Analytics (D&A) –Senior – Java Developer for Analytics Application
As part of our EY-GDS D&A (Data and Analytics) team, we help our clients solve complex business challenges with the help of data and technology. We dive deep into data to extract the greatest value and discover opportunities in key business and functions like Banking, Insurance, Manufacturing, Healthcare, Retail, Manufacturing and Auto, Supply Chain, and Finance.

The opportunity
We’re looking for candidates with strong technology and data understanding in analytics application development space, having proven delivery capability. This is a fantastic opportunity to be part of a leading firm as well as a part of a growing Data and Analytics team.

Your key responsibilities
Drive project/service delivery
Work with Product Managers to build the “right” software
Collaborate with other platforms tech leads to ensure integrated end-to-end design
Document design decisions and enforce existing process guidelines
Follow best practices for Software Development
An inclination towards learning new technologies and applying them to solve customer problems
Mentor junior developers
Leverage DevOps practices for Continuous Integration and Continuous Deployment.
Conduct design & code reviews
Monitor operating efficiency of existing application systems
Interact with senior leaders, understand their business goals, contribute to the delivery of the workstreams
Design and optimize model codes for faster execution

Skills and attributes for success
4+ years’ experience in Java, J2EE, Web Services, RESTFUL APIs, Spring, Spring Boot, Hibernate, JSON and XML
3+ years’ experience with one of the following Web services SOAP, REST and JSON
At least 4 years of experience in developing back-end micro services using Java, Spring Boot, NoSQL or PostgreSQL or other databases and Tomcat
2+ years’ experience in one of the following Build and CICD technologies: SVN, GitHub, Maven, Jenkins, Nexus or Sonar
At least 1 year of experience in integration of messaging platforms such as Kafka, RabbitMQ in solution design/development
At least 3 years of experience developing high traffic external facing applications using: Angular 4+ with Typescript, Node.js, CSS/SCSS and HTML 5
At least 1 year of experience with Agile development methodologies including Scrum or Kanban
Prior experience with code deployment activities and procedures for high traffic external facing applications
Experience in application’s Operational maintenance and performance tuning
Hands-on expertise in cloud services like AWS, and/or Microsoft Azure
1+ years of experience in container orchestration frameworks: Kubernetes, Docker Swarm, or Amazon ECS
Demonstrable understanding of high-quality coding and testing practices
An appetite to learn new technologies and a drive for continual improvement

To qualify for the role, you must have
Be a computer science graduate or equivalent with 6-10 years of industry experience
Have working experience in an Agile base delivery methodology (Preferable)
Flexible and proactive/self-motivated working style with strong personal ownership of problem resolution.
Excellent communicator (written and verbal formal and informal).
Participate in all aspects of solution delivery life cycle including analysis, design, development, testing, production deployment, and support.

Ideally, you’ll also have
Client management skills

What we look for
People with technical experience and enthusiasm to learn new things in this fast-moving environment

What working at EY offers
At EY, we’re dedicated to helping our clients, from start–ups to Fortune 500 companies — and the work we do with them is as varied as they are.

You get to work with inspiring and meaningful projects. Our focus is education and coaching alongside practical experience to ensure your personal development. We value our employees and you will be able to control your own development with an individual progression plan. You will quickly grow into a responsible role with challenging and stimulating assignments. Moreover, you will be part of an interdisciplinary environment that emphasizes high quality and knowledge exchange. Plus, we offer:

Support, coaching and feedback from some of the most engaging colleagues around
Opportunities to develop new skills and progress your career
The freedom and flexibility to handle your role in a way that’s right for you

About EY
As a global leader in assurance, tax, transaction and consulting services, we’re using the finance products, expertise and systems we’ve developed to build a better working world. That starts with a culture that believes in giving you the training, opportunities and creative freedom to make things better. Whenever you join, however long you stay, the exceptional EY experience lasts a lifetime. And with a commitment to hiring and developing the most passionate people, we’ll make our ambition to be the best employer by 2020 a reality.",3.8,"EY
3.8",India,"London, United Kingdom",10000+ employees,1989,Company - Private,Accounting,Accounting & Legal,₹500+ billion (INR),"Deloitte, KPMG, PwC"
563,Sr Data Analyst - Service Delivery,"Driving Infinite Possibilities Within A Diversified, Global Organization
JOB ACTIVITIES

•Lead the project team as a Service Delivery Lead/Project Manager, for the Honeywell Data Management projects
•Provide project management expertise in the development of IT strategy and assure effective delivery of multiple complex projects within Honeywell IT, ensuring both schedule and budget fidelity.
•Oversee projects, manage budget and resource plans, and identify and resolve conflicts and dependencies.
•Deploy standardized work, project management methodologies, governance and tools to enable consistent, high quality, agile and waterfall project management style execution of IT projects across the Enterprise.
•Ensure learnings are shared across the organization to enable higher productivity.
•Manage stakeholder expectations by demonstrating and communicating key indicators of improved effectives on a periodic basis
•Contribute in improving IT processes, program and change management.
•Facilitate a culture of openness, transparency, experimentation, honest introspection, continuous improvement, learning and sharing.
•Effectively manage project financials, including purchase orders, internal labor, capital/expense breakdown, actuals, and accurate monthly forecasting to minimize cost variance.

YOU MUST HAVE

•Bachelors Degree in Computer Science, Engineering, or a related discipline with atleast 8 years of experience managing Programs/large complex data projects
•At least 2 years of hands-on experience managing project financials and related metrics, including purchase orders, internal labor, capital/expense breakdown, actuals, and accurate monthly forecasting to minimize cost variance
•At least 2 year of hands-on experience managing projects using agile concepts, practices and tools
•Strong leadership, project and change management skills
•Ability to deliver on complex situations or problems without guidance or supervision, driving ""fast and right"" results in matrixed environment

WE VALUE

•Experience delivering Data Mastering or Analytics projects
•Experience in Agile and Waterfall project management methods
•PMP certification preferred
•Agile certification preferred
•Wide and deep understanding of key program management practices with strong business acumen and customer focus
•Consistently makes timely decisions even in the face of complexity, balancing systematic analysis with decisiveness
•Ability to create business value through project planning and management
•Conveys information with clarity and directness, ensuring the message is understood across diverse, global teams
•Mentor and guide peers on project management standards and tools
•Conveys specific, observable, and/or measurable expectations for each assignment, and verifies understanding and agreement on deliverables and timeframes.

CORP IT 2020

Additional Information
JOB ID: HRD94061
Category: Information Technology
Location: Devarabisanahalli Village, KR Varturhobli,,East Taluk - Phase I,Bangalore,KARNATAKA,560103,India
Exempt
Business Services",3.8,"Honeywell
3.8",Bengaluru,"Charlotte, NC",10000+ employees,1885,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"GE, Johnson Controls, United Technologies"
564,Principal Data Scientist,"Principal Data Scientist

Principal Data Scientist in Advanced Analytics for Real World Evidence and Clinical Outcomes will provide a high level of expertise in employing cutting-edge analytical & computational approaches to drive evidence-based pharmaceutical product development. He/She will provide scientific and technical leadership in machine learning and AI, and he/she will work closely with other disciplines across Sanofi including Business Units, Digital, R&D, Biostatistics, Information Technology Systems and other Data Science partners to deliver cutting edge analysis to key business questions. Examples of Advanced Analytics activities:
Machine/Deep Learning to elucidate disease trajectories, patient subtypes, define underdiagnosed conditions, and unmet health needs.
Create a framework for generating re-usable models and insights across big-data (e.g. EHRs, claims) and rich small data sets (e.g. clinical trials, imaging).
Generating insights by merging diverse data streams e.g. health, surveillance, trend data, sensor, imaging, …
Adoption of emerging technology into an analytical framework: distributed analytics, graph databases
People
Act as a subject matter expert in machine learning, statistical and/or modelling working on team projects and to advance internal capabilities by mentoring and advising junior colleagues.
Translate and appropriately champion advanced analytics results and capabilities to non-technical audiences.
Work with internal and external data scientists to scope and execute Advance Analytics projects.
Performance
Develop computational and statistical methodologies in Advanced Analytics for RWE & CO, - to be applied to pre-clinical, clinical trial, and complementary real-world information streams.
Maintain internal and external profile through contributions to congresses, publications, and external KOLs.
Provide expertise and execute advanced analytics for solving problems across R&D, Medical Affairs, HEVA and Market Access Strategies and Plans.
Process
Apply a broad array of capabilities spanning machine learning, statistics, mathematics, modelling, simulation, text-mining/NLP, data-mining to extract insights and be able to communicate and champion these efforts across the company.
Plan and deploy methodological standards, standardized processes, demos, and POCs for the company’s highest priority business needs.
Contribute to the design, development, and implementation of Sanofi’s data science architecture and ecosystem to guide decision-making and building foundational capabilities
Required Skills & Experiences:
High level proficiency in at least two or more technical or analytical languages (R, Python, etc..).
Extensive experience with advanced ML techniques (neural networks/deep learning, reinforcement learning, SVM, PCA, etc.).
An ability to interact with a variety of large-scale data structures e.g. HDFS, SQL, noSQL
Experience working across multiple environments (e.g. AWS, GCP, Linux) for optimizing compute and big data handling requirements.
Experience with any of the following: biomedical data types/population health data/real world data/novel data streams relevant to the pharmaceutical industry
Experience with big data analytics platforms or high-level ML libraries such as H2O, SageMaker, Databricks, Keras, pyTorch, TensorFlow, Theano, DSSTNE or similar
Strong oral and written communication skills
A demonstrated ability to work and collaborate in a team environment, and a willingness to mentor junior colleagues.
Desirable Skills & Experiences:
Ability to prototype analyses and algorithms in high-level languages embracing reproducible and collaborative technology platforms (e.g. GitHub, containers, jupyter notebooks)
Exposure to NLP technologies and analyses
Knowledge of some datavis technologies (ggplot2, shiny, plotly, d3, Tableau or Spotfire)
Experience with advanced ML techniques (RNN, CNN, LSTM, GRU, Genetic Algorithms, Reinforcement Learning, etc.).
Qualifications
PhD or ScD in quantitative field such as Medical Informatics, Statistics, Applied Mathematics, Computational Biology, Computer Science, Engineering or related field with 3 years of industry or academic experience
Relevant Master’s Degree, with 5+ years of related industry experience
At Sanofi diversity and inclusion is foundational to how we operate and embedded in our Core Values. We recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our colleagues, patients and customers. We respect and celebrate the diversity of our people, their backgrounds and experiences and provide equal opportunity for all.",3.7,"Sanofi
3.7",Mumbai,"Paris, France",10000+ employees,1973,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Pfizer, GlaxoSmithKline"
565,Lead Data Scientist,"To be a key member of the Analytics team, working closely with data scientist, data engineers as well as business users to develop, maintain and automate delivery of model pipelines in our infrastructure. In this role, the person is expected to take on critical tasks such as productionizing, deploying and testing of machine learning & analytics models. The person will work closely and report to the lead data scientist in the team.

In this role, you will:
Spend > 75% of your time coding and implementing re-usable Machine Learning frameworks
Work with data engineers to source, analyse and engineer features
Work with data scientists to develop, test and deploy Machine Learning models
Keep up to speed with the latest industry and technology developments on Machine Learning

Basic Qualifications:
A degree in Statistics, Machine Learning, Computer Science, Data Science or related field
Familiarity with at least one major Machine Learning frameworks: Tensorflow, Pytorch, Keras, Scikit-Learn, Spark ML, etc.
Familiarity with Python, SQL and Unix/Linux Commands
Familiarity with Dockers, Kubernetes, REST APIs, AWS or similar cloud services
Familiarity with Distributed/Cluster computing environment like Spark

Preferred Qualifications:
Overall, 14+ yrs experience in IT Industry
Proficiency in the mathematics underlying Machine Learning
Ability to present complex technical information in a clear and concise manner to a variety of audiences
Minimum of 3-5 years working on Machine Learning models deployment",3.7,"DBS Bank
3.7",India,"Singapore, Singapore",10000+ employees,1968,Company - Public,Banks & Building Societies,Finance,₹500+ billion (INR),"OCBC Bank, Citi, Standard Chartered Bank"
566,Data Analyst,"Job Details
Job Name: Data Analyst
Required skills: Big Data,Python
Experience: 2 - 10 Years
Location: Chennai
Job Description:
JOB DESCRIPTION
* Use statistical analysis, machine learning, pattern recognition, and data visualization along with domain knowledge and subject-specific
models to solve science, engineering, and commercial problems
* Solve challenging data science problems by developing novel and/or adapting existing computational methods
* Debugging and performance tweaking in Python
* Taking ownership over parts of an application and collaborating on global issues Understand and enjoy working in a micro services based architecture

REQUIRED SKILLS
Python, Hands-on experience in PostgreSQL, SQL Server, Oracle, RESTFul, GIT, API, JSON, Statistical Analysis, Machine Learning, Pattern Recognition,
Data Visualization, Numpy, Pandas, Scipy, Matplotlib, Soup, Scrapy, Teradata, NoSQL, Redis, Elastic Search, Mongo, Django, Flask, Pyramid, SVN, Mercurial,
Linear Algebra and Optimization

DESIRED SKILLS
Hypothesis Testing, Monte Carlo Simulation, Clustering",3.3,"ARi
3.3",Chennai,"East Peoria, IL",501 to 1000 employees,2006,Company - Private,Architectural & Engineering Services,Business Services,₹500 million to ₹1 billion (INR),-1
567,Data Engineer,"Strong problem solving skills
Strong coding skills
Passion for building scalable, global, complex systems to solve problems with proven ability to deliver high quality software.
Solid understanding of Object-Oriented design and concepts.
Innovative and creative with Web technologies to build high performing websites and web services.
Demonstrated proficiency with AJAX, Javascript, CSS is a plus.
Do you want to define the future of Internet commerce?
Are you a top-notch software engineer with a creative flare, strong problem-solving skills, the drive to build and ship products often, a solid computer science foundation, and the desire to build Amazon's next generation Internet-facing technology? Come talk with us about joining our team to help our tax teams serve customers better.
Is your next project defining a world class Internet service?
With us, you will be building cutting-edge applications and services in an environment of highly distributed systems used by Amazon Tax teams. Your innovation will provide new functionality for millions of vendors/payees globally with a goal of making it easy to comply with tax regulations.
Are you ready to create systems to expand one of the world’s largest e-commerce engines?
If so, come be a member of Amazon’s Taskless Technology team. Taskless Tech builds software systems that ensure compliance for Amazon businesses and its subsidiaries and makes it easy for for millions of Amazon vendors including publishers, app developers, game developers, marketplace sellers, associates and others to comply for tens of billions of dollars in transactions. We're constantly looking for opportunities to expand capabilities in new geographies and new lines of business.
Can you work at the scale of the biggest Internet companies?
The solutions that you will deploy must scale to accommodate rapid processing and integration with large enterprise customers. However, to add to the challenge, the solutions must also support intuitive world class UI for Amazon Tax teams to pay millions of vendors.
Amazon is a premier place to build, deploy and operate Internet-scale services.
Join our development team to work hard, have fun and make history. You will join a highly technical and entrepreneurial culture defining and building a selling experience to complement Amazon’s world-class websites.
BS or MS in Computer Science or in a relevant Engineering discipline.
5+ years of industry experience
Strong analytical thinker who knows how to pick the right tool for the job
Knowledge of professional software engineering practices & best practices for the full software development life cycle, including
Agile methodologies, coding standards, code reviews, source control management, build processes, testing, and operations
Ability to communicate clearly and concisely with technical and non-technical customers in order to understand ambiguous problems and articulate technical designs and solutions to complex problem",-1,Amazon Dev Center India - Hyd,Gurgaon,-1,-1,-1,-1,-1,-1,-1,-1
568,SENIOR DATA SCIENTIST,"Location: Chennai / Bangalore

The Data Team is a boutique consulting firm with strong expertise in big data and data science. The Senior Data Scientist is a key role in the organization, and will be leading project delivery on data science projects or data products. The Senior Data Scientist is an important role within the organization responsible for providing expertise, thought leadership, mentorship and leadership in the area of statistical analysis, data analysis and data science. Accordingly senior data scientists are expected to a hands-on practitioners in business analysis, hypothesis generation, data preparation, relational modelling, statistical modelling, algorithm design and scalable machine learning and deep learning. They’ll be expected to provide deep expertise in these areas. In addition, Senior Data Scientists are expected to mentor data analysts and data scientists on project deliverables, and ensure quality and timeliness in the output. The Data Team offers high-impact work with diverse opportunities in the areas of data science for Senior Data Scientists to grow into roles such as business consulting. Prior experience in doing data science and managing data science teams is required for this role. Experience in working on large scale Hadoop databases is required for this role. Past experience in bots and API development, test driven development, continuous delivery are preferred. Client facing skills are considered a plus.

Required Skills
True depth of knowledge in statistics, machine learning, cloud platforms and databases
Critical thinking skills in business with the ability to confidently face clients and mentor data scientists
A highly imaginative mind set and the ability to formulate new and relevant hypotheses from the data
Ability to perform advanced statistical analysis on diverse data sets in Python, R, Scala and Java
Ability to implement scalable machine learning and statistical analysis algorithms with frameworks such as Spark, Tensorflow or Torch
Current knowledge of cloud technologies and architectures such as on Azure, and hands on skills in implementing machine learning algorithms at scale
Expertise validating and critically evaluating machine learning algorithms and their performance
Ability to work in a Linux environment, on cloud-based virtual machines and containers
Should have managed a team in past roles in a managerial setting, or directly faced clients
Excellent interpersonal, presentation and written communication skills
Education and Work Experience Requirements
Bachelor’s degree in computer science or applied mathematics (Master’s degree or PhD preferred)
Higher degree in business, statistics, machine learning or computer science is a plus
Between 8 and 10 years of demonstrated experience in the industry including significant prior experience in data analysis and data science
Relevant certifications in data science will be considered favorably",4.2,"The Data Team
4.2",Chennai,"Singapore, Singapore",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
569,Sr. Data Scientist,"EXPERIENCE:
2+years
JOB DESCRIPTION:
Experience in analyzing massive and complex structured and unstructured data sets.
Ability to extract, and clean data, visualize it, communicate it and utilize it.
Around 4+ years’ relevant experience with data mining/business intelligence/statistics/data analysis.
Practical experience with building Analytical/statistical/mathematical algorithms such as predictive modeling, Optimization, Simulation, multiple regression.
Strong ability and experience in crisp and powerful data visualizations methods and tools.
Excellent analytical, logical reasoning and problem solving skills.
TECHNOLOGY STACK:
Below skills are preferred not mandatory

Exposure in using SAS E-Miner/R/both with proficiency in SAS preferably

Hands-on experience and solid working knowledge of SAS (Macros, Base and EG), SQL, PL SQL, VB, VBA for MS-Excel.

Knowledge of Hadoop (and other big data technologies), SQL and Java/C/C++ is desirable.

Excellent understanding of technical architecture requirements for big data systems.",-1,Copiousminds,Mumbai,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
570,Software Engineering - Data Engineer,"Job Description:


Job Title - Software Engineer- Data Engineer

Looking for someone having strong hands-on experience with web service development, AI Model deployment to help data science team to do deep data analysis and data movement studies using AI/ML model training.

The Purpose of This Role

The Workplace Investing Data Engineering and Exchange AI Delivery Chapter team is looking for a Level 4 Data Engineer to join our team to help support our Healthcare AI team. This role is a jack of all trades Agile position where you will help with conducting deep data analysis; doing data movement, webservice development and AI model deployment; and performing some scrum master duties helping keep sub-squad team members organized and on track. You will partner with your teammates on our development team and peer data scientists to help do data research and movement to support gathering data to support AI/ML model training, be developing data flows to help feed productionalized models, performing systems integration activities deploy AI models and helping implement model measurement. If you have an inquisitive and consulting mindset, excellent SQL skills and experience in building and deploying data movement solutions and a passion for delivering innovative products and services that improve the lives of our customers, a career on the WI Minerva AI squad could be for you!

The Value You Deliver
Work with data scientists and business sponsors to understand the business use cases that need to be solved and then conduct data analysis to find the right data sources for the project and conduct data analysis to profile needed tables
Develop ETL workflows in Oracle, Hadoop and/or AWS/Snowflake using Informatica or Python to structure data for AI model training and development and to measure already deployed models
Develop data webservice APIs in Java or Python to feed into productionalized models.
Help peers with crafting value-oriented stories and help lead Agile Ceremonies (standups, review and retros) and preparing team status information for team stakeholders.
The Skills that are Key to this role
Proven track record of working in collaborative teams to deliver high quality data solutions in an agile environment, leveraging Scrum practices, tools and story writing
Superior SQL skills and experience performing deep data analysis on multiple database platforms
At least 2 years of hands on data movement/ ETL/ Data science experience
At least 1 year of hands on application and/or webservice development experience with Java and or Python
Extensive experience developing RESTful services with Java/ Springboot, and/or Python
Strong exposure with web fundamentals like HTML5, CSS, Angular and JavaScript and integration with responsive web applications.
Knowledge of CICD and SCM tools such as GIT/ Stash/ Udeploy/ Jenkins/ Docker/ Maven.
Unix/ Linux command line experience (with tools like WinSCP & Putty) is an important skill as is shell scripting
Data platform and data ETL development experience in one or more of the following:
Oracle Relational Data warehouse/ PL/SQL/ Informatica
Hadoop: Using Spark, Sqoop, Hive and/or Impala and analysis using tools like Hue
AWS: Data movement using native AWS tools such as Glue or tools like Matillion and familiarity with (Athena, Snowflake, Sagemaker)
Exposure to data visualization tools (e.g, OBIEE, Tableau, D3) a plus.
Experience with team collaboration and documentation tools such as Jira, Confluence, MS Teams, Sharepoint, Visio, Powerpoint required
The Skills that are Good To Have for this role
You are self-driven, highly motivated and a quick learner
You should have an analytical and consulting mindset- being fearless in asking engaging questions to help ease out requirements details and technical implementation options often from more senior team members and customers.
Excellent verbal and written communications skills.
You love working with data and are confident in your SQL skills
You are passionate about data and technology and have experience with or an interest in the Healthcare domain.
You have excellent attention to detail and have experience in drafting business value oriented user stories and a willingness to help facilitate Agile ceremonies
Company Overview

At Fidelity, we are focused on making our financial expertise broadly accessible and effective in helping people live the lives they want. We are a privately held company that places a high degree of value in creating and nurturing a work environment that attracts the best talent and reflects our commitment to our associates. We are proud of our diverse and inclusive workplace where we respect and value our associates for their unique perspectives and experiences. To know more visit : FMR India

Location : BLR - Manyata

Shift timings: 11:00 AM -8:00 PM IST

Certifications:
Category:
Information Technology",4.0,"Fidelity Investments
4.0",Bengaluru,"Boston, MA",10000+ employees,1946,Company - Private,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Charles Schwab, Vanguard, Citi"
571,Data Science Analyst,"Job Description

We are looking for a Data Science Analyst who will support our product, sales, leadership and marketing teams with insights gained from analyzing company data. The ideal candidate is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action.

Job Responsibilities
Work for managing the successful design, execution, and measurement of data initiatives across customer-facing engagements requiring advanced automation scenarios.
Applying data Science, ML algorithms, using standard statistical tools and techniques for solving client business problems.
Develop custom data models and algorithms to apply to data sets.
Working on advanced automation client use cases.
Interface and communicate with the onsite Program Managers.
Sort out business problems to translate into analytical questions to simplify and accelerate the solution development. Balancing excellent business communication skills with a deep analytical understanding is needed.
Job Requirements
Strong problem solving skills with an emphasis on product development.
Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
Excellent written and verbal communication skills for coordinating across teams.
Hands on experience in Statistical Techniques such as Decision Tree, Segmentation, Logistic and Multiple Regression, and others.
Preferred Qualifications
Bachelor’s degree in Engineering or equivalent work experience.
Overall 6-9 years of experience with at least a minimum 3 years working experience on any data-driven company/platform.
5+ years of hands-on experience in data visualization, analytics, or business intelligence.
2+ years professional experience in software development in languages like Java, Python, Scala.
Experience in data processing with Python, R & SQL.
Location

This position will be based out of our Kochi office, but will require visits to our client site in Portugal / Spain.",3.0,"GI Group Holdings
3.0",Kochi,"Wayne, NJ",1001 to 5000 employees,2001,Company - Private,Asphalt Product Manufacturing,Manufacturing,₹100 to ₹500 billion (INR),-1
572,Data Engineer,"Company Description

About Eurofins

Eurofins Scientific is an international life sciences company, providing a unique range of analytical testing services to clients across multiple industries, to make life and our environment safer, healthier and more sustainable. From the food you eat, to the water you drink, to the medicines you rely on, Eurofins works with the biggest companies in the world to ensure the products they supply are safe, their ingredients are authentic and labelling is accurate. Eurofins believes it is a global leader in food, environmental, pharmaceutical and cosmetics products testing and in agroscience CRO services. It is also one of the global independent market leaders in certain testing and laboratory services for genomics, discovery pharmacology, forensics, CDMO, advanced material sciences and in the support of clinical studies.

In over just 30 years, Eurofins has grown from one laboratory in Nantes, France to over 47,000 staff across a network of more than 900 independent companies in over 50 countries and operating more than 800 laboratories. Eurofins offers a portfolio of over 200,000 analytical methods to evaluate the safety, identity, composition, authenticity, origin, traceability and purity of biological substances and products, as well as providing innovative clinical diagnostic testing services, as one of the leading global emerging players in specialised clinical diagnostics testing.

In 2019, Eurofins generated total revenues of EUR € 4.56 billion, and has been among the best performing stocks in Europe over the past 20 years.

About Eurofins IT Solutions India Pvt Ltd

Eurofins IT Solutions India Pvt Ltd (A CMMI Level 3 Company) is a 100% full owned subsidiary of Eurofins. This young captive centre located in Bangalore was established in 2012 to be the largest IT Solutions group within Eurofins to cater to all the internal IT business needs. The primary focus of IT Solution group will be to develop the next generation LIMS (Lab Information Management system), Customer portals, Ecommerce solutions, ERP/CRM system & B2B platforms for various Eurofins Laboratories and businesses.

EITS India is a Young, Dynamic and Growing organization with lot of career growth prospects. We strongly believe that ‘Our people are our assets’ and we ensure that all our staff are provided with great work environment, good benefits and challenging Global projects to enable a fulfilling career. We are committed to provide enriching experience to our employees.

Job Description

POSITION TITLE: Data Engineer

REPORTING TO: Manager

REPORTING LOCATION: Bangalore

WORKING LOCATION: Bangalore

SUMMARY OF POSITION AND OBJECTIVES:

We are looking for a savvy Data Engineer to join our team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. Person in this role will support our software developers, database architects, data analysts and scientists as well as business owners on data initiatives and will ensure an optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives mainly based on event streams to support real time analytics and right presentation of it using tools like Tableau, PowerBI.

POSITION & OBJECTIVES:

Job description:
Create and maintain optimal data pipeline architecture
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and Azure ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Work with Data Visualization tool esp. Tableau, Tableau Desktop/ Power BI Desktop.
QUALIFICATIONS AND EXPERIENCE REQUIRED:

SKILLS REQUIRED:
Advanced working SQL knowledge and experience working with relational databases, mainly MS SQL, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Experience supporting and working with cross-functional teams in a dynamic environment.
Basic Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with Azure or AWS cloud services: EC2, EMR, RDS, Redshift
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with data manipulation languages: Python, R, (Power)Shell, etc.
Experience with the preparation of data for visualization (e.g. data profiling, data cleansing, volume assessment and partitioning, modeling data, etc.).
Experience of working on SSRS and SSIS, good to have SSAS.
Experience working with Data Visualization tools esp. Tableau (mandatory) / Power BI.
ADDITIONAL SKILLS REQUIRED:
Knowledge on NoSQL DB / MongoDB will be an added advantage.
Experience with cloud-based data sources (e.g. Dynamics 365, Azure DW, Azure SQL, Azure Data Factory).
Some experience and ability to learn how to work with unstructured data sources.
Experienced in interacting with business users to analyze the business process and requirements and transforming requirements into visualizations and reports.
Knowledge with the selection of appropriate data visualization strategies (e.g., chart types) for specific use cases. Ability to showcase complete dashboard implementations that demonstrate visual best-practices (e.g., color themes, visualization layout, interactivity, drill-down capabilities, filtering, etc.).
Knowledge of dashboard visualization development best practices.
Experience in gathering and translating end user requirements into effective efficient dashboards.
Experience in working in a fast-paced, dynamic and Agile development lifecycle
Experience in optimizing user queries and dashboard performance.
Proven experience in estimating work and break down implementations into tangible modules.
Good to have some experience in embedded analytics (i.e., embedding visual data analytics in other transactional and operational systems).
EXPERIENCE
Candidate with 5+ years of experience in a Data Engineer role
Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.
Candidate should be a technical hands-on person with proven experience.
Understanding of Product Development Lifecycle and Lean Agile Scrum Methodologies
Excellent Communication, Interpersonal and Presentation skills.
Fluent written and oral English is essential.
Methodology we have in place and expect to be used:
Scaled Agile, Lean, Kanban, Zero Defect development method
Daily Stand-ups with other developers directly involved
Scrum of Scrums, Innovation Sprints
Continuous integration
Automatic Build and Deployments
Automated Unit & Functional Testing
Follow Development guidelines and coding style
SonarQube based Static Code Analysis
Qualifications

Graduate degree in Computer Science, Statistics, Informatics, Information

Additional Information",3.3,"Eurofins Scientific
3.3",Bengaluru,"Luxembourg, Luxembourg",10000+ employees,1987,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹100 to ₹500 billion (INR),-1
573,Data Analyst,"Finaxar is a state-of-the-art technology company that provides platform driven SME working capital finance solutions. Our team comprises seasoned veterans from banking, supply chain management, data science and technology with proven track records. We are backed by 500 Startups, Monk’s Hill Ventures, as well as funds and family offices from Singapore, USA and Europe. Our solutions are built by people that understand small and medium enterprises’' financing challenges and strive to dramatically improve small businesses’ working capital financing to such a point that they won’t go back to the old ways of working.

Few links to know more about Finaxar:

https://www.visa.com.sg/about-visa/newsroom/press-releases/visa-names-finaxar-as-winner-of-visa-everywhere-initiative-2019-in-singapore.html

https://www.businesstimes.com.sg/asean-business/cathay-financial-indovina-bank-finaxar-tie-up-to-improve-sme-financing-in-vietnam

https://www.channelnewsasia.com/news/business/lazada-partners-finaxar-to-offer-financing-for-its-merchants-10649480

*********************************************************************************************************

Data Analyst will be responsible for performing the following tasks to the highest standards:
Perform all analytical and reporting related activities
Identify and formalize data sources, hypotheses, analysis concepts
Facilitate business review discussions to gain insights
Develop dashboards to gain real time insights, provide data visualization, to allow quick access to view and monitor operational and metric performances.
Present and deliver weekly / monthly / ad-hoc reports to management and key stakeholders.
Requirements
You must have a bachelor's degree in business, finance, information systems or a related field.
You should also have advanced skills in SQL and Microsoft Excel, Metabase. Knowledge of statistics would be plus.
In addition to technical skills, you must have the ability to prioritise tasks and manage time well. The ability to effectively communicate the results of your analysis is critical.
1-3 years of experience in the related field is desired.
Excellent written and oral communication skills with strong attention to detail
High level of initiative and willingness to learn on the job
Ability to manage multiple projects simultaneously
Able to keep up in fast-paced team environment
Ability to stay on task, meet deadlines and deliver projects on time
Show high level of organization skills on all tasks
Benefits
Technology culture of trust and empowerment
Competitive salary",3.2,"Finaxar
3.2",Pune,"Singapore, Singapore",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
574,Principal Data Scientist,"Location:: Anywhere in India (remote)
Key skills:: Machine Learning Algorithms

Desired Candidate Profile::
We are looking for AI engineers who are as passionate as we are about artificial intelligence, advancing science, and inventing the next generation of intelligent machines.
We are hiring for candidates with 4+ years hands on development in experience in ML/AI.
Knowledge in a broad range of machine learning areas, including: Deep learning, including novel architectures with attention and memory, supervised learning, semi-supervised and unsupervised learning, including generative models, Reinforcement learning, Meta-learning, Multi-task learning, transfer learning, few-shot learning, continual/lifelong learning, Interpretability, fairness, accountability of machine learning models, Brain-inspired machine learning algorithms, Optimization for AI/ML, Bayesian learning, graphical models, and causal models. Familiarity with Big Data ML toolkits, such as Tensorflow, Spark ML, or H2O
You will work on the most cutting-edge, exciting projects that have immediate use in the industry. Your creativity and innovative problem solving will be essential to the success of our team and the company.
Reach out to us if you have solved real-life problems at scale utilizing message queueing (Apache Kafka, MS EventHub, or equivalent) and streaming event processing technologies (Apache Storm, Apache Spark, or equivalent), applied machine learning and AI algorithms to very large datasets at scale.
Education:: - Bachelors/ Masters / Phd
We think the knowledge acquired by earning a doctorate or master’s degree in Computer Science with AI as a specialization would be of great value in this position, but if you're smart and have the experience that backs up your abilities, for us, talent trumps degree every time
Company Profile: This is the right place for you, if want to work in
A Data Science and Big Data technology start-up.
A place where you would want to create value for yourself, and our customers
An environment that supports your personal growth
Culture that believes the greater priorities in life are family, health and integrity
Group of the best in class professionals who are excited about the work they do
Contact::
Sangeetha: sangpraman@gmail.com, +919655998843",-1,CereSight,India,"Tiruchirappalli, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
575,Senior Data Engineer,"Department overview:

At IHS Markit Automotive, were currently investing in our technology and data platform to develop new revenues generating products, leveraging open source and big data technologies. These include new data integration, advanced analytics, visualization, aggregation and smart data initiatives that address new customer needs and are highly visible and strategic within the organization.

These initiatives are using best of breed technologies, such as Hadoop, Spark, Cassandra, Kafka, and AWS along with in-house developed technologies. The successful candidate will be working in a fast paced, dynamic team environment, building brand new commercial products which are at the heart of our business.

Position summary

The candidate will work along with product managers, technology leads, data scientists and analysts to develop new products and improve existing products that generate key insights on industry trends by building data pipelines, building data & technology eco-system for machine learning algorithms & dashboards and addressing various data engineering requirements using best of breed technologies. The person will need to coordinate with Product managers, Industry Analysts, Data Scientists and Technology experts to develop and deliver the product in accordance with customer requirements and agreed timeline.

Duties & accountabilities
Build, improve & maintain data pipelines and data eco-system to support variety of analytics done by Data Science team
Drive data engineering tasks of new product build or improve existing products
Work under limited supervision and communicate effectively to set achievable expectations, to have a tight control over timelines and quality of work output
Understand the need from the stakeholders and fellow analysts and translate the need into design and develop the systems based on the design
Develop systems in various languages like Python, R or SQL
Be very curious and motivated to support various advanced aspects of analytics
Continuously learn and translate those learnings into improvements to benefit Data Science solutions
Business competencies

Education and experience
Minimum education requirement of four year degree in an Engineering or a computer science or a quantitative discipline. Additional education is preferred.
3+ years of experience in building business analytics solutions with end-to-end responsibilities on data modelling, ETL/ELT and reporting.
Solid knowledge of both Big Data and relational database technologies
Excellent SQL Skills
Proficient in Python
Experience in R preferred
Experience in one of the BI tools like Tableau/Qlikview/Spotfire
Experience working with cloud tools preferred
Excellent written and spoken communication skills
Commercial awareness

NA

Management requirements

NA

Personal competencies

Personal impact

Should be able to work in a team and independently. Should be able to partner effectively with team members in various geographic locations and time zones

Communication

Excellent written and spoken communications skills

Teamwork

Should be able to work in a team and independently. Should be able to partner effectively with team members in various geographic locations and time zones

-----------------------------------------------
IHS Markit is committed to providing equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by the laws and regulations in any of our locations.

We are proud to provide reasonable accommodations to applicants with disabilities. If you are interested in applying for employment with IHS Markit and need special assistance or an accommodation to use our website or to apply for a position, please contact or call +1 212 849 0399. Determination on requests for reasonable accommodation are considered on a case-by-case basis. This contact information (email and phone) is intended for application assistance and accommodation requests only. We are unable to accept resumes or provide information about application status through the phone number or email address above. Resumes are only accepted through the online application process, and only qualified candidates will receive consideration and follow-up.

IHS Markit maintains a substance-free workplace; employees may be asked to submit to a drug test (where permitted by law). In addition, as a federal contractor in the United States, the company participates in the E-Verify Program to confirm eligibility to work.

For information please click on the following links:

IHS Markit Business Code of Conduct
Right to Work
EEO is the Law
EEO is the Law Supplement
Pay Transparency Statement

-----------------------------------------------

Current Colleagues

If you are currently employed by IHS Markit, please apply internally via the Workday internal careers site.",3.5,"IHS Markit
3.5",Bengaluru,"London, United Kingdom",10000+ employees,2016,Company - Public,Consulting,Business Services,₹100 to ₹500 billion (INR),"Thomson Reuters, International Data Group"
576,Data Engineer,"Bachelors/Masters in Engineering, Computer Science or equivalent experience
8+ years of experience in the IT industry, experience in the Data space is preferred.
Work experience in Teradata system (Certified Teradata developer is a plus); Should have strong SQL programming skills
Advanced Shell scripting experience
Working knowledge on any ETL tool (i.e. Informatica/ AbInitio) is preferable.
Knowledge of Scheduling Tools is a plus
Excellent written and oral communication skills
Strong analytical skills including the ability to define problems, collect data, establish facts, and draw valid conclusions
Expertise in database programming and performance tuning techniques in Teradata is a plus
Familiar with data movement techniques and best practices to handle large volumes of data
Experience with data warehousing architecture and data modeling best practices
Experience with File Systems, server architectures, and distributed systems
Strong communication skills and willingness to take initiative to contribute beyond basic responsibilities
Experience to any of the BI tool such as (QlikView, Tableau, Micro strategy, Business Objects).
Knowledge of Big Data (Hadoop/Spark/HBase/Hive) or Java is highly preferre",3.6,"PayPal
3.6",Chennai,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple"
577,"Data Scientist, full stack developer","we are searching Data Science and Chatbots Trainee Employees For our Organisation.
Fresher & Experience can also apply

qualification: BCA, MCA, B.E (appering students can also apply for this )

https://forms.gle/W4hJNMF2brGd8ShN9

Job Type: Full-time

Salary: ₹85.00 to ₹304.00 /hour

Experience:
work: 1 year (Preferred)
total work: 1 year (Preferred)
Education:
Secondary(10th Pass) (Preferred)",-1,A square technologies,Bhopal,"Noida, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
578,AI/Machine Learning Engineer (Premium Colleges only),"Requirements

We are looking for applicants with a strong background in Analytics and Data mining (Web, Social and Big data), Machine Learning and Pattern Recognition, Natural Language Processing and Computational Linguistics, Statistical Modelling and Inferencing, Information Retrieval, Large Scale Distributed Systems and Cloud Computing, Econometrics and Quantitative Marketing, Applied Game Theory and Mechanism Design, Operations Research and Optimization, Human Computer Interaction and Information Visualization. Applicants with a background in other quantitative areas are also encouraged to apply.

We are looking for someone who can create and implement AI solutions. If you have built a product like IBM WATSON in the past and not just used WATSON to build applications, this could be the perfect role for you.

All successful candidates are expected to dive deep into problem areas of Zycus’ interest and invent technology solutions to not only advance the current products, but also to generate new product options that can strategically advantage the organization.

Skills:
Experience in predictive modelling and predictive software development
Skilled in Java, C++, Perl/Python (or similar scripting language)
Experience in using R, Matlab, or any other statistical software
Experience in mentoring junior team members, and guiding them on machine learning and data modelling applications
Strong communication and data presentation skills
Classification (svm, decision tree, random forest, neural network)
Regression (linear, polynomial, logistic, etc)
Classical Optimization(gradient descent, newton raphson, etc)
Graph theory (network analytics)
Heuristic optimisation (genetic algorithm, swarm theory)
Deep learning (lstm, convolutional nn, recurrent nn)
Must Have:
Experience: 1-9 years
The ideal candidate must have proven expertise in Artificial Intelligence (including deep learning algorithms), Machine Learning and/or NLP
The candidate must also have expertise in programming traditional machine learning algorithms, algorithm design & usage
Preferred experience with large data sets & distributed computing in Hadoop ecosystem
Fluency with databases
Benefits",3.3,"Zycus
3.3",Bengaluru,"Princeton, NJ",501 to 1000 employees,1998,Company - Private,Computer Hardware & Software,Information Technology,₹500 million to ₹1 billion (INR),"SAP Ariba, GEP, Coupa Software Inc"
579,Lead Decision Scientist,"PayPals Next-Generation Platforms Consumer Risk team is responsible for assessing and managing buyer-side financial risk exposures for this $8 billion portfolio (including identity theft, stolen financials, account takeover, and credit risk), as well as developing and implementing the policies, treatments, and experiences related to the management of these exposures. The team is also responsible for partnering with the corresponding Business Units to align with and influence their strategic priorities, educate business partners about Risk management principles, and collaboratively optimize the Risk treatments and experiences for these unique products and partners.

Each Decision Scientist on this team has full ownership of a portfolio of merchants and is responsible for end-to-end management of loss and decline rates. Day-to-day duties include data analysis, monitoring and forecasting, creating the logic for and implementing risk rules and strategies, providing requirements to data scientists and technology teams on attribute, model and platform requirements, and communicating with global stakeholders to ensure we deliver the best possible customer experience while meeting loss rate targets.

Scope of Responsibility:
Works independently and proficiently. Accountable for own results. Reviews are mainly for consultation and sharing ideas
Works on multiple assignments simultaneously and in all areas of a standard project in the area of responsibility
Focuses primarily on how to achieve overall analytic objectives of a project with speed and quality.
Suggests ideas for operational plans and objectives
Clear subject matter expert within group / geography
Works independently and proficiently on multiple assignments simultaneously with speed and quality
Mentor junior decision/data scientists.
Job Requirements:
Strong analytical skills -- ability to build quick estimates using back-of-the-envelope analysis, structure (and, if needed, execute) more complex analyses, pull together business cases and forecasts to navigate through multi-dimensional sets of tradeoffs.
Enthusiasm for data-driven problem solving within a fast-paced environment is a must. In addition, experience with Microsoft Excel or statistical software, working knowledge of SQL or other relational database languages, and hands-on experience in data analysis involving large data sets are strongly desired Work experience at the management consulting firms is a plus.
Polished communication and influence skills risk decision scientists need to collaborate cross-functionally with product managers, data scientists, business owners, and customers to learn from subject-matter experts, present findings in a clear and concise manner, and reach alignment on how to execute risk strategies. Demonstrated ability to influence groups and effectively resolve conflicts is required.
An innate intellectual curiosity, and a willingness to build awareness of current payments industry and risk management best practices. PayPal is constantly innovating by introducing new products and entering new markets, so successful risk analysts on this team must quickly get up speed on new content areas. You will be expected to become an expert in your specific domain.
Can-do attitude, team player, energetic personality, ability to work well under pressure in a fast-paced and constantly changing environment to meet deadlines. The successful risk analyst is a self-starter who has the resilience to learn from their mistakes and reach their true potential.
Identify typical problems and issues during normal course of work and take proactive actions to solve them with minimum guidance. Recommends changes to policies and establishes procedures that affect immediate organization(s).
Exercises discretion in resolving a variety of issues in imaginative as well as practical ways.
Impact of decision has moderate to large reach
Offers insight for and contributes to improving existing technology, tools, processes, and business solutions. Adds value to brainstorming sessions
BS/BA degree with 8+ years of related professional experience or masters degree with 6+ years of related experience or Doctorate with 4+ years of related experience.",3.6,"PayPal
3.6",Bengaluru,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple"
580,Machine Learning Engineer,"About Us:

Paxcom a leading Digital Solution Provider is a part of PaymentUs now, a leading electronic bill payment provider. PaymentUs leads the North American marketplace in electronic bill payment solutions and have recently signed partnerships with Paypal and Alexa.

We are looking for passionate programmers skilled in Java, Python, Angular, Dotnet, NodeJS, Python, Jenkins, Postgresql, Docker, Kubernetes, Spark and AWS to join our development team.

For more details please visit https://paxcom.ai/

Job Description:
In this position, the AI/ML Specialist will work with stakeholders and technical team members to deliver capabilities through agile acquisition, by leveraging advanced latest technology.
Must have at least 2+ years relevant experience in Data Science / Engineering
BS, Master's or PhD in data science, math, computer science, or a related field
2+ years of machine learning experience.
Experience with machine learning and artificial intelligence techniques and their implementations in open source technologies.
Experience in retrieving, manipulating, fusing, and exploiting multiple structured and unstructured data sets from various sources.
Experience with analyzing large volumes of data using distributed processing architectures with open source tools (e. g. Spark, Python, or R).
Should have leverage knowledge of data science, methodologies, and processing techniques to analyze vast amounts of chat data for monitoring & support.
Work with an agile team to develop machine learning analytics across different domains where chat has been implemented.
Experience with performing statistical analysis, data mining, temporal and pattern analysis,correlation of events, predictive modeling, and pattern recognition for various use cases.
Good with document and visualize analytics both temporally and spatially, and present analytic results and uncertainty to decision-makers.
What we expect from you?
You have the ability to work in a fast-paced environment adapting to changing priorities
You are focused and detail oriented but know when to seek help from others
You have excellent written and verbal communication skills to articulate problems and solutions to both technical and non-technical audiences
You possess superior troubleshooting and analytical skills to determine the root cause of issues
You strive to identify areas of improvement and work proactively to prevent issues from occurring
You are a self-starter with an appreciation for tackling technical challenges of varying complexity
You are diligent when making decisions and can easily justify your actions.
Why Join us?
You hate micromanagement and freedom to work is important to you
Enjoy flexible and relaxed work environment
Work life Balance is important to you
Enjoy Motivating Working Conditions
A friendly, Supportive, Professional and achievement-oriented management team
Competitive remuneration
An opportunity to learn new things every day and work on latest technologies",3.7,"Paxcom India Pvt. Ltd
3.7",New Delhi,"Gurgaon, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
581,"Data Scientist, Pratham Digital","Pratham Education FoundationData Insight & Analytics

About Pratham

Pratham was founded in 1995, to provide pre-school education to children in Mumbai slums. Over the last 20 years Pratham has grown to be India’s largest NGO working to provide quality education to underprivileged youth and children in over 21 states and union territories across the country, with a range of interventions.

Pratham is a widely recognized organization, having received notable awards such as the WISE Prize for Innovation, Skoll Award for Social Entrepreneurship, the Henry R Kravis Prize in Leadership and the CNN-IBN Indian of the Year for Public Service. For more details, refer to www.pratham.org

About Pratham Digital

Pratham started its digital intervention with the Hybrid learning program in 400 villages of Rajasthan, Maharashtra and Uttar Pradesh in the year 2015. In 2017 with the support of Google.org, and Sarva Mangal Family Trust this program expanded to over 1000 villages. The support led to the formation of core groups within Pratham which produced over 350 videos in and about 70 learning games and software needed to deploy and monitor digital resources in the village communities. These resources are present in 10 regional languages and English

Subsequently, the digital resources were also made available in Pratham’s foundational learning camp programs and also in the Early Childhood Education support program on an experimental basis. The digital learning material (games and videos) created for different age groups is available on Google Playstore as the PraDigi app, which was launched in October 2017 along with Youtube and other learning platforms.

The digital hardware and software are currently available in various Pratham programs across 21 states with content in 11 languages including Punjabi, Assamese, Bengali, Odiya, Telugu, Tamil, Kannada, Marathi, Gujarati, Hindi and English. The games are developed in HTML5/JavaScript on that they can be embedded on web pages for an online version or used on desktops in an offline version.

Data Scientist – Job Description

We’re looking for talented people who will put our goal to develop innovative educational methodologies at the center of everything we do.

We need a data scientist who will help us discover the information hidden in vast amounts of data that we have collected over the years, and help us make smarter decisions to deliver even better products and content. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality automated assessment tool using machine learning techniques.

Responsibilities

Think creatively and identify opportunities to leverage machine learning in order to improve a learner’s learning experience
Creating automated student assessment system and constant tracking of its performance
Use advanced technologies such as speech and vision synthesis to evaluate non textual response to questions for assessing soft skills.
Ability to use NLTK and identify words related to the defined keywords would be critical
Ability to use NLP to provide feedback on learner response
Translate and summarize complex analysis into understandable, actionable insights and recommendations that directly drive effective content delivery strategy
Data mining using state-of-the-art methods
Develop machine learning and other AI models with Python, R, or other languages and tools
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Work effectively in a team environment, as well as independently, to deliver against key initiatives
Take initiatives and drive each project to completion with minimal guidance while effectively managing multiple projects at a time
Contribute to a positive and supportive team culture.
Work closely with our software engineers to put algorithms into practice
Mentor and provide direction to other members in the team.

Desired Qualifications and Experience

Required:
Bachelors in mathematics, statistics, engineering or computer science or related field; Masters or PHD degree preferred.
5+ years of relevant quantitative and qualitative research and analytics experience.
Extensive knowledge and practical experience in several of the following areas: machine learning, statistics, NLP, deep learning, recommendation systems, dialogue systems, information retrieval
Skilled with Java, C++, or other programming language, as well as with R, MATLAB, Python or similar scripting language
Experience with common NLP techniques, such as Pre-processing (tokenization, part-of-speech tagging, parsing, stemming); Semantic analysis (named entity recognition, sentiment analysis); Modeling and word representations (TF-IDF, LSA, LDA, word2vec)
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.
Experience with data visualisation tools, such as Power BI
Proficiency in using query languages such as SQL
Experience with NoSQL databases, such as Datastore
Ability to articulate the strengths and weaknesses of various predictive modeling techniques
Strong understanding of statistical testing necessary to assess model performance
Great communication skills and ability to generate discussions around data analytics
Inquisitive mind and willingness to make the difference
Excellent track record of original research is highly desirable

Application Process

Send the following to digital@pratham.org (early applicants will be given preference) and mention ‘Application for the position of Data Scientist’in the subject line, with the following attachments:

1. Current Résumé: Résumé should contain:
Contact Information for Applicant
Academic Background, universities attended/degrees acquired
Past work experience, highlighting relevant skills
Languages Spoken",4.0,"PRATHAM Education
4.0",India,"Mumbai, India",5001 to 10000 employees,-1,Non-profit Organisation,Social Services,Non-Profits,Unknown / Non-Applicable,-1
582,Machine Learning Engineer,"Bengaluru

Qualification:
Any graduation

Experience:
2 – 4 years

Roles and Responsibilities:
Development of Machine Learning based application modules for integration in our xcPEP platform

Skills required-:
Data Acquisition and Validation
Experience in Text Analytics, developing different Statistical Machine Learning, Data mining solutions to various business problems and generating data visualizations using Python.
Experience in image processing and Optical Character Recognition
Working knowledge of PostgreSQL and mySQL
Linear Regression, Logistic Regression, Decision Trees, Random Forest, K-Means Clustering
Please write to us at careers@advancedstructures.in with (Machine Learning Engineer) in the subject line. Advanced Structures India Private Limited is an Equal Opportunity Employer",3.6,"Advanced Structures India Pvt Ltd
3.6",Bengaluru,"Bengaluru, India",51 to 200 employees,2014,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
583,Data Analyst,"Position Summary:
The Data Analyst is responsible for supporting activities associated with reporting and quality assurance of data in the technology development, implementation, and operational analysis. The data analyst will work to support a wide range of projects and requirements including report processing, data analysis, quality checking the data through generation of various reports, and working with customers to rectify data discrepancies and missing data in the operational processes. The data analyst must be able to use their analytical skillset to help prioritize development requirements with the highest value. The candidate will serve as the business mediator to the tech development team for all report related issues and enhancements. The Data Analyst will deliver business cases to schedule and develop reports using inputs from all functional areas of the company such as finance, operations, clinical, pharmacy services, etc.

Roles and Responsibilities:
Use data from company’s enterprise system to develop reports
Process information and data files to create invoices
Use BI tools and resources to Interpret data, analyze results using statistical techniques
Developing and implementing data analyses, data collection systems and other strategies that optimize statistical efficiency and quality
Acquiring data from primary or secondary data sources and maintaining databases
Provide support with management and maintenance of master data in the enterprise systems
Validate and Quality check sources of data, information, files, and consolidate them to create consistent reports
Develop, design, and maintain dashboards and reports for business owners in various functional areas such as Finance, Operations, Sales, etc.
Work closely with the technical team in extraction and development of data management tools and data to crate business/user friendly metrics, KPIs, and reports that can allow business owners to make decisions.
Produce actionable reporting products.

Technical Skills:
Proven work experience as a data analyst
Technical expertise regarding data models, database design development, data mining and segmentation techniques
Knowledge and experience to use statistical packages for analyzing datasets (Excel etc.)
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Expertise at resolving queries, report writing and present findings
Must have proficiency with MS Office and advance excel, internet and web-based applications
Strong writing skills for technical and business writing in ENGLISH

Specialized Skills:
Should be able to communicate effectively and confidently with business partners, project team members and senior management
Excellent verbal, written communication with the ability to develop and present information in various formats
Candidate should have ability to prioritize work, meet deadlines and work independently. Additionally, should be proactive to handle multiple projects and activities in a timely manner
Detailed experience in data management and reporting tools and applications
Excellent verbal and written communication in English
Ability to work with US, UK, and Canada based business owners in a professional business conducive communication style

Professional Experience:
0-3 years’ experience

Qualification:
Bachelor’s degree in any Analytics, Data, Business Intelligence or equivalent course.

Perks:
Monday to Friday – 5 Days work schedule
Health insurance benefits
Accidental and disability insurance benefits
Opportunity to grow and promote from within
Staff development activities

Do not apply if:
Unwilling to work in Night Shift. Must have proven experience in working with US based clients in the Night Shift
Not able to work on Advanced Excel
Not fluent in speaking, reading, writing English as this position requires fluent English language-based communication.",3.3,"kyte Tech Consulting LLP
3.3",Ahmedabad,"Ahmedabad, India",51 to 200 employees,2015,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
584,Data Science : Senior Associate,"2-4 years overall experience with minimum 1-3 years in Analytics delivery experience with hands on quantitative research + statistics +Presentation
Passionate about solving business problems, providing business Insights, and statistics, well versed with multivariate/ forecasting/ and who is capable of proactively suggesting clients and helping analysts to apply them to solve biz. problems
Need to have data mining skills (including data auditing, aggregation, validation and reconciliation), advanced modelling techniques, testing and creating and explaining results in clear and concise reports.
Advance statistical tools (Regression, Forecasting etc.), Machine Learning, Analytical tools (Clustering, Basket analysis, Decision trees, Random forest etc.)
Apply advanced statistical and predictive modeling techniques to build, maintain, and improve decision systems.
Broad understanding and experience with real-time analytics and business intelligence platforms such as Tableau/Power BI etc.
Should be able to work with SQL databases and several programming languages and statistical software packages such as Python, R, Java, MatLab or SPSS
A degree in a relevant subject is highly desirable e.g mathematics, data analysis, natural science, process analysis etc
Certifications in advance analytics skills is good to have
Experience on HR & Operations analytics preferred.
Should be ready to work in a dynamic and changing environment with changing requirements from time to time.
Strong communication skills, both verbal and written",3.8,"Mindtree
3.8",Bengaluru,"Bengaluru, India",10000+ employees,1999,Company - Public,IT Services,Information Technology,₹50 to ₹100 billion (INR),"Infosys, Tata Consultancy Services, Wipro"
585,Data Engineer,"COMPANY

DigiCert, Inc.

POSITION

Data Engineer

LOCATION

Bengaluru

ABOUT DIGICERT

DigiCert is a leading provider of scalable security solutions for a connected world. The most innovative companies, including the Global 2000, choose DigiCert for its expertise in identity and encryption for web servers and Internet of Things devices. DigiCert supports SSL/TLS and other digital certificates for PKI deployments at any scale through its certificate lifecycle management platform, Central®. The company has been recognized with dozens of awards for its enterprise-grade management platform, fast and knowledgeable customer support, and market-leading growth. To know more about DigiCert https://www.linkedin.com/company/digicert-inc-/life/?viewAsMember=true

Key Responsibilities

Design, build, and maintain a flexible and reliable Python code base
Collaborate with other internal teams to design data pipelines from different systems to our data warehouse.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Identify bottlenecks and implement fixes to maintain optimum data pipeline architecture
Load test pipeline to recommend modifications to help with scaling.
Make continuous improvements to the data warehouse architecture to support DigiCert's growing data needs
Enhance the existing monitoring framework and add new monitors to gauge the health of the data pipeline and data warehouse
Share team responsibilities for all aspects involved with maintaining a high level of uptime
Requirements

Bachelor's Degree preferred or equivalent
5+ years' experience developing data platforms in Python
2+ years' experience with CI/CD engineering
2+ years' experience working with MySQL
Familiar with object-oriented programming concepts
Good understanding of API connections and concepts
Have experience working with ETL (Extract, Transform, Load) pipelines
Experience using GIT for version control
Experience with JSON, PHP is a plus
Experience in cloud services is a plus (AWS - RDS, EC2)
Experience in developing large scale data structure and pipelines is a plus
Experience working with Cassandra is a plus
Experience working with BI tools such as Tableau, DOMO is a plus
Ability to take ownership and initiative on projects
Methodical, risk averse and process oriented",3.8,"DigiCert
3.8",Bengaluru,"Lehi, UT",1001 to 5000 employees,2003,Company - Private,IT Services,Information Technology,₹10 to ₹50 billion (INR),"GlobalSign, Comodo, Entrust Datacard"
586,Senior Data Scientist (10 to 15 years),"They are looking for Senior Applied Scientist to be based at Bangalore with the following skills: Â

â€¢Total 10 to 15 years of industry experience in predictive modeling and analysis Good skills with programming languages, such as Java or C/C++
â€¢Must have experience using Python and/or R, able to write production level code, which is well-written and explainable.
â€¢A successful candidate will be a person who enjoys diving deep into data, doing analysis, discovering root causes, and designing long-term solutions.
â€¢Must have experience in helping to build production systems that take inputs from multiple models and make decisions in real time.
â€¢Must have experience in delivering ML / DL projects from beginning to end, including understanding the business need, aggregating data, exploring data, building & validating predictive models, and deploying completed models to deliver business impact to the organization.
â€¢Masters/ PhD in a highly quantitative field (Computer Science, Machine Learning, AI, Operational Research, Statistics, Mathematics, etc.)

Kindly send your profile to tulsiarora(at)mysearch.in.net or call on 90361 39000
00-16.00 Years",-1,MY Search,Bengaluru,"New Delhi, India",1 to 50 employees,-1,Other Organisation,-1,-1,Unknown / Non-Applicable,-1
587,BA- Data Analyst,"Job Description

This entry level Data Analyst/Business Analyst require strong self-starters with data analysis & excel skills who enjoys the challenge of delivering projects within tight deadlines. CAPCO is looking for structured and organized individuals having the ability to manage multiple and often conflicting priorities. Role is specifically focused on small projects and strategic initiatives related to operational efficiency.

Candidates are expected to have -

A fair understanding and/or experience in banking operations or technology in a Financial/Capital Markets domain
Analyse financial documents and fill in an excel template with related information as directed by Capco UK Data model & QA team
Domain experience across key business areas of Trade Processing, Reporting, Banking Operations – at least one
Around 1-4 years of business analysis/data analysis experience at a Bank or Bank related engagements
Good communication to work across multiple remote locations
Excellent skills in MS Excel, MS Power-point, and MS Word

Attitudes and Initiative

Candidates need to be proactive, flexible and curious. Should be open to work in shifts (APAC and UK)",3.9,"CAPCO
3.9",Pune,"London, United Kingdom",5001 to 10000 employees,1998,Company - Public,Consulting,Business Services,₹50 to ₹100 billion (INR),"Deloitte, EY, Accenture"
588,DATA SCIENCE DEVELOPER IN TRIVANDRUM,Urgently Looking for an experienced Data Science Developer in Trivandrum Kerala Job Details * Develop andimplementdatabases data collection systems data analytics and other strategies that optimize statistical efficiency and quality *Acquiredata from primary or secondary data sources and maintain databases data systems *Identify analyze and interpret trends or patterns in complex data sets *Filter and quot clean quot data by reviewing computer reports printouts and performance indicators to locate and correct code problems *Work with management toprioritizebusiness and information needs *Locate and define new process improvement opportunities Job Requirements * IT Skills * Minimum one year experience is required * Bachelors Degree in Computer Science * Good Communication Skills,-1,Acuwin Innovations Pvt :Ltd,Thiruvananthapuram,-1,-1,-1,-1,-1,-1,-1,-1
589,Data Analyst,"Responsibilities:
He/she will work on Global MI projects
He/she will collaborate with counties’ team in risk management/analytics, data management, business operations, and DevOps
He/she will maintain the analytical database and build monitoring reports both regular and ad hoc based

Required skills:
Desired 1-2 years’ experience in BI
Proven problem-solving skills using logical reasoning and analytical methods
Advanced knowledge of Tableau, SQL, and R or Py
Working knowledge of AWS S3, ATHENA, GLUE, SAGEMAKER
What You Need for this Position

You should have knowledge of:
Tableau
SQL
BI tools(SSIS
SSRS
SSAS)
Aditional
No. of Positions
Education level
B.Tech
Career level
Experienced",4.8,"Bloom Consulting Services
4.8",Bengaluru,"Nagpur, India",1 to 50 employees,2015,Company - Private,IT Services,Information Technology,₹10 to ₹50 million (INR),-1
590,Data Analyst,"Department: AnalyticsQualification: BTech/BSc IT Reports to: VP Technology Skills : SQL + Tableau + R 2 to 5 years of experience in the Analytics industry. Experience in OTT sphere will be an added advantage. Data crunching, insights generation, strategic thinking. Good communication skills to convey technical and advanced concepts in precise and clearly understandable terms to a variety of audiences.

Requirements : Candidate should have strong analytical and logical thinking Should be able to work on a large dataset Able to write complex SQL queries to create an aggregate table Able to create dashboards in Tableau, also able to take care of the server side activities Must have knowledge of deck creation for upper management Knowledge of scripting language: Javascript would be an added advantage Submit your cv at careers@balajitelefilms.com",2.7,"altbalaji
2.7",Mumbai,"Mumbai, India",51 to 200 employees,-1,Company - Public,-1,-1,Unknown / Non-Applicable,-1
591,Data Engineer,"Job Title:
Data Engineer
Job Code:
SWTIND250118_24

Job Description / Responsibilities
Build workflows to ensure data extraction quality and storage into our backend data store
Architect, build and train ML/AI models that can predict outcomes and report on anomalies.
Design data pipelines to perform ETL on content/data from multiple types of source systems.
Create data analytics views using RDBMS/Key-Value stores, on private and public/cloud
Create software that is well tested, maintainable, extensible and scales out with large data
Minimum Qualifications:

2+ years of software development with Python
2+ years of SQL (MySQL/Postgres) and Key-Value databases
1+ years of experience with scikit
2+ years of experience in data extraction, data transformation using custom Python/Java
Experience working with MapReduce/Hadoop/kafka/Elastic stack
Experience with Node backend and React/Redux
Experience working with git/mercurial, Amazon/Google cloud, Linux/LAMP stack
Experience in testing or test driven development
Experience with Data science and Machine Learning algorithm development
Location:

Hyderabad/Bangalore
Package:

Highly competitive to match experience and capability",3.8,"T&VS
3.8",Bengaluru,"Bristol, United Kingdom",51 to 200 employees,-1,Company - Public,-1,-1,Unknown / Non-Applicable,-1
592,Data Engineer,"Data Engineer

Job Id
ED-AA-01

Designation
Analyst

Experience
1 – 3 years of relevant experience in the Analytics industry

Job Location
Pune

Academics
UG: B.E / B.Tech, PG: Post Graduation is not compulsory

Job Profile and Responsibilities

Responsibilities:


Interface with clients to understand high level as well as detailed project requirements and understand business problems.
Develop solution architecture to extract, transform and load data and other required solution to answer business questions, be responsible for end to end data management.
Manage client communication and meetings, documentation and other processes. Generate and communicate insights and project results to client, seek and incorporate feedback.

Should have hands-on experience in one or more of the followings:
Programming in Python, Java, JavaScript, PHP, Ruby, R etc
Frameworks and libraries like Pandas, Numpy, SQLAlchemy, Spark etc.
Data ETL tools like Talend, Alteryx etc.
Management and operation on databases like MySQL, PostgreSQL, MS SQL, MongoDB, Cassandra, Neo4j etc.
Cloud platforms like Amazon Web Services (EC2, Glue, Athena, RDS, Redshift etc.), Google Cloud Platform (BigQuery, Cloud SQL etc.), MS Azure (ADF, Azure SQL etc.)
Working with REST and SOAP APIs.

Desired Candidate Profile:


Eye for detail, passion for accuracy.
Great analytical and problem-solving skill.
Ability to adapt and thrive in a fast paced and demanding environment of a young start-up.",4.7,"Rudder Analytics
4.7",Pune,"Pune, India",1 to 50 employees,2015,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
593,Senior Data Scientist,"Responsibilities:
A keen desire to solve business problems, and to find patterns and insights within structured and unstructured data

Ability to work independently

Excellent written and verbal communication skills for coordinating across teams

A drive to learn and master new technologies and techniques

Strong ability to formulate business problems mathematically and strong problem-solving skills

Proven data manipulation skills

Have been active in the community in terms of articles / blogs / speaking engagements at conferences

Must Have:
At least 4+ years of experience in Data analysis and Hadoop stack development using various database technologies with recent 2+ years associated in Data science

Experience in Python or Scala, Spark, Linear Regression Modelling, Algorithms, Predictive Modelling, Statistical Model development.

Experience in implementing analytical solutions using programming languages, such as R, Python, Spark, Java and more, for solving analytical problems within engineering

Experience with data visualization tools and spatial analytics

Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications

Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks/ANN, RNN, CNN, Deep learning techniques, Image & Text processing, NLP etc.) and their real-world advantages/drawbacks.

Strong problem solving skills with an emphasis on domain usecase

Excellent written and verbal communication skills for coordinating across teams

Experience in use case related to Retail ,Telecom ,Banking",3.3,"TO THE NEW Digital
3.3",Noida,"Jakarta, Indonesia",51 to 200 employees,-1,Company - Public,-1,-1,Unknown / Non-Applicable,-1
594,Software Engineer - Data Science,"About the Department

Data Science

Summary of the Role

Software Engineer will be working as part of Data Science team to build and maintain scalable web crawlers to fetch data from multiple online sources.

Job Responsibilities
As a Python Developer, your role is to apply your knowledge set to fetch data from multiple online sources, cleanse it and build APIs on top of it
Develop a deep understanding of our vast data sources on the web and know exactly how, when, and which data to scrap, parse and store this data
Develop frameworks for automating and maintaining constant flow of data from multiple sources
Job Requirements
Strong coding experience in Python (knowledge of Java, Javascripts is a plus)
Experience with SQL and NoSQL databases
Experience with micro services, multi-threading and AWS/Azure
Strong knowledge of scraping frameworks such as Scrapy, Selenium,Portia etc.
Experience with web crawling is a must.
Experience with web technology, such as HTTP, JSON, HTML, XPath or JavaScript.
Experience with ELK(Elasticsearch, Logstash, Kibana) is plus.
Particulars Requirement

Experience 2-6 years

Education BE/B.Tech

Role Python Developer- Web Crawling/Software Engineer

Functional Area Software Development

Reporting to Rahul Kulhari

LOB Data Science

Group Software Engineer

Location Bangalore

Employment Type Full Time",3.7,"Edge Networks ATS
3.7",Bengaluru,"Bangalore, India",51 to 200 employees,2012,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
595,Data Analyst,"We are currently looking out for a Data Analyst for one of our Client.
Minimum Qualification

3 Openings
6 month-1 years of experience in data-analytics; experience in the e-commerce industry is preferred
Must have a firm grasp and analyst-level understanding of database structures and strong hands-on ability to write SQL queries for data exploration/aggregation
Must have demonstrated hands-on development experience using Tableau or similar analytics/visualization tools
Advanced Excel proficiency including Pivot tables, vlookup / hlookup, graphs etc.
Strong sense of urgency
Self-starter with ability to work in a fast-paced environment
Preferred Qualification
Data Driven: Sharp aptitude and excellent numerical acumen; ability to sift through large volumes of data
Communication Skills: Good written and oral communication skills with the ability to present and clearly explain data to non-technical audiences
Industry and domain expertise: Sound knowledge on various trends, relevant statistical tools and also have the ability to understand the business environment & grasp the business expectations.",5.0,"BLEUMING TECHNOLOGIES
5.0",Chennai,"Bengaluru, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
596,Business Intelligence Analyst _ Bangalore,"Job Description

The Business Intelligence Analyst will partner with the Sales Operations (based in the US) and Business Operations (based in US & Bangalore) to build the data infrastructure for analytical, planning and reporting needs. This is an exciting opportunity to join a fast-paced business at an exciting time where Kaseya is expanding both organically and through multiple acquisitions. The successful candidate will be strategic, analytical, and have a demonstrated ability to work with large amounts of data.

This position will be responsible for enriching the customer and financial database, creating various Key Performance Indicators and build reports to highlight the business performance both financially and operationally. The role requires a candidate with strong project management skills, communication skills and technical experience. The successful candidate will be comfortable working in cross-functional teams internationally. The ideal candidate must have superior attention to detail and the ability to successfully manage multiple competing priorities simultaneously. The position represents an exciting opportunity to be a part of an extremely dynamic and high paced environment, supporting a global organization and offers significant opportunities for rapid growth.

Primary Responsibilities Include
Develop and manage the financial and operational data warehouse of the company
Develop automated reporting on Power BI or a similar software
Sales and operational forecasting across multiple business entities
Partner with the business team to develop new ideas and creative solutions
Basic Qualifications

Bachelors degree in a computer science, business, economics, finance or similar discipline with analytical bias
2+ years of experience working with financial and operational data

Preferred Qualifications
MBA a plus
Technology / SaaS company experiences a plus
Experience working with Amazon Web Services
Strong leadership and people management skills
Knowledge of Business Intelligence tools (i.e. Power BI, Tableau, Looker, Domo)
Strong analytical skills
Process improvement experience
Superior attention to detail, project management skills and the ability to successfully manage multiple projects simultaneously
Proven ability to meet tight deadlines and prioritize workload
Candidates must also have fluency in standard software including Excel
Knowledge of SQL is highly desirable
Strong communication and presentation skills
Demonstrated experience in gathering, analyzing and synthesizing business requirements from multiple sources",3.5,"Kaseya
3.5",Bengaluru,"Miami, FL",501 to 1000 employees,2000,Company - Private,Computer Hardware & Software,Information Technology,₹10 to ₹50 billion (INR),"SolarWinds, CA Technologies"
597,Data Science Engineer,"Responsibilities:
· Partners with business stakeholders to translate business objectives into clearly defined analytical projects.
· Identify opportunities for text analytics and NLP to enhance the core product platform, select the best machine learning techniques to the specific business problem and then build the models that solve the problem.
· Own the end-end process, from recognizing the problem to implementing the solution.
· Define the variables and their inter-relationships and extract the data from our data repositories, leveraging infrastructure including Cloud computing solutions and relational database environments.
· Build predictive models that are accurate and robust and that help our customers to utilize the core platform to the maximum extent.

Skills and Qualifications:
· 3 years + of experience.
· An advanced degree in predictive analytics, machine learning, artificial intelligence; or a degree in programming and significant experience with text analytics/NLP. He shall have a strong background in machine learning (unsupervised and supervised techniques). In particular, excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, logistic regression, MLPs, RNNs, etc.
· Experience with text mining, parsing, and classification using state-of-the-art techniques.
· Experience with information retrieval, Natural Language Processing, Natural Language Understanding and Neural Language Modeling.
· Ability to evaluate the quality of ML models and to define the right performance metrics for models in accordance with the requirements of the core platform.
· Experience in the Python data science ecosystem: Pandas, NumPy, SciPy, scikit-learn, NLTK, Gensim, etc.
· Excellent verbal and written communication skills, particularly possessing the ability to share technical results and recommendations to both technical and non-technical audiences.
· Ability to perform high-level work both independently and collaboratively as a project member or leader on multiple projects.

Job Type: Full-time

Salary: ₹500,000.00 to ₹1,500,000.00 /year

Experience:
work: 3 years (Preferred)
total work: 3 years (Preferred)
Education:
Bachelor's (Preferred)",3.3,"Cognologix technologies
3.3",Pune,"Pune, India",51 to 200 employees,2016,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
598,Sr Data Engineer,"Job Description – Data Engineer

As Data Engineer, this role will be responsible for designing and implementing data pipeline to solve business problems

Roles & Responsibilities:
Create and implement data pipeline processes to support business problems.
Work with all stakeholders to review Data Model, Data Flows, high level ETL design, source to target data mapping document and be the point of contact for any questions on data pipelines
Develop & unit test ETL processes for optimal performance
Work with technical architects and developers to research and assess various technologies that can be used together to solve business problems
Understand and implement systems architecture and programming constructs such as APIs, data models and ER diagrams. .
Identify, analyze, and interpret trends or patterns in complex data sets
Focus on fast, iterative and agile development
Focus on performance,scalability, availability and security
A strong agile team member
Influences and applies data standards, policies and procedures
Prior experience handling terabyte scale data will be a plus
Skills:
Experience in Hadoop, Hive, MapReduce, Sqoop, Impala, Oozie and NoSql like hbase
Good knowledge on hadoop architecture, administration, hdfs file system, api, along with data warehousing concepts
Proficient in Python/Scala/Java
Exposure to Azure data flows/ETL is a plus
Data mapping competencies with strong knowledge of sql
Good in Relational database design and concepts
Proficient in one of the object oriented languages
Excellent understanding of data structures
Good in analytical and problem solving skills
Attention to detail
Good understanding of data lake concepts is a plus
Qualifications & Experience :
Bachelors or Masters degree in Computer Science or any relevant discipline.
At least 7 years of experience building large scale data systems

Apply for this Job",3.5,"CoStrategix
3.5",Bengaluru,"Cincinnati, OH",51 to 200 employees,2006,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
599,Data Analyst,"Job Description

Cerner is growing and currently looking for a Data Analyst. As a Data Analyst, you will analyze, prepare, and process data sets to be consumed for direct insights, statistical modeling or other analytical exploration for internal and external clients. You will also access and compile data sets from various sources for exploratory and pre-defined analyses, audit data sets for completeness, validity, and other pertinent data health measures, support evaluation of data sets for analytical possibilities and pitfalls, conduct basic statistical testing and exploratory data analysis and create basic data visualizations. You will be tasked with helping to put together presentations to help our teams make data-driven decisions while consulting with stakeholders and clients on analysis and outcomes.

Ultimately, your analytical skills strengthen business practices, so we can improve clinical and financial outcomes for health care organizations around the globe. You do this by managing and reviewing organizational data and metrics--considering all factors and drawing conclusions based on the numbers and the facts. Your end goal is to provide your organization with the tools it needs to make the best business decisions for our clients and partners.

Qualifications

Basic Qualifications:

• Bachelor's degree in Engineering or equivalent work experience
• At least 1 year of work experience in operational, clinical, financial or health care metrics

Preferred Qualifications:

• At least 1 year of experience in Data Science and hands-on programming experience in R/Python
• At least 1 year of experience in working with areas like Prediction (Regression and Classification), Text mining, Text Classification, Forecasting, and Clustering
• At least 1 year of experience in machine learning practice, in NLP area

Expectations:

• Willing to work on a flexible schedule as needed
• Ability to work overtime and irregular hours when needed
• Willing to travel as needed",3.6,"Cerner
3.6",Bengaluru,"Kansas City, MO",10000+ employees,1979,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"McKesson, GE Healthcare, Epic"
600,Deep Learning Scientist,"PositionDeep Learning Scientist

LocationMumbai, India
Role Summary
â€¢Execute and take ownership of deep learning projects end-to-end. Good exposure to various deep learning algorithms and frameworks
â€¢Understand the problem and the kind of data required and the format in which it is required and prepare the data using the relevant methodologies
â€¢Keep updated on latest research in AI and deep learning and find ways in which it can be used to solve business problems
â€¢Must be able to read research papers (eg: some novel architectures, training techniques, etc.) and be able to implement it fully to solve our specific problems
Essential QualificationMasters/PhD in a Quantitative & Engineering disciplines - Mathematics, Statistics, Physics, Computer Science, Electronics, and Data Mining etc.
BE/BTech
Experience2-5 years
Prior experience in implementing production-level deep learning projects is a must
Technical SkillsSkill Set
â€¢Must have worked on at least 2-3 real life Data science projects.
â€¢Expert user of Python/R and SQL
â€¢Hands-on experience in handling unstructured (image, video, audio) and build solutions using Deep Learning / Machine Learning
â€¢Experience in implementing object detection, GANâ€™s. Knowledge of reinforcement learning is a plus.
â€¢Good grasp and detailed knowledge of any one deep learning library (PyTorch, Tensorflow, etc) is a must
â€¢Strong interpersonal skill, entrepreneur mindset
â€¢Self-motivated, ability to handle ambiguity
â€¢Strong problem solving skills

Please contact R. ChandraShekar @ 9533601953
00-5.00 Years
Bachelor Of Technology (B.Tech/B.E), Masters in Technology (M.Tech/M.E/M.Sc)",3.1,"Talent Corner Hr Services Private Limited
3.1",Mumbai,"Mumbai, India",201 to 500 employees,2002,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
601,Battery Expert - Data Anaytics,"Business Analyst/BigData Expert - Pyspark/Python/Azure (6-9 yrs)Role : Data Scientist(DA)
Experience : 6 to 9 years
Job Location : Bangalore
Job Description for Data Analyst.
Ability to understand Azure Cloud setup, its libraries and the structure so you can advise stakeholders and provide guidance to team
Create, analyses and maintain Diagnostics/predictive/prescriptive statistical models.
Work includes all phases of the modeling process: Research, Architecture and design, data extraction and processing,ML model building, Visualization and validation.
To work through the entire life cycle of a project from Conceptualization to implementation.
Co-ordinate with different SMEs for seeking the inputs to explore data extraction approach and Work closely with endusers to understand their needs
Develop and maintain working relationships with key customer stakeholders
Skills Required :
Exp. Range -6-9 years of work experience in Microsoft Azure environment, Databricks, PowerBI and advance statistical analysis & data processing
Proficiency required in one or more of analytical tools such as Pyspark,Python, SQL ETL operations.
Understanding of cloud features including load balancing, networks and scaling is expected
Statistical modeling (Regression, Classification, Time-series forecasting) /Machine Learning /Optimization/Visualization
Knowledge on Machine Learning Techniques would be added advantage
Ability to move data around, from a database or an API, through a transformation or to a model and into human-readable form (ROC curve, Excel chart, map, d3 visualization, Tableau, etc.)
Knowledge on Automotive domain, especially Battery internals would be an advantage.

Basic Qualification:

· Bachelors/Masters in Engineering in EEE,ECE,CES or Data Science

· Strong mathematical background in statistics and machine learning for 6-9 years",3.5,"Mercedes-Benz Research and Development India Private Limited
3.5",Bengaluru,"Chakan, India",1001 to 5000 employees,1996,Company - Private,IT Services,Information Technology,₹10 to ₹50 billion (INR),"Volkswagen, Tata Motors"
602,Architect I - Data Science,"Job Title
Architect I - Data Science
Job Description


Key areas of responsibilities
Work with service innovation leaders and R&D leaders to identify opportunities for leveraging system log data to drive serviceability solutions
Designs the architecture and the analytics pipelines while taking into account appropriate time frames, and costs.
Mentors the team and reviews the content created by them
Mine and analyze data from system log central database to drive system diagnostics efficiency
Develop custom data models and algorithms to apply to data sets
Define strategy to develop predictive modelling to increase and optimize system diagnostics experiences
Contribute the technical road mapping for the team
Coordinate with different functional teams to implement models, processes, monitoring of data accuracy & outcomes
We are looking for Our ideal candidate is a driven professional who has a strong background in the following:
Overall 9+ yrs exp with minimum 6+ years of experience in delivering meaningful results through data analytics
Excellent written and verbal communication skills for coordinating across teams
Sufficient business acumen to understand business objectives & dynamics
Deep understanding and minimum 4+ years of hands on experience in developing models using Artificial Intelligence, Machine Learning and Deep Learning related technologies (such as Keras, TensorFlow, pyTorch, Azure ML, AWS ML, Scikit, Jupyter, MatLab etc.)
Developed & Proficient in algorithms on regression modelling (linear/logistic), supervised and unsupervised classification, tree-based techniques (Decision trees /Random forest), neural nets, bagging, Pattern Mining and boosting techniques, etc.
Strong hold of concepts in Statistics and expertise in Machin Logs Processing, text mining and text analytics.
Strong programming skills in R and Python
Nice to have
Working knowledge with NoSQL databases like MongoDB, PostgreSQL and Cassandra running huge volumes of data.
Knowledge on Data Integration/Ingestion/Processing/Analytics/Reporting & BI based Visualization.
Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Bengaluru,"Amsterdam, Netherlands",10000+ employees,1891,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),-1
603,Data Analyst,"Looking for Analyst

Any Degree

0-2yrs experience

must have analytical knowledge

must be good in excel

Expected Start Date: 1/6/2020

Job Type: Fresher

Salary: ₹144,000.00 to ₹180,000.00 /year

Experience:
work: 1 year (Preferred)
2 year: 1 year (Required)
Education:
Bachelor's (Preferred)",3.9,"WyzMIndz Solution Pvt Ltd
3.9",Bengaluru,"BENGALURU, India",51 to 200 employees,2010,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
604,Data Analyst,"Data Analyst


We are actively recruiting a few Data Analyst for our team in Chennai, India.

You would work alongside our newest client and be responsible for management information reporting and co-ordinating business intelligence for designated contracts, focusing on report creation, data manipulation and data integrity, data extraction, data analysis and determining information requirements and appropriate delivery methods to meet the customers’ needs.


Essential Duties and Responsibilities

Reporting
Develop a range of reports in various formats including Excel, PowerBI and PowerPoint etc. as requested from the Customer.
Collating, analysing and preparing Management Information reports and providing any ad hoc reports requested by Directors and Managers
Co-ordinating the delivery of key reporting and business intelligence to teams and internal stakeholders
Data Management / Analysis
Data validation, consolidation, segregation and extraction
Reviewing and improving report automation effectiveness through extensive use of VBA, Macros, Power Pivots and Data Models
Checking reports for accuracy prior to publication
Drawing conclusions from data, identifying key trends and making recommendations
Data entry and auditing
Personal Specification:

Relevant professional qualification or degree
Proven industry experience within a Data Analyst role with experience in MI report creation, co-ordinating business intelligence, and data integrity and data analysis.
Extensive experience working with MS packages with highly proficient knowledge of Excel formulas and functions
Good experience of compiling and editing Visual Basic for Applications (VBA)
Experience of creating reports in MS PowerBI
Good Analytical skills
Strong communication skills, both verbal and written
Excellent problem solver
High attention to detail
Multitasker",2.8,"GP Strategies
2.8",Chennai,"Columbia, MD",1001 to 5000 employees,1966,Company - Public,Consulting,Business Services,₹50 to ₹100 billion (INR),"IBM, Accenture, Raytheon Technologies"
605,Machine Learning Engineer,"Softnautics is looking for Senior Engineer who is technically strong, possesses hands-on experience in Machine Learning Solutions in domain of Audio, Video, IoT. He/She should have some experience working with complex (SoC / Microprocessor) Embedded Systems is mandatory for this role

The role will be part of Embedded department in which there is a very strong culture of teamwork, cooperation and collaboration

Experience

2 – 8 Years

Responsibilities

Mentor, lead and build the team of 3 or more engineers

Documentation and Process adherence

Technical ownership for module (s) and / or project (s) and / or domain (s)

Effort estimation, planning, customer Interaction

Person Specification

Required Skills & Experience:
1-3 years of leadership experience

2- 5 years of experience with Machine Learning Solutions in the domain of Audio, Video, IoT

3- 5 years of experience working with Complex (SoC / Micrprocessors) Embedded System

Strong at programming, debugging and communication

Sound knowledge of version control and bug tracking systems – GIT, JIRA, Perforce, CVS etc.

Hands on experience on Machine Learning Algorithms – Conventional and Deep Learning

Hands on experience working on Machine Learning Platforms / Frameworks like TensorFlow, TensorFlow Lite, Keras, Caffe/2, MxNet, pyTorch etch

Sound knowledge of Cloud Computing tools – Google cloud, AWS, Azure, IBM Cloud etc.

Experience working on Large datasets – Learning, tuning, deployment on Embedded Platform

Familiar with Deep Learning Compilers – CPUs, GPUs, FPGAs

Should be able to work in aggressive, high pressure environment

Excellent written and verbal communication

Self-starter, problem-solving mentality, and creative thinker

Desirable Skills:
Experience of leading the module with 1 or 2 engineers

Quality process – CMMi, Agile Scrum

Good knowledge of working with Open source software packages is beneficial and preferred

Positive attitude

Ready to switch between domains based on the projects",3.7,"Softnautics
3.7",Ahmedabad,"Santa Clara, CA",51 to 200 employees,2007,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
606,Data Analyst,"Greetings!!!

Job Summary:

Responsible for the Data Analysts in coordination with all the Department Heads and present the same to the Managing Director of the company for company’s overall strategy and goals.

Job Qualifications & Requirements:
 Graduation in relevant field
 Strong knowledge on MS Excel & MS Office
 Strong Analytical Knowledge and good with numbers
 Demonstrated success defining Data Analysis with PowerPoint Presentation
 Excellent communication skills
 Fluent in English language for Presentation preparation

Job Responsibilities:
 Should be able to mine the correct data, analyse it properly, correct data into information useful for core/strategic decisions of the company
 Monthly Sales Analysis which includes
o Value wise analysis
o Head quarter wise
o Brand wise
o SKU wise
o Therapeutic Area wise
Competition Analysis
 Pharmacy Sampling, Tracking & Analysis
 Daily Call report – Tracking & Analysis
 Notice Activity – Tracking & Analysis; Delegate wise
 Improved data management and reports in ERP for Marketing Analytics
 Updating Prescribes and Pharmacies analysis.

Thanks,
Regards,
Shivani Thakkar

Job Type: Full-time

Salary: ₹0.00 to ₹250,000.00 /year

Experience:
work: 1 year (Preferred)
total work: 1 year (Preferred)
Education:
Secondary(10th Pass) (Preferred)",-1,FLAGARANT SERVICES LLP,Ahmedabad,-1,-1,-1,-1,-1,-1,-1,-1
607,Data Engineer,"About Us:

Whatfix is disrupting the way Application Support and Learning content is consumed by providing Contextual and Interactive WalkThroughs inside enterprise applications at the exact time a task is being performed.

We provide enterprises with a Software Platform that allows them to create Interactive Guides or Flows that sit as an overlay inside any web application. Flows are Contextual - appear based on where you are in the application (location) and who you are (role). Optimal performance and adoption of any web application is attained when there is easy access to Contextual Information - inside the application at the time a task is being performed.

Your Opportunity:

As a part of the Whatfix Data Engineering team, you will be responsible for creating the Data Lake infrastructure from scratch and get your hands dirty by working on cutting edge tech stack.

Primary Requirement:
Strong experience in schema design and SQL
Knowledge of frameworks & distributed systems, good at algorithms, data structures, core java, design pattern.
Understanding & experience in technologies like Cassandra/Redshift/Hive
Must have built fault tolerant ETL pipelines
Worked with distributed data processing frameworks - Apache Spark, Apache Flink or Hadoop.
Knowledge of service oriented architecture
Deploying systems on the public cloud
Good analytical skills is a plus
Requirements
Bachelor’s/Master’s degree in Computer Science
Overall 3+ years of experience with at least minimum 1 year working experience on any data driven company/platform.
Strong understanding of different storage architectures and their appropriate application.
Exceptional problem solving, analytical and organisation skills with a detail-oriented attitude.
Passion for learning new technologies
A self-motivated learner and builder with strong customer focus and obsession with quality
Database performance concepts like indices, segmentation, projections, and partitions.
Good to have
Previously worked in a SaaS company
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status",4.2,"Whatfix
4.2",Bengaluru,"Bengaluru, India",51 to 200 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
608,Senior Deep Learning Data Scientist,"We are looking for the following kind of professionals to join our team. In case you are interested, please mail us your resume at team@numbertheory.ai

What you'll be doing in your new job:
Design, develop and deploy deep learning systems for Visual AI Problems
Analyse deep learning architectures and define architecture strategy
Deploy Models in production and enable auto retraining framework
Work on Model Deployment on Edge device
Optimally manage available resources such as compute hardware, edge memory and data
Define relevant metrices for model performance
Define data augmentation pipeline and pre-processing strategies
Implement appropriate Deep Learning algorithms and ability to debug neural networks
Study and reproduce DL prototypes/research papers

What are we looking for:
2-6 years of experience in Designing and Deploying Deep Learning Solutions
In-Depth knowledge of Deep Learning Architectures
In-Depth knowledge of Transfer Learning, Adversarial Learning
In-Depth knowledge of Image Processing and Computer Vision algorithms
Robust working knowledge with deep learning frameworks (like Tensorflow, PyTorch, Keras)
Excellent Python Coding Skills
Experience with GPU/CUDA programming
Worked on Edge side model deployment
Deeper understanding of math, probability, statistics and algorithms
Deeper understanding of data structures, data modelling, and software architecture
Understanding in Distributed Computing

Qualification: PhD in Computer Vision from premium institute

Notice Period: 15 days or 1 month",-1,Number Theory,Gurgaon,"Gurgaon, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
609,Data Engineer,"About Us

HealthifyMe was founded in 2012 by Tushar Vashisht and Sachin Shenoy, and incubated by Microsoft Accelerator. Today, we are India and South East Asia's largest and most loved health & fitness app, with over 16 Million users from 300+ cities in India+SEA and rated over 4.6/5. The HealthifyMe mobile app has been rated as the top Health/Fitness app on Play Store by Google for the last 3 years, and has received the prestigious 'Editor's Choice' badge by Google.Our coaching services are delivered by a world class team of over 500 coaches including nutritionists, trainers and yoga instructors. We combine the power of artificial intelligence and human empathy to deliver measurable impact in the lives of our consumers. We launched the world's first AI nutritionist 'Ria' with learnings developed from billions of data points on consumer lifestyles, coupled with 400 man-years of nutritionist/fitness intelligence.

HealthifyMe has raised over $25 Million in funding from marquee investors such as Sistema, IDG, Inventus, Blume and Samsung Next. HealthifyMe works with over 75 corporates across the country to deliver employee wellness solutions. We aspire to be a leading health and fitness platform across the globe.

Data Engineer Responsibilities
Design, construct, install, test and maintain data pipeline and data management systems.
Ensure that all systems meet the business/company requirements as well as industry practices.
Integrate up-and-coming data management and software engineering technologies into existing data structures.
Processes for data mining, data modeling, and data production.
Create custom software components and analytics applications.
Collaborate with members of your team (eg, Data Architects, the Software team, Data Scientists) on the project’s goals.
Recommend different ways to constantly improve data reliability and quality.
Data Engineer Requirements
Experience in a related field with real-world skills and testimonials from former employees.
Familiar with data warehouses like Redshift, Bigquery and Athena.
Familiar with data processing systems like flink, spark and storm.Develop set
Proficiency in Python and SQL.Possible work experience and proof of technical expertise.
You may also consider a Master’s degree in computer engineering or science in order to fine-tune your skills while on the job. (Although a Master’s isn’t required, it is always appreciated).
Intellectual curiosity to find new and unusual ways of how to solve data management issues.
Ability to approach data organization challenges while keeping an eye on what’s important.
Look forward to
Working with a world-class team.
Fun & work at the same place with an amazing work culture and flexible timings.
Get ready to transform yourself into a health junkie
Join HealthifyMe and Make History",3.4,"HealthifyMe Wellness Private Limited
3.4",Bengaluru,"Bengaluru, India",501 to 1000 employees,2012,Company - Private,Healthcare Services & Hospitals,Healthcare,Unknown / Non-Applicable,-1
610,Data Engineer,"Data Engineer
Guidewire’s Cyence Risk Analytics products help the property & casualty (P&C) industry to model new and evolving risks such as cyber. By combining internet-scale data listening, adaptive machine learning, and insurance risk modeling, Cyence Risk Analytics provides insights that help P&C customers face new risks, take advantage of new opportunities, and develop new products. To learn more about Cyence Risk Analytics, please visit https://www.guidewire.com/products/cyence
We are seeking talented Data Engineers to join our team in Chennai, India for our internet-scale data listening team.
Roles & Responsibilities:
Build and manage pipelines to collect and process data at scale.
Coordinate with global teams to understand data processing requirements.
Write highly efficient and optimized code that is easily scalable.
Adherence to coding and quality standards.
Analyze the processed data to identify anomalies.
Perform code reviews on a regular basis.
Build & maintain tools to automate the pipelines and for infrastructure management.
Develop frameworks to help operationalize new products
Be a multi-tasker, supporting teams across the globe. You’ll be one of the go-to people when anyone needs a data driven assessment of a situation
Required skills:
S./M.S. degree or equivalent experience in IT/Computer Science with 2– 5 years of Programming experience
Experience with Python
Experience with shell scripting
Experience working with large scale data, No SQL databases ( preferably Mongo DB)
Ability to write complex queries and optimize queries on a relational database.
Good Logical and Analytical skills
Strong hold of Algorithmic analysis and usage of data structures
Exceptional communication and organization skills
A driven personality that is biased toward action, collaboration, and delivery
Preferred:
Experience with web crawling and scraping
Experience with BigData technologies
Experience with Jenkins or any CI server
Experience with AWS
Experience with Docker
Why us?
Cyence is an analytics platform that quantifies the financial impact of cyber risk. Our first market is the insurance industry, where we help our clients understand, assess and manage risks associated with a wide range of cyber security events in a data-informed way. Cyence is now a product family within Guidewire Software, but we have retained our startup culture of collaboration.
We are Guidewire Software, and we're perhaps the best company to work for that you've never heard of. We are proud to be voted a “Top 3” employer on Glassdoor by our own employees, and positioned as a market leader by industry experts like Gartner.

We serve the second-largest financial services industry in the world (after banking), worth $2 trillion USD. We build the core applications that companies use to sell insurance policies, settle claims, and bill their customers. We also have a portfolio of products serving the innovative needs of our customers in areas such as data management, digital online portals, and predictive analytics.

We serve customers all over the world, helping them handle billions of dollars of business. This is a lucrative and under served market, and we have grown rapidly through a combination of quality products, excellent service, innovative technology, and a passionate belief in our core values of rationality, collegiality & integrity.
About Guidewire

Guidewire is the platform P&C insurers trust to engage, innovate, and grow efficiently.

Guidewire combines core, data, digital, analytics, and AI to deliver our platform as a cloud service. 380 insurers, including the largest and most complex in the world, run on Guidewire.

As a partner to our customers, we continually evolve to enable their success. We are proud of our unparalleled implementation track record with 700+ successful projects, supported by the largest R&D team and partner ecosystem in the industry. Our marketplace provides hundreds of add-ons that accelerate integration, localization, and innovation.

Guidewire Software Inc. provides equal employment opportunities to all applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. All offers are contingent upon passing a criminal history and other background checks where it's applicable to the position.",4.1,"Guidewire Software
4.1",Chennai,"San Mateo, CA",1001 to 5000 employees,2001,Company - Public,Computer Hardware & Software,Information Technology,₹50 to ₹100 billion (INR),"Oracle, Accenture, Duck Creek Technologies"
611,Data Science AI Ops Lead,"Job Title: Data Science AI Ops Lead
Career Level: E1

Company
AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. But we're more than one of the world's leading pharmaceutical companies. At AstraZeneca, we're proud to have a unique workplace culture that inspires innovation and collaboration. Here, employees are empowered to express diverse perspectives and are made to feel valued, energized and rewarded for their ideas and creativity.

Role

We are looking for an AI Ops Lead to join our Data Science & AI team in Chennai. The ideal candidate will have industry experience working in a range of different cloud environments where they devised and deployed large-scale production infrastructure and platforms for data science. The position will involve taking these skills and applying them to some of the most exciting data & prediction problems in drug discovery.

The successful candidate will be part of building a new, close-knit team of deeply technical experts and together have the chance to create tools that will advance the standard of healthcare, improving the lives of millions of patients across the globe. This platform will support major AI initiatives such as clinical trial data analysis, knowledge graphs, imaging & omics for our therapy areas. You will also have responsibility to help provide the frameworks for data scientists to develop scalable machine learning and predictive models with our growing data science community, in a safe and robust manner.

As a strong software leader and an expert in building complex systems, you will be responsible for inventing how we use technology, machine learning, and data to enable the productivity of AstraZeneca. You will help envision, build, deploy and develop our next generation of data engines and tools at scale. You will be bridging the gap between science and engineering and functioning with deep expertise in both worlds.

Key Accountabilities
• Own the development roadmap to build and operationalise our data science environment, platforms and tooling.
• Support any external opportunities, through close partnership and engagement such as Benevolent.AI collaboration.
• Deployment of systems, applications and tooling for data science on cloud environments.
• Understanding of the necessary guardrails required for different use cases and data sensitivities.
• Adapt standard machine learning methods to best exploit modern parallel environments (e.g. distributed clusters, multicore SMP, and GPU).
• Provide the necessary infrastructure and platform to support the deployment and monitoring of ML solutions in production Optimizing solutions for performance and scalability.
• Liaise with the Data Engineering team to ensure that the platform and the solutions deployment therein benefit from an optimised and scalable data flow between source systems and analytical models
• Implementing custom machine learning code and developing benchmarking capabilities to monitor drift of any analyses over time.
• Understanding of the latest AI webservices and data science tools, from DataBricks to citizen data science tools like Dataiku, C3.AI and Domino. Experience working on regulatory data would be helpful but not essential.
• Liaise with other teams to enhance our technological stack, to enable the adoption of the latest advances in Data Processing and AI
• Being an active member of the Data Science team, you will benefit from, and contribute to, our expanding bank of Data Science algorithms and work efficiently with our data science infrastructure.
• Appreciation of how to optimise predictive models, run in production and monitor. Experience running a service team will be beneficial.
• Testing and assessing the quality of new tools.
• Line management responsibilities as well as team recruitment, training provision and coaching

Candidate Knowledge, Skills and Experience

• BSc in Computer Science or related quantitative field or MSc/Ph.D degree in Computer Science or related quantitative field.
• More than 2 years of experience and demonstrable deep technical skills in one or more of the following areas: machine learning, recommendation systems, pattern recognition, natural language processing or computer vision.
• Experience managing an enterprise platform and service, handling new customer demand and feature requests.
• Strong software coding skills, with proficiency in Python and Scala preferred.
• Significant experience with AWS cloud environments, working knowledge of Google and Azure platforms. Knowledge of Kubernetes, S3, EC2, Sagemaker, Athena, RDS and Glue is essential. Certification in appropriate areas will be viewed favourably.
• Experience with best practice of data transport and storage within cloud system.
• Experience building large scale data processing pipelines. e. g. Hadoop/Spark and SQL.
• Experience provisioning computational resources in a variety of environments.
• Experience with containers and microservice architectures e.g. Kubernetes, Docker and serverless approaches.
• Experience with automation strategies e.g. CI/CD, gitops.
• Use of Data Science modelling tools e.g. R, Python, SAS and Data Science notebooks (e.g. Jupyter).
• Creative, collaborative, & product focused.
• Ability to just get things done.

Other

The role will have line reports and task management responsibilities within project or services may occur.

Department Data & Analytics, S&EUIT
Science and Enabling Units IT is a global IT capability supporting Drug Research, Drug Development, Product & Portfolio Strategy, Medical Affairs, Finance, HR, Compliance, Legal and Global Business Services. We are organized around 7 key capability areas: Business Partnering, Solution Delivery, Architecture, Application Support, Data & Analytics, Change & Operations, operating out of sites across the US, UK, Sweden, India and Mexico.

Data & Analytics provides analytics and data insight services and solutions critical to the Data & AI/ML emerging strategy and mission of S&EUIT and AZ. D&A is organized into teams specializing in Information Architecture, Data Engineering, Data Visualisation, Knowledge Management, Data Science, Data Analysis and Information Governance.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",3.9,"Guidewire Software
4.1",Chennai,"Cambridge, United Kingdom",10000+ employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Roche, GlaxoSmithKline, Novartis"
612,Senior Data Scientist,"We are looking for a senior Data Scientist with 7+ years of progressive experience in mining large complex data sets, using a variety of advanced quantitative/modelling techniques. Candidate should have a knack to manage and deliver end to end projects with a proficiency to handle and deliver strategic insights to support crucial business decisions.
Candidate should have great analytical skills with an acumen for analysis, math and statistics and should be well versed with the concepts of machine learning. A rich experience in delivering analytics projects including social media analytics and big data is required.

RESPOSIBILITIES
Understanding business objectives and developing models based on structured and unstructured data to derive relevant metrics
Make the most effective use of the available Big Data infrastructure and Data Science techniques to address the business issues
Build effective presentations to communicate complex analysis and findings suitable for a wide array of audiences
Proactively plan and prioritize work according to criticality and shifting priorities/ strategies, while balancing need to drive longer-term initiatives
Mentor and coach junior team members
SKILLS
Proven experience as a Data Scientist or Data Analyst
Preparing and maintaining project, stage and exception plans as required
Identifying and obtaining support and advice required for the management, planning and control of the project
Experience in Predictive modelling, ensemble modelling, sentiment analysis, NLP, Time-Series Analysis, Deep Learning, Reinforcement learning, Recommender Systems
Presentation of insights using data visualization techniques
Problem-solving aptitude
Excellent communication and presentation skills
TOOLS & TECHNOLOGY
Familiar with statistical modelling tools such as Python, R, SAS etc. with proficiency in Python
Knowledge and experience of working with SQL and NoSQL databases
Experience in story telling with tools like Tableau, Power BI etc.
Experience with unstructured data using Hadoop
Proficiency in statistical analysis, quantitative analysis, predictive analytics, and optimization algorithms
Proficiency in statistical analysis, quantitative analysis, predictive analytics, and optimization algorithms
Benefits and Perks
Working with smart, young, mission-driven people
Approachable management team
Mobile allowance
Travel allowance
Regular team outings
Flexible Schedules",1.0,"Emerging India Group
1.0",India,"Noida, India",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
613,Business and Data Analyst,"Locations: Bangalore, Data Science & Analytics, Mountain View, New Jersey

We are looking for a Business and Data Analyst for a growing portfolio of customers. As a member of the TV Retargeting products, analytics and business operations team, you will have a huge impact on our business and the success of our customers. You should have an interest in solving business challenges using data, gathering requirements, analyzing use cases and working towards efficient solutions.

For campus recruiting: see our blog for sample test questions and group discussion topics.

Responsibilities:
Work with our Sales and Account Managers to understand customers’ KPIs and goals
Work with Business Operations team to launch new and optimize ongoing TV Retargeting digital media campaigns
Create case studies by analyzing past viewership and exposure data
Work closely with the data engineering team to understand the underlying drivers of positive and negative performance across our customers
Develop and run data science experiments and interpret the results
Implement the insights gained from your experiments across customers
Proactively communicate the key insights from the performance to the relevant internal teams: sales, account management and engineering
Communicate your ideas for improvement for our internal toolset within the TV Retargeting product and engineering team

Requirements:
Strong analytical background and critical thinking
Strong organizational skills and attention to detail
Ability to thrive in a fast-paced, high-volume, and deadline-driven environment
Engineering and Technical degree preferred
Marketing / Advertising / Analytics related experience is preferred but not necessary
Familiarity with the TV or Digital advertising ecosystem is helpful, but not required
Experience with a scripting programming language and SQL is helpful, but not required",4.1,"Alphonso
4.1",Bengaluru,"Mountain View, CA",51 to 200 employees,2012,Company - Private,TV Broadcasting & Cable Networks,Media,Unknown / Non-Applicable,-1
614,Data Engineer,"About SpringML

At SpringML, we are all about empowering the doers in companies to make smarter decisions with their data. Our predictive analytics products and solutions apply machine learning to todays most pressing business problems so customers get insights they can trust to drive business growth.

We are a tight-knit, friendly team of passionate and driven people who are dedicated to learning, get excited to solve tough problems and like seeing results, fast. Our core values include putting our customers first, empathy and transparency, and innovation. We are a team with a focus on individual responsibility, rapid personal growth, and execution. If you share similar traits, we want you on our team.

Whats the opportunity?

SpringML is looking to hire a topnotch Data Engineer who is passionate about working with data and using the latest distributed framework to process large datasets.

As a Data Engineer, your primary role will be to design and build data pipelines. You will be focused on helping client projects on data integration, data prep and implementing machine learning on datasets. In this role, you will work on some of the latest technologies, collaborate with partners on early win, consultative approach with clients, interact daily with executive leadership, and help build a great company.

Required Skills:
4-7 years Python or Java programming
4+ years of hands-on experience of Java / J2EE or REST Services / Spring-boot / Application servers
3+ years of Unix/Linux experience
Qualification Required
· Bachelors in Computer Science (or equivalent)
· Google Cloud Data Engineer Certification is preferred.
Responsibilities
· Ability to work on any product on the Google cloud platform.
· Must be hands-on and be able to write code as required
· Flexibility to work on newer product areas.
· Ability to lead junior engineers.
· Ability to interact directly with end customers.
· Architect and design solutions.
· Conduct code reviews.
Powered by JazzHR",4.4,"SpringML
4.4",Hyderabad,"Pleasanton, CA",1 to 50 employees,2015,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
615,Data Engineer (APAC),"MongoDB is the leading modern, general purpose database platform, designed to unleash the power of software and data for developers and the applications they build. Developers around the world are using MongoDB to build software to create new businesses, modernize existing businesses, and transform the lives of millions of people around the world.

Headquartered in New York, with offices across North America, Europe, and Asia-Pacific, MongoDB has more than 17,000 customers, which include some of the largest and most sophisticated businesses in nearly every vertical industry, in over 100 countries.

MongoDB is growing rapidly and seeking a Data Engineer to be a key contributor to the overall internal data platform at MongoDB. You will build data driven solutions to help drive MongoDB's growth as a product and as a company. You will take on complex data-related problems using very diverse data sets.

Our ideal candidate has experience with
Several programming languages (Python, Scala, Java, etc.)
Data processing frameworks like Spark
Streaming data processing frameworks like Kafka, KSQ, and Spark Streaming
A diverse set of databases like MongoDB, Cassandra, Redshift, Postgres, etc.
Different storage format like Parquet, Avro, Arrow, and JSON
AWS services such as EMR, Lambda, S3, Athena, Glue, IAM, RDS, etc.
Orchestration tools such as Airflow, Luiji, Azkaban, Cask, etc.
Git and Github
CI/CD Pipelines
You might be an especially great fit if you
Enjoy wrangling huge amounts of data and exploring new data sets
Value code simplicity and performance
Obsess over data: everything needs to be accounted for and be thoroughly tested
Plan effective data storage, security, sharing and publishing within an organization
Constantly thinking of ways to squeeze better performance out of data pipelines
Nice to haves
You are deeply familiar with Spark and/or Hive
You have expert experience with Airflow
You understand the differences between different storage formats like Parquet, Avro, Arrow, and JSON
You understand the tradeoffs between different schema designs like normalization vs. denormalization
In addition to data pipelines, you're also quite good with Kubernetes, Drone, and Terraform
You've built an end-to-end production-grade data solution that runs on AWS
You have experience building machine learning pipelines using tools likeSparkML, Tensorflow, Scikit-Learn, etc.
Responsibilities

As a Data Engineer, you will:
Build large-scale batch and real-time data pipelines with data processing frameworks like Spark on AWS
Help drive best practices in continuous integration and delivery
Help drive optimization, testing, and tooling to improve data quality
Collaborate with other software engineers, machine learning experts, and stakeholders, taking learning and leadership opportunities that will arise every single day
Do you know, Why MongoDB is a fantastic place to work and build your career?
Disrupting a $64 Billion market
Top NoSQL database in the world
Largest Ecosystem and the fastest growing database in the world
Close to 17,000 customers in over 100 countries and over 90+ million downloads
>120% net ARR expansion rate over each of the last twenty quarters
Sequoia Capital and a number of other Top VC firms have invested in MongoDB. Sequoia Capital calls us out as one of their flagship portfolios; Sequoia has also invested in Apple, Google, Youtube, and WhatsApp
9-figure revenue company, with very high double-digit growth rates
Be a part of the company that's reinventing the database, focused on innovation and speed
Enjoy a fun, inspiring culture that is engineering focused
Work with talented people around the globe
Learn, contribute, and make an impact on the product and community.


Life at MongoDB

Our India office culture
180+ people, with teams in Sales, Engineering, HR, Finance, IT & Marketing
Regular group outings and opportunities to get to know your colleagues
Employee affinity groups


Our Benefits
Competitive salary and equity
Comprehensive Health cover, dental cover, travel insurance & Life Insurance.
Free lunch twice per week and a fully stocked kitchen with healthy and sweet treats.
Macbooks are company standard
26 weeks Maternity & 20 Paternity leave to spend time with new arrivals.",4.6,"MongoDB
4.6",Gurgaon,"New York, NY",1001 to 5000 employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
616,Principal Data Scientist,"10+ years of experience in machine learning, data mining, mathematical optimization.
PhD or Masters in Computers Science, Computer Engineering, or mathematics
Expert level knowledge in Hadoop/Mahout/MapReduce frameworks
Strong knowledge of NoSQL and Relational database systems including HBase, CouchDB, PostgreSQL, MySQL, Oracle etc.,
Background in predictive, diagnostic, operations analytics for engineering/industrial/M2M applications is strongly desired.
Good understanding of distributed systems
Knowledge of R, Matlab, SAS or other open-source/proprietary statistical packages

Overall: Recognized as the ‘go to’ expert in Analytics domain within the organization

Build design/code/test frameworks and rapid prototyping of new hypothesis
Assist engineering leadership in hiring and interviewing top talent
Steer Scrum reviews and stand-up meetings
Mentor junior staff, conduct design/code/test reviews
Contribute strongly to IP portfolio of the company in the form of patent disclosures, whitepapers, and blogs.

Roles and Responsibilities:
Drive architecture and design of in-house IP and customer solutions in the area of engineering analytics
Responsible for analyzing large data sets to develop custom models and algorithms to drive business solutions
Build complex data sets from multiple data sources and build learning systems and algorithms to analyze and filter continuous data flows and offline data analysis
Conduct statistical analysis and build models to determine trends, patterns and significant data relationships

Immediate joiner or short joiner is highly invited.

Contact
Bangalore - Corporate Office
Novel Tech Park, 46/4, GB Palya, Hosur Road, Bangalore, India - 560068.
+91 636 023 - 5133

Chennai
#408, Plot #2,1st Extn Street,Andal Nagar,AGS Colony, Velachery,Chennai, India - 600042.
+ 91 900 326 - 2287
info@continuesintelligence.com
Global Presence
Guidance Management W.L.L , #201,Opp Qatar Navigation Plaza, P.O.Box 30606, Doha - Qatar.
+ 974 443 19 651 (Board)
+ 974 662 59 283
+ 1 (972) 591 - 8280 (US)

Share

Connect and share.

Subscribe

Subscribe to our newsletter to receive news, updates, free stuff and new releases by Email.

© Copyright 2020, All Rights Reserved - Continues Intelligence Lab
Privacy Policy | Terms of Use

Home
Brief
About
Services
Solutions
Lab
Contact",-1,Continues Intelligence Lab,Bengaluru,"Bengaluru, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
617,Data Engineer,"Job Description


Role: Data Engineer

About the Data Solutions Team

Our data team is a curious and talented group of data engineers and data scientists who work collaboratively to solve some of the most the complex challenges our manufacturing customers face.

You’ll work with leaders in the automotive, medical device, apparel, construction, and pharmaceutical industries. You will sift through massive amounts of factory floor data to uncover insights on how customers make products and develop solutions to pressing business problems.

What you’ll do:
Use and improve the client’s automated software frameworks for data acquisition and model configuration
Design and implement data pipelines for acquiring and transforming raw plant floor data into actionable information.
Handle installation and deployment of on-premise data acquisition and edge-computing appliances at factory locations
Coordinate with client IT and operations teams to ensure the systematic and reliable acquisition of data
Work closely with the product and sales teams to create data solutions for manufacturers
Support existing deployments and quickly adapt solutions to changing conditions
Experience: 3-6 years

Qualifications:
BS or MS in Computer Science, Computer Engineering, Electrical Engineering, or a related technical discipline
Experience working with cloud technologies (GCP mandatory)
Experience with Python or other scripting languages (Mandatory)
Experience working in Linux/Windows including using the command line (comfortable with shell access, SSH, etc.)
Experience with SQL and/or noSQL databases (e.g. Mongo)
Familiarity with ETL
Good communication skills, both for internal collaboration and working with clients
You love learning new technologies and like to tinker to understand how things work
You use a systematic problem-solving approach when facing challenging technical problems
Also helpful, but if you’re the kind of engineer we’re looking for, you’ll be able to learn as you go so we’re not worried about which ones you know on day one.
Experience with packages such as NumPy, SciPy, pandas
Understanding of statistics (e.g., hypothesis testing and regression models)",3.7,"Intelegencia
3.7",Noida,"Atlanta, GA",501 to 1000 employees,2009,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
618,Data Science,"As a Data Scientist, Geospatial you will work on our machine learning platform and actively contribute to the development of our state-of-the-art preprocessing and modeling capabilities. You will join some of the best and brightest Data Scientists in the world in order to build innovative predictive modeling solutions that allow end-users to build more accurate models faster.

We are looking for talented people with excellent computer skills and deep knowledge of Statistical Learning who can analyze problems, develop innovative solutions, and implement them for real-world use on top of our machine learning platform.

DataRobot is based around delivering best-in-class data science solutions and this position provides the opportunity to develop key components of our platform.

Skills
Highly motivated and passionate about machine learning and computer science

Strong experience working with Geospatial data

Deep knowledge of different statistical and machine learning approaches and problem domains

Hands-on experience applying machine learning to real-world problems

Hands-on experience working in a fast-paced environment in Python

Hands-on experience writing testable, documented and maintainable code

Strong analytical and problem-solving skills

Ability to work with raw data sources in a variety of formats

Bonus
Experience with distributed computation frameworks

Outstanding achievements in “Kaggle like” competitions

Proficiency with C/C++ or Java (Scala, Clojure)

Experience in a management role

Contribution to open source solutions

Familiarity with either R, SAS or Matlab",-1,lemark institute of art,Mumbai,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
619,Data Analyst,"Data analysts translate numbers into simple readable statics, every business collects data, whether it's sales figures, market research, logistics, or transportation costs. A data analyst's job is to take that data and use it to help companies make better business decisions.
Analytical Skills: Data analysts work with large amounts of data: facts, figures, and number crunching. You will need to see through the data and analyse it to find conclusions.
Communication Skills: Data analysts are often called to present their findings, or translate the data into an understandable document. You will need to write and speak clearly, easily communicating complex ideas. Demonstrates good communication skills.
Critical Thinking: Data analysts must look at the numbers, trends, and data and come to new conclusions based on the findings.
Attention to Detail: Data is precise. Data analysts have to make sure they are vigilant in their analysis to come to correct conclusions.
Math Skills: Data analysts need math skills to estimate numerical data.
Programming Skills: This role requires an understanding of programming logic, although no experience with a specific programming language is required. Familiarity with SQL will be an important part of the data analyst role.
Educational Requirements: Bachelors of Science in any related fields.
Overall Knowledge/Skills/Abilities: Must have strong analytical skills and an understanding of system databases, data elements, and application software solutions to maximize data gathering and data analysis.
Have the ability to interpret their intent and application. Demonstrates the ability to handle a variety of responsibilities under pressure. Must be able to function independently.",4.1,"TBO Group
4.1",Gurgaon,"Dubai, United Arab Emirates",201 to 500 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
620,Bioinformatic (Data Scientist) -Variant analyst,"Job Location – Pune – India
Required experience – 3-5 Years with M.Sc. or 2-4 Years with PhD of academic/Industrial

Innoplexus offers Data as a Service and Continuous Analytics as a Service product, leveraging Artificial Intelligence and advanced analytics to help reduce the time to market, significantly.

Our products leverage proprietary algorithms and patent pending technologies to help global Life sciences & Financial services organizations with access to relevant data, real time intelligence & intuitive insights, across the life cycle of the products.

We automate the collection, curation, aggregation, analysis & visualization, of billions of data points from thousands of data sources, using domain-specific language processing, ontologies, computer vision, machine learning, network analysis and more.

You are the right person in our team if you can:
Understand Biological data, molecular biology, computational biology, proteomics and genomics data
Should have a very fair understanding of Adverse Events and Toxicity
Application of Machine Learning or Deep Learning experience in biological data
Sound understanding of uses of NLP in biological data
Hands on experience of Applied Statistics in Life Science data
Understand R, Python, Weka, Spark and latest technologies in data sciences
Knowledge of Proteins, Drugs, Clinical trials and Literatures databases is required

We need you to have:
BTech or MSc or M Pharma or PhD in Biotechnology/Bioinformatics/Cheminformatics/Pharmacoinformatics/Pharmacy

To excel in this job, you must bring 3-5 Years with M.Sc. or 2-4 Years with PhD of academic/Industrial with experience in:

Good presentation and communication skills
Strong leadership qualities. Ready to own the work
Experience in CRO or Pharma is desirable
Working experience on Adverse Events and Toxicity module
Good analytical and reasoning skills
Track record of managing small team is an advantage
Understanding of Biological data and databases is a plus
Knowledge of databases like Proteins, Drugs and Literatures databases is desirable
Research paper publications in good journals

Innoplexus believes in the power of collaboration and teamwork. You will work and grow alongside creative thinkers to turn great ideas into reality. We will help you develop your skills with training courses and knowledge sharing.",4.1,"Innoplexus
4.1",Pune,"Frankfurt am Main, Germany",201 to 500 employees,2011,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),"Palantir Technologies, Mu Sigma, IQVIA"
621,Advance Analytics Consultant,"Role

Advance Analytics Consultant

Business Function

Global Analytics and Web Insights
Reports to

Sr. Manager – Global Analytics & Web Insight

Department

Asset, Pricing and Operations
Nature and Purpose:

The role will be responsible for the creation and maintenance of advanced analytical models working with global stakeholders within Farnell and Avnet. The post holder will be assigned key projects, including those aligned to the Avnet Intelligence Programme (AIP), to develop best in class processes and techniques to leverage data sciences. This is a global role based in India, day to day management will be from Bangalore with direction provided from the Marketing Insights and Analytics Manager in Leeds.

Data quality and integrity should be consistently adhered to, as to ensure accurate and consistent reporting and decision making
Accountabilities with Key Outcomes:
1

Day to day the role will be responsible for:
Develop, enhance and maintain advanced analytic models that generate new business insights and/or deliver predictive services for the business.
Leverage predictive analytics, experimental data designs and models to drive business performance.
Develop predictive models such as customer churn, NPS, attribution, market basket analysis and customer Life Time Value (cLTV).
Partner with Leadership team (Farnell and Avnet), eComm/Marketing, BI and other Business Units to develop best in class processes and techniques to leverage data sciences (i.e. predictive modelling) across the Avnet ecosystem.
Globally responsible for assigned business analytics and reporting across network of MDD transactional websites/marketing platforms to achieve business sales per day performance in accordance with overall strategy.
Customer level reporting and analysis of our marketing programs leading to improved overall performance.
Manage, lead and develop a matrix team to ensure the successful execution and innovation of our proposition
Lead core insights from the data to suggest, create and execute fundamental improvements to marketing campaigns.
Transform large, complex, disparate, and often raw (normalized) data sets into quantifiable relationships, trends, and actionable insights.
Produce analytics that drive and measure progress including calculations to inform/influence marketing programs and multichannel activity, as well as measure the effectiveness of marketing (ROI).
Deliver forward looking marketing insights; understand industry trends and evolving external landscape that may inform/influence strategic plans.
Combine business data, industry benchmarks, and emerging industry trends to produce insights that inform the marketing strategy, customer experience, and customer segmentation at a global level.

2

Project Management and Training
Manage end to end deliverables of the projects, regular task and ad-hoc work by adhering to timelines and stakeholder expectations
Ensure that the Standard Operating Procedures are followed where applicable and all relevant documents are updated
Work with team members within the wider Business Analytics team as mentor

3

People Management
Day-to- day management and oversight for functional teams within Analytics matrix structure. This would include
– Coaching and performance management

– Workflow allocation within the team

– Escalation handling and management
4

Business Development
Work with the Leadership and Business Stakeholders to develop pipeline for projects
Support the expansion of Farnell initiatives into the wider AIP
Develop personal in-depth relationship with key business leaders and ensure continuous inflow of Business-As- Usual and project work

5

Stakeholder Management
Manage Stakeholder interactions by having regular updates and growing stakeholder engagement
Meeting /exceeding quality and timeline expectations for all projects
Design, plan and scope out projects with stakeholders
Explain project methodology and project approach to required stakeholders

Knowledge, Skills and Experience:
Essential

Experienced Analyst with 5+years complex analytics including 2+years of experience in Advance Analytics

Experience in Statistical models; Marketing Analytics concept is must

Marketing Analytics / data modeling / experience with core analytics tool sets (e.g. R,SAS,SPSS, SQL, Advance Excel etc)

Understanding of data nuances and focus on quality

Demonstrated experience and in-depth knowledge with advance/web analytics and measurement tools such as Statistical Modelling

Familiarity with development procedures, preferably in an ecommerce environment

Flexible, able to respond immediately to often changing business priorities

Must have the ability to combine strategic and analytical skills with creative and visual skills

Razor sharp written and verbal communication and presentation skills

Thorough understanding of website metrics, data analysis, behavioral analysis and reporting tools.

Desirable

Master’s/Bachelor's Degree in business, marketing or statistics",2.6,"Farnell Components
2.6",Bengaluru,"Leeds, United Kingdom",1001 to 5000 employees,1939,Company - Private,Electrical & Electronic Manufacturing,Manufacturing,₹1 to ₹5 billion (INR),-1
622,Applied Scientist,"6+ years of practical experience applying ML to solve complex problems on computer vision and/or image and video processing.
Proficiency in algorithm and model development, model validation and model implementation for large-scale applications in the image/video domain
Experience distilling customer requirements into problem definitions, dealing with ambiguity and competing objectives
Strong communication and data presentation skills
Hands-on experience programming in R, Java, C#, C++ or similar programming languages
Prime Video is disrupting the traditional television and movie industry with a growing library of high-quality media. Prime Video launched in 2007 and has quickly become a strategic priority for the company, reflected in the service’s recent expansion into over 240 countries and territories worldwide. We boast one of the largest video catalogs in the world, and the storage and delivery scale is truly mind-boggling.

We would love to have you join us to build models that stretch the limits of video and audio compression. We are building state of the art models and algorithms to make compressed video smaller and better, and deliver industry-leading innovations in the measurement and understanding of perceptual audio and video quality. As a member of our team, you will apply your deep knowledge of Computer Vision and Machine Learning to concrete multimedia problems that have broad cross-organizational, global, and technology impact.

Your work will focus on retrieving, cleansing and preparing large scale datasets, training and evaluating models and deploying them to production, with continuous monitoring and evaluation. You will work on large engineering efforts that solve significantly complex problems facing global customers. You will be trusted to operate with independence and are often assigned to focus on areas with significant impact on audience satisfaction. You must be equally comfortable with digging in to customer requirements as you are drilling into design with development teams and developing production ready learning models. You consistently bring strong, data-driven business and technical judgment to decisions.

You will work with internal and external stakeholders, cross-functional partners, and end-users around the world at all levels. Our team makes a big impact because nothing is more important to us than pleasing our customers, continually earning their trust, and thinking long term. You are empowered to bring new technologies and deep learning approaches to your solutions.
MS in Computer Science, Machine Learning, Operational Research, Statistics or a related quantitative field
Strong fundamentals in problem solving, algorithm design and complexity analysis
Maintain an understanding of industry and technology trends in area of research.
Understand business context to decisions made within and across groups.
Strong personal interest in learning, researching, and creating new technologies with customer impact
Superior verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts.
Proven track record in technically leading and mentoring scientists as well as engineers",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
623,Applied Scientist,"6+ years of practical experience applying ML to solve complex problems on computer vision and/or image and video processing.
Proficiency in algorithm and model development, model validation and model implementation for large-scale applications in the image/video domain
Experience distilling customer requirements into problem definitions, dealing with ambiguity and competing objectives
Strong communication and data presentation skills
Hands-on experience programming in R, Java, C#, C++ or similar programming languages
Prime Video is disrupting the traditional television and movie industry with a growing library of high-quality media. Prime Video launched in 2007 and has quickly become a strategic priority for the company, reflected in the service’s recent expansion into over 240 countries and territories worldwide. We boast one of the largest video catalogs in the world, and the storage and delivery scale is truly mind-boggling.

We would love to have you join us to build models that stretch the limits of video and audio compression. We are building state of the art models and algorithms to make compressed video smaller and better, and deliver industry-leading innovations in the measurement and understanding of perceptual audio and video quality. As a member of our team, you will apply your deep knowledge of Computer Vision and Machine Learning to concrete multimedia problems that have broad cross-organizational, global, and technology impact.

Your work will focus on retrieving, cleansing and preparing large scale datasets, training and evaluating models and deploying them to production, with continuous monitoring and evaluation. You will work on large engineering efforts that solve significantly complex problems facing global customers. You will be trusted to operate with independence and are often assigned to focus on areas with significant impact on audience satisfaction. You must be equally comfortable with digging in to customer requirements as you are drilling into design with development teams and developing production ready learning models. You consistently bring strong, data-driven business and technical judgment to decisions.

You will work with internal and external stakeholders, cross-functional partners, and end-users around the world at all levels. Our team makes a big impact because nothing is more important to us than pleasing our customers, continually earning their trust, and thinking long term. You are empowered to bring new technologies and deep learning approaches to your solutions.
MS in Computer Science, Machine Learning, Operational Research, Statistics or a related quantitative field
Strong fundamentals in problem solving, algorithm design and complexity analysis
Maintain an understanding of industry and technology trends in area of research.
Understand business context to decisions made within and across groups.
Strong personal interest in learning, researching, and creating new technologies with customer impact
Superior verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts.
Proven track record in technically leading and mentoring scientists as well as engineers",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
624,OneID Assoc Data Analyst,"Neustar, Inc. is a leading global information services provider driving the connected world forward with trusted, holistic identity resolution. More information is available at https://www.home.neustar.

Job Requisition:

R-2333 OneID Assoc Data Analyst (Open Date: 04/26/2019)

Primary Location:

BANGALORE

Job Description:

Neustar, Inc. (NYSE: NSR) is a trusted, neutral provider of real-time information and analytics to the communications services, financial services, retail, educational, and media and advertising sectors. Neustar applies its advanced, secure technologies to help its clients promote and protect their businesses. More information is available at www.neustar.biz.

The Data and Analytics organization at Neustar is the DNA of the company. The DNA encodes the essence of existence and character that drives continuous innovation with data, continuous insights with analytics and continuous evolution with cutting-edge data products and services. Our vision is to be the trailblazer in Connection Science driven information services that create meaningful value for our customers. Our mission is to enable cutting-edge data products & services delivered through superior data, unique insights and top-of-the-class technology solutions. We believe in developing a Collaborative, Creative, yet Competitive, Customer Centric culture. We are shaping the present and the future at Neustar and are seeking “TENXERS” who share the same DNA.

Job Description:

We are looking for Associate Data Analyst to bring big data, marketing analytics, and database technology together to deliver best-in-class insights. You must be a hands-on data guru who’s passionate about data, database product development, and play well with others. If you have a curiosity for different industries and companies, a passion for data analytics, and skills to create effective and repeatable data transformation and profiling methods, we would like to hear from you.

Data is rarely perfect. We are looking for data analysts who will ensure we have the best data for client marketing insights. You will work in a cross functional team that spans Strategy, Data Management, Analytical Insights, and Product Solutions. You will use a keen eye, an understanding of the client’s industry and business practice, and common sense.

Responsibilities:
Analyze data and identify data pattern to bring insight out of data.
Build story around the data findings and explain in simple words.
Data discovery and validation.
Follow best practices and document the processes.
Pay attention to Detail.
Skills and Experience:
Bachelor in computer science/engineering/statistics/economics (master degree preferred).
1-3 years of experience in data analysis and exploratory analysis.
Have strong analytical thinking and soft skills.
Experience in Hive SQL.
Strong in MS Excel for data crunching.
Good knowledge of Hadoop platform.
Should be team person and strong interpersonal skills.
Nice to have:
Experience in digital marketing, campaigning and advertising.
Experience in Spark SQL.
Why work with us?
Because you love to build beautiful, innovative solutions that wow the customer.
Because you believe in changing the status quo and are up for the challenge of your life.
Because you know you can make a difference to people, places and things.
About Us

Every day, the world generates roughly 2.5 quadrillion bits of data. Neustar isolates certain elements and analyzes, simplifies and edits them to make precise and valuable decisions that drive results. As one of the few companies capable of knowing with certainty who is on the other end of every interaction, we’re trusted by the world’s great brands to make critical decisions some 20 billion times a day.

DIVERSITY

Diversity, inclusion and teamwork are second nature to Neustar; and these values permeate our entire business structure. Neustar is committed to creating an environment where a wide spectrum of opinions and beliefs are actively sought, listened to and respected. Further, our talented workforce draws from the many geographic areas and markets in which Neustar operates worldwide, which represents a distinct competitive advantage. The rich and varied personal and professional backgrounds of our employees make Neustar a dynamic and rewarding company at which to build a career. We invite you to join us.

EOE of Minorities/Females/Vets/Disability

Neustar, Inc. considers all applicants for employment without regard to race, color, religion, sex, national origin, age, disability, sexual orientation, or status as a Vietnam-era or special disabled veteran in accordance with federal law and other state and local requirements. Neustar, Inc., complies with applicable state and local laws prohibiting discrimination in employment and provides reasonable accommodation to qualified individuals with disabilities in accordance with the American with Disabilities Act (ADA) and applicable state and local laws.

Neustar does not accept unsolicited resumes from external firms or agencies. Neustar will not be responsible for placement fees associated with unsolicited resumes.

DIVERSITY
Diversity, inclusion and teamwork are second nature to Neustar; and these values permeate our entire business structure. Neustar is committed to creating an environment where a wide spectrum of opinions and beliefs are actively sought, listened to and respected. Further, our talented workforce draws from the many geographic areas and markets in which Neustar operates worldwide, which represents a distinct competitive advantage. The rich and varied personal and professional backgrounds of our employees make Neustar a dynamic and rewarding company at which to build a career. We invite you to join us.

EOE of Minorities/Females/Vets/Disability
Neustar, Inc. considers all applicants for employment without regard to race, color, religion, sex, national origin, age, disability, sexual orientation, or status as a Vietnam-era or special disabled veteran in accordance with federal law and other state and local requirements. Neustar, Inc., complies with applicable state and local laws prohibiting discrimination in employment and provides reasonable accommodation to qualified individuals with disabilities in accordance with the American with Disabilities Act (ADA) and applicable state and local laws.",3.7,"Neustar
3.7",Bengaluru,"Sterling, VA",1001 to 5000 employees,1996,Company - Private,Internet,Information Technology,₹50 to ₹100 billion (INR),"Adobe, Akamai, Oracle"
625,Director Data Science,"Description:

At Walmart, were accelerating a journey towards becoming the worlds leading data driven retailer. As the worlds largest retailer, we have the opportunity to use an unmatched retail data asset to deliver lower prices and better products for our customers and suppliers. As the Value Realization Lead, youll be leading a team that works across functions and domains to deliver analytics and data science-based solutions to complex business challenges. Youll be at the forefront of working across business, product, technology and data teams to deliver algorithmic solutions to drive top-line and bottom-line results across Walmart businesses. This role is a central element in Walmarts overall data strategy mission of accelerating data driven automation.

As the Value Realization Lead, you will be applying your expertise to analyze complex business use cases, and design and build analytics-based solutions. You will work with business leaders, data engineering teams, product teams, and data scientists to prioritize and develop strategic use case roadmaps and deploy solutions for the prioritized use cases.

The ideal candidate will be:

Curious: You stay up to date with the latest technology developments in the data science community, and are excited to enable high-impact outcomes in the face of complex problems and large datasets

Bold and with a bias for action: Youre a doer, thriving on the challenges of delivering hardened and optimized models as part of production systems

Pragmatic and focused on results: You like working in a fast-paced environment and making practical trade-offs to test, learn and deploy analytics solutions that have material impact on Walmarts business

Key Responsibilities:

• As team lead, grow a team of analytics consultants to drive business value through application of advanced analytics and data science.

• Coordinate across functional teams of data scientists, analysts, product managers, engineers, and business operators on value realization initiatives

• Develop and leverage a consistent framework to identify and prioritize uses cases based on business value

• Collaborate with data engineering teams to identify data sets needed to support value use cases

• Apply algorithmic and other analytical models as appropriate to address business use cases

• Identify opportunities to further automated decision making goals based on data

• Develop and leverage internal and external partnerships and networks to maximize the achievement of business goals

• Support implementation of automated data quality checks in product roadmaps

• Architect, develop, and deploy large-scale data analytics services from prototype through production that meet key business requirements (performance, reliability, speed, monitoring, self-service, etc.)",3.3,"Walmart
3.3",Bengaluru,"Bentonville, AR",1001 to 5000 employees,1962,Company - Public,"Department, Clothing, & Shoe Shops",Retail,₹500+ billion (INR),"Target, Costco Wholesale, Amazon"
626,Staff Data Engineer (APAC),"MongoDB is the leading modern, general purpose database platform, designed to unleash the power of software and data for developers and the applications they build. Developers around the world are using MongoDB to build software to create new businesses, modernize existing businesses, and transform the lives of millions of people around the world.

Headquartered in New York, with offices across North America, Europe, and Asia-Pacific, MongoDB has more than 17,000 customers, which include some of the largest and most sophisticated businesses in nearly every vertical industry, in over 100 countries.

MongoDB is growing rapidly and seeking a Staff Data Engineer to be a key contributor to the overall internal data platform at MongoDB. You will build data driven solutions to help drive MongoDB's growth as a product and as a company. You will take on complex data-related problems using very diverse data sets.

Our ideal candidate has experience with
Several programming languages (Python, Scala, Java, etc.)
Data processing frameworks like Spark
Streaming data processing frameworks like Kafka, KSQ, and Spark Streaming
A diverse set of databases like MongoDB, Cassandra, Redshift, Postgres, etc.
Different storage format like Parquet, Avro, Arrow, and JSON
AWS services such as EMR, Lambda, S3, Athena, Glue, IAM, RDS, etc.
Orchestration tools such as Airflow, Luiji, Azkaban, Cask, etc.
Git and Github
CI/CD Pipelines


You might be an especially great fit if you
Enjoy wrangling huge amounts of data and exploring new data sets
Value code simplicity and performance
Obsess over data: everything needs to be accounted for and be thoroughly tested
Plan effective data storage, security, sharing and publishing within an organization
Constantly thinking of ways to squeeze better performance out of data pipelines


Nice to haves
You are deeply familiar with Spark and/or Hive
You have expert experience with Airflow
You understand the differences between different storage formats like Parquet, Avro, Arrow, and JSON
You understand the tradeoffs between different schema designs like normalization vs. denormalization
In addition to data pipelines, you're also quite good with Kubernetes, Drone, and Terraform
You've built an end-to-end production-grade data solution that runs on AWS
You have experience building machine learning pipelines using tools like SparkML, Tensorflow, Scikit-Learn, etc.


Responsibilities

As a Staff Data Engineer, you will:
Estimate task complexity, report progress, and voice risks to peers and managers
Both learn from and teach peers and junior engineers
Develop and maintain expertise in big data best practices
Design and build large-scale batch and real-time data pipelines with data processing frameworks like Spark on AWS
Help drive best practices in continuous integration and delivery
Help drive optimization, testing, and tooling to improve data quality
Collaborate with other software engineers, machine learning experts, and stakeholders, taking learning and leadership opportunities that will arise every single day


Success Measures:

In 3 months

you will have familiarized yourself with much of our data platform, be making regular contributions to our codebase, will be collaborating regularly with stakeholders to widen your knowledge and helping to resolve incidents and respond to user requests

6 Months

you will have successfully investigated, scoped, executed, and documented a small to medium sized project and worked with stakeholders to make sure their data needs are satisfied by implementing improvements to our platform

12 Months

You will have become the key person for several projects within the team and will have contributed to the data platform's roadmap. You will have made several sizable contributions to the project and are regularly looking to improve the overall stability and scalability of the architecture

Do you know, Why MongoDB is a fantastic place to work and build your career?
Disrupting a $64 Billion market
Top NoSQL database in the world
Largest Ecosystem and the fastest growing database in the world
Close to 17,000 customers in over 100 countries and over 90+ million downloads
>120% net ARR expansion rate over each of the last twenty quarters
Sequoia Capital and a number of other Top VC firms have invested in MongoDB. Sequoia Capital calls us out as one of their flagship portfolios; Sequoia has also invested in Apple, Google, Youtube, and WhatsApp
9-figure revenue company, with very high double-digit growth rates
Be a part of the company that's reinventing the database, focused on innovation and speed
Enjoy a fun, inspiring culture that is engineering focused
Work with talented people around the globe
Learn, contribute, and make an impact on the product and community.
Life at MongoDB

Our India office culture
180+ people, with teams in Sales, Engineering, HR, Finance, IT & Marketing
Regular group outings and opportunities to get to know your colleagues
Employee affinity groups
Our Benefits
Competitive salary and equity
Comprehensive Health cover, dental cover, travel insurance & Life Insurance.
Free lunch twice per week and a fully stocked kitchen with healthy and sweet treats.
Macbooks are company standard
26 weeks Maternity & 20 Paternity leave to spend time with new arrivals.",4.6,"MongoDB
4.6",Gurgaon,"New York, NY",1001 to 5000 employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
627,Data Science Intern,"Stipend As per the industry standard
Location Kolkata
Job Information

Industry:
IT (Data Science)

Skills:
Basic knowledge in Machine Learning, Artificial Intelligence, Natural Language Processing, Python, Angular. Must be proficient in working Java Script.

Education:
B. Tech is preferred, along with MBA.

Duration of Internship:
6 Months.

Employment Type Full Time

Experience Fresher.",3.7,"newAmps Consulting
3.7",Kolkata,"Kolkata, India",1 to 50 employees,2015,Company - Private,IT Services,Information Technology,₹10 to ₹50 million (INR),-1
628,Artificial Intelligence / Machine Learning Engineer,"Nagpur, India Full-Time

About the Job
AI / ML is one of the most exciting technologies of the decade. This role is your opportunity to build and deploy new AI products from the ground up. You will be part of a team helping chart our AI strategy and define the problems we are solving with AI. You will help build our AI development and production infrastructure and set our technical standards. To succeed you must become an expert in building AI models and putting them into production.

Requirements
Have 1+ years of work experience with large volumes of data preferably in healthcare.

Have a formal education in relevant fields such as stats, computer science or applied mathemathics.

Love data. You need to eat, breathe and sleep data. For you, everything has to be measured and data-driven.

You should have a very good understanding of Python and Image processing, and hands-on software development skill from the development to production.

Are an expert at data visualization and presentation.

Have a strong background in statistical concepts and machine learning models.",3.6,"Healthcoco Technologies
3.6",Pune,"Pune, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
629,Senior Data Analyst,"Postman is the only complete API development environment. Today we have 10 million developers and over 500K companies using our comprehensive set of built-in tools to support every stage of the API life cycle. With Postman you can design, mock, debug, test, document, monitor, and publish your APIs all in one place.

We are looking for a Senior Data Analyst in Data team to help us scale our analysis processes and deliver more value to the organisation.

About the team

Data team at Postman acts as a central hub for asking analysis questions. We are a small team of engineers and analysts who believe in impact driven work.

We believe in democratisation of data and work towards building data products so that decision making through data is as self-served as possible.

We are major supporters of knowledge distribution, be it factual or philosophical. We don’t shy away from getting our hands dirty whenever it comes to anything data.

Do come prepared because you will be in for one of the craziest ride of your lifetime.

Responsibilities:
Work closely with Data Engineering and partner teams to author and develop core data sets, within our Data Warehouse and BI tool, to empower operational and exploratory analyses
Work with partner teams to define goals and identify metrics for improving existing features and new releases
Build dashboards and reports to drive awareness and understanding of metrics and experiment results
Deep-dive into domain heavy problems and own the implementation of end-to-end solution
Help us in defining the information architecture of Postman eco-system
Help us in solving problems at scale such as Forecasting, Experimentation etc.
Requirements
You have 3+ years of experience as a Data Analyst or similar experience across college projects
The ability to clearly and effectively communicate the results of complex analyses
At least 1 BI tool experience such as Looker, Tableau, Power BI etc.
You have curiosity about how things work
Benefits

This position will be located in our beautiful office at 100 ft road, Indiranagar in Bangalore. You will enjoy our incredible perks: home-cooked meals, snacks, game room, flexible hours, ergonomic workstations and cuddles from our endearing Chief Happiness Officer, Cooper.

What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world.

Be a part of something big.",4.4,"Postman
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
630,Data Engineer,"Summary

GumGum's Data Engineer builds and maintains distributed systems, services and data pipelines. The role is focused on working on complex distributed systems, the performance of these systems and the ongoing optimization in service of our core business. This role is required to write highly scalable and fault tolerant code within company adopted technologies.

Reporting to our Data Engineering Manager, this role works as part of a team of engineers in the technology division of our advertising business.

Technologies Used by GumGum:
For Distributed Data processing: Kafka, Spark/Spark-Streaming on Databricks, Druid
For Data warehousing and reporting: AWS redshift, AWS Athena, Snowflake, Superset and Looker
For Data Pipelining: Apache Airflow, AWS Data Pipeline
In addition to above, additional technologies currently adopted: Groovy, docker, AWS ECS, DynamoDB, RDS

Responsibilities

Create and maintain optimal data pipeline architecture with Apache Kafka, Apache Spark, Apache Druid and Snowflake for real-time analytics
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Spark on Databricks, Apache Airflow and AWS 'big data' technologies like AWS Glue, AWS Athena.
Participate in technical discussions, code reviews, help the team in implementing engineering best practices.
Work on GumGum's proprietary Reporting Server API and on various reports using Groovy, SQL and Java
Work on GumGum's proprietary time-series forecasting systems infrastructure in spark on databricks and data pipelines in airflow
Work as part of the engineering team, supporting key projects and providing tactical recommendations for improving and helping the team to be efficient at scale

Minimum Qualifications

1+ year of experience in data engineering and warehousing
1+ year of Apache Spark experience in production workloads
2+ years of Software Engineering experience (Java/Scala/Python)
2+ years of experience in SQL and API Development
Experience with big data tools: Spark, Kafka, Hadoop, Druid etc.
Experience with stream-processing systems: Spark-Streaming, Flink etc.
Familiar with various AWS services, Serverless architecture and containers
Must be able to write quality code and build secure, highly available systems.
Excellent problem solving and critical thinking skills
Strong Verbal and written communication skills
Can work effectively remotely by utilizing technology tools to stay connected to the distributed team
Able to explain technical concepts to developers and project managers in a way that they understand and is effective
Desire to work with a team of people solving complex problems and sharing knowledge freely
Can execute individually but also operate as part of a distributed team
Is flexible in approach. Knows there is not one way to solve a problem
Able to explain technical concepts to developers and project managers in a way that they understand and is effective
Desire to work with a team of people solving complex problems and sharing knowledge freely
Can execute individually but also operate as part of a distributed team
Is flexible in approach. Knows there is not one way to solve a problem and can get to the best solution for GumGum through collaboration without locking in on a personal position

Career & Development Focus

Ongoing learning and development for education opportunities such as webinars, books, classes, relevant conferences and events
Opportunities to pursue business related side projects and yearly Hackathon
Highly encouraged to contribute to open source software, including our own open source software
Environment of learning from peers, including meetups, presentations and blog posts
Opportunity to work with cutting edge technology
Life Skills sessions - geared towards the whole life/ health / person
Leadership Bites Dinner Series - connecting current and future GumGum leaders over great food and meaningful conversation
Please note that we are not currently accepting candidates from recruiting agencies or 3rd parties.*
WE INVITE YOU TO LEARN MORE ABOUT GUMGUM!

Our Values…

Be Thoughtful

We listen to understand different perspectives, show everyone respect, and relentlessly seek solutions for our clients (internal and external).

Have Agility

We are quick, nimble, and change direction gracefully, while maintaining control.

Show Grit

We bring energy and perseverance to everything we do.

Our Team…

At GumGum, we innovate. Our two divisions, Advertising and Sports, are powered by expansive, sophisticated AI-driven marketing and analytics solutions. Our vision is clear: We want to use our proprietary technology to solve the hard problems across the media industry. As a company, we celebrate kindness, resilience, the courage to think outside the box and the importance of having fun. All of our internal operations and decisions are undertaken with complete transparency, with a highly accessible executive, leadership team. For GumGummers, we believe in providing all the necessary tools, resources and guidance needed for them to excel. And, they do excel.

Our Tech…

GumGum is constantly evolving to be at the forefront of computer vision and machine learning advancements. With nearly 10 years experience, we use our proprietary image recognition technology to deliver highly engaging, contextually relevant ad experiences across premium publishers all over the world.

Our Products & Services…

Our Advertising business serves contextual marketing messages in line with content users are actively engaged with.

Our Sports business helps marketers and rights holders understand the full media value of their sponsorship investments across broadcast and social media. And we deliver on brand safety by leveraging our AI to detect unsafe text and imagery, allowing us to deliver ads in brand safe, contextually relevant environments.

Our Hackathons…

What's a Hackathon? We're glad you asked. Our employees split into teams and spend 48 hours 'hacking' together before presenting their ideas to our executive team. It's a chance for anyone within our company to showcase the visions they want to bring to fruition.

Our Culture…

GumGum recently earned LA's Best Places to Work Award 2020 and Inc. Magazine's Best Places to work in 2020, and it's no surprise why. With company-sponsored social hours, annual holiday celebrations and on-site gatherings, GumGummers enjoy a fun, creative and collaborative workplace. We provide ourselves on our strong track record of giving employees the autonomy and support they need to succeed.

Oh, and doggies…

We love our dogs so much, we even have an Instagram dedicated to them! Follow us: @dogsofgumgum

In Addition...

About GumGum

Careers at GumGum

GumGum Women in Tech Panel - Living a Balanced Life

Women of GumGum Around the World

Innovators in Esports Content

Sponsorship Targeting with Visual Intelligence

GumGum Sports - Sizzle Reel - 2019 (EMEA)

GumGum - LinkedIn

GumGum Advertising

GumGum Sports

Forbes",3.7,"GumGum
3.7",Pune,"Santa Monica, CA",201 to 500 employees,2008,Company - Private,Internet,Information Technology,₹10 to ₹50 billion (INR),Vibrant Media
631,Data Analyst - Credit and Risk,"Work closely with business teams to identify specific insights that can drive business impact. You will be a part of the Credit and Risk team.
Hands-on experience on SQL
Ability to effectively engage with business stakeholders and translate business requirements into high impact reports and visualizations
Developing new capabilities for our clients beyond static reports and spreadsheets (focus on PowerBI, Data Studio and Tableau products.
Hands-on experience on integrating, querying and preparing datasets for reporting and analytics
Data mining within the organization as well as enrich data from 3rd party databases
Experience working in an agile development environment.
Work proactively with Product functions to translate insights into actionable items.
Requirements and qualifications
Experience of 2+ yrs of experience in Data Visualization & Reporting.
Bachelor Degree in Computer Science / IT / Electronics / Statistics / Mathematics
Role Category:
Credit & Risk

Location:
Mumbai, India, Asia

Employment Type:
Full time",3.0,"FLEXILOANS TECHNOLOGIES
3.0",Mumbai,"Mumbai, India",201 to 500 employees,2016,Company - Private,Lending,Finance,Unknown / Non-Applicable,"LendingKart, Capital Float, NeoGrowth Credit"
632,Data Analyst OneID,"Neustar, Inc. is a leading global information services provider driving the connected world forward with trusted, holistic identity resolution. More information is available at https://www.home.neustar.

Job Requisition:

R-1605 Data Analyst OneID (Open)

Primary Location:

HYDERABAD

Job Description:

Neustar, Inc. (NYSE: NSR) is a trusted, neutral provider of real-time information and analytics to the communications services, financial services, retail, educational, and media and advertising sectors. Neustar applies its advanced, secure technologies to help its clients promote and protect their businesses. More information is available at www.neustar.biz.

The Data and Analytics organization at Neustar is the DNA of the company. The DNA encodes the essence of existence and character that drives continuous innovation with data, continuous insights with analytics and continuous evolution with cutting-edge data products and services. Our vision is to be the trailblazer in Connection Science driven information services that create meaningful value for our customers. Our mission is to enable cutting-edge data products & services delivered through superior data, unique insights and top-of-the-class technology solutions. We believe in developing a Collaborative, Creative, yet Competitive, Customer Centric culture. We are shaping the present and the future at Neustar and are seeking “TENXERS” who share the same DNA.

Job Description:

We are looking for Data Analyst to bring big data, marketing analytics, and database technology together to deliver best-in-class insights. You must be a hands-on data guru who’s passionate about data, database product development, and play well with others. If you have a curiosity for different industries and companies, a passion for data analytics, and skills to create effective and repeatable data transformation and profiling methods, we would like to hear from you.

Data is rarely perfect. We are looking for data analysts who will ensure we have the best data for client marketing insights. You will work in a cross functional team that spans Strategy, Data Management, Analytical Insights, and Product Solutions. You will use a keen eye, an understanding of the client’s industry and business practice, and common sense.

Responsibilities:
Analyze data and identify data pattern to bring insight out of data.
Build story around the data findings and explain in simple words.
Data discovery and validation.
Follow best practices and document the processes.
Skills and Experience:
Bachelor in computer science/engineering/statistics/economics (master degree preferred).
3-5 years of experience in data analysis and exploratory analysis.
Have strong analytical thinking and soft skills.
Strong programing skills in Hive SQL.
Strong in MS Excel for data crunching.
Good knowledge of Hadoop platform.
Should be team person and strong interpersonal skills.
Nice to have:
Experience in digital marketing, campaigning and advertising.
Experience in Spark SQL.
Why work with us?
Because you love to build beautiful, innovative solutions that wow the customer.
Because you believe in changing the status quo and are up for the challenge of your life.
Because you know you can make a difference to people, places and things.
About Us

Every day, the world generates roughly 2.5 quadrillion bits of data. Neustar isolates certain elements and analyzes, simplifies and edits them to make precise and valuable decisions that drive results. As one of the few companies capable of knowing with certainty who is on the other end of every interaction, we’re trusted by the world’s great brands to make critical decisions some 20 billion times a day.

Neustar does not accept unsolicited resumes from external firms or agencies. Neustar will not be responsible for placement fees associated with unsolicited resumes.

DIVERSITY
Diversity, inclusion and teamwork are second nature to Neustar; and these values permeate our entire business structure. Neustar is committed to creating an environment where a wide spectrum of opinions and beliefs are actively sought, listened to and respected. Further, our talented workforce draws from the many geographic areas and markets in which Neustar operates worldwide, which represents a distinct competitive advantage. The rich and varied personal and professional backgrounds of our employees make Neustar a dynamic and rewarding company at which to build a career. We invite you to join us.

EOE of Minorities/Females/Vets/Disability
Neustar, Inc. considers all applicants for employment without regard to race, color, religion, sex, national origin, age, disability, sexual orientation, or status as a Vietnam-era or special disabled veteran in accordance with federal law and other state and local requirements. Neustar, Inc., complies with applicable state and local laws prohibiting discrimination in employment and provides reasonable accommodation to qualified individuals with disabilities in accordance with the American with Disabilities Act (ADA) and applicable state and local laws.",3.7,"Neustar
3.7",Hyderabad,"Sterling, VA",1001 to 5000 employees,1996,Company - Private,Internet,Information Technology,₹50 to ₹100 billion (INR),"Adobe, Akamai, Oracle"
633,Talent & Career Data Analyst/Specialist,"Position Type :

Full time

Type Of Hire :

Experienced (relevant combo of work and education)

Education Desired :

Master of Business Administration

Travel Percentage :

25%

Are you curious, motivated, and forward-thinking? At FIS, youll have the opportunity to work on some of the most challenging and relevant issues in financial services and technology. Our talented people empower us, and we believe in being part of a team that is open, collaborative, entrepreneurial, passionate and above all fun.

About the team

Talent & Career Enablement Team supports the execution of overall Talent & Career function. Our team is responsible for providing support to the leads in developing and delivering resources for whole of FIS. Key focus areas for this role include - Performance Management/Performance365, Talent and Digital Solutions, Career and Talent Partnering Support, Succession Planning Tools and Process, Research and content design & Process Improvement

What you will be doing:
Helping to produce regular Project and Program level reports for Talent & Career COE senior management and other key stakeholders.
Provide support to Senior Data Analyst in the team for various Automation and Reporting related tasks.
Prepare global dashboards by leveraging on available internal tools such as Workday and Visier.
Ability to innovate and recommend process and system enhancements for effective user experience as part of product/service designing.
Stay abreast of any process/system changes and guide stakeholders in implementation.
Supports the development and facilitation of training for People Office, business leaders and employees around associate tools and processes.
Ensures data quality and follows global data standards
What you bring:
3-5 years in a Human Resources with projects/background work as Data Analyst or MIS background preferred.
Has Exposure to workforce analytics- either as a user or a designer/analyst
Worked on HRIS Tools (preferably workday)
Experience creating support materials and benchmarking.
Experience working with large data files to analyze data and create various reports
Ability to maintain confidentiality
Must possess excellent verbal and written communication skills and be able to effectively communicate across multiple job levels both in and outside of the People Office function.
Proficient in Microsoft Office suite, specifically Excel, PowerPoint, and SharePoint.
Excellent customer service, problem solving, and multi-tasking skills
Demonstrated ability merge multiple sources of data and conduct analysis to identify trends and uncover insights.
Ability to work in a Global Matrix Environment and is Flexible working in different time zones as and when needed
Tolerance for change in transforming organization and developing Talent & Career team
What we offer you:
A multifaceted job with a high degree of responsibility and a broad spectrum of opportunities
A broad range of professional education and personal development possibilities FIS is your final career step!
A competitive salary and benefits
A variety of career development tools, resources and opportunities
Privacy Statement

FIS is committed to protecting the privacy and security of all personal information that we process in order to provide services to our clients. For specific information on how FIS protects personal information online, please see the Online Privacy Notice.

Sourcing Model

Recruitment at FIS works primarily on a direct sourcing model; a relatively small portion of our hiring is through recruitment agencies. FIS does not accept resumes from recruitment agencies which are not on the preferred supplier list and is not responsible for any related fees for resumes submitted to job postings, our employees, or any other part of our company.",3.6,"FIS
3.6",Pune,"Jacksonville, FL",10000+ employees,1968,Company - Public,Financial Transaction Processing,Finance,₹500+ billion (INR),"Fiserv, First Data, Jack Henry & Associates"
634,Data Analyst/C11,"Roles and Responsibilities
Interpreting data and analyzing results using statistical techniques to identify trends or patterns in complex data sets
Identifying and documenting Critical Data Elements used in Surveillances, Research and Analysis etc.
Providing Level 3 support as required to resolve data issues and gaps
Specification
Bachelors degree (in science, computers, information technology or engineering)
Person with overall 3-5 years of experience, working in similar roles across banking or services technology;
Well versed with SDLC life cycle having exposure to various Phases
Experience as a data analyst in financial markets (Trading, Market Data or Compliance)
Knowledge of and experience with databases, SQL and analytical tools like Business Objects, Micro strategy etc.
Strong analytical skills with ability to collect, analyze and disseminate large volumes of data with attention to detail, accuracy, and data quality
Experience working with relational DBMSs like Sybase, Oracle, SQL Server, Sybase, SQL etc.
Good understanding of database validations, constraints, syntax and data types.
Ability to communicate clearly and concisely, both orally and in writing with business and technology stakeholders
Ability to multitask and work effectively with little supervision
Technical / Functional Proficiency:
Min. 3-5 years of working experience as Senior Data Analyst in Finance and Banking
Comfortable working with large data volumes and be able to demonstrate a firm understanding of logical data structures and analysis techniques
Experience in RDMS and No SQL databases
Knowledge of agile development methodologies
Leadership Skills:
Excellent communication skills. Clearly articulating and documenting technical and functional specifications is a key requirement
Proactive problem-solver
Relationship builder and a very good team player
Good analytical and business skills
-------------------------------------------------

Grade :All Job Level - All Job FunctionsAll Job Level - All Job Functions - IN

------------------------------------------------------

Time Type :

------------------------------------------------------

Citi is an equal opportunity and affirmative action employer.
Minority/Female/Veteran/Individuals with Disabilities/Sexual Orientation/Gender Identity.

Citigroup Inc. and its subsidiaries (""Citi) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity CLICK HERE.

To view the ""EEO is the Law"" poster CLICK HERE. To view the EEO is the Law Supplement CLICK HERE.
To view the EEO Policy Statement CLICK HERE.
To view the Pay Transparency Posting CLICK HERE.",3.5,"Citibank
3.5",Pune,"Elk Grove Village, IL",5001 to 10000 employees,-1,Subsidiary or Business Segment,Lending,Finance,₹1 to ₹5 billion (INR),-1
635,Senior Data Scientist - Mathematical Finance,"At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.

What is the Senior Data Scientist – Mathematical Finance – Client Analytics group responsible for?
Works individually in support of a Fintech (Wealth Management) initiative.
Designs, develops and programs methods, processes, and systems to consolidate and analyze structured or unstructured, diverse “big data” sources to generate actionable insights and solutions for on-going research and product enhancement.
Develops and codes software programs, algorithms and automated processes to cleanse, integrate and evaluate large datasets from multiple disparate sources.

What are the ongoing responsibilities of an Senior Data Scientist – Mathematical Finance?
Mathematical Modelling:
Demonstrates Expertise in advanced mathematics, especially mathematical finance
Demonstrates a good grasp of probability distributions and stochastic calculus
Designs and validates mathematical models to find interlinkages and applications of academic models within a business context
Works on mathematical optimization modules similar to Traveling salesman problems under multivariate constraints. Familiarity with Lagrangian multivariate optimization problems a plus
Analyzes and interprets the results of research experiments through statistical models Solves analytical problems utilizing large structured, semi-structured and un-structured data in a distributed processing environment

Data Analysis:
Collects data from disparate systems, analyzes and delivers the data as intelligence that is actionable
Uses distributed and parallel processing frameworks like Spark for the analysis
Statistical Analysis (Data Mining and Advanced Analytical Techniques)
Develops predictive, statistical, behavioral, or other models using supervised and un-supervised machine learning / statistical modeling techniques
Performs ad hoc statistical and data mining analyses
Training, Research and Development

What ideal qualifications, skills & experience would help someone to be Successful?
Master’s degree in Mathematical Finance / Quantitative Finance / Financial Engineering from Tier-1 or Tier -2 Institutes highly preferred
Ph.D in Mathematics, Statistics, Econometrics, Engineering or related disciplines, from Tier-1 or Tier -2 Institutes. (Mandatory)
4-6 years of experience in data science.
Certifications in Financial Mathematics or related subjects from institutes such as IIQF, IFMR, TIFR etc would be highly valued.

Experience:

4-6 years of experience in data science
Understanding and prior experience with financial markets (Mandatory)
Knowledge of and Experience with Stochastic calculus, Simulations, Linear Algebra, statistical modeling, Time series analysis (especially state space models) (Mandatory)
Knowledge and experience of key machine learning and deep learning framework, e.g. Keras, TensorFlow
Hands on Experience in Python (Mandatory)
Proven Experience in Statistical and Mathematical modelling
Experience in SQL

Other Skills:


Proven ability to take initiative and work under pressure in a changing/growing environment
Should be self-driven and be able to work in an unstructured environment
Proven ability to work with ambiguous (not well defined) challenges
Excellent written and verbal communication skills
Displays curiosity to learn and learns independently
Ability to translate business challenges into analytical problems
Able to cultivate interpersonal customer and co-worker relationships
Ability to articulate and explain statistical / machine learning techniques to business partners
Ability to work individually or as a team as task requires

What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.

Highlights of our benefits include:

Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.",3.8,"Franklin Templeton Investments
3.8",Hyderabad,"San Mateo, CA",5001 to 10000 employees,1947,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Fidelity Investments, Vanguard"
636,Data Engineer,"Experience : 5-10 Years
Location : Bangalore

We are looking for various roles
Significant experience in Data Engineering role.
Extensive hands-on experience with Spark/ Scala, Strong AWS
Strong Experience in Python
Experience with messaging and streaming platforms like Kafka, RabbitMQ or JMS will be an added advantage
A self-starter attitude with an enthusiasm to work in a start-up environment
What You Need for this Position

You should have knowledge of:
Python
Spark
AWS
Aditional
No. of Positions
Education level
Career level
Experienced",4.8,"Bloom Consulting Services
4.8",Bengaluru,"Nagpur, India",1 to 50 employees,2015,Company - Private,IT Services,Information Technology,₹10 to ₹50 million (INR),-1
637,"Data Engineer, Enterprise Data","Position Overview

The Data Engineer is an emerging role in Ralph Lauren’s Analytics team, and will play a pivotal role in operationalizing the most critical data and analytics initiatives for Ralph Lauren’s digital business initiatives.

Purpose & Scope

Based in Bengaluru, India this Data Engineer will work with the Global Analytics team to build, maintain, and optimize data pipelines for key data and analytics consumers including business and data analysts and data scientists covering our digital and physical channels and value chain. Data engineers also need to guarantee compliance with data governance and data security requirements while creating, improving and operationalizing these integrated and reusable data pipelines. This would enable faster data access, integrated data reuse and vastly improved time-to-solution for Ralph Lauren’s data and analytics initiatives. The data engineer will be measured on their ability to integrate analytics and (or) data science results with Ralph Lauren’s business processes.

This role will require both creative and collaborative working with IT and the wider business. It will involve evangelizing effective data management practices and promoting better understanding of data and analytics. The data engineer will also be tasked with working with key business stakeholders, IT experts and subject-matter experts to plan and deliver optimal enterprise data assets.

Essential Duties & Responsibilities

Build data pipelines: The primary responsibility of data engineers is to architect, build, and maintain data pipelines that will provision high quality data ready for analysis. This includes ingestion, exploration, modeling, and curation of high value data.

Drive Automation through effective metadata management: The data engineer will be responsible for using innovative and modern tools, techniques and architectures to partially or completely automate the most-common, repeatable and tedious data preparation and integration tasks in order to minimize manual and error-prone processes and improve productivity.

Learning and using modern data preparation, integration and AI-enabled metadata management tools and techniques.
Tracking data consumption patterns.
Performing intelligent sampling and caching.
Monitoring schema changes.
Recommending — or sometimes even automating — existing and future integration flows.

Educate and train: The data engineer should be curious and knowledgeable about new data initiatives and how to address them. This includes applying their data and/or domain understanding in addressing new data requirements. They will also be responsible for proposing appropriate (and innovative) data ingestion, preparation, integration and operationalization techniques in optimally addressing these data requirements. The data engineer will be required to train counterparts such as data scientists, data analysts, LOB users or any data consumers in these data pipelining and preparation techniques, which make it easier for them to integrate and consume the data they need for their own use cases.

Participate in ensuring compliance and governance during data use: It will be the responsibility of the data engineer to ensure that the data users and consumers use the data provisioned to them responsibly through data governance and compliance initiatives. Data engineers should work with data governance teams (and information stewards within these teams) and participate in vetting and promoting content created in the business and by data scientists to the curated data catalog for governed reuse.

Become a data and analytics evangelist: The data engineer will be considered a blend of data and analytics “evangelist,” “data guru” and “fixer.” This role will promote the available data and analytics capabilities and expertise to business unit leaders and educate them in leveraging these capabilities in achieving their business goals.

Experience, Skills & Knowledge

Education and Experience

A bachelor's or master's degree in computer science, statistics, applied mathematics, data management, information systems, information science or a related quantitative field is required.
The ideal candidate will have a combination of IT skills, data governance skills, analytics skills and Retail industry knowledge with a technical or computer science degree.
At least 4 years or more of work experience in data management disciplines including data integration, modeling, optimization and data quality, and/or other areas directly relevant to data engineering responsibilities and tasks.
At least 2 years of experience working in cross-functional teams and collaborating with business stakeholders in Retail in support of a departmental and/or multi-departmental data management and analytics initiative.
Deep Retail Industry knowledge or previous experience working in the business would be a plus.

Technical Knowledge/Skills

Strong experience with advanced analytics tools for Object-oriented/object function scripting using languages such as R, Python, Scala, or similar.
Strong ability to design, build and manage data pipelines in PySpark and related technologies for data structures encompassing data transformation, data models, schemas, metadata and workload management. The ability to work with both IT and business in integrating analytics and data science output into business processes and workflows.
Strong experience with popular database programming in relational and nonrelational environments including on AWS Redshift, AWS Aurora, SQL Server and similar platforms.
Experience in working with large, heterogeneous datasets in building and optimizing data pipelines, pipeline architectures and integrated datasets using traditional data integration technologies. These should include ETL/ELT, data replication/CDC, message-oriented data movement and upcoming data ingestion and integration technologies such as stream data integration and data virtualization.
Strong experience in working with and optimizing existing ETL processes and data integration and data preparation flows and helping to move them in production.
Experience in working with both open-source and commercial message queuing technologies such as Kafka, Amazon Simple queuing Service, stream data integration technologies such as Apache Nifi, Apache Kafka Streams, Amazon Kinesis and stream analytics technologies such as Apache Kafka KSQL.
Basic experience working with popular data discovery, analytics and BI software tools like MicroStrategy, Tableau, Qlik, PowerBI and others for semantic-layer-based data discovery.
Basic understanding of popular open-source and commercial data science platforms such as Python, R, KNIME, Alteryx, others is a strong plus but not required/compulsory.
Basic experience in working with data governance, data quality, and data security teams and specifically and privacy and security officers in moving data pipelines into production with appropriate data quality, governance and security standards and certification.
Demonstrated ability to work across multiple deployment environments including cloud, on-premises and hybrid, multiple operating systems and through containerization techniques such as Docker, Kubernetes, AWS Elastic Container Service and others.
Experienced in agile methodologies and capable of applying DevOps and increasingly DataOps principles to data pipelines to improve the communication, integration, reuse and automation of data flows between data managers and consumers across an organization

Interpersonal Skills and Characteristics

Strong experience supporting and working with cross-functional teams in a dynamic business environment.
Required to be highly creative and collaborative. An ideal candidate would be expected to collaborate with both the business and IT teams to define the business problem, refine the requirements, and design and develop data deliverables accordingly. The successful candidate will also be required to have regular discussions with data consumers on optimally refining the data pipelines developed in nonproduction environments and deploying them in production.
Required to have the accessibility and ability to interface with, and gain the respect of, stakeholders at all levels and roles within the company.
Is a confident, energetic self-starter, with strong interpersonal skills.
Has good judgment, a sense of urgency and has demonstrated commitment to high standards of ethics, regulatory compliance, customer service and business integrity.

#LI-AD1

Data Engineer, Enterprise Data",3.6,"Ralph Lauren
3.6",Bengaluru,"New York, NY",10000+ employees,1967,Company - Public,Other Retail Shops,Retail,₹500+ billion (INR),-1
638,Principal Software Engineering - Data Science,"Job Description:


Job TitlePrincipal - Data Science (Data Scientist)

The Purpose of This Role

The Artificial Intelligence Chapter delivers both internal use cases, digital tools and customer facing applications by leveraging a diverse set of data sources. We employ a full spectrum of data science techniques - statistical models, predictive models from machine learning, and topic modeling from natural language processing are all part of the mix. You will work on data science projects at the intersection of machine learning and financial services, with data engineers, software developers, and other data scientists. You will work on all phases of projects, from initial design to the final coding updates to put into production.

The Value You Deliver
Leading & building data science applications from inception to installation for various FMR business units
Supporting existing Analytics, Research & Data interdisciplinary teams, whose members will be data scientists, software developers, and data engineers
Designing and build machine learning models in latest frameworks and algorithms
Communicating project updates & value created through work to both technical and business stakeholders
The Skills that are Key to this role

Technical / Behavioral
You are knowledgeable about machine learning and statistics
Expert in handling various data types and structures: structured, unstructured, voice, static versus streaming data. Extensive prior experience in integrating data
Possess extensive knowledge of and experience in applying data mining and machine learning, deep learning and Reinforcement learning techniques
Expertise in Natural Language Processing (NLP) and Natural Language Understanding (NLU) techniques
You are fluent in Python and SQL with an ability to design, train, and code up machine learning and statistical models (experience with big data platforms such as Snowflake, Spark, and Hive is a big plus)
You know how to work well in a team to deliver on both business and technical requirements
The Skills that are Good to Have for this role
Experience in working with any AI/NLP for building chatbots with any one of the technologies (JavaScript, Node.js or Python).
You have excellent technical communication skills, with an ability to give compelling presentations
How Your Work Impacts the Organization

Analytics, Research & Data delivers business analytics, financial research & data capabilities to various business units with Fidelity. We use data and analytics to personalize incredible customer experiences and develop solutions that help our customers live the lives they want. As part of our digital transformation, we have significant investments to create innovative big data capabilities and platforms. One of them is to build various enterprise data lakes by gathering data across Business Units.

The Expertise Were Looking For
10+ years of hands-on experience in Data Science, Machine Learning/AI use cases
Graduate / Post Graduate degree with focus on Mathematics, Statistics & Programming
5+ years of hands-on Python, SQL programming experience
Location : Bangalore - Manyata/EGL

Shift timings: 11:30 am - 7:30 pm

Certifications:
Category:
Information Technology",4.0,"Fidelity Investments
4.0",Bengaluru,"Boston, MA",10000+ employees,1946,Company - Private,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Charles Schwab, Vanguard, Citi"
639,Data Analyst,"Job Description

About Us :
Since 1997, Magna Infotech has been a leading provider of Technology Staff Augmentation and Solutions in the Indian Subcontinent. The only staffing company with Industry-Focused Verticals, Magna provides its customers with a comprehensive Talent Management solution specific to an industry, geography or business purpose. Our 10,000+ associates are proficient in 500+ skill sets, across multiple industry sectors. They are ably supported by sophisticated internal tools, an industry-leading fulfilment engine and an unparalleled associate engagement and support framework. For associates and employees, we offer an enriching experience that promotes career growth and lifelong learning. With a customer base of 250+ companies, it’s our constant endeavour to be recognized as a “partner-of-choice"".

About Company :
www.magna.in

Roles and Responsibility :
·

Strong business and financial acumen

·

Strong data collation skills, data
interpretation and analysis

·

Experience in bringing out meaningful
insights

·

Monitor/capture various market trends and
financial details of domestic and global markets

·

Strong verbal and written communication
skills, including presentation and executive messaging

·

Draft and present executive level
deliverables and strategic recommendations

·

Extensive experience with data analysis",2.6,"Magna Infotech (India)
2.6",Bengaluru,"Hyderabad, India",5001 to 10000 employees,1997,Company - Private,Staffing & Outsourcing,Business Services,₹100 to ₹500 billion (INR),-1
640,Data Engineer,"Location: India-Mumbai

Responsibilities:
Work with business users and other stakeholders to understand business processes.
Ability to design and implement Dimensional and Fact tables
Identify and implement data transformation/cleansing requirements
Develop SSIS packages using Business Intelligence Development Studio (BIDS)
Test and debug SSIS packages
Determine testing needed to assure the functionality and integrity of the ETL solutions, create test plans, and evaluate testing results taking corrective action as necessary
Visualize data using SSRS
Implementing OLAP (SSAS) cubes
Write SQL code – Queries/Stored Procedures/Functions
Required Skills:
2+ years hands-on experience in data warehouse projects with MS SQL Server 2008/2012
Bachelor’s degree, preferably in Computer Science or equivalent professional experience
Strong SQL writing skills
Hands-on and deep experience with Warehouse schema design
Familiarity with Kimball data warehouse methodology
Experience using Business Intelligence Development Studio (BIDS) to build SSIS packages
Experience in gathering and analyzing business requirements
Understand project-specific requirements, standards, guidelines, and processes
Demonstrated success working in a team-based environment
Good written/oral communication skills
Strong analytical and problem-solving skills

APPLY",3.6,"Quantiphi
3.6",Mumbai,"Marlborough, MA",501 to 1000 employees,2013,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
641,Lead Data Scientist,"Exp: 6 - 10 years

Preferred: Talents from Tier 1 Global Schools

Advanced degree (Ph.D. preferred) in Engineering, Science, Mathematics, or related
Expert knowledge of probability, statistics and machine learning theory including experience in: Deep Learning, Clustering, Decision Trees, Logistic Regression, Dimensionality Reduction, and Random Forests for prediction and recommendations.
Expert knowledge of Experimental Design and Statistical Decision Theory
3+ years working with business stakeholders as a trusted adviser in Data Science and Monetization
3+ years providing mentorship, education, and thought leadership to organizational stakeholders regarding best practices in data science
Microsoft IoT/data science toolkit: Azure Machine Learning, Datalake, Datalake analytics, Workbench, IoT Hub, Stream Analytics, CosmosDB, Time Series Insights, PowerBI
Experience working in a start-up environment, preferably in an IoT/AI company
Preferred: Building IoT analytics models, including failure diagnosis and failure prediction
Preferred: Executing customer advanced analytics, including marketing mix analysis, segmentation, retention modeling, targeted marketing, basket analysis, next product recommendation

Role:
Gather and analyze data, devise innovative data science solutions and build prototypes to enable development of high-performance algorithms in scalable, product-ready code
Understand problems from the client’s point of view, build and execute solid analytics work plans, gather and organize large and complex data assets, perform relevant analyses (data exploration and statistical modeling), manage priorities and deadlines, foster teamwork in interactions, develop client relationships with client counterparts, and communicate hypotheses and findings in a structured way
Passion for understanding business problems and trying to address them by leveraging data - characterized by high-volume, high dimensionality from multiple sources
Design, develop and implement real-time, highly complex advance machine learning models to solve real time company problems
Experience with building predictive statistical, behavioral or other models via supervised and unsupervised machine learning, statistical analysis, and other predictive modeling techniques
Contribute to Company IP and patent portfolio/s
Extensively publish in NIPS, Kaggle, JML, ICLR, nature ,nuerocomputing. etc",-1,Staffio HR,Bengaluru,"Bengaluru, India",1 to 50 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
642,Data Analyst,"Data Analyst 1 to 5 years work experience. Determination in working in a high data volume environment. Fresh graduate will also be considered. Combination of analytical, technical savviness and business acumen.

Good understanding of experimental approaches in Degree or equivalent experience in Computer Science, Data Science, Statistics, Operations Research or any other quantitative discipline preferred. Coimbatore Gather, organize, analyze and input information from proxy reports, news and earnings press releases, corporate descriptions and other relevant stock information Use a variety of data analysis tools to explore our existing data sets to uncover The Data Analyst role is a hands on individual contributor responsible for end-to-end design, development deployment of analytics solutions for assigned projects. We are looking for an energetic Analyst with proven record of developing solutions pertinent to identification, analysis and interpretation of patterns from complex data problems.",3.0,"Sripathi Paper and Boards
3.0",Coimbatore,"Coimbatore, India",201 to 500 employees,-1,Unknown,Industrial Manufacturing,Manufacturing,₹1 to ₹5 billion (INR),-1
643,"Staff Data Engineer, Platform (APAC)","MongoDB is the leading modern, general purpose database platform, designed to unleash the power of software and data for developers and the applications they build. Developers around the world are using MongoDB to build software to create new businesses, modernize existing businesses, and transform the lives of millions of people around the world.

Headquartered in New York, with offices across North America, Europe, and Asia-Pacific, MongoDB has more than 17,000 customers, which include some of the largest and most sophisticated businesses in nearly every vertical industry, in over 100 countries.

MongoDB is growing rapidly and seeking a Staff Data Engineer to be a key contributor to the overall internal data platform at MongoDB. You will build data driven solutions to help drive MongoDB's growth as a product and as a company. You will take on complex data-related problems using very diverse data sets.

Our ideal candidate has experience with
Several programming languages (Python, Scala, Java, etc.)
Data processing frameworks like Spark
Streaming data processing frameworks like Kafka, KSQ, and Spark Streaming
A diverse set of databases like MongoDB, Cassandra, Redshift, Postgres, etc.
Different storage format like Parquet, Avro, Arrow, and JSON
AWS services such as EMR, Lambda, S3, Athena, Glue, IAM, RDS, etc.
Orchestration tools such as Airflow, Luiji, Azkaban, Cask, etc.
Git and Github
CI/CD Pipelines


You might be an especially great fit if you
Enjoy wrangling huge amounts of data and exploring new data sets
Value code simplicity and performance
Obsess over data: everything needs to be accounted for and be thoroughly tested
Plan effective data storage, security, sharing and publishing within an organization
Constantly thinking of ways to squeeze better performance out of data pipelines
Nice to haves
You are deeply familiar with Spark and/or Hive
You have expert experience with Airflow
You understand the differences between different storage formats like Parquet, Avro, Arrow, and JSON
You understand the tradeoffs between different schema designs like normalization vs. denormalization
In addition to data pipelines, you're also quite good with Kubernetes, Drone, and Terraform
You've built an end-to-end production-grade data solution that runs on AWS
You have experience building machine learning pipelines using tools like SparkML, Tensorflow, Scikit-Learn, etc.
Responsibilities

As a Staff Data Engineer Platform, you will:
Estimate task complexity, report progress, and voice risks to peers and managers
Both learn from and teach peers and junior engineers
Develop and maintain expertise in big data best practices
Design and build large-scale batch and real-time data pipelines with data processing frameworks like Spark on AWS
Help drive best practices in continuous integration and delivery
Help drive optimization, testing, and tooling to improve data quality
Collaborate with other software engineers, machine learning experts, and stakeholders, taking learning and leadership opportunities that will arise every single day


Success Measures

In 3 months

you will have familiarized yourself with much of our data platform, be making regular contributions to our codebase, will be collaborating regularly with stakeholders to widen your knowledge and helping to resolve incidents and respond to user requests

6 Months

you will have successfully investigated, scoped, executed, and documented a small to medium sized project and worked with stakeholders to make sure their data needs are satisfied by implementing improvements to our platform

12 Months

You will have become the key person for several projects within the team and will have contributed to the data platform's roadmap. You will have made several sizable contributions to the project and are regularly looking to improve the overall stability and scalability of the architecture

Do you know, Why MongoDB is a fantastic place to work and build your career?
Disrupting a $64 Billion market
Top NoSQL database in the world
Largest Ecosystem and the fastest growing database in the world
Close to 17,000 customers in over 100 countries and over 90+ million downloads
>120% net ARR expansion rate over each of the last twenty quarters
Sequoia Capital and a number of other Top VC firms have invested in MongoDB. Sequoia Capital calls us out as one of their flagship portfolios; Sequoia has also invested in Apple, Google, Youtube, and WhatsApp
9-figure revenue company, with very high double-digit growth rates
Be a part of the company that's reinventing the database, focused on innovation and speed
Enjoy a fun, inspiring culture that is engineering focused
Work with talented people around the globe
Learn, contribute, and make an impact on the product and community.


Life at MongoDB

Our India office culture
180+ people, with teams in Sales, Engineering, HR, Finance, IT & Marketing
Regular group outings and opportunities to get to know your colleagues
Employee affinity groups


Our Benefits
Competitive salary and equity
Comprehensive Health cover, dental cover, travel insurance & Life Insurance.
Free lunch twice per week and a fully stocked kitchen with healthy and sweet treats.
Macbooks are company standard
26 weeks Maternity & 20 Paternity leave to spend time with new arrivals.",4.6,"MongoDB
4.6",Gurgaon,"New York, NY",1001 to 5000 employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
644,Data Engineer (SQL and Python),"Springer Nature opens the doors to discovery for researchers, educators, clinicians and other professionals. Every day, around the globe, our imprints, books, journals, platforms and technology solutions reach millions of people. For over 175 years our brands and imprints have been a trusted source of knowledge to these communities and today, more than ever, we see it as our responsibility to ensure that fundamental knowledge can be found, verified, understood and used by our communities – enabling them to improve outcomes, make progress, and benefit the generations that follow.

Visit: group.springernature.com and follow @SpringerNature

Springer Nature is seeking a highly motivated Data Engineer for its highly-regarded Analytics Centre of Excellence serving the Research division that includes Nature, Springer, BioMedCentral and ScientificAmerican.

As a Data Engineer, you’ll be building big data pipelines from very highly trafficked websites and content. You will provide the engineering that supports analysis and insight into the behaviour of researchers in both their roles as authors and users of scientific information as well as general trends in the world of research. Driving change that improves their experience with SpingerNature and supports our purpose to advance discovery.

Roles and Responsibilities

Develop, document and maintain robust processes that transform and clean data for input into a variety of live systems and analytical workflows
Maintain process quality and robustness through coding best practice, including version control, documentation and peer review
Partner with Product Owners to establish and maintain the data pipelines (ETL/Batch/Streaming) from different source data platforms to a central platform.
Develop analytics layers, transformations from source data systems, enriching data and providing the views and variables needed for the wider business to gain the most value from the data.
Develop predictive modelling pipelines from production to analytics to data science and back into production
Implement cutting edge solutions to help us become best-in-class data handlers
Consult with stakeholders throughout the business to shape and implement solutions in support of business objectives

Role Requirement

University degree with a strong analytical/quantitative background or equivalent experience (e.g. Data Science, Statistics, Mathematics, Econometrics, Physics, Computer Science etc.)
Excellent working knowledge of SQL, Python or Java, cloud data engineering platforms and database and software engineering principles
Experience with Google Cloud Platform preferred: Bigquery, Dataflow, Cloud Composer etc.
Demonstrable experience of using data engineering in achieving the wider goals and strategy of the business
Well organized and accurate with good time management
Visit the Springer Nature Editorial and Publishing website at www.springernature.com/editorial-and-publishing-jobs for more information about our Research E&P career opportunities.",3.2,"Springer Nature
3.2",Pune,"Heidelberg, Germany",10000+ employees,2015,Company - Private,Publishing,Media,Unknown / Non-Applicable,-1
645,Data Analyst,"Job Location : Pune
Experience: 1-3 years
Job Description :

Day to Day job as a Data Analyst:
Implementations of new clients which includes code/configuration changes in php
Testing of newly Implemented Clients on Test and Production environments
Explores and interpret large volumes of data in various forms
Includes Analyzing/resolving/responding to tickets that come via ticketing tool.
Involved in creating and following up on Jira issues with the developers/co-workers
Creates and evaluates the data needs of support tickets and assures the integrity of the data
Dealing with basic Linux commands
Dealing with version control system (Git)
What we would look for in a Data Analyst:
Bachelor’s Degree or Masters in computer application.
At least 1-3 years of data analysis experience
Should have strong knowledge in SQL.
At least 1-2 years of experience interacting directly with clients in a Professional Services or Technical Support role
Strong communication and interpersonal skills
Consultative approach to problem-solving and excellent judgment
Unwavering integrity, attention to detail, and desire to exceed client expectations
Experience with business tools such as Microsoft Office, Github, and Jira
Basic knowledge of Software testing is a plus
Job Type: Full-time

Experience:
total work: 1 year (Required)
SQL: 1 year (Required)
Work Remotely:
Temporarily due to COVID-19",4.0,"Live Connections
4.0",Pune,"Chennai, India",201 to 500 employees,1996,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
646,Data Scientist - Job Code(NLP-18),"Job Description :
Responsibilities:
Sound experience in AI, Natural language processing, Machine Learning
Experience in Language Modelling, POS tagging, PCFG, Named Entity Recognition, Co-reference Resolution, Question Answering etc
Good understanding of various classification techniques such as Clustering, Logistic Regression, CRFs, MEMM, Neural Networks, SVMs, Decision Trees etc
Coding experience with Python and SQL/NoSQL databases, familiarity with Linux
Candidates with Publications in reputed conferences or journals are preferred
00-4.00 Years",4.1,"UVJ Technologies Private Limited
4.1",India,"Cochin, India",201 to 500 employees,2003,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
647,Data Engineer,"When everything's connected, how we connect is everything… and we'd like to connect with you too! We are looking for you to help us deliver exceptional customer experiences as a Data Engineer.

As a technologist, we know you’re in high demand. And we know it’s important you find the right fit for your future. Have ideas you want to contribute? We’re listening. Looking for exposure to different clients, different technologies? It’s what we do. Want to make an impact on the future? We’re innovating every day. Teamwork key? You'll have the opportunity to work on global projects with a knowledge-thirsty, international team. Join our inclusive Corporate IT team and you’ll help create meaningful employee experiences that drive memorable customer experiences.

What you’ll be doing
The data engineer will be responsible for all aspects of execution and delivery for new and ongoing client implementations of the analytic platform. This will require working with clients and coordinating with internal business consulting, analyst, data science, and technology teams.
Technical and functional analysis of customer implementation and integration requirements
Documentation of implementation requirements and expected effort
Configuration and setup of the analytics platform
Configuration of data loaders and development and configuration of workflow processes and customizations to the platform
Participate in testing
Proactive identification of internal and external dependencies, highlighting issues, scope changes, and progress against project plan
Communication of project status/issues to clients and internal management
Partner with various internal teams
Provide technical support to assist clients and partners during and post implementation.

What you'll bring to the role
Bachelor’s Degree in Computer Science, Information Systems or related with 2-3 years of relevant experience
In-depth familiarity with Big data technology and its application.
Proficiency with the Azure or AWS ecosystem
Experience with Big Data ETL
Understanding of complex data flows, identification of data processing bottlenecks and designing and implementing solutions.
Proficiency in .NET, C#, Python, Linux bash, Power Shell.
Experienced in consuming third-party REST APIs (JSON) and SDKs
A broad set of technical skills and knowledge across hardware, software, systems and solutions development and across more than one technical domain.
Experienced in U SQL, PostgreSQ, TSQL
Experience in professional services or technical consulting with enterprise software solutions, specifically enterprise software installation, configuration, customization, and testing.
Proven ability to balance and manage multiple, competing priorities.
Collaborative interpersonal skills and ability to work within cross-functional teams.
Self-starter who relies on experience and judgment to plan and accomplish goals in complex fast-paced environment to ensure quality of all data integration points.
Excellent customer service skills.
Creative problem-solving and analysis skills.
Ability to handle problem situations quickly, inventively, and resourcefully.
Project management skills including:
Ability to prioritize and manage tasks
Ability to plan, commit, and deliver to schedules
Ability to identify, escalate, and manage project issues
Willingness to work extended hours on an as-needed basic

#LI-IG1",3.4,"TTEC
3.4",Hyderabad,"Englewood, CO",10000+ employees,1982,Company - Public,Staffing & Outsourcing,Business Services,₹100 to ₹500 billion (INR),"Teleperformance, TaskUs, Convergys"
648,Sr. Business Intelligence Analyst,"Bachelor's degree in Business, Engineering or a related field
5+ years of professional experience in analytics, business analysis or comparable consumer analytics position
Advanced working knowledge of data mining using SQL, ETL, data warehouse as well as Excel
Excellent communication (verbal and written) and interpersonal skills and an ability to effectively communicate with both business and technical teams.
High business accumen, problem solving skills, project management skills, attention to detail, and exceptional organizational skills
Ability to deal with ambiguity and competing objectives in a fast paced environment
Ability to display complex quantitative data in a simple, intuitive format and to present findings in a clear and concise manner
Excellent organizational skills including prioritizing, scheduling, time management, and meeting deadlines
A self starter, who proactively converts gaps into opportunities
At Amazon, we are working to be the most customer-centric company on earth. To get there, we need exceptionally talented, bright and driven people. Are you relentless? Are you passionate about leveraging data to deliver actionable insights that could impact the daily business decisions at Amazon India? Does the prospect of dealing with massive volumes of data excite you? Do you love using data to answer challenging product and customer behavior questions? Would you like to be part of the next big thing while it’s still day one?

This role is with the Direct Fulfillment team of Amazon. We are looking for a Business Intelligence Analyst to drive important data driven decisions for the team.

you will used advanced analytical techniques to develop solutions that answer business questions related to selection performance and customer experience. Specific responsibilities include:
Analyse large data sets to build a channel allocation model for new or existing selection on DF. This would require building recommendation models for new selection while looking at speed & profitability of similar selection. May also require collaborating with ML team to build ground truth data and productize the model
Interface with business groups to gather data and metrics requirements
Develop automated, scalable analytical solutions for large-scale, business-critical problems. For eg: building a self-service tool for category managers to assess health of DF business
Translate analytic insights into concrete, actionable recommendations for business or product improvements. Work with several internal teams to drive action on recommendations. The individual will not just own the analysis but also driving adoption and results through stakeholder collaboration.
Support strategic data analysis requests, prioritizing based on business needs
7+ years of relevant experience in a business analyst, data analyst or statistical analysis role
Advanced technical or business degree (MS or MBA)
Experience in developing requirements and formulating business metrics for reporting, familiarity with data visualization tools, e.g. Tableau, PowerBI, Quicksight",-1,ASSPL - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
649,Machine Learning Engineer,"Job Location
Mountain View, California or Pune, India

Role and Responsibilities
Engineering core machine learning capabilities in our IoT platform by building tools and high-performance infrastructure for running ML models at the edge.
Creating supervised and semi-supervised ML models for the platform.
Core Qualifications
Candidates must meet ALL of the following qualifications.

Experience in Agile software development with strong programming experience in C++ or Python.
Experience in building and using high-speed data processing infrastructure and tools.
Have used or developed high performance C++ packages (e.g. LAPACK, BLAS, YOLO etc.)
Some experience with real-time stream processing data systems.
Training in data mining or statistics, enough to understand the context of developing software to be used by data scientists.
Algorithm experience in the families of predictive algorithms (regression, neural nets, decision trees) and clustering algorithms (k-means or other).
Bonus Qualifications
Any of the following extra qualifications will make a candidate more competitive.

Strong experience with C++ development and high-performance computing.
Cython programming or written python wrapper for C++.
Experience developing Machine Learning software infrastructure, algorithms and libraries.
Training or experience in Deep Learning, such as Keras, TensorFlow, convolutional neural networks (CNN) or Long Short Term Memory (LSTM) neural network.
Experience with PMML or PFA or TFR is of interest (see www.DMG.org).
How To Apply
To apply, submit resume and cover letter to HR at jobs@foghorn.io.
Indicate how you meet core and bonus qualifications including two to four detailed paragraphs of three data mining projects you have deployed.",4.0,"Foghorn Systems
4.0",Pune,"Palo Alto, CA",1 to 50 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹10 to ₹50 million (INR),-1
650,Advance Analytics Consultant,"Role

Advance Analytics Consultant

Business Function

Global Analytics and Web Insights
Reports to

Sr. Manager – Global Analytics & Web Insight

Department

Asset, Pricing and Operations
Nature and Purpose:

The role will be responsible for the creation and maintenance of advanced analytical models working with global stakeholders within Farnell and Avnet. The post holder will be assigned key projects, including those aligned to the Avnet Intelligence Programme (AIP), to develop best in class processes and techniques to leverage data sciences. This is a global role based in India, day to day management will be from Bangalore with direction provided from the Marketing Insights and Analytics Manager in Leeds.

Data quality and integrity should be consistently adhered to, as to ensure accurate and consistent reporting and decision making
Accountabilities with Key Outcomes:
1

Day to day the role will be responsible for:
Develop, enhance and maintain advanced analytic models that generate new business insights and/or deliver predictive services for the business.
Leverage predictive analytics, experimental data designs and models to drive business performance.
Develop predictive models such as customer churn, NPS, attribution, market basket analysis and customer Life Time Value (cLTV).
Partner with Leadership team (Farnell and Avnet), eComm/Marketing, BI and other Business Units to develop best in class processes and techniques to leverage data sciences (i.e. predictive modelling) across the Avnet ecosystem.
Globally responsible for assigned business analytics and reporting across network of MDD transactional websites/marketing platforms to achieve business sales per day performance in accordance with overall strategy.
Customer level reporting and analysis of our marketing programs leading to improved overall performance.
Manage, lead and develop a matrix team to ensure the successful execution and innovation of our proposition
Lead core insights from the data to suggest, create and execute fundamental improvements to marketing campaigns.
Transform large, complex, disparate, and often raw (normalized) data sets into quantifiable relationships, trends, and actionable insights.
Produce analytics that drive and measure progress including calculations to inform/influence marketing programs and multichannel activity, as well as measure the effectiveness of marketing (ROI).
Deliver forward looking marketing insights; understand industry trends and evolving external landscape that may inform/influence strategic plans.
Combine business data, industry benchmarks, and emerging industry trends to produce insights that inform the marketing strategy, customer experience, and customer segmentation at a global level.

2

Project Management and Training
Manage end to end deliverables of the projects, regular task and ad-hoc work by adhering to timelines and stakeholder expectations
Ensure that the Standard Operating Procedures are followed where applicable and all relevant documents are updated
Work with team members within the wider Business Analytics team as mentor

3

People Management
Day-to- day management and oversight for functional teams within Analytics matrix structure. This would include
– Coaching and performance management

– Workflow allocation within the team

– Escalation handling and management
4

Business Development
Work with the Leadership and Business Stakeholders to develop pipeline for projects
Support the expansion of Farnell initiatives into the wider AIP
Develop personal in-depth relationship with key business leaders and ensure continuous inflow of Business-As- Usual and project work

5

Stakeholder Management
Manage Stakeholder interactions by having regular updates and growing stakeholder engagement
Meeting /exceeding quality and timeline expectations for all projects
Design, plan and scope out projects with stakeholders
Explain project methodology and project approach to required stakeholders

Knowledge, Skills and Experience:
Essential

Experienced Analyst with 5+years complex analytics including 2+years of experience in Advance Analytics

Experience in Statistical models; Marketing Analytics concept is must

Marketing Analytics / data modeling / experience with core analytics tool sets (e.g. R,SAS,SPSS, SQL, Advance Excel etc)

Understanding of data nuances and focus on quality

Demonstrated experience and in-depth knowledge with advance/web analytics and measurement tools such as Statistical Modelling

Familiarity with development procedures, preferably in an ecommerce environment

Flexible, able to respond immediately to often changing business priorities

Must have the ability to combine strategic and analytical skills with creative and visual skills

Razor sharp written and verbal communication and presentation skills

Thorough understanding of website metrics, data analysis, behavioral analysis and reporting tools.

Desirable

Master’s/Bachelor's Degree in business, marketing or statistics",2.7,"Premier Farnell
2.7",Bengaluru,"Leeds, United Kingdom",1001 to 5000 employees,1934,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,₹100 to ₹500 billion (INR),RS Components
651,Principal Data Scientist,"DirecTech Labs is hiring a Principal Data Scientist to join its team! This role will play an integral part in the building, growing and nurturing of our maturing predictive analytics start-up. You'll have a chance to drive the behavioral intelligence that powers our actionable analytics and global messaging platform with over a million users and 20 million lifecycles in our database. You will be a key member of the data science team working to improve current behavioral models, develop new ones, and prove the efficacy and business impact of our global messaging and alerts. You’ll also support the product team in the creation and validation of new analytics for our dashboard.

We are looking for a mixture between a statistician, machine learning expert and engineer with an interest in predictive analytics and an ability to communicate their ideas and findings in a comprehensive and digestible way to business persons and IT alike: someone who has a passion for building data products and services, especially ones that seek to understand, segment and predict human behavior. The ideal candidate has experience with creating insights and predictions around human behavior, understands the principles of behavioral science and knows what to look for in the data to generate meaningful insight.

If you're a scrappy builder backed by deep data analytics experience and looking to play a pivotal role within a maturing startup, this one is for you.

What You'll Do:
Gather, evaluate and document business requirements, translate to data science solution definitions, and implement solutions using such tools and languages as SageMaker, Jupyter Notebooks, Spark, Tensor Flow and Python.
Analyze all data from all available sources (e.g. behavioral, sales, performance, social) to identify and inform Product and Customer Experience teams areas of opportunity for product performance insights, optimization and future features.
Leverage your statistical and computational knowledge along with a passion for human behavior to design and build algorithms to solve challenging problems.
Ability to design and build an end-to-end prototype data science solution to a business problem
Build a behavioral profile and segmentation model aggregating personal attributes, psychologic attributes, past and predicted future behaviors to create customer genomes.

About You:
You have a MS in Statistics, Machine Learning, or Predictive Analytics from a Tier 1 University
You have 8+ years creating predictive models using advance machine learning techniques
You have proven work examples of turning significant amounts of data into informative/insightful actions through various statistical techniques that turn into explosive and accurately measured business results
You have an expert command of statistical analysis, algorithm development, and state-of-the-art tools and methodologies for data science
You have previous experience building advanced ML algorithms for prediction of churn, predicting the future lifetime value of a person, predicting future customer behavior and predicting upsell/cross sell opportunities
Proficiency in methods in analytics and data science algorithms including decision trees, probability networks, association rules, clustering, regression, and neural networks.
You have an expert command of SQL and Python as applied to data science with experience
You have excellent communication and presentation skills to be able to manage expectations both up, down and outside the organization
You don't shy away from a challenge, are curious and looking to make a big impact
You are comfortable wearing multiple hats and want to get your hands dirty
You know how to spot an issue (technical or interpersonal) and can tactfully and effectively resolve it before pressure starts to build
You are a critical thinker, not afraid to question and be questioned
You take your own initiative to identify and solve problems without needing a hierarchical structure to tell you what to do
You love to explain your work and are great at helping people understand and believe in your results

Bonus Points if:
You already have experience in the direct sales industry, gig economy company or another account based industry (insurance, real estate, etc…)

You know that game theory is more than just “Points” and loyalty programs.

What You'll Get:
An amazing company culture that encourages creativity, personal growth, work/life balance, fun and teamwork.
The chance to work for a “data” company building “data” products.
Working with ""A Players"" across the organization.
Huge opportunity to build something in an industry that is hungry for solutions.
Competitive salary, fully paid health benefits and paid vacation in the business you help create!

Employment Type: Full-Time – Cool Office in Noida Sector 62. – REMOTE-WORK FROM HOME IS POSSIBLE",4.4,"DirecTech Labs
4.4",Noida,"Santa Monica, CA",1 to 50 employees,2016,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 million (INR),-1
652,Data Analyst/ Senior Data Analyst,"Analyst:

Engineers with 0-3 years of experience from IITs, NITs, BITS, PSG College of Technology, VIT, CBIT, ICFAI and similar good schools.

Responsibilities:
Understanding and synthesize the client requirements and information
Decide approach while thinking through possible deadlocks in advance
Get actionable insights from data with analytical tools like Project R, SQL, R, Python etc. which can be used in real time in all decision making
Create new statistical models/ improve existing models

Qualifications:

Proficiency in SQL, R, Python, Advance Excel and VBA or other analysis/ programming language. (Intermediate level)
Expertise and strong experience in data gathering and analysis
Good analytical and communication skills
Candidates with strong business knowledge
Hands on expertise in Data modelling, Data migration & Data consolidation tools through working on online analytical projects / internships / Job.
Important:

Please write good cover letter as we give high importance to the same while evaluating a candidate. We recommend you to spend sufficient time and effort in writing a good cover letter. Applications without a cover letter will be ignored by the Talent Acquisition Team.
Please create your Cover Letter around the following points:
Reason to join Perceptive Analytics
Mention the snapshot of Data Analytics Project pursued during the Academics or Internship/Job, if any
Information on skills acquired and technical know-how
Achievements, if any
Note: Please ensure that you write about the following statement in your cover letter, in a separate paragraph. This will help us to gauge your understanding about the position and your overall thought process for this role. Overlooking this will lead to rejection of your resume.

“In god we trust. Everyone else must bring data.”

About Perceptive Analytics

Perceptive Analytics is a Data Analytics company, offering specialized services in Data Analytics, Web Marketing Analytics, and Spreadsheet solutions. We serve large to medium sized companies USA and India.

We have the reputation of being known as a trusted partner/advisor with a penchant to deliver compelling value. Perceptive Analytics provides solutions to problems in industries across multiple sectors such as Banking, Finance services and Insurance and e-commerce.

Perceptive is known for its employee friendly approach. You will have continuous training, sports facilities, medical insurance, access to world class journals and above all, a fun environment to work in. Bright candidates will also be eligible for stock options.

Every employee here is an owner of his/her project. Direct connect with the clients gives a complete freedom to an employee to handle their projects. Different industry projects lead to exposure to an employee. There is no space for monotony - every day is a new challenge.",3.9,"Perceptive Analytics
3.9",Hyderabad,"Hyderabad, India",1 to 50 employees,2013,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
653,Data Engineer,"The thrill of working at a start-up that is starting to scale massively is something else.

Simpl (getsimpl.com) was formed in 2015 by Nitya Sharma, an investment banker from Wall Street and Chaitra Chidanand, a tech executive from the Valley, when they teamed up with a very clear mission - to make money simple, so that people can live well and do amazing things.

Simpl is the payment platform for the mobile-first world, and we’re backed by some of the best names in fintech globally (folks who have invested in Visa, Square and Transferwise), and has Joe Saunders, Ex Chairman and CEO of Visa as a board member.

Everyone at Simpl is an internal entrepreneur who is given a lot of bandwidth and resources to create the next breakthrough towards the long term vision of “making money Simpl”.

Our first product is a payment platform that lets people buy instantly, anywhere online, and pay later. In the background, Simpl uses big data for credit underwriting, risk and fraud modelling, all without any paperwork, and enables Banks and Non-Bank Financial Companies to access a whole new consumer market.

Responsibilities

You will be focused on making sure of data correctness and accessibility, and building scalable systems to access/process it. Another major responsibility is helping AI/ML Engineers write better code. You will also build scalable, high performance data intensive services.

Examples:

- We have data pipelines processing aggregate and statistical data. Should we store this

in Redshift, in flat files in S3, or somewhere else?

- How should we structure our data pipelines?

- We need to track various data points to identify our customers in various locations, including from different devices, and determine that two seemingly disparate users are actually the same. How can we do this efficiently and effectively?

Your job is to understand what we’re trying to build, make informed choices about this and then get us going.

Example interview questions:

- Consider the query `SELECT * FROM foo INNER JOIN bar ON foo.x = bar.x WHERE foo.primary_key = ?`. What happens if you run this in Postgres? How does that differ if you run it in Redshift, or SparkSQL?

- Suppose we store a table in flat CSV files on S3. What kinds of jobs is this good for, and bad for? How is Parquet or BerkeleyDB different?

- What data structures are good for storing a graph, assuming the common query is finding a connected component?

On these questions, we’re primarily interested in computer science fundamentals. A good answer might be “a B-Tree, with keys structured as ...”. A bad answer might be be “use Neo4J, I don’t know how it works but it’s fast”.",4.3,"Simpl
4.3",Bengaluru,"Bengaluru, India",51 to 200 employees,2015,Company - Private,Financial Transaction Processing,Finance,Unknown / Non-Applicable,-1
654,DATA SCIENTIST /,"Exposure to ML concepts - Probabilistic Models, Supervised and Unsupervised Learning, Neural Networks & Deep learning, Ensembling. Understanding of concepts behind Machine Learning algorithms such as Probability, Statistics, Linear Algebra. Exposure to libraries such as theano, tensorflow, keras, torch, caffe etc.",-1,HelloLeads,Tiruchchirappalli,"Tiruchirappalli, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
655,Data Scientist Embedded Systems Innovation,"We are looking for self-motivated scientists & engineers to join our supercharged workplace and build a first generation analytical product. If you are a geek about anything – algorithms, math, machine learning, data wrangling/visualizing, high performance computing, scientific computing & tools, or anything else you can convince us about – we want to meet you!

You will :
Individual technical contributor with self-drive to understand problem statements and make design decisions – ‘own’ what you do, make your calls, and defend them
Build a first generation analytical software product – design, code, test (unit & functional) and maintain the software, while proving that your implementations ‘work’
Implement software engineering processes and discipline for fast and reliable development of high-quality software product – make the software ‘elegant’
Work as a team player in a high performance environment that rewards ownership – make your opinion count withing the team and the organization

You Have :
Bachelors or Masters in CS / Electronics from a premier institute with 3-7 years of industry experience
Solid design, excellent programming and debugging skills on a Unix-based OS (Ubuntu, Fedora, OSX) and fluency with a DVCS like Git.
Programming Languages: Python, C++
Any of these – more the better!

Skilled with python packages: scikit-learn, pandas, numpy and scipy
Understanding of common algorithms and their application in solving real-world problems
Strong mathematical background in linear algebra, optimization and descriptive & inferential statistics
Understanding of machine learning concepts like generalization, regularization, linear models, neural network and expertise with using data to build systems based on machine learning techniques
We value intellectual curiosity, open communication and creative thinkers who know how to stand up and be counted. If this sounds like who you are, we should talk.

Write to deepa.m@careerxperts.com to get started!",-1,CareerXperts,India,"Bangalore, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
656,Data Analyst,"Data Analyst

Salary: 15k to 25k

Exp: 2+ year

Loc: Noida

Complete Knowledge of Power Bi

Job description

 Interpret data, analyze results using statistical techniques and provide ongoing reports

 Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality

 Acquire data from primary or secondary data sources and maintain databases/data systems

 Identify, analyze, and interpret trends or patterns in complex data sets

 Filter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems

 Work with management to prioritize business and information needs

 Locate and define new process improvement opportunities

Interested candidate kindly contact

Manish Rana

9310202047

Forever Placement

Job Type: Full-time

Salary: ₹15,000.00 to ₹25,000.00 /month

Experience:
work: 1 year (Preferred)
Power bi : 1 year (Preferred)
Education:
Secondary(10th Pass) (Preferred)",-1,Forever Placement,Noida,"Noida, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
657,Data Analyst,"At f5websolutions we are looking to hire a full time data analyst with experience of 4 years.
Knowledge on Amazon Product listing , Order processing , payments , Reimursement , Amazon seller central , Amazon Market Web Service is required.
Must have good communication skills in English , both verbal and written.
Job Type: Full-time
Salary: ₹20,000.00 to ₹25,000.00 /month
Experience:
Amazon Market Web Service: 1 year (Required)
Amazon Order and payment process: 1 year (Preferred)
Amazon Product listing: 2 years (Preferred)
Education:
Bachelor's (Preferred)
Location:
Pune, Maharashtra (Preferred)
Shifts:
Evening (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,F5websolutions,Pune,-1,-1,-1,-1,-1,-1,-1,-1
658,Data Analyst,"Experience
2 Years
Location
Vijayawada
Role
Data Analyst
Your Skills
Tableau / Microsoft Power Bi (Model development using statistical methods ,Analyze data and generate insight - result interpretation and presentation, analyze data using statistical techniques and provide adhoc and ongoing reports)
Job Description
Product development Envisage the product features as per requirement, plan and execute.
Maintaining heigh coding standards and practices and exercisequality control on all aspect of web developement
Breaking new ground, researching and implementing innovative web technologies and features .
problem-solving in all areas of web development
Industry Type
IT Software, Software services
Functional Area
IT Software-Application Programming, Maintainance",-1,Entrolabs It solutions,Vijayawada,-1,-1,-1,-1,-1,-1,-1,-1
659,Data Analyst,"PEOPLE REQUIRED FOR HINGLISH TRANSCRIPTION, THEY NEED KNOWLEDGE IN HINDI AND ENGLISH. AND SHOULD HAVE A GOOD TYPING SPEED.
Job Types: Full-time, Temporary, Contract
Salary: ₹200.00 to ₹500.00 /HR
Qualification: +2 Pass
No age limit
Language:
ENGLISH (Required)
HINDI (Required)
Job Types: Full-time, Part-time, Fresher, Walk-In
Salary: ₹150.00 to ₹500.00 /hour
Experience:
0: 1 year (Required)
Education:
Higher Secondary(12th Pass) (Required)
Work Remotely:
Yes",-1,SWASTIK CONTECH PRIVATE LIMITED,Khandagiri,-1,-1,-1,-1,-1,-1,-1,-1
660,Data Analyst/Business Analyst,"We are looking for a Business Analyst with a minimum of 6 Months of Work Experience with Technology field and MBA Graduate. You will be working on support technical experts who have experience in designing and developing applications including new developments, enhancements, maintenance and support. The role involves continuous collaboration with customers, offices in Australia, Singapore and USA. Once you have an understanding of the platform, you will be expected to create well-written requirements, following best practices/ methodologies, this role may include overseas travel.
Ultimately you will be responsible for requirements specifications and documentation of the platform.
This is your opportunity to work with leading Financial Software Services Organisation.

Required Skills
Facilitate requirements sessions and produce well-written documentation that effectively
Experience in reverse engineering and understanding existing applications
Decipher data patterns, workflow and interactions.
proficient in agile practices(backlog management, story writing, story mapping, visual planning, use of personas, outcome-based planning, etc.).
Experience working with distributed teams in different time-zones
Strong commitment to quality
Strong communication skills, problem-solving skills and adaptability
A passion for technology and the financial domain with demonstrated ability to learn quickly
Preferred Skills
Knowledge of how software development lifecycle works.
Exposure to software languages and frameworks.
Prior background in cloud technologies
Behavioural attributes
Ability to take ownership
Strong Inclination to understand the business area
Excellent collaboration and interpersonal skills
Great attitude, being a team player and effective contributor
Focused on productivity
Willingness to learn based on the job.
Perks and Benefits
12 Days Leave & Generous Bonus & Other Opportunities

RoleBusiness Analyst
Industry TypeIT-Software / Software Services
Functional AreaIT Software - Application Programming, Maintenance
Employment TypeFull Time, Permanent
Role CategorySystem Design/Implementation/ERP/CRM

Job Type: Full-time

Job Type: Full-time

Salary: ₹15,000.00 to ₹30,000.00 /month",2.4,"IESL
2.4",Chandigarh,"Lagos, Nigeria",201 to 500 employees,-1,Company - Private,Oil & Gas Services,"Oil, Gas, Energy & Utilities",Unknown / Non-Applicable,-1
661,Data Analyst,"Work Location: Chennai

Required Experience: 3 to 5 years

Job Description:
Knowledge on R Programming, VBA, Macros
Proficient in Microsoft excel with exposure on Pivot tables, Vlookup, logic formulas
Presenting various analysis and reports to the management as and when required
understanding of Marketing and the importance of clean/ accurate lists.
Understanding of data privacy & compliance (ie: GDPR)
Demonstrated experience in design, develop and maintain BI reports, optimizing efficiency in manipulating data and writing complex queries
Build an understanding of business and operational strategies and identify critical metrics required to support those strategies
Experience in working with large datasets,derive insights and present information through visualization and reports",4.8,"iKomet Technology Solutions
4.8",Chennai,"Chennai, India",1 to 50 employees,2015,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
662,Data Scientist/ Machine Learning Consultant ( UK,"Job Location:
London - United Kingdom

Salary Per Annum:
40,000 + Bonus

UK - Work permit / visa will be sponsored by the company

Qualification:
B.Tech / M.Tech / MCA / M.Sc or equivalent

Experience Needed:
Over all: 5+ Years IT experience
Solid 1+ Year experience in Machine learning development projects

Job Skills & Responsibilities:
Experience in machine learning
Exposure to machine learning models and corresponding statistics like K-means, Bayesian, Clustering
Strong technical skills with Python along with NumPy, Pandas, Scikit-Learn
Machine learning experience -> predictive and prescriptive modelling
Data wrangling and data cleansing experience
Strong analytical skills
Any experience with Node.JS would be beneficial.
statistical/mathematical background
Business Verticals:
Financial / Banking
Telecom
Travel
Healthcare",-1,Imurgence,India,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
663,Data Science/ Machine Learning,"Experience: 4+ to 7years
Work Location: Faridabad
Education: B.E/B.TECH, BCA, MCA/ Diploma or IT Technical qualification
Salary: Negotiable
Role: Data Science/ Machine Learning
We are looking for an energetic Machine Learning Engineer/ML Specialist with 4+ to 7years of experience. The chosen candidate will be responsible for developing all aspects of data mining, predictive analytics, solution development to name a few.

Desired Skills:
A strong track record and demonstrable interest in mining and analyzing data, looking for stories, patterns, trends and insights.
Looking for Python Machine Learning, Q Learning, Data Science, Artificial Intelligence
Experience in Deep Learning is mandatory.
Focus on developing clear and concise analytical approach for problem-solving
Skilled in working with large and complex datasets with a keen eye for detail and accuracy.
Strong understanding of ML libraries and applications e.g. Time series analysis, Neural Net, SVMs, Boosting methods and implementation using Python.
Experience in Pyspark will be an added advantage.
Develop hypotheses, design experiments, collaborate with engineering team on implementing the A/B tests, and evaluate their performance
Proven achievements resulting from data analysis and ability to succeed in both collaborative and independent work environments
Comfortable manipulating and analyzing complex, high-volume, high-dimensionality data from varying sources.
Answer complex business questions by using appropriate statistical techniques on available data or designing and running experiments to gather data.
Required Candidate profile

Desired Qualifications for ML Engineer/ML Specialist role:
Minimum 3 years of experience with machine learning, analytic consulting, product development
Minimum 3 years hands-on coding experience
Qualification- (B.E/B.TECH, BCA, MCA/ Diploma or IT Technical qualification).
Possess good analytical & communication skills.
Must be hard-working, motivated & willing to go extra mile in completing projects on time.

Work Location:
Faridabad, Haryana.
Interested candidates kindly revert back with your updated Resumes on mentioned e-mail id hritcompany29@gmail.com",3.0,"Connect Infosoft Technologies
3.0",Faridabad,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
664,Sr Data Analyst,"We collect peta-bytes of retail data and are looking for data analysts who can derive meaningful insights from this data for our clients. Apart from building dashboards and reports, data analyst are also responsible for forensic data analysis, troubleshooting data issues and ensuring data integrity.

Primary Responsibilites
Distill our technology's performance down to consumable and familiar key performance indicators and visualizations
Build/utilize tools and processes that will scale the reporting function
Perform diagnostic and forensic analysis of product performance
Develop new ways to view and describe our business and product lines
Collaborate with the Engineering and Product Management groups
Mentor Junior Analysts
Technical Skills
SQL expert and basic Python
Proficient in basic statistics (sample sizing, Bayesian vs frequentist)
Exposure to web analytics tools and/or BI tools
Exposure to a statistical package (R, SAS, Matlab) is a plus
Experience with Hadoop (Hive/Pig/Hbase) is a plus
Scrappiness with UNIX is a plus
We are looking for passionate and curious engineers, who are tinkerers at heart and love to build. At CodeHall, we have a strong focus on the right tools, frameworks and libraries which helps engineers build solutions to real world problems in a fast and efficient manner. If you write code using modern toolsets, frameworks and platforms and are interested in any of the job opportunities below, send your resume to careers@codehall.in",3.3,"CodeHall
3.3",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
665,Data Science Internship,"Mate Labs is looking for a kick-ass and enthusiastic Data Scientist / Analyst Intern who has a really good understanding of machine learning and deep learning. We love GitHub and open source projects. We look for guys who are passionate about open-source projects and contributions.

Mate Labs has built ""Mateverse"" for Data Analysts so that they can build customized machine learning and data science models for a quick prediction like sales forecasting without writing even a single line of code. At Mate Labs, we are solving a unique problem of Algorithm & Hyperparameter selection in the field of Artificial Intelligence.

Machine Learning has transformed industries and is ready to revolutionize the way you live, work, and commute. It has created millions of new job opportunities and will continue to do so. This industry is going through a very exciting phase and at Mate Labs, we want to be at the forefront of this revolution. If it sounds exciting and you want to be a part of this revolution, join Mate Labs. Apply Now.

Job Responsibilities:

• Be working with Regression Algorithms (Linear Regression, Logistic Regression, Polynomial Regression, Ridge Regression, Lasso Regression etc.)
• Be working with ARIMA and LSTMs for time-series forecasting
• Be working with custom Mateverse algorithms
• Be working with technologies like Scikit-learn, Pandas, Numpy, Keras, Tensorflow, and PyTorch
• Be building mathematical models and implementing it in Python (preferably).

Skills Required:

• Machine Learning Algorithms(Regression(MUST)& Time-series forecasting (MUST), Classification, Clustering)
• Frameworks - Scikit-learn, Keras, Tensorflow, Pandas, Numpy, Caffe(Optional), PyTorch(Optional), ARIMA
• Has worked on multiple business use-cases.
• SAS or equivalent, Tableau, or any other data preparation tools.",-1,Matelabs Innovations Pvt. Ltd.,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
666,Scientist C,"Director NCPOR invites online applications from Indian Nationals for filling up the following positions:

Scientist C

Mode of recruitment: Direct Recruitment

Pay Matrix: Pay Level -11
(67700-208700)

No. of posts: 01 (UR)

Age: 40 years

Desirable:
(i) Doctorate in the relevant subject or area of specialization as above.
(ii) Proven Experience in scientific expeditions and related large sample/data analysis.

Candidate Profile:
Doctorate in the relevant subject

Experience:10 Years

Location:Vasco-da-Gama

Education:Masters Degree in Physics/ Earth Sciences/ Marine Sciences / Biological Sciences

Company:National Centre for Polar & Ocean Research (NCPOR)

SALARY:Pay Level -11

Last Date: Last Date to Apply is Over. : 2020-May-14

Key Skills: Education Academic Administrative

Company details

National Centre for Polar & Ocean Research (NCPOR)

National Centre for Polar & Ocean Research Earth System Science Organization (ESSO) (An Autonomous Society under the MINISTRY OF EARTH SCIENCES, Govt. of India) Headland Sada, Mormugao, Vasco-da-Gama, Goa - 403804 (www.ncpor.res.in)

National Centre for Polar & Ocean Research (NCPOR), an Autonomous Society under the Ministry of Earth Sciences, Government of India, New Delhi",-1,National Centre for Polar & Ocean Research (NCPOR),Vasco Da Gama,-1,-1,-1,-1,-1,-1,-1,-1
667,Scientist C,"Director NCPOR invites online applications from Indian Nationals for filling up the following positions:

Scientist C

Mode of recruitment: Direct Recruitment

Pay Matrix: Pay Level -11
(67700-208700)

No. of posts: 01 (UR)

Age: 40 years

Desirable:
(i) Doctorate in the relevant subject or area of specialization as above.
(ii) Proven Experience in scientific expeditions and related large sample/data analysis.

Candidate Profile:
Doctorate in the relevant subject

Experience:10 Years

Location:Vasco-da-Gama

Education:Masters Degree in Physics/ Earth Sciences/ Marine Sciences / Biological Sciences

Company:National Centre for Polar & Ocean Research (NCPOR)

SALARY:Pay Level -11

Last Date: Last Date to Apply is Over. : 2020-May-14

Key Skills: Education Academic Administrative

Company details

National Centre for Polar & Ocean Research (NCPOR)

National Centre for Polar & Ocean Research Earth System Science Organization (ESSO) (An Autonomous Society under the MINISTRY OF EARTH SCIENCES, Govt. of India) Headland Sada, Mormugao, Vasco-da-Gama, Goa - 403804 (www.ncpor.res.in)

National Centre for Polar & Ocean Research (NCPOR), an Autonomous Society under the Ministry of Earth Sciences, Government of India, New Delhi",-1,National Centre for Polar & Ocean Research (NCPOR),Vasco Da Gama,-1,-1,-1,-1,-1,-1,-1,-1
668,Data Analyst,"OakNorth is the next-generation credit and monitoring platform that provides banks and lending institutions with the insight and foresight needed to create a better borrowing experience for the Missing Middle – the growth business who are the backbones of communities and economies globally but who have been in banking’s blind spot for decades.
The business was founded in 2015 by Rishi Khosla and Joel Perlman, who previously co-founded Copal Amba and grew it to 3,000 employees over 12 years, before selling it to Moody’s (NYSE: MCO) in 2014, returning 125 times capital to seed investors.
Since its inception, OakNorth has secured over $1bn from several investors, including: Clermont Group, Coltrane, EDBI of Singapore, GIC, Indiabulls, NIBC, Toscafund, and SoftBank’s Vision Fund.
The Platform has been deployed at various banks across North America, Europe, and Asia, and in the UK where OakNorth lends off of its own balance sheet via OakNorth Bank. The platform has helped OakNorth Bank become the fastest-growing business in Europe according to the Financial Times FT 1000 (2020), profitably lending over £4bn to date. In terms of the impact this has had on the economy, OakNorth Bank’s loans have directly helped with the creation of 13,000 new homes and 17,000 new jobs in the UK, as well as adding several billion pounds to the economy.
With offices in London, New York, Manchester, Singapore, Hong Kong, Shanghai, Istanbul, Gurgaon and Bangalore, the global team across the OakNorth Holdings group is over 800 people.

Job Responsibilities:

• Review raw financial data received in various formats and standardize its processing
• Analyse and interpret acquired data from internal/external data sources and develop validations and a quality control process
• Use internal proprietary tools to manipulate and migrate data into the Platform
• Collaborate daily with other areas of the firm on execution of tasks
• Design scalable data management and entry process solutions that can be readily implemented across the team
• Model financial data to fit data templates
• Perform due diligence on new sources quickly and identify data questions and concerns
• Construct and maintain data dictionaries

Desired Skills:

• 3-6 years professional experience in a data-intensive role
• Strong analytical skills
• Excellent organizational skills, including attention to precise details
• Have a solid working knowledge of MS Excel
• Knowledge of VBA, SQL, Python, or other programing languages is a plus
• Financial industry experience is a plus
• Ability to handle multiple tasks, meet reporting deadlines, and demonstrate flexibility with delivery of assignments
Thank you very much for your interest in OakNorth. We are happy to consider you for roles within our group of companies. If we can identify a match between your skill set and our immediate recruiting needs, please expect to hear from us very soon. If we are unable to identify a fit in the near term, please note that we intend to retain the data you send to us so we may contact you in the future.

For more information regarding our Privacy Policy and practices, please visit: https://www.oaknorth.com/privacy-notice/employees/",4.0,"OakNorth
4.0",Bengaluru,"London, United Kingdom",51 to 200 employees,2015,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
669,Data Analyst,"Online applications are invited from the interested and eligible candidates for selection/empanelment of manpower for the following posts, on contract basis

Data Analyst

No. of posts: 02

Consolidated remuneration: Rs.80,000/- p.m.

Essential Qualifications:
i) Masters Degree in Technology/ Engineering (M.Tech/ ME) in Electronics & Communication/ IT/Computers/ Computer Science from a recognized University or institution with minimum 60% marks.
or
ii) B.E/ B.Tech in Electronics and Communication/IT/Computers/Computer Science or Master in Computer Application from a recognized University or institution with minimum 60% marks

Experience: 1. Minimum 6 years experience in case of Post Graduate Degree holders and 8 years experience in case of Graduate Degree holders
Working experience with Government/ PSU
Proficiency in working on advanced Excel and at least one of Python, R, Stata or other similar data analysis tools
Knowledge of good data visualisation tools/dashboards
Ability to handle large data sets
Certifications in Data Analysis tools(mandatory)
Candidate Profile:
Working experience with Government/ PSU

Experience:1-5 Years

Location:Ropar

Education:M.Tech/ ME

Company:National Institute of Electronics and Information Technology

SALARY:Rs.80,000/- p.m.

Last Date: Last Date to Apply is Over. : 2020-May-11

Key Skills: Data Analyst Statistics

Company details

National Institute of Electronics and Information Technology

National Institute of Electronics and Information Technology (An Autonomous Scientific Society of Ministry of Electronics & Information Technology (MeitY), Govt. of India) Birla Farms, Bada Phull, Rupnagar(Ropar)-140001, Punjab",3.6,"OakNorth
4.0",Bengaluru,"New Delhi, India",501 to 1000 employees,-1,Government,Education Training Services,Education,Unknown / Non-Applicable,-1
670,Analytic Consulting- Consultant II,"FICO (NYSE: FICO) is a leading global analytics software company, helping businesses in 90+ countries make better decisions. Join our world-class team today and fulfill your career potential!

Job Summary

Credit Risk/Collection Analytics – Modelling & Strategy

Are you up for a challenge to deliver world class collection analytics and advanced credit risk solutions? FICO is looking for highly experienced credit risk analysts/modelers to join our high performing team. This is a great opportunity for you to contribute your credit risk and collections knowledge, showcase your advanced analytical/modelling skills and deliver a fully automated and managed solution combining AWS components with some of FICO’s flagship Analytical, AI and Machine Learning products. Our clients are major Financial institutions, Telcos and Utilities companies from all around Asia.

Role
The Cloud Analytics team at FICO’s Global Delivery Center in Bangalore provides consulting services to leading banks, financial institutions, and Telcos across Asia-Pacific region. The team is focused in developing managed analytics services (models and strategies) deployed on “cloud” based platforms. The team works on a wide variety of projects involving development of advanced predictive models and strategies, optimization, and regulatory compliance using the latest tools & techniques.

The role will involve:
Working with FICO’s leading credit risk and collections consultants to design and develop risk/collection models and strategies.
Working with clients in Asia to understand what are the different sources of data available and how those can be utilized to design analytical solutions that can improve the client’s existing business operational practices (acquisitions, account management, fraud, collections, etc.)
Job Description

Responsibilities

Analyze data to draw meaningful insights.
Develop scorecard models and advanced Machine Learning models to predict different outcomes through the customer lifecycle management.
Lead model development and strategy development initiatives, guiding junior analysts on model design, profile variable generation, choice of data sources and appropriate modeling algorithm.
Conduct project management responsibilities – take ownership of delivery timelines and quality, track and provide status update to stakeholders, highlight risk/challenges and work through resolutions.
Guide junior analysts to design dashboards and reports that will provide important insights for our customers
Provide consulting support to customers for interpretation and effective usage of scorecards and decision rules
Work simultaneously on a number of different projects of varying complexity and length

Basic Skills and Experience

Advanced degree in mathematics, statistics, physics, engineering or similar technical field with relevant course work in probability, statistics and quantitative methods
6-9 years of core analytical experience with at least 3 years of project/ people management
At least 5 years’ experience working in the credit risk industry or within collections department’s BI teams of banks
Hands-on experience with building models/ scoring algorithms using SAS, Python, R, or FICO Model Builder
Strong command of language with ability to communicate persuasively and effectively

Preferred Skills and Experience

Hands on experience of developing Machine Learning models – such as GBM, Random Forest, XgBoost, etc. and ability to interpret the model results from business perspective
Worked on big data platforms – Hadoop, Hive, Spark, etc.
Experience of designing reporting dashboards on Tableau
Experience in working with AWS EMR to process files using SQL-on-Hadoop technologies such as Hive, Spark SQL and/or Presto

Why Make a Move to FICO?

At FICO, you can develop your career with a leading organization in one of the fastest-growing fields in technology today – Big Data analytics. You’ll play a part in our commitment to help businesses use data to improve every choice they make, using advances in artificial intelligence, machine learning, predictive and prescriptive modeling, and much more.

FICO makes a real difference in the way businesses operate worldwide:

Credit Scoring — 150+ billion FICO Scores have been sold to date, making it the most used credit score in the world.
Fraud Detection and Security — 2.6+ billion payment cards globally are protected by FICO fraud systems.
Lending — 3/4 of US mortgages are approved using the FICO Score.
Anti-Money Laundering — our solutions check more than half a billion transactions a day to prevent criminal schemes such as terrorist financing

Global trends toward digital transformation have created tremendous demand for FICO’s solutions, placing us among the world’s top 100 software companies by revenue. We support many of the world’s largest banks, insurers, retailers, telecommunications providers and other firms reach a new level of success.

Our success is dependent on really talented people – just like you – who thrive on the collaboration and innovation that’s nurtured by a diverse and inclusive environment. We’ll provide the support you need, while ensuring you have the freedom to develop your skills and grow your career. Join FICO and help change the way business thinks!

Learn more about how you can fulfill your potential at www.fico.com/Careers

FICO values the benefit that diversity and a culture of inclusion bring to our workplace. We are an equal employment opportunity and affirmative action employer and we’re proud to offer employment and advancement opportunities to all applicants without regard to race, color, ancestry, religion, sex, national origin, pregnancy, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.",3.6,"FICO
3.6",Bengaluru,"San Jose, CA",1001 to 5000 employees,1956,Company - Public,Computer Hardware & Software,Information Technology,₹50 to ₹100 billion (INR),-1
671,Clinical Data Analyst II,"Job Purpose:
The Clinical Data Analyst II (CDA II) shall perform all clinical data cleaning activities on assigned projects, commensurate with experience and/or project role. Further responsibilities shall include support on data processing activities and study level documents e.g. Protocol Deviation Specification, Data Validation specification, etc.
Key Accountabilities:
Accountability
Supporting Activities
Lead/Responsible for data cleaning and data review activities e.g. query management.
Review of protocols and EDC Screens if required.
Support data processing activities from database setup to database lock, e.g. SAE reconciliation.
Perform user acceptance testing on study database setups.
Perform medical coding on small studies
Track and review CRFs. Support data entry where required.
Perform and or support the setup of DM documents and ensure proper documentation e.g. CRF Completion Guidelines (CCG)
Perform/lead functional QC activities and testing
Mentor project team members
Be a subject matter expert when needed

Qualifications
Personal skills that include:
Good interpersonal, oral and written communication skills
Excellent learning ability
Work with integrity
Business / Operational skills that include:
Commitment to quality
Understanding of Global Data Operations tasks, specifically within Data Management and Database Programming and relevant data standards
Sound awareness of relevant regulations, including ICH-GCP, 21CRF11
Knowledge and Experience:
Good interpersonal, verbal and written communication skills
Knowledge of medical terminology and awareness of coding dictionaries (e.g.MedDRA & WHODRUG)
Ability to work in team environment
Good analytical skills and attention to detail
Effective time management to meet daily metrics or team objectives, completion of assigned tasks in a timely manner
Robust knowledge of ICH-GCP Guidelines, local regulatory requirements and PAREXEL SOPs and study specific procedures
Good knowledge of EDC systems (e.g. DataLabs, Rave.)
Good knowledge of electronic source data capture systems (e.g. ClinBase)
Good knowledge of all DB set- up activities including but not limited to Database Configuration Specifications, Data Validation
Basic knowledge of SAS
Bachelors degree and / or other medical qualifications or relevant industry experience",3.8,"Parexel
3.8",Mumbai,"Newton, MA",10000+ employees,1982,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹100 to ₹500 billion (INR),"PPD, IQVIA, PRA Health Sciences"
672,Data Analyst,"Key Responsibilities:
Maintain Business Intelligence (BI) infrastructure, including production changes.
Identify new and emerging technologies and enhance existing processes related to analytics and reporting.
Work with stakeholders to determine business requirements, priorities, define key performance indicators (KPI) and develop BI and data warehouse (DW) strategy.
Perform ad-hoc analysis and other job-related duties as assigned.
Create specifications for reports, data and analysis based on business needs and required or available data elements.
Help develop and move forward the company’s BI offerings.
Analyze complex business problems and issues using data from internal and external sources to provide insight to decision-makers.
Desired Skills and Experience:
2-4 years BI experience using database technology, emphasis on analytical and reporting tools.
Domain knowledge of Digital Marketing is preferred.
Ability to analyze large amounts of raw data and summarize into clear, accurate, meaningful, value-added reports and analysis.
Strong analytical and problem solving skills.
Solid understanding of BI Tools such as Tableau or Power BI with the ability to independently conceptualize and generate reports, metrics, and dashboards for fact based decision making and identifying continuous improvement opportunities.
Experience with one or more databases like MySQL, PostgreSQL, MS SQL.
Advanced knowledge of Microsoft Excel is absolutely essential.
Strong understanding database methodology, data analysis, SQL queries, ETL and business intelligence applications.
Excellent analytical skills. The candidate should not only be able to analyze the data, but also drive the implementation of the recommendations.
Excellent oral and written communication skills.
Job Type: Full-time

Pay: ₹200,000.00 - ₹1,000,000.00 per year

Experience:
work: 1 year (Preferred)
total work: 3 years (Preferred)
Education:
Secondary(10th Pass) (Preferred)",-1,Decision Tree Analytics,Gurgaon,-1,-1,-1,-1,-1,-1,-1,-1
673,Data Analyst,"Logistics done differently.

The Data Analyst (COE) at XPO Logistics within the Advance Solutions Group is a critical driver of the company’s success in delivering world-class solutions for our clients. The Data Analyst plays a key role in contributing to the operational efficiency and financial success of the company through effective planning, execution, delivery of projects on time and budget. The Data Analyst collaborates with all functional and client teams, including PMO, Engineering, Finance, Managed Transportation, IT, Proposal Operations and other business units both domestic and global based on the need.

What you’ll do on a typical day:
Responsible for providing insights and foresights from the client’s data using the advanced data analytics platform
Perform client’s data cleaning, ingestion, integration and processing
Initiate data discovery sessions with clients to make sure if our interpretation on data is correct and lock the data for the analysis
Develop and implement advanced data analysis and analytics solutions that support the business needs by Interpreting data, analyze results using statistical techniques and advanced analytics tools
Design and produce standard and ad-hoc analysis and various reporting solutions
Create and schedule Python scripts for supporting advance data-analytics platform
Working with cross-functional teams providing data support
Working hours - 12:00 PM to 9:00 PM

What you need to succeed at XPO:
At a minimum, you’ll need:
Minimum 2-4-years’ experience in the Data Analytics function of any relevant industry
4 years BE/BS degree or equivalent education.
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Hands on experience in using advanced analytics tools R, Python etc.
Hands on experience in writing complex SQL queries (joining multiple datasets and ETL DW concepts)
Advanced Microsoft Excel skills ( VBA, Macros etc.) .
Hands on experience in working with remote teams (Onsite – Offshore Setup)
Effective Verbal and written communication in English to interact with US counter parts and our clients
Ability to communicate effectively (both Oral and Written) with technical and non-technical audiences

It’d be great if you also have:
Experience in Supply Chain, Logistics, Distribution Center, Transportation, manufacturing environment.
Working experience in any one of the BI tools like Tableau, OBIE or similar tools
Working experience in any of the ETL tools like Airflow, Informatica, Pentaho or similar tools
Experience in Business Intelligence, Data Warehouse, Analytics, and or BA roles
Ability to conform to shifting priorities, demands and timelines through analytical and problem-solving capabilities.
Experience with Warehouse Management Systems (WMS), Order Management System (OMS), Transportation Management System (TMS)
Should have excellent interpersonal, organizational, written, verbal, and presentation skills to communicate at levels of business stakeholders.

Be part of something big.

XPO is a leading provider of cutting-edge supply chain solutions to the most successful companies in the world. We help our customers manage their goods most efficiently using our technology and services. Our greatest strength is our global team – energetic, innovative people of all experience levels and talents who make XPO a great place to work.

The above statements are intended to describe the general nature and level of work being performed by people assigned to this classification. They are not intended to be construed as an exhaustive list of all responsibilities, duties, and skills required of personnel so classified. All employees may be required to perform duties outside of their normal responsibilities from time to time, as needed.",3.7,"XPO Logistics
3.7",Mumbai,"Greenwich, CT",10000+ employees,2011,Company - Public,Transportation Management,Transportation & Logistics,₹500+ billion (INR),"DHL Supply Chain, UPS, FedEx"
674,Engineering Data Analyst,"JOB DETAILS
Job Name: Engineering Data Analyst
Required skills: MY SQL/mSql
Experience: 1 - 4 Years
Location: Chennai

Job Description:Required Skills :
Python, Tableau

Desired Skills:
SQL

Job Description

The major role of the candidate is to analyze machine data, captured in real time and generate meaningful
dashboards out of it, which in turn help in making engineering decisions. Analyzing data collected from the
test labs or field machines helps in further improvement of the performance of a machine.
Bachelor's degree in Engineering (Mechanical, Automobile, Electrical, Electronics & its allied branches)
Self-motivated with ability to work both independently and collaboratively within a team
Strongly skilled in Python
Strong Analytical and problem-solving skills
Experience utilizing business intelligence tools like Tableau
Ability to understand automotive terminologies
Excellent attention to detail, highly organized and process oriented
Excellent verbal and written communication skills
Competence in querying & extracting data from SQL databases in Tableau is a plu",3.3,"ARi
3.3",Chennai,"East Peoria, IL",501 to 1000 employees,2006,Company - Private,Architectural & Engineering Services,Business Services,₹500 million to ₹1 billion (INR),-1
675,Data Analyst,"Data Analyst


Netherlands |
Waalwijk,
Netherlands
Job ID: 35914
Job Description

Position at Ingram Micro Commerce & Lifecycle Services

Ben jij de kritische Data Analyst die energie krijgt van complexe en omvangrijke datasets die je vervolgens vertaalt naar praktische oplossingen om onze logistieke processen te verbeteren?

Je bent verantwoordelijk voor het verzamelen, analyseren en documenteren van business behoeften van onze klant bol.com en de operatie.

De functie

Als Data Analyst ben je in staat, door jouw haarscherpe analyses, inzicht te krijgen in de procestijden en kosten van de verschillende procesdelen in onze logistieke operatie. Je vertaalt de analyses naar werkende oplossingen en begeleid, samen met diverse interne en externe stakeholders, van implementatie tot evaluatie. Door de combinatie van jouw analytische en sociale skills lukt dit met gemak. De analyses worden gebruikt voor directe toepassing, waarbij de continue ontwikkeling van de kwaliteit en performance van ons voorop staat. Daarnaast houd je de marktontwikkelingen goed in de gaten, brengt deze in kaart en identificeert strategische business- en klantbehoeften. Je standplaats is Waalwijk, waar het team Data Analytics werkt. Af en toe een uitstapje naar één van onze andere warehouses in Waalwijk hoort daar natuurlijk ook bij. Je rapporteert aan de Manager Data Analystics, Markus Meuldijk.

Over Ingram Micro Commerce & Lifecycle Services

Ingram Micro CLS is de e-fulfilment partner van grote e-tailers waaronder bol.com en de Bijenkorf. Al jaren groeien wij en onze klanten sterk. Dit verwachten wij ook in de komende jaren door het veranderende aankoopgedrag van consumenten en uiteraard de prestaties van onze klanten. Wij innoveren hierdoor continu en investeren in mensen, machines, gebouwen en software. Ingram Micro is een Amerikaanse onderneming met 154 distributie centra in 45 landen. Bekijk hier een video van onze organisatie.

Wat zijn de taken en verantwoordelijkheden van een Data Analyst?
het ontwerpen, vervaardigen en doorontwikkelen van tools voor analyse van gegevens;
Je analyseert en assisteert bij verbeteringen van bestaande warehouseprocessen op basis van jouw data-analyses;
Je adviseert en ondersteunt het het management in het bepalen van strategie;
Je bent verantwoordelijk voor het opstellen van rapportages en analyses in samenwerking met de Engineers, Operatie, planning en op verzoek van management;
Initiëren van reguliere datavoorziening richting stakeholders en op reguliere basis analyseren van trends;
Documenteren van de verschillende uitgevoerde analyses, resultaten en ontwikkelde modellen;
En je levert support richting cost-analyses en planning analyses.
Wat breng jij mee?
Je hebt een afgeronde hbo of wo opleiding op het gebied van Supply Chain Management of Technische bedrijfskunde;
Tussen de 1 en 5 jaar ervaring, dit omdat we een junior én een senior Data Analyst zoeken;
Je hebt kennis van Python en R.;
Fulltime beschikbaarheid;
Uitstekende kennis van de Nederlandse en Engelse taal in woord en geschrift.
Wat bieden wij?

Wij bieden je een uitdagende en afwisselende baan binnen een succesvolle mutinational. Je krijgt veel verantwoordelijkheid en volop ruimte voor eigen initiatief.

Verder bieden we:
Prima primaire en secundaire arbeidsvoorwaarden;
Een jaarcontract met daarna uitzicht op een vast contract;
25 vakantiedagen en vier extra dagen als je niet verzuimt;
Een super voordelige pensioenregeling;
Reiskostenvergoeding;
Korting in de personeelsvoordeelwinkel;
Korting op verschillende verzekeringen.
Solliciteren

Wil jij een belangrijke bijdrage leveren aan het behalen van de doelstellingen van Ingram Micro eServices? Solliciteer nu via de ‘Solliciteer’button. Toch nog vragen? Stel ze gerust! Neem contact op met Jacqueline Vreijdenberger, 06- 11 076 113. Een VOG aanvraag en persoonlijkheidsvragenlijst maken deel uit van het sollicitatieproces.

Werving en selectiebureau’s; wij zoeken onze mensen graag zelf. Mochten we jullie hulp nodig hebben dan weten we jullie te vinden.",3.3,"Ingram Micro
3.3",Chennai,"Irvine, CA",10000+ employees,1979,Company - Private,Computer Hardware & Software,Information Technology,₹1 to ₹5 billion (INR),"Copaco, Tech Data, COMPAREX"
676,Data Analyst,"Overview:
Frost & Sullivan is looking for a Data Analyst/Sr Data Analyst to join our analytics team in Chennai to support our core research team in various research projects through contributions in statistical analysis and database management.

Responsibilities:
Gathering, extracting and analyzing data from various resources relating to focus markets.

Using business intelligence and statistical software to help build predictive models and perform analysis and deliver forecasts using appropriate techniques.

Identifying and analyzing trends or patterns in complex data sets.

Preferred candidate should possess:
2+ years of work experience in handling projects in advanced statistics and analytics.
A Bachelor’s degree in Statistics, Computer Science, Management or related field with an emphasis on analytics.
Business acumen and ability to translate data insights into meaningful business recommendations.
Strong analytical skills with the ability to collect, manage, aggregate, and analyze data from multiple sources with attention to detail and accuracy into a structured database and produce forecasts using statistical techniques, including segmentation, clustering, regression, time series analysis, etc.
Proficiency in advanced Excel and hands on experience in R.
Excellent written and oral communication skills, and interpersonal skills, and the ability to synthesize action items from abstract discussions.
Quick learner and highly motivated.
Ability to work in a cross cultural environment.

If you are passionate to work on complex business problems that can be solved using data, statistical modeling, we would like to talk to you.",3.1,"Frost and Sullivan, Inc.
3.1",Tamil Nadu,"San Antonio, TX",1001 to 5000 employees,1962,Company - Private,Film Production & Distribution,Media,₹10 to ₹50 billion (INR),-1
677,Data Scientist AI ML Team,"Come aboard our growing global team and work for a category leader with a market presence in 15 countries. You will work with some of the leading financial institutions worldwide who rely on our product innovation in helping them shield themselves against the global $4 trillion problem of financial fraud. We create ‘customer-centric predictable enterprises’ and we do this by directing intelligence to the heart of every customer interaction. In real-time.

We are seeking sharp, energetic Data Scientists to help us keep pace with our global expansion. You’ll be core member of a specialist team working on our Artificial Intelligence & Machine Learning stream. You bring your skills, experience and passion and we will give you the springboard for your ambitions.

The Role:
Work as part of Clari5.ai team in defining, prototyping and implementing data science models/algorithms as part of the product.

Take ownership of the data science model end-to-end from data collection to model building to monitoring the model in production.

Along with product managers and domain experts, own the business outcomes/metrics which the data science model/algorithm drives.

Work with the product managers and engineering to define best practices for the team.

Mentor junior colleagues and conduct internal workshops.

Help to make data science and data-driven decision making a part of the organisation’s DNA.

Your Skills:
Must have 3 – 8 years of experience working on model building.

Solid understanding of the mathematics related to data science – probability, statistics, linear algebra etc.

Ability to understand business concerns and formulate them as technical problems that can be solved using data and math / stats / ML.

Experience working as part of a product team, along with engineers and product managers, to define the problem and execute the data science solution.

Must have built 2-3 end to end ML projects in the past.

Knowledge of R or Python is a must.

Strong hands on experience in working with SQL databases.

Experience working with large data sets, coming from varied sources, is a plus

Conceptual understanding of big data technologies (Hadoop / HDFS / Spark) is a plus.

Prior experience in Natural Language Processing, Recommender Systems or Social Network Analysis is a huge plus.

Your Education / Qualification:
Bachelor’s degree or equivalent combination of education and 3 years or more of experience.
Bachelor’s degree in Computer Science, Masters in Mathematics / Statistics preferred.
About Us
Endorsed Category Leader in Financial Crime Risk Management Systems for Enterprise Fraud by Chartis Research, Winner of Best Fraud Detection Product by Risk.net and ranked consistently in Chartis’ RiskTech100 rankings, CustomerXPs redefines real-time, cross-channel banking Enterprise Fraud Management using AI like a central nervous system to fight financial crime. The company’s flagship product Clari5 harnesses the combined power of Automation, AI, Decision Sciences & Real-time Decisions. Clari5 currently processes over 10 billion transactions, manages over 450 million accounts and reliably secures 4% of the global population’s banking transactions. With 200 million accounts at a single site, Clari5 has the world’s largest implementation of a fraud management solution. Tier 1 banking customers across 15 countries who trust Clari5 for driving their fraud management strategy are recipients of global industry acclaim, including Banking Technology’s Best Use of IT in Risk Management/Regulation and Celent’s Model Bank of the Year.",3.5,"CustomerXPs
3.5",Bengaluru,"Bengaluru, India",51 to 200 employees,2006,Company - Private,Computer Hardware & Software,Information Technology,₹500 million to ₹1 billion (INR),-1
678,DATA SCIENTIST / MACHINE LEARNING EXPERT,"Relevant Experience
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Excellent understanding of Machine learning techniques and algorithms
ETL Knowledge (data cleansing)
Data Visualization
Expereience in BI poject
Experience in Agile/ SCRUM projects
Experience in supply chain is an added advantage
Key Technical Requirements
Required
R / Mathlab / Octave
NoSQL database such as MongoDB, DocumentDB, CosmosDB, etc
Git
Desirable
JavaScript, Angular 2/4, Node JS
Azure and AWS",4.0,"Spectrus
4.0",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
679,Oracle Data Warehouse Engineer & Analyst,"About Swiss Re

Swiss Re is one of the world’s leading providers of reinsurance, insurance and other forms of insurance-based risk transfer, working to make the world more resilient. We anticipate and manage a wide variety of risks, from natural catastrophes and climate change to cybercrime.

At Swiss Re we combine experience with creative thinking and cutting-edge expertise to create new opportunities and solutions for our clients. This is possible thanks to the collaboration of our 15,000 employees across the world.

We offer a flexible working environment where curious and adaptable people thrive. Are you interested in joining us?

About the Role:

We are the Swiss Re People Analytics team and seeking an Oracle Data Warehouse Engineer. He or she is responsible for the data integration and information exploitation, so that we as a team successfully deliver information products to our customers.

You will develop, inspects and tests our DWH, executes reconciliations, coordinates delivery of our monthly load process, actively increases data quality in the warehouse and consults us on new project or data-source needs as well on data quality improvements. You will become the key person for a good collaboration with our IT development and operational Database team.

We work in an agile setup. We emphasize team work and always strive to improve. You are actively supplying to deployment & test automation.

Our Oracle Data Warehouse Engineer...
Responsible for our monthly and load process in collaboration with IT Ops team. Continuously work on optimization and development of our database warehouse model.
Develops, tests and deploys data-marts and delivery views with in PL/SQL or SQL skills.
Tunes and optimizes load performance with our IT Ops team.
Collaborates and interacts with our Tableau developer and data Scientists.
Builds data marts and information delivery views for our analytical need as well new Dashboards
Uses programming languages like Python, Java, Groovy, Bash and deployment/testing tools like Bamboo, Gradle Ansible, Puppet, Chef, Maven, Gradle to increase our level of automation
About the team:

Our data warehouse is the master HR warehouses developed and operated in our Information Data Warehouse unit. The information scope of the warehouse is HR and Business Executives to in decision-making for support of the Business. Do you share our real passion for high quality information products that have high exposure and wide usage?

We are organized as an agile Analytical and consulting team setup. Team collaboration, continuous feedback and people over process is our DNA. We work together on improvement activities, tool evaluations, and prototyping. We together develop, extend and rewrite our tool chain to deliver more and faster value to our customers. Do you love to work in a team that always challenges itself on how to become better?

About you:
You hold a bachelors or master's degree in a technical field, preferably Information Technology or you have experience in the area of data warehousing or database development in your previous jobs.
You have a minimum 8+ year experience with Oracle Data Warehouses and you have built load processes or used ETL tools like Informatica Power Center, Kettle/Pentaho.
You have proven knowledge of relational databases in Oracle and database development tools like Toad for Oracle, SQLPlus, Sybase Power Designer, PL/SQL).
You love working with data and information. You have strong analytical skill, you have an eye for detail and you can work with complex data constellations.
You enjoy to identify issues, offer a workaround and implement a problem resolutions to satisfy a customers concern.
You are a great teammate, a good communicator and you love collaborating within the team and various other teams spread around the globe.
You are proficient in English.
The Company is an equal opportunity employer. It is the practice of the Company to recruit, hire and promote without regard to race, religion, color, national origin, sex, disability, age, pregnancy, sexual orientation, marital status, military status, or any other characteristic protected by law. Decisions on employment are based solely on an individual's qualifications for the position being filled.
Swiss Re",3.8,"Swiss Re
3.8",Bengaluru,"Zurich, Switzerland",10000+ employees,1863,Company - Public,Insurance Agencies & Brokerages,Insurance,₹500+ billion (INR),"Munich Re, Hannover RE, SCOR"
680,Senior Data Analyst,"We are seeking a full-time Senior Data Analyst with 5 years or more experience of doing various marketing campaigns using SAS model, strong analytical skills and keen attention to detail to develop and deliver marketing programs for retail, finance, insurance and other businesses.

Must have grounding in traditional data mining/database marketing and experience in the evolving digital data marketing landscape. Bridgetree is a virtual company and the position will require to work from Kolkata/Bangalore-India office. Must be a legal Indian resident.

Requirements:
Creates Marketing campaigns e.g. Mailing, e-mailing, Call lists etc.
Analyzes Data and builds various reports efficiently using different business intelligence and reporting tools
Responds to various data requests like building waterfall and customer profile reports, Mail/Email Campaign Response Analysis
Performs additional checks and implement diagnostic reporting to ensure that the final production is 100% accurate and quality assured
Recommends and implements better ways to make the process lean and efficient – set up and maintain automated data processes
Qualifications:
5+ years of working experience in a Statistical Analyst role using SAS, SQL. Knowledge of SSIS, R or Python will be added advantage.
Must have a master’s degree in Mathematics, Statistics or Economics with good educational background.
Personally, strives to ensure data quality, consistency, and accuracy in all work.
Desires to participate in a learning environment where sharing and collaboration with others is the culture.
Must have great communication and problem-solving skills
To apply: Please email your resume to jobs@bridgetree.com",3.4,"Bridgetree
3.4",Bengaluru,"Mooresville, NC",51 to 200 employees,1995,Company - Private,Advertising & Marketing,Business Services,₹1 to ₹5 billion (INR),-1
681,Lead - Data Scientist,"About Us :
2COMS is a Human Supply Chain Management company. With over 2500+ employees and more than 7 branches, we offer a wide variety of services, connecting more than 4000 professionals with over 70 clients every day. Over the last 20 years, we have remained dedicated to developing our people, strengthening our capabilities, and building trusting relationships with our clients and partners. We also pride ourselves on providing superior talent to deliver high-quality solutions aligned with the key objectives of our clients—disciplined financial management, continuous performance improvement, and integrated technology enablement. We do so with flexibility and nimbleness that fit your objectives—not ours. We are excited for the future and the opportunity to work with you in these areas to exceed your expectations.

About Company :
XXXX

Roles and Responsibility :
Leading Analytics company is hiring for the below mentioned role

Job Title : Lead Data Scientist

Job Location : Chennai - Bangalore

Exp : Total : 9+ yrs (Rel : 7+ yrs in Data Science)

Qua : Graduate / Post Graduate
* Excellent Communication
Job Requirements :
Role involves 60% individual contribution, 25% customer engagement and
15% project management
Lead individual projects on their own end to end, effortlessly switching
between roles of an Individual Contributor, team member and Project

Manager as demanded by each project
Work closely with project team, Customer stakeholders and internal
Business Units in devising creative analytical approaches to solve business

problems
Enhancing existing models, build new ones and maintain all models along
with developing and updating code and process documentation

Skills Required:
Demonstrated analytic, quantitative, and programming skills
Proficiency in a structured programming language is a must - knowledge of
one of statistical/general purpose scripting languages software such as R,

SAS, Python, Java etc. is mandatory.
Strong SQL, Microsoft Excel, VBA (preferred), Access and PowerPoint skills
Experience in conducting quantitative analyses and interpreting results
Excellent written and verbal communication skills
Organized, structured and reliable while being an effective problem solver
Experience:
Relevant big data and analytics experience including hands-on programming in one (or more) of the above languages. Minimum 5 years spent with Analytics teams of reputed consultants and IT/ITES companies doing statistical modelling using above tools.

Desired Candidate :
* Relevant Data Science exp is a must
* Model Building is a Must
* Python coding
* Statistical models
* Machine learning
* Advanced Analytics
Recruiter Name : Rafikh
Recruiter Number : 8420577308
Recruiter Email Id : rafikhunnisa.s@2coms.com",4.2,"2COMs
4.2",Chennai,"Kolkata, India",1001 to 5000 employees,1999,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
682,Data Science Platform Administrator,"About our group:
We are a proactive, highly solutions oriented and collaborative team that works with all the various business groups and data scientists across the organization to provide data engineering and Data Science platform services. Our purpose of capturing massive amounts of data is to transform this vital information into concrete and valuable insights that will allow Seagate to make better and more strategic business decisions.

About the role-you will:
Design , build and manage high available systems for data science platforms like R , Python , KNIME , Tensor flow , H2O etc
Provide platform security management, application and underlying infrastructure support (OS, Storage, Applications, Web and Database) and ensuring processes are aligned with tactical and strategic information management initiatives
Deploying solutions in AWS cloud and onPrem environments
Supporting system application requests with updates to existing installations that require integration with the highly available platform
Evaluate, integrate and implement emerging technologies
Develop integration solutions with Python workflow scripting
Partner with internal business, engineering and data science teams worldwide for delivering incremental improvements to the advanced analysis platform.
Create and maintain architecture blueprints to integrate both vendor and open source technology analysis tools and systems into the platform.
Develop early prototypes for iterative review with customers to arrive at optimal and robust data-driven solutions.

About you:
Experience with various data science platforms R , Python , Anaconda , Tensor flow , H2O etc
Strong Linux Scripting and Administration experience
Experience with deploying solutions using containerization ( Docker / Kubernetes)
Firm understanding of GPU and relationship to Deep Learning/Neural Nets
Demonstrated experience developing and managing complex technical projects involving parallel or distributed computing, including Hadoop, the Apache Stack and related technologies
Understands importance of statistical analysis and machine learning
Solid understanding of program execution in open source R and Python environments
Ability to communicate complex technical solutions in a clear, precise and actionable manner with both technical and non-technical customers
Work flexible hours to accommodate meeting with global teams
Solid understanding of Agile software development methodologies
Good understanding of service-oriented architecture concepts (SOA and REST)
Requires innately curious person with creative ability to solve complex problems

Your experience includes:
Installing, configuring, maintaining and upgrading applications and packages in a linux environment, including application uptime monitoring tools
Linux scripting and administration
Advanced SQL techniques, stored procedures and data warehousing solutions
Python or javascript or similar development language
Expertise related to DevOps engineering including version control systems (Git, SVN), and automated build and testing (Jenkins, vagrant)
Configuration management (e.g. Puppet, SALT, Ansible)
Bachelor's degree and/or relevant experience

You might also have :
Containerization, including Docker and Kubernetes

Job Family: Engineering Professional",3.3,"Seagate Technology
3.3",Pune,"Cupertino, CA",10000+ employees,1979,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Western Digital, Fujitsu"
683,Senior Data Scientist - AWS Professional Services,"A Bachelor or Masters Degree in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.) or equivalent experience
10+ years of industry experience in predictive modeling, data science and analysis
Previous experience in a ML or data scientist role and a track record of building ML or DL models
Experience using Python and/or R
Knowledge of SparkML
Able to write production level code, which is well-written and explainable
Experience using ML libraries, such as scikit-learn, caret, mlr, mllib
Experience working with GPUs to develop models
Experience handling terabyte size datasets
Track record of diving into data to discover hidden patterns
Familiarity with using data visualization tools
Knowledge and experience of writing and tuning SQL
Past and current experience writing and speaking about complex technical concepts to broad audiences in a simplified format
Experience giving data presentations
Extended travel to customer locations may be required to deliver professional services, as needed
Strong written and verbal communication skills
Excited by using massive amounts of data to develop Machine Learning (ML) and Deep Learning (DL) models? Want to help the largest global enterprises derive business value through the adoption of Artificial Intelligence (AI)? Eager to learn from many different enterprise’s use cases of AWS ML and DL? Thrilled to be key part of Amazon, who has been investing in Machine Learning for decades, pioneering and shaping the world’s AI technology?
At Amazon Web Services (AWS), we are helping large enterprises build ML and DL models on the AWS Cloud. We are applying predictive technology to large volumes of data and against a wide spectrum of problems. Our Professional Services organization works together with our AWS customers to address their business needs using AI.

AWS Professional Services is a unique consulting team. We pride ourselves on being customer obsessed and highly focused on the AI enablement of our customers. If you have experience with AI, including building ML or DL models, we’d like to have you join our team. You will get to work with an innovative company, with great teammates, and have a lot of fun helping our customers.

If you do not live in a market where we have an open Data Scientist position, please feel free to apply. Our Data Scientists can live in any location where we have a Professional Service office.

A successful candidate will be a person who enjoys diving deep into data, doing analysis, discovering root causes, and designing long-term solutions. It will be a person who likes to have fun, loves to learn, and wants to innovate in the world of AI. Major responsibilities include:
Understand the customer’s business need and guide them to a solution using our AWS AI Services, AWS AI Platforms, AWS AI Frameworks, and AWS AI EC2 Instances .
Assist customers by being able to deliver a ML / DL project from beginning to end, including understanding the business need, aggregating data, exploring data, building & validating predictive models, and deploying completed models to deliver business impact to the organization.
Use Deep Learning frameworks like MXNet, Caffe 2, Tensorflow, Theano, CNTK, and Keras to help our customers build DL models.
Use SparkML and Amazon Machine Learning (AML) to help our customers build ML models.
Work with our Professional Services Big Data consultants to analyze, extract, normalize, and label relevant data.
Work with our Professional Services DevOps consultants to help our customers operationalize models after they are built.
Assist customers with identifying model drift and retraining models.
Research and implement novel ML and DL approaches, including using FPGA.
This role is open for Mumbai/Pune/Bangalore/Chennai/Hyderabad/Delhi/Pune.

·
PhD in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.)
12+ years of industry experience in predictive modeling and analysis
Good skills with programming languages, such as Java or C/C++
Ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations
Consulting experience and track record of helping customers with their AI needs
Publications or presentation in recognized Machine Learning, Deep Learning and Data Mining journals/conferences
Experience with AWS technologies like Redshift, S3, EC2, Data Pipeline, & EMR
Combination of deep technical skills and business savvy enough to interface with all levels and disciplines within our customer’s organization
Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment",-1,AWS ProServe IN - Karnataka,India,-1,-1,-1,-1,-1,-1,-1,-1
684,Data Analyst,"Hiring Data Analyst for Mumbai with 2-9 years’ experience!!

Type: Full-time

Salary: As per industry standards

Job Roles & Responsibilities: -
Coordinate with Sales Team for the collection of sales data
Analysis of data – Activation, Acumen, Online Audit, Market Samples, Offline Audit
Generates Reports highlighting discrepancies in sales orders
Distribution sales experience of 1-2 years
Have experience on customer insights and sales insights
Communicates the discrepancies by seeking clarification from respective BDM/Stake Holder
Compiles the explanation and sends to Team lead for recommended action
Communicates recommended action to the stake holders
Collects proof of implementation for recommended action, escalates
Generates Daily/Weekly/Monthly action taken reports
Prepare Dashboards and flash the same to the sales team and respective stake holders
Education: Graduate/ Postgraduate- Regular, with Good academic record.

Required Skills Mandatory: handling MIS, sales coordination, data analysis, data presentation

POC: Priyanka Goel (7303582699)

Job Type: Full-time

Salary: ₹200,000.00 to ₹500,000.00 /year

Experience:
work: 2 years (Preferred)
total work: 2 years (Preferred)
Education:
Bachelor's (Preferred)
Work Remotely:
Yes",3.5,"Channelplay Ltd
3.5",Mumbai,"Gurgaon, India",1001 to 5000 employees,2006,Company - Private,Advertising & Marketing,Business Services,₹1 to ₹5 billion (INR),"Denave, V5 Global, TracyLocke"
685,AWS Data Lab Solution Architect,"Are you a data and analytics specialist? Do you have deep expertise in AWS services for managing data at speed and scale? Do you think big about how data can change the world, and love building software? Would you like a career that gives you opportunities to help customers and partners use cloud computing services to build new solutions, faster, and at lower cost?


At AWS, were hiring highly technical cloud computing architects and engineers to collaborate with our customers on building solutions in database, data management, and analytics. AWS Data Lab is located in Seattle, New York, Herndon, London, and now Bangalore. You will focus on real time and batch-based data processing, business intelligence, analytics, and machine learning systems. These solutions are built alongside the customer and quickly put into production use in a matter of weeks. You'll work closely with AWS Field Teams including Solution Architects, Technical Account Managers, and AWS Service Developers to partner with customers to solve hard problems with data. Every day, you'll be working with AWS Services and Data Lab Customers to determine the optimal implementation, build it, prove it works, extract documents and CloudFormation templates to speed project delivery. If you are builder, and love data, then this could be your ideal job!




Roles & Responsibilities
· Understand customer requirements and render those as architectural models that will operate at large scale and high performance. Where customers have architectures prepared, validate them against non-functional requirements and finalize the build model.
· Work alongside customers to build data management platforms using Elastic Map Reduce (EMR), Redshift, Kinesis, Amazon Machine Learning, Amazon Athena, Lake Formation, S3, AWS Glue, DynamoDB, ElastiCache and the Relational Database Service (RDS)
· Render working, high performance data management solutions, as CloudFormation and reusable artifacts for implementation by the customer
· Prepare architecture and design briefs that outline the key features and decision points of the application built in the Data Lab
· Work with customers to advise on changes as they put these systems live on AWS
· Extract best-practice knowledge, reference architectures, and patterns from these engagements for sharing with the worldwide AWS solution architect community

Basic Qualifications

· Highly technical and analytical, possessing seven or more years of Database and/or Analytics Systems development and deployment experience, IT systems and engineering experience, security and compliance experience, etc.
· Possess significant experience of software development and/or IT and implementation/consulting experience.
· Strong verbal and written communications skills are a must, as well as the ability to work effectively across internal and external organizations and virtual teams.
· Ability to think understand complex business requirements and render them as prototype systems with quick turnaround time.
· Implementation and tuning experience in the Big Data Ecosystem, (such as EMR, Hadoop, Spark, R, Presto, Hive), Database (such as Oracle, MySQL, PostgreSQL, MS SQL Server), NoSQL (such as DynamoDB, HBase, MongoDB, Cassandra, design principles) and Data Warehousing (such as Redshift, Teradata, Vertica, schema design, query tuning and optimization) and data migration and integration.
· Track record of implementing AWS services in a variety of business environments such as large enterprises and start-ups.
· Knowledge of foundation infrastructure requirements such as Networking, Storage, and Hardware Optimization.
· BS level technical degree required; Computer Science or Mathematics background preferred. [DB1]
· AWS Certification, eg. AWS Solutions Architect, Developer, or AWS Certified Big Data - Specialty

Preferred Qualifications

· Hands on experience leading large-scale global database, data warehousing and analytics projects.
· Demonstrated industry leadership in the fields of Database and/or Data Warehousing, Data Sciences and Big Data processing.
· Deep understanding of data, application, server, and network security
· Experience with Statistics, Machine Learning and Predictive Modelling.
· Hands on experience as a database, data warehouse, big data/analytics developer or administrator, or work as a data scientist.
· Experience working within the software development or Internet industries is highly desired.
· Technical degrees in computer science, software engineering, or mathematics
· Working knowledge of modern software development practices and technologies such as agile methodologies and DevOps.

Amazon is an Equal Opportunity-Affirmative Action Employer Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation",4.2,"Amazon
4.2",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
686,Senior Data Engineer,"We’re looking for an experienced Data Engineer to be part of our team who has a strong cloud technology experience to help our data engineering team to take our products to the next level.

This is a hands-on role, you will be required to code and develop the product. You need to have a strong software development background and love to work with cutting edge big data platforms.

You are expected to bring with you extensive hands-on experience with Google Cloud Platform (BigQuery, Dataflow, Cloud Composer), Spark and other Big Data processing frameworks and technologies as well as advanced knowledge of RDBMS and Data Warehousing solutions.

Requirements
Strong background working on large scale Data Warehousing and Data processing solutions.
Strong Python programming experience.
Experience designing & architecting products.
SQL and RDBMS handling is a must.
Good knowledge of OO, functional and procedural programming paradigms.
Knowledge of various design patterns.
Good in-depth knowledge of data structures and algorithms.
Strong experience with Linux operating systems.
At least 3+ years of experience working as a developer.
Highly desirable
Understanding of agile principles specifically scrum.
Docker, Puppet, Ansible, etc..
Understanding of digital marketing and digital advertising space would be advantageous.
Benefits

Datalicious is a global data technology company that helps marketers improve customer journeys through the implementation of smart data-driven marketing strategies. Our team of marketing data specialists offer a wide range of skills suitable for any challenge and cover everything from web analytics to data engineering, data science and software development.",3.6,"Datalicious
3.6",Bengaluru,"Sydney, Australia",1 to 50 employees,2007,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,"Ensighten, Adobe, Visual IQ"
687,Data Analyst,"Send your resume to growth@gaddieltech.com quoting the Job Code Titlle
Job Description
Analyzing, Mining and Reporting Data
Predictive analysis from structured and unstructured data
Application of standard statistical methods for analysis, documentation and presentation

Desired Candidate Profile:
Keen knowledge in statistical methods
Hands on in different ETL Tools
Critical thinking and providing educated guesses where data is sparse or sporadic
Experience: 6+ Years

Key Differentiator:
Good analytical skill, keen attention to detail and knowledge in modeling tools",-1,Gaddiel Technologies,Tiruchchirappalli,"Tiruchirappalli, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
688,Data Analyst,"Qualification:
Any graduate with 2-5 years experience in data analysis, decision support, including demonstrated proficiency with analytical software.
Proficient in PL/SQL, PowerPivot, Excel, VBA, Macros, MySQL DB and Microsoft PowerPoint.
Strong communication skills and should be fluent in written and spoken English.

JOB ROLE & RESPONSIBILITIES:
Perform complex data analysis in support of ad-hoc and standing customer requests.
Deliver data products in report/ presentation format, or verbally, to management's specifications and timelines.
Write excel and SQL programs to analyze and extract valuable information from healthcare data.
Perform basic statistical analyses for projects and reports.
Develop graphs, reports, and presentations of project results.
Create and present quality dashboards.
Promote an image of a high quality organization through expertise and responsiveness.
Takes responsibility for assignment completion and follow-through.
Good working relationships with internal and external customers.",3.6,"Anion Healthcare BPO
3.6",India,"Hyderabad, India",1 to 50 employees,1999,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
689,Data Science,"Selecting features, building and optimizing classifiers using machine learning techniques.
Data mining using state-of-the-art methods.
Extending company's data with third party sources of information when needed.
Enhancing data collection procedures to include information that is relevant for building analytic systems.
Processing, cleansing, and verifying the integrity of data used for analysis.
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance
Creating Heat Maps, should be able to develop custom codes over Google Maps API
Deduce a unique and more efficient TRP (Television Rating Point) system and similar rating system for other advertising
mediums like Radio and Print

Location: India (Bengaluru)",3.6,"ADmyBRAND
3.6",Bengaluru,"Bengaluru, India",1 to 50 employees,2016,Company - Private,Publishing,Media,₹500 million to ₹1 billion (INR),-1
690,Data Analyst,"Data Analyst Part Time

Data Entry Data Analysis Operation English Answering Calls Hindi Speaking Compulsory Communication Advanced Excel, Ms Office, Team Management Skills, ....",-1,Padmavati Marketing,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
691,Senior Data Analyst,"The role

At Farfetch we experience high levels of volatility within our data as a result of several factors such as a varied set of customers, a retail trading calendar, frequent changes to the way we attract customers to our site and a complex data chain and quality. You’ll be responsible for working with a start-up and using internal modelling to help us better flag and understand the root cause of this volatility and understand which of these matters and which actions we should take. In addition, you’ll use other models in the business built to look at volatility to understand how these tools can work in harmony.
What you’ll do
Work closely with start-up and internal experts to understand how to get the best out of our tools and our data in terms of understanding volatility and answer questions such as:
- Which parts of volatility matter?
- What caused it?
- How do we take action with the insight?
A key area will also involve working closely with the start-up advising on development of the tool to ensure it is usable by Farfetch in a scalable manner and is intuitive to use from a user perspective.
Who you are
A professional with a minimum of 4 years of experience with data analytics, with e-commerce orientation (mandatory);
A graduate of a Bachelor of Science program or a higher level post-secondary educational program in Computer Science, Math, Engineering, Operation Research, or quantitative disciplines (desired);
Understanding of statistical significance and volatility - preferably in a retail environment, but open minded on this;
Understanding of regression / AI is a bonus - but key focus is that commercial analyst mindset;
Very skilled in Excel and SQL skills;
An excellent communicator with presentation skills, both verbal and written;
Very skilled in English, both written and spoken;
An excellent strategic thinker and with analytical skills, ideally developed in a commercial role preferably within an Internet or retail/consumer products business and/or management consulting;
Experience delivering high value, actionable insight;
Ability to start with a business problem and using data recommend quick solutions;
Experienced in leveraging data and analytics to solve real-world problems and create new solutions;
An individual that can change directions quickly to respond to new information and changing circumstances;
Experienced with BI and data visualization tools (e.g., SSRS, Tableau, etc.) is preferred;
Knowledgeable in web development (e.g., HTML, Javascript, etc.) is a plus.
Responsible for developing and delivering ongoing understanding of volatility in Farfetch, partnering with innovative start-ups and working with other areas of the business to get the most value out of existing tooling.",3.8,"Farfetch
3.8",New Delhi,"London, United Kingdom",1001 to 5000 employees,2008,Company - Public,Internet,Information Technology,Unknown / Non-Applicable,Neiman Marcus
692,FTC - Marketing Data Analyst & Campaign Support (WI),"About the opportunity


Purpose of your role

Based upon their knowledge of customer data, the successful candidate will work with campaign teams to optimise their effectiveness through more enhanced / personalised target audience selection.

The candidate will work with campaign teams to define potential target audiences based upon available customer data from Marketo and any other relevant sources and then support the set up of the campaigns in Marketo. Diligence will be required to ensure that we are allowed to communicate with the specific customers based upon customer interests, preferences, business requirements and regulatory boundaries; this is critical as this role is the guardian of these rules.

Core elements of the role will also support the sourcing of data to collate and report upon the teams’ KPI’s and any subsequent actions that follow from them.

This role is part of a team supporting the WI business.

Key Responsibilities

Customer audience identification
Taking a campaign brief, identify an optimal target customer audience from the available customer base / data set.
Check what we are allowed to send to the respective audience based upon pre-set conditions.
Ensure the appropriate customer audience is available for marketing communications through relevant systems and tools.
Support the onboarding of new clients
Data Analytics
Support the wider analytics team and campaign managers in customer analytics such as performance measurement, segmentation analysis and behavioural analysis.
Experience and Qualifications Required
Experienced and competent at data handling.
Knowledge of asset management / financial services sector preferred (but not essential).
Sense of urgency and awareness of when to escalate issues.
Self-motivated, a proactive approach with an analytical, enquiring mind and willingness to learn.
Ability to work on own initiative to achieve objectives and goals, requesting support when and where required.
Strong sense of ownership with ability to work on challenging issues and overcome constraints and obstacles.
Timeliness and high productivity while working under pressure to meet deadlines.
Strong customer service orientation.
Commitment and professionalism.
About you


Essential Skills Required:
Strong analytical skills and very numerate.
Ability to analyse a request and produce innovative solutions.
Attention and care to detail - passion for data driven Insight
Good networking and communication skills (verbal and written).
Good organisation and coordination skills.
Good Microsoft office skills – Excel, PowerPoint, Word.
Desired Skills:
Some experience / knowledge of tools used by FIL e.g. Marketo, Power BI and Tableau (although training will be given)
About Fidelity International


Fidelity International offers investment solutions and services and retirement expertise to more than 2.4 million customers globally. As a privately-held, purpose-driven company with a 50-year heritage, we think generationally and invest for the long term. Operating in more than 25 locations and with $479.9 billion in total assets, our clients range from central banks, sovereign wealth funds, large corporates, financial institutions, insurers and wealth managers, to private individuals.

Our Workplace & Personal Financial Health business provides individuals, advisers and employers with access to world-class investment choices, third-party solutions, administration services and pension guidance. Together with our Investment Solutions & Services business, we invest $371 billion on behalf of our clients. By combining our asset management expertise with our solutions for workplace and personal investing, we work together to build better financial futures.",3.7,"Fidelity International
3.7",Gurgaon,"London, United Kingdom",5001 to 10000 employees,1969,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
693,Battery Expert - Data Anaytics,"Business Analyst/BigData Expert - Pyspark/Python/Azure (6-9 yrs)Role : Data Scientist(DA)
Experience : 6 to 9 years
Job Location : Bangalore
Job Description for Data Analyst.
Ability to understand Azure Cloud setup, its libraries and the structure so you can advise stakeholders and provide guidance to team
Create, analyses and maintain Diagnostics/predictive/prescriptive statistical models.
Work includes all phases of the modeling process: Research, Architecture and design, data extraction and processing,ML model building, Visualization and validation.
To work through the entire life cycle of a project from Conceptualization to implementation.
Co-ordinate with different SMEs for seeking the inputs to explore data extraction approach and Work closely with endusers to understand their needs
Develop and maintain working relationships with key customer stakeholders
Skills Required :
Exp. Range -6-9 years of work experience in Microsoft Azure environment, Databricks, PowerBI and advance statistical analysis & data processing
Proficiency required in one or more of analytical tools such as Pyspark,Python, SQL ETL operations.
Understanding of cloud features including load balancing, networks and scaling is expected
Statistical modeling (Regression, Classification, Time-series forecasting) /Machine Learning /Optimization/Visualization
Knowledge on Machine Learning Techniques would be added advantage
Ability to move data around, from a database or an API, through a transformation or to a model and into human-readable form (ROC curve, Excel chart, map, d3 visualization, Tableau, etc.)
Knowledge on Automotive domain, especially Battery internals would be an advantage.

Basic Qualification:

· Bachelors/Masters in Engineering in EEE,ECE,CES or Data Science

· Strong mathematical background in statistics and machine learning for 6-9 years",4.2,"Daimler
4.2",Bengaluru,"Stuttgart, Germany",10000+ employees,1886,Company - Public,Transportation Equipment Manufacturing,Manufacturing,₹500+ billion (INR),"Audi, Porsche, BMW"
694,Senior Data Scientist,"Job Description

Looking for an experienced Data Scientist with hands-on experience in a variety of data analysis methods, ML, DL algorithms using Python.

Experience: 10+ years

Location

Pune/Bangalore(IND)
San Jose/Aguora Hills(CA, USA)
Send us your resume at careers@nutanxt.com",-1,NutaNXT Technologies,Pune,"Santa Clara, CA",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
695,Data Science,"Location: Hyderabad

Job Requirements

Experience with managing large real time data sets is an advantage.
An eye for detail with strong analytical skills and a curious mind.
Excellent communication, presentation and written skills with a passion to connect with people.
Independent and highly passionate about technology.
Efficient, responsible and self motivated with a focus on outcome and customer excellence.
Strong leadership, articulate and loves to meet and engage with people.

Qualifications

Degree / Masters/PhD in quantitative fields such as Mathematics, Statistics, Information Technology Engineering or Science.
Minimum 2 years of relevant working experience.
Knowledge of statistical and data mining techniques, which may include data modelling, regression, time series models, clustering algorithms and others.
Working experience with R and/or Python, SQL, ETL concepts, Data Governance and Big Data frameworks such as Hadoop, SPARK, etc.
Exposure to Business Intelligence tools such as Tableau, Qlikview, SAS and other BI tools will be an added advantage.
No Of Positions : 3",3.5,"Web Synergies
3.5",India,"Singapore, Singapore",201 to 500 employees,1998,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
696,Commodities Fundamental & Quantitative Analyst,"This role involves working with and supporting the Singapore Commodities business, providing analytical support and coverage of Commodities fundamentals. The candidate will work closely with the trader and develop understanding of how and what drives bulk commodity and metals markets. The role would involve fundamental analysis is an attempt to understand the cyclical nature of a commodity market through the use of supply and demand data. The role would also involve creating algo-based trading strategies to identify arbitrage opportunities for the desk. In fulfilling this role, the candidate will develop unique understanding of both the commodity market and systems used within the business to support commodities.
The role suits a self-motivated, highly energetic individual who has a strong background in coding and a keen interest in both financial markets and commodities. The ideal candidate will be a lateral thinker who can view, process and decipher information at ease and work well with in a team environment.
Position Description:
Build and manage algorithm based trading strategies & models to identify arbitrage opportunities.
Build quant-based models by historical back-testing for generating trading strategies
Perform fundamental and quantitative analysis on bulk commodity data to derive insights, generate new trade ideas and build new trading idea models for the desk.
Build automated processes that assist with real-time communication of this analysis
Work closely with commodities trader, sharing insights accrued.

Educational Background
IIT/ NIT Graduates, preferably with MBA in Finance.
Skills Required
Candidate must have:
Good understanding and interest in Financial Markets and Commodities.
Min of 1 year of relevant work experience in Commodities market.
VBA/Macro and other coding expertise for spreadsheet analysis work.
Ability to collaborate information, interpret and draw tradeable conclusions.
Strong understanding in finance, statistics.
Experience in complex option pricing of commodities preferable, though not mandatory.
Must have attention to detail.
Must be confident and able to communicate well.
Apply Now",3.8,"Morgan Stanley
3.8",Mumbai,"New York, NY",10000+ employees,1935,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
697,Data Analyst,"99Games is looking for a Data Analyst to help us analyze game data and communicate insights that’ll help guide game development and game marking to create better games.

RESPONSIBILITIES
Work closely with game teams to define data to be collected from our games for analysis
Analysis of key performance indicators such as customer acquisition, retention, lifetime value, user cohorts and virtual economy balance
Create LTV and Revenue Models
Defining the data acquisition of AB tests and analysis of the gathered AB test data to estimate the effect on key metrics and choose the best features
Develop models for predicting player behavior
Answer in-depth analysis questions from the team and generate detailed weekly performance reports around trends and key metrics specific to goals and present to senior management
Identify and report actionable insights to internal stakeholders, suggest recommendations and influence the direction of the business by effectively communicating results
Stay current on customer queries from support and marketing channels
Work closely with game designers, developers, artists, marketing and support teams to reach a common goal
Stay current on industry trends including new game genres, game design best practices, and emerging technology.
REQUIREMENTS
2+ years of experience in a data scientist or analyst role, involving some of the following: data analytics, CRM data analysis, data mining, business intelligence, predictive modeling
Excellent quantitative skills and deep understanding of statistics
Experience with AB testing and calculating statistical significance
Intuitive grasp of data and strong with Excel
Experience in interpreting data and analytics results to provide actionable insights into user/product behavior and deriving conclusions from those insights
Proven ability to work highly independently
Ability to juggle several projects at once
Outstanding communication skills-both written and spoken
MBA – Stats/Finance, M. Stat/M.Sc in a quantitative discipline (Mathematics, Physics, Statistics, Operations Research, Computer Science, Economics)
Passion for games is a must",3.8,"99Games
3.8",Udupi,"Udupi, India",51 to 200 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
698,Data Engineer,"Min. Exp: 1 year
Ahmedabad, India
Job Role
Skills Required
Personality
Job Role
Create and maintain optimal data pipeline architecture.
Build the infrastructure required for optimal ETL of data from a variety of data sources using AWS technologies.
Build large-scale batch and real-time data pipelines with data processing frameworks like Spark, Storm or other AWS technologies.
Skills Required
Good understanding on Java / Python.
B.Tech / M.Tech in CS with major in 'Data Engineering'/'Big Data'.
Understanding of Spark & other big data technologies.
Added advantage if the candidate has experience in data modeling, ETL design, implementation and maintenance.
Personality
You want to work in a small, agile team.
You mentor other developers when needed.
You work hard and don’t need much oversight.
You like variety in your projects.
You want to be proud of what you do at your job.
Interested applicants should send their resume and cover letter at career@iqm.com",-1,iqm.com,Ahmedabad,"New York, NY",1 to 50 employees,2014,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
699,Data Engineer,"What we are looking for:
Must be proficient in advanced working SQL, experience working with a variety of databases and a stronghold in Hadoop (Spark, Spring)/Google Cloud technology (AWS) for extracting and analyzing large datasets
Hands on experience with one or more of Java, Scala or Python language
Experience working in various data warehouses, reporting/ analytic tools and environments
Good to have an exposure to and fundamental understanding of advanced statistical techniques
Knowledge of deep learning and AI tools and their application in the Retail domain will be preferred

Responsibilities:
Design, construct, install, test and maintain highly scalable data management systems

Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and cloud-based ‘big data’ technologies

Create data catalog, data flow diagrams and interprets data results to users

Use data and their analytical ability to find and interpret rich data sources; manage large amounts of data; merge data sources; ensure consistency of datasets; create visualizations to aid in understanding data; aid in building mathematical/statistical models using the data; and present and communicate the data insights/findings and produce and present results with dashboard

You must be:
A team player who likes to work hard and play harder, have excellent interpersonal, organizational and time-management skills

Able to think strategically and analytically to effectively complete assigned work within given timelines

Someone who possesses excellent written and oral communication skills and have an attention to detail

A person with an ability to multi-task on multiple projects and tasks at the same time

A person who gives importance to attention to detail and be highly organized

Positive and upbeat with the ability to learn quickly

Be able to laugh. At others and most importantly at yourself. Need a sense of humor

You can expect:
A fast-paced, high-growth startup environment where you will gain a career and not just a job

The company to invest in your personal and professional development. We support your ongoing education and training by reimbursing you for relevant educational courses

An open office culture, no cabins or cubicles and a place that is looking for your input to help us grow

The support of your teammates to always do better. Own it and win together!

Exposure of International Retail market. Learn about a high growth industry and build critical skill-set

Excellent employee referral program. Refer your friends, work with your friends and be awarded for it

Work along with the smart, creative and energetic team who truly believe in ‘working hard and partying harder!’

Educational Requirement:
UG – B.Tech/B.E.",4.9,"Profectus
4.9",Bengaluru,"Schaumburg, IL",1 to 50 employees,2017,Company - Private,"Department, Clothing, & Shoe Shops",Retail,Unknown / Non-Applicable,-1
700,Senior Data Analyst,"We’re looking for a Senior Data Analyst who will be responsible for assisting in the efficient planning, collection, and maintenance of data sources to join our analytics team. If you meet the following requirements, wish to enter a creative, collaborative, and fun environment, and work alongside people dedicated to the success of our company, please apply online at careers.liventus.com

Job Responsibilities:
Build Tableau reporting
Identify, clean, and combine data to solve relevant business problems
Research and troubleshoot data related questions, tickets, and issues
Monitor and maintain our existing data to ensure it remains clean, accurate, consistent, and impactful
Transform data into meaningful insight and recommendations for business partners from various areas and companies, including but not limited to the Executive and Sales teams
Work with other members of Data Analytics team to develop business workflows that will help us make better decisions and be more efficient in our daily work
Coordinate development of test data, system testing, and documentation for all phases of our data migration processes (ETL)
Stay up-to-date on emerging technologies
Occasionally perform ad hoc reporting to answer specific business questions from upper management
Support users by developing thorough and complete documentation

Job Requirements:Candidate must have the following:
5-8 years of experience in data analysis using query tools required
Strong Tableau report building skills
Strong SQL skills with the ability to perform advanced queries and create stored procedures
Experience with dashboard reporting, scorecards, and executive presentations focused on analytics
Understanding of CRM reporting capabilities
Ability to gather business requirements and translate to technical specifications
Bachelor’s degree in Management of Information Systems (MIS), Mathematics, Statistics, Computer Science, or Business with an analytics focus
Data manipulation skills within Excel, such as VLOOKUP, Pivot Tables, VBA, etc.
An understanding of statistical and predictive modeling techniques and concepts
Strong analytic/problem-solving, documentation, and prioritization skills
A desire to learn new things and an ability to adapt to change and innovation
Ability to work on a team and manage individual prioritized workload
Candidate must be able to effectively communicate in English (written & verbal)
Knowledge of any scripting language e.g. Shell script, JavaScript, etc.
Knowledge of any ETL Tool e.g. SSIS

Benefits:
Group Mediclaim policy
Accident policy
Parental Health Insurance
Retirement benefits (Provident Fund)
Gratuity",4.8,"Liventus
4.8",Bengaluru,"Northbrook, IL",51 to 200 employees,2002,Company - Private,IT Services,Information Technology,₹500 million to ₹1 billion (INR),-1
701,Data Engineer,"Posted on 09-June 2020

Location: Hyderabad

Experience: 5 – 7 years

Roles and Responsibility:
Create and maintain optimal data pipeline architecture, assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centres and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems
Desired Qualification:
Bachelor of Engineering or B. Tech
Desired Experience:
Industry experience of 5-7 year of strong experience in Data Engineer Role.
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience with big data tools: Elastic Search and Redshift
Experience with relational SQL and NoSQL databases, including Oracle and Redshift
Experience with data pipeline and workflow management tools: especially Airflow
Experience with AWS cloud services: EC2, EMR, RDS, Redshift
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Experience with data visualization tools such as Quick sight, looker or Sisense.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.",4.3,"AMBC
4.3",Hyderabad,"Naperville, IL",1 to 50 employees,2001,Private Practice / Firm,IT Services,Information Technology,₹500 million to ₹1 billion (INR),-1
702,Sr. Data Analyst,"Required Educational Qualifications

Bachelors in Computer Science and/or Mathematics from Tier 1 institute.

Required Experience:
At least 4 (four) years as an analyst and 2 years as Big Data Engineer.

What you will be doing here -
Design & Develop data analysis framework for standard reporting requirements.
Reporting trends & impact as per the cadence.
Analyse data from multiple angles, looking for trends that highlight problems or opportunities.
Cater to non-standard ad-hoc queries.
Manage data requests from internal & external stakeholders (like investors and business partners).
Interface & provide relevant input to AI & research team.
Ensure that data pipeline is healthy & exhaustive in nature, just-in-time.
Make recommendations to adopt new business strategies.
Skills Required -
Mastery in writing MySQL or any other SQL.
Knowledge of Scala/Python is a good add on.
Skilled with Apache Spark framework.
Mastery in analytical tools like Excel Sheets or similar.
Mastery in representing raw data into relevant and easily comprehensible information.
Ability to break down complex problems into simpler parts
Ability to ask solution oriented questions

What makes you a perfect fit:
Leadership Skills
Entrepreneurial Mindset
Developing People
Analytical Ability
Attention to Detail
Problem Solving
Critical Thinking
Planning & Organization
Strategic Thinking
Innovative Thinking
Interpersonal Skills
Effective Communication
Active Listening
Teamwork
Effective Presentation
Personality Attributes
Curiosity
Discipline
Loyalty
Accountability
Result orientation
Proactive
Send your resume to hr@bobble.ai",4.4,"Bobble App
4.4",Bengaluru,"New Delhi, India",1 to 50 employees,2015,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,"Google, SwiftKey, Sogou"
703,Data Analyst,"The position is full-time and would be based at the company’s Chennai office. The successful applicant would have 1 - 2 years' relevant experience and be responsible for collection, validation & analysis of Mutual fund data.

01 July 2019

Data Analyst


The position is full-time and would be based at the company’s Chennai office. The successful applicant would have 1 - 2 years' relevant experience and be responsible for collection, validation & analysis of Mutual fund data.

Key Areas of Responsibility

Collection, validation, analysis of mutual fund information.
Updating the mutual fund information into our databases in a timely manner.
Perform quality checks.
Communicate with UK and Offshore asset management companies via email/telephone.
Provide clarifications to clients’ queries based on priority and urgency levels.
Extract and provide various project-related reports as required by the manager.

Key Skills

Key Technical Skills

Possess basic knowledge of Mutual funds and/or of the financial sector.
Proficient in MS Office (including MS Outlook)

Key Behavioural Skills

Very good written and spoken English communication skills.
Good Analytical and Problem solving skills.
Ability to work independently and come up with ideas to enhance the process.
Ability to achieve the defined SLA standards with regard to Turn Around Time, Work accuracy etc. and maintain them throughout one’s tenure in the department.
Ability to quickly learn new concepts relating to Mutual funds and be able to apply them in the work.

How to Apply

To apply for this job, click here

If you have any questions regarding this job, please feel free to email india.jobs@financialexpress.net

Apply now >",3.6,"fundinfo AG
3.6",Chennai,"Zurich, Switzerland",51 to 200 employees,-1,Company - Public,-1,-1,Unknown / Non-Applicable,-1
704,Data Scientist Intern and Machine learning/AI,"Responsibilities

The Data Scientist is responsible for advising the business on the potential of data, to provide new insights into the business’s mission, and through the use of advanced statistical analysis, data mining, and data visualization techniques, to create solutions that enable enhanced business performance.

Machine learning/AI: As an AI/ML engineer, the industry looks upon the following necessities from candidates.
Ability to write code in Java and Python
Knowledge on basics of math and probability
Good understanding and strong knowledge in algorithms and statistics
Appreciation of data modelling, software architecture and data structures and
Past experience of working in frameworks in last job or internship
Reasonable communication skills
Working in teams
Preferred degree in Computer Science, Mathematics or similar courses or fields
Finally a demonstrated experience of working in Machine Leaning Jobs before is an added advantage
With this broader understanding, let’s now get to the key part of what should be specifically focused in the AI/ML job descriptions.

Experience: 2 to 6 yrs

Job Type: Part-time

Salary: ₹8,000.00 to ₹20,000.00 /month

Experience:
total work: 1 year (Preferred)
Education:
Bachelor's (Preferred)
Required travel:
50% (Preferred)
Industry:
Software Development",-1,Sumicro Technologies private limited,Hyderabad,-1,-1,-1,-1,-1,-1,-1,-1
705,Applied Scientist,"A PhD in Computer Science, Machine Learning, Operational research, Statistics or in a highly quantitative field
Experience in predictive modelling and analysis, predictive software development
Strong problem-solving ability
Good skills with Java/Scala or C++, Perl/Python (or similar scripting language)
Experience in using R, Matlab, or any other statistical software
Strong communication and data presentation skills
Excited by Big Data, Machine Learning and Predictive Software? Interested in creating new state-of-the-art solutions using Machine Learning and Data Mining techniques on Terabytes of Data?
At Amazon, we are developing state-of-the-art large-scale Machine Learning Services and Applications on the Cloud involving Terabytes of data. We work on applying predictive technology to a wide spectrum of problems in areas such as Amazon Retail, Seller Services, Customer Service, Alexa, Chatbots and so on. We are looking for talented and experienced Machine Learning Scientists (Masters/Ph.D. in a related area preferred) who can apply innovative Machine Learning techniques to real-world e-Commerce problems. You will get to work in a team dedicated to advancing Machine Learning technology at Amazon and converting it to business-impacting solutions.
Major responsibilities
Use machine learning, data mining and statistical techniques to create new, scalable solutions for business problems
Analyze and extract relevant information from large amounts of Amazon’s historical business data to help automate and optimize key processes
Design, develop and evaluate highly innovative models for predictive learning
Establish scalable, efficient, automated processes for large scale data analyses model development, model validation and model implementation
Research and implement novel machine learning and statistical approaches
Experience handling gigabyte and terabyte size datasets
Experience working with distributed systems and grid computing
Knowledge of the latest and state of the art ML technology
Publications or presentation in recognized Machine Learning and Data Mining journals/conferences",-1,Amazon Dev Center India - Hyd,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
706,Applied Scientist,"A PhD in Computer Science, Machine Learning, Operational research, Statistics or in a highly quantitative field
Experience in predictive modelling and analysis, predictive software development
Strong problem-solving ability
Good skills with Java/Scala or C++, Perl/Python (or similar scripting language)
Experience in using R, Matlab, or any other statistical software
Strong communication and data presentation skills
Excited by Big Data, Machine Learning and Predictive Software? Interested in creating new state-of-the-art solutions using Machine Learning and Data Mining techniques on Terabytes of Data?
At Amazon, we are developing state-of-the-art large-scale Machine Learning Services and Applications on the Cloud involving Terabytes of data. We work on applying predictive technology to a wide spectrum of problems in areas such as Amazon Retail, Seller Services, Customer Service, Alexa, Chatbots and so on. We are looking for talented and experienced Machine Learning Scientists (Masters/Ph.D. in a related area preferred) who can apply innovative Machine Learning techniques to real-world e-Commerce problems. You will get to work in a team dedicated to advancing Machine Learning technology at Amazon and converting it to business-impacting solutions.
Major responsibilities
Use machine learning, data mining and statistical techniques to create new, scalable solutions for business problems
Analyze and extract relevant information from large amounts of Amazon’s historical business data to help automate and optimize key processes
Design, develop and evaluate highly innovative models for predictive learning
Establish scalable, efficient, automated processes for large scale data analyses model development, model validation and model implementation
Research and implement novel machine learning and statistical approaches
Experience handling gigabyte and terabyte size datasets
Experience working with distributed systems and grid computing
Knowledge of the latest and state of the art ML technology
Publications or presentation in recognized Machine Learning and Data Mining journals/conferences",-1,Amazon Dev Center India - Hyd,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
707,Research Scientist,"Experience 2-3 years of experience in generic formulation development of injectables for regulated markets(US/EU/Japan) from reputed company
Location Gurgaon
Description

RESPONSIBILITIES:
Planning, coordination and execution of product development activity for global markets.
Evaluation of literature and patents related to products under development.
Planning of stability studies and reviewing of development and stability data.
Compilation of Technology Transfer Dossier related documents.
Scale-up and technology transfer of products to manufacturing locations.

TECHNICAL EXPERIENCE:
Handling of Para IV ANDA products for US market.
Good understanding of regulatory requirements of global markets.
Good understanding of Patent and IPR strategies.
Execution of exhibit batches and technology transfers to manufacturing locations.

PERSONAL ATTRIBUTES:
Commitment, ownership, integrity, adherence to time lines.
Should have good planning and organizing capabilities.
Should be self motivated and having positive attitude.
Should have good drafting and communication skills.
Should have good team spirit.",3.7,"Fresenius Kabi Oncology
3.7",Gurgaon,"Gurgaon, India",501 to 1000 employees,-1,Subsidiary or Business Segment,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹100 to ₹500 billion (INR),-1
708,Machine Learning Engineer,"We are looking for a Machine Learning (ML) Engineer to help us improve the current products. Your ultimate goal will be to shape and build efficient self-learning applications.

Key Responsibilities:
Identify key variables, parameters and elements defining a problem or its solution.
Research and develop innovative, scalable and dynamic solutions to hard problems
Select appropriate data sets and data representation models
Run machine learning tests and experiments
Perform statistical analysis and fine tuning using test results
Scale the machine learning infrastructure for speed and performance
Keep abreast of developments in the field

Knowledge, Skills & Experience:
4+ years of Experience with Machine Learning or similar role
Ability to come up with the best model that would solve the problem at hand and develop and tune that model
Can apply probability models and machine learning approaches to solving complex problems
Strong coding skills with ability to write high performance code in Java/Python/R
Have experience using machine learning libraries or platforms
Strong understanding of data structures, data modelling and software architecture
Experience building scalable, sound architectures and reliable, high performance back-end services that work amazingly well in the complex real world as well as stand the test of time.
Deep knowledge on mathematics, statistics and data analysis Outstanding analytical and problem solving skills",4.7,"Grid Logic Software Private Limited
4.7",Hyderabad,"Gurgaon, India",501 to 1000 employees,2010,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
709,Data Scientist / Analyst,"If you are someone who always argues that data tells you everything and can speak numbers in your sleep, then you are it.

Requirements
Bachelor of Engineering in Computer Science, Math, Physics, Engineering, Statistics from Tier-1 college.
Development experience in SQL and any scripting language (Shell, Python, etc.)
Basic understanding of statistic and Experience manipulating large data sets through statistical software(ex R, Matlab etc).",4.0,"Adoro
4.0",Mumbai,"Munich, Germany",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
710,Lead Data Scientist,"Lead Data Scientist

31st January 2020

By Nalini Hire

In

/

vPhrase Analytics Solutions Pvt. Ltd.

Published

15th April 2020

Location

Pune, India

Category

Engineering

Job Type

Full-time

Description

About vPhrase

vPhrase helps make data easier to understand by explaining the insights in words, using AI. The company's patent-pending platform, Phrazor, analyses data, derives insights and then communicates those insights, in words, in multiple languages.

Role Overview

As a lead data scientist at vPhrase, you would be responsible for developing, testing and maintaining our data models in production. These models would power analytical and decision modules of our product’s AI engine. The candidate is also expected to lead the research team.

Requirements
Phd./Masters/Bachelors in Statistics, Computer Science, Economics or a related field with at least 8 years of experience.
The candidate should have directly led a team in some capacity.
Deep understanding of machine learning models, data analytics tools and deep learning frameworks.
Background in Natural Language Processing (NLP) and text analytics is a must.
Experience implementing and maintaining at least one NLP based feature into production.
Deep understanding of Natural Language Processing (NLP), intelligent search and text analytics.
Ability to handle large and complex structured as-well-as unstructured datasets.
Ability to perform independent research across various domains of analytics.
Proficiency working in Python/R and SQL.
Key Responsibilities
Working closely with our product teams to power intelligence in our AI product.
Designing and implementing products related to intelligent search, natural language processing and analytics.
Designing own experiments and developing new methodologies for analysis as per business goals.
Finding possible problems, exploring different approaches and arriving at solutions that enhances our analytical modules.
Building data models and maintaining them in testing as well as production environments.
Benefits

Being part of a startup that’s turning out to be a game-changer, you will be blessed with:
A young and energetic workplace where new ideas are always welcome. The crazier, the better.
Freedom to try new things; failure is not censured.
Casual dress code
5 day work week. Yes, Sat-Sun off
No over-time, proper work-life balance
Take-it-when-you-need-it vacation
Above all, we as a team devote one day every month to volunteer for social causes close to our hearts.

Apply

Apply

Your name *

Your e-mail address *

Your phone number *

Total Work Experience *

Current CTC *
(In Rs.)

Expected CTC *
(In Rs.)

Notice Period *
(In months)

Linkedin Profile Link *

Relocation *
Confirm that you are willing to relocate to the job location

Covering Letter *

Your CV *
Drop files here

browse files ...

Captcha

Captcha *

Tweet

Related

NLP/NLQ Engineer


About vPhrase vPhrase helps make data easier to understand by explaining the insights in words, using AI. The company's patent-pending platform, Phrazor, analyses data, derives insights and then communicates those insights, in words, in multiple languages. Role Overview We are looking for an experienced NLP/NLQ engineer who has worked on…
Solutions Consultant - BI/MIS reporting - Pharmaceuticals Industry


Role Overview The Solutions Consultant will act as a trusted advisor to our customers while adding industry and function specific breadth to our product. Our product team heavily relies on providing clients with industry/vertical and market knowledge to provide the best service to its clients in analytics, BI and reporting.…
Technical Architect (Product)


About vPhrase vPhrase helps make data easier to understand by explaining the insights in words, using AI. The company's patent pending platform, Phrazor, analyses data, derives insights and then communicates those insights, in words, in multiple languages. Role Overview We are looking for a Technical Architect for our Product(Phrazor) with…

NLP/NLQ Engineer

Sales Director",4.5,"vPhrase
4.5",Pune,"Mumbai, India",1 to 50 employees,2015,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
711,Machine Learning Engineer,"Location:Port Blair
category:IT Software – Other
experience:2 – 5 Years
Company:Tradeindia com Infocom Network Ltd,

Source URL: https://www.wisdomjobs.com",5.0,"Tavas Consultancy
5.0",India,"Ahmedabad, India",1 to 50 employees,2018,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
712,Data Analyst,"Work Experience
Candidate with 1-3 Years of work experience of Charges/ Payment Posting in US Healthcare with RCM Company.",-1,Nath Outsourcing Solutions,Nagar,-1,-1,-1,-1,-1,-1,-1,-1
713,Splunk Data Analytics and Business Intelligence Analyst,"JOB SUMMARY:

The Compute Engineer – Supervising Associate supports the best practices in engineering activities aligned to specific applications and/or systems within Enterprise Workplace Technology (EWT). The person in this role creates the blueprints for data management systems to integrate, centralize, protect and maintain the data sources. Develops, constructs, test and maintains architectures. The data engineer has a background in software engineering and loves to play around with databases and large –scale processing systems. Thanks to these interests, he/she can easily master technologies and is therefore familiar with a diverse set of languages that span both statistical programing languages and languages oriented more towards web development.
The role supports the design and development of IT architecture (integrated process, applications, data and technology) solutions aligned to the overall enterprise architecture and direction from IT as well as EY’s compliance standards for technology development and deployment.
The role supports the technical planning, architecture development and modification of specifications based on business strategic directives or general and identified changes required for operational readiness in applications, systems, networks and servers.
The role participates in business reviews, develops specifications to meet engineering requirements aligned to new products or services being introduced as well as for changes to current applications and other core components of the IT infrastructure.
The role is expected to plan, research, evaluate, design and develop appropriate technology solutions/applications by applying engineering, hardware and software design theories and principles to maintain business as usual (BAU) functionality as well as identify, establish and coach others in best practices in solution engineering.
The role supports the integration of these new products and services proposed by participating in the appropriate planning of all phases of development including feasibility studies, time and cost estimates, build and testing for compatibility in order to achieve an integrated architecture across interdependent technologies.
The role is an individual contributor, though they are often asked to manage project aligned teams in their collaborative efforts and to coach less seasoned members of the team in directives. The role is managed by the Service Owner / Service Manager of the Enterprise Log Management and Analytics (ELMA) service.
ESSENTIAL FUNCTIONS OF THE JOB:
Supports the best practices in engineering, design planning, development and aligned project management of all build activities for a specific new or existing application or system within EY.
Understands the broad and specific directives of EY products and applications both within the current service model as well any proposed modifications or additions to same. Uses this knowledge to identify and plan for approval appropriate solutions in response to assigned or identified basic to complex engineering directives.
Partners and works with the business and external vendors as necessary to ascertain and plan the proposed modifications necessary to meet and achieve the identified and agreed engineering modifications or build directives.
Support, propose a design and execute an architectural plan as needed to achieve the engineering directives inclusive of impacted applications, systems, networks and servers. Works with impacted business units, vendor and business resourcing and agrees change readiness and compatibility as well as timing required to achieve success.
Supports the activities of the agreed engineering project in a coordinated effort with other engineering, business and vendor resources as may be assigned to participate in design, build and delivery of a viable solution.
Identifies and communicates to the appropriate business leads the necessary delivery of components within the EY infrastructure and aligned configuration of same needed to support the engineering deliverable.
Support the alignment of the engineering plan with business priorities so that new designs and build plans as well as the budgeted spending is maintained throughout the development lifecycle. Supports the appropriate communication of accomplishments according to plan as well as notifies all of variances or contingencies in any aspect of the agreed design plan as they are identified.
Supports, as a point of contact, the engineering build–out work in progress and aligned service or application design activities by working with external engineers at the vendor locations, peers within the business as well as management.
Supports appropriate compilation and documentation of all engineering/development activities to appropriately capture all actions and activities.
Supports best practices in engineering/development solutions within the depth and breadth of the assigned business component of EY.
Creation of applications, dashboards, scripts and small programs to enhance the based product functionality, create integrations between other tools and services or automate manual repetitive / time consuming tasks.

ANALYTICAL/DECISION MAKING RESPONSIBILITIES:

The role requires an analytical acumen and solution orientation to probe for understanding and to make role appropriate decisions to address the nuances of assigned applications and/or services in current use across geographic regions or to solution within same. The role requires some consultative questioning, influence management and critical thinking skills to understand a current directive and identify and design viable engineering solutions that are both cost effective and supporting the value to the business. The role needs to drive the priority and time management of their own efforts and others (as applicable in group efforts) as well as communicate results and findings to affected individuals/business units and management as and when appropriate or necessary.

KNOWLEDGE AND SKILLS REQUIREMENTS:
Desire and ability to thrive in a fast-paced, highly demanding, dynamic business and information technology environment.
Customer service orientation
Excellent knowledge as Splunk App Developer
Proficient Python skills
Advanced scripting and programming skills
In-depth knowledge and skills to use and apply descriptive and inferential statistics including probability, hypothesis testing, estimation, associations, correlation, regression analysis, and forecasting
Analytic and business intelligence skills to identify meaningful patterns, analyze them, and then integrate and communicate them via data visualization and reporting techniques
Strong data visualization, reporting, and communications skills and abilities
Significant Data Analytic skill (Business Analytic skills)
Good knowledge in the Splunk Enterprise Product – Splunk Administration beneficial
Agile Dev/Ops skills
Maintains solid interpersonal skills to engage across multiple levels of the firm, in cross business discussions within a matrixed, geographically dispersed organization and to build a solid network of peers and others of influence. Adapts personal communication style to the style of others, develops rapport and stays calm under pressure or escalating issues using advanced oral and written English communication skills.
Projects solid consultative skill to conduct effective questioning, hone in on key directives to formulate ideas and materials as well as present those ideas clearly and concisely across the organization.
Maintains an advanced knowledge of services and applications with the assigned EY processes and operating environment to recognize and position improvement opportunities and next generation solutions achievable through engineering.
Manifests analytical and problem solving ability to escalate and negotiate conflicting engineering issues, handle multiple and shifting engineering priorities across a broad spectrum of operating environments and provide solutions that are both financially sound and operationally feasible.
Develops an in depth and continuous understanding of EY’s business and the way IT’s Engineering teams adds to the effectiveness of the EY business. Identifies and positions appropriate services and solutions as part of both knowledge sharing and engineering services remit.
Manage engineering projects by delegating work effectively utilizing the proper people, time and project management disciplines across a diverse culture and multiple time zones. Works to resolve team conflicts through an ability to implement and communicate difficult decisions as well as provide individual, team and peer mentoring as appropriate.
SUPERVISION RESPONSIBILITIES:
The role is generally an individual contributor but can and will operate as a lead and therefore manage specific engineering projects and activities. From time to time the role may be asked to mentor and guide across time zones and cultures and maintain effective and efficient oversight of all aligned activities. The role itself is generally guided by the Enterprise Log Management and Analytics (ELMA) Service Owner/Manager.
OTHER REQUIREMENTS:
The role may also require the periodic allocation of additional time on the job to support multiple demands and escalating issues or to accommodate teams or staff in other time zones
JOB REQUIREMENTS:

EDUCATION:
College degree in related technology field (Computer, Engineering, Science, etc.) or comparable job experiences aligned to a particular engineering directive.
EXPERIENCE:
Approximately 5+ years of experience in an engineering or development role
Software development experience with Python
Deep knowledge in Splunk Dashboard development
Rest API Architecture knowledge desirable
Particular MS Azure knowledge
Able to exhibit a progression of increasingly complex job responsibilities during the period inclusive of project management skills and engineering remediation techniques and planning.
Working in a virtual team spanning multiple continents and time zones is required
CERTIFICATION REQUIREMENTS:
Splunk Administrator certification beneficial
Any MS certifications are beneficial",3.8,"EY
3.8",India,"London, United Kingdom",10000+ employees,1989,Company - Private,Accounting,Accounting & Legal,₹500+ billion (INR),"Deloitte, KPMG, PwC"
714,Data Engineer- Pune,"Description

6sense is a Predictive Intelligence Engine that is reimagining how B2B companies do sales and marketing. It works with big data at scale, advanced machine learning and predictive modeling to find buyers and predict what they will purchase, when and how much.

6sense helps B2B marketing and sales organizations fully understand the complex ABM buyer journey. By combining intent signals from every channel with the industry's most advanced AI predictive capabilities, it is finally possible to predict account demand and optimize demand generation in an ABM world. Equipped with the power of AI and the 6sense Demand Platform™, marketing and sales professionals can uncover, prioritize and engage buyers to drive more revenue.

6sense is seeking a Data Engineer to become part of a team designing, developing, and deploying its customer centric applications.

A Data Engineer at 6sense will have the opportunity to
Create, validate and maintain optimal data pipelines, assemble large, complex data sets that meet functional / non-functional business requirements.
Improving our current data pipelines i.e. improve their performance, remove redundancy, and figure out a way to test before v/s after to roll out.
Debug any issues that arise from data pipelines especially performance issues.
Experiment with new tools and new versions of hive/presto etc. etc.
Required qualifications and must have skills
BE/BTech/BS or equivalent
Excellent analytical and problem-solving skills
6+ years work experience showing growth as a Data Engineer.
Strong hands-on experience with Big Data Platforms like Hadoop / Hive / Spark / Presto
Experience with writing Hive / Presto UDFs in Java
String experience in writing complex, optimized SQL queries across large data sets
Experience with optimizing queries and underlying storage
Comfortable with Unix / Linux command line
Nice to have Skills
Used Key Value stores or noSQL databases
Good understanding of docker and container platforms like Mesos and Kubernetes
Security-first architecture approach
Application benchmarking and optimization
Interpersonal Attributes
You can work independently as well as part of a team
You take ownership of projects and drive them to conclusion
You're a good communicator and are capable of not just doing the work, but teaching others and explaining the ""why"" behind complicated technical decisions
You aren't afraid to roll up your sleeves: This role will evolve over time, and we'll want you to evolve with it!",4.9,"6sense
4.9",Pune,"San Francisco, CA",51 to 200 employees,2013,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
715,Principal Data Scientist,"Yodlee’s Data Science team is driving innovations using Big Data at Yodlee. We have a high-caliber, focused and a mission-driven culture for our teams. The models we build and the analysis that we derive from financial data matters to crucial cutting-edge business decisions made across the global financial services firms every day and solves real world problems. We are leveraging our deep expertise in financial data to launch innovative solutions into the Financial Services Industry.

Description

You need to be a thinker. We are looking for a very curious data scientist who enjoys a deep dive into the raw data to help figure out the right set of questions and find the answers to those questions.

You also need to be a doer. You will be responsible for data cleansing, transformation and creating predictive models and classifiers.

You need to be smart and build smart products. A big part of this job is about creating actionable insights for our customers and the business using machine learning and statistical techniques. Translate analytic insights into concrete, actionable recommendations for business or product improvement.

You need to be ambitious. You must be passionate about applying mathematical modeling to solve real world problems. You must be willing to work with a team of modelers on cutting-edge prediction techniques who knows the best practices around modeling and validation. And more than anything, you must love to turn ideas into reality. If you are the happiest when you can prove the impact of statistical models/machine learning in generating business impact, let us know.

Required Skills and Experience:
8+ years of experience in the area of data science/machine learning (OR) PhD degree specializing in a relevant field such as Probability, Statistics, Machine Learning, Data Mining, Artificial intelligence/Computer Science.
Deep understanding of statistical modeling/machine learning/ data mining concepts
Strong analytical and quantitative problem solving ability
Strong interpersonal and communication skills: ability to tell a clear, concise, actionable story with data, to folks across various levels of the company.
Experience in managing high performance teams",-1,Envestnet | Yodlee,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
716,Machine Learning Engineer,"Job Description:

We are looking for a Machine Learning (ML) Engineer to help us create artificial intelligence products.

Machine Learning Engineer responsibilities include creating machine learning models and retraining systems. To do this job successfully, you need exceptional skills in statistics and programming. If you also have knowledge of data science and software engineering, we’d like to meet you.

Your ultimate goal will be to shape and build efficient self-learning applications.

Responsibilities
Study and transform data science prototypes
Design machine learning systems
Research and implement appropriate ML algorithms and tools
Develop machine learning applications according to requirements
Select appropriate datasets and data representation methods
Run machine learning tests and experiments
Perform statistical analysis and fine-tuning using test results
Train and retrain systems when necessary
Extend existing ML libraries and frameworks
Keep abreast of developments in the field
Requirements
Proven experience as a Machine Learning Engineer or similar role
Understanding of data structures, data modeling and software architecture
Deep knowledge of math, probability, statistics and algorithms
Ability to write robust code in Python, Java and R
Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)
Excellent communication skills
Ability to work in a team
Outstanding analytical and problem-solving skills
BSc in Computer Science, Mathematics or similar field; Master’s degree is a plus
Job Type: Full-time

Experience:
Machine Learning: 1 year (Required)
Education:
Bachelor's (Required)
Work Remotely:
Yes",3.2,"AIT
3.2",Coimbatore,"Wien, Austria",1001 to 5000 employees,1956,Other Organisation,-1,-1,₹1 to ₹5 billion (INR),-1
717,Machine Learning Engineer,"We are looking for an expert in machine learning to help us extract value from our data. You will lead all the processes from data collection, cleaning, and pre-processing, to training models and deploying them to production. The ideal candidate will be passionate about artificial intelligence and stay up-to-date with the latest developments in the field.
Job Types: Full-time, Part-time
Salary: ₹25,000.00 to ₹45,000.00 /month
Experience:
Machine Learning: 3 years (Preferred)
work: 3 years (Preferred)
total work: 3 years (Preferred)
Education:
Bachelor's (Preferred)
Industry:
Marketing
Work Remotely:
Temporarily due to COVID-19",5.0,"Invogue
5.0",Mumbai,"Pune, India",1 to 50 employees,-1,Company - Private,Architectural & Engineering Services,Business Services,Unknown / Non-Applicable,-1
718,Data Analyst,"We are looking for Data Analyst with good experience in collecting , analysing and curating game data.

Job Description
Candidate who are passionate about online games and have a deep understanding of games on a variety of Platform from PC to mobile.
Responsible for collecting, analysing and organising game and user specific data
Compile , Sort and verify the accuracy of data
Candidate who is interested in games like Counter Strike, League of legend, Dota 2 is highly preferable.
Open to work in rotational shift
No of Position(s)
2
Experience
0-1years
Industry Type
IT Software - Application Development
Functional Area
Software Services
Education
Graduate
PG Diploma
Location
Gurgaon
Keywords
Data Analyst
Telephone
+91 124 4703906
Remuneration (p.a)
4Lakhs
Reference
Data Analyst- 20916",3.5,"Stigasoft
3.5",Gurgaon,"Gurgaon, India",51 to 200 employees,2009,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
719,Data Science Intern,"About CourseBricks:

CourseBricks is a Data Science Education and Consulting organization based in Trichy (https://coursebricks.com). CourseBricks Academy offers Bootcamp style courses in Data Science, Machine Learning and Deep Learning. CourseBricks’ consulting arm works with clients across the world on various Data Science initiatives.

About the position:

We are looking for Data Science Intern with a background in computer vision, image processing and Optical Character Recognition (OCR).

The duration of the internship is 2 months and the position would be based in Thillai Nagar, Trichy. We prefer candidates who are already based in Trichy.

As a Data Science Intern, you will:
Work on developing a novel computer vision model for image recognition
Deploy the model in an real time application
Required Qualifications:
B.E/B.Tech/M.E./M.Tech in Computer Science, Robotics, Data Science/Artificial Intelligence and Electronics & Communications
Coursework and project experience in Computer Vision/Image Processing
Exposure to Optical Character Recognition (OCR)
Coursework in Data Science/Machine Learning
Python programming experience
Github repos of relevant projects
Desired Skills (not mandatory):
Knowledge of Deep Learning
We are looking for candidates who can start immediately. We are looking for candidates based out of Trichy.

Job Types: Full-time, Internship

Salary: ₹10,000.00 to ₹20,000.00 /month

Education:
Bachelor's (Preferred)
Location:
Tiruchchirappalli, Tamil Nadu (Required)
Work Remotely:
Temporarily due to COVID-19",-1,CourseBricks,Tiruchchirappalli,-1,-1,-1,-1,-1,-1,-1,-1
720,Analytics Manager II,"Amazon is seeking a leader to drive the Analytics efforts for Buyer Risk Prevention (BRP). As Analytics Manager you will lead a team of Business Analysts to (a) define an agenda for how to apply advanced analytics techniques to solve customer and associate problems, (b) deliver business insights which help drive business improvements to prevent abuse against Amazon's policies, and (c) lead the reporting function on key metrics. You will bring innovation, a passionate voice, and an ability to prioritize and execute on a fast-moving set of priorities, competitive pressures, and operational initiatives. You will partner closely with program, product and technology teams to define and build innovative and delightful experiences for them. You must be highly analytical and have the ability to break business problems down into steps that drive product development at Amazon speed.


Responsibilities:

· Drive effective teamwork, communication, collaboration and commitment across different groups with competing priorities;
· Effectively manage customer expectations and resolve conflicts that balance client and company needs;
· Drive team to manage deep-dives, map dependencies, remove bottlenecks, anticipate and make trade-offs, balance the business needs versus technical constraints;
· Possess great analytical abilities and judgment. Use quantitative and qualitative data to prioritize and influence, show creativity, experimentation and innovation, and drive projects with urgency in this fast-paced environment;
· Manages a very strong team of Business Analysts who use data and metrics to drive decision-making and innovate on behalf of the customer.



Basic Qualifications

· History of teamwork and willingness to roll up one's sleeves to get the job done;
· Strong attention to detail including precise and effective customer communications and proven ability to manage multiple and competing priorities simultaneously;
· Experience managing a team of Business Analysts to deliver results and measure their success;
· Analytical and quantitative skills; ability to use hard data and metrics to back up assumptions;
· Experience working cross-functionally;
· Presentation and written communication skills are essential: clear, organized, concise with an ability to adapt to appropriate audience;
· Experience with SQL and scripting (bash, perl or python) ability;
· Experience with complex problem solving and analysis using statistical methods, and financial modeling;
· +4 years of proven experience in data analysis, report building, research or similar work;
· Bachelors degree in Economics, Marketing, Statistics, or Business

Preferred Qualifications

· Masters' degree (MBA) in Economics, Marketing, Statistics, or Business;
· Strong analytical and organization skills;
· Proven ability to develop new ideas and creative solutions;
· Proven ability to work successfully in an ambiguous environment;
· Proven ability to manage higher level of stakeholders;
· Exceptional interpersonal and communication skills, both written and verbal;
· Ability to multitask and manage multiple projects (work prioritization, planning and task delegation);
· Proven experience with Python;
· Data Science skills.",4.2,"Amazon
4.2",Hyderabad,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
721,GS Accelerate - Louisa - Data Analyst,"MORE ABOUT THIS JOB


About the TeamLouisa is a GS Accelerate business focused on connecting the minds of our 36000 people to deliver one Goldman Sachs to clients.

RESPONSIBILITIES AND QUALIFICATIONS


HOW YOU WILL FULFILL YOUR POTENTIAL• You will be part of Louisa, focusing on building data sourcing, controls and distribution that enables the business to operate efficiently with data• You will help design data architecture to enhance existing pipelines as well as build feeds for new data sources.• You will participate in data architecture decisions and partner with engineering teams to implement data products in production systems.• This is a wide open opportunity for a motivated individual to use their skills to drive change in a high-visibility, challenging environment.SKILLS AND EXPERIENCE WE ARE LOOKING FOR• Bachelor’s degree or higher in Finance, Engineering or related disciplines• 2+ years of financial industry experience with strong analytical and problem solving skills• Good understanding and experience in using data structures and algorithms• Basic understanding in working with SQL/NoSQL• Good communication and interpersonal skillsPreferred Qualifications• Basic understanding of data analysis methodologies• At least 1 years’ experience dealing with data modeling• Experience in working with SQL/NoSQL data stores• Ability to work with the Louisa team to transform business requirements into data solutions• Experience working in a start-up business or a new business line within a larger organization is preferred• Proactive and self-directed with the ability to chase down and follow up on requests to a variety of businesses within the firm• Ability to present findings in a concise manner

ABOUT GOLDMAN SACHS


ABOUT GOLDMAN SACHSAt Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world. We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers. We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html

© The Goldman Sachs Group, Inc., 2020. All rights reserved.Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity",4.0,"Goldman Sachs
4.0",Bengaluru,"New York, NY",10000+ employees,1869,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"J.P. Morgan, Merrill Lynch, Morgan Stanley"
722,Data Consultant,"We are looking for a Data Consultant with experience in Analytical Solutions Consulting and sound knowledge in Machine Learning.

Mate Labs has built ""Mateverse"" for Data Analysts so that they can build customized machine learning and data science models for a quick prediction like sales forecasting without writing even a single line of code. At Mate Labs, we are solving a unique problem of Algorithm & Hyperparameter selection in the field of Artificial Intelligence.

Machine Learning has transformed industries and is ready to revolutionize the way you live, work and commute. It has created millions of new job opportunities and will continue to do so. This industry is going through a very exciting phase and at Mate Labs, we want to be at the forefront of this revolution. If it sounds exciting and you want to be a part of this revolution, join Mate Labs. Apply Now.

Job Responsibilities:

* Understanding the clients problems and Architecting Solutions around it.
Recommend design and develop state-of-the-art data-driven analysis using statistical & advanced analytics methodologies to solve clients problems.
Build deep client relationship, network & be a thought partner.
Excellent communication skills to be able to present findings to senior stakeholders
Working with Business Development / Sales team to customize solutions for the client
Working with the Data Science team on deliverables and owning it.

Skills Required:

* Proficiency in Python, Statistical/Predictive modeling and Machine Learning Algorithms (Regression & Time-series forecasting (MUST), Classification, Clustering)
Proven experience working on multiple business use-cases across various domains.
Subject matter expertise in solving Supply Chain related problems would be a plus.
Problem-solving, Project management, and communication skills & Creative thinking
Ability to think on his/her feet and engage with both the business and analytical community

Requirements:

* 3 - 5 years of experience
B.Tech or A degree in a quantitative field like Statistics, Mathematics, Economics, etc. or post-grad in management with strong technical skills.

Benefits:

*Startup culture(immense scope to learn and grow).
Amazing team to work with.
Health Insurance for the employees.",-1,Matelabs Innovations Pvt. Ltd.,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
723,Consultant - Data Science,"Antuit.ai is the leader in AI-powered SaaS solutions for Demand Forecasting & Planning, Merchandising and Pricing. We have the industry’s first solution portfolio – powered by Artificial Intelligence and Machine Learning – that can help you digitally transform your Forecasting, Assortment, Pricing, and Personalization solutions. World-class retailers and consumer goods manufacturers leverage antuit.ai solutions, at scale, to drive outsized business results globally with higher sales, margin and sell-through.

Antuit.ai’s executives, comprised of industry leaders from McKinsey, Accenture, IBM, and SAS, and our team of Ph.Ds., data scientists, technologists, and domain experts, are passionate about delivering real value to our clients. Antuit.ai is funded by Goldman Sachs and Zodius Capital.

The Role:
Antuit.ai offers AI products that help CPG and retail companies to plan and operate their business better. The data scientist will play a critical role in ensuring the products are configured to provide the best solution to the users.

Responsibilities:
A key member of the Forecasting and Supply Chain team, this person will facilitate product solutioning and enhance user experience with analytical insights and addressing the problem statements encountered by users. Specific tasks include:
Understand the client’s business including nuances of the products, sales channels, business cycles and levers like promotions, advertising etc.
Ensure completeness, accuracy and quality of data received
Identify anomalies in the business using the data and work with the client to resolve the anomalies
Configure the AI product model to generate the necessary model outputs
Evaluate the accuracy of the model outputs and analyze the output to identify issues in the model
Create and present reports showing model performance, and have an engaging conversation with business stakeholders
Analyze and resolve any ongoing issues with model performance
Qualifications and Skills:
4+ years of experience working with retail or CPG clients
Good understanding of CPG or retail supply chain process. Understanding of Retail/CPG data model is a plus.
4+ years of hands on experience in python and SQL to do exploratory analysis and identify anomalies
Good understanding of regression and/or time series models
Expertise in evaluating model output and identifying model improvement opportunities.
Excellent problem-solving skills
Natural ability to think analytically
The ability to plan work and meet deadlines
Accuracy and attention to detail
Flawless oral and written communication skills
Massive appetite to learn and curiosity to understand the business problem and solutions
Good team player with humility and patience to work with high caliber talent
Information Security Responsibilities
Understand and adhere to Information Security policies, guidelines and procedure, practice them for protection of organizational data and Information System.
Take part in Information Security training and act accordingly while handling information.
Report all suspected security and policy breach to Infosec team or appropriate authority (CISO).
EEOC
Antuit is an at-will, equal opportunity employer. We consider applicants for all positions without regard to race, color, religion, national origin or ancestry, gender identity, sex, age (40+), marital status, disability, veteran status, or any other legally protected status under local, state, or federal law.

To apply, please send your resume or CV to careers@antuit.com",3.9,Matelabs Innovations Pvt. Ltd.,Bengaluru,"Chicago, IL",201 to 500 employees,2013,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
724,Machine Learning and Data Scientist,"Worked on End to End Data Mining/Machine Learning Project Life Cycle
Experience on statistical / machine learning model development and implementation
Programming efficiency in Python / R.
Participate in data architecture and engineering decision-making to support analyticsUnderstanding machine learning algorithms
Development and implementation of datasets and database with machine learning tools for real time business problems
Understanding big data system architecture elements, tools and frameworks - like Hadoop, HDFS, hive, impala, Hbase, etc

Key Responsibilities:
Guide the client on technology evaluation, design data architectures, application architectures and techniques.
Support in business development activities like opportunity identification, client proposals, identifying new business opportunities, etc.
Assist in response to RFPs, RFIs, scoping, technical architecture, delivery mechanisms, approach notes, etc
Lead team in delivering machine learning solutions to client
Responsible for delivering client engagements and POCs, requirement gathering, solution design and development involving multiple work streams, machine learning solutions.

Exp: 3 to 8 yrs

Location: Bangalore/Mumbai/Hyderabad/Chennai/Pune/NCR",4.1,"Camsdata
4.1",Mumbai,"Bengaluru, India",51 to 200 employees,2017,Company - Private,IT Services,Information Technology,₹10 to ₹50 million (INR),eTeam
725,Data Analyst,"The Applications Development Senior Programmer Analyst is an intermediate level position responsible for participation in the establishment and implementation of new or revised application systems and programs in coordination with the Technology team. The overall objective of this role is to contribute to applications systems analysis and programming activities.

Responsibilities:
Conduct tasks related to feasibility studies, time and cost estimates, IT planning, risk technology, applications development, model development, and establish and implement new or revised applications systems and programs to meet specific business needs or user areas
Monitor and control all phases of development process and analysis, design, construction, testing, and implementation as well as provide user and operational support on applications to business users
Utilize in-depth specialty knowledge of applications development to analyze complex problems/issues, provide evaluation of business process, system process, and industry standards, and make evaluative judgement
Recommend and develop security measures in post implementation analysis of business usage to ensure successful system design and functionality
Consult with users/clients and other technology groups on issues, recommend advanced programming solutions, and install and assist customer exposure systems
Ensure essential procedures are followed and help define operating standards and processes
Serve as advisor or coach to new or lower level analysts
Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency.
Qualifications:
5-8 years of relevant experience
Experience in systems analysis and programming of software applications
Experience in managing and implementing successful projects
Working knowledge of consulting/project management techniques/methods
Ability to work under pressure and manage deadlines or unexpected changes in expectations or requirements
Education:
Bachelors degree/University degree or equivalent experience
This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required.
Experience in Equities Trading Flows, proficient cross- equities domain knowledge
Strong SQL experience, programming skills specific to data analysis and adhoc data extraction
Solid understanding of FIX/ FpML Knowledge of security, market data and reference data
Experience in client facing business management roles. Experience on running workshops with business and technology stakeholders
Proven Track record as business analyst performing requirements definition, functional design, preparation of test scripts, and implementation;
Preferable -Experience in message oriented/message driven applications and architectures
Excellent analytical and process-based skills, i.e. process flow diagrams, business modelling, and functional design;
Experience in order management systems
Familiarity with Listed Derivatives, Future/Options will be a plus
Proficient in using MS Excel to manipulate data and derive conclusions
Ability to own delivery/reported issues to completion.
Right attitude to gel well with the technology team locally/globally
The candidate should have the ability to work on multiple projects at any given time
Awareness of Project Management tools such as MS Project, Collabnet (Team forge)
Willingness to work in fast moving environment and deliver solid technical solutions
Desirable skills Development /coding experience with Python/R/Machine Learning.
-------------------------------------------------

Grade :All Job Level - All Job FunctionsAll Job Level - All Job Functions - IN

------------------------------------------------------

Time Type :

------------------------------------------------------

Citi is an equal opportunity and affirmative action employer.
Minority/Female/Veteran/Individuals with Disabilities/Sexual Orientation/Gender Identity.

Citigroup Inc. and its subsidiaries (""Citi) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity CLICK HERE.

To view the ""EEO is the Law"" poster CLICK HERE. To view the EEO is the Law Supplement CLICK HERE.
To view the EEO Policy Statement CLICK HERE.
To view the Pay Transparency Posting CLICK HERE.",3.5,"Citibank
3.5",Pune,"Elk Grove Village, IL",5001 to 10000 employees,-1,Subsidiary or Business Segment,Lending,Finance,₹1 to ₹5 billion (INR),-1
726,Big Data Engineer,"Role Brief:

Our Big Data capability team needs hands-on developers who can produce beautiful & functional code to solve complex analytics problems. If you are an exceptional developer with an aptitude to learn and implement using new technologies, and who loves to push the boundaries to solve complex business problems innovatively, then we would like to talk with you.

Responsibilities:
You would be responsible for evaluating, developing, maintaining and testing big data solutions for advanced analytics projects
The role would involve big data pre-processing & reporting workflows including collecting, parsing, managing, analyzing and visualizing large sets of data to turn information into business insights
The role would also involve testing various machine learning models on Big Data, and deploying learned models for ongoing scoring and prediction. An appreciation of the mechanics of complex machine learning algorithms would be a strong advantage.
Qualifications & Experience:

1 to 4 years of demonstrable experience designing technological solutions to complex data problems, developing & testing modular, reusable, efficient and scalable code to implement those solutions.

Ideally, this would include work on the following technologies:
Expert-level proficiency in at-least one of Java, C++ or Python (preferred). Scala knowledge a strong advantage.
Strong understanding and experience in distributed computing frameworks, particularly Apache Hadoop (YARN, MR, HDFS) and associated technologies -- one or more of Hive, Sqoop, Avro, Flume, Oozie, Zookeeper, etc..
Hands-on experience with Apache Spark and its components (Streaming, SQL, MLLib) is a strong advantage.
Operating knowledge of cloud computing platforms (AWS/Azure ML)
Experience working within a Linux computing environment, and use of command line tools including knowledge of shell/Python scripting for automating common tasks
Ability to work in a team in an agile setting, familiarity with JIRA and clear understanding of how Git works
In addition, the ideal candidate would have great problem-solving skills, and the ability & confidence to hack their way out of tight corners.

Experience:

Must Have (hands-on) experience:
Scala or Python expertise
Linux environment and shell scripting
Distributed computing frameworks (Hadoop or Spark)
Cloud computing platforms (AWS/Azure ML).
Desirable (would be a plus):
Statistical or machine learning DSL like R
Distributed and low latency (streaming) application architecture
Row store distributed DBMSs such as Cassandra
Familiarity with API design
Education:

B.E/B.Tech in Computer Science or related technical degree",-1,Fractal.ai,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
727,Data Analyst,"Bachelor's degree in Computer Science, Engineering, Operations Research, Math, or related discipline.
Minimum 2+ years of experience as an Analyst role preferred.
Highly proficient in Microsoft Office and Windows based applications.
SQL Knowledge and Hands-on experience is a must.
Demonstrated Analytical ability, results-oriented environment with external customer interaction.
Excellent written and verbal communication and presentation skills and the ability to express thoughts logically and succinctly.
Entrepreneurial drive and demonstrated ability to achieve stretch goals in an innovative and fast-paced environment.
Through the Amazon Marketplace, Amazon provides individuals or enterprises the opportunity to sell their goods on the Amazon platform. Worldwide, more than a million sellers use this Marketplace and thereby contribute to the success of Amazon. Amazon is growing its Marketplace aggressively worldwide. In this context, Amazon India Seller Services is setting up a new service to help with driving selection improvement on Amazon.

In order to drive improvement in the Amazon selection, this program will contribute in identification and on-boarding of new selection and drive efficiency of the existing selection.

About the Role: We are looking for a hands-on, detail oriented and highly motivated data analyst to help create data backed insights that will drive selection improvement . The candidate should be comfortable interfacing with technology systems and be able to analyze data and gather actionable conclusions. Operating in a rapidly changing environment will require the candidate to be adept at dealing with ambiguous, new and challenging situations. The candidate will be comfortable in executing repeatable processes.
Experience with E-Commerce, Retail and Business Analytics would be an advantage.
Understanding of data warehousing, data modeling concept and building new DW tables
Advanced SQL skills, fluent in R and/or Python, advanced Microsoft Office skills, particularly Excel and analytical platforms",-1,ASSPL - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
728,Senior Machine Learning Engineer,"Job Description
CreditVidya is looking for bright candidates for the position of Senior Machine Learning Engineer. The candidate is expected to:

• Have demonstrated passion and enthusiasm for Machine Learning through projects, products, etc. Ability to develop new ML models from scratch.

• Be sharp at Algorithm Design and Complexity Analysis, solving new problems with ease with effective and computationally efficient methods

• Enjoy programming and be comfortable with one or more languages such as, C, C++, Java, Scala, and Python

• Eager to quickly learn new concepts, languages, tools and technologies as required, for example, the credit underwriting fundamentals or new deep learning frameworks

• Enjoy building products that are generic and can cater to multiple tenants, through appropriate parameterization/abstraction

• Be ready to work on distributed programming and big data frameworks such as Spark and optimize the performance on multiple nodes

• Be excited to work in a startup environment and take end-to-end responsibilities working with the co-team members

Key Skills:

BS/MS in a relevant field with 2-5 years' experience. Or PhD in a relevant field with 0-3 years' experience",4.5,"Creditvidya
4.5",Hyderabad,"Hyderabad, India",51 to 200 employees,2012,Company - Private,Banks & Building Societies,Finance,Unknown / Non-Applicable,-1
729,Big Data consultant - AWS Professional Services,"Are you a Data Analytics specialist? Do you have Data Warehousing, Hadoop/Data Lake experience? Do you like to solve the most complex and high scale (billions + records) data challenges in the world today? Do you like to work on-site in a variety of business environments, leading teams through high impact projects that use the newest data analytic technologies? Would you like a career path that enables you to progress with the rapid adoption of cloud computing?

At Amazon Web Services (AWS), were hiring highly technical cloud computing architects to collaborate with our customers and partners on key engagements. Our consultants will develop, deliver and implement AI, IOT, and data analytics projects that help our customers leverage their data to develop business insights. These professional services engagements will focus on customer solutions such as Machine Learning, IoT, batch/real-time data processing, Data and Business intelligence.

This is a customer facing role. You will be required to travel to client locations and deliver professional services when needed.


· Expertise - Collaborate with AWS field sales, pre-sales, training and support teams to help partners and customers learn and use AWS services such as Athena, Glue, Lambda, S3, DynamoDB NoSQL, Relational Database Service (RDS), Amazon EMR and Amazon Redshift.


· Solutions - Deliver on-site technical engagements with partners and customers. This includes participating in pre-sales on-site visits, understanding customer requirements, creating packaged Data & Analytics service offerings.


· Delivery - Engagements include short on-site projects proving the use of AWS services to support new distributed computing solutions that often span private cloud and public cloud services. Engagements will include migration of existing applications and development of new applications using AWS cloud services.

· Insights - Work with AWS engineering and support teams to convey partner and customer needs and feedback as input to technology roadmaps. Share real world implementations and recommend new capabilities that would simplify adoption and drive greater value from use of AWS cloud services.

· Innovate - Engaging with the customers business and technology stakeholders to create a compelling vision of a data-driven enterprise in their environment

This role is open for Mumbai/Pune/Bangalore/Chennai/Hyderabad/Delhi/Pune.


Basic Qualifications


· Bachelors degree, in Computer Science, Engineering, Mathematics or a related field or equivalent professional or military experience

·8+ years of experience of IT platform implementation in a technical and analytical role

· 5+ years of experience of Data Lake/Hadoop platform implementation

· Hands-on experience in implementation and performance tuning Hadoop/Spark implementations.

· Experience Apache Hadoop and the Hadoop ecosystem

· Experience with one or more relevant tools (Sqoop, Flume, Kafka, Oozie, Hue, Zookeeper, HCatalog, Solr, Avro)

· Experience with one or more SQL-on-Hadoop technology (Hive, Impala, Spark SQL, Presto)

· Experience developing software code in one or more programming languages (Java, Python, etc)


Preferred Qualifications


· Ability to think strategically about business, product, and technical challenges in an enterprise environment

· Masters or PhD in Computer Science, Physics, Engineering or Math


· Hands on experience leading large-scale global data warehousing and analytics projects

· Ability to collaborate effectively across organizations

· Understanding of database and analytical technologies in the industry including MPP and NoSQL databases, Data Warehouse design, BI reporting and Dashboard development

· Demonstrated industry efficiency in the fields of database, data warehousing or data sciences

· Implementing AWS services in a variety of distributed computing, enterprise environments

· Customer facing skills to represent AWS well within the customers environment and drive discussions with senior personnel regarding trade-offs, best practices, project management and risk mitigation

· Desire and ability to interact with different levels of the organization from development to C-Level executives",4.2,"Amazon
4.2",India,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
730,Senior Software Engineer - Data Science,"At LYNK, we connect people with time-sensitive and business-critical questions to a curated community of 500,000+ experts. Our vetted experts span a comprehensive range of sectors and geographies and include world-class analysts, technologists, seasoned C-level executives and experienced consultants. Equally, we are committed to democratising access to knowledge for entrepreneurs, start-ups and the wider communities we operate in. In doing so, we empower our experts to bolster their credentials amongst a broader audience, while gaining access to challenging new projects and opportunities.

We are seeking a high-caliber, growth-minded Senior Software Engineer to build our engineering team in Hyderabad. This role is hands-on so we expect you to lead from the front. You will work closely with Product and Design teams globally and participate in all aspects of product development – from designing, building and delivering products for our clients.

What You’ll Do

Join us and tackle some of the most challenging problems in natural language processing and large scale applied machine learning. You will build cutting edge natural language understanding technologies and deploy them on a global scale.
Develop sourcing, cleansing, structuring and ingesting new data sources
Gather and process raw data at scale (including writing scripts, web scraping, calling APIs, write SQL queries, writing applications, etc.)
Build data pipelines that clean, transform and aggregate data into databases and adopt data warehouse solutions like AWS Redshift
Develop data pipelines that unify various data sources into one cohesive platform for data access
Design and Develop NLP engine and applications
Apply machine learning and predictive modelling techniques
Develop creative solutions to business problems using mathematical algorithms
Evaluate different NLP technology and tools
Work on very large text-based data sets, applying the latest techniques for entity recognition and sentiment extraction, with the goal of identifying features of real-time text feeds
What Expertise You’ll Add To The Team
7+ years of overall experience in developing highly available and scalable web applications in an agile environment
3+ years in Python programming skills including experience using Python libraries like Scrapy, numpy, Pandas, Tensorflow, Keras, Spacy, Scikit-learn
Hands on experience in NLP, sentiment analysis and text processing (classification, clustering and transfer learning)
Experience in manipulating/analyzing large datasets, finding patterns/insights within structured and unstructured data
Excellent conceptual understanding of machine learning techniques and algorithms such as decision forests, Naive Bayes, Regression, SVM and k-NN
Deep understanding of text representation techniques such as n-grams,bag of words, word2vec etc
Able to recommend machine learning solutions based on the risks and trade-offs of the model
Able to validate models using proof of concept, statistical validation and external research
Knowledge and working experience of building full stack applications with MongoDB, Express, Angular/React, and Node.js (i.e., MEAN/MERN technology stack) is plus
Excellent knowledge and working experience with AWS services such as EC2, S3, RDS, Lambda, API Gateway, SQS, and SNS
Knowledge of building services using java stack is plus
A bachelor’s degree or higher in computer science, software engineering, or a related field
If this position sounds interesting to you, we would love to chat and tell you more about our work culture and environment and see if this will be a good fit for both of us. Lynk is committed to attracting, developing and retaining the best people. We have created an engineering culture of excellence where there is a high degree of professionalism and collaboration. Our company is growing rapidly and provides plenty of opportunities for your personal and career development.

Why join Lynk?
Lynk is a VC- AND revenue-backed, product-driven startup working with leading institutional clients, top level experts and thought leaders globally
We operate in a high-octane environment where our people think about the big picture and always strive to “make it happen”
Our team, spread across five countries today (and growing!), is multinational, multilingual and multicultural. Our clients have likened us to a mini United Nations.
You will be constantly challenged with new problems to solve every day.
We are here to realize big dreams and have a firm belief in our core mission – to democratize access to knowledge.
Bonus Attributes
Strong passion for business and enthusiastic about taking part in shaping Lynk’s growth
Function well in a very fast-paced startup environment
Track record of excelling in small teams
Team players who thrive in uncertainty and like to “make things happen”!
What We Commit To You
Competitive remuneration package in a rapidly-expanding startup
Work in a collaborative, co-creation hub in the heart of the city - with amazing facilities
Comprehensive medical insurance coverage, including dental
Generous leave policy, including a ‘work remote policy’
The opportunity to travel and work around the globe with our international clients and growing number of offices (Hong Kong, Shanghai, Singapore, Mumbai, Hyderabad, New York City)
The opportunity to be a part of something impactful
Notes:

- LYNK employees are prohibited from trading Restricted Securities (defined as any security whose performance is linked to a single company) for any Personal Trading Account.

- All future new joiners are required to undergo a background check.",2.1,"The Straits Network
2.1",Hyderabad,"Hong Kong, Hong Kong",51 to 200 employees,2015,Company - Private,Financial Analytics & Research,Finance,Unknown / Non-Applicable,-1
731,Assistant Manager - Data Science,"With a
startup spirit and 90,000 curious and courageous minds, we have the expertise
to go deep with the world’s biggest brands—and we have fun doing it. Now, we’re
calling all you rule-breakers and risk-takers who see the world differently and
are bold enough to reinvent it. Come, transform with us.

Inviting
applications for the role of AM, Data Science

In this role,
we are looking for a commerce graduate / Postgraduate in Finance with prior data
handling experience. In this role, you will be expected to work on strict
deadlines, in a high-pressure business environment while being a standout
colleague.

Prior Commercial
Analytics in sales / orders reporting / MIS experience in the BPO Industry with
Access skills experience will be preferred

Responsibilities
Technical
expertise: Provide expertise in Statistics, Mathematical modeling
and simulation, Numerical Analysis and Differential Equation
Curiosity: a
desire to go beneath the stated client needs and discover and distill a problem
down into a very clear set of hypotheses that can be tested.
Cleverness: the ability to look at
a problem in different, creative ways.
Should
be able to Handle large data sets, Compute and Calculate Sales Incentives
with multiple slice and dice of the Sales data.
Should
be able to identify automation opportunities, handle customer queries and
issues and process log variations,
exceptions, output errors for traceability
Ensure
client satisfaction and successful external & internal audits
Qualifications


Minimum
qualifications
MBA
/ M.Sc. Statistics / M.Sc. Operations Research
Meaningful
work experience
Preferred qualifications
Relevant
work experience in Reporting and handling large data sets and databases
Flexibility to adapt to a
variety of engagement types, working hours and work environments and
locations
Very
good written and verbal communication skills
Proficient
in MS Office applications, especially in MS excel, R, Python
Good
analytical and problem-solving skills and ability to handle team and
client discussions
Genpact is
an Equal Opportunity Employer and considers applicants for all positions
without regard to race, color, religion or belief, sex, age, national origin,
citizenship status, marital status, military/veteran status, genetic
information, sexual orientation, gender identity, physical or mental disability
or any other characteristic protected by applicable laws. Genpact is committed to building a
dynamic work environment that values diversity and inclusion, respect and
integrity, customer focus, and innovation. For more information, visit
www.genpact.com. Follow us on Twitter, Facebook, LinkedIn, and YouTube.",3.6,"Genpact
3.6",Noida,"New York, NY",10000+ employees,1997,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"Accenture, IBM, Capgemini"
732,Sr. Principal Data Scientist,"Senior Principal Data Scientist

Senior Principal Data Scientist will help transform evidence-based pharmaceutical product development with Advanced Analytics in the Real-World Evidence and Clinical Outcomes department at Sanofi. He/ She will work closely with other disciplines across Sanofi including Biostatistics, Information Technology Systems and other Data Science partners to drive the use of novel analytics and data types to generate patient-centered evidence with impact across the Sanofi pipeline and business.

Examples of Advanced Analytics activities:
Machine/Deep Learning to elucidate disease trajectories, patient subtypes, define underdiagnosed conditions, and unmet health needs.
Create a framework for generating re-usable models and insights across big-data (e.g. EHRs, claims) and rich small data sets (e.g. clinical trials, imaging).
Generating insights by merging diverse data streams e.g. health, surveillance, trend data, sensor, imaging, …
Adoption of emerging technology into an analytical framework: distributed analytics, graph databases
People
Proactively engage RWE & CO colleagues, Sanofi technical and analytical partners, and Information Technology Services to identify, scope, and implement analytics approaches and solutions impacting a broad range of activities.
Provide expertise by advising on team members or executing advanced analytics for solving problems across R&D, Medical Affairs, HEVA and Market Access Strategies and Plans.
Performance
Expand the reach and help drive the development of a high-functioning organization through the development and deployment of cutting-edge analytics and computational techniques applied to a wide range of data including structured and unstructured healthcare data sources, pre-clinical, clinical trial and complementary real-world information streams.
Provide operational support on multiple projects with a core role in providing expertise in machine learning, statistics, mathematics, modelling, simulation, text-mining/NLP, data-mining on real world data across Sanofi.
Lead development and adoption of new computational and statistical methodologies for big data.
Maintain internal and external profile through contributions to congresses, publications.
Process
Plan and deploy methodological standards, standardized processes, demos, and POCs for the company’s highest priority business needs.
Help drive the vision and further the development of Advanced Analytics capabilities in RWE & CO by participating in the broader Statistical, Machine Learning and Data Science communities
Contribute to the design, development, and implementation of Sanofi’s data science architecture and ecosystem to guide decision-making and building foundational capabilities.
Knowledge, Skills & Competencies / Language
Proficiency in at least two or more technical or analytical languages (R, Python, etc..) and a willingness to embrace new coding approaches.
Experience with advanced ML techniques - neural networks/deep learning, reinforcement learning, SVM, PCA, etc.
An ability to interact with a variety of large-scale data structures e.g. HDFS, SQL, noSQL
Experience working across multiple environments (e.g. AWS, GCP, Linux) for optimizing compute and big data handling requirements.
Ability to prototype analyses and algorithms in high-level languages embracing reproducible and collaborative technology platforms (e.g. GitHub, containers, Jupyter notebooks)
Exposure to NLP and dataviz capabilities preferred.
Strong oral and written communication skills
A demonstrated ability to work and collaborate in a team environment
Qualifications
PhD or ScD in quantitative field such as Medical Informatics, Applied Math, Engineering, Computer Science or related field with a minimum of 5 years of industry or academic experience
Relevant Master’s Degree, with 7 or more years of related industry experience
At Sanofi diversity and inclusion is foundational to how we operate and embedded in our Core Values. We recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our colleagues, patients and customers. We respect and celebrate the diversity of our people, their backgrounds and experiences and provide equal opportunity for all.",3.7,"Sanofi
3.7",Mumbai,"Paris, France",10000+ employees,1973,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Pfizer, GlaxoSmithKline"
733,Data Analyst,"Required Skills & Experience

We are looking for a Data Analyst Executive
Eligible Qualifications : B. Tech, BCA, M.Tech, MCA
Experience : 3-5 years, fresher’s can also be considered
Location of Job : Gurgaon/Connaught Place, New Delhi

Technicals Skills

Following technical skills are pre-requisite:
Well versed with Software development methodologies, such as SDLC (Software Development Life Cycle), DDLC (Document Development Life Cycle).
Database schema design and implementation
Should have worked in either of technologies Sql Query/ Tableau/ Excel (Macros)/ Access (Query) writing for data analytics.
For planning and coordinating activities, organizations remain in invariant communication with one another and the data transfer has to be performed efficiently and smoothly as possible.
He/ She should manage the execution of the technologies, help the businesses in utilizing the systems, and should be well versed with the basics of computer systems such as Networking, Installation of necessary software and hardware.
Ability to determine the interrelationships between solutions and requirements.
Ability to think analytically and should be a problem solver and logic building should be very strong.
Good interpersonal skills to form effective working relationships with people at all levels.
Excellent communication and presentation skills and strong written & oral English skills.",3.8,"SSPL
3.8",New Delhi,"Chandigarh, India",1 to 50 employees,-1,Company - Private,Electrical & Electronic Manufacturing,Manufacturing,Unknown / Non-Applicable,-1
734,Data Engineer,"Noon is making education fun by social learning and collecting a lot of data points, which help to make product and customer experience better. Data comes from a variety of sources, internal and external, and in different formats. The data that we collect in a heterogeneous and distributed storage (data lake).

For our users (employee, customer) to be productive, data needs to be accessible uniformly. While understanding the nature of the data they deal with, our users should not be held responsible for its quality. The collected data might end up containing duplicates, being outdated, and generally being corrupted in several ways; one of the jobs of a data engineer is to prevent these issues and to minimize their occurrence.

We massage data, put its pieces together to provide a different perspective, elaborate it, store it, manipulate it, and optimize its access. We are also in the process of building pipelines to make the data flow from one sector of our architecture to another. We write efficient software, maintain our clusters, optimize and advise on queries, and continuously re-evaluate our process to make it faster and more accurate. To do this, we keep the discussion open, share our findings, and hold each other accountable.

We are in the middle of a substantial transformative process. We are piecing together a data science architecture that needs to sustain tons of gigabytes of data in a dependable and distributed way so that the data is at the fingertips of its users. If you haven’t scared yet? Then maybe you might consider joining forces with us.

Requirement
Excellent knowledge of SQL and Python
Experience with cloud platforms, in particular, Amazon Web Services
Preferred knowledge of Java / Scala
Good understanding of SQL and NoSQL databases, Star schema (data modeling, data warehousing)
Excellent Experience of Python, Java or Scala
Experience with big data: Hadoop, Spark, Kafka, Flink (HDFS, HBase, Hive)
Knowledge of algorithms and data structures
Deep understanding of the distributed systems
Experience with data visualization tools like Tableau or ElasticSearch will be a big plus",4.1,"Noon Academy
4.1",IndiraNagar,"Riyadh, Saudi Arabia",51 to 200 employees,2014,Company - Private,Primary & Secondary Education,Education,Unknown / Non-Applicable,-1
735,Sr Big Data consultant - AWS Professional Services,"Are you a Data Analytics specialist? Do you have Data Warehousing, Hadoop/Data Lake experience? Do you like to solve the most complex and high scale (billions + records) data challenges in the world today? Do you like to work on-site in a variety of business environments, leading teams through high impact projects that use the newest data analytic technologies? Would you like a career path that enables you to progress with the rapid adoption of cloud computing?

At Amazon Web Services (AWS), were hiring highly technical cloud computing architects to collaborate with our customers and partners on key engagements. Our consultants will develop, deliver and implement AI, IOT, and data analytics projects that help our customers leverage their data to develop business insights. These professional services engagements will focus on customer solutions such as Machine Learning, IoT, batch/real-time data processing, Data and Business intelligence.

This is a customer facing role. You will be required to travel to client locations and deliver professional services when needed.


· Expertise - Collaborate with AWS field sales, pre-sales, training and support teams to help partners and customers learn and use AWS services such as Athena, Glue, Lambda, S3, DynamoDB NoSQL, Relational Database Service (RDS), Amazon EMR and Amazon Redshift.


· Solutions - Deliver on-site technical engagements with partners and customers. This includes participating in pre-sales on-site visits, understanding customer requirements, creating packaged Data & Analytics service offerings.


· Delivery - Engagements include short on-site projects proving the use of AWS services to support new distributed computing solutions that often span private cloud and public cloud services. Engagements will include migration of existing applications and development of new applications using AWS cloud services.

· Insights - Work with AWS engineering and support teams to convey partner and customer needs and feedback as input to technology roadmaps. Share real world implementations and recommend new capabilities that would simplify adoption and drive greater value from use of AWS cloud services.

· Innovate - Engaging with the customers business and technology stakeholders to create a compelling vision of a data-driven enterprise in their environment

This role is open for Mumbai/Pune/Bangalore/Chennai/Hyderabad/Delhi/Pune.


Basic Qualifications


· Bachelors degree, in Computer Science, Engineering, Mathematics or a related field or equivalent professional or military experience

·12+ years of experience of IT platform implementation in a technical and analytical role

· 5+ years of experience of Data Lake/Hadoop platform implementation

· Hands-on experience in implementation and performance tuning Hadoop/Spark implementations.

· Experience Apache Hadoop and the Hadoop ecosystem

· Experience with one or more relevant tools (Sqoop, Flume, Kafka, Oozie, Hue, Zookeeper, HCatalog, Solr, Avro)

· Experience with one or more SQL-on-Hadoop technology (Hive, Impala, Spark SQL, Presto)

· Experience developing software code in one or more programming languages (Java, Python, etc)


Preferred Qualifications


· Ability to think strategically about business, product, and technical challenges in an enterprise environment

· Masters or PhD in Computer Science, Physics, Engineering or Math


· Hands on experience leading large-scale global data warehousing and analytics projects

· Ability to collaborate effectively across organizations

· Understanding of database and analytical technologies in the industry including MPP and NoSQL databases, Data Warehouse design, BI reporting and Dashboard development

· Demonstrated industry efficiency in the fields of database, data warehousing or data sciences

· Implementing AWS services in a variety of distributed computing, enterprise environments

· Customer facing skills to represent AWS well within the customers environment and drive discussions with senior personnel regarding trade-offs, best practices, project management and risk mitigation

· Desire and ability to interact with different levels of the organization from development to C-Level executives",4.2,"Amazon
4.2",India,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
736,Senior Data Engineer,"Provide technology consulting to external customers and internal project teams. Responsible for providing technical support and/or leadership in the creation and delivery of technology solutions designed to meet customers business needs and, consequently, for understanding customers businesses. As trusted advisor create and maintain effective customer relationships so as to insure customer satisfaction. Maintain knowledge of leading edge technologies and industry/market domain knowledge. Actively contribute to the companys solutions portfolio by providing information ranging from technical knowledge to methodologies based on experience gained from customer projects. Shape technical direction and technical strategies within the organization and for external customers. Accountable for consistent and significant chargeability levels (or expense relief for internal project teams) and for assisting in meeting or exceeding revenue and customer satisfaction goals. Contribute to organizations profitability by generating and cultivating new business opportunities and by providing technical support for deal proposal development.

Responsibilities:
Responsible for implementing part or all of the technical solution to the client, in accordance with an agreed technical design.
Achieve and maintain proficiency with Hadoop cluster and Hadoop application development, debugging, and performance tuning of applications using Map Reduce, HBase, Hive, Drill, YARN, Spark and other APIs.
Occasionally responsible for providing a detailed technical design for enterprise solutions.
Understands a broad spectrum of company technology in order to provide part or all of a detailed technical design which meets customer requirements.
Often leads small to medium technical projects.
Works with and under the direction of the Project/Technical Manager and with customer nominated representatives.
Liaises with Solutions Architect as appropriate.
Provides technical support and input on the application of technology to a defined business segment.
Provides advice on solution and integration opportunities to defined segments.
Provides technical leadership on specific integration activities that are part of an engagement.
Provides planning and design support for the development of solution architectures that will be implemented in a multiple system environment.
Communicates across client community, and is viewed as adding value.
Demonstrates execution of the company strategy.
Contributes to knowledge tools and communities, and ensures project learnings are documented and shared.
Role models Knowledge sharing and re-use within practice or profession.
Proactively encourages membership and contributions of others to professional community. Uses professions to meet the relevant certification and professional standards.
Produces internally published material such as knowledge briefs, service delivery kit components or modules, etc.
Participates in the selling process in C&I and works with sales/principals on pre- sales activities.
Education and Experience Required:
5+ years of professional experience and a Bachelor of Arts/Science or equivalent degree in computer science or related area of study; without a degree, three additional years of relevant professional experience (8+ years in total).
Knowledge and Skills:
Has sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise.
Has mastered in technical discipline in most of these technology areas:
Proficiency in Java programming and scripting a must with at least 5+ years of experience
Familiarity with Hadoop and the Hadoop Eco-System framework
Enterprise application design and development using data access in RDMBS, Messaging and web application including APIs like JDBC/JPA/Hibernate, JMS.
Strong understanding of the Java ecosystem and enterprise offerings, including debugging and profiling tools (jconsole), logging and monitoring tools (log4j, JMX), and security
Prior experience working with one or more of the following is preferred: Kafka, HBase, MongoDB, Hive, Drill and MapReduce programming.
Contribution to Open Source community is a plus
Has led small team in delivery of a specific deliverable.
Has mastered at least one technical discipline with strong knowledge in at least three major technology areas.
Possesses advanced level of business, technical, or functional knowledge.
Has ability to perform/drive resolution of problems on combinations and interactions of products.
Ability to apply technology and consulting to solve a client business problem.
Able to communicate and present complex issues with assurance and confidence.Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing.
Ability to conduct/lead oral status/technical interchange meetings with clients on small to medium sized engagements.
Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form. Ability to write relevant components of a proposal document (e.g. answer specific RFP questions). Ability to translate verbal requirements from face to face client meetings into requirements documents, statements of work, and proposals.
Able to discuss (within own area of expertise) requirements with a customer, and to challenge and clarify when appropriate. From the requirements, able to develop a high level design or plan, and then estimate the amount of effort required to deliver. Able to advise the engagement owner about the risks associated with this work package.
Ability to work with a team to provide written responses to technical proposals and /or reports/documentation for delivery.
Willingness to travel about 30%
We offer:

• A competitive salary and extensive social benefits

• Diverse and dynamic work environment

• Work-life balance and support for career development

• Want to know more about HPE? Then lets stay connected!

https://www.facebook.com/HPECareers

https://twitter.com/HPE_Careers

1061033",4.2,"Hewlett Packard Enterprise
4.2",Hyderabad,"Palo Alto, CA",10000+ employees,2015,Company - Public,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,"Oracle, Accenture"
737,"Data Analyst : Consumer Products, Intern (Remote)","Hi,

This is Samvid, co-founder and product lead. I wanted this to be a bit informal, so I'm just gonna talk here instead of creating a document.

Job Location: Gurgaon, Currently Remote due to Coronavirus Indefinitely

Compensation: 0 - 10,000/month

Our Vision

We're looking to recruit for the core team of our funded startup.

Less than 1% of people complete their New Year's resolution. Less than 9% do something about it after the first week.

We believe that the main challenge of our times is self-regulation and self discipline. For this, technology should be a solution and not the primary cause for distractions. We want to tackle this by using behavioural psychology, AI & games to help achieve our goals through small, byte sized habits.

Learn more about our product & vision here : http://bit.ly/AtmVsn

Who We Are

We have experience in building products as a core part of other startups (nearbuy, Limetray) and have used these opportunities to understand how to build technology businesses from the grounds-up. Gaurav and I are founders, and batchmates from NSIT CS, batch of 2013.

Who We Are Looking For

We are a team of about 5 right now and are looking to expand to 15. We need people across product, engineering and design. The way we see everyone's role at Atom is that everyone has a core competency which will be their primary responsibility, beyond which, each person has the right to choose to do more than just their role. We distribute tasks democratically and we will continue to do that as part of our culture.

Why should you join ?

The main takeaway for people wouldn't be the pay, if money is in your top three motivations to apply, I would discourage you from applying. We are at a point where we want to figure out product-market fit and as part of a small organisation you learn how to do that. Additionally, you will learn how to build and launch a consumer product for the western market, how to setup a team for a startup and more ownership in your field of work. Unless these aren't your priority, or if our vision doesn't appeal to you I would recommend against this profile.

Interview Process

We do this quite differently, for reasons that seem obvious to us. Basis your CV, we will have a video-call. Post that, we usually like people to come on board with us for 2-3 weeks and work with us. If you're already working, you can do this on weekends. We've seen this work well for us in previous startups mostly because it really helps us understand each other in terms of vision, culture and how we approach problems. This will definitely be more than an employer-employee relationship and we know that first 5-10 people in a startup are absolutely critical, perhaps even more so than founders. This ""trial"" helps both parties sort of de-risk the process.

If you've made it this far, congratulations. You've more focus than the majority. Let's finally get into the actual day-to-day

Responsibilities

Own and manage what to measure and what data to look out, in order to make the organisation more data-informed
Work to prepare experiments and targets for every product launch
Identifying what to measure, and the best way to do so through tools like Google Analytics, Amplitude, Mixpanel etc.
Understanding and working with data visualisation tools like tableau to enable teams to take better decision
Desired Skills and Experience

We've been thinking about who we want to work with, and how we want the company culture to be quite deeply. Though this is something that we know will change, we want to make it as explicit. View our values here : http://bit.ly/AtmCltr

Data Analysis
SQL
Python
If all this seems appealing to you, you can apply here.",3.7,"Atom
3.7",Gurgaon,"Coimbatore, India",1 to 50 employees,2007,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
738,Machine Learning Engineer,"Job Locations :
Bangalore, Kochi

Must have

3 - 10 years’ experience developing software for Computer Vision, Machine/Deep learning
Hands on with C, C++, Python, Linux, C#
Hands on with OpenCV, TensorFlow, Caffe, CUDA, OpenCL, OpenGL
Hands-on experience with internals of networks (CNN, RNN, LSTM, SSD etc). Customization of NN and improving performance
Experience with GPU/DSP/ISP/SoC architecture and system software.
Hands-on experience with one or more leading embedded SoC platforms (Nvidia, Qualcomm, NXP, Movidius, etc.)
Good analytical and problem-solving skills
Knowledge of computer architecture
Can build prototypes leading to production worthy solutions
Contribution in research communities, publishing papers or participation in Github projects related to machine learning would be a distinct advantage.

Education

Electronics/Electrical/Computer Science Graduate/Post Graduate/PhD",4.6,"Ignitarium Technology Solutions
4.6",Bengaluru,"Bengaluru, India",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
739,Data Engineer - Python,"Key Responsibilities:
Partner with other engineers and team members to develop software that meets business needs

Follow Agile methodology for software development and technical documentation

Innovate constantly and stay current with latest technologies while staying focused on solving problems at hand

Requirements

Degree in Computer Science or related fields.

3+ years’ experience in developing software applications.

Hands-on experience in Spark, Python, Pyspark

Experience with ETL/Data Pipelines.

Knowledge of Algorithms and DS a must

Building and managing data lake/data warehouses.

Experience with business reporting and analytics tool.

Experience with No-SQL databases (Preferably MongoDB or Casandra)

Proficiency in SQL queries.

Functional knowledge of cloud services, CI/CD pipelines, architecture design, scaling and testing strategies is desirable.

Ability to work with minimal supervision.

Team player with good interpersonal skills.

Ability to drive technology projects/solution.

Upload Resume Close",-1,Benchire,Bengaluru,"Bengaluru, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
740,Data Science Internship,"About the company:
KUKbit Software Lab helps clients manage their cloud environments from initial design through building, deploying, and ongoing management. We apply best practices that are developed over 5+ years in traditional IT and 3+ years as a premier AWS partner to help and ensure that our client's environment is secure, meet compliance requirements and maintain high availability to provide the broadest set of services and security for enterprise-grade apps, across any multi-cloud environment.

About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Working on data science algorithms and AI concepts 2. Using Python or R for web scraping 3. Building AI models using Python, machine learning, and deep learning algorithms 4. Processing of unstructured/structured data

Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 15th May'20 and 19th Jun'20
are available for duration of 2 months
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply

Number of internships/jobs available: 3

Categories: Data Science",-1,KUKbit Software Lab,Pune,-1,-1,-1,-1,-1,-1,-1,-1
741,Data Science Internship,"About the company:
KUKbit Software Lab helps clients manage their cloud environments from initial design through building, deploying, and ongoing management. We apply best practices that are developed over 5+ years in traditional IT and 3+ years as a premier AWS partner to help and ensure that our client's environment is secure, meet compliance requirements and maintain high availability to provide the broadest set of services and security for enterprise-grade apps, across any multi-cloud environment.

About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Working on data science algorithms and AI concepts 2. Using Python or R for web scraping 3. Building AI models using Python, machine learning, and deep learning algorithms 4. Processing of unstructured/structured data

Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 15th May'20 and 19th Jun'20
are available for duration of 2 months
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply

Number of internships/jobs available: 3

Categories: Data Science",-1,KUKbit Software Lab,Pune,-1,-1,-1,-1,-1,-1,-1,-1
742,Manager Data Scientist,"Company Introduction

Information Security & Data Analytics Series A funded company

Working in cutting edge technologies - Using AI for predictive intelligence and Facial Biometrics

Among Top 5 Cyber excellence companies globally (Holger Schulze awards)

Bronze award for best startup of the year (Indian Express IT awards), only cyber security company in top 3

More than 100+ clients in India

Job Descriptions
6+ Yrs. of industry experience in python(core) development
Minimum 3+ Yrs. of experience in NLP
Minimum 3+ Yrs. of experience in ML/DL
Strong Knowledge in core Python development.
Excellent command over various Machine Learning / Deep Learning algorithms.
Strong Knowledge on NLP.
Strong knowledge of Word embedding techniques like, GloVe, Bert etc.
Good exposure to various advanced deep learning networks like NN, RNN, CNN, P-CNN, and LSTM.
Must have complex project experience in regression, classification, clustering algorithms.
Must be well exposed to various text pre-processing techniques in NLP.
Must have experience in feature engineering, feature selection techniques.
Must be able to handle deployment complexities like big data management, model integration to existing environment.
Must have very good command on Python.
Should have strong knowledge of Regular expression.
Excellent knowledge on File Handling, Iterators, OS module and automation in Python is a must.
Must be comfortable in working with various operating systems including Windows and Linux.
Should be able to suggest alternative methods of solving complex problems.
Should be able to automate various OS tasks.
Experience with text processing.
Should be able to work in a team and alone.
Team Management skills",4.3,"Innefu Labs Pvt. Ltd.
4.3",New Delhi,"New Delhi, India",51 to 200 employees,2010,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
743,Sr Data Engineer,"ServiceNow is changing the way people work. With a service-orientation toward the activities, tasks and processes that make up day-to-day work life, we help the modern enterprise operate faster and be more scalable than ever before.

We’re disruptive. We work hard but try not to take ourselves too seriously. We are highly adaptable and constantly evolving. We are passionate about our product, and we live for our customers. We have high expectations and a career at ServiceNow means challenging yourself to always be better.

ServiceNow is currently seeking a world class data-engineer to join our Analytics team in Hyderabad. The candidate should be a self-starter working cross functionally with Operations, business & IT stakeholders to fulfill ServiceNow’s data, reporting & analytics needs.

This individual will take responsibility for performing translating business requirements through data analysis & creating scalable data models to support business need. The candidate is expected to be proficient in applying industry best practices for optimal design & development of data warehouse objects. This individual will also partner closely with the onsite Global Business Intelligence Team to adhere to enterprise standards, policies & processes.

A solid background in business intelligence methodologies and prior documented experience with SAP HANA and various databases like SQL Server, Snowflake, MongoDB etc. in a development role is required.

What you get to do in this role:
Collaborate with Head Quarters Analytics team to understand business requirements and design appropriate data solutions to meet business need
Leverage prior experience and industry standard best practices to analyze cross functional data and provide insights to business teams
Assist stakeholders with data analysis, design data models & develop DB Views, Calculation Views etc. in SAP HANA to meet business need
Build data pipelines, performing data munging, profiling, analysis etc
Implement snapshot processes, data refresh schedules, exception handling procedures as necessary
Define required data integration requirements between various systems and work with extended team to get them created
Follow all documented architecture, design & deployment processes to ensure compliance with policies
Partner with Global Analytics team to help implement solutions for end user adoption
Develop functional subject matter expertise within various areas of enterprise business processes
In order to be successful in this role we need someone who has:
Bachelor’s degree or equivalent in Computer Science, Computer Engineering, Information Systems or similar. Master’s degree preferred
6+ years of documented experience as a SQL developer in data warehouse technologies
2+ years of SAP HANA experience is a must.
Hands on knowledge of Bigdata systems and Snowflake
Special consideration for an interest or experience in Data Science projects, and for experience in working with large historical snapshot tables
Expertise in database design & development & SQL on SAP HANA or SQL Serve
Experience in ad-hoc data analysis, solution design, reporting & dashboard development
Prior ServiceNow platform experience is a huge plus
Excellent communication skills, ability to work individually and in a broader geographically disperse team
We provide competitive compensation, generous benefits and a professional atmosphere. This is a very collaborative and inclusive work environment where individuals strong on aptitude and attitude will have an opportunity to grow their professional careers through working with some of the most advanced technology and talented developers in the business.",3.7,"ServiceNow
3.7",Hyderabad,"Santa Clara, CA",10000+ employees,2004,Company - Public,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 billion (INR),"BMC Software, CA Technologies, Salesforce"
744,Principal Engineer - Data Engineering,"Zeta intends to replace many legacy systems in use by banks for processing payments. Banks need to leapfrog into an era of connected devices and omnipresent commerce. Banking should become an integral part of the commerce and enterprise systems, thereby enabling seamless consumer and business transactions. The average number of interactions an account holder may have with a bank would increase to 12-15 per day in the near term from the current average of 3-4 transactions per month. These could grow to an unimaginably large number in future. Most banking systems aren’t designed for this scale. In many ways, these systems are limiting the imagination of possibilities. We want this changed fundamentally, in an inter-operable and regulatory compliant manner.

We build large-scale transaction processing systems that can work with many current and future payment networks. We build applications that help banks realize the value of this new approach early. We help banks to rapidly deliver the value of these applications to their customers.
What is the Job like?
Designing and building large components or multiple services
Ensure high quality of architecture and design of systems
Create the optimum technical solution considering all the non-functional requirements
Functionally decompose complex problems into simple, straight-forward solutions
Articulate precisely both technical and business requirements by engaging with architects, data scientists, businesses and product managers
Mentor team members through technical discussions, design and ideation through white-boarding
Help managers arrive at a growth plan for the team members
Contribute strategically by working with tech leaders to maximize the productivity of teams by instilling an effective development environment
Evaluate the technical needs and select appropriate software, hardware, scalability and security requirement and suggest integration methods
Perform code and design reviews
Who should apply?
6+ years of experience building microservices.
Experience in Object-oriented design and programming
Strong experience in architecting and building distributed systems, scalability, and availability
Strong knowledge of data structures, algorithms, and designing for performance
Strong knowledge of cloud technologies like AWS/Google Cloud/Azure
Proficient with RDBMS
Strong knowledge on data stores, database design, data modelling and SQL queries
Strong knowledge of one or more big data processing stacks
Excellent code quality
Experience in Apache Spark, Kafka, RDBMS, Hadoop / Presto / AWS Athena.
Strong database and storage fundamentals, including a good understanding of database internals (RDBMS).
Strong Java skills, including experience working on large scale applications
In-depth understanding of concurrency, synchronization, NIO, memory allocation and GC
Experience working on real time streaming solutions using Flink / Spark or Kafka streams.
Experience with IaaS clouds like AWS/Google Cloud, Azure, OpenStack, etc.
Experience in working with Message Brokers and Application Containers
Great ability to mentor and train other team members

Good to have
Experience working on one or more large scale Java applications / platforms
Knowledge of Cryptography and Network Security
You have studied distributed systems like Dynamo, HBase, various messaging and queuing systems and understand nuances of Time, Clocks, and Ordering of Events, rate control, load distribution
You can smell fraud, transaction risks and abuse a mile away
Co-founded by Bhavin Turakhia (CEO) and Ramki Gaddipati (CTO), Zeta® is on a mission to make digital payments easy, inclusive and valuable for corporations, employees and merchants everywhere in India. Our products revolve around a key idea that spending and receiving money should be easy, fast, and trouble-free. Our Business Units are 1) Enterprise Solutions Group (ESG)- Zeta offers employee-benefit solutions like meal benefits, fuel and gadget allowance, communication reimbursements, RnR and more. To strengthen the ESG offerings we've tied-up with partners like RBL, Kotak and IDFC-First banks. 2) Zeta Express®-an innovative payment solution aimed at making corporate cafeterias cashless. The suite includes the Zeta Super Tag™, Zeta Express® Kiosk, Express Remote and Zeta Super ID. 3) Zeta Banking- Zeta is a technology partner/enabler that provides digital services: Card Management, Corporate Products solution and Customer lifecycle automation. Our corporate clientele includes over 14,000 clients across industries ranging from large conglomerates to small start-ups. Zeta has over 450 employees spread over 11 Indian cities: Mumbai, New Delhi, Hyderabad, Bangalore, Chennai, Pune, Kolkata, Nashik, Baroda, Kochi, and Ahmedabad. Zeta is ISO certified and PCI-DSS compliant. Zeta has also partnered with market leaders like Sodexo, RBL Bank, IDFC First Bank, Kotak Mahindra Bank, ADP India, Excelity Global and Aon Hewitt.

Zeta was awarded the best B2B platform and the best Payment App at the Payments and Cards Summit 2018. Zeta was also recognized as one of India’s most innovative product companies at NASSCOM Emerge 50 awards 2017 and was named the Fintech Rising Star for 2017 by the India FinTech forum.

Here’s what we’ve built so far:
1. Zeta Tax Benefits: Fully-digitized employee tax-benefits programme that helps employees save over 80k in taxes and helps organisations save up 90% of their time and resources
2. Zeta Express: A corporate cafeteria solution that makes cafeterias automated and completely cashless
3. Zeta Super Card: An advanced card-based payment solution that is 10x more secure than bank-issued cards
4. Zeta Spotlight: A digitized rewards, recognition and gifting solution that is easy to distribute and easy to spend",4.2,"Zeta
4.2",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
745,Finance Data Engineer - Finance Platforms & Data,"MORE ABOUT THIS JOB


Our Data, Platform, Infrastructure and Risk engineers work with multiple Finance businesses to drive consistency, efficiency and reuse across Finance & Risk Engineering solutions via the delivery of common services, tools, frameworks, and practices.With increasing complexity and volumes in Finance, we continuously need to scale our data. Cutting across all areas of Finance, our Data Engineering team is designing our common datastores in the Data Lake. We are a dynamic team of talented junior and senior developers, technical architects, and functional analysts who work in concert to deliver high profile projects using OO technologies.

RESPONSIBILITIES AND QUALIFICATIONS


HOW YOU WILL FULFILL YOUR POTENTIAL• Work in a dynamic, fast-paced environment that provides exposure to all areas of Finance• Build strong relationships with business partners• Understand business needs, facilitating and developing process workflow, data requirements, and specifications required to support implementation• Develop technical specifications, high level/detailed design, testing strategies, and implementation plans from business requirements• Manage end-to-end systems development cycle from requirements analysis, coding, testing, UAT and maintenanceSKILLS AND EXPERIENCE WE ARE LOOKING FOR• Bachelors degree in Computer Science, Mathematics, Electrical Engineering or related technical discipline• Experience in software development, including a clear understanding of data structures, algorithms, software design and core programming concepts• Comfortable multi-tasking, managing multiple stakeholders and working as part of a team• Excellent communication skills including experience speaking to technical and business audiences and working globally• Expertise in Java development & Relational Databases• Can apply an entrepreneurial approach and passion to problem solving and product development• Strong problem solving and analytical skillsPreferred Qualifications• Strong programming experience in at least one compiled language (e.g. C, C++, Java)• In-depth knowledge of relational and columnar SQL databases, including database design• Experience with continuous delivery and deployment• Proficient at working with large and complex code bases• Comfortable working in highly dynamic and rapid development environment (Agile development experience)• Technologies: Web/RESTful service development: HTML 5, JavaScript/AngularJS, JSON• Technologies: Linux and shell scripting, TDD (JUnit), build tools (Maven/Gradle/Ant), Scala, Spark, Tableau

ABOUT GOLDMAN SACHS


ABOUT GOLDMAN SACHSAt Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world. We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers. We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html

© The Goldman Sachs Group, Inc., 2020. All rights reserved.Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity",4.0,"Goldman Sachs
4.0",Bengaluru,"New York, NY",10000+ employees,1869,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"J.P. Morgan, Merrill Lynch, Morgan Stanley"
746,Machine Learning Engineer,"Job Description

We are looking for an expert in machine learning to help us extract value from our data. You will lead all the processes from data collection, cleaning, and preprocessing, to training models and deploying them to production.

The ideal candidate will be passionate about artificial intelligence and stay up-to-date with the latest developments in the field.

Responsibilities
Understanding business objectives and developing models that help to achieve them, along with metrics to track their progress
Managing available resources such as hardware, data, and personnel so that deadlines are met
Analyzing the ML algorithms that could be used to solve a given problem and ranking them by their success probability
Exploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real world
Verifying data quality, and/or ensuring it via data cleaning
Supervising the data acquisition process if more data is needed
Finding available datasets online that could be used for training
Defining validation strategies
Defining the preprocessing or feature engineering to be done on a given dataset
Defining data augmentation pipelines
Training models and tuning their hyperparameters
Analyzing the errors of the model and designing strategies to overcome them
Deploying models to production
Skills
Proficiency with a deep learning framework such as TensorFlow or Keras
Proficiency with Python and basic libraries for machine learning such as scikit-learn and pandas
Expertise in visualizing and manipulating big datasets
Proficiency with OpenCV
Familiarity with Linux
Ability to select hardware to run an ML model with the required latency
{{Make sure to mention any other frameworks, libraries, or other technologies relevant to your project}}
{{List any education level or certification you may require}}
Job Type: Full-time

Salary: ₹350,000.00 to ₹500,000.00 /year

Experience:
Machine Learning: 1 year (Preferred)
work: 1 year (Preferred)
total work: 1 year (Preferred)
Education:
Secondary(10th Pass) (Preferred)",3.9,"App Innovation Technologies
3.9",Coimbatore,"Grand Rapids, MI",1 to 50 employees,2014,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
747,Data Analyst,"Job Summary

Experience:
3 - 6 Years

Location:
Cochin

Designation:
Data Analyst

Degree:
BA, BBA/BMS, BCA, BCom, BCS, BE-Comp/IT, BEd, BE-Other, BIS, BIT, BSc-Comp/IT, BSc-Other, BTech-Comp/IT, BTech-Other, CA, CS, DE-Comp/IT, DE-Other

Educational Level:
Graduate/Bachelors

Stream of Study:
Computer Science/IT

Industrial Type:
IT-Software/Software Services

Functional Area:
IT Software - Application Programming / Maintenance

Key Skills:
VBA,MS ACCESS,EXCEL

Job Post Date:
Tuesday, March 17, 2020

Company Description

Our client is a leading global BPO organisation. They specialise in Corporate Information Solutions that re-engineer end-to-end business processes. Blending the right balance of people, process, delivery and technology, they will help you to engage more effectively with internal and external audiences to drive your brand differentiation and establish your competitive edge.
you’ll soon realise the potential of your information. Whether for internal or external audiences, they will transform the way it is created, produced, managed and delivered, turning it into a valuable business asset through their customised solutions.

Job Description

Job Description for Analyst/Sr. Analyst

Activities to be Performed:
1) Database Builds and Maintenance
Excel / Access / MS Outlook VBA coding
Building of workflow tools
Pricing Tool
Advanced Data Managing Tool (like Power Query, Power BI, etc.)

2) Monthly Reporting / Dashboard Maintenance:
The collation and processing of Business MI data
Running of Business Object Reports for circulation within the team
Various Dashboard Reporting

3) One off Jobs:
Support for new business tenders, when large amt. of data need manual intervention
Pricing exercise: Some print knowledge would be desirable not mandatory. The translation of a client supplied data set can be transposed into the SAS model format to allow pricing to take place
Building of Excel models for the wider business.

4) Support Activities / Admin Tasks:
Pricing data capture – Using a central email inbox
Specification site input compliance
Monitoring of auction activities etc.

Must have Skills:
Must be advanced level skilled in the use of Microsoft Excel and Microsoft Accessalong with the ability to understand and manipulate VBA coding
Speak & understands Mandarin (Converse with Chinese colleagues & stakeholder)
Data analysis and management reporting
Good to have Skills
Strong Math’s and Statistics skills
Experience of using BIsoftware (e.g. business objects, Tableau) would be an added advantage
Be strong at Planning and organizing multiple pieces of information in to a coherent structure
Have the ability to understand basic business finance and purchase to pay processes
Organized have the skill to work on more than one task at a time.
Knowledge of the print sector an advantage but not essential
Work Timings: 8am – 5pm IST. However, should be open to other shift timings as well per business needs",3.8,"Sampoorna Computer People
3.8",Kochi,"Mumbai, India",1 to 50 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
748,Data Scientist/Analyst,"As a Data Scientist, you will lead the development of a trading system and market analytics development, creating a range of forecasting and pricing models, contract and portfolio optimisation, and risk analysis.

Responsibilities
Detailed quantitative modelling of energy market fundamentals
Development of power market data forecasting models utilising machine learning and statistical techniques
Research UK power market and real time operation of Balancing Mechanism
Monitoring real time energy market information and implementing automated trading practices
Identification of value creation opportunities and developing trading strategies
Process and analysis of large financial datasets
Apply critical and creative thinking whilst considering data driven solutions
These are broad roles in a business that develops flexible generation projects from inception to operation. We are looking for a smart and driven analyst who is motivated by technical challenges and who has the vision to join a growing, dynamic company.

Requirements
Proficiency with Python, SQL and Database experience
Data analysis programming experience in Python using libraries, especially machine learning packages
An interest in the renewable energy sector is crucial
Proven programming, analytical and problem solving abilities
Experience with machine learning techniques and data science solutions
Communication skills are key as you’ll be interacting with people across the business as well as stakeholders outside of it
Engineering or physical sciences grounding, degree qualified in STEM subject
Valid UK driving licence desirable but not necessary.
What We Offer
Full-time permanent positions (unless otherwise described).

A challenging, stimulating and flexible work environment where talented professionals will be encouraged to forge successful careers. We are a fast-growing business deploying a disruptive technology, with all the opportunities that presents. As part of our team, you will have the scope to develop your role to match your aspirations and your strengths.

Competitive salary and bonus; company pension; flexible working hours; training program; flat management structure, and a bright spacious modern office environment in central Gloucester.

All our positions require a valid UK driving licence and eligibility to work permanently in the UK.",-1,Noriker Power,Odisha,"Gloucester, United Kingdom",1 to 50 employees,-1,Unknown,-1,-1,Unknown / Non-Applicable,-1
749,Data Science,"Experience : 3 – 6 years

Location : Pune
Good knowledge and experience on Machine learning, predictive analytics, Decision trees,NLP etc. Good communication and innovative mind set. Educational background – Bachelors degree In Computer Science and statistics/Mathematics.",3.3,"Nitor Infotech
3.3",Pune,"Pune, India",201 to 500 employees,2006,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
750,Data Engineer,"ZoomRx is creating a revolution in pharma market research through its innovative mobile & web-based platform. One of our extremely exciting product, Ferma - a SaaS platform for domain-specific enterprise search utilizing carefully curated healthcare knowledge graph for the Biotech firms in the US.

We need a developer who is quick in logical thinking, problem-solving techniques, and product development.

As a Data Engineer, you will work on
Algorithms and systems that power the contextual search engine using text mining, information retrieval, and machine learning
Data extraction from semi-structured text using Natural Language Processing and ingest into graph datasets and ElasticSearch
Implement and support efficient reliable data pipelines to move data from a wide variety of data sources to data marts/data lake
Build Data Ingestion frameworks taking into account access patterns scalability, response time and availability
The position requires one to work on complex technical projects with peers in an innovative and fast-paced environment
Mentor peers, share information, knowledge and help build a great team
What we are looking for?
Excellent problem-solving skills with a strong foundation in Computer Science including core data structures, algorithms, and analysis of running time and memory requirements
Able to build end-applications using a correct choice of GCP Components like GCS, DataFlow, Dataproc, Serverless Functions, Object Storage, Pub/Sub and Open Source components like Redis, MySQL, Neo4j, etc.
Strong Python development experience handling huge data preferably using Pandas
Strong communication skills, experience in Agile methodologies, ETL/ELT skills, Data movement skills, Data processing skills
Working experience in storing and retrieving data using Lucene based search engines ElasticSearch/Solr
Extra Points for
Experience in stream processing technologies using Apache Kafka, Apache NiFi
Exposure to NLP and its related libraries such as SpaCy
Experience designing Multi-tenant applications
Location
41/1, Vasantha Avenue, MRC Nagar, RA Puram, Chennai 600 028.",4.2,"ZoomRx
4.2",Chennai,"Cambridge, MA",51 to 200 employees,2009,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
751,Senior Associate Scientist,"Relocation Assistance Offered Within Country
# 84344 - Mumbai, Maharashtra, India

We are looking for Senior Associate Scientist I&S to join our ambitious team based at our Global Technology Centre in Mumbai.

As a Senior Associate Scientist you will execute Personal Care development programs for assigned brands/region by partnering with commercial & supply chain teams and by introducing new innovative products which cater to unmet consumer needs, modifications to existing formulae and simplification/harmonization of global bundles for the assigned geography, in compliance to safety standards, defined quality standards, FDA norms and government regulations. Additionally, you will also lead the technology transfer process of new products from lab/pilot scale development to commercial production phase at plants.

Job Context & Challenges:

In this role you will be required to execute complex development projects and/or multiple support projects. Develops and selects appropriate methods, tests and procedures. Also develops and recommends product quality, process and/or packaging specifications. Such assignments require selection of appropriate methods, tests and procedures. You would also support funding the growth program of the organization by exploring opportunities to optimize cost through formula and process optimization as well as identifying new vendors for quality ingredients sourcing at low cost.

You will need to support Quality and EOHS system implementation at India Global Technology Centre. The incumbent needs to work closely with other GTC’s and support/implement common programs. Within CP, the individual would interface with various departments and functions such as Supply chain, Packaging, Regulatory and Marketing/CIC so as to ensure timely completion of programs. As a part of Product Development, incumbent need to demonstrate ability to innovate with minimal guidance and execute the programs.

Functional linkages:

Internal: VPs/GMs, Department/Section Managers, Professional and Technical staff, Peers in other Functions (Primarily Supply chain, Packaging, Regulatory and Marketing)

External: Government/Regulatory officials, Product Vendors/Suppliers

Key Accountabilities:
Driving Sustainable growth by developing new innovative products to meet consumer/business need
Partner with stakeholders within GTC and outside GTC (such as marketing, supply chain etc.) to drive sustainable business growth.
Gain expertise of Personal care fundamentals and independently lead pilot plant activities with strong focus on EOHS & Quality.
Develop strong business acumen (end to end business understanding) by partnering closely with commercial & supply chain functions.
Constantly identify opportunities to improve processes with clear focus improving speed to market for all existing & new products.
Build formal & informal networks to constantly stay updated with new technology trends and breakthroughs.
Leverage performance management & development process to improve self-performance & capability.
Execute Personal care / Home care technology product development projects independently for all existing & new product bundles, from conceptualization to implementation on the ground.
Gain thorough understanding of product portfolio and related regulatory requirements for the assigned geography.
Initiate and Implement new ideas and programs in the spirit of continuous improvement in R&D.
Lead supplier qualification programs for raw materials & provide required support to packaging material qualification programs.
Process Compliance: Ensure 100% compliance to all relevant standards & processes. Ensure accurate documentation of processes, test results and project output.
Experience:

Essential:
Industrial experience in formulation development in FMCG or a Pharma company preferably in development of Oral Care / Personal Care / Home Care Products.
Should have a Masters degree with minimum 2 years’ experience in Cosmetic/ Pharma product development with a reputed FMCG/Pharma company.
Strong analytical ability and result orientation.
Experience in preparation of supporting data related to new product launches/ Re-launches to ensure smooth technology transfer to plant.
Proficient in spoken and written English
Professional Qualifications & Training:
Essential: M.Sc.(Organic Chemistry), M.Pharm Pharmaceutics
Desirable: Knowledge and/or experience in product development.
Equal Opportunity Employer
Colgate is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity, sexual orientation, national origin, ethnicity, age, disability, marital status, veteran status (United States positions), or any other characteristic protected by law.

Are you interested in working for Colgate-Palmolive? You can apply online and attach all relevant documents such as a cover letter and resume or CV. Applications received by e-mail are not considered in the selection process. Become part of our team. We look forward to your application.

Colgate-Palmolive is a leading global consumer products company, tightly focused on Oral Care, Personal Care, Home Care and Pet Nutrition. Colgate sells its products in over 200 countries and territories around the world under such internationally recognized brand names as Colgate, Palmolive, elmex, Tom’s of Maine, Sorriso, Speed Stick, Lady Speed Stick, Softsoap, Irish Spring, Protex, Sanex, Elta MD, PCA Skin, Ajax, Axion, Fabuloso, Soupline and Suavitel, as well as Hill’s Science Diet and Hill’s Prescription Diet.

For more information about Colgate’s global business, visit the Company’s web site at http://www.colgatepalmolive.com. To learn more about Colgate Bright Smiles, Bright Futures® oral health education program, please visit http://www.colgatebsbf.com. To learn more about Hill's and the Hill’s Food, Shelter & Love program please visit http://www.hillspet.com. To learn more about Tom’s of Maine please visit http://www.tomsofmaine.com.

Reasonable accommodation during the application process is available for persons with disabilities. Please contact Application_Accommodation@colpal.com with the subject ""Accommodation Request"" should you require accommodation.",3.9,"Colgate-Palmolive
3.9",Mumbai,"New York, NY",10000+ employees,1806,Company - Public,Consumer Products Manufacturing,Manufacturing,₹500+ billion (INR),-1
752,Senior Data Scientist,"The Senior Data Scientist will participate in requirement gathering including data discovery, system design, model implementation, code reviews, testing and maintenance of the platform developing applications Python, predictive modelling and analysis. The role will require a deep understanding of Computer Vision, deep learning, machine learning techniques and you will be part of a highly focused development team that includes data scientists, data engineers and business analysts and guiding them to help build products and specialized services on offer to our clients across multi-platform environment. The role offers a high degree of challenge and provides opportunity to experiment offerings that speaks of innovation.

Skills required

6+ years of relevant industry or research experience with strong knowledge of data mining, machine learning techniques, algorithmic optimization techniques, developing applications using predictive modelling and analysis.
Work closely with data engineering and technology teams to transfer knowledge and processes into production environment. Demonstrated experience in designing Platform Roadmap for key products and solutions.
Strong in Predictive and Prescriptive analytics approaches and experienced in operating tools like R and in programming using Python.
Understanding python integration with MySQL, Django, flask and REST API.
Knowledge of Image processing libraries such as OpenCV, PIL, and pytesseract.
Communicate analytic solutions to stakeholders and implement improvements as needed to operational systems. A thought leader with excellent written and verbal communication skills.
Familiarity with the fast-paced startup environment and culture that fosters a shared purpose among team by building a collaborative work environment
Capable of building & sustaining long-term relationships with businesses and internal & external stakeholders.
Ability to simultaneously mantle project responsibilities and with limited supervision.

Education

PhD/MTech/MS/M. Stat or equivalent degree in Computer Science or Economics or Mathematics or Operational research (OR) or Statistics.

For any query, you may reach amitabh.ranjan@karvy.com.

About Karvy Analytics

Karvy Analytics is a new age arm of the leading Karvy Conglomerate. A focussed Analytics company, the young and forward thinking team is building world class solutions for the global analytics universe in Banking & Financial Services, Healthcare and Retail domain. Karvy Analytics offers a range of solutions that bring immediate business benefits to our global customers by leveraging big data, statistical and mathematical modelling techniques, social analytics, and mobile descriptive analytics for new business insights.

We provide an integrated decision support ecosystem of services across-industry, enabling and transforming the way decisions are taken.",1.0,"Karvy Analytics
1.0",Hyderabad,"Hyderabad, India",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
753,Technical Lead - Data and Machine Learning Engineering,"Company Overview Danaher Corporation
Danaher is a global science and technology innovator with more than 59,000 associates committed to helping our customers solve complex challenges and improve quality of life around the world. Our world class brands have unparalleled leadership positions in some of the most demanding and attractive industries and our technologies address a broad range of societal needs:
Protecting the global water supply and ensuring environmental stewardship
Protecting the world's food supply and verifying pharmaceutical dosages and authenticity
Leading scientific research and advancing patient health with the highest diagnostic confidence
Improving dental outcomes and promoting access to comfortable patient care around the world Danaher generates over $18 billion USD of annual revenue from five business segments: Life Sciences, Diagnostics, Dental, Water Quality, and Product Identification.

For additional company details, see www.danaher.com.

Danaher Digital

Danaher Digital is our digital innovation, incubation and acceleration center where we’re bringing together the leading strategic product and business leaders, technologists and data scientists for the common purpose of accelerating development and commercialization of disruptive and transformative digital solutions into the marketplace.

We accelerate Danaher’s digital innovation journey by partnering with Danaher operating companies (OPCOs) to monetize and commercialize the potential of emerging and disruptive digital trends such as AI, Machine Learning (ML), Big Data, IoT, Augmented Reality (AR), Cloud (SaaS/PaaS) and other Digital frontiers. If you are driven to forge new disruptive and transformative digital apps, platforms and services by working with such cool and emerging technologies, you belong in Danaher Digital.

True to Danaher’s shared purpose of “Helping Realize Life’s potential”, we work alongside industry’s leading companies in large, diverse and growing markets segments – from industrials to environmental sciences to life sciences to medical diagnostics. If you are inspired by and motivated to create true impact on lives and industries, at a scale and breadth that Danaher is uniquely positioned for, then you belong in Danaher Digital.

If you thrive in startup-like environments where you can envision, architect and rapidly build hi-tech solutions that are ground-breaking in the diverse markets Danaher is uniquely positioned to lead, then Danaher Digital is where you want to be.

Located in Silicon Valley, the heart of global innovation, Danaher Digital is ideally situated to capitalize on the digital mega trends transforming our world. And now we are establishing a strategic talent and innovation hub in India’s Silicon Valley – Bangalore, with broad ranging product capabilities and leadership.
Position Description
As a Technical Lead for Data and Machine Learning (ML) Engineering, you will join a team of skilled Data Scientists, Software engineers and Cloud Architects to drive Danaher’s Digital transformative initiatives in Data and Analytics (Machine Learning/AI) platforms and applications targeted at multiple industrial segments such as Life Sciences, Diagnostics, Industrial manufacturing and environmental sciences. You will lead a team of engineers tasked with building cloud-based data and analytics services to translate Danaher’s strategic vision in to technical reality.
You will be called upon to work collaboratively with our business stakeholders, Architects, Product Managers/Owners, to set goals for your team and guide them with hands-on technical expertise. You will not hesitate to get your hands dirty in technical implementations. You will bring your proficiency in Data Engineering, SQL/NoSQL databases, ML Engineering, analytics pipelines, SQL/NoSQL databases and detailed SW planning/execution acumen.
You will have the opportunity to build new teams and mentor them to become highly efficient in what they do and in on-time delivery of tasks. You will work with a globally distributed Agile team in a fast-paced environment. Responsibilities
Lead a team of skilled engineers to build data pipelines and production level ML infrastructure in a fast-paced environment.
Lead your team of Data and ML engineers to translate Data & Analytics requirements in to short- and long-term implementation plans. Be comfortable with details and be hands-on to make sure the delivery expectations are met.
Lead your team to launch new data ingestion, extraction, transformation and loading processes on AWS/Azure cloud with a keen focus on scalability, reliability, performance and reusability. Build key data sets and lead feature engineering efforts to empower exploratory analysis and advanced analytics.
Collaborate with our data scientists to identify and build data pipelines and patterns that are relevant to advanced analytical model building and then curate, clean, wrangle and prepare data for efficient use at large scale.
Lead your team to understand Machine Learning/Deep Learning model performance requirements, refactor model code as necessary, design model deployment frameworks and deploy models in prototype/production environments.
Closely collaborate with other engineering teams to ship machine learning products to production.
Interact with both business and technical stakeholders to deliver high quality products and services that meets/exceeds business customer, and technical requirements.
Leverage your experience to evaluate new data technologies and build a scalable data engineering and ML engineering framework.
Share in code and design reviews with agile team
Integrate 3rd party software components into existing software applications
Work with geographically distributed teams while maintaining highest standards in collaboration and communication. Requirements
7+ year of demonstrated experience in developing highly scalable, reliable, and real-time data processing pipelines combined with experience in Machine Learning workflow and model deployment
7+ years of experience leading and software product development teams in an Agile environment
5+ years of experience with a variety of SQL and No-SQL data stores such as MongoDB, Cassandra, HBase, MySQL/Postgres
5+ years of demonstrated experience in developing data pipelines using Python/Java/Scala on various frameworks(especially on Apache Spark) on AWS, Azure, or similar cloud platforms; Demonstrated experience in Data security aspects and implementation.
2 to 3 years of demonstrated experience in designing and deploying software using frameworks for machine learning such as TensorFlow, Theano, Keras, Scikit-learn, Spark ML, CNTK, Torch, Caffe, MXNet, H2O
Ability to work with structured, semi-structured and unstructured datasets uncovering information and identifying complex links across different data sets
Experience with Docker and Kubernetes
Experience with one or more programming languages such as Java, Scala or Python.
Ability to nurture/mentor others in the team.
A can-do attitude in anticipating and resolving problems to help your team to achieve its goals.
Excellent communication skills with direct team members as well as external teams and stakeholders.
Must have experience in Agile development methods.
Willingness to travel (< 20%)",-1,Danaher Digital,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
754,Data Analyst,"“Make every logistics journey your best one yet” - Quincus
The Company.
At Quincus, our technology is designed to ease shipping issues—wherever in the world they may be. We commit ourselves in designing the most effective total end to end supply chain solutions through a dedicated technology ecosystem. This offers our users a personalized experience that bypasses traditional and expensive logistics options.
By combining advanced technology, data analytics, and hands-on experience, we eliminate traditional and expensive logistics options.

The Opportunity.
As our business continues to grow, we are looking for a Data Analyst to join our team who will discover the information hidden in vast amount of data and help make smarter decisions for better products. The primary role involves interpreting data, analyzing results using statistical techniques.
Your day to day.
-Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality.
-Acquire data from primary or secondary data sources and maintain databases/data systems.
-Identify, analyze, and interpret trends or patterns in complex data sets.
-Identifying patterns and trends in data sets.
-Define new process improvement opportunities.

Who you are.
-3+ years of working experience as a data analyst or business data analyst.
-Hands on experience in MS Office Package with Advance Excel (Vlookup, Pivot table, HLookup, Conditional Formatting, UDFs, etc.)
-Technical expertise regarding data models, database design development, data mining and segmentation techniques.
-Knowledge of statistics and experience using statistical packages for analyzing datasets.
-Ability to analyse large datasets.
-An analytical mind and inclination for problem-solving.

What’s in it for you.
-People: Work with passionate, smart, and entrepreneurial go-getters.
-Fun environment: cool office space, stocked pantry, and team bonding.
-Compensation: competitive salaries and benefits.",4.0,"Quincus
4.0",New Delhi,"Singapore, Singapore",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
755,Machine Learning-AI - Data Science,"Job Description

Job Skill:AI - Data Science

Designation: Career Level - 10-Analyst

Job Location: Bengaluru

Qualifications: Any Graduation

Years of Experience: 5-7 years

About Accenture

Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Combining unmatched experience and specialized skills across more than 40 industries and all business functions —underpinned by the world’s largest delivery network — Accenture works at the intersection of business and technology to help clients improve their performance and create sustainable value for their stakeholders. With 500,000 people serving clients in more than 120 countries, Accenture drives innovation to improve the way the world works and lives. Visit us at www.accenture.com

Job Summary

You will be aligned with our Artificial Intelligence vertical and help us apply your expertise in building world class solutions, conquering the business problems, addressing technical challenges using AI Platforms and technologies. Utilize the existing frameworks, standards, patterns to create architectural foundation and services necessary for AI applications that scale from multi-user to enterprise class. Demonstrate self as an expert by actively blogging, publishing research papers and creating awareness in this emerging area.

You will be working as a part of Machine Learning team which provides computers with the ability to learn without being explicitly programmed. It focuses on the development of computer programs that can change when exposed to new data.

You will be responsible for AI - Data Science wherein you will be working in operations that follow multiple approaches for project execution from adapting existing assets to use cases, exploring third-party and open source solutions for speed to execution. You will leverage the vast global network of Accenture to collaborate with internal teams to create unique solutions. Solid knowledge in at least one of the following – Supervised and Unsupervised Learning, Classification, Regression, Clustering, Neural Networks, Ensemble Modelling, Multivariate Statistics, Non-parametric Methods, Reliability Models, Markov Models, Stochastic models, Bayesian Models are required for this role.

Good to have skills: AI - Data Science,Good communication skills

Roles and Responsibilities

In this role you are required to do analysis and solving of increasingly complex problems. Interaction is with peers within Accenture before updating supervisors. Likely has some interaction with clients and/or Accenture management. Minimal instruction on daily work tasks and a moderate level of instruction on new assignments will be provided. Decisions made by you impact your own work and may impact the work of others. In this role the person would be an Individual contributor and/or oversees a small work effort and/or team
Qualifications
Any Graduation",3.9,"Accenture
3.9",Bengaluru,"Dublin, Ireland",10000+ employees,1989,Company - Public,Consulting,Business Services,₹500+ billion (INR),"Cognizant Technology Solutions, EY, McKinsey & Company"
756,Data Analyst,"Technical skills: proficient in Excel,relational database like MS SQL,ORACLE etc,knowledge in LINUX,Scripting language like SHELL
Responsibilities: collect the data available from the available sources,load them to database,study data from different dimensions and present intelligent reports used for campaign optimization
If you are self driven and self motivated individual with passion towards work ,please drop in your CV's to info@doptit.com",-1,DoptitAI,Kochi,-1,-1,-1,-1,-1,-1,-1,-1
757,Data Science Engineer,"Data Science Engineer
Full time
-
Pune",3.8,"Talentica
3.8",Pune,"Pune, India",201 to 500 employees,2003,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
758,Principal Data Engineer,"We are seeking top engineering talent to join our creative, dynamic, and highly driven team. Zynga’s mission is to “Connect the World through Games” by building a truly social experience that makes the world a better place. The ideal candidate will have a devotion to software craftsmanship, an unwavering commitment to quality, and the desire to have their work seen by tens of millions of people worldwide.

The Analytics Engineering team is responsible for all things data at Zynga. We own the full game and player data pipeline - from ingestion to storage to driving insights and analytics. As a Principal Data Engineer, you will be responsible for the software design and development of quality services and products to support the Analytics needs of our games. In this role, you will be part of our Central Technology group focusing on advanced technology developments for building scalable data infrastructure and end-to-end services which can be leveraged by the various games. We are a 120+ organization servicing 1500 others across 13 global locations.

Your responsibilities will include
Build and own multi PB-scale data platform.
Design, code, and develop new features/fix bugs/enhancements to systems and data pipelines (ETLs) while adhering to the SLA.
Follow engineering best methodologies towards ensuring performance, reliability, scalability, and measurability.
Collaborate with other Software Engineers, ML Engineers, Data Scientists, and other stakeholders, taking on learning and leadership opportunities that will arise every single day.
Mentor junior engineers in the team to level them up.
Raise the bar on sustainable engineering by improving best practices, producing best in class of code, documentation, testing and monitoring.
You will be a perfect fit if you have
Bachelor’s degree in Computer Science, or a related technical discipline (or equivalent).
6+ years of strong data engineering design/development experience in building massively large scale distributed data platforms/products.
Advanced coding expertise in SQL & Python/JVM-based language.
Expert in heterogeneous data storage systems (relational, NoSQL, in-memory etc).
Deep knowledge of data modeling, lineage, access and its governance.
Excellent skills in AWS services like Redshift, Kinesis, Lambda, EMR, EKS/ECS etc.
Wide exposure to open source software, frameworks and broader cutting edge technologies (Airflow, Spark, Druid etc).
Familiar with infrastructure provisioning tools (e.g Terraform, Chef)
Consistent proven ability to deliver work on time with attention to quality.
Excellent written and spoken communication skills and ability to work effectively with others in a team environment.
What we offer you:

Work in a studio that has complete P&L ownership of games
Competitive salary, discretionary annual bonus scheme and Zynga RSUs
Full medical, accident as well as life insurance benefits
Catered breakfast, lunch and evening snacks
Child care facilities for women employees and discounted facilities for male employees
Well stocked pantry
Generous Paid Maternity/Paternity leave
Employee Assistance Programs
Active Employee Resource Groups – Women at Zynga
Frequent employee events
Additional leave options for most employees
Flexible working hours on many teams
Casual dress every single day
Work with cool people and impact millions of daily players!
#LI-HK1",4.0,"Zynga
4.0",Bengaluru,"San Francisco, CA",1001 to 5000 employees,2007,Company - Public,Video Games,Media,₹50 to ₹100 billion (INR),-1
759,Data Engineer: Data Integration,"Introduction
At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

As Data engineer, you will develop and move data from the operational and external environments to the business intelligence environment using Ab Initio software. Skills include designing and developing extract, transform and load (ETL) processes.
Responsibilities:
Coordinate with multiple technical teams to ensure apt integration of functions to identify and define necessary system enhancements to deploy new products and process improvements
Provide expertise in area and advanced knowledge of applications programming and ensure application design adheres to the overall architecture blueprint
Utilize advanced knowledge of system flow and develop standards for coding, testing, debugging, and implementation
Develop comprehensive knowledge of how areas of business, such as architecture and infrastructure, integrate to accomplish business goals
Resolve variety of high impact problems/projects through in-depth evaluation of complex business processes, system processes, and industry standards
Provide in-depth analysis with interpretive thinking to define issues and develop innovative solutions

Required Technical and Professional Expertise
Minimum 4+ years of experience in Abinitio development
Expertise in advanced Abinitio components
Ability to demonstrate micro / macro designing and familiar with Unix Commands and basic work experience in Unix Shell Scripting
Demonstrated ability in solutioning covering data ingestion, data cleansing, ETL, data mart creation and exposing data for consumers
Preferred Technical and Professional Expertise
You love collaborative environments that use agile methodologies to encourage creative design thinking and find innovative ways to develop with cutting edge technologies
Ambitious individual who can work under their own direction towards agreed targets/goals and with creative approach to work
Intuitive individual with an ability to manage change and proven time management
Proven interpersonal skills while contributing to team effort by accomplishing related results as needed
Up-to-date technical knowledge by attending educational workshops, reviewing publications
About Business Unit
IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter business by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world. What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Kolkata,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
760,Data Analyst,"Looking for freshers with some knowledge on data analytics
mainly for marketing
Should have relevant knowledge
Job Types: Part-time, Internship, Fresher
Salary: ₹8,000.00 to ₹14,000.00 /year
Experience:
work: 1 year (Preferred)
total work: 1 year (Preferred)
Education:
Bachelor's (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,"IBM
3.9",Ernakulam,-1,-1,-1,-1,-1,-1,-1,-1
761,Data Analyst,"Looking for a Data Analyst (Freshers only) to Analyze data and communicate results to client, often with the aid of Automation techniques and software.

Responsibilities and Duties:
Develop data mining processes for large data files.
Getting the data collected from various sources.
Assess accuracy of new data sources and data gathering techniques.
Processing, cleansing, and verifying the integrity of data used for analysis.
Skills Required:
Qualification - Any degree
Experience - Freshers only
Excellent Analytical and Statistical skill.
Good English communication skills.
Must be able to learn, understand, and apply new technologies.
Work location: Trivandrum

Job Type: Full-time

Education:
Bachelor's (Preferred)",-1,ACUWIN INNOVATIONS Pvt Ltd.,Thiruvananthapuram,-1,-1,-1,-1,-1,-1,-1,-1
762,Machine Learning Engineer,"OakNorth is the next-generation credit and monitoring platform that provides banks and lending institutions with the insight and foresight needed to create a better borrowing experience for the Missing Middle – the growth business who are the backbones of communities and economies globally but who have been in banking’s blind spot for decades.

The business was founded in 2015 by Rishi Khosla and Joel Perlman, who previously co-founded Copal Amba and grew it to 3,000 employees over 12 years, before selling it to Moody’s (NYSE: MCO) in 2014, returning 125 times capital to seed investors.

Since its inception, OakNorth has secured over $1bn from several investors, including: Clermont Group, Coltrane, EDBI of Singapore, GIC, Indiabulls, NIBC, Toscafund, and SoftBank’s Vision Fund.

The Platform has been deployed at various banks across North America, Europe, and Asia, and in the UK where OakNorth lends off of its own balance sheet via OakNorth Bank. The platform has helped OakNorth Bank become the fastest-growing business in Europe according to the Financial Times FT 1000 (2020), profitably lending over £4bn to date. In terms of the impact this has had on the economy, OakNorth Bank’s loans have directly helped with the creation of 13,000 new homes and 17,000 new jobs in the UK, as well as adding several billion pounds to the economy.

With offices in London, New York, Manchester, Singapore, Hong Kong, Shanghai, Istanbul, Gurgaon and Bangalore, the global team across the OakNorth Holdings group is over 800 people.

SME are crucial in global economy. Although they account for 99% of business in the UK/US, their financing need is increasingly difficult to be met by major banks, due to higher risk of default and heterogeneity of different sectors in SME.
To solve these challenges, OakNorth is building a platform to improve productivity of SME lenders. From credit appraisal, to loan monitoring, the OakNorth Machine Learning team has identified multiple key areas that can be optimised by recent advances in Machine Learning (ML), Natural Language Processing (NLP), Computer Vision (CV), and Information Retrieval (IR).
We are looking for a passionate machine learning and/or software engineer who will be joining the fastest growing and profitable fintech in Bangalore. You enjoy solving challenging tasks, creating and maintaining impactful and data-driven products with innovative techniques.
We expect you to
have experience in ML, CV, NLP, IR, or related fields
have a master (or PhD) degree with 3 years' experience in industry
able to learn new technologies and comprehend academic literatures independently.
We would love to see
Experience with modern deep learning frameworks (e.g. PyTorch, Tensorflow, Jax)
Experience working on distributed software system (e.g. Spark, Hadoop, ElasticSearch)
Publications in related academic venues (e.g. ACL, CVPR, EMNLP, ICML, KDD, NeurIPS)
You will
Convert research findings into production-level software systems and maintain them.
Research and evaluate techniques that can improve/solve a concrete business workflow/problem.
Work with domain experts to shape the future of our platform.
Thank you very much for your interest in OakNorth. We are happy to consider you for roles within our group of companies. If we can identify a match between your skill set and our immediate recruiting needs, please expect to hear from us very soon. If we are unable to identify a fit in the near term, please note that we intend to retain the data you send to us so we may contact you in the future.",4.1,"OakNorth Bank
4.1",Bengaluru,"London, United Kingdom",51 to 200 employees,2015,Company - Private,Lending,Finance,Unknown / Non-Applicable,-1
763,Associate Scientist,"Designation: Research Associate / Senior Research Associate

Job Location: Bengaluru

Department: Analytical Discovery Chemistry

About Syngene

Incorporated in 1993, Syngene International Ltd. is an innovation-focused global discovery, development and manufacturing organization providing integrated scientific services to the pharmaceutical, biotechnology, nutrition, animal health, consumer goods and specialty chemical industries around the world. Syngene’ s clientele includes world leaders such as Bristol-Myers Squibb, Baxter, Amgen, GSK, Merck KGaA and Herbalife. Its innovative culture is driven by the passion of its 4240- strong team of scientists who work with clients from around the world to solve their scientific problems, improve R&D productivity, speed up time to market and lower the cost of innovation .

Job Description

Key Responsibilities:
Performing the analysis (HPLC/LCMS) and its documentation as per the procedure .
Upload analytical data in SAP and update the sample analysis status.
Review and approval of analytical data.
Calibration and documentation as per the schedule
Adherence to Product specifications, all operating procedures and other laboratory practices.
Corrective and preventive actions as and where applicable
Generation and maintenance of Quality Records.
Effective communication with Discovery Chemistry Analytical R&D group leaders and Discovery chemistry team to resolve the issues.
Giving technical inputs and coordinating with the document team personnel for the preparation of documents.
Maintenance of the Auditable documents & product traceability.
Attend training on environment, health, and safety (EHS) measures imparted company
Follow environment, health, and safety (EHS) requirements at all times in the workplace ensuring individual and lab/plant safety

Educational Qualification:
Master’s Degree in a Chemistry

Technical/functional Skills:
Should be familiar with analytical method development using HPLC/LCMS and Preparative purification
Hands on experience with analytical instruments such as HPLC/GC/LCMS
Theoretical knowledge in various analytical techniques and skills in analytical data interpretation

Experience:
0-4 years

Behavioral/Functional Skills:
Able to follow instructions and perform the tasks under the supervision of the project leader
Fair interpersonal skills
Good Team player

Equal Opportunity Employer:
It is the policy of Syngene to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by applicable legislation or local law. In addition, Syngene will provide reasonable accommodations for qualified individuals with disabilities.",3.5,"Syngene
3.5",India,"BENGALURU, India",1001 to 5000 employees,1994,Unknown,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
764,Big Data Engineer,"CAREERS

Big Data Engineer

Bengaluru, India
JOB DESCRIPTION

Develops data architectures and pipelines by;
Understanding requirements;
Understanding deadlines;
Understanding systems flow, data usage, and work processes;
Working in tandem with the Analytics team and providing inputs as and when required
Investigating problem areas;
Follow Agile and Scrum practices;
Be thought partner to the onsite counterpart in creating the data charter for the client
Should be able to lead client calls and answer design specific queries
Documents and demonstrates solutions by developing documentation in the forms of flowcharts, layouts, diagrams, charts, code comments and clear code;
Provides information by collecting, analyzing, and summarizing development and service issues;
Accomplishes engineering and organization mission by completing related results as needed and on time with high quality;
THE IDEAL CANDIDATE WILL

Thorough understanding of the entire Hadoop Ecosystem
Should have created convoluted data-pipelines
Should have expertise with more than one of the following Hive, Map Reduce, Pig, Oozy, Spark
Should have worked with clusters from different distributors namely MapR, CloudEra, Hortonworks
Should have worked extensively on data modeling and data lake creation
Should be able to estimate, design pipelines based on High data volumes and create base data assets for analytical work to commence
Proficient with Ubuntu/Linux and shell scripting
Should be aware of one Scripting language namely Python/Scala/Java
Expert in performance tuning Hive queries based on storage formats and partitioning
Strong fundamentals in SQL
Experience with Streaming data sources and NoSql databases is a plus
ELIGIBILITY CRITERIA

2 to 6 years of relevant experience
Bachelor’s and/or Master’s degree in computer science or equivalent experience
Strong communication, analytical and problem-solving skills with a high attention to detail
Send your CV to careers@tredence.com",3.5,"Tredence
3.5",Bengaluru,"San Jose, CA",501 to 1000 employees,2013,Company - Private,Consulting,Business Services,₹1 to ₹5 billion (INR),-1
765,Data Analytics - Consultant,"Designation : Data Analytics - Consultant
Location : Chennai
Experience : 1+ Yrs
Job Code : IT 1000
No Of Positions : 5
Job Description Experience in data analysis
Proficiency in SAS, SQL, Excel/VBA, Statistical modeling (Logistic / Linear regression, GLM modeling, Time-series forecasting, Scorecard development, Clustering, Segmentation",4.2,"Infiniti Software Solutions
4.2",Chennai,"Chennai, India",201 to 500 employees,2005,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹5 to ₹10 billion (INR),-1
766,Data Analyst,"About OnlineTyari:
OnlineTyari (OT) is India's largest multi-lingual platform for test preparation founded by IIT and IIM alumni. We are backed by marquee investors like Michael & Susan Dell Foundation, Contrarian Fund, Mohandas Pai, Tracxn Labs, 500Startups, etc.

OnlineTyari is first of its kind online marketplace for exam preparation for SSC, IAS, IBPS and many other competitive exams. We have become the preferred destination for both content providers and students.

Within one year of inception, we are already the biggest education app in India by a huge margin. With 5 million+ app downloads and 4 lakh+ people using our platform every single day, our app usage is increasing exponentially month on month. More than 1 billion questions have been attempted by students on the OT platform. OnlineTyari is poised for a massive growth as mobile internet revolution is providing a gateway to millions of Indians to fulfill their aspirations.

With a strong management team of IIT and IIM alumni and backing of marquee investors, we are scaling new heights every day and disrupting the traditional education sector with smart technologies.

To know more about us, please visit:
website: www.onlinetyari.com and android app: https://goo.gl/G3AuwD

Office Location –Gurgaon- https://goo.gl/maps/ 6fNjp5Dd3ro

Position Summary

OnlineTyari is a faced paced startup disrupting the education sector rapidly and helping millions of Indians build a better career! We are looking for a passionate Product Designer who will take ownership of the complete Design cycle and create an amazing user interface on our app and website! You will play a critical role in providing a great and seamless user experience to our users. You would also work closely with the founders in building a distinct and attractive OnlineTyari brand connecting with millions of our users!

Responsibilities:
Lead all aspects of design cycle to translate the Company’s product vision into seamless user interface and intuitive user experience
Create comprehensive style guide and unify the design language across all products and marketing channels to create a seamless and distinct Brand experience.
Map the user flow and product journey and understand the impact of each touch point
Collaborate with the product and engineering team to deliver highly creative designs, wireframes, user stories, user journeys, and mock ups
Create beautiful and attractive User Interface, graphic designs, icons, etc. as per Company’s brand and design guidelines
Regularly meet and interact with users to understand their personas and requirements
Improve conversions through design tweaks and create new features based on user feedback and usability analytics

Requirements:
Atleast 4 years of UI/UX design experience for high traffic web and app products
A great design portfolio that demonstrates creative design thinking and a deep understanding of latest UI/UX trends and practices
Extensive experience developing software interfaces using Adobe Suite tools (e.g.,
Photoshop, Illustrator) HTML5, CSS3, and JavaScript skills are a plus
Strong visual design skills with proven ability to create beautiful responsive designs
Solid experience in UX research and usability testing
Willing to take ownership and result oriented
Quick learner and ability to solve problem using data driven approach

What we offer:
Be part of the fastest growing edtech company
Your contributions will have a potential to create an immediate positive impact on 6 million+ Indians!
Get full freedom to dream big and chase your passion
Flexible, fun and modern work culture with a highly motivated and energetic team
Work with top talent",3.4,"Onlinetyari
3.4",Gurgaon,"Gurgaon, India",1 to 50 employees,2014,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
767,Machine Learning Engineer,"OakNorth is the next-generation credit and monitoring platform that provides banks and lending institutions with the insight and foresight needed to create a better borrowing experience for the Missing Middle – the growth business who are the backbones of communities and economies globally but who have been in banking’s blind spot for decades.
The business was founded in 2015 by Rishi Khosla and Joel Perlman, who previously co-founded Copal Amba and grew it to 3,000 employees over 12 years, before selling it to Moody’s (NYSE: MCO) in 2014, returning 125 times capital to seed investors.
Since its inception, OakNorth has secured over $1bn from several investors, including: Clermont Group, Coltrane, EDBI of Singapore, GIC, Indiabulls, NIBC, Toscafund, and SoftBank’s Vision Fund.
The Platform has been deployed at various banks across North America, Europe, and Asia, and in the UK where OakNorth lends off of its own balance sheet via OakNorth Bank. The platform has helped OakNorth Bank become the fastest-growing business in Europe according to the Financial Times FT 1000 (2020), profitably lending over £4bn to date. In terms of the impact this has had on the economy, OakNorth Bank’s loans have directly helped with the creation of 13,000 new homes and 17,000 new jobs in the UK, as well as adding several billion pounds to the economy.
With offices in London, New York, Manchester, Singapore, Hong Kong, Shanghai, Istanbul, Gurgaon and Bangalore, the global team across the OakNorth Holdings group is over 800 people.

SME are crucial in global economy. Although they account for 99% of business in the UK/US, their financing need is increasingly difficult to be met by major banks, due to higher risk of default and heterogeneity of different sectors in SME.
To solve these challenges, OakNorth is building a platform to improve productivity of SME lenders. From credit appraisal, to loan monitoring, the OakNorth Machine Learning team has identified multiple key areas that can be optimised by recent advances in Machine Learning (ML), Natural Language Processing (NLP), Computer Vision (CV), and Information Retrieval (IR).
We are looking for a passionate machine learning and/or software engineer who will be joining the fastest growing and profitable fintech in Bangalore. You enjoy solving challenging tasks, creating and maintaining impactful and data-driven products with innovative techniques.
We expect you to
1. have experience in ML, CV, NLP, IR, or related fields
2. have a master (or PhD) degree with 3 years' experience in industry
3. able to learn new technologies and comprehend academic literatures independently.
We would love to see
1. Experience with modern deep learning frameworks (e.g. PyTorch, Tensorflow, Jax)
2. Experience working on distributed software system (e.g. Spark, Hadoop, ElasticSearch)
3. Publications in related academic venues (e.g. ACL, CVPR, EMNLP, ICML, KDD, NeurIPS)
You will
1. Convert research findings into production-level software systems and maintain them.
2. Research and evaluate techniques that can improve/solve a concrete business workflow/problem.
3. Work with domain experts to shape the future of our platform.
Thank you very much for your interest in OakNorth. We are happy to consider you for roles within our group of companies. If we can identify a match between your skill set and our immediate recruiting needs, please expect to hear from us very soon. If we are unable to identify a fit in the near term, please note that we intend to retain the data you send to us so we may contact you in the future.

For more information regarding our Privacy Policy and practices, please visit: https://www.oaknorth.com/privacy-notice/employees/",4.0,"OakNorth
4.0",Bengaluru,"London, United Kingdom",51 to 200 employees,2015,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
768,DATA SCIENCE EXPERT,"Skills Required:
Relevant Experience: 5 Years

Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive
Bayes, SVM, Decision Forests, etc
Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc.(depending
on specific project requirements). Excellence in at least one of these is highly desirable
Great communication skills
Experience with data visualisation tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive, Pig (actual list depends on what you
are currently using in your company)
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase (depending on project needs)",-1,Tech Pathway,Jaipur,-1,-1,-1,-1,-1,-1,-1,-1
769,Associate Director Data Scientist- Advanced Analytics,"Position Title
Associate Director Data Scientist- Advanced Analytics

29-May-2020

Job ID
289004BR

Job Description
Your responsibilities include, but are not limited to:
•Innovate in one or multiple business verticals by redefining the way to solve a problem using Data Science and Artificial Intelligence: design, develop and deliver various data science based insights, outcomes and innovation (using mathematics, computer science, statistics, engineering, management science, technology, economics, etc.) and build“proof of concepts & blueprints” to drive faster, timely, highly detailed, workable and pro-active decision making based on data based insights and science and shape strategic glide path of the company
•Collaborates with globally dispersed internal customers, external partners and Institutions and multi-functional teams to seek critical business problems, drive operational efficiencies and innovative ways, and deliver optimally on high visibility pivotal initiatives
•Project runs critical initiatives: plans proactively, anticipates and actively leads change, sets partner expectations as required, identifies operational risks and independently drives issues to resolution, balances multiple priorities and minimizes surprise critical issues
•Provides training, mentorship or directions for colleagues without having formal reporting line.
•Independently identifies research articles and reproduce/apply methodology to Novartis business problems
•Provides agile consulting, mentorship and non-standard exploratory analysis for unplanned urgent problem.

Minimum requirements
• Bachelors or Masters in Life Sciences, Mathematics, Statistics, Medical Informatics, or Computer Science, B-Tech / M- Tech, BCA / MCA, Operation Research or related disciplines.
• Fluent English (oral and written) 8-12 years of relevant experience in Data Science and Analytics.
• Experience with visualization software / tools to create Dynamic Dashboards using Tableau/Qlik Sense/ Power BI/ R Shiny(3+ Years)

Why consider Novartis?

750 million. That’s how many lives our products touch. And while we’re proud of that fact, in this world of digital and technological transformation, we must also ask ourselves this: how can we continue to improve and extend even more people’s lives?

We believe the answers are found when curious, courageous and collaborative people like you are brought together in an inspiring environment. Where you’re given opportunities to explore the power of digital and data. Where you’re empowered to risk failure by taking smart risks, and where you’re surrounded by people who share your determination to tackle the world’s toughest medical challenges.

We are Novartis. Join us and help us reimagine medicine.

Novartis are an equal opportunities employer and welcome applications from all suitably qualified persons.

Job Type
Full Time

Country
India

Work Location
Hyderabad, AP

Functional Area
Research & Development

Division
Global Drug Development

Business Unit
GDO GDD

Employment Type
Regular

Company/Legal Entity
Nov Hltcr Shared Services Ind

Shift Work
No",3.9,"Novartis
3.9",Hyderabad,"Basel, Switzerland",10000+ employees,1996,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
770,Data Analyst,"Responsibilites :
Backgrounds in technology, information management, relational database design and development, business intelligence, data mining or statistics.
Solid understand of data analysis techniques or processes will help reduce the need for you to learn every data analysis tool in the market
Experinece in importing, cleaning, transforming, validating or modeling data with the purpose of understanding or making conclusions from the data for decision making purposes.
Experinece in Performing audit on data and resolve business related issues for customer base
Experinece in Performing data analysis and facilitate in delivery to all end users.
Explorering sift through mountains of data to discover the data you actually need

Send us the Resume at info@zettamine.com",3.9,"ZettaMine
3.9",Hyderabad,"Hyderabad, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
771,Data Science Internship,"Data Science Internship (Python/Machine Learning/NLP):

Roles and responsibilities:

- Working on Python, Django/ Machine Learning/ NLP technologies.

- Working on the day to day tasks assigned by the company.

- Working on the project

Eligibility: Any BE/BTech/BCA from 2020/21/22 batches can apply.

Duration: 1 - 6 months

Mode of internship: Online/Virtual.

Perks - Internship Experience Certificate

Contact number: 9148984674

Company Location: Bangalore

Job Types: Part-time, Internship

Work Remotely:
Yes",-1,TechCiti Software Consulting Pvt Ltd,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
772,Customer Data Analyst,"Job Responsibilities
Preparation of the Database
Simulation and analysis
Fault logics preparation and maintaining the data
Software testing’s of the products application software
Database configuration for the existing/new products
Eligibility
Male BSc Computer Science / Diploma (CSE/ IT / ECE) / B.TECH (CSE/ IT / ECE)
Year of Passing : 2016, 2017,2018
Ready to sign 2.5 years service agreement with the company
Freshers are preferred",3.0,"Efftronics Systems
3.0",Vijayawada,"Vijayawada, India",501 to 1000 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
773,Product Manager - Data,"With its quest to bring people out of their homes to experience entertainment, bookmyshow has been increasing its portfolio of offerings to users across India and International markets and giving them more reasons to come out of their home by venturing into Live entertainment (concerts, plays, sports and activities) along with movies.

Bookmyshow Live entertainment vertical is growing exponentially and we are looking for passionate and data driven product manager to lead the consumer side of Live entertainment business

You will have a key role in defining the product development roadmap, defining priorities and identifying opportunities in the market. Data, Customer empathy, building at scale are key facets of a Product Manager. PMs are product owners at Bookmyshow, but will also deliver at an individual level

Your Profile

Define and communicate your product’s vision, execution, goals and own the results.
Formulate and communicate your product’s vision, strategy and roadmap and own the results by aligning with stakeholders
Work with Marketing and Sales/business to ensure that the product proposition is clear to the end customer
Demonstrate a good level of understanding of the full technology stack and understand how your product interacts with all areas of the business
Work with cross functional teams spanning across product, data scientists, data engineers, engineering and Product design
Identify customers behaviours and needs through research and analysis.
Empower and collaborate with your team to unlock their full potential.
Strategically evolve and grow existing products and services to constantly deliver a better user experience.
Gather product requirements, and document them accordingly for projects in development.
Manage collaboration and communication with other teams, both internal and external, to ensure teams have what they need and can work efficiently.

Your Checklist

User focused individual who keeps the customer at the heart of everything we do, while having strong commercial awareness.
Data driven. Base your decisions on facts rather than opinions
A good understanding of systems experience with designing user interfaces via wireframe mockups
3+ years of product management experience ideally for consumer web products or Ecommerce
Ability to work with large quantities of data and business skills to leverage analytics for decision making
Excellent verbal, written communication and interpersonal skills. Work closely with engineering and business to drive product roadmap
You thrive in prioritisation under uncertainty and have the ability to win consensus for your ideas amongst your stakeholders
Experience of managing successful delivery in an Agile software environment to deliver customer-led outcomes
Ability to lead a team of product Managers
Product design experience is a definite plus",3.6,"BookMyShow
3.6",Bengaluru,"Mumbai, India",1001 to 5000 employees,2007,Company - Private,Ticket Sales,"Arts, Entertainment & Recreation",Unknown / Non-Applicable,-1
774,Data Analyst,"Career Opportunity -

This opportunity is from one of my client in Banking Domain

Location : Chennai

Exp - 3 +years

Data Analyst

Required Skills

Solution Architecture experience in the areas of Data Analytics, Integration and reporting (Specifically implementations using Open Source Tools (Python) / Big Data Distribution,
Strong experiencewith python programming language, (pandas, dask, numpy, PySpark…),
Strong experience on big data manipulation (Spark, Elastic Search…),
Solid experience in the areas of RDBMS (Oracle, SQL Server) in terms of database design, optimization, performance management etc.,
Experience in no-sqldatabases: MongoDB, Cassandra, neo4j…
Design / Architecture Experience in Building Products, Frameworks and Components,
Ability to understand Hardware / Software Architecture and solution skills in line with the infrastructure,
Good understanding of Computer Science: algorithms, complexity, etc.
Wider IT culture & interest: OS, parallelization, network, machine learning, databases

Job Responsibilities

Definition of technical strategy within the SSC and also for the CIB Data Hub
Define and deliver a roadmap to evolve the architecture of the SSC and CIB Data Hub
Define Standards, Guidelines, Best Practices and Frameworks / Assets
Work across multiple projects being delivered by the SSC to ensure target architecture standards are maintained
Work with IT teams outside the SSC to provide architectural guidance and best practice
Reporting and presenting to architecture committees as required
Track and report on delivery of shared functionality
Stakeholder management
Encourage continuous improvement, innovation and creativity
Facilitate problem solving & collaboration
Ability to discover / analyze problems, and present solutions in a clear and concise manner
Contribute to the implementation of improvements to the data processing systems
Proof of concept data projects",3.6,"Antal International
3.6",Chennai,"London, United Kingdom",1001 to 5000 employees,1993,Franchise,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
775,Consultant – Data Analyst with Python,"Consultant – Data Analyst with Python
Function: Operations

Noida, India

With
a startup spirit and 90,000 curious and courageous minds, we have the
expertise to go deep with the world’s biggest brands—and we have fun doing it.
Now, we’re calling all you rule-breakers and risk-takers who see the world
differently, and are bold enough to reinvent it. Come, transform with us.

Are
you the one whom we are seeking ?

Inviting
applications for the role of Consultant – Data Analyst with Python

In
this role, the focus is to ensure smooth delivery, client engagement and
spearhead business growth of a large account in U.S. It is imperative for this
hire to have deep Banking & Capital Markets experience, in-depth
understanding of technology and domain skills in Auto Finance, Equipment
Finance and Lending.

Responsibilities
Assisting users with Python setup and
configuration, getting access to data sources within the organization, and
responding to their questions
Performing analysis projects on behalf
of the users
Understand data requirements of the
requestor
Interact with the requestor to handle
any changes and updates to the request.
Do required analysis of the data set
as required.
Work with the team on data projects to
provide timely solutions.
Create and Visualize reports/analysis
and share it with the stakeholders.
Qualifications


Minimum
qualifications we seek in you!
BE/B.Tech/equivalent
Preferred
qualifications
Good Python development skill is a
must.
Working knowledge of R is an added
advantage.
Working knowledge of Tableau &
Spotfire is an added advantage.
Good communication skills & highly
proactive in approach.
Ability to manage & prioritize
deliverables.
Ability to be learn and apply new
processes and tools
Process orientated awareness of Lean
Six Sigma.
Genpact
is an Equal Opportunity Employer and considers applicants for all positions
without regard to race, color, religion or belief, sex, age, national origin,
citizenship status, marital status, military/veteran status, genetic
information, sexual orientation, gender identity, physical or mental disability
or any other characteristic protected by applicable laws. Genpact is committed to
creating a dynamic work environment that values diversity and inclusion,
respect and integrity, customer focus, and innovation. For more information,
visit www.genpact.com. Follow us on Twitter, Facebook, LinkedIn, and YouTube.",3.6,"Genpact
3.6",Noida,"New York, NY",10000+ employees,1997,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"Accenture, IBM, Capgemini"
776,Data Engineer,"Job Description

If you love the challenges that come with big data then this role is for you. We are looking for Data Engineers who can handle of events a day, manage petabyte scale data on Redshift and S3, and develop data pipelines using Spark/Scala EMR, SQL based ETL, and Java services.

This role requires you to live at the cross section of data and engineering. You have a deep understanding of data, analytical techniques, and how to connect insights to the business, and you have practical experience in insisting on highest standards on operations in ETL and big data pipelines..

We deal in AWS technologies like Redshift, S3, EMR, EC2, DynamoDB, Kinesis Firehose, and Lambda. You'll build our data portfolio and partner with Product, Marketing, BI, and ML teams to build new behavioural events, pipelines, datasets, models, and reporting to support their initiatives. You'll also continue to develop our offline analytics capabilities in Tableau and build out our real time dashboarding capabilities.

Come innovate with the Coda Data & Analytics Team!

Basic Qualifications

Bachelor’s degree in computer science, mathematics, statistics or a similar quantitative field
Experience with Redshift or another columnar store DW
Experience with cloud solutions / AWS / Azure / Google cloud
Experience building reports and/or data visualization
Experience with Hadoop/MapReduce/AWS/EMR
Experience with Spark/Scala/PySpark/ Apache Kafka / Kinesis Streams / AWS Glue
Experience building or administering reporting/analytics platforms
Experience building flexible data APIs that consumers use to power other parts of the business Preferred Qualifications
3 to 5 years of experience as a data/software developer/scientist or related technical job
Experience working with predictive analytics/decision models/data mining libraries as well as the tools for developing it
Experience in algorithm design and problem solving
Experience leading small teams of engineers
Experience with Agile Development
Experience with Machine Learning (Classification, Collaborative Filtering)
Love for Data",4.4,"Coda Global
4.4",Tamil Nadu,"Southlake, TX",51 to 200 employees,-1,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
777,Business Analysis/Data Science,"Representative responsibilities

Studying and assessing the current data models in our product portfolio and refining them as needed.
Keeping track of the current state of data models, DB structures, data dictionaries business/user requests, prioritization of needs for new data entities, rationalize needs against available entities.
Working with the core Development/Engineering team on efficient data models
Researchinge and architecting database solutions, platforms and engines
Establishing and maintaining a proper pipeline of data – requirements, cleansing, normalization, model build, integrations, periodic updates of master data
Ensuring transaction data needs and solutions
Defining and implementing infrastructure requirements for data storage, retrieval, backup and recovery
Supporting ensuring good data related practices
Assisting Delivery Management in the defining and executing of data models and solutions
Build out of analytics solutions

Requirements & Desired Qualifications

Hands on familiarity and experience with the various responsibilities stated above
Hands on experience with various database engines and platforms some of which may be embedded in our products in OEM and other similar arrangements
Strong experience with building Excel models
Hands on the experience with multiple analytics engines such as MS PowerBI, Thoughtspot, Tableau
Ability to work with multiple development leads and teams, sales and marketing, executives and customers
Exposure to and understanding of emerging disciplines of AI and machine learning, libraries etc.
Technical – engineering / CS academic qualifications preferred
5-6 years of experience

Please send resume to info@nathanresearch.com",-1,Nathan Research,Chennai,"Dallas, TX",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
778,Data Life Cycle Product Manager,"Position Title
Data Life Cycle Product Manager

10-Jun-2020

Job ID
293037BR

Job Description
20 years and 2 million-years of patient data waiting for you to unlock the next breakthrough in medicine.
This role will help drive the development and execution of Novartis’ ambition to turn data into real strategic asset to drive actionable insights across the organization.
This ambition is one of key pillars in the broader digital transformation happening at Novartis to be a ‘medicines and data science company.

Your responsibilities include, but are not limited to:

•Contribute in shaping the enterprise wide data strategy to enable clean and linked data across the Pharma value chain (including Research, Development, Manufacturing, Procurement & Supply Chain, Commercial and Medical Affairs). This will drive valuable insights from data and digital at scale without the need for Data Scientists to spend significant time and effort in accessing and curating data in execution of individual use cases.
•Drive execution of enterprise wide data strategy by applying the standardized DLC Management approach aligned to FAIR data principles while leading global 2-Pizza AGILE teams in execution of specific business use cases
•Define and shape specific data/ analytics use cases by working closely with stakeholders in business units. Build trusted partnership with the stakeholders and champion the value of clean and linked data
•Be overall responsible for execution of the defined use cases to ensure value realization while ensuring adherence with enterprise wide data strategy. Ensure the vertical MVP uses cases align and leverage the standardized horizontal DLC Assets to deliver value leveraging JIRA template and governance in an agile way.
•Provide servant leadership to AGILE teams at the global level by playing the role of Scrum Master. Facilitate, moderate and iterate meetings with stakeholders and team. Ensure quality Team Dynamics through coaching team members, mediating through conflicts and helping team make decisions. Fostering high quality outputs from each member. Drive continuous learning regarding everything AGILE. Build a focused Product mindset, ease product backlog items and be familiar with product vision.

Minimum requirements
•BS/MS/PhD Excellent English required (oral & written).
•Minimum 10 years of experience working in global companies with at least 5 years of experience in leading global projects in Data Life Cycle Management using AGILE methodology.
•Deep expertise in Data Life Cycle Management and data wrangling including Data Ingestion, Unification, Anonymization, Search, Master & Meta Da-ta Management and Data Governance.
•Experience in FAIR data principles, creating Uniform Resource Identifiers (URIs), building Ontologies and working with Semantic Web technologies (RDF, SPARQL, OWL).
•At least 5 years of hands on experience working on data management and analytics tools. Hand on experience in working with Python and other scripting tools is preferred. Experience in working with cloud technologies such as AWS and Microsoft Azure is preferred.
•Domain expertise in at least one of the following areas – a) Pharma R&D, b) Manufacturing, Procurement and Supply Chain and c) Marketing and Sales.

Why consider Novartis?
799 million. That’s how many lives our products touched in 2019. And while we’re proud of that fact, in this world of digital and technological transformation, we must also ask ourselves this: how can we continue to improve and extend even more people’s lives?

We believe the answers are found when curious, courageous and collaborative people like you are brought together in an inspiring environment. Where you’re given opportunities to explore the power of digital and data. Where you’re empowered to risk failure by taking smart risks, and where you’re surrounded by people who share your determination to tackle the world’s toughest medical challenges.

Imagine what you could do at Novartis!

Commitment to Diversity & Inclusion:
Novartis embraces diversity, equal opportunity and inclusion. We are committed to building diverse teams, representative of the patients and communities we serve, and we strive to create an inclusive workplace that cultivates bold innovation through collaboration, and empowers our people to unleash their full potential.

Join our Novartis Network: If this role is not suitable to your experience or career goals but you wish to stay connected to learn more about Novartis and our career opportunities, join the Novartis Network here: https://talentnetwork.novartis.com/network

Job Type
Full Time

Country
India

Work Location
Hyderabad, AP

Functional Area
BD&L & Strategic Planning

Division
CORPORATE

Business Unit
DIGITAL OFFICE

Employment Type
Regular

Company/Legal Entity
Nov Hltcr Shared Services Ind

Shift Work
No",3.9,"Novartis
3.9",Hyderabad,"Basel, Switzerland",10000+ employees,1996,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
779,Data Engineer,"Analog Devices (NASDAQ: ADI) designs and manufactures semiconductor products and solutions. We enable our customers to interpret the world around us by intelligently bridging the physical and digital worlds with unmatched technologies that sense, measure and connect.

Data Engineer, Analytics & Customer Insights

The Analytics & Customer Insights team at Analog Devices (ADI) is looking for an experienced data engineer with hands on skills and knowledge of data architecture to lead on the design and implementation of our new data infrastructure to meet our business needs. You will oversee the data infrastructure and data integration of ADI’s digital intelligence and design the data models to enable our analytics programs and achieve profitable revenue growth. You will also set the process and standards of data collection, storage, usage, and ETL in collaboration with IT, analysts, and program managers.

Responsibilities
Understand business requirements. Design, manage and optimize data models in supporting various business programs
Identify and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Develop proper control of the data to allow for versioning management, tracking against actuals and gap analysis
Integrate data from multiple disparate systems using APIs, Webhooks, JSON, REST, SOAP, SFTP, etc.
Collaborate with infrastructure team to design, build, test and maintain data integration, ETL processes and data management delivery within a global data lake and data warehouse environment such as MS Azure or AWS
Develop processes and tools to perform data analysis, monitor and remediate data quality issues with closed feedback loop
Work closely with data architect and program manager to create data map and data dictionary to help users to leverage and interpret the data and provide trainings on database, ETL processes, and standards to different audiences and user groups.
Work with different functional team to assist with data-related technical issues and support their data infrastructure needs.
Qualifications
Bachelor or Master’s degree in Physics, Math, Computer Science, Statistics, or related field, plus 1 + years of related work experience
1 + years of experience designing, coding, testing and debugging multiple ETL integration interfaces of varying size and complexity.
Strong experience with programming language, such as SAS, Python and/or R
Experience integrating third party APIs & Web services and solid programming background.
General Data Science knowledge (basic AI + Machine learning concepts)
Strong understanding and experience with Cloud Storage infrastructure, and operationalizing storage services & solutions (Designing and implementing data solution in AWS, Azure or Google Cloud will be plus)
Familiar with No SQL databases (i.e. MongoDB, Hadoop, Hive Spark, etc.), data streaming and integrating unstructured data will be plus.
Experience implementing Big Data solution using Apache Hadoop, Cloudera, and MapR distributions will be plus
Experienced in Hadoop Ecosystem e.g. Data lifecycle, governance, tools, various type of data access e.g. Batch, Script, SQL, stream, in-mem etc, security and operations. (MapReduce, HBase, Hive, Impala, Oozie, Zookeeper will be plus)
Strong technical communication skills and ability to engage a variety of business and technical audiences explaining features, metrics of Big Data technologies
Must be eager to learn new tools and technologies
#LI-NS1

For positions requiring access to technical data, Analog Devices, Inc. may have to obtain export licensing approval from the U.S. Department of Commerce - Bureau of Industry and Security and/or the U.S. Department of State - Directorate of Defense Trade Controls. As such, applicants for this position – except US Citizens, US Permanent Residents, and protected individuals as defined by 8 U.S.C. 1324b(a)(3) – may have to go through an export licensing review process.

Analog Devices, Inc. is an Equal Opportunity Employer Minorities/Females/Vet/Disability

EEO is the Law: Notice of Applicant Rights Under the Law

Education Level: Bachelor's Degree
Travel Required: No",3.9,"Analog Devices
3.9",Karnataka,"Norwood, MA",10000+ employees,1965,Company - Public,Electrical & Electronic Manufacturing,Manufacturing,₹500+ billion (INR),"Texas Instruments, Qualcomm"
780,Data Analyst,"Position title
Data Analyst
Description
Proficiency in using query languages such as SQL, Big Query, Excel, Advanced Excel and Snowflake
Extensive use of SQL and RDBMS systems
Crunch a large volume of data and observe trends using BI tools
Good Knowledge of BI tools such as tableau, looker, Qlikview
Good communication skills is a plus
Required Skills
Business analysis to gather required BI system requirements
Translate business requirements into specifications that will be used to drive data store/ data warehouse/ data mart design and configuration
Crafting and executing queries upon request for data
Presenting information through reports and visualization
Extending company’s data with third party sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Job Responsibilities
Bachelors/ Masters in Computer Science or Electronics from tier 1 & 2 colleges
Contacts

careers@algoscale.com",3.7,"Algoscale
3.7",Noida,"Noida, India",1 to 50 employees,2014,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
781,Machine Learning Engineer,"Position: Machine Learning Engineer

Location: Noida & Remote

Experience Required: 3 to 6 years

Skillsets:

Our team is seeking experienced engineers who can help us design and build both infrastructure and algorithms in the areas of machine learning and computer vision.

Responsibilities:

Drive the end-to-end problem solving for a people tracking ML product. Design novel and breakthrough ML technology to fully solve ambiguous problems for real-world environment. Work with data acquisition, ML infrastructure, computer vision and data serving team to propose solutions for new problems. Work closely with development and QA teams in transitioning prototypes to commercial products.

Minimum Qualifications:

B.E/M.E/PhD in Computer Science, or equivalent field.

3-6 years core experience in ML research & infrastructure.

Must have skills:
Computer Vision - Experience with object detection, tracking, classification, recognition (Face, Iris, Finger, Gesture,), scene understanding, facial expression analysis.
Delivered at-least two products in the customer environment.
Thorough understanding of full ML pipeline, starting from data collection to model building to experimental framework to data analytics.
Deep understanding of at-least two popular frameworks (Tensorflow, Keras, MxNet, Caffe. CNTK, Theano / Pytorch), their strength and applicable AI use-cases.
Experience implementing ML algorithms - Regression, Naive Bayes, Bayesian Network, Decision Tree, Neural Network, SVM, Boosting, K-Means, Ensembler Classifiers, Random Forest, convex optimization, transfer learning.
Experience in frameworks such as Spark, Lucene to implement real-time ML systems
Strong mathematical understanding.
Should have deep expertise in Computer Vision at at-least one vision framework such as OpenCV/PyTorch.
Image Processing - hands-on expertise
Programming in Python, C / C++ Usage of Mat lab, Open CV tool kits.
Experience on real-time implementation of complex algorithms.
Able to execute quickly with ever-changing problem set and environment.
Ability to work in small team / rapid prototyping environment.
Good to Have:
Knowledge and experience in building image/video data-sets to evaluate the solution.
Experience with Multi-Threading and C++/Python/Java/Boost/R/SQL desirable.
Advanced degree in Machine Learning, Computer Vision, Applied Mathematics, and Statistics or related fields.
Expected Start Date: 8/6/2020

Job Types: Full-time, Contract

Salary: ₹75,000.00 to ₹200,000.00 /month

Experience:
total work: 3 years (Required)
Education:
Bachelor's (Preferred)
Work Remotely:
Yes",4.5,"Infiniticube Services Pvt Ltd
4.5",Noida,"Noida, India",1 to 50 employees,2017,Company - Private,IT Services,Information Technology,₹10 to ₹50 million (INR),-1
782,Data Analyst - Looker,"Role:- Data Analyst (Looker)

You will play a crucial role in implementing, improving, and maintaining Looker reports. This includes partnering and consulting with business and analytics teams to provide guidance and assistance in creating and streamlining Looker reports.

Responsibility:-
Interacting with clients, to understand their needs and come up with an end-to-end solution
Translate business requirements to actionable data tasks (English <-> SQL)
Use Looker to create a metadata repository (LookML), Views, and dashboards.
Become a subject matter expert on Looker, both as a development platform and visualization tool
Be responsible for maintaining security and data access models within Looker
Monitor and optimise the performance of our Looker instance
Implement best practices for LookML coding and data model design
Control and monitor data access
Qualification :-

B.Tech any stream (preferably CS, IT, Electronics)

Requirements:
Strong technical knowledge in SQL and
Data analysis skills
Expertise in visualization technologies including Tableau, Looker and/or another BI tool
Strong business intuition and ability to understand complex business systems
Optional Requirement
Experience on spectacle (https://spectacles.dev/)
Minimum Experience - 0-1 year

CTC - 4-6LPA",4.2,"VinSol
4.2",New Delhi,"New Delhi, India",51 to 200 employees,2000,Private Practice / Firm,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
783,Data Engineer,"Looking for Data Engineer

4+ years of experience in working with large and varieties of data.

Strong experience in Relational /NoSQL/Graph Data bases.

Experience with big data tools: Hadoop, HDFS, Spark, Hive, Sqoop, Kafka, Yarn, Zookeeper etc.

Experience in Scala, Python, pySpark, Java, Rest API, Microservices etc.

Experience in data engineering, data pipelines in any of Cloudera, Azure, AWS, and Google Cloud platforms.

Experience in Structured and Unstructured Data sets.

Experience in Ticketing tools like Zendesk, Service Now, JIRA.

Masters/bachelor’s degree/diploma in computer science or equivalent.

Required Candidate profile

Experience: 4-9 Years
Skill sets: NoSQL, Big Data, Scala, Python, pySpark, Java, Rest API, Microservices.
Location: Hyderabad
Notice: Immediate - 15 Days

Salary: Not Disclosed by Recruiter

Industry:Internet / Ecommerce

Functional Area:IT Software - Application Programming, Maintenance

Role Category:Programming & Design

Role:Software Developer

Keyskills
JavaNoSQLScalaBig DataAPIpySparkMicroservicesPython
Desired Candidate Profile
Please refer to the Job description above
Company Profile

Harjai Computers Pvt Ltd

Harjai Computers Pvt. Ltd. is the preferred partner of top IT and Multinational companies all over INDIA and around the world for providing the best talent via Staff Augmentation (Temp Staffing / Subcontracting). Over the years, we've assisted our numerous clients scale new heights by deploying top professionals.
View Contact Details+

Recruiter Name:Sachin Chauhan

Contact Company:Harjai Computers Pvt Ltd

Telephone:8879700585

Reference Id:NGS_Data Engineer",4.4,"Harjai Computers
4.4",Hyderabad,"Mumbai, India",201 to 500 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
784,"Application Developer/Data Engineer, Supply Chain Systems","Posted: Oct 25, 2019
Role Number:
200117123
At Apple, great ideas have a way of becoming great products, services, and customer experiences very quickly. A job at Apple is unlike any you’ve ever had. You will be inspired and you will be challenged. Bring passion and dedication to your job, and there is no telling what you could accomplish!

We seek an Application engineer to be part of the team that builds top-notch business applications for World’s leader in Supply Chain, Apple Inc.

As a part of IS&T SCI team, you will play a pivot role in building end-to-end , best-in-class software solutions for Apple Supply Chain needs varying from Supply Planning, Demand Planning, Product distribution and so on. You will partner with various internal customers to define and implement solutions that optimize our internal business processes.
Key Qualifications
8+ years of relevant experience in enterprise level application development using advanced Oracle database technologies.
5+ years of programming experience Python Data Analytics platforms, Pandas Data frames, sqlalchemy, numpy etc
Hands on Experience with large volume databases for both OLTP and OLAP environment.
In depth Python programming experience in building high scale enterprise level Application, specialized in queues/multiprocessing/multithreading
Experience in Application database design/architecture (Oracle/no-sql/graph databases)
Experience with REDIS data store, any in-memory data structure platforms
Experience in building Django / Flask / wildfly Java based App server
Good experience in consuming or exposing web services (i.e. SOAP, REST)
Thorough knowledge on UNIX/Linux platforms. Scripting experience with Shell, XML , JSON, Advanced SQLs, Oracle PL/SQLs
Experience in developing applications for Supply Chain business domain.
Proven ability in supporting the expansion and maintenance of various Oracle database based solutions.
Ability to successfully manage and collaborate with contractors
Experience in several full system implementation life-cycles (Analyze, Design, Build, Test, Implement, Support).
Ability to multi-task ,work independently with minimal supervision;
Excellent verbal and written communication skills
Comfortable working in a multi-discipline, geographically dispersed team.
Description
As an Application Developer / Data Engineer you will work with application owners, developers, QA, project managers, Support teams and end users. Lead proof-of-concept and pilot implementations to demonstrate new ideas or illustrate the use of new technologies and how to apply it into our systems.
Strive for top quality results and continuously look for ways to improve and enhance system reliability, performance, and security.
He or she must be able to perform regular design and code reviews and participate in debugging and coding to resolve issues. Provide technical guidance and mentoring to a small team of software engineers; Develop critical system components as well as take bottom line for team’s timely deliverables quality and performance
Demonstrates solid understanding of information management, data modeling, system integration, development methodologies (including unit testing) and web technologies.
Participate in architectural design meetings for data/system integration projects
Team lead experience is a plus. Occasionally will need to handle Application Production (warranty) support.
Working with highly leveraged outsourcing model
Education & Experience
B.S / M.S in Computer Science or equivalent.",4.7,"Apple
4.7",Hyderabad,"Cupertino, CA",10000+ employees,1976,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Google, Microsoft, Samsung Electronics"
785,Data Engineer,"Who We Are:
Ocrolus is a fintech infrastructure company that transforms documents into actionable data. Powered by Artificial Intelligence and a unique human-in-the-loop data validation process, Ocrolus plugs directly into customer workflows via API, eliminating the need for manual data work. The solution includes built-in fraud detection and analytics, enabling customers to make smarter and faster business decisions with unprecedented precision.

Use-cases include loan underwriting, account openings, invoice processing, and other document-intensive processes. Ocrolus has raised over $30 million in venture capital, backed by Oak HC/FT, FinTech Collective, Bullpen Capital, and QED Investors, among others.

We are seeking a candidate with proven experience working as a Data Engineer, Full Stack Software Engineer with a Data focus, or similar role. The ideal candidate is comfortable in DevOps and Software Engineering.
Responsibilities
Manage competing priorities across the company
Maintain and automate reporting infrastructure
Manage the design and architecture of our Data Warehouse
Create Scripts to automate and manage ETL processes and Dependencies
Advise on the design of our application DB, machine learning components, and our data infrastructure.
Cleaning and restructuring datasets
Managing and optimizing reporting systems
Requirements

At least 2 years experience as a Data Engineer, or related Software or DevOps experience
Total year of experience is looking for 5 Years.
Fluent in Python and SQL
Experience with Data Warehouses and Schema Design
Strong communication skills and experience communicating across business units
Experience working with Data Scientists and Data Analysts
Ability to create fast solutions to problems introduced in a changing environment with iteration towards optimal solutions
Machine Learning experience a plus
Analytical and BI skills a plus
Postgres and RedShift experience is a plus

We’re a young and rapidly growing FinTech company - if you have ever wanted to jump on a rocket ship as it’s taking off, now is your chance!",4.9,"Ocrolus
4.9",Gurgaon,"New York, NY",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
786,Data Analyst,"Duties and Responsibilities
Research and verify the accuracy of the data from source documents within the time limits.
Verify the accuracy and the credibility of the information.
Prepare documents, files and reports utilizing various computer (Microsoft Office) programs.
Enter data into prescribed computer database, files and forms.
Review data for deficiencies or errors, correct any incompatibilities if possible.
Keep information confidential.
Requirements
Any graduate, higher preferred.
Good verbal and written communication skills.
Problem analysis and problem solving.
Proficient in relevant computer skills such as MS Office.
Typing speed and accuracy.
Eager to learn and cooperate with the time.",3.4,"Edunuts
3.4",New Delhi,"Connaught Place, India",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
787,Data Engineer,"Greetings from vibrant HR Consultancy!!!
We have immediate openings for Data Engineer

Designation : Data Engineer
CTC : As per company standard
Location : Coimbatore
Shift : General Shift
Experience : 2 to 5 Years of experince

Skills:
Passion on data handling. (M)
Minimum 1 year experience in USA Real Estate domain(M)
Database

Experience in designing ETL for data movement between excel, flat file, RDBMS like SQL Server using Bulk Insert, BCP utility, DTS and a variety of SSIS packages including custom transformations for a wide range of business requirements (O)
Expert knowledge on complex usage of SQL queries. (M).
Knowledge on C#.Net.
Having knowledge on Python (O)
Cloud

Good Understanding & Knowledge on Azure (O)

Data

Prior Experience with Large volume of data handling
Ability to find solutions for various data problems.
Prior exposure to data mining & data analytics.
Interstead candidates please share me your updated resume to preethi@vibranthr.net OR Contact - 9343075322

Thanks & Regards
Preethi
Team Vibrant
00-5.00 Years",-1,Vibrant Hr Consultancy,Coimbatore,-1,-1,-1,-1,-1,-1,-1,-1
788,Data Analyst,"CSIR-Institute of Genomics & Integrative Biology (IGIB), desires to engage qualified incumbents on purely temporary basis as detailed below:

Post code: 06

Data Analyst

Essential qualification: B.Tech/M.Sc. in Life Science/Computer Sciences/Allied Sciences
Desirable: Good Programming skills and interest in working on Genomics Sciences and 55% marks in the clearing examination.

Age Limit: 35 years

Stipend: Rs.31,000/- (Consolidated) p.m.

Initial Tenure till: 31.03.2021

Candidate Profile:
Good Programming skills and interest

Experience:0-1 Year

Location:New Delhi

Education:B.Tech/M.Sc. in Life Science/Computer Sciences/Allied Sciences

Company:CSIR- Institute Of Genomics & Integrative Biology

SALARY:Rs.31,000/- p.m.

Last Date: Last Date to Apply is Over. : 2020-Apr-30

Key Skills: Research Fellowship

Company details

CSIR- Institute Of Genomics & Integrative Biology

CSIR- Institute Of Genomics & Integrative Biology Mall Road, Delhi - 110007",4.1,"CSIR- Institute Of Genomics & Integrative Biology
4.1",New Delhi,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
789,DATA ENGINEER,"Big Data Developer - Java

About Happiest Minds Technologies

Happiest Minds enables digital transformation for enterprises and technology providers by delivering seamless customer experience, business efficiency and actionable insights through an integrated set of disruptive technologies: big data analytics, AI & cognitive computing, Internet of Things, mobility, cloud, security, unified communications, SDN-NFV, RPA, etc. Happiest Minds offers domain-centric solutions applying skills, IPs and functional expertise in IT services, product engineering, infrastructure management and security. These services have applicability across industry sectors such as retail, consumer packaged goods, edutech, e-commerce, banking, insurance, hi-tech, engineering R&D, manufacturing, automotive and travel/transportation/hospitality.

Headquartered in Bangalore, India; Happiest Minds has operations in the US, UK, The Netherlands, Australia and Middle East.

Skills

Required Skills: Java Programming, Big data, Spark,

Roles and responsibilities/What You’ll Do
· Design and develop data applications using selected tools and frameworks as required and requested.
Working on disparate data sets.
Process unstructured data into a form suitable for analysis.
Monitoring data performance and modifying infrastructure as needed.
What We’re Looking For
Experience in Core Java
Hands on experience in Hadoop, HDFS & HIVE development and implementation
Hands on Experience in Spark Programming
Good knowledge on Kafka
Good knowledge of database structures, theories, principles, and practices
Hands on experience in HBase/Cassandra
Good to have experience on SCALA, Python
Translate complex functional and technical requirements into detailed design and development
Good to have experience on Cloud Implementation (AWS / Azure)
Good Experience in SQL",4.1,"Happiest Minds Technologies
4.1",Bengaluru,"Bengaluru, India",1001 to 5000 employees,2011,Company - Public,IT Services,Information Technology,₹5 to ₹10 billion (INR),-1
790,SQL Data Analyst,"The purpose of this role is to work within the programme to build out the inventory of impacted clients / contracts / trades and credit.

Main Duties

Incorporate new data feeds / sources as required.
Act as point of escalation for all analysis issues
Reporting to management of progress and escalations.
Enrich Sales revenue to produce impact view
Produce client packs for impacted clients
Produce MI on progress of inventory completeness
ad-hoc queries that come from various sources

Business Knowledge

Investment Banking experience in one or more of: Client Onboaridng, Operations, Middle Office and Front Office
Working knowledge of the key regulations currently impacting investment banks.
Working knowledge of Markets products
Client Reference Data / Trade data / PnL / Legal Documents

Ideal Experience

5 years experience of analysis in an investment bank
Expert in Excel
Excellent database skills (SQL/Oracle)
Exposure to Client Reference Data / Trade data / PnL / Legal Docs within an Investment Bank",3.9,"CAPCO
3.9",Bengaluru,"London, United Kingdom",5001 to 10000 employees,1998,Company - Public,Consulting,Business Services,₹50 to ₹100 billion (INR),"Deloitte, EY, Accenture"
791,SQL Data Analyst,"Greetings from Careator Technologies Private Limited., (CTPL).

CAREATOR Technologies is an emerging technology company, based on the strengths of understanding evolution of technologies right from the inception stage, offers a wide spectrum of services that span across both Application Life Cycle Management process of Software Engineering and Resource Management of Projects that deliver complex IT solutions for critical business processes. We @ CAREATOR, closely work with best MNCs (Product Based Companies & Service Based Companies) in India, UK, Australia, Canada & USA. CAREATOR is always been successful in meeting their customer needs and follows best IT practices to retain the right talented professional

We are hiring the following professionals on immediate basis. If you are interested and suitable for this position, please apply immediately.

SQL Data Analyst Location – Bangalore & Hyderabad

No of Positions – 5

Experience - 2-3 Yrs

Our client is looking for strong SQL Data Analyst with SQL expertise & work on client facing roles with excellent communication skills

Responsibilities & Duties - 1. Strong Hands-on experience on SQL - (creation of procedures, functions, triggers, events), Understanding of the data and its relevant data sources. 2. Program specific database functions to create database triggers and design data tables. 3. After reviewing and analyzing data, design reports to show statistics and other information about specific database topics. 4. Remove dead data files and other irrelevant information to free up database space. 5. Write scripts to analyze data and perform specific data queries. 6. Isolate and resolve issues with data and databases. 7. Collect data from multiple sources and add it to the database and create visualization reports. Good to have - Any prior working experience on BI tools. Skillset - • Must have strong programming skills, particularly in SQL, structured query language, and other common programming languages • Candidate should be proficient in math to write complex scripts and queries in SQL and other programming languages • Sharp analytical thinking is essential for SQL data analysts, who analyze specific data sets and statistics • Work with multiple data sources and data sets, which requires a talent for multitasking",4.4,"Careator Technologies
4.4",Bengaluru,"Hyderabad, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
792,Sr. Research Scientist,"ROLE PURPOSE:

Biomass preparation, processing engineer and team member to absorb technology from outsourced research.

KEY ACCOUNTABILITIES:

Work Output
Biomass preparation engineering - Equipment engineering, process design and optimisation at different scales
Process Engineering - Develop biomass pretreatment processes at pilot, commercial scale for the identified products.
Downstream Processing - Develop suitable downstream processes for product isolation, Recovery and purification – Pilot and commercial
Process engineering package development – User requirement specifications, PFD, P & ID, Mass balance and Energy Balance.
TEM studies
Technical Management
Technology absorption from outsourced research
Process scale up and equipment engineering
Feedstock management
HSE & other regulatory compliance
Zero Accident in Work
PPE use 3. Lab/work place compliance
Learning & mentoring
Situational Leadership & Negotiations
QUALIFICATIONS:

Necessary:
M.Tech or MS in Chemical/Biochemical/Mechanical engineering
2 - 3 years of Biomass process experience
Desirable:
Project scale up experience in multiple products
Project engineering",3.6,"Jio
3.6",Mumbai,"Mumbai, India",5001 to 10000 employees,2010,Company - Private,"Cable, Internet & Telephone Providers",Telecommunications,Unknown / Non-Applicable,-1
793,Software Developer – Data Science and Engineering,"Design, Architect and Develop Native iOS Apps based on suitable design patterns
Knowledge in basic OOPS concepts
Good knowledge in designing and implementing interface, protocols, Categories and other basic language features
Good knowledge and work experience in hardware specific features like
Location Detection
Accessing Camera and Photo Library
Good knowledge in Map Kit
Basic knowledge in third-party framework integrations like Facebook, Twitter, etc.

Good knowledge in gcd or NSOperationQueue
Basic knowledge in KVC
Good knowledge in UIKit framework
Good knowledge in APNS
Experience: 3 - 8 years",4.4,"Sulekha
4.4",Chennai,"Chennai, India",1001 to 5000 employees,2004,Company - Private,Internet,Information Technology,₹10 to ₹50 billion (INR),-1
794,NLP & Text Mining Data Scientist,"Job title

NLP & Text Mining Data Scientist
Department

Analytics & Data Science
Report To

Deepthi Devarakonda / Simhan Ramakrishnan
No of yrs. of exp

4+ years
Work Location

Pune, MH, India
No of Positions

2
Assigned Recruiter
Talent Partner

Version Control
Version No.

Date

Remark

Updated by
1.0

5/7/2020

Initial Version

SR

It’s Time For A Change…

Your Future Evolves Here

Evolent Health has a bold mission to change the health of the nation by changing the way health care is delivered. Our pursuit of this mission is the driving force that brings us to work each day. We believe in embracing new ideas, challenging ourselves and failing forward. We respect and celebrate individual talents and team wins. We have fun while working hard and Evolenteers often make a difference in everything from scrubs to jeans.

Are we growing? Absolutely—56.7% in year-over-year revenue growth in 2016. Are we recognized? Definitely. We have been named one of “Becker’s 150 Great Places to Work in Healthcare” in 2016 and 2017, and one of the “50 Great Places to Work” in 2017 by Washingtonian, and our CEO was number one on Glassdoor’s 2015 Highest-Rated CEOs for Small and Medium Companies. If you’re looking for a place where your work can be personally and professionally rewarding, don’t just join a company with a mission. Join a mission with a company behind it.

Position summary

The NLP and Text Mining scientist will support building of AI products in Agile fashion that empower healthcare payers, providers and members to quickly process medical data to making informed decisions and overall reduce health care costs. As a research scientist/engineer part of Data Science and Artificial Intelligence team you will be working primarily on unstructured text data to build machine learning models for information retrieval applications. These applications include but are not limited to optical character recognition, understanding the contents of the medical documents using natural language processing, and integrating processes into the overall AI pipeline to mine healthcare and medical information with high recall and other relevant metrics. We ingest claims, medical charts, etc. from providers containing unstructured data which will be transformed into structured data to support automated entry into our storage layers for downstream applications. The results will be used dually for real-time operational processes with both automated and human-based decision making as well as contribute to reducing healthcare administrative costs. We work with all major cloud and big data vendors offerings including but not limited to (Azure, AWS, Google, IBM, etc.) to achieve AI goals in healthcare and support Evolent business.

Essential functions

The NLP Text Mining Scientist / Engineer will have the opportunity to shape team culture and operating norms as a result of the fast-paced nature of a new, high-growth organization.
4+ years of Industry experience primarily related to Unstructured Text Data and NLP (PhD work and internships will be considered if they are related to unstructured text in lieu of industry experience but not more than 2 years will be accounted towards industry experience)
Develop Natural Language Medical/Healthcare documents comprehension related products to support Evolent Health business objectives, products and improve processing efficiency, reducing overall healthcare costs
Gather external data sets; build synthetic data and label data sets as per the needs for NLP/NLR/NLU
Apply expert software engineering skills to build Natural Language products to improve automation and improve user experiences leveraging unstructured data storage, Entity Recognition, POS Tagging, ontologies, taxonomies, data mining, information retrieval techniques, machine learning approach, distributed and cloud computing platforms
Own the Natural Language and Text Mining solutions — from platforms to systems for model training, versioning, deploying, storage and testing models with creating real time feedback loops to fully automated services
Work closely and collaborate with Data Scientists, Machine Learning engineers, IT teams and Business stakeholders spread out across various locations in US and India to achieve business goals
Provide training to other Data Scientist and Machine Learning Engineers in your speciality
Strong understanding of mathematical concepts including but not limited to linear algebra, Advanced calculus, partial differential equations and statistics including Bayesian approaches
Strong programming experience including understanding of concepts in data structures, algorithms, compression techniques, high performance computing, distributed computing, and various computer architecture
Good understanding and experience with traditional data science approaches like sampling techniques, feature engineering, classification and regressions, SVM, trees, model evaluations
Additional course work, projects, research participation and/or publications in Natural Language processing, reasoning and understanding, information retrieval, text mining, search, computational linguistics, ontologies, semantics
Experience with developing and deploying products in production with experience in two or more of the following languages (Python, C++, Java, Scala) (4+ years)
Strong Unix/Linux background and experience with at least one of the following cloud vendors like AWS, Azure, and Google for 2+ years
Hands on experience with one or more of high-performance computing and distributed computing like Spark, Dask, Hadoop, CUDA distributed GPU (2+ years)
Thorough understanding of deep learning architectures and hands on experience with one or more frameworks like tensorflow, pytorch, keras (2+ years)
Hands on experience with libraries and tools like Spacy, NLTK, Stanford core NLP, Genism, johnsnowlabs for 2+ years
Understanding business use cases and be able to translate them to team with a vision on how to implement
Identify enhancements and build best practices that can help to improve the productivity of the team.


Nice to Have
Medical concepts with codes from standard ontologies (SNOMED CT, LOINC, RxNorm, ICD, etc.)
Lucene, Solr, Elastic Search experience
Experience with Kubernetes and dockers
Experience building REST API’s for AI work and knowledge of microservices architecture
Participation in open source community projects
Academic Qualification:
Master’s degree or above in Computer Science, Computational linguistics, Mathematics, Physics or electrical engineering with research experience from a strong academic program along with thesis (No Post Graduate diplomas and undergraduate degrees)
Completion of thesis/research is required as part of graduation in computer science, artificial intelligence, Mathematics, Physics, Electrical Engineering or statistics
A PhD degree in Computer Science, Artificial Intelligence, Computational Linguistics, Machine Learning, or related technical field is preferred from a strong academic program
Publication record in top NLP conferences (NIPS, ICLR, ACL, NAACL, EMNLP, SIGIR, WWW etc) is preferred",2.8,"Evolent Health
2.8",Pune,"Arlington, VA",1001 to 5000 employees,2011,Company - Public,Healthcare Services & Hospitals,Healthcare,₹1 to ₹5 billion (INR),-1
795,Data Engineer,"Responsibilities
Deliver highly scalable and reliable applications.
Develop well-architected, intuitive and elegant frameworks and features to support scalability and flexibility
Refactor and optimize our code for improved reliability, performance, simplicity and maintainability
Join a highly collaborative team in an energetic environment
Participate in system monitoring, including through an on-call rotation
Qualification
Develop robust data processing pipelines to make data available across a variety of applications.
Work collaboratively with Product, Design/UX, DevOps, Management and other teams to deliver data as a service
Continuously improve data processing platform by analyzing existing bottlenecks and suggesting efficient alternatives.
Respond quickly and proactively to data quality issues by developing process and reports to triage and repair issues while avoiding business impact.
Conduct research and development activities in the data space to ensure that we are improving our capabilities relative to trends and changes in technology.
Identify robust methodologies to bring data science models to production.",4.7,"Class One Exchange
4.7",Chennai,"San Jose, CA",1 to 50 employees,2014,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
796,Senior Data Engineer,"Senior Data Engineer

Job Id
ED-SA-01

Designation
Senior Analyst

Experience
3 – 5 years of relevant experience in the Analytics industry

Job Location
Pune

Academics
UG: B.E / B.Tech, PG: Post Graduation is not compulsory

Job Profile and Responsibilities

Responsibilities:


Interface with clients to understand high level as well as detailed project requirements and understand business problems.
Develop solution architecture to extract, transform and load data and other required solution to answer business questions, be responsible for end to end data management.
Manage client communication and meetings, documentation and other processes. Generate and communicate insights and project results to client, seek and incorporate feedback.
Lead and manage team members.

Should have hands-on experience in one or more of the followings:
Programming in Python, Java, JavaScript, PHP, Ruby, R etc
Frameworks and libraries like Pandas, Numpy, SQLAlchemy, Spark etc.
Data ETL tools like Talend, Alteryx etc.
Management and operation on databases like MySQL, PostgreSQL, MS SQL, MongoDB, Cassandra, Neo4j etc.
Cloud platforms like Amazon Web Services (EC2, Glue, Athena, RDS, Redshift etc.), Google Cloud Platform (BigQuery, Cloud SQL etc.), MS Azure (ADF, Azure SQL etc.)
Working with REST and SOAP APIs.

Desired Candidate Profile:


Ability to lead a team and manage projects independently.
Eye for detail, passion for accuracy.
Great analytical and problem-solving skill.
Ability to adapt and thrive in a fast paced and demanding environment of a young start-up.",4.7,"Rudder Analytics
4.7",Pune,"Pune, India",1 to 50 employees,2015,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
797,Data Analyst,"VARITE is looking for a qualified Data Analyst for one of its clients located in Noida (Sec 144) . If you are interested in this opportunity, kindly respond ASAP with your updated resume. We will be glad to represent you to our client and help in your job search. WHAT THE CLIENT DOES? A system integration and one of the largest IT Services companies. WHAT WE DO? VARITE is a global IT company providing software and engineering consulting and team augmentation services to Fortune 1000 companies in USA, CANADA and INDIA. VARITE is currently a primary and direct vendor to the leading corporations in the areas of Cloud, Data Sciences, Infrastructure Application Software, Mobility, Robotics, Banking & Financial Systems.
Salary Negotiable
Industry IT Software
SubIndustry Software Development
Functional Area IT Software Development
Specialization Database Architect/Designer
Role Executive / Officer Level
Keyskills
Data AnalysisAdvance ExcelPivot Table
Desired Candidate Profile
Please refer on JD
Education
Highest Qualification
Graduation B.E/B.Tech",5.0,"Fine Jobs
5.0",Noida,"Mumbai, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
798,Data Analyst,"Job description:
Should conduct Operational data analysis related to services and analyzing the operational efficiency to improve further.
Creating a detailed operational analysis, outlining problems, opportunities and solutions.
Should develop and monitor data quality metrics and ensure operations data and reporting needs are met.
Strong technology, analytical and communication skills are must.
Budgeting and operational forecasting of services provided.
Planning and monitoring of new projects/ upcoming projects.
Analysis of new initiatives and finding impediment for effective implementation.
Financial modeling for operations.
Variance Analysis
Analysis of penalties and coming out with solutions for diminution of same.
Reporting and data interpretation of operations data.
Defining operations requirements and reporting them back to stakeholders
Expected to develop new models that underpin sound operational decisions.
Streamlining and improving of internal and external reports.
The role should also call for a strong understanding of regulatory and reporting requirements as well as plenty of experience in forecasting, budgeting and financial analysis combined with understanding of key performance indicators.
The end goal is to provide financial insights that help the decision-making process, and align capital and resource allocation within the operations budget.
One should also drive fresh initiatives for financial planning and operational excellence.
Qualification:
Business Studies/ Business Administration/ Management/ Information Technology from good B School
The core skills:
Experience working with senior decision makers
Strong communication/interpersonal skills
Proven analytical background
Advanced Excel skills
Required Candidate profile
Dear Candidate,

Please be noted that this is purely data analyst position, which required Advanced data analytical skills,Advanced excel skills.

Job Type: Full-time

Salary: ₹300,000.00 to ₹400,000.00 /year

Experience:
work: 1 year (Preferred)
Education:
Bachelor's (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,askIITians Web Pvt ltd,Noida,-1,-1,-1,-1,-1,-1,-1,-1
799,Data Analyst,"About Dasceq
Dasceq is transforming collection industry in USA using AI/ML and Big Data. We are focused to build a best in class Collection AI SaaS Product and have already established our product for $320billion Auto and Short Term Industry. We are expanding our team and looking for next generations data scientist with experience to lead high end AI Product Development. We don’t do lip service and we are committed to solve a $1.6 Trillion collection problem and looking to expand our amazing Analytics team. If you would like to build something high end and push boundaries contact us today!

Job codes: DASDA

Qualifications :
Bachelors/ Masters in Data Science/ Business Analytics ; Econometrics ; Statistics ; Math; Computer Science preferred with 2 to 3 years experience in Business Analytics / Data Science with hands on experience in R / Python / SQL and sound knowledge of Excel and at least one Visualization tool.

Preferred Institutes:
Tier1 or Tier 2 Institutes

Job Description :
The prospective hire would be part of the Analytics Team , assisting our sales and customer success partners with critical business insights based on exploratory analysis and adhoc requirement based analysis as the need maybe. Sound knowledge of data handling and manipulation along with SQL , R/ Python is needed for the role. The candidate should also be proficient in excel graphs and charts and be adept in making power point presentables. Prior customer facing experience will be and added bonus for the role.

Pay:
As per experience and market standards

Apply at: ritu@dasceq.com

Please send: Latest resume with current Salary and Bonus components mentioned",2.0,"Dasceq
2.0",India,"Irving, TX",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
800,Data Engineer,"We are looking for a Data Engineer to join our Data services & Analytics team. In this role, you will have to work closely with a team of business analysts, data analysts & data scientists to analyze, evaluate, design & document databases as well as application interfaces. Be integral part of an evaluation and modernization process that will expose you to both legacy & cloud database technologies alike. You are a highly motivated, self-starter willing to learn, work in a fast-paced start-up like environment & enjoy solving problems.

Responsibilities
Analyze source ERP systems & unify data to meet end user data requirements.
Able to take raw data & model/transform it to cater to reporting requirements.
Design & implement data lake, cloud based datawarehouse/marts architecture.
Develop, test & deploy data pipelines to transport data between source systems & the datawarehouse.
Requirements:
5+ years of experience in data engineering - building data pipelines and performing complex data transformations.
3+ years of experience in data modeling, relational databases like Oracle, SQL Server & ETL/ELT tools like Talend, DBT.
Ability to perform data profiling & quality checks.
Good exposure to BI tools like Tableau, JReport, Looker etc.
Good hands on experience in one or more programming languages like Java, Python etc.
Exposure to cloud technologies & services like AWS, AZURE would be an added advantage.
Suitable domain knowledge/work experience in Supply Chain, Retail industry.",3.6,"Antal International
3.6",Chennai,"London, United Kingdom",1001 to 5000 employees,1993,Franchise,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
801,Data Engineer - AIM,"Have you ever ordered a product on Amazon and when that box with the smile arrived, wondered how it got to you so fast? Wondered where it came from and how much it cost Amazon? If so, the Amazon Global Supply Chain Optimization Technology organization is for you. Watch this video to learn more about our organization, SCOT: http://bit.ly/amazon-scot


SCOT's Automated Inventory Management (AIM) team is seeking talented individuals who enjoy the challenge of diving into complex problems and solving the unsolvable to help our executives make impactful business decisions. AIM teams owns Availability metrics that measures & improves the key customer experience on product availability. We regularly work directly with executive leadership to improve that experience.

As a Data Engineer, you will analyze large amounts of business data, solve real world problems, and develop metrics and business cases that will enable us to continually delight our customers worldwide. You will also work with a team of Product Managers, Data Scientists, and Software Engineers to automate and scale the analysis, and to make the data more actionable to manage business at scale. You will own many large datasets, implement new data pipelines that feed into or from critical data systems at Amazon.


Successful candidates will bring strong technical abilities combined with a passion for delivering results for customers, internal and external. This role requires a high degree of ownership and a drive to solve some of the most challenging data and analytic problems in retail. Candidates must have demonstrated ability to manage large-scale data modeling projects, identify requirements and tools, build data warehousing solutions that are explainable and scalable. In addition to the technical skills, a successful candidate will possess strong written and verbal communication skills and a high intellectual curiosity with ability to learn new concepts/frameworks and technology rapidly as changes arise.


Our diversity, measured by thought, gender and culture, is paramount to our ability to meet the evolving needs of our customers. Amazon is an Equal Opportunity-Affirmative Action Employer Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.


Basic Qualifications

· Bachelor's degree in computer science, engineering, mathematics, or a related technical discipline
· 5+ years of industry experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets
· 5+ years of hands-on experience in writing complex, optimized SQL queries and coding in scripting languages like Python, Shell Scripting, etc.
· Experience using big data technologies (Hadoop, Hive, Hbase, Spark, EMR, etc.)
· Experience using business intelligence reporting tools (Tableau, Business Objects, Cognos, etc.)
· Knowledge of data management fundamentals and data storage principles
· Build robust and scalable data pipelines using a range of tools and programming languages.
· Knowledge of distributed systems as it pertains to data storage and computing


Preferred Qualifications

· Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations
· Implement standardized, automated operational processes to deliver accurate and timely data for reporting to meet or exceed SLAs
· Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy
· Experience providing technical leadership and mentoring other Data Engineers for best practices on data engineering
· Experience working directly with remote technical teams",4.2,"Amazon
4.2",Hyderabad,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
802,Data Engineer,"Company: PayU Finance India Private Limited Location:
Bangalore/Mumbai

Roles and Responsibilities:
Perform diagnostic and predictive analytics to help create a portfolio segmentation strategy considering, among others, macroeconomic environment, industry and micro-industry concentrations, product, lifetime value, usage, risk appetite, geography, seasoning, term, credit performance, etc.  Influence, monitor, and assess impacts to Family Capital Funding's portfolio as a result of pricing, product, acquisition strategy, underwriting policy, fraud detection, and portfolio monitoring and collections.  Create predictive early detection credit deterioration capabilities using internal and external performance data.  Investigate, create, implement and validate various risk and financial forecasts using complex data including cohort and time series analysis of loan balances, revenue performance, net income performance, portfolio dynamics, etc. and ensure an enterprise wide consistency in estimations.  Interface with Acquisition, Pricing, Product, Marketing, Finance, and Operations teams to help build relationships, set goals and track operations performance, providing an actionable feedback loop as it relates to portfolio performance across key Family Capital Funding metrics.  Ensure sound credit control by taking a pro-active approach to risk management within the risk guidelines of Family Capital Funding.  Demonstrate governance, control and risk management behaviours in alignment with Family Capital Funding policies and practices. Document all new processes per Enterprise policy  Assist with developing and enhancing credit structuring/packaging and risk assessment capabilities to identify and maintain good business opportunities with new and existing clients.  Perform detailed analysis and interpret information to make recommendations to Senior Management on critical strategies including non-standard and ad-hoc requests as determined by management.  Ensure the timely and effective communication of forecasting results & variance drivers; anticipating potential needs in an effort to establish and maintain good working relationships with key business stakeholders.
Qualifications and Experience:
Undergraduate degree in Economics, Engineering, or Mathematics  2 to 5 years of related experience in a Business Analytics, Finance, Strategy, or Product functional area  Excellent business judgment and risk assessment as demonstrated by previous work or academic experience in an analytic role related to economic or business analysis  Strong Analytical and Problem-Solving Skills as demonstrated by previous experience in developing creative solutions to business strategy, technological, and operational problems  Excellent SQL and analytic programming skills (R, Python, SAS, Excel), willingness to work closely with large data sets and get into the details with business processes  Knowledge and experience with statistical concepts and financial analytics (break-even analysis, NPV estimation, downside risk assessment)  Desire to help small businesses by eliminating inefficiencies and excessive costs in the lending business",3.5,"PayU
3.5",Bengaluru,"Hoofddorp, Netherlands",1001 to 5000 employees,-1,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
803,Data Analyst,"Company Description

PubMatic is a digital advertising technology company for premium content creators. The PubMatic platform empowers independent app developers and publishers to control and maximize their digital advertising businesses. PubMatic’s publisher-first approach enables advertisers to maximize ROI by reaching and engaging their target audiences in brand-safe, premium environments across ad formats and devices. Since 2006, PubMatic has created an efficient, global infrastructure and remains at the forefront of programmatic innovation. Headquartered in Redwood City, California, PubMatic operates 13 offices and nine data centers worldwide.

Job Description

PubMatic is looking for a sharp analytical individual to work as a Data Analyst in the Finance Reporting & Insights function. People with a penchant for extracting the truth out of numbers and summarizing it for the finance and operations teams would be best fit for the role.

Responsibilities:
The Data Analyst will be responsible for collecting and analyzing tremendous data sets using tools such as Microsoft Excel, Access, SQL and hive databases and presenting them in easy-to-understand formats.
The Data Analyst will be expected to retrieve data from publishers, ad networks & aggregators UI and develop spreadsheets and excel macros to filter, analyze, generate reports and draw conclusions from that data. It will be important to focus on the primary metrics while understanding the business requirements of the different teams within the business.
Apart from reporting tasks, the Data Analyst will work closely with other functions in the Pune Billing Team to assist with preparation of monthly publisher statements, tools that will improve productivity and the revenue yield generated for our publishers.

Requirements:
Exposure to business analysis, tracking metrics and building revenue monitoring tools
Should be involved in MIS functions requiring independent analysis of data
Exposure to financial modeling and operations analysis is a plus
Basic knowledge of running mapreduce jobs in hive databases
Basic programming knowledge

Technical Skills:
MS Office products including strong grasp of Excel (Charting, Formulae, Pivots
Advance Excel/Access: VB Macros in Excel and MS Access
VBA programming exposure is a plus
MS-SQL / MySQL
Hands on experience on Hive Database / Data Analytics tools
Added advantage if hands on experience in HTML / PHP / Java Script / Python

General attributes:
Any graduation, as specified by role, with good academic record / Masters is a plus
Total work experience of 3 to 5 years in a fast paced change-oriented environment
Worked in shifts interacting with US or UK clientele / vendors
Logical reasoning ability, problem solving and analytical mindset
Pro-active, quick learning, detail oriented
Excellent written and spoken English with ability to handle communication across levels.
Working hours would be 8PM to 5AM

Qualifications

Graduation in Math, Statistics, Science or Engineering

#LI-MD1

Additional Information

All your information will be kept confidential according to EEO guidelines.",4.4,"PubMatic
4.4",Pune,"Redwood City, CA",501 to 1000 employees,2006,Company - Private,Internet,Information Technology,₹10 to ₹50 billion (INR),AdMeld
804,Data Analyst,"Location:
Kolkata

Requirements:
Experience in data models and reporting packages
Ability to analyse large datasets
Ability to write comprehensive reports
Strong verbal and written communication skills
An analytical mind and inclination for problem-solving
Masters or PhD in Statistics, Mathematics, Computer Science, Information Technology or related fields.
Responsibilities:
Interpret data, analyze results using statistical techniques and provide ongoing reports
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality
Acquire data from primary or secondary data sources and maintain databases/data systems
Identify, analyze, and interpret trends or patterns in complex data sets
Filter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems",-1,Vixplor Analytics,Kolkata,-1,-1,-1,-1,-1,-1,-1,-1
805,Research Scientist,"Company manages a 3500 acres under plantation.

We need to expand in medicinal and aromatic plantation.

Job Type: Full-time

Salary: ₹25,000.00 to ₹200,000.00 /month

Experience:
work: 1 year (Preferred)
total work: 2 years (Preferred)
Education:
Secondary(10th Pass) (Preferred)",-1,"Langlai Tea, Aromatics and Herbs",Kolkata,-1,-1,-1,-1,-1,-1,-1,-1
806,Data Analyst (OCN),"Data Analyst (OCN) (VEC000869)

Description

This position description is subject to change at any time as needed to meet the requirements of the program or company.

POSITION SUMMARY/MAJOR JOB ACTIVITIES:
The mission of the Data & Value team is to maintain data quality and derive insight, from Vectrus’s rapidly growing data sets. Responsible for maintaining data standards, extracting, transforming, reporting, and visualizing data across business functions to assist the Leadership decision making to improve efficiency, reduce costs, increase customer satisfaction across all Programs.

We believe our team provides an ideal platform for someone passionate about helping Business functions make data driven decisions.
Build holistic understanding of our enterprise solutions, our Customer, the BI data infrastructure and environment, and business goals.
Leverage industry best practices in establishing repeatable BI practices, principles, and processes.
Create dashboards, provide key metrics, and custom-formatted reports for Customer and stakeholder use in a timely manner.
Provide ad-hoc query support as requested.
Collaborate with decision makers to translate business questions into verifiable hypothesis.
Develop clear, concise, actionable recommendations from data using statistical sampling, modeling and analysis.
Perform extracting, importing, and exporting of data in various applications ensuring data quality standards are met.
Assist with ongoing data architecture processes and governance.
Supports User Acceptance Testing on production data loading.
May perform other duties as assigned.
MATERIAL & EQUIPMENT DIRECTLY USED:
Personal computer, printers, network equipment and electronic test equipment and other general office equipment.

WORKING ENVIRONMENT:
Typical office environment.

.

PHYSICAL ACTIVITIES:
Requires sitting and using office equipment and computers. Occasionally requires bending and lifting of computer equipment, supplies and materials.

Qualifications

MINIMUM QUALIFICATIONS:
Education/Certifications: One year related experience may be substituted for one year of education, if degree is required.
Associates degree.
Microsoft's MCSE: Data Management and Analytics Certification preferred.
Hortonworks or Intellipaat Big Data Hadoop Certification preferred.
ITIL v3 or higher Certification.
Lean Six Sigma (LSS) Training Green Belt Certification preferred).
Experience:
1+ year working as a Data Analyst.
4+ years of SQL, R and/or Python experience.
5+ years of IBM Maximo Asset Management 7.6 & Eclipse BIRT 4.3.
2+ years of experience using Data Visualization tools such as: Power BI Excel, Cognos, Tableau.
Advanced Microsoft Office skills.
Experience in data management, specifically in validating, loading, and auditi.ng of data and reports in multiple systems.
Experience in analyzing big data and unstructured datasets using (Hadoop and/or Cosmos) preferred.
Skills
Experience with data mining/data warehousing, data modeling, Python, SQL, statistical analysis, linear algebra, database management.
Experienced with building reports using tools like Power BI, Excel, BIRT Reports or similar tools.
Solid familiarity with data and analytic emerging technologies, including: Artificial Intelligence (AI), Internet of Things (IoT), Block chain, 5G, Cloud, Edge Computing, Big Data, Machine Learning, and Automation.
Familiarity with agile development methodology.
Ability to utilize statistics to generate clear and effective recommendations.
Comfortable deconstructing complex-open ended problems.
Action-oriented, self-motivated, agile and driven to think out-of-the-box on key initiatives.
Experienced, ITIL-qualified, Service Management Professional with a passion for Service Improvement.
Able to ﻿ communicate effectively in English with non-technical stakeholders and work with them to produce reports and visualizations.
Able to work under pressure and meet established deadlines.
.

Licenses/Certifications:
NA

SUPERVISORY/BUDGET RESPONSIBILITIES:
None

Primary Location: India-Chennai
Job: Information Technology
Clearance Level required at Start Date: No Clearance Required
Travel: No
Work Status: Full-time

We are committed to an inclusive and diverse workplace that values and supports the contributions of each individual. This commitment along with our common Vision and Values of Integrity, Respect, and Responsibility, allows us to leverage differences, encourage innovation and expand our success in the global marketplace. Vectrus is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, age, color, religion, sex, national origin, protected veteran status or status as an individual with a disability. EOE/Minority/Female/Disabled/Veteran.",3.8,"Vectrus
3.8",Chennai,"Colorado Springs, CO",10000+ employees,-1,Contract,General Repair & Maintenance,"Building, Repair & Maintenance",₹50 to ₹100 billion (INR),-1
807,"Lead Data Scientist (Data Analysis, Machine Learning)","What's the role?


At HERE Technologies in Automotive Product Engineering team, we are looking for highly skilled, self-motivated, Sr / Lead Data Scientist who is passionate about innovating and developing machine learning and data analytics solutions to build our industry-leading map. We provide the opportunity to collaborate with an energetic and dedicated team that works on cutting-edge technology to create tools and services. The candidate will work with researchers, developers, architects to develop, deploy, and maintain applications in multiple environments.

Responsibilities:
Help design and build the next iteration of process automation in HERE Content Engineering employing a highly scalable Big Data infrastructure and machine learning as applied to global-scale digital map-making
Build and test analytic and statistical models to improve a wide variety of both internal data-driven processes for map-making data decisions and system control needs
Act as an expert and evangelist in areas of data analysis, machine learning, statistics, and predictive analysis and modeling
Function as a predictive modeling or application team lead.
What You’ll Get:
Challenging problems to solve
Opportunities to learn cool new things
Work that makes a difference in the world
Freedom to decide how to perform your work
Variety in the types of projects
Feedback so you will know how well you are doing
Collaborative, Supportive Colleagues
Who are you?


You are a go-getter with an eye for detail, strong problem solving and debugging skills with any Graduate in Computer Science or related field and the following;

• MS or PhD in a discipline such as Statistics, Applied Mathematics, Computer Science, Data Science, or others with an emphasis or thesis work on one or more of the following areas: statistics/science/engineering, data analysis, machine learning, computational geometry, and image processing.• 8+ years related, professional experience.• Knowledge of data mining and analytic methods such as regression, classification, clustering, association rules, decision trees, Bayesian network analysis, etc. expert-level knowledge in one or more of these areas.• Proficiency with a statistical analysis package and associated scripting language such as Python, C++, R, Matlab, SAS, etc. • Programming experience with SQL, shell script, Python, etc. • Knowledge of and ideally some experience with Cloud platform such as AWS, and the tools such as Pig, Hive, etc., for working with big data in Hadoop and/or Spark for data extraction and data prep for analysis.• Experience with and demonstrated capability to effectively interact with both internal and external customer executives, technical and non-technical to explain uses and value of predictive systems and techniques. • Demonstrated proficiency with understanding, specifying and explaining predictive modeling solutions and organizing teams of other data scientists and engineers to execute projects delivering those solutions.Preferred Qualifications: • Development experience with C++/Python/Shell Script• Development experience with Docker• Development experience with GIS data• Development experience with Relational Database/ NoSQL Database""

What we Offer

We will support you in delivering your day to day tasks and achieving your personal goals and develop your skills. Personal development is highly encouraged at HERE. You can take different courses and trainings at our online University and join cross-functional team projects within our Talent Platform. Our office is located with easy access by public transportation options. So, what are you waiting for? Apply now and make HERE your destination. We are just getting started...!

HERE is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, age, gender identity, sexual orientation, marital status, parental status, religion, sex, national origin, disability, veteran status, and other legally protected characteristics.

Make HERE your destination, we are just getting started! Apply now!

Who are we?


Ever checked in somewhere on social media? Ever tracked your online orders? You might be using HERE Technologies every single day without even realizing it. You can find us everywhere: in vehicles, smartphones, drones or third-party apps. We believe that with the right people, we will continue to be a game-changer in the technology industry and improve the daily lives of people around the world. Find out more by clicking the video below or going HERE.",3.7,"HERE Technologies
3.7",Mumbai,"Amsterdam, Netherlands",5001 to 10000 employees,1984,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Google, TomTom, Apple"
808,Data Analyst,"The person would be responsible for data collection and input in the varioustools and dashboards
The person would be responsible for working with various teams and collate thedata from all the teams.
The data would include sales, inventory, advertising, product details. All thedata points would be linked with each other that would help the person togenerate insights and formulate strategy.
Theperson would then prepare the strategy documents and reports and share with themanagement.
RequiredExperience, Skills and Qualifications

Theperson should have a good knowledge of Microsoft excel, Tableu or MicrosoftAzure Platform.
Understandingof a few data analytics, data visualization tools would be helpful
Theperson should be willing to work in a team and as a part of fast growingcompany where processes would be very dynamic in nature.",-1,Service industry for Pharmaceuticals company,Vadodara,-1,-1,-1,-1,-1,-1,-1,-1
809,Data Engineer,"Our client is seeking an experienced Data Engineer with an experience in building data-driven infrastructure and AI solutions.

In this role, you will be responsible for the delivery and operations of end-to-end AI solutions and to build infrastructure for processing big and unstructured data sets.

This includes productizing the findings from our research team into scalable, and robust system, which meet the highest production standards. You will work closely with data scientists, quantitative researchers and portfolio managers to understand the potential business value of data sets and ultimately build data processing pipelines around those data sources.

What you’ll do
Participating in the elaboration, architecture, design, development, testing, deployment, operation, maintenance, and enhancement of tools, libraries, frameworks, platform and full stack software solutions.
Designing, implementing and operating friendly and scalable APIs and micro services
Collaborating with the research group to productize the quantitative models and research findings as well as maintain AI models deployed in production
Developing big data processing pipelines for new data sources containing structured and unstructured data
Building platform infrastructure, visualization and exploration capabilities around our big data sets
Using the best software engineering tools and techniques. Review and test code, help manage automated testing and deployments
Working on both the backend and front-end aspects of complex solutions
What’s required
Proficient in programming in Python
Degree in a quantitative or technical discipline from top university (computer science, engineering, etc.)
5+ years of relevant experience in hands-on large-scale software development and enterprise architecture
Extensive experience designing and developing in-house software solutions
Understanding of data structures and algorithms and experience with big data platforms
Ability to devise novel and innovative solutions to challenges
Innate curiosity, entrepreneurial spirit, open minded and team player
Company’s culture
The company is driven by the mission of shaping the future of investment management. They have an international and multicultural team of creative and open-minded problem solvers.
Combining the best talents from physics, computer science, mathematics, social sciences and finance, the company all together are striving for constant innovation.

For your valuable work, the company offers:
Highly dynamic, innovative, passionate and entrepreneurial team
Open and inclusive company culture
Autonomous and self-managed agile teams
About the company
The company, backed by leading industry giants, is a developing next generation technology to revolutionize how investment decisions are made. The company offers differentiated, amplified and future-oriented investment intelligence mined from alternative data. Extracting early signals from the vast amount of data, empowering investment professionals with unique investible insight and hence better returns. From hedge fund to asset manager, they help our clients to enhance their investment models and derive information edge from a variety of data sources.

Location: Gurgaon, India

Job Type: Permanent and Full-Time",5.0,"itForte
5.0",Gurgaon,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
810,Data Analyst,"The person would be responsible for data collection and input in the varioustools and dashboards
The person would be responsible for working with various teams and collate thedata from all the teams.
The data would include sales, inventory, advertising, product details. All thedata points would be linked with each other that would help the person togenerate insights and formulate strategy.
Theperson would then prepare the strategy documents and reports and share with themanagement.
RequiredExperience, Skills and Qualifications

Theperson should have a good knowledge of Microsoft excel, Tableu or MicrosoftAzure Platform.
Understandingof a few data analytics, data visualization tools would be helpful
Theperson should be willing to work in a team and as a part of fast growingcompany where processes would be very dynamic in nature.",-1,Service industry for Pharmaceuticals company,Vadodara,-1,-1,-1,-1,-1,-1,-1,-1
811,Data Analyst,"Designation:
Data Analyst

Experience:
0 - 2 years

Location:
Hyderabad

Education:
Any Graduate in Any Specialization

Area of expertise:
Analytics

Job description
Responsible for designing & implementing interactive visualization dashboards and proficient in data preparation activities. Provide advice and guidance to business end-users in applying data visualization & analytics techniques to summarize business performance & provide actionable recommendations.

Requirements:
The Candidate should have skills are
Strong SQL or MySql skills with the ability to learn other analytic tools
Proven analytic skills, including mining, evaluation, analysis, and visualization
Technical writing experience in relevant areas, including queries, reports, and presentations
Knowledgeable of Advanced analytics & data visualization applications

Knowledgeable in different data acquisition techniques in both traditional & new methods appreciate the advantages & limitations of different technical solutions in meeting data analytics/visualization needs

Develop, implement and maintain leading-edge analytic systems, taking complicated problems, and building simple frameworks

Create best-practice reports based on data mining, analysis, and visualization

Ability to work as a part of the team and add value to the development team by providing innovative development related solutions.

Passion for learning new skills and technologies and sharing that knowledge with peers and co-workers
Interested candidates can apply by forwarding their resume to info@istlabs.in",-1,iScientific TechSolutions Labs,Hyderabad,-1,-1,-1,-1,-1,-1,-1,-1
812,Data Analyst,"Job Description : Job Responsibilities include: • Creating excel templates for data collection and reporting • Collating and consolidating raw data from various sources • Transforming the raw data to metrics using MS Excel /SQL • Presenting the metrics in simple, comprehensible & neat / readable format • Distributing the reports to the end users & management as per schedule • Ensuring timely delivery and quality of reports & basic analysis • Responding to queries by end users of reports • Automating reports using VB Macros & SQL • Catering to ad-hoc reporting requests by the management • Pulling data and reports from SAP ERP • Assisting in other functions of the department including implementation of new programs and initiatives.

Eligibility : Should have 2 -3 years of relevant experience in MIS / Reporting / Analytics and a Bachelors Degree in Science / Statistics / Operations Should know Advanced MS Excel / VBA / Coding concepts and have working knowledge of automation using MS Excel. Candidates knowing basic SQL and ERP would be preferred.

Venue Locaiton : Bandra",4.2,"ROCHEM Separation Systems
4.2",Maharashtra,"Mumbai, India",501 to 1000 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
813,Data Engineer: Big Data,"Introduction
At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities
As Data Engineer, you will develop, maintain, evaluate and test big data solutions. You will be involved in the design of data solutions using Hadoop based technologies along with Python & Spark programming.
Responsibilities:
Responsible to Ingest data from files, streams and databases. Process the data with Spark, Scala and Kafka
Develop programs in Scala and Python as part of data cleaning and processing
Responsible to design and develop distributed, high volume, high velocity multi-threaded event processing systems
Develop efficient software code for multiple use cases leveraging Python and Big Data technologies for various use cases built on the platform
Provide high operational excellence guaranteeing high availability and platform stability
Implement scalable solutions to meet the ever-increasing data volumes, using big data/cloud technologies Apache Spark, Kafka, any Cloud computing etc.
If you thrive in a dynamic, collaborative workplace, IBM provides an environment where you will be challenged and inspired every single day. And if you relish the freedom to bring creative, thoughtful solutions to the table, there's no limit to what you can accomplish here.

Required Technical and Professional Expertise
Minimum 6+ years of experience in Big Data technologies
Minimum 4+ years of experience in Python and Scala programming
Experience in developing applications on Big Data and Cognitive technologies including API development
Application Development background along with knowledge of Analytics libraries, open-source Natural Language Processing, statistical and big data computing libraries
Expertise in Spark, Scala and Kafka technologies
Ability to demonstrate micro / macro designing and familiar with Unix Commands and basic work experience in Unix Shell Scripting
Demonstrated ability in solutioning covering data ingestion, data cleansing, ETL, data mart creation and exposing data for consumers
Preferred Technical and Professional Expertise
Expertise in Python or Scala programming
You love collaborative environments that use agile methodologies to encourage creative design thinking and find innovative ways to develop with cutting edge technologies
Ambitious individual who can work under their own direction towards agreed targets/goals and with creative approach to work
Intuitive individual with an ability to manage change and proven time management
Proven interpersonal skills while contributing to team effort by accomplishing related results as needed
Up-to-date technical knowledge by attending educational workshops, reviewing publications
About Business Unit
IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world. What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Pune,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
814,Data Analyst | Advance Auto Parts | 4-7 years,"About the Job
Advance Auto Parts is a leading player in the automotive aftermarket parts industry in the US. As an organization. we are continually innovating and seeking to elevate the customer experience across our 4900+ stores. The company in India is an integral part of the larger organization supporting all regions in the US across IT, Digital, E-Services, Finance, and HR.
You will be one of the many team members who will pave the road ahead for Advance. In your role as a Data Analyst, you will be responsible for delivering business insights through advanced analytics and reporting. Develop answers to complex business questions through data analysis, applying various techniques and methods. Apply a healthy combination of technical skills and business acumen, to translate data into business insights to support data driven decision making.

Role & Responsibilities

Aggregate data from various sources, manipulate and analyze them at scale, support strategic and tactical initiatives

Extract and transform data and join datasets from different sources (Salesforce, MSSQL Server, S3, Google Analytics, etc.) and with different formats (xlsx, csv, .json, etc)

Process, cleanse, and verify data-integrity for analysis. Analyze data for errors and inconsistencies

Identify, analyze, and interpret trends or patterns in complex data sets, comprising of both structured and unstructured data, using statistical techniques and advanced analytics

You will benefit from

Range of Healthcare Perks

Life Insurance

Long-term/Short-term Disability Insurance

Employee Stock Purchase Plan

Sick Leaves

Paid Vacations

Paid Maternity",3.2,"Advance Auto Parts
3.2",Hyderabad,"Raleigh, NC",10000+ employees,1932,Company - Public,Motor Vehicle Parts & Accessories Shops,Retail,₹500+ billion (INR),"AutoZone, O'Reilly Auto Parts, NAPA Auto Parts"
815,Big Data Engineer,"Description

Job Responsibilities
Strong computer science fundamentals
Preferable to have exposure to Hadoop admin activities
Experience designing solutions for Big Data environments
Strong logical thinking and ability to work in a fast paced environment
Fast Learner with a go-getter attitude
Perform high complexity integration testing and validate all services integrate according to specifications
Responsible for prevention and early detection of defects through verification and validation activities ensuring the integrity and quality of all work products
Job Requirements
1 + years of experience handling large volumes and velocity of data
2 + years of hands-on experience working with Spark and Hadoop based technologies
1 + years of experience with data ingestion, processing and extracting value from it
1+ years of experience with major Hadoop distributions
1+ years of experience with No-SQL databases, preferably MongoDB
Technology Competencies
Core Java, J2EE, Collections,
Good to have: Scala, Python
Hadoop, HDFS, Spark, Kafka and related Big Data tools,
DB/NoSql - MongoDB, My Sql or any No SQL DB.
Education
Engineering Graduates / Post-Graduates from premier institutions are preferred. Graduates from IIT, BITS, & NIT are preferred.
Work Experience

MUST have more than 2+ years of hands on Java & Bigdata technologies experience

About Company

This is an open invitation for India’s best in class Data Engineer to join the disruptive technology and thought the leader in the global Talent Relationship Marketing Cloud Platform. If you live & breath engineering by solving not only engineering problems but are passionate about building state of the art products that help a billion+ job seekers, then welcome to Phenom People. AT Phenom we build products that connect right fit talented candidates (job seekers) with companies seeking for Phenomenal talent. We help companies establish, nurture and mature relationship with talented candidates through the hiring life-cycle. Based in Greater Philadelphia area, we server global Fortune 500 companies.

Explore Location
Close the mapbox popup

No locations found

Apply Now
Add To Cart",4.3,"Phenom People
4.3",Hyderabad,"Ambler, PA",501 to 1000 employees,2011,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
816,Creative/ Data Analytics Manager,"Will be responsible for understanding various types of content that is created for a client, and data points that originate from that content (impressions / views / clicks) and help relate what content works and what does not work. Will be responsible for leading, developing and managing all aspects of Creative Analytics. This person will need to provide an overview into what content is critical, what is performing and what is under performing to senior management. They will need to be able to explain data findings and answer questions in a clear and comprehensive manner. This person will need to explain data at an aggregate level as well as at a granular level. The Manager will work with a variety of data sources to continually monitor, evaluate and report against appropriate KPIs across campaign types for multiple clients. The Manager is responsible for working with internal and external teams. Will need to provide recommendations to inform creative decisions and drive the business forward.

KEY RESPONSIBILITIES

Decipher meaningful differences in performance between creative variations, accounting for variables such as audience segments and impression volumes
Provide creative-level analysis to complement the placement-level analysis (performed by media teams) in order to generate a holistic view of campaign performance.
Provide regular and timely marketing performance analysis against communication plans.
Understand client's business goals and requirements, design and develop analytic approaches tailored to needs.
Develop client tools and services, such as dashboard development and decision aids to support programs, creative and recommended solutions.
Formulate specific and actionable insights
Recommend data strategies (e. g. what we should capture, how we should capture it, and the triggers/actions as a result, etc.).

skills and knowledge required

Understands the implications and analytic approaches with dynamically-served creative and auto-optimization platforms
Must have a firm grasp of reporting for Web site, online advertising, social media and mobile.
Proficiency with programming languages, SQL, Python or R a plus.
Familiarity platforms like Adobe Analytics, Crimson Hexagon, Sprinklr, Excel, Tableau etc
Understands creative analytics best practices.
Understands the creative process that generates content to powerfully engage customers.
Possesses well-developed analytical ability to extract insight from data and translate into creative directions
Strong attention to detail.

EDUCATION/EXPERIENCE REQUIREMENTS

5+ years of experience in marketing analytics or business intelligence (focused in analytics

Experience working for a Creative Media/Advertising agency in an analytics role or a business analyst from a top-tier strategy consulting firm.",3.7,"Social Wavelength
3.7",Mumbai,"Mumbai, India",201 to 500 employees,2009,Company - Private,Publishing,Media,Unknown / Non-Applicable,WAT Media
817,Data Analyst,"OakNorth is the next-generation credit and monitoring platform that provides banks and lending institutions with the insight and foresight needed to create a better borrowing experience for the Missing Middle – the growth business who are the backbones of communities and economies globally but who have been in banking’s blind spot for decades.

The business was founded in 2015 by Rishi Khosla and Joel Perlman, who previously co-founded Copal Amba and grew it to 3,000 employees over 12 years, before selling it to Moody’s (NYSE: MCO) in 2014, returning 125 times capital to seed investors.

Since its inception, OakNorth has secured over $1bn from several investors, including: Clermont Group, Coltrane, EDBI of Singapore, GIC, Indiabulls, NIBC, Toscafund, and SoftBank’s Vision Fund.

The Platform has been deployed at various banks across North America, Europe, and Asia, and in the UK where OakNorth lends off of its own balance sheet via OakNorth Bank. The platform has helped OakNorth Bank become the fastest-growing business in Europe according to the Financial Times FT 1000 (2020), profitably lending over £4bn to date. In terms of the impact this has had on the economy, OakNorth Bank’s loans have directly helped with the creation of 13,000 new homes and 17,000 new jobs in the UK, as well as adding several billion pounds to the economy.

With offices in London, New York, Manchester, Singapore, Hong Kong, Shanghai, Istanbul, Gurgaon and Bangalore, the global team across the OakNorth Holdings group is over 800 people.

Job Responsibilities:
Review raw financial data received in various formats and standardize its processing
Analyse and interpret acquired data from internal/external data sources and develop validations and a quality control process
Use internal proprietary tools to manipulate and migrate data into the Platform
Collaborate daily with other areas of the firm on execution of tasks
Design scalable data management and entry process solutions that can be readily implemented across the team
Model financial data to fit data templates
Perform due diligence on new sources quickly and identify data questions and concerns
Construct and maintain data dictionaries
Desired Skills:
3-6 years professional experience in a data-intensive role
Strong analytical skills
Excellent organizational skills, including attention to precise details
Have a solid working knowledge of MS Excel
Knowledge of VBA, SQL, Python, or other programing languages is a plus
Financial industry experience is a plus
Ability to handle multiple tasks, meet reporting deadlines, and demonstrate flexibility with delivery of assignments
Thank you very much for your interest in OakNorth. We are happy to consider you for roles within our group of companies. If we can identify a match between your skill set and our immediate recruiting needs, please expect to hear from us very soon. If we are unable to identify a fit in the near term, please note that we intend to retain the data you send to us so we may contact you in the future.",4.1,"OakNorth Bank
4.1",Bengaluru,"London, United Kingdom",51 to 200 employees,2015,Company - Private,Lending,Finance,Unknown / Non-Applicable,-1
818,Applied Scientist II,"PhD/Master Degree in Computer Science with experience in Deep Neural Network specialization either in Computer Vision and/or Natural Language Processing.
3+ years of hands on experience in building machine learning systems for large data sets.
Strong skills in problem solving, programming and computer science fundamentals.
Expertise in using Python programming language.
Well versed in DeepLearning Frameworks like Tensorflow, MXNet or alternatively front ends like Keras along with numpy, pandas and scikit-learn
RBS Tech is committed to support business growth across WW Retail through standardization, simplification and automation. We are developing an automated solution – ACE – to fix catalog defects. ACE uses Machine Learning/Deep Learning to fix attribute defects identified by Sherlock (auto audit platform) across Amazon’s selection that will improve customer shopping experiences. The defects are reviewed for validation and fixed, in the process helping the machine to learn.
Last year the team worked on discoverability challenges customers are facing on Amazon properties by backfilling hidden attributes by applying various deep learning techniques and an ensemble of classifiers. This year, we are working on highly ambiguous use cases like size variations problems, expanding the scope of discoverability use cases. All these use cases are ideal candidates to apply various Deep learning techniques.
We are hiring applied scientists who can creatively solve these use cases.
As an Applied Scientist in RBS ACE team, you will work with talented peers to develop novel algorithms and modeling techniques to solve these high impact issues. You will leverage Amazon’s heterogeneous data sources and large-scale computing resources to accelerate advances in artificial intelligence. You will collaborate with other scientists and work in a fast paced team environment. Your work will directly impact our customer shopping experience, save millions in concessions. You will constantly stretch the boundaries of Machine Learning to tackle business challenges.
If you are customer obsessed, self-driven, tenacious and analytical, you will have fun solving our business problems of unprecedented scale. As an experienced machine learning scientist, you will help research and develop new computer algorithms leveraging both classical and deep learning techniques.
PhDs, specialized in Information Retrieval and Machine Learning.
Experience in designing and implementing information retrieval, web mining systems using Deep Learning and Neural Networks.
Big thinker that can take broad visions and concepts and develop structured plans, actions and measurable metrics and then execute those plans.",-1,ADCI - BLR 14 SEZ,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
819,Data Engineer,"Years of Experience: 4- 9 Years

Responsibilities for Data Engineer
Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS big data technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Qualifications for Data Engineer
Experience building and optimizing big data ETL pipelines, architectures and data sets.
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing and highly scalable big data data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
Skills:

We are looking for a candidate with 3-9 years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools:
Experience with big data tools: Spark, Kafka, HBase, Hive etc.
Experience with relational SQL and NoSQL databases
Experience with AWS cloud services: EC2, EMR, RDS, Redshift
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, Scala, etc.
Qualification

Bachelor/Master degree in Computer Science Engineering, Mathematics or related.",3.3,"Altimetrik Corp
3.3",Chennai,"Southfield, MI",1001 to 5000 employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
820,Senior Data Analyst,"As a Senior Data Analyst at Tide (fondly referred to as a Tidean, a mighty challenger of the banking world) you’ll join an ambitious team of highly motivated, talented Tideans who love to collaborate, and are driven by helping people achieve their business ambitions. We live and breathe our values, which are to put our members first, work as one team and be data driven, as part of our team, they’ll matter to you too.

As part of this team, you will be working with our CRM team to help them find new offerings to differentiated customer segments. You will help them set up experiments and to evaluate the results of their campaigns. You will work closely with the decision makers of the CRM team in order to help them set the strategy.

Requirements

Let’s not beat around the bush. We’re an international scale up, we’re busy! If fast paced environments, cross team exposure, inquisitive freedom and the ability to have a real impact on a rapidly growing scale up appeals to you, then you already have the mind of a Tidean. If you have that along with the following experience, we’d love to hear from you.

The non-negotiables:
5+ years of experience in Business Intelligence or Analytics Teams
Excellent SQL Proficiency - You’re good at quickly getting a grasp of any dataset that you're working with
Excellent communication skills, specifically in demonstrating the value of data to a non-technical audience
Basic understanding of statistics
Strong data visualisation skills, including knowledge of self-serve tools like Looker, Tableau or similar
You can communicate your analyses clearly to both technical and non-technical audiences
You’re a self-starter - you take initiative in spotting opportunities and finding ways to solve challenges with data
Ability to deal with ambiguity and competing objectives in a fast paced environment
The highly desirables:
Experience in Fin-tech, a start-up or fast growing company
Experience working in subscription and/or app-based business models
Experience with CRM and mailing systems
Experience in using data for commercial use such as LTV analysis or KPI benchmarking
Experience in setting up experiments and evaluating them
Experience with NPS and reviews collection, analysis and distribution
About Tide

With over 100,000 members, we're the leading provider of SME business accounts in the UK. Why? Because we’re solving a real world problem by being passionate about helping our Members.

SME’s have been underserved and overlooked by traditional banks for years. In an entrepreneurial age where everyone is expected to take a shot, traditional banks have not evolved with the needs of the market. That’s where Tide comes in.

With quick on-boarding, low fees and innovative features, we thrive on making data driven decisions to help SMEs save both time and money.

Here’s what we think about diversity and inclusion...

Diversity is what makes our world interesting. Fact. We don’t build our product for one type of person, Tide is here for everyone. And that’s how we build our teams. We’re a melting pot of different cultures, races, religions, girls who like girls, boys who like boys and those who like both. We’re proud of the fact that we represent society and it will always be our mission to do so. Everyone here is given a voice, and if you like the sound of that, we’d encourage you to come and find your voice here, too.

Benefits

Here at Tide, not only do we love what we do, but we love the people who do it. That’s why we look after our Tideans",3.0,"Tide
3.0",Hyderabad,"London, United Kingdom",51 to 200 employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
821,Data Engineer (DataOps),"Job Summary:

The Life& Annuity Predictive Analytics (LAPA) business unit at Milliman is a lean, agile, diverse, and geographically distributed data science startup that develops leading edge data products and deploys them on the cloud as web applications for the world’s premiere life insurers.

As a key part of our DevOps team, the DataOps Engineer will take a leadership role in designing, developing, and operating our data infrastructure for web app data products.

This position is based in Gurugram, India.

Primary Responsibilities:
Work collaboratively in an Agile/Scrum team with both development and other data engineering (DataOps) team members
Design, create and maintain data pipelines
Drive automation through effective metadata management
Drive automation in data integration and management
Maintain infrastructure documentation
Contribute to new technology evaluation and continuous process improvement
Skills and Requirements:

Required:
2+ years of software engineering/DevOps/DataOps experience
Experience with SQL, RDBMS, and data warehousing
Advance query optimization skills for multiple data platforms
Experience with cloud infrastructure and managed services (Azure/AWS)
Knowledge of CI/CD tools
Deep knowledge and use of command line in Linux environment
Programming experience in any language
Experience with Hadoop, Hive, Spark and Presto
Hands-on knowledge and experience with web application delivery, cloud environments, and CI/CD
Experience in deploying data science solutions/models into production environments
Ability to work in a highly collaborative environment as well as independently with minimum supervision
Excellent written and verbal communication skills
BS degree in computer science, engineering, or other STEM field
Preferred:
Experience with Microsoft Azure (Resource Manager IaaS, storage, security, etc.)
Experience with Data Orchestration (Airflow preferred)
Experience with supporting data governance and data quality initiatives, including developing and implementing data standards, policies, practices and procedures that improve data integrity
Knowledge of performance and security test tools
Experience with the R language for statistical computing
Experience with RStudio Shiny web application framework
Experience with containerized development and deployment (Docker)
About Milliman:

Milliman is one of the world’s largest independent professional services firms. Founded in 1947, the firm provides consulting services to clients in four practice areas: healthcare, life insurance and financial services, employee benefits and pensions, and property and casualty insurance. Today, Milliman has more than 3,500 employees, nearly $1 billion in annual revenue, and more than 60 offices worldwide.

Requirements
software engineering/DevOps/DataOps experience",3.8,"Milliman
3.8",Gurgaon,"Seattle, WA",1001 to 5000 employees,1947,Company - Private,Consulting,Business Services,₹100 to ₹500 billion (INR),-1
822,Data Engineer,"We are looking for Data Engineer who has experience and interest in building IoT based Big Data Processes from design to deployment. The following expertise required to serve this position.

Location: HSR Layout, Bengaluru.

Education Qualification: BE Computer Science / MCA only.

Experience Level: 0 to 1 year experience in data engineering.
Strong knowledge and experience in Data Structures, Modeling and Algorithms
Experience in designing and building Data Processing from ingestion, storage, stream analytic, match-merge, data warehousing etc.
Prior experience in database development with Relational Database (PostgreSQL / MySQL / SQL Server) and NoSQL (MongoDB, Azure CosmoDB, Couchbase)
Experience in developing Big Data applications using Java, Spark, Hive, Oozie, Kafka, and Map Reduce is a huge plus.
Exposure in Azure Data Lake, HDInsight, DataBrick and SQL Warehouse is BIG PLUS.
Exposure in data science and machine learning tools and technologies is a plus
Demonstrate strong understanding of development processes and agile methodologies
Strong analytical and communication skills. Should be self-driven, highly motivated and ability to learn quick
If you are qualified and interested to join IoT product company, apply today.

Send your resume to : jobs@factana.com",-1,FACTANA,Bengaluru,"Bengaluru, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
823,Data Analyst,"About us.

Brave finds rising star talent for high growth companies. That means we’re always on the lookout for brilliant folks like you. We work to understand your work interests, career goals, and talents. And then put you in touch with our clients who might want to interview you. Feel free to share our details with a friend or peer. We’d be happy to link them with jobs too.

About our client.

Our client is a venture-backed technology company operating in East Africa. We build and deploy cloud-connected retail outlets, which serve as consumer access points for goods and services delivered in partnership with major suppliers. Their first consumer solution delivers significant cost savings and quality of life improvements.

If you share their passion for technology and vision for global impact and think that you will thrive in a fast-paced work environment, this is the role for you!

About your role.

As a Data Analyst, you will drive our analytics function by generating data-driven insights to guide commercial and operating strategy; developing metrics, dashboards, and statistical analyses; helping to shape our overall vision & strategy.

What You Will Do.

Build models to identify trends, forecast performance, and identify improvements to the company strategy, products, and operations
Design and run data analyses to guide decision-making
Design and prepare company dashboards and other key stakeholder reporting
Design and develop automation tools to streamline day-to-day activities
Identify and coordinate data infrastructure improvements with the software team
Drive cost-saving and increased revenue processes through data insights
Enable the success of the team members by supporting them in accessing, understanding, and utilizing data
Ensure consistency, accuracy, and overall integrity of business metrics
Develop and maintain business intelligence documentation, training materials, best practices, and overall data toolkit

Skills.

Bachelor’s degree, ideally in Computer Science, Math, Statistics, or Economics (Master's degree a plus)
Experience in data analysis, consulting, finance, or other quantitatively rigorous roles (ideally, 3-5+ years)
The ability to balance priorities, clarify stakeholder requirements, pay keen attention to detail, and generally keep deliverables on schedule
Proficiency with Tableau and/or Looker, SQL, Excel, and statistical methods (Python an added plus)
Ability to communicate technical details clearly and concisely to management & external Stakeholders
Ability to perform people and process analysis
Passion for problem-solving, data, and analytics",3.4,"Brave Venture Labs
3.4",Pune,"Nairobi, Kenya",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
824,Data Science Research Associate Opening,"4 month posision (remote) as a data science research associate

Qualification and experience:
PhD/Masters (economics, statistics, computer science or related fields, with deep expertise relevant to at least some of the problems and methods described above)
Excellent coding skills in multiple languages (R, Python, STATA)
Experience with large datasets
Experience with designing, implementing and analyzing experiments
Experience using cloud computing services such as AWS, Azure, etc.
Experience working with Github or similar tools for collaboration and version control
Experience supervising research assistants

Expected remuneration: Rs. 20,000 to Rs.30,000 (Depending upon the qualifications)

Candidate Profile:
Experience working with Github or similar tools for collaboration and version control

Experience:0-5 Years

Location:Ahmedabad

Education:PhD/Masters (economics, statistics, computer science or related fields)

Company:Indian Institute of Technology (IIT) Ahmedabad

SALARY:Rs.20,000/- to Rs.30,000/-

Last Date: Last Date to Apply is Over. : 2020-Jun-05

Key Skills: Research Fellowship

Company details

Indian Institute of Technology (IIT) Ahmedabad

Indian Institute of Technology, Palaj, Gujarat 382355",-1,Indian Institute of Technology (IIT) Ahmedabad,Ahmedabad,-1,-1,-1,-1,-1,-1,-1,-1
825,Data Analyst,"Candidate should have:
Knowledge of catastrophe data collection like Flood data, Earthquake data, Image processing data from satellite, LIDAR and Drone
Synthesizing and visualizing data for internal and external reporting

Personal Profile:
Education: MS / M tech/ M.Sc. in Geo Informatics or Environmental Science or Geology
Excellent written and verbal communication skills
Self-starter with an ability to collaborate actively with others in a cross-functional team
Problem solver and technology enthusiast
Creativity, innovation, and resourcefulness
Willingness to learn, and to innovate in a rapidly changing market
Ability to deal with ambiguity and change
""Roll-up your sleeves"" attitude to get things done

To Apply for this position send us your CV at careers@advancedRiskAnalytics.com",-1,Wayzontech Services,Pune,-1,-1,-1,-1,-1,-1,-1,-1
826,Data Modeler - Pune - Officer/C11,"The Global Functions Technology Services (GFTS) Data Services group supports the Citigroup Finance, Enterprise Risk, and Compliance. The group provides centralized expertise in data management processes and technologies in the areas of Data Architecture, Data Modeling, Data Lineage, Data Quality, Data Acquisition, Integration and Distribution.

Design, Build and Deploy Data Models across multiple diverse database platforms to meet data needs of enterprise applications in Finance and Risk Technology primarily using SDLC/SRLC methodologie . It centers on technologies such as Erwin Data Modeler, Netezza, Teradata, XML, JSON, Big Data and Oracle.

Responsibilities:
Logical and Physical Data Modelling
Develop source to target mappings (TRL (target record layout) to physical data models)
Ensure and track model deployments across all the environments/swim lines
Works with PMO to align the changes to SDLC
Provide walk through s and publishing the changes to all technology teams before every release rollout
Troubleshoot problems faced by SIT & UAT testing teams provide solutions
Acts as a steward in offshore teams, and make sure everyone is aligned to the process
PROD support on identified issues when required
Managing versioning repository
Act as effective communicator, work with different teams and Testing partners on issues
Very proficient with SQL to investigate and analyze the data Loading/transformation issues.
Qualifications:
Minimum of 5+ years experience in development of Logical and Physical data models.
Banking and finance domain experience is a plus.
Data Modelling using Erwin
UML Modeling
XML/JSON schema design
Thorough understanding of database concepts
Passion for technology and self- starter
Orientation towards Disciplined development processes
Good Modelling discipline
Team work
Good written & verbal communication skills
Ability to mentor junior team members
Education:
B.Tech, preferably in computer science. Other preferred branches are EE, ECE. Candidates with passion for data modeling and systems development from other disciplines also can apply.
This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required.

-------------------------------------------------

Grade :All Job Level - All Job FunctionsAll Job Level - All Job Functions - IN

------------------------------------------------------

Time Type :

------------------------------------------------------

Citi is an equal opportunity and affirmative action employer.
Minority/Female/Veteran/Individuals with Disabilities/Sexual Orientation/Gender Identity.

Citigroup Inc. and its subsidiaries (""Citi) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity CLICK HERE.

To view the ""EEO is the Law"" poster CLICK HERE. To view the EEO is the Law Supplement CLICK HERE.
To view the EEO Policy Statement CLICK HERE.
To view the Pay Transparency Posting CLICK HERE.",3.7,"Citi
3.7",Pune,"New York, NY",10000+ employees,1812,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
827,CPU Architecture Research Scientist,"Job Title : CPU Architecture Research Scientist
Job Location : Bangalore, India.
Job Description :

A world-class research lab that excels at novel product development through fundamental architecture research looking for highly qualified, dynamic senior level researchers in the area of Microprocessor Architecture
The goal is to reposition the trajectory of todays CPU Cores towards much greater power and area efficiency while delivering industry-leading performance
All Research Scientists will advance the state-of-the-art in deep collaboration with product architecture/design teams while also contributing to scientific literature/conferences and developing Intellectual Property
Main responsibilities CPU Architecture Researchers will be responsible for power/area/performance driven architecture, microarchitecture development and optimization
Strong software expertise in C++/Perl/Python and experience building architecture simulators or system software is very relevant to most of these roles
Qualification :

- Must have a PhD in EE/CS
Research background and an inclination for out-of-the-box disruptive thinking is a big plus
Job Posted : 2017-11-27",-1,Approgence,Bengaluru,"Irvine, CA",1 to 50 employees,2006,Company - Private,IT Services,Information Technology,₹500 million to ₹1 billion (INR),-1
828,Data Engineer,"Requirements
2+ years of experience in DBMS domain
Proven SQL Server 2008/2012 skills
Responsibilities
Development of methodologies and tools to extract/update data from different data sources and put it into database",4.0,"Knoema
4.0",Bengaluru,"Washington, DC",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
829,Data Analyst,"We are looking for Data Analyst
a. Expert in Microsoft Excel - Vlookup, Pivot tables, Graphs and Charts
b. Experience in MIS work
c. Qualification - Graduation in Statistics
d. Overall experience - 4-5 yrs
Interested Candidate please contact on 8424876189
Job Type: Full-time",4.0,"SynergyConnect Data Innovation Pvt. Ltd
4.0",Maharashtra,"Mumbai, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
830,Web / Data Analyst,"Job Summary
Work with website analytical tools such as Google Analytics and others as necessary.
Analyse digital data across web/mobile/social channels.
Identifying actionable insights.
Measuring campaign performance and market trends across digital channels.
Seek out and review new analytics tools that would benefit the business
Defining and analysing KPI’s to aid key strategic decisions.
Becoming a key Google Analytics user driving the positive use of digital analytics.
Ensure the accuracy of data and reports to ensure the highest quality of standards.
Provide analysis around customer behaviour, product performance and conversions, promotion impact, industry & competitor trends.
Required Skills
Must have excellent analytical and problem solving skills.
Strong marketing/analytical acumen and experience.
Excellent command of the English language both written and spoken.
Proven e-commerce experience with understanding and exposure to the different marketing channels and how they affect each other.
An understanding of Google Analytics / PPC / Affiliate Marketing and SEO.
Experience in analysing data and drawing out insights from that analysis.
The ability to understand customers and their individual needs.
Results orientated individual.
Self-motivated and self-starter.
The Benefits
Established company with great financial stability.
International luxury offices in Vadodara, Gujarat.
Fast personal and career development.
World class training.
International travel opportunities.
Service recognition awards.
Market leading salary packages.
Accommodation in company guest house.
Bonus plans.
Regular social activities.
Management developed from within.
Unrivalled team working dynamics.
Develop ground breaking technology.
Innovative forward thinking organisation.",4.4,"Darshan Soft-Tech
4.4",Vadodara,"Vadodara, India",51 to 200 employees,2006,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
831,Engineering/ Data Science/ Product Intern,"Interns- Java/Android/iOS/Testing
Product
Data Science
Opportunity to work full time based on performance during internship period.",3.5,"Lybrate
3.5",New Delhi,"Faridabad, India",51 to 200 employees,2014,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
832,Data Analyst,"Parity Computing , a unit of RELX/Elsevier, is inviting applications for data analyst positions for its OrgDB product to curate organization metadata and name variants to help produce excellent organization publication profiles. The work involves investigating research organizations and their structure to extract and normalize data, interpreting the metadata policies, deciding the best approach to curate the data, and analyzing the impact of curation on organization publication profiles. We are looking for individuals who can conduct excellent research, work independently, and pay attention to detail. Premium is placed on those individuals who can produce a high-quality content.

Parity’s OrgDB product is the leading authoritative database of the world’s research producing organizations. OrgDB powers STM industry applications for characterizing organizations and accurately attributing their research works.

Required skills

Able to think analytically, use a systematic and logical approach to analyze data, problems and situations.,

Familiarity with scientific research, publications, universities and research organizations,

Ability to perform independent research on topics related to the structure of and relationships among universities and research organizations,

Ability to think abstractly and collect and classify entities such as person and organization names, organizational structure, scientific expertise, and related entities,

Ability to interpret policies, follow them consistently, develop positive and negative examples for each policy, and assist in fine tuning policies

Ability to assess the quality, completeness, and other characteristics of the content

Preferred qualifications

Post Graduation
Outstanding oral and written communication skills
Skills in working with databases, software tools, and modeling languages such as XML.
Demonstrated ability to meet deadlines
Excellent planning, organizational, and time management skills.
Ability to work under pressure and meet deadlines
Elsevier is an equal opportunity employer: qualified applicants are considered for and treated during employment without regard to race, color, creed, religion, sex, national origin, citizenship status, disability status, protected veteran status, age, marital status, sexual orientation, gender identity, genetic information, or any other characteristic protected by law. If a qualified individual with a disability or disabled veteran needs a reasonable accommodation to use or access our online system, that individual should please contact 1.877.734.1938 or accommodations@relx.com.

Elsevier is a global information analytics business that helps institutions and professionals progress science, advance healthcare and improve performance for the benefit of humanity. We help researchers make new discoveries, collaborate with their colleagues, and give them the knowledge they need to find funding. We help governments and universities evaluate and improve their research strategies. We help doctors save lives, providing insight for physicians to find the right clinical answers, and we support nurses and other healthcare professionals throughout their careers.Elsevier provides digital solutions and tools in the areas of strategic research management, R&D performance, clinical decision support, and professional education; including ScienceDirect, Scopus, SciVal, ClinicalKey and Sherpath. Elsevier publishes over 2,500 digitized journals, including The Lancetand Cell, more than 35,000 e-book titles and many iconic reference works, including Gray?s Anatomy. Elsevier is part of RELX Group, a global provider of information and analytics for professionals and business customers across industries. Elsevier employs over 7,000 people in more than 70 offices worldwide. We are an employer of choice, attracting and developing talented and creative people who thrive in a challenging and fast-paced environment. We offer an excellent compensation and benefits package as well as a real opportunity for career growth in a growing organization.",3.7,"RELX Group
3.7",Bengaluru,"London, United Kingdom",10000+ employees,1880,Company - Public,Enterprise Software & Network Solutions,Information Technology,₹500+ billion (INR),-1
833,Associate Scientist,"Associate Scientist
Location


Hyderabad, India

Requisition Number

IN5021-3450-R

Apply Now

Position Overview


Nektar Therapeutics is seeking to hire an Associate Scientist/Sr. Research Associate with specialization in Biologics to join their Bioanalytical Development Team.

Position Summary:

We are seeking a highly motivated scientist with hands-on experience in Ligand Binding Assay (LBA) development. The individual will join the Global Bioanalytical Organization and play an active role in the development of LBA assays for early stage research, preclinical and later-stage development programs. He/she will have a strong background in immunoassay and bioanalytical PK assays with a good understanding to develop a robust assay. Ideally, he/she will have developed immunoassays for novel protein-polymer, where completely new methodologies may be needed. The successful candidate will develop, design and conduct studies in immunoassay or other assay-based protein quantitation from plasma, serum, or other complex matrices. Experience in transferring methods to CROs for GLP assay development is highly desirable. The ideal candidate will be able to work with robotic liquid handling systems, including programming and validating results from automated systems. The ideal candidate will be independent, have excellent interpersonal skills and will thrive in a goal-oriented, team environment. The ability to manage multiple teams and multiple tasks across different sites is a plus.

Responsibilities
Develop appropriate immunoassays for new chemical entities and biomarkers using ELISA and MSD platform to quantify proteins in complex matrices such as plasma or serum. Independently design and conduct experiments, and interpret and summarize data. Must be able to think creatively about assay development.
Perform Method validation and sample analysis as per regulatory bioanalytical guidance/ industry practices/internal SOPs.
Ensure activities conducted in the bioanalytical lab are in compliance with established SOPs, procedures, systems, regulatory guidance without deviating from established procedures.
Regular interaction with QA (Quality Assurance) during data and reports review, closure of observations, reports sign off and archival.
Ensure timely calibrations and maintenance of equipment.
Collaborate with other members of the Bioanalytical team, and Research Biology and Pharmacology teams.
Ensure assay robustness to allow successful inter lab transfer for GLP assay development Program and validate liquid handling systems for high throughput assay methods.
Interpret results – anticipate and understand the issues related to the assay.
Participate in, and present data to project teams. Communicate with research management on a regular basis and assist with development of research goals and strategies.
May need to manage and supervise junior scientists to perform routine BA lab operation.
Requirements:
A recent Ph D or M/.Sc or MPharm in Pharmacy, Biochemistry, Protein Chemistry, Analytical Biochemistry, Chemistry, Analytical Chemistry with 5-9 years work experience in a research and/or development environment is required.
Expertise in a broad range of immunoassay techniques, including excellent liquid handling skills, both manual and robotic.Must be detail-oriented and able to conduct experiments in a precise and accurate manner.
Expertise in bioanalytical method development using LBA techniques, excellent technical and problem-solving capabilities.
Must have good knowledge on Good Laboratory Practices (GLP) procedures and bioanalysis related guidance documents on OECD, USFDA and EMA.
Ability to work with CROs for technology transfer.
Ability to summarize and present the data.
Able to think creatively and strategically within his/her area of expertise.
Possesses excellent oral and written communication skills.
Hands on experience on LC-MS/MS and electronic data management like LIMS, eLN will be considered an added advantage
We are an Equal Opportunity Employer and do not discriminate against applicants due to race, ethnicity, gender, veteran status, or on the basis of disability or any other federal, state or local protected class. Nektar Therapeutics will consider for employment qualified applicants with criminal histories in the manner proscribed by the San Francisco Fair Chance Ordinance.",3.5,"Nektar Therapeutics
3.5",Hyderabad,"San Francisco, CA",201 to 500 employees,1990,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹10 to ₹50 billion (INR),"Bristol Myers Squibb, Merck, GlaxoSmithKline"
834,Data Analyst,"Designation : Data Analyst
Qualification: BA English / BA English Literture
Experience : Fresher
Salary: 1.2-1.65 Lakh PA
Industry : Online Technology /Internet
Location: Mumbai
Skills : Excellent written and verbal Communication, MS Office
Job Role & Responsibilities

Verification of Social Media posts.
Tagging of Social Media posts accurately as per Topics and Sentiments of the post
Prepare Power point presentation and Excel reports and Analysis
Knowledge of various Social media and other websites
Note: This is a Contract Based job (1 Year – renewal based on performance)

Working Days : 5 Days a Week (9:00 AM to 5:00 PM)
Job Nature : Full Time
If You are interested apply here, Please feel free to get in touch with us for",-1,smart4talent,Mumbai,"Faridabad, India",1 to 50 employees,2009,Company - Private,Staffing & Outsourcing,Business Services,₹10 to ₹50 million (INR),-1
835,"SDE- III, Data Engineer- Glance","SDE- III, Data Engineer- Glance

Who are we and What do we do?

Glance – An InMobi Group Company:

Glance is an AI-first Screen Zero content discovery platform, and it's scaled massively in the last few months to one of the largest platforms in India. Glance is a lock-screen first mobile content platform set up within InMobi. The average mobile phone user unlocks her phone >150 times a day. Glance aims to be there, providing visually rich, easy to consume content to entertain and inform mobile users - one unlock at a time. Glance is live on more than 80 millions of mobile phones in India already, and we are only getting started on this journey! We are now into phase 2 of the Glance story - we are going global!

Roposo is part of the Glance family. It is a short video entertainment platform. All the videos created here are user generated (via upload or Roposo creation tools in camera) and there are many communities creating these videos on various themes we call channels. Around 4 million videos are created every month on Roposo and power Roposo channels, some of the channels are - HaHa TV (for comedy videos), News, Beats (for singing/ dance performances) along with a For You (personalized for a user) and Your Feed (for videos of people a user follows).

What's the Glance family like?

Consistently featured among the ""Great Places to Work"" in India since 2017, our culture is our true north, enabling us to think big, solve complex challenges and grow with new opportunities. Glanciers are passionate and driven, creative and fun-loving, take ownership and are results-focused. We invite you to free yourself, dream big and chase your passion.

What can we promise?

We offer an opportunity to have an immediate impact on the company and our products. The work that you shall do will be mission critical for Glance and will be critical for optimizing tech operations, working with highly capable and ambitious peer groups. At Glance, you get food for your body, soul, and mind with daily meals, gym, and yoga classes, cutting-edge training and tools, cocktails at drink cart Thursdays and fun at work on Funky Fridays. We even promise to let you bring your kids and pets to work.

What will you be doing?
Designing, developing, constructing, installing, testing and maintaining the complete data management & processing systems.
Building highly scalable, robust, fault-tolerant, & secure user data platform adhering to data protection laws.
Taking care of the complete ETL (Extract, Transform & Load) process.
Ensuring architecture is planned in such a way that it meets all the business requirements.
Exploring new ways of using existing data, to provide more insights out of it.
Proposing ways to improve data quality, reliability & efficiency of the whole system.
Creating data models to reduce system complexity and hence increase efficiency & reduce cost.
Introducing new data management tools & technologies into the existing system to make it more efficient.
Setting up monitoring and alarming on data pipeline jobs to detect failures and anomalies
What do we expect from you?
BS/MS in Computer Science or equivalent experience
5 years of recent experience in Big Data Engineering.
Good experience in working with Hadoop and Big Data technologies like HDFS, Pig, Hive, Zookeeper, Storm, Spark, Airflow and NoSQL systems
Excellent programming and debugging skills in Java or Python.
Apache spark, python, hands on experience in deploying ML models
Has worked on streaming and realtime pipelines
Experience with Apache Kafka or has worked with any of Spark Streaming, Flume or Storm
Why Join Us?

You will contribute to creating disruptive and innovative consumer experiences using technology. We value autonomy, collaboration, technical innovation and results-oriented thinking. Glance's culture is all about rewarding excellence so there are fantastic opportunities for the right candidates!",4.0,"Glance
4.0",Bengaluru,"Hyderābād, India",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
836,Data Engineer,"· Mission statements

o Responsible for building the pipelines and tools in the DARWIN environment

o Produce data sets for specific analysis projects, dashboards and applications, and general reuse.

o Identify data engineering needs and implement optimal solutions.

o Provide subject matter expertise to other users who are working in the DARWIN environment.

People

o Maintain effectiveness relationships with the end stakeholders with an end objective to develop education and communication content as per requirement

o Interact effectively with healthcare professional on publications content

o Constantly assist other writers in developing knowledge and sharing expertise

Performance

o Create and maintain optimal data pipelines using Sanofi’s data platform and infrastructure

o Assemble large, complex data sets that meet the needs of data analysts and data scientists as per agreed timelines and quality

o Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.

o Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.

o Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.

o Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.

o Create data tools for analytics and data scientist team members that facilitate their discovery, access and use of data.

Process

o Build processes supporting data transformation, data structures, metadata, dependency and workload management.

o Successfully manipulate, process and extract value from large disconnected datasets.

o Bring Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.

Stakeholders

o Work with data and analytics experts to strive for greater functionality in our data systems.

o Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.

Knowledge, Skills & Competencies / Language

o 5+ years of experience in a Data Engineer role

o Experience supporting and working with cross-functional teams in a dynamic environment.

o Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.

o Strong project management and organizational skills.

o Strong analytic skills related to working with unstructured datasets.

o Excellent English language knowledge

Qualifications

o Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field

Requirements of the job

o Experience and knowledge PySpark programming

o Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.

o Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.

o Build processes supporting data transformation, data structures, metadata, dependency and workload management.

o A successful history of manipulating, processing and extracting value from large disconnected datasets.

o Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.

At Sanofi diversity and inclusion is foundational to how we operate and embedded in our Core Values. We recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our colleagues, patients and customers. We respect and celebrate the diversity of our people, their backgrounds and experiences and provide equal opportunity for all.",3.7,"Sanofi
3.7",Hyderabad,"Paris, France",10000+ employees,1973,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Pfizer, GlaxoSmithKline"
837,Data Engineer III,"About us

If youre thinking scale, think bigger and dont stop there. At Walmart Labs Chennai, we dont just innovate, we enable transformations across stores and different channels for the Walmart experience. Take a regular day at Walmart Labs and match that with 260 million customers a week, 11,695 stores, under 59 banners in 28 countries and e-commerce websites in 11 countries. Thats Walmart Labs Chennai for you. With fiscal year 2019 revenue of $514 billion, Walmart employs approximately 2.3 million associates worldwide. We innovate to deliver a simple and seamless experience for our customers. Our tech talent solves the biggest and most complex problems. They drive digital transformation where data and analytics are enabling us to better serve our customers and create a digital relationship with them. As our customers evolve and adapt, we are taking it a few notches further here. Were changing what customers can expect from the experience of shopping, from the physical stores, to mobile, social and even online; were not just ready for the future of shopping, were creating it.

Our Ideal Candidate

You have a deep interest and passion for technology. You love writing and owning codes and enjoy working with people who will keep challenging you at every stage. You have strong problem solving, analytic, decision-making and excellent communication with interpersonal skills. You are self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities.

Your Qualifications
Bachelor's Degree or Masters Degree with 3+ years of experience in Computer Science or related field.
Experience in ETL and Expertise in SQL.
Expertise in Big Data Ecosystem with experience in Hadoop, Hive, Spark, Strome, Cassandra, NoSQL DBs.
Expertise in MPP architecture and knowledge of MPP engine (Spark, Impala etc).
Data pipeline/workflow management tools such as Azkaban, Airflow and oozie
Cloud Development experience
Experience in building scalable/highly available distributed systems in production.
Understanding of stream processing with knowledge on Kafka.
Knowledge of Software Engineering best practices with experience on implementing CI/CD, Log aggregation/Monitoring/alerting for production system.
Very good expertise in production support related activities (issue identification, resolution)
Our Team

The Global Data Organisation @ Walmart Labs in Chennai provides Data Foundation Infrastructure, Visualization Portal, Machine Learning Platform, Customer platform and Data Science products that form part of core platforms and services that drive Walmart business. The group also develops analytical products for several verticals like Marketing, Finance, Supply chain, Pricing, Customer, HR etc.

Our team which is part of GDO, Chennai is responsible for creating and maintaining the Global Data Lake wherein we build the global data domain data for Walmart customers across the Globe and shopping in various ways like in Brick and Mortar Store, dot com, mobile etc. The team is responsible for time critical, business critical and highly reliable systems that influence Walmart business. The team is spread over multiple locations and we work towards providing the best experience to our customers.

Your Opportunity

As part of the Global Data Engineering Team @Walmart Labs, youll have the opportunity to make a difference by being a part of Support and Development team that helps in building best shopping experience for Walmart Customers at our Stores and online. Here you are also required to continuously innovate to lower the development cost, provide greater value to the business and provide best experience to our Business partners and Customers.

Your Responsibility

· Develop high performance and scalable solutions that extract, transform, and load big data.
Design, build, test and deploy cutting edge solutions at scale, impacting millions of customers worldwide drive value from data at Walmart Scale
Experience performing root cause analysis on data and processes to answer specific business questions and identify opportunities for improvement.
Experience building and optimizing big data data pipelines, architectures and data sets involving petabyte and terabyte of data.
Interact with Walmart engineering teams across geographies to leverage expertise and contribute to the tech community.
Engage with Product Management and Business to drive the agenda, set your priorities and deliver awesome product features to keep platform ahead of market scenarios.
Closely interact with Data Engineers from within Walmart to identify right open source tools to deliver product features by performing research, POC/Pilot.
Engage with Product Management and Business to support and build data solutions and develop expertise w.r.t data thereby being known as the true data analyst.
Engage with the engineering team to provide seamless production support.",3.3,"Walmart
3.3",Chennai,"Bentonville, AR",1001 to 5000 employees,1962,Company - Public,"Department, Clothing, & Shoe Shops",Retail,₹500+ billion (INR),"Target, Costco Wholesale, Amazon"
838,Data Engineer,"GALE is a business agency that brings together an equal balance of business consulting expertise & agency creativity to solve the world’s most complex marketing challenges. We operate without silos to deliver innovative business strategy, data insights, and transformative creative work. We work best with brands that are looking to solve tomorrow’s problems, today. GALE is a global company with offices located in New York, Toronto, Singapore and Bengaluru.

If you’re driven by a passion to build something great, a desire to innovate, and a commitment to achieve excellence in your craft, GALE is a great place for you.

About the role

As a Data Engineer, you will design, develop and deploy scalable, high volume batch and real-time data solutions for scaling of AdTech / MarTech solutions. You will build and deploy large scale data processing pipelines in a production environment.

About you
You have a Bachelor's degree in Math / Statistics / Engineering or other equivalent quantitative disciplines
A minimum of 3 years of relevant work experience building and deploying large scale data processing pipelines in a production environment
Proficiency in Python and Lambda architecture is a must
Experience with building real-time data pipelines using Flink / Faust / Kafka / Spark / Storm / Kinesis streams is a must for real-time use cases such as complex event processing and real-time dashboards
Experience integrating Machine Learning / Artificial Intelligence / Deep Learning models into real-time and batch data pipelines
Knowledge of how to use underlying AWS / Azure / GCP offerings. An understanding of services similar to EC2, EMR, S3, MKS, CloudWatch, Redshift, and Athena supported by additional open-source Apache libraries and frameworks as required (I.e. Oozie, Airflow, Beam, and Nifi)
Experience with AdTech / MarTech use cases such as a single view of the customer and related problems such as online and offline customer profile unification, data cleansing, deduping, real-time loyalty rewards, real-time content personalization, and recommendations is ideal
Experience with high performance, in memory, and time-series databases (i.e RocksDB, Redis, and InfluxDB)
Strong communication skills with the ability to be client-facing and work in a consulting environment is essential
You should be analytical, creative, and passionate about building and maintaining best-in-class data infrastructures
What you’ll be doing
Design, develop, and deploy scalable, high volume batch, and real-time data solutions (dashboards, data feeds, and Machine Learning / Artificial Intelligence algorithms) for scaling / sustainability of AdTech / Martech solutions.
Design and build infrastructure that allows big data to be accessed and analysed
Develop data set processes for data modelling and mining
Synthesizing real-time analytics such as real-time DSL and windowing",3.3,"GALE Partners
3.3",Bengaluru,"New York, NY",201 to 500 employees,2014,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
839,Data Analyst,"We are looking for a passionate Data Analyst to turn data into information, information into insight and insight into business decisions. You will conduct full lifecycle activities to include requirements analysis and design, develop analysis and reporting capabilities, and continuously monitor performance and quality control plans to identify improvements.
Responsibilities
Inspect, clean, transform and model data with the goal of discovering useful information
Interpret data, analyze results using statistical techniques and provide valuable insights in the form of reports.
Identify, analyze, and interpret trends or patterns in complex data sets.
Develop and implement data collection systems and other strategies that optimize statistical efficiency and data quality. Acquire and maintain databases/data systems
Work closely with management to prioritize business and information needs.
Locate and define new process improvement opportunities.
Skills and Qualifications
Minimum 5 years of working experience as a data analyst.
Degree in Mathematics, Economics, Information Management or Statistics.
Technical expertise regarding data models, database design development, data mining and segmentation techniques.
Strong knowledge of and experience with reporting packages (Business Objects etc), databases (SQL etc), programming (XML, Javascript, or ETL frameworks).
Knowledge of statistics and experience using statistical packages for analyzing large datasets (Excel, SPSS, SAS etc).
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.
Adept at queries, report writing and presenting findings.
To apply, please submit a cover letter, resume and portfolio to jobs@voice-over.co Submissions without a cover letter & resume or portfolio will not be considered.",-1,Voiceover,Gurgaon,"New York, NY",Unknown,-1,Unknown,-1,-1,Unknown / Non-Applicable,-1
840,Satellite Data Analyst,"Company Description

Robert Bosch Engineering and Business Solutions Private Limited (RBEI) is a 100% owned subsidiary of Robert Bosch GmbH. We are one of the world’s leading global suppliers of technology and services, offering end-to-end Engineering, IT, and Business Solutions.

With a global footprint and presence in US, Europe, Japan, China, and the Asia Pacific region, we are at the forefront of designing, developing, and executing IoT ecosystems through our all-encompassing capability within the 3 aspects of IoT – Sensors, Software, and Services.

We have always focused on improving the quality of the life of people, providing newer revenue-generating opportunities, and improving operational efficiencies for enterprises through an array of solutions. With our unique ability to offer end-to-end solutions that connect Sensors, Software, and Services, we enable businesses to move from the traditional to digital, or improve businesses by introducing a digital element in their products and processes.

Job Description
Experience in image processing, time series analysis and predictive analytics
Creation of geospatial AI algorithms and its automation
Experience with Python machine learning and deep learning libraries such as Scikit-learn, Pandas, PyTorch/FastAI, or TensorFlow/Keras
Experience in implementation of algorithms in cloud platforms
Understanding of machine learning as well as deep learning techniques and algorithms such as k-NN, Naive Bayes, SVM, Random Forests, CNNs, RNNs, LSTMs.
Ability to design and implement deep learning models for object detection, semantic and instance segmentation, GANs.
Experience in data visualization in Jupyter Notebooks using matplotlib and other libraries.
Experience with Hyper parameter-tuning and training models to a high level of accuracy.
Ability to perform data extraction, transformation, loading from multiple data sources and sinks.
Develop and train deep learning models for computer vision problems such as object detection, image classification, tree detection, building footprint segmentation, and 3D point cloud segmentation.
Validate deep learning and geospatial analysis models, tools, and Python APIs
Qualifications
Masters/Ph.D degree in Computer Science and Data science
Able to implement and write processing scripts in R or Python.
Strong knowledge and work experience on different types of models like Static, Statistical, Mechanistic, Deterministic, Stochastic, Descriptive, Explanatory Dynamic Simulation models and apply them for crop modeling to analyze the outcomes.
Result-oriented mid-career scientist with at least 6-8 years of relevant working experience.
Additional Information
Personal Characteristics
Confident, flexible, solution driven.
An inquisitive mind that is not afraid to explore new roads and take initiative.
Good analytical and problem solving skills, with eye for detail.
Ability to work independently and work well in a multi-disciplinary and international team.
Well organized, keeping to deadlines, pro-active and responsible.",4.1,"Bosch Group
4.1",Bengaluru,"Gerlingen, Germany",10000+ employees,1886,Company - Private,Computer Hardware & Software,Information Technology,₹500+ billion (INR),-1
841,Data Analyst,"Data Analyst Responsibilities:
Managing master data, including creation, updates, and deletion.
Managing users and user roles.
Provide quality assurance of imported data, working with quality assurance analyst if necessary.
Commissioning and decommissioning of data sets.
Processing confidential data and information according to guidelines.
Helping develop reports and analysis.
Managing and designing the reporting environment, including data sources, security, and metadata.
Supporting the data warehouse in identifying and revising reporting requirements.
Supporting initiatives for data integrity and normalization.
Assessing tests and implementing new or upgraded software and assisting with strategic decisions on new systems.
Generating reports from single or multiple systems.
Troubleshooting the reporting database environment and reports.
Evaluating changes and updates to source production systems.
Training end users on new reports and dashboards.
Providing technical expertise on data storage structures, data mining, and data cleansing.
Data Analyst Requirements:
Bachelor’s degree from an accredited university or college in computer science.
Work experience as a data analyst or in related field.
Ability to work with stakeholders to assess potential risks.
Ability to analyze existing tools and databases and provide software solution recommendations.
Ability to translate business requirements into non-technical, lay terms.
High-level experience in methodologies and processes for managing large scale databases.
Demonstrated experience in handling large data sets and relational databases.
Understanding of addressing and metadata standards.
High-level written and verbal communication skills.
Job Type: Full-time

Salary: ₹198,000.00 to ₹414,000.00 /year

Experience:
data Analyst: 1 year (Preferred)
total work: 2 years (Preferred)
Education:
Bachelor's (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,Futurios Technologies,Bengaluru,"Newbury, United Kingdom",1 to 50 employees,-1,Self-employed,-1,-1,Unknown / Non-Applicable,-1
842,Data Engineer,"Responsibilities:
Leverage data engineering experience to build data platforms and promote data-driven solutions.
Develop data driven apps on one of the largest data repositories in existence.
Balance independent and collaborative problem-solving.
Communicate findings and results with the team.

Requirements:
2-5 years of industry experience.
BS or MS degree in Computer Science.
Mastery in developing data solutions using SQL, Hive, HDFS, Spark and data modeling.
Detailed experience in Unix and Shell Scripting.
Experience in any one of the languages: Java and/or Python/Scala.
Hands on experience with cloud technologies: AWS/GCP.
Expertise in debugging and troubleshooting code.
Experience in optimizing data pipelines.
Experience in deploying models to production.
Strong presentation and communication skills.",-1,hudsondata.com,Gurgaon,-1,-1,-1,-1,-1,-1,-1,-1
843,Data Analyst,"Minimum 5 years team lead Experience in data analyst role
Experience participating in technology implementation projects
Experience with Microsoft SQL,Server,multi dimensional analytics (MDA)/online analytical Processing
Experience with reporting application solutions
Job Type: Full-time

Experience:
Data analyst/Developer: 5 years (Required)",-1,DaivikTechnologies,Kochi,-1,-1,-1,-1,-1,-1,-1,-1
844,Data Analyst,"Walk-in interview/ Written Test

Data Analyst

Number of posts: 1 (One) ;UR-1

Essential qualification: Degree in computer application with two years of work experience in related field. should be proficient in data analysis and statistical packages.

Age limit: Not exceeding 40 years

Emoluments: Consolidated salary Rs.30,000/- p.m

Nature of Duties: Data entry and analysis involved in NTEP; including wage of NIKSHAY 7 LMS applications.

Place of posting: Chennai

Duration: Initially for a period of one year

Experience:2 Years

Location:Chennai

Education:Degree in computer application

Company:ICMR- National Institute for Research in Tuberculosis

SALARY:Rs.30,000/- p.m

Last Date: Last Date to Apply is Over. : 2020-May-21

Key Skills: Walk-in written test

Company details

ICMR- National Institute for Research in Tuberculosis

ICMR- National Institute for Research in Tuberculosis Deartment of Health Research, Ministry of Health and Family Welfare, Government of India",3.4,"ICMR- National Institute for Research in Tuberculosis
3.4",Chennai,"Chetput, India",51 to 200 employees,-1,Government,-1,-1,Unknown / Non-Applicable,-1
845,Data Engineer II,"Do you want to be in the forefront of engineering big data solutions that takes Transportation models to the next generation? Do you have a solid analytical thinking, metrics driven decision making and want to solve problems with solutions that will meet the growing worldwide need? We are looking for top notch Data Engineers to be part of our world class Transportation Business Intelligence team. We are building real time analytical platforms using big data tools and AWS technologies like Hadoop, Spark, EMR, SNS, SQS, Lambda, Kinesis Firehose, DynamoDB Streams.
The ideal candidate relishes working with large volumes of data, enjoys the challenge of highly complex technical contexts, and, above all else, is passionate about data and analytics. He/she is an expert with data modeling, ETL design and business intelligence tools and passionately partners with the business to identify strategic opportunities where improvements in data infrastructure creates out-sized business impact. He/she is a self-starter, comfortable with ambiguity, able to think big (while paying careful attention to detail), and enjoys working in a fast-paced and global team. It's a big ask, and we're excited to talk to those up to the challenge!
· 4-7 years of experience performing quantitative analysis, preferably for an Internet with large, complex data sources.
· Hands-on experience on Big data technologies and frameworks. Hive / Spark / Hadoop, SQL on Big Data / Redshift
· Experience in near real time analytics
· Experience with scripting languages i.e. Python, Perl, etc.
· Experience with ETL, Data Modeling, and working with large-scale datasets. Extremely proficient in writing performant SQL working with large data volumes
· Ability to manage competing priorities simultaneously and drive projects to completion.
· Bachelor's degree or higher in a quantitative/technical field (e.g. Computer Science, Statistics, Engineering).
· Experience with large scale data processing, data structure optimization and scalability of algorithms a plus

Basic Qualifications

· 3+ years of experience as a Data Engineer or in a similar role
· Experience with data modeling, data warehousing, and building ETL pipelines
· Experience in SQL
· 4-7 years of experience performing quantitative analysis, preferably for an Internet with large, complex data sources.
· Hands-on experience on Big data technologies and frameworks. Hive, Spark, Hadoop, SQL on Big Data, Redshift
· Experience in near real time analytics
· Experience with scripting languages i.e. Python, Perl, etc.
· Experience with ETL, Data Modeling, and working with large-scale datasets. Extremely proficient in writing performant SQL working with large data volumes
· Ability to manage competing priorities simultaneously and drive projects to completion.
· Bachelor's degree or higher in a quantitative/technical field (e.g. Computer Science, Statistics, Engineering).

Preferred Qualifications


· Experience with large scale data processing, data structure optimization and scalability of algorithms a plus
Amazon is an Equal Opportunity-Affirmative Action Employer Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation",4.2,"Amazon
4.2",Hyderabad,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
846,Data Analyst,"Data Analyst
Organization:
Foundation for Innovative New Diagnostics (FIND) is established in India as an independent non-profit created under Section 8 (Indian) Companies Act, 2013 with its office in New Delhi. FIND India is the key implementing partner of Central TB Division, Ministry of Health & Family Welfare, Government of India, for strengthening and expanding TB laboratory diagnostic capacity within the Revised National TB Control Program (RNTCP) supported by the Global Fund. FIND India is a subsidiary of FIND, an international non-profit organization based in Geneva, Switzerland. The organization is dedicated to activities that result in: 1) new diagnostic tools; 2) expanded access to these tools; and 3) strengthened diagnostic testing capacity for poverty-related diseases in low- and middle-income countries.
Your mission/Overall objective:
Viral hepatitis in India is increasingly recognized as a serious public health problem resulting in significant health, social and economic burdens on the affected individuals, their families, as well as the country’s health system. Despite significant progress in the availability of treatment, access to diagnosis remains a major challenge in the path to elimination. Global data suggests a higher prevalence and transmission of infectious diseases such as tuberculosis (TB), human immunodeficiency virus (HIV), syphilis, hepatitis B virus (HBV), and HCV among prisoners. Studies have found that HCV infection prevalence in prisons is higher than in normal population, ranging from 3.1% to 38% depending on HCV endemicity in the geographical location of the prison.
FIND will conduct Hepatitis C micro-elimination through screening followed by confirmatory HCV diagnosis among prison inmates in Punjab and take further appropriate action under the Government of Punjab and prisons department. The intervention will cover 9 Central and 10 district prisons of Punjab with an estimated 21,400 in-mates during the project period. Experience across the prisons will help to establish capacity to expand HCV diagnosis and treatment coverage to sub-district levels beyond project period.

For more information about the organization, please visit http://www.finddx.org/

Location: Chandigarh

Your responsibilities:

Specifically, key responsibilities will include, but are not limited to, the following:

1. Understand and apply the FIND India data management protocols to relevant projects
Collect, compile and analyze site level data as per the project mandate. Ensure accuracy and completeness of data fields in all databases
Ensure follow-up on getting and digitizing the treatment cards and screening logs from across all prison sites.
Compiling of screening and treatment initiation reports on daily basis for all the project sites.
Weekly follow-up for the patients due for treatment linkage, drug dispensing and SVR and maintaining the logs
Support source data verification as and when required across all project sites.
Consolidate report on a monthly basis in the prescribed format.
Maintain appropriate databases & stocks of consumables and ensure accuracy and completeness in all recording and reporting.
Present analytical findings to internal and external partners in a professional manner.
Monitor and support maintenance of project MIS at the state level. Provide analytical support to the state and national project team
Any other job assigned by project lead as per project need

Desired Experience and qualifications:
Bachelor’s degree in computer science, information management or related field
Minimum of 2 - 3 years relevant work experience in public health, management consulting, pharmaceutical or other industries requiring a high level of quantitative /analytical skills
Advanced problem solving, analytical, and quantitative skills, including significant experience working in Excel (modeling)
Ability to handle multiple tasks simultaneously, set priorities, and work independently and flexibly with a strong commitment to excellence
Entrepreneurial mindset and demonstrated ability to perform consistently at a high level in unstructured, high-pressure situations
Exceptional written and verbal communication skills in English
Nature of Appointment:
The selected candidate shall be initially offered a consultancy contract until December 2020. The position will be prolonged subject to satisfactory performance, project extension and fund availability.
Compensation offered:
The gross remuneration budgeted for the position shall be commensurate with the qualifications, experience and salary history, of the selected candidate.
Please mail a motivation letter, a detailed resume and three references to the email address provided. Deadline to send your application: 18 June 2020
(But don’t wait until the deadline! We will start screening right away and if we find the right person, we will stop searching.)
Please note that only applicants meeting the profile requirements will be personally contacted. Applications sent by recruitment agencies will not be considered.

Job Types: Full-time, Contract

Experience:
Public Health Work: 2 years (Required)
Education:
Bachelor's (Required)",-1,Foundation For Innovative New Diagnostics,Chandigarh,-1,-1,-1,-1,-1,-1,-1,-1
847,Data Engineer,"Miles is looking to expand its data science and data engineering team in INDIA!

Here's a quick checklist:
You live in India
Want to work for a fast-growing Silicon Valley Startup
You are passionate about solving challenging problems
You are looking to put your stamp on the product

What you'll need:
At least 4+ years experience
Confident in designing, building, managing, and owning a growing and complex data pipeline. Your experience should reflect success with something similar.
Strong understanding of relational DB such as MySQL/PostgreSQL, document-based storage systems such as MongoDB or CouchDB, key-value stores (Memcached, Redis), Column-oriented stores (HBase, Cassandra), graph-oriented stores; their distinct advantages, disadvantages, and trade-offs
Experience with building stream-processing systems, using solutions such as Kinesis, Kafka, Storm or Spark-Streaming.
Good knowledge of Big Data querying tools, such as Pig, Hive, and Impala
Proficiency with Snowflake, Hadoop v2, MapReduce, HDFS
Knowledge of various ETL techniques and frameworks
Good understanding of Lambda Architecture
Develop and implement interactive analytic reports and dashboard using various tools such as Tableau, Looker, Chart.io
You should have worked on developing large-scale deployable software projects
Work closely with business and data science team for the deliverables.
Enjoy equity and influence in a fast-growing and dynamic pre-Series A company

Education
Master's (preferred) or Bachelor's (required) in CS/ML/AI or relevant computational/engineering discipline",2.3,"Miles
2.3",Bengaluru,"Redwood City, CA",1 to 50 employees,2016,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
848,Data Engineer,"Your next career adventure awaits you in the Evergreen City of India!

Our client is one of the big 4 companies around the world and they have high regard towards the work they do. We are looking for a passionate Data Architect at Trivandrum, Kerala who can part of a progressive team and succeed together.

Experience: 06 to 10 Years

We’d love to hear from you if:
You have done your Bachelor’s/Master’s in Electronics/Computer Engineering.
You are experienced in Development, Data Modelling, data-oriented solutions/system.
You are experienced in Azure Data Factory & Data Lake.
You are experienced in SSIS (MSBI).
You are experienced in SQL Server and data integration tools such as Alteryx, SSIS.

Our client interlace diversity and equal opportunity in a serious way.
If there is anything we can do to create a more comfortable interview experience for you, please let us know.",3.7,"Roljobs Technology Services Pvt Ltd
3.7",Thiruvananthapuram,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
849,Data Science Intern,"Role: Intern
Location: Bhubaneswar
Duration: 3-6 Months

Key Responsibilities:
Apply Data Mining/ Data Analysis methods using a variety of data tools, building and implementing models using algorithms and creating / running simulations to drive optimization and improvement across business functions.

Education qualification:
Final year engineering students from top institutes. Information Technology and Computer Science background are preferred.
Excellent written and verbal communication skills for coordinating across teams.
Should have knowledge on R, Python, SQL etc.
Reach us on careers@eta-iota.com.",-1,ETAIOTA Systems,Bhubaneswar,-1,-1,-1,-1,-1,-1,-1,-1
850,Data Engineer,"Bachelors Degree in an engineering or technical field
5+ years experience with and detailed knowledge of data warehouse technical architectures, infrastructure components, ETL/ ELT and reporting/analytic tools.
Experience in relational database concepts with a solid knowledge of SQL.
Strong knowledge of various data warehousing methodologies and data modelling concepts. Hands on modelling experience is highly desired
Experience performing various performance tuning activities at the both database level as well as ETL
Knowledge of professional software engineering practices & best practices for the full software development lifecycle, including coding standards, code reviews, source control management, build processes, testing, and operations
Amazon Business Data Analytics and Insights (ABDAI) team is looking for a Data Engineer (DE) to play a significant role in building their large-scale, high-volume, high-performance data integration and delivery services. These data solutions would be primarily used in periodic reporting, and drive business decision making while dealing efficiently with the massive scale of data available through our Data Warehouse as well as our software systems. You will be responsible for designing and implementing solutions using third-party and in-house reporting tools, modelling metadata, building reports and dashboards, and administering the platform software. You are expected to build efficient, flexible, extensible, and scalable data models, ETL designs and data integration services. You are required to support and manage growth of these data solutions.
You must be a self-starter and be able to learn on the go. Excellent written and verbal communication skills are required as you will work very closely with diverse teams.
As a Data Engineer in ABDAI team you will be working in one of the world's largest cloud-based data lakes. You should be skilled in the architecture of data warehouse solutions for the Enterprise using multiple platforms (EMR, RDBMS, Columnar, Cloud). You should have extensive experience in the design, creation, management, and business use of extremely large datasets. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions, and to build data sets that answer those questions. Above all you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive change.
Industry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, processing, and extracting value from large datasets.
Coding proficiency in at least one modern programming language (Python, Ruby, Java, etc)
Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets
Experience building data products incrementally and integrating and managing datasets from multiple sources
Query performance tuning skills using Unix profiling tools and SQL
Experience leading large-scale data warehousing and analytics projects, including using AWS technologies – Redshift, S3, EC2, Data-pipeline and other big data technologies
Experience providing technical leadership and mentor other engineers for the best practices on the data engineering space
Linux/UNIX including to process large data sets.
Experience with AWS
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.",-1,ADCI HYD 13 SEZ,Hyderabad,-1,-1,-1,-1,-1,-1,-1,-1
851,Senior Analyst - IT Tableau Developer/ Data Analyst,"200699 Senior Analyst - IT Tableau Developer/ Data Analyst (Open)

Job Title: Senior Analyst - IT Data Analyst/Tableau Developer

About Our Group

At Seagate, we are working towards building a future highly efficient, next-generation transformative IT teams. To this effect and to support the transformation initiatives that will be undertaken in near future we are looking for like-minded, innovative, cost optimal partners who can help support and drive the business and technology visions of Seagate. The new IT teams we are building in the area including Big Data and Analytics, Machine Learning, IoT, Artificial Intelligence, Enterprise Security, AWS, Azure, PaaS, IaaS etc.

About the Role - You will:

You will be expected to play a key role in driving the future business road map of the company. We are looking to hire people who are looking to contribute, enhance their skills in latest technology areas and are ready to work in an extremely challenging and fun place to deliver results in very aggressive timeline
IT Data Analyst/ Tableau Developer
End to End Create Tableau Dashboards
Map reporting requirements to the Data Models
Develop test plans to test for Data Integrity
About you:
Sound analytical skill
Strong verbal and written communication
Data analyst with troubleshooting skills. Unix shell scripts is an advantage
Ability to map reporting requirements to the Data Models
Develop test plans to test for Data Integrity
Flexible to work with Global teams as needed
Your Experience Includes
Moderate experience in data models and reporting packages
Moderate experience with data base languages like SQL, MySQL
Extensive experience in Creating end to end Tableau Dashboards
Location: Pune

Job Family: Professional",3.3,"Seagate Technology
3.3",Pune,"Cupertino, CA",10000+ employees,1979,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Western Digital, Fujitsu"
852,Data Analyst,"Overview:
Institutional Shareholder Services Inc. (ISS) is currently seeking a full-time Data Analyst. This position will be permanent based in Mumbai office and will become an integral part of the data operations team. The role entails helping deliver data and research in assigned market. Our team is composed of 4 pillars listed below, with global coverage.

Core (Individual) - identify (master data) management, employment history
Core (Company) - board of directors, shareholder rights, stock, audit finding
Compensation - burn rate, dillution, say-on-pay and equity plan proposals
Pay - actual pay and grants received by top executives

Responsibilities:
Search for, collect and verify data (of basic and intermediate levels of complexity) for companies under his/her assigned market based on current collection methodologies and acceptable sources
Attend to internal/client queries and requests to ensure data captured is aligned with data methodology and policy guidelines
Comply with established work process standards to ensure quality of data collected
Meet pre-determined turn-around goals for work assignments
Escalate data interpretation issues, as needed
Perform root-cause analysis if data issues are identified
Update internal documents for performance metrics monitoring
Participate in working committees/ projects and/or tasks aside from his/her core responsibilities
Maintain appropriate paper and electronic files as required by ISS and client file retention policies

Qualifications:
Degree in Business, Legal Management, Finance, Economics, Accounting, Social Sciences, Communication or any equivalent/related course; Freshers/Fresh graduates are encouraged to apply
Knowledge and experience in using MS Office;
Excellent English communication (both oral and written) and reading comprehension skills;
Strong analytical and problem solving skills, with clear attention to detail;
Ability to prioritize and work under tight deadlines;
Fast learner, able to master new concepts, theories, ideas and processes with ease;
Willingness to work beyond traditional working hours/days as required by the business;
Experience in data collection and analysis, corporate governance and business research would be an advantage.

Due to the great number of applications we receive for each of our open vacancies, we are unable to respond on an individual basis.

Institutional Shareholder Services Inc. is an equal opportunity employer committed to diversifying its workforce. It is the policy of the Firm to ensure equal employment opportunity without discrimination or harassment on the basis of race, color, religion, creed, age, sex, gender, gender identity, sexual orientation, national origin, citizenship, disability, marital and civil partnership/union status, pregnancy (including unlawful discrimination on the basis of a legally protected pregnancy/maternity leave), veteran status, or any other characteristic protected by law.

#LI-CCA0818",3.2,"Institutional Shareholder Services Inc
3.2",Mumbai,"Rockville, MD",201 to 500 employees,1985,Subsidiary or Business Segment,Financial Analytics & Research,Finance,₹1 to ₹5 billion (INR),Glass Lewis & Co
853,Data Analyst,"Strong experience in Scala/Spark. * Experience in Bigdata using HDFS * Experience in Java/Spark/Python * Good to have experience in Hadoop Ecosystems like PIG, HIVE, Map Reduce, Flume, Sqoop ,Kafka * Good experience in SQL * Good communication skills, both written an oral.

Strong understanding of Data Structures and Algorithms * Job Type: Full-time

Salary: ₹500,000.00 to ₹1,500,000.00 /year

Work Remotely:
Temporarily due to COVID-19",-1,"Institutional Shareholder Services Inc
3.2",Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
854,Senior Machine Learning Engineer,"Ushur is transforming the way businesses communicate, with cutting-edge AI and automation technologies. Previously using outdated emails and phone calls, businesses are now automating their conversations with automated text-messaging using Ushur’s platform. We are creating breakthrough experiences for our enterprise customers by deploying the best of web, mobile and data analytics technologies. We focus on fast, iterative development with an emphasis on design-right philosophy. Currently, at Ushur, we are experiencing unprecedented & exciting growth with endless opportunities to innovate!

The Role

Ushur seeks a Senior Engineer with Machine Learning Expertise to join a high-impact team to enhance the Language Intelligence framework that is at the core of industry’s leading Micro-Engagement Platform from Ushur.

What you’ll be doing…

As one of the key members of of the Language Intelligence team, your responsibilities will include:
Design, develop and support machine learning and deep learning models involving
Ushur’s Language Intelligence that encompasses the spectrum of NLP and NLU to support information processing as well as drive the Ushur micro-engagements with users.
Responsible for designing and/or adapting various algorithms, undertaking experiments and impacting the Ushur Micro-engagement Platform.
Construct comprehensive knowledge graphs to support various applications that are delivered over the Ushur Platform.
Research and employ modern algorithms into the Ushur Platform to keep innovating with efficiency, impacting the feature-base of Ushur’s Platform.

Collaborating with engineers from AI & other teams on data analysis and feature design efforts

Qualifications

MS/PhD in Computer Science or related field
At least 3 years hands-on working experience in the AI/ML Area
Demonstrable experience with NLP/NLU techniques, language data
Strong knowledge of NLP tasks and techniques, NER, training machine learning models, neural networks
Strong programming skills in Python or Java and fluency in data manipulation (SQL/Spark/Pandas) and machine learning kits like scikit-learn, Keras/Tensorflow, XGBoost, Gensim
Excellent verbal & written communication, strong organizational skills and attention to detail

Why Join us?

We are passionate about Ushur, our product, and helping our employees grow and develop in their career in a caring, collaborative environment. We offer a very competitive compensation plan & stock options for the ideal candidates.",4.3,"Ushur
4.3",Bengaluru,"Sunnyvale, CA",1 to 50 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
855,Junior Research Scientist,"Role title
Junior Researech Chemist
Business/Function

Technology
& Engineering
Current incumbent
Department

Synthesis
Support Group
Reports to role

Team
Leader
Location

R&T
Goa
Global Reporting
level (CEO=1)
Work level
Role purpose

This section describes the
overall purpose of the role, why it exists and how it adds value to the
business. It is a summary list of up to six statements for key result areas
where the role holder will have decision making responsibility.
Preparation
of reference materials thru existing /new routes
Screen
synthetic routes for economic processes
Good
experimental skills with appetite for learning and updating latest
developments in synthetic Organic chemistry
Adopt
simple quantitative analytical methods

Accountabilities

This is a summary list of
6-8 statements for key result areas. These accountabilities should normally
be ongoing, and unlikely to change significantly from year to year. The focus
should be on results rather than activities. When completing the role accountabilities
you should: Use action verbs (e.g. ensure, provide, execute, manage, design,
translate); Provide a broad indication of the performance levels required
(e.g. effectively, accurately, in line with defined standards); Ensure the
accountabilities relate clearly to this role; Give an indication on freedom
to act (e.g. independently, under supervision) and interdependencies with
other roles.
Carry out
assigned synthesis of reference materials /active ingredient and
intermediates
Always
ensure the safe laboratory practices and fine tune the chemistry and process
in to economical & commercially viable process.
Ability to
work coherently on the assigned
experiments and meets
timelines.
Carry out,
as necessary, process optimisation of assigned individual reaction steps.
To receive
preliminary analytical methods from R&T and optimise the same to fully
developed ready to use in-process analysis.
Carefully documents the experiments in the
electronic notebook (ELN) or in summary tables. Reference material procedures
are documented in SmartDoc (Reference Materials Preparation) in order to
retain our gained knowledge
Efficiently conducts experiments using
established test methods to produce high quality data and results with
limited repeat testing.
Continually
seek to improve knowledge experimental chemistry.

Syngenta Role Profile

Critical success factors & key
challenges

Please
identify up to three critical success factors for the role. These will form
the basis on which success in the role will be measured. These factors may be
quantitative and qualitative in nature, but they should be 'hard' in terms of
being able to provide robust measures for role performance. Additionally list
up to three key challenges that the job holder will face in the first 12
months.
Able
to Demonstrate personal commitment to
the team
Value and
use individual differences and talents
Work
tenaciously to deliver agreed goals
Should be self-discipline
to achieve results

.
Role title
Junior Researech Chemist
Business/Function

Technology
& Engineering
Current incumbent
Department

Synthesis
Support Group
Reports to role

Team
Leader
Location

R&T
Goa
Global Reporting
level (CEO=1)
Work level
Role purpose

This section describes the
overall purpose of the role, why it exists and how it adds value to the
business. It is a summary list of up to six statements for key result areas
where the role holder will have decision making responsibility.
Preparation
of reference materials thru existing /new routes
Screen
synthetic routes for economic processes
Good
experimental skills with appetite for learning and updating latest
developments in synthetic Organic chemistry
Adopt
simple quantitative analytical methods

Accountabilities

This is a summary list of
6-8 statements for key result areas. These accountabilities should normally
be ongoing, and unlikely to change significantly from year to year. The focus
should be on results rather than activities. When completing the role accountabilities
you should: Use action verbs (e.g. ensure, provide, execute, manage, design,
translate); Provide a broad indication of the performance levels required
(e.g. effectively, accurately, in line with defined standards); Ensure the
accountabilities relate clearly to this role; Give an indication on freedom
to act (e.g. independently, under supervision) and interdependencies with
other roles.
Carry out
assigned synthesis of reference materials /active ingredient and
intermediates
Always
ensure the safe laboratory practices and fine tune the chemistry and process
in to economical & commercially viable process.
Ability to
work coherently on the assigned
experiments and meets
timelines.
Carry out,
as necessary, process optimisation of assigned individual reaction steps.
To receive
preliminary analytical methods from R&T and optimise the same to fully
developed ready to use in-process analysis.
Carefully documents the experiments in the
electronic notebook (ELN) or in summary tables. Reference material procedures
are documented in SmartDoc (Reference Materials Preparation) in order to
retain our gained knowledge
Efficiently conducts experiments using
established test methods to produce high quality data and results with
limited repeat testing.
Continually
seek to improve knowledge experimental chemistry.

Syngenta Role Profile

Critical success factors & key
challenges

Please
identify up to three critical success factors for the role. These will form
the basis on which success in the role will be measured. These factors may be
quantitative and qualitative in nature, but they should be 'hard' in terms of
being able to provide robust measures for role performance. Additionally list
up to three key challenges that the job holder will face in the first 12
months.
Able
to Demonstrate personal commitment to
the team
Value and
use individual differences and talents
Work
tenaciously to deliver agreed goals
Should be self-discipline
to achieve results

.",4.0,"Syngenta
4.0",India,"Basel, Switzerland",10000+ employees,2000,Company - Public,Chemical Manufacturing,Manufacturing,₹500+ billion (INR),-1
856,"Data Analyst, Level 3","Job Overview:

This job entails interpretation (analyzing and reviewing) of Clinical trials data across various therapeutic areas and actively contribute to the development of database products that support informed decision making at various stages of clinical development and post approval phases using modelling and simulation approaches. This job necessitates a profound knowledge of pharmacology and clinical research, experience in development and quality management process of clinical databases for conducting systematic literature review and meta-analysis (pair wise, network and model based meta-analysis) and basic knowledge of information science (PICOS based literature search)

Responsibilities:

·Play a key role in the development of clinical database products in various therapeutic areas like Metabolic& CV, Neuroscience, Autoimmune, Oncology, Respiratory etc., with a very high quality that support Meta-analysis (Pair wise, Network and Model based meta-analysis)

·Analyze and review the information pertaining to

oTrial design, treatments, demographics and outcomes data (biomarker, clinical, safety and quality of life outcomes) for full time course from clinical literature (Journals, conference abstracts, Regulatory reviews etc.)

oThe data extracted from graphs for outcomes reported on linear, logarithmic and semi-log scales with precision

·Perform the above consistently with a very high quality, provide the required feedback and training to the data analysts at L1/L2 continuously thereby contributing to the enhancement of database quality

·Review the literature search results, identify the miss cases and share the analysis report basing which the PICOS based search algorithm shall be enhanced (by lead consultant/Quality manager/Project Manager) to include the specific terms resulting in the miss cases

·Work with lead consultant, peer data analysts and Quality manager to understand and contribute to the database rules, meta-data management, specifications and quality enhancement on continuous basis to assure “first time correctness”

·Undergo relevant training programs (Statistics, R coding, Systematic literature review and Data analysis methods) and excel in these skill enhancement programs to grow in the organization ladder

Education, Experience, Training, and Knowledge:

·Masters in Pharmacology or Pharmaceutics (with relevant experience), Pharma D, Clinical Practice, Masters in Public Health and Epidemiology.PhD in Pharmaceutical sciences and MD Pharmacology are eligible with minimal/no work experience

·Minimum 2-4 years of experience in the areas of Information science, Systematic Literature review, Health-economics and public health sectors, pharmaceutical industry experience preferred

·Strong knowledge of Pharmacology and clinical research is a must

·Knowledge of clinical development and post approval phases, , PICOS approach, trial designs, Pharma Industry data standards/ontologies

·Knowledge of statistics, data management tools like R is an added advantage

Skills& Abilities:

·Comfortable in a team environment and able to communicate with and collaborate with peer scientists

·Excellent interpersonal skills

·Strong learning skills to be able to support databases in multiple disease areas",3.7,"Certara
3.7",Secunderabad,"Princeton, NJ",501 to 1000 employees,-1,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
857,Analytics Manager,"Overview

Established in 2012, Factspan is a leading pure play analytics company with expertise in converting data into actionable business insights. We provide the expert services that organizations need to establish their own analytics center of excellence. Our dedicated team of data scientists and consultants partner with the clients to provide analytics solutions which organizations need every day to take data driven decisions. Headquartered in Seattle, we also have our office in Bangalore, India. Our clients include Fortune 100 companies in Retail, Financial Services, Insurance, Hospitality and Technology industries. Our Vision is to be the foremost player in the business analytics space.

Roles and responsibilities
Interacting with client/onsite team to understand client's business problems, defining, executing and delivering the analytical solution to the business problems
Carry out all aspects of project management including work planning, estimation, scope refinement, quality and delivery
Responsible for project progress while taking corrective action wherever necessary and revising it so as to meet changing needs and requirements
Manage operational workflow and ensure seamless delivery for both quick turnaround analysis and long term projects.
Conceptualize the analytical methodology for business problems and lead a team to configure solution which includes defining metrics, visualizations, data processing, validation and ingestion flows.
Research new methods of analysis, suggest areas of analysis to the team, understand clients’ long-term analytics requirements and actively suggest methods to answer such needs.
Understand the nature of the data and how it relates to the problem at hand.
Communicate expectations and establish deadlines in agreement with client and delivery team. The person will be responsible for formulating a strategic vision and a tactical roadmap to meet clients' needs
Managing cross-functional interdependencies
Able to build relationships, trust and work collaboratively on small and large teams across functions and in a professional manner
Develop POCs and create POVs towards account growth
Subject matter expert in Advance Analytics - including Solutions Definition.
Being part of sales presentations and contributing to RFPs/RFIs thereby being able to win new business from existing and new clients.
Proactive towards organisational initiatives and people activities like training, developing people by creating growth plans, etc.
SKILLS
Has documented success with developing a business strategy and managing complex transformation projects
Exceptional communication skills; presentation, facilitation, oral, written, listening and conflict resolution
Enthusiastic about assuming responsibility and accountability
Flair for evaluating alternatives and deciding on a plan of action
Adept at critical and creative thinking
Leadership abilities, across the client enterprise and in a multiple project environment, which influences clients, team members, and key stakeholders
Hands on expertise with different analytical tools and databasesHands on expertise with different analytical tools and databases
Qualification & Experience
4-8 years of experience into Analytics
Bachelor’s or Master’s degree in Statistics/Mathematics/Engineering
Possess strong analytical/logical thinking skills
Hands-on while delivering projects
Ability to think: Possess strong analytical/logical thinking skills.
Strong structured problem solving skills
Experience with statistical software such as SQL, R, etc.
Experience working with US clients
Behavioral Attributes
Analytical thinking
Excellent Verbal/Written communication
Possess strong analytical/logical thinking skills
Excellent Interpersonal & Presentation skills
Willingness to go beyond the textbook while applying statistics in a business situation which typically entails less than ideal data quality/quantity",2.9,"Factspan
2.9",Bengaluru,"Seattle, WA",51 to 200 employees,2012,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
858,Data Analyst,"Good in Data Extraction.

Processing confidential data and information according to guidelines.

Prepare and present analytical reports

Job Type: Full-time

Pay: ₹10,000.00 - ₹18,000.00 per month

Experience:
total work: 1 year (Required)
Work Remotely:
Temporarily due to COVID-19",-1,Datagain Inc.,Thane,-1,-1,-1,-1,-1,-1,-1,-1
859,Data Analyst,"Requirement
B.Tech. / B.E in any Engineering Stream/ MCA / Bachelor’s degree in any science stream.
0-2 years’ experience - Fresher’s are welcome to apply.
Added advantage if you have basic knowledge about Mechanical/Electrical appliances, FMCG products
Added advantage if you have experience of working with API’s used to extract web data - dimensional data from databases and web is an added advantage. Basic programming skills to program custom scrapping tools
Should have excellent computer knowledge - MS Office – Excel, MS Word, etc.
Engineering Product / Data Mining understanding – Product information like Manufacturer / Part Number / Product Description / Energy rating / Energy consumption etc.
Good Analytical & Communication skills (Ability to communicate with clients)
Data management capabilities, attention to detail.
Demonstrates interpersonal skills and team work
Quick learner and flexible to perform multiple jobs
What you've got
If you have the ability to look down at the meaning of data with good analysis and identify trends and patterns of information clubbed with excellent computer skills, then this role is what you are looking for. Expertise in streamlining of data management projects and end to end process flow, ensuring deliverables are prepared to exceed customer expectations, status reporting, developing, documenting, and maintaining data quality goals and standards.",-1,Outsource Bigdata,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
860,Data Analyst,"English

Location : Madurai, Tamil Nadu, India

AISpotters is a fast paced growing Human Intelligence division in Mithr Artificial Intelligence Pvt Ltd. We are proud to provide data analysis services to several Artificial Intelligence companies. Dubbed as “Human Intelligence Services”, our Data analysts are vital to the development of Artificial Intelligence algorithms leading to the development of Chatbots, Automated Interactive voice response (IVR), Digital Assistants (like SiriTM, AlexaTM ) and more.

Here is an amazing opportunity to be part of this adventure, you will use your strong English language background to first prove your language proficiency by successfully completing one of standardized English test for proficiency such as IELTSTM, TOEFLTM. Both online and tutor based training will be provided as part of the benefits helping ideal candidates to successfully clear the exams. In this past growing division, successfully English language experts will have an opportunity to lead a team of similar language experts and work directly with AI researchers to human intelligence services.

At Mithrai, we believe in “Transformation Through Technology” and we are committed to bringing that transformation for the benefit of mankind. Our rich work culture and strong ethics, where we value individual development as a company’s growth makes a great place to work.

Responsibilities
Identification and annotation of English language lexicon, Parts Of Speech, Sentiment / Emotion.
Summarization of long-form documents into paragraphs of varying sizes with an emphasis on core content and keywords
Transcription of free running audio recorded in native English language speakers (US-EN, UK-EN)
Development of dataset to enable training of AI algorithms.
Work real-time with project leads and engineering teams to evaluate new features/implementations of annotation tools

Minimum Qualifications:
1

BA/MA degree in English literature.

2

Good command in English language and proficient in reading, writing and speaking.

3

Opportunity for aspiring Linguist, who have expertise in many aspects of English language, including sounds (phonetics, phonology), words (morphology), sentences (syntax), and meaning (semantics).

4

Strong written and oral communication skills with an ability to communicate effectively with all stakeholders.

5

Outstanding interpersonal skills with a strong customer service focus (internal and external).

6

Highly ethical team player.

Preferred Qualifications
1

Experience working in fast-paced startup environments

2

Experience working in BPO

3

Passionate about language understanding, Artificial Intelligence, and Mobile Technology

4

High energy, self-starter with an ability to successfully prioritize and multi-task in an atmosphere in which time sensitive deadlines are the norm, as are an interruption.

5

Strong computer skills with a proficiency in MS Office.",-1,AISpotters,Madurai,-1,-1,-1,-1,-1,-1,-1,-1
861,Associate Scientist/ Senior Associate Scientist 1,"Designation: Associate Scientist / Senior Associate Scientist

Job Location: Bengaluru

Department: Discovery Chemistry R&D

About Syngene

Incorporated in 1993, Syngene International Ltd. is an innovation-focused global discovery, development and manufacturing organization providing integrated scientific services to the pharmaceutical, biotechnology, nutrition, animal health, consumer goods and specialty chemical industries around the world. Syngene’ s clientele includes world leaders such as Bristol-Myers Squibb, Baxter, Amgen, GSK, Merck KGaA and Herbalife. Its innovative culture is driven by the passion of its 4240- strong team of scientists who work with clients from around the world to solve their scientific problems, improve R&D productivity, speed up time to market and lower the cost of innovation .

Job Description

Key Responsibilities:
Perform synthetic chemistry reactions, reaction workups, purification of the compounds by column chromatography, crystallization, re-crystallization techniques, preparative (Tables Listings & Columns) TLC and operating lab equipment
Assist the supervisor to take stock of resources (raw materials, solvents, etc.) in the project and report any shortfall and search literature using Reaxys
Provide hands-on training and supervision to juniors while performing synthesis of compounds
Ensure that the samples generated during synthesis are given for analysis and record subsequent results obtained and update the supervisor / group leader on the progress of synthesis and ensure samples are packed appropriately for shipment
Record the observations of experiment/reaction, results, utilization of resources and other activities related to the reaction in the laboratory or e-notebook following guidelines and in timely manner and ensure that the same is handled safely and confidentially.
Ensure that the instruments / equipment is calibrated, undergone preventive maintenance and are kept clean before use and in case of any breakdown, report to maintenance immediately
Ensure that they know the Material Safety Data Sheet (MSDS) of the chemicals they are handling and aware of emergency response procedures in case of accidental spillage, leakage or fire and ensure proper waste segregation as per EHS norms
Always follow EHS and quality system requirements in the workplace ensuring individual safety and lab safety
Attend all mandatory trainings and update training records as and when trainings are completed
Always ensure confidentiality
Prepare SOPs/IOPs/EOPs/OCPs when any new lab activity is identified or existing one requires updation
Any other lab responsibilities as indicated by the EHSQ team member/ supervisor / group leader.

Educational Qualification:
MSc (Chemical Sciences).

Technical/functional Skills:
Good knowledge in Synthetic Organic Chemistry and excellent experimental skills (success rate of reaction >80%)
Handling of some specialized technical reactions including hazardous/exothermic/sensitive reactions
Familiar with operations of relevant apparatus - instrument / equipment.
Good Knowledge of analytical techniques and analytical data interpretation.
Good communication skills

Experience:
5-8 years relevant experience.

Behavioral Skills:
Able to work independently and make decisions with minimal supervision
Good interpersonal skills
Good team player

Equal Opportunity Employer:
It is the policy of Syngene to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by applicable legislation or local law. In addition, Syngene will provide reasonable accommodations for qualified individuals with disabilities.",3.5,"Syngene
3.5",India,"BENGALURU, India",1001 to 5000 employees,1994,Unknown,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
862,Data Analyst,"Job Description

Designation: Data Analyst/ Senior Data Analyst
Qualification: Any stream – Graduate / Post Graduate with experience in Market Research
Desired Skills: SPSS is must, Quantum will be an added advantage.

Technical Skills:
At least 1 year of experience in SPSS (knowledge of Quantum will be added advantage).
Ability to work on Data Tabulation, Data Cleaning as per standards using SPSS programming
Knowledge of Excel formulas, macros etc.
Work on Custom Tables as required by the clients specification
Ability to do the checks / quality measures, necessary for tables output
Personal Skills:
Analytical skills
Adherence to timelines
High Commitment
Ability to work under pressure
Team-player
Ability to actively support/ consult clients regarding all questions around DP and tabulation
Understanding of Market Research (do’s and dont’s)
Why Choose Us?
We can help you reach your next level
Lean Hierarchy
Fun place to work
Transparent
Employee focused
Only Good Geeks
Lots of Benifits",-1,Inginit,Maharashtra,-1,-1,-1,-1,-1,-1,-1,-1
863,Sr. Applied Scientist,"PhD in Computer Science, Mathematics, Statistics, or other quantitative field with exposure to statistical modeling and machine learning
6+ years of applying machine learning for solving real-world problems in industry
Proficiency in C/C++, Java, or Python
Proficiency with at least one machine learning or statistical modeling library (R, Matlab, Scikit-learn)
Past delivery of large-scale ML solutions for complex business problems
Outstanding written and verbal communication skills
The Outbound Marketing Automation (OMA) is looking for a smart and motivated applied scientist to join the Lumos team. We are a high-energy and innovative group that deliver highly relevant, personalized communications on various automated channel like email to Amazon customers worldwide. We utilize the data footprint on Amazon to generate messages to bring best-in-class engagement with our customers.

As a member of our team you will interact closely with other automated advertising technology and retail customer experience teams. You will be involved with the development and launch of large-scale ML systems involving large data processing pipelines modeling customer data.

In OMA, we look for experienced leaders who possess a wide variety of skills. As the successful applicant for this role, you will solve varied complex problems across Amazon (including business prioritization, technical challenges in optimization, large-scale computing, distributed systems, web applications, scalability, security, machine learning, and algorithms, to name just a few), you will drive multiple programs in parallel, you will work with business stakeholders and partner technical teams across Europe, India and the USA, and you will support the growth and development of a high-performing engineering team. OMA is composed of many clever and generally awesome people (if we say so ourselves!), so you'll learn a huge amount - and have a lot of fun - in the process!
Publications in top ML conferences or journals
Experience with a popular deep learning toolkit (TensorFlow, MXNet, PyTorch, Caffe etc)",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
864,"Modeling Engineer, Sr. I","Position: Modeling Engineer Sr. I



Eligibility Criteria:

Years of Experience: 1 - 3 yrs

Educational qualification: M.S./M.E./M.Tech in Mechanical, Chemical or Aeronautical Engineering



Primary Responsibilities:
Complete Computational Fluid Dynamics Models of complex reactor systems
Solve liquid and gas fluid flow problems, with and without chemical kinetics
Work with engineers from various Business Units to solve flow, thermal, chemical reaction and mass transport problems and then proposes appropriate design solutions
Write reports to summarize modeling activity and presents to BU engineers as necessary


required to perform the job:
Computational Fluid Dynamics modeling using commercial packages
Experience to solve complex problems, validate model accuracy, and determine appropriate actions.
Good oral and written communication skills.
Desirable Skill:
Use of Modeling tools, particularly Ansys Fluent.
Knowledge of chemical kinetics with the ability to derive rate expressions.
Knowledge of Plasma physics and Plasma modeling.",4.3,"Lam Research
4.3",Neem-Ka-Thana,"Fremont, CA",10000+ employees,1980,Company - Public,Electrical & Electronic Manufacturing,Manufacturing,₹500+ billion (INR),"Applied Materials, Tokyo Electron, ASML"
865,Data Analyst,"Required Skills
Candidate should have good typing skills and MS Office applications knowledge

Qualification
Graduates/Postgraduates with excellent English communication skills and willingness to work in rotating shift",2.9,"Affinity Express
2.9",Pune,"Elgin, IL",1001 to 5000 employees,1999,Company - Private,Advertising & Marketing,Business Services,₹10 to ₹50 billion (INR),-1
866,Senior Systems Modeling Engineer,"Join our Physical Modeling team! We focus on creating cutting-edge simulation engines, tools, and component libraries to simulate physical systems. Your primary focus will be to add detailed reference application examples that use our Simscape component libraries to model a wide range of systems, including renewables (heat pumps, wind power, photovoltaics), automotive (actuation, HVAC, transmissions), domestic appliances (boilers, dryers, washing machines) and consumer electricals (printers, power supplies, drives, robotics).

We seek an individual excited about helping engineers and scientists build better products by using model-based design. You will need first-hand experience of system modeling in at least one industry or technology area, plus possess the skills to ramp up quickly on adjacent ones. You should be comfortable with modeling physical phenomena across multiple domains, ideally including mechanical, thermal, electrical and fluid power. You will also need to be a good communicator, both aurally and in written form.
Develop in-depth application reference examples
Develop supporting written materials and webinars
Develop requirements for Simscape library component enhancements
Design experience from at least one application area/industry e.g. renewables, domestic appliances, automotive, factory automation
Strong writing skills
Good aural communication
Plusses
Experience with MATLAB and Simulink
Experience with Simscape and the Simscape language
Commercial software engineering experience
Experience with designing application user interfaces
A bachelor's degree and 7 years of professional work experience (or a master's degree and 5 years of professional work experience, or a PhD degree, or equivalent experience) is required.",4.4,"MathWorks
4.4",Bengaluru,"Natick, MA",5001 to 10000 employees,1984,Company - Private,Computer Hardware & Software,Information Technology,₹100 to ₹500 billion (INR),-1
867,Senior Data Analyst,"Experience:
00 - 8.00 years
Position Type:
Full Time – FT
Functional Area:
Intelligence & Analytics
Education:
B.Sc,M.Sc.
Work Location:
Bangalore

This Job requirement is for our Indegene Inc entity for a Senior Data Analyst in Bangalore Location
Role:
Senior Data Analyst

About Indegene:

At Indegene, we look to change healthcare for the better. Being an Indegene employee is not just doing a job, but it is about real contribution and outcomes. We are a global team of over 1,200 employees across 14 global locations. Our singular focus is to deliver real outcomes that are measurable, impactful, and sustainable. This has made us a recognized global leader and partner to some of the largest and most respected healthcare organizations.

Joining us means you will be part of a great company, one that joins hands to really improve patient and business outcomes using analytics, technology, operations, and medical expertise. Our people are exceptionally bright, motivated, and customer focused. Even though they are from diverse cultural and academic backgrounds, they have three things in common—they are really passionate about healthcare, they are committed to their customers and teams, and they sincerely believe that collaboration is the key to achieving their personal and professional goals.

Job Summary:

A Senior Data Analyst needs to discover, explore, analyze, and document data from all sources and target systems to better understand the total scope of data availability. He or she also coordinates with the internal and external stakeholders. The role of the Senior Data Analyst also involves understanding the complete requirement of the project, as well as documenting as per company’s requirement.

Job Description:

The roles and responsibilities of the Senior Data Analyst include the following:
Analyzing and debugging/rectifying the bugs identified
Synthesizing the data into information consumable by senior business decision makers
Being responsible for developing programs within the timelines assigned
Participating in the project review processes
Interacting with different stakeholders
Performing requirement analysis to strategize further action points
Adhering to compliance procedures and internal/operational risk controls in accordance with any and all applicable regulatory standards, requirements, and policies


Desired Skills and Experience:

· Education—BSc/MSc

· Experience—5-8 years of relevant experience, with minimum 1-2 years of experience in managing a team of data analysts and 3-5 years of experience in developing back-end SQL procedures using MS SQL

· Data management, clinical, and/or research experience, with solid understanding of clinical trials methodology and terminology

· Understanding of the best practices followed in the department regarding processes, communication (internal and external), project management, documentation, and technical requirements of the project

· Experience in developing stored procedures, triggers, and complex SQL queries

· Exposure to VB and .Net is mandatory as the role involves building an engine to read data from MS Excel files and create SQL queries dynamically

· Exposure to data warehousing/ETL

· Should be a self-starter and capable of operating on minimal management oversight

· Ability to work under pressure to meet agreed deadlines

· Passion, energy, and enthusiasm to drive results

· Passion to design artistically and a keen interest to learn new concepts and technologies",3.6,"Indegene
3.6",Bengaluru,"Bengaluru, India",1001 to 5000 employees,1998,Company - Private,Healthcare Services & Hospitals,Healthcare,₹10 to ₹50 billion (INR),"Accenture, Cognizant Technology Solutions, Tata Consultancy Services"
868,Data Analyst,"National Institute Of Biomedical Genomics (NIBMG) looking for a motivated and bright individuals interested to explore career opportunities in this multi-organization national initiative, of which NIBMG has a lead role to perform.

Data Analyst
No. of posts: 01

Consolidated Retainer fee: Rs.31000/- per month

Essential Qualificatiosn: B.Tech/MSc in Life Sciences/ Physical Sciences/ Computer Sciences/ Allied Sciences

Desirable:
PhD/MSc which involved analysis of genotype data.
Experience of human sample collection/ wet-lab experiments

Candidate Profile:
PhD/MSc

Experience:0-5 Years

Location:Kalyani

Education:B.Tech/MSc in Life Sciences/ Physical Sciences/ Computer Sciences/ Allied Sciences

Company:National Institute Of Biomedical Genomics (NIBMG)

SALARY:Rs.31000/- per month

Last Date: Last Date to Apply is Over. : 2020-May-11

Key Skills: Manager

Company details

National Institute Of Biomedical Genomics (NIBMG)

NATIONAL INSTITUTE OF BIOMEDICAL GENOMICS (An Autonomous Institution of the Government of India) P.O.: N.S.S., Kalyani 741251, West Bengal, INDIA Website: www.nibmg.ac.in",-1,National Institute Of Biomedical Genomics (NIBMG),Kalyani,-1,-1,-1,-1,-1,-1,-1,-1
869,Data Analyst Intern,"Role requires the ability to interpret data from different sources, analyze data and communicate how to apply findings to the business models and needs for the company. Your interpretation of the data will require a large amount of interaction with other teams to understand what the sources of data are, how this data might affect the business and its processes, and what problems are being solved by drawing conclusions from the data that has been collected.
*
Qualifications:
BE/ B.Tech/ ME/ M.Tech/ MCA/ MSc - CSE, ECE, EEE, Statistics, Math, Economics

BSc Statistics, Math, Economics , BCA, BSc IT etc
A passion for helping organizations understand how to solve problems through analytics.
Ability to manage simultaneous tasks in a fast-paced, technology-oriented environment.
Job Types: Full-time, Part-time, Internship, Fresher

Salary: ₹25,000.00 to ₹30,000.00 /month

Education:
Bachelor's (Required)",-1,iBAX,Chennai,"Chennai, TN",Unknown,-1,Unknown,-1,-1,Unknown / Non-Applicable,-1
870,Artificial Intelligence Scientists,"Experience 2- 4 Years
Salary 4 LPA - 6 LPA
Job Location Chennai

Industry:
IT-Software / Software Services

Keywords:
Artificial Intelligence

About Job:
Must have Excellent knowledge in AI / Machine learning (Mandatory).
Machine learning frameworks like keras, tensor flow etc.
And also other big data tools like Hadoop etc, Must know R and python.
Good understanding in SDLC & Business cycle.",4.0,"Careerera
4.0",Chennai,"Wayland, MA",501 to 1000 employees,-1,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
871,Senior Data Engineer,"About Us

upGrad is an online education platform building the careers of tomorrow by offering the most industry-relevant programs in an immersive learning experience. Our mission is to create a new digital-first learning experience to deliver tangible career impact to individuals at scale. upGrad currently offers programs in Data Science, Machine Learning, Product Management, Digital Marketing, and Entrepreneurship, etc. upGrad is looking for people passionate about management and education to help design learning programs for working professionals to stay sharp and stay relevant and help build the careers of tomorrow.
upGrad was awarded the Best Tech for Education by IAMAI for 2018-19
upGrad was also ranked as one of the LinkedIn Top Startups 2018: The 25 most sought-after startups in India
upGrad was earlier selected as one of the top ten most innovative companies in India by FastCompany.
We were also covered by the Financial Times along with other disruptors in Ed-Tech
upGrad is the official education partner for Government of India - Startup India program
Our program with IIIT B has been ranked #1 program in the country in the domain of Artificial Intelligence and Machine Learning
About the Role

We are looking for a Data Engineer to help us scale the existing data infrastructure and in parallel work on building the next generation data platform for analytics at scale, machine learning infrastructure and data validation systems.
In this role, you will be responsible for communicating effectively with data consumers to fine-tune data platform systems (existing or new), taking ownership and delivering high performing systems and data pipelines, and helping the team scale them up, to endure ever growing traffic.
This is a growing team, which makes for many opportunities to be involved directly with product management, development, sales, and support teams. Everybody on the team is passionate about their work and we’re looking for similarly motivated “get stuff done” kind of people to join us!

Roles & Responsibilities
Engineer data pipelines (batch and real-time ) that aids in creation of data-driven products for our platform
Design, develop and maintain a robust and scalable data-warehouse and data lake
Work closely alongside Product managers and data-scientists to bring the various datasets together and cater to our business intelligence and analytics use-cases
Design and develop solutions using data science techniques ranging from statistics, algorithms to machine learning
Perform hands-on devops work to keep the Data platform secure and reliable
Skills Required
Bachelor's degree in Computer Science, Information Systems, or related engineering discipline
6 + years’ experience with ETL, Data Mining, Data Modeling, and working with large-scale datasets
6+ years’ experience with an object-oriented programming language such as Python, Scala, Java, etc
Extremely proficient in writing performant SQL working with large data volumes
Experience with map-reduce, Spark, Kafka, Presto, and the ecosystem.
Experience in building automated analytical systems utilizing large data sets.
Experience with designing, scaling and optimizing cloud based data warehouses (like AWS Redshift) and data lakes
Familiarity with AWS technologies preferred
Qualification – B.Tech/M.Tech/MCA(IT/Computer Science)

Years of Exp – 6-9",3.5,"upGrad Education Private Limited
3.5",Mumbai,"Mumbai, India",501 to 1000 employees,2015,Company - Private,Education Training Services,Education,₹1 to ₹5 billion (INR),"Udacity, General Assembly, Springboard"
872,BBRC-Genomics-Associate Scientist,"JOB DESCRIPTION

Designation: Associate Scientist

Job Location: Bangalore

Department: Translational Medicine- Translational Sciences

About Syngene

Incorporated in 1993, Syngene International Ltd. is an innovation-focused global discovery, development and manufacturing organization providing integrated scientific services to the pharmaceutical, biotechnology, nutrition, animal health, consumer goods and specialty chemical industries around the world. Syngene’ s clientele includes world leaders such as Bristol-Myers Squibb, Baxter, Amgen, GSK, Merck KGaA and Herbalife. Its innovative culture is driven by the passion of its 4240- strong team of scientists who work with clients from around the world to solve their scientific problems, improve R&D productivity, speed up time to market and lower the cost of innovation .

Job Purpose:
To play a key role in TM-TS, develop an early-stage research strategy, initiate and lead discovery programs while managing ongoing programs in TM-TS. The role will work part of TMTS, and work with internal and external collaborators .

Key Responsibilities:
Experience in isolating DNA and RNA from blood, tissues and FFPE samples and cell lines. Experience with optimization of extraction protocols and for parameters like yield, input sample quantities and sample types is important.
Expertise in PCR, qPCR, cDNA/gDNA library preparation. Exposure to microarray techniques.
Proficiency in preparation of libraries for Next Generation Sequencing of transcriptome and genome, with significant experience in optimization of parameters like input RNA/DNA quantities and sample type
Experience with single cell RNA-seq will be plus.
Experience with various NGS protocols (DNA Amplicon based, hybrid capture based low input, degraded DNA and RNA samples e.g. FFPE samples.
Strong understanding of experimental design and statistical principles behind experimental design and differential gene expression. Experience with analysis of single cell RNA-sequencing data will be a plus

Educational Qualification:
M.Sc or M. Tech in Biotechnology, Molecular biology or Biological Sciences,

Technical/functional Skills:
DNA/ RNA Isolation, Expertise in PCR, qPCR, Experience in NGS protocols

Experience:
2 to 5 Years

Behavioral Skills:
A proactive team player.
Ensure completion of experiments and generate accurate and reproducible data from experiments.
Ability to work independently, prioritize tasks and work on multiple projects simultaneously with; comfortable working in a dynamic environment with changing requirements.
Good oral and written communication and presentation skills to work in a multi-disciplinary team
Equal Opportunity Employer:
It is the policy of Syngene to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by applicable legislation or local law. In addition, Syngene will provide reasonable accommodations for qualified individuals with disabilities.",3.5,"Syngene
3.5",India,"BENGALURU, India",1001 to 5000 employees,1994,Unknown,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
873,Applied Scientist 1,"Position Requirements:
Master's degree in Computer Science, Computer or Electrical Engineer, Mathematics, or a related field plus at least one year of experience in the job offered or related occupations of Software Engineer, Software Developer, or a related occupation. Employer will accept a Bachelor’s degree and five years of experience in the job offered or a related occupation as equivalent to the Master’s degree and one year of experience. One year of experience in the job offered or related occupation must involve designing and developing large-scale, multi-tiered, distributed software applications, tools, systems and services using Java, Object Oriented Design and Distributed Programming].

Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, Oracle/Berkeley databases, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills

Amazon Selling Partner Services team drives the Selling On Amazon business and develops solutions that enable millions of sellers around the world to sell on Amazon's Marketplaces. More than half of shipments for Amazon customers are generated from this business. The team is focused on building a technology platform that will support the explosive business growth in existing markets, streamline the business for Amazon and the Selling partners and launch business in new markets and establish a fair marketplace.

Our team is seeking engineers with broad technical skills to help us optimize how we synthesize massive amounts of data and complex business rules into mission critical financial information. As a member of this team you will employ object oriented techniques in Java, and DynamoB, PostGres and ElasticSearch skills to help us support Amazon's next generation of selling partner services. Along the way you'll gain and leverage a unique understanding of how Amazon.com works; from the numerous software systems that comprise the website's back-end, to the details of our business model, and the relationships we're establishing with an ever-growing network of selling partners who depend on Amazon.com to run their businesses.

The ideal candidate will draw upon exemplary analytical, critical thinking, and problem solving skills, and a passion for maintaining highly reliable, distributed systems which operate 24/7/365. Successful members of this team collaborate effectively with internal end-users, aggressive cross-functional software development teams, and technical support/sustaining engineering teams to solve problems and deliver successfully against high operational standards of system availability and reliability. We look for engineers who are excellent communicators, self-motivated, flexible, hardworking, and who like to have fun!

Position Responsibilities:
Participate in the design, development, implementation, testing and documentation of large-scale, multi-tiered, distributed software applications, tools, systems and services using [Java, Object Oriented Design and Distributed Programming]. Translate functional requirements into robust, scalable, supportable solutions that work well within the overall system architecture. Participate in the full development cycle, end-to-end, from design, implementation, and testing to documentation, delivery and maintenance. Produce comprehensive, usable software documentation. Evaluate and make decisions around the use of new or existing software products and tools.

Preferred Qualifications
Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
874,Senior Clinical Data Analyst,"About Novotech:

Novotech is internationally recognised as the leading independent and full-service contract research organisation (CRO) in the Asia Pacific region. We provide a wide range of clinical development services across all research phases and therapeutic areas and have been instrumental in the success of hundreds of Phase I – IV clinical trials throughout the Asia Pacific. Powered by the highest quality people, Novotech strives to set the benchmark for both business and clinical trial performance. Our people are one of our key strengths. We value our people and recognise the work they do. We are lucky to have the best people and talent from across the Asia Pacific region work together to deliver to clinical trial success for our clients. Our people and those we look to recruit have an attitude of making things happen. They are problem solvers, driven with a focus on delivering quality, accountability and a high level of performance.

Brief Position Description:

As part of Novotech’s Biometrics unit, the Senior Data Analyst (SDA) is responsible for all data analysis and business intelligence activities related to study related clinical and operational data. The SDA acts as primary point of contact for all data analysis matters to the study team and is responsible for the timely delivery of quality outputs following all applicable regulatory, compliance, best practice and operational procedures.

Minimum Qualifications & Experience:

Graduate in information science, data science or life science-related field, or similar. More than five years’ experience in a senior role related to data science, data analysis, clinical data management or clinical data programming in a pharmaceutical company, CRO or EDC software provider.

Responsibilities
The Senior Data Analyst (SDA) is responsible for providing technical, procedural (SOPs) and planning leadership across multiple projects assigned to the data analyst team members ensuring that they deliver in accordance with SOPs, programming best practices, and the timelines agreed within the Project Team.
Collaborate with cross-functional stakeholders to implement data science solutions to solve business needs using available technological solutions.
Scope data analysis effort for projects and project manage all data analysis activities across multiple projects for different study stakeholders.
Gather study requirements from data management for data review and external data reconciliation and provide guidance on appropriate outputs (dashboards, visualisations, listings, reports).
Extract, assess, integrate, transform data sources to provide data visualisation outputs for analytics.
Design and develop prototypes and final versions of data outputs (dashboards, reports, visualisations, listings) using Business intelligence tools and Data Visualisation tools.
Design and develop standard dashboards and content for different audiences.
Analyse, manipulate and understand data from multiple sources to present and create dashboards and reports to make business decisions.
Assist teams on best-practice for data visualisation dashboard development.
Educate teams on how to use all the features of applicable data visualisation platform in conjunction with data visualisation dashboards.
SME for the data visualisation development and assisting team members.
Identify and communicate project risks and maintain documentation within project files as appropriate
Represent data analysis group at internal / external meetings as appropriate.
Assess and implement new data analysis, BI and data visualisation processes and technologies.
Take an active role in the development of best practices, process improvement, quality control and governance related to all data analysis matters.
Provide training and mentoring to Data Analysis of team members in SOPs, software applications, and best practices.
Provide Subject Matter Expertise on all data analysis and visualisation related activities.
Attributes and Skills

Expert knowledge of clinical study data structures and schemas of EDC databases. Expert knowledge in data processing activities such as extracting, integrating, transforming and presenting data. Statistical Programming skills in Python, R or similar. Knowledge of SQL and EDC systems. Working knowledge of Spotfire, Power BI, Tableau or other data review and visualisation tool. Ability to gather business requirements from multiple stakeholders and clients and provide guidance on the use of appropriate data visualisations.

Experience mentoring and training others. Awareness of regulatory and compliance issues and understanding of the application of SOPs and Quality Control to daily activities. Excellent analytical, communication and problem-solving skills.

Opportunities and Benefits:

To deliver clinical trial and research excellence for our clients, our people are 'best in class'.

At Novotech, we seek and nurture people with exceptional talent. We are committed to providing our people with regular internal and external training, a competitive bonus structure and a supportive work environment. We are also focused on providing our people with a wide variety of career growth and development opportunities.

For more information about where your next career step at Novotech might take you, visit http://novotech-cro.com/novotech-careers",4.5,"Novotech
4.5",Bengaluru,"Sydney, Australia",501 to 1000 employees,1996,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
875,Data Engineer,"Data Engineer Responsibilities:
Liaising with coworkers and clients to elucidate the requirements for each task.
Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed.
Reformulating existing frameworks to optimize their functioning.
Testing such structures to ensure that they are fit for use.
Preparing raw data for manipulation by Data Scientists.
Detecting and correcting errors in your work.
Ensuring that your work remains backed up and readily accessible to relevant coworkers.
Remaining up-to-date with industry standards and technological advancements that will improve the quality of your outputs.
Data Engineer Requirements:
Bachelor's degree in Data Engineering, Big Data Analytics, Computer Engineering, or related field.
Master's degree in a relevant field is advantageous.
Proven experience as a Data Engineer, Software Developer, or similar.
Expert proficiency in Python, C++, Java, R, and SQL.
Familiarity with Hadoop or suitable equivalent.
Excellent analytical and problem-solving skills.
A knack for independent and group work.
Scrupulous approach to duties.
Capacity to successfully manage a pipeline of duties with minimal supervision.
Job Type: Full-time

Salary: ₹360,000.00 to ₹870,000.00 /year

Experience:
total work: 2 years (Preferred)
Data Engineer: 1 year (Preferred)
Education:
Diploma (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,Futurious Technologies,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
876,Quantitative Analyst,"The successful candidate will be a highly analytical individual with hands on programming skills. The candidate will work closely with the research team and clients towards the ongoing development and integration of new investment strategies, models and tools on Axle

Location

Mumbai
Responsibilities

Perform daily/weekly/monthly tasks of performance and risk reporting
Develop and automate investment processes and strategies via VBA and Matlab
Develop tools to integrate trading decision systems with risk management systems
Ad hoc tasks (such as operational tasks, internal documentation tasks and preparation of marketing materials)
Skills/Experience

Excellent programming skills in Matlab/Excel-VBA
Thorough with financial concepts and calculations like Drawdown, VaR, Eloss etc.
Understanding of financial market products like options, futures, FX forwards etc.
Working knowledge of Bloomberg is preferred
Should be self-driven and detail oriented with an analytical mindset
Should be a proactive and quick learner; a team player showing enthusiasm and drive to accomplish results in a fast paced environment
Min. 2 years of relevant work experience
Qualifications

B.Tech/M.Tech/MBA/CFA/FRM",5.0,"B&B Analytics
5.0",Mumbai,"Zug, Switzerland",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
877,Analyst - Data Scientist,"Job Summary

Experience:
3 - 5 Years

Location:
Mumbai

Designation:
Analyst - Data Scientist

Degree:
BE-Comp/IT, BE-Other, BTech-Comp/IT, BTech-Other, ME-Comp/IT, ME-Other, MTech-Comp/IT, MTech-Other, PhD-Comp/IT, PhD-Other

Educational Level:
Graduate/Bachelors

Industrial Type:
IT-Software/Software Services

Functional Area:
IT Software - Application Programming / Maintenance

Key Skills:
Data Scientist

Job Post Date:
Thursday, March 19, 2020

Company Description

We are capability centre based in Mumbai, initially started as a back-office operational support to the UK business unit.

However, over the recent years, we have significantly increased the breadth and depth of our capabilities and offerings to keep pace with the changing needs of the Group. These include Digital & Knowledge Services, Finance and Actuarial, Information Technology (IT), Customer Service, Risk and Audit.

Our core purpose is to be a strategic partner to company, enabling growth by delivering change and driving synergies through a highly capable and agile workforce.

With our diversified service offerings we provide our people with exciting opportunities to grow personally and professionally.

Company is a leading savings and investments business serving around 5.5 million retail customers and more than 800 institutional clients.

It-s innovative asset management and customer solutions are supported by extensive investment capabilities, an international distribution network and two strong brands.

Job Description

3 – 5 yrs experience as Data Scientist
Should have at-least 1 end-to-end ML project experience
Very high proficiency in R or Python
Excellent in forecasting methods like simple exponential smoothing, multiplicative seasonal indexes, simple and weighted moving averages and time series forecasting methods
Exposure to with advanced deep learning techniques such as LSTM. CNN, Dense neural networks as well as neural networks design and implementation through tools like tensorflow, keras, pytorch, deepai or equivalent.
Good SQL experience",3.8,"Sampoorna Computer People
3.8",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
878,Data Lake Developer,"For Us, It's A Mission

At Mylan, we mean it when we say we work every day to provide access to high quality medicines to the world's 7 billion people. If you are unconventional, relentless and passionate. If you believe in doing what's right, not what's easy. If you are a doer and have a passion for serving others, we want to talk to you.

Make a Difference

At Mylan, each person has the ability to make a difference. From the providers who sell and market our products, to the producers who develop and manufacture them and finally to our business partners who support the providers and producers, we all have a mission critical role. Here's how this role will help:

ESSENTIAL DUTIES AND RESPONSIBILITIES
To perform this job successfully, an individual must satisfactorily perform each essential duty. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential duties.
1. Create and maintain optimal data pipeline architecture on Azure platform.
2. Develop batch processing solutions by using Data Factory and Azure Databricks.
3. Delivering a Data Warehouse in the Azure Cloud.
4. Design relational and non-relational data stores on Azure.
5. Identify, design, and implement internal process improvements : automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc..
6. Developing Big Data Solutions with Azure Machine Learning.
7. Strong interaction with business departments to provide consultative support for digitization efforts, as well as close collaboration with the Business Technology management, focused on future innovation topics.
8. Participate and lead in design sessions, demos and prototype sessions, testing and training workshops with business users and other IT colleagues.
9. Design & Build for any API Development or SQL DB development.
10. Providing service management, orchestration, monitoring and management requirements of Azure cloud platform.
11. Create data tools / products for analytics and data scientist team members that assist them in building and innovative solutions that drive tangible business value.
12. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
13. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
14. Design security for source data access. Chose the appropriate authentication mechanism, (ie Azure Active Directory (Azure AD), etc).
15. Design for real-time processing by using Stream Analytics and Azure Databricks.

Make Our Values Your Values

Mylan hires only the best. People who thrive in a culture of innovation and empowerment. People who are active learners and have a positive attitude. People who are leaders and know that by working together we can run faster, reach higher and achieve more. By doing so, we will continue to set new standards in health care. Here are the minimum qualifications and essential functions for this position:

QUALIFICATIONS

The qualifications listed below are representative of the minimum knowledge, skill, and/or ability required.

SKILLS AND ABILITIES

1. 10 years of experience in Microsoft technologies including SQL.

2. At least 5 years as a Sr Developer with at least 3 years hands on experience as Azure Data Engineer building large scale Azure data solutions.

3. At least 5 years of experience in Azure based data solutions.

4. At least 3 years of experience on working with large projects including the most recent project in the cloud (Azure) or on prem with a focus on Azure Data services.

5. At least 5 years of Hands-on administration, configuration management, monitoring, performance tuning of Hadoop/Distributed platforms.

6. At least 5 years of demonstrated experience at least in the most recent 2 years of designing and delivering solutions using Cortana Intelligence suite of analytics services part of Microsoft Azure including Azure Machine Learning Studio, HDInsight, Polybase, Azure Data Lake Analytics, Azure Data Warehouse, Streaming Analytics, Data Catalog, R/R Studio

7. Experience in designing and building logics required for optimal extraction, transformation, and loading of data from a wide variety of data sources

8. Experience within Data Security design, including but not limited to:

a. Choosing the appropriate authentication mechanism, such as Azure Active Directory (Azure AD)

b. Defining strategies for data encryption for data at rest and in transit

9. Experience partnering with Business Analysts and Data Scientists to enable effective and efficient data preparation and delivery

10. Experienced in vendor management and working with 3rd parties onshore & offshore.

11. Experience working in a global team.

12. Experience working in an Analytics / Big Data solutions on MS Azure Cloud

13. Experience with code management tools, automated testing

14. Experience creating and maintaining optimal data pipeline architecture on Azure platform

15. Experience developing batch and real-time processing solutions by using Data Factory and Azure Databricks

16. Familiar with AGILE and Azure DevOps methodology

17. Hands on PoC capabilities are needed to prove a particular architecture concept

18. Azure Native Services experience across Data Fabric and Service Fabric

19. Experience in Application modernization from legacy on-premise data architecture platform technology stack to modernized Azure Cloud base Architecture.

20. Experience with Git, NoSQL Data Solutions, Microsoft Azure, HD Insights, Azure ML, DataBricks ML Flow, R or Python.

21. Must have excellent communication skills.

EDUCATION/EXPERIENCE (Note: Please select one)

Minimum of a Bachelor's degree in Computer Science and Engineering is preferred with minimum 10 years of experience. However, a combination of experience and/or education will be taken into consideration

Why Mylan?

If you want to be part of a global health care company that is making a difference and changing lives, Mylan may be the place for you. With a workforce of more than 35,000 worldwide, we can make a difference. We encourage you to visit Mylan.com to learn more about our unconventional culture, our approach to doing business and how we plan to set new standards in health care.

Mylan offers competitive salary, excellent benefits and an environment conducive to professional growth and advancement. All qualified applicants will receive consideration for employment without regard to their disability or protected veteran status. Mylan is an Equal Opportunity Employer, Minorities/Female/Disabled/Veteran.",3.8,"Mylan Inc.
3.8",Bengaluru,"Hatfield, United Kingdom",10000+ employees,1961,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
879,Off Campus Recruitment - Quantitative Researcher,"Description:
Graviton is a privately funded quantitative trading firm striving for excellence in financial markets' research. We are seeking fresh talent from the top IIT's to join us as Quantitative Researchers for our team in Gurgaon.If you are a student graduating in 2020 from Computer Science , Electrical or Maths Stats Computing streams with a greater than 8 CGPA please apply here.

This role is open to students from campuses that we could not visit this year. Please check your individual placement policy restrictions before applying.

Graviton trades across a multitude of asset classes and trading venues using a gamut of concepts and techniques ranging from time series analysis, filtering, classification, stochastic models, pattern recognition to statistical inference analysing terabytes of data to come up with ideas to identify pricing anomalies in financial markets.

As a Quantitative researcher your responsibilities will include

Develop new or improve existing trading models using in-house platforms

Use advanced mathematical techniques to model and predict market movements

Analyse large financial datasets to identify trading opportunities

Provide real time analytical support to experienced traders

Requirements :
Possess a degree in a highly analytical field, such as Engineering, Mathematics, Computer Science from IITs schools

Quantitative bend of mind

A working knowledge of Linux/Unix

Programming experience, preferably in C++ or C

Strong interest in learning about financial markets.

Have a strong work ethic

Hard Working

Benefits:
Our open and casual work culture gives you the space to innovate and deliver. Our cubicle free offices , disdain for bureaucracy and insistence to hire the very best creates a melting pot for great ideas and technology innovations. Everyone on the team is approachable, there is nothing better than working with friends!

Our perks have you covered.

Competitive compensation

6 weeks of paid vacation

Monthly after work parties

Catered breakfast and lunch

Fully stocked kitchen

Gym membership

International team outing",5.0,"Graviton Research Capital LLP
5.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2014,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
880,Data Engineer,"Zauba Technologies is a startup based in Bangalore. Zauba's services are used by leading companies in India. Zauba is powered by a young and passionate team. We are looking for individuals who would like to be a part of our founding team.

As a Data Engineer and as a part of founding team, you will be expected to visualise and develop disruptive data products. Eventually you would be responsible for entire project lifecycle of products you would visualize. Your rewards will be directly proportional to the value you generate.

Job Responsibilities
Design and development of robust, scalable and highly efficient data engineering solutions for structured and unstructured data (Including gathering and processing raw data at scale, writing scripts, web scraping, calling APIs, writing SQL queries, etc.)
Develop processes for text mining and extraction of information from unstructured data
Design, architect and develop efficient data pipelines around the data collected
Take ownership of existing web product and applications
Design and implement data models that scale across the enterprise
Take ownership of existing data workflows and processes
Enhance scalability, performance, and stability of existing infrastructure
Work closely with other team members to integrate your innovations and algorithms into our production systems

Essentials
Java/Python - Intermediate to advanced level
SQL - Advanced
MySQL Intermediate to advanced level
Regex - Basic to intermediate level
Linux Basic to intermediate level

Good to have
Hadoop/Spark
R
MongoDB

Must have qualities
Skills to learn new skills quickly
Desire to create disruptive products and services
Passion - not just to work in startups but to take them to next level
Above average programming aptitude
Be passionate about producing high quality engineering deliverables
Be productive working independently or collaboratively
Have an eye for building efficient processes
Be self motivated
Proactively take ownership

Interested?

Send your resume to hr@zaubacorp.com",3.8,"Zauba Corp
3.8",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 million (INR),-1
881,Quantitative Research,"We are looking for highly trained professionals who are interested in applying advanced mathematical quantitative methods to the modeling of global financial markets. You would be joining a group made up of highly proficient individuals from various scientific disciplines. We have a spectrum of opportunities for individuals with the right scientific skills. Experience in finance is not required.

The ideal research candidate will have:
A Ph.D. in Computer Science, Mathematics, Physics, Statistics, or a related technical discipline.

A demonstrated capacity to do first-class research.

Computer programming skills.

An intense interest in applying quantitative analysis to solve difficult problems.

Send us a copy of your resume to
careers@dolatcapital.com

For internship opportunities, please send us a copy of your resume to
careers@dolatcapital.com",4.0,"Dolat Capital
4.0",Mumbai,"Mumbai, India",51 to 200 employees,1970,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
882,Data Engineer,"Bachelor’s degree in Computer Science or related field
5+ years relevant experience
5+ years experience with SQL, SQL Tuning, Oracle, OLAP, Big Data Technologies
5+ years experience developing end-to-end Business Intelligence solutions: data modeling, ETL and reporting
Experience with Java and experience with scripting languages like Perl, Python, Unix shell scripts,VBA and MS Excel
Proficiency with Linux and systems administration
Proven ability at looking at solutions in unconventional ways. Sees opportunities to innovate and can lead the way.
Top notch communication (verbal and written) and interpersonal skills to convey key insights from complex analysis in summarized business terms and an ability to effectively communicate with technical teams.
Ability to work with shifting deadlines in a fast paced environment.
Operations Finance Technology team, responsible for building technical solutions for multi-billion WW Operational Cost analytic including Inbound cost (Receiving / PO), variable Cost, fixed cost, outbound (Customer Shipments / Transportation), and Customer Service, is looking for a Data Engineer.

As a data engineer, you will get the exciting opportunity to work on very large data sets in one of the world's largest and most complex data warehouse environments. You will work closely with the business teams in analysis on various cost savings initiatives, many non-standard and unique business problems and use creative-problem solving to deliver actionable output.
You will be responsible for designing and implementing an analytical environment using third-party and in-house reporting tools, modeling metadata, building reports and dashboards. You will have an opportunity to work with leading edge technologies like Redshift, Hadoop/Hive/Pig. You will be writing scalable queries and tuning performance on queries running over billion of rows of data.

You should be analytical, have an extremely high level of customer focus and a passion for process improvement. You should be motivated self-starter that can work independently in a fast paced, ambiguous environment. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions.
Bachelors in Computer Science or related field
Practical Knowledge of Linux or Unix shell scripting
Experience in working with business customers to drive requirements analysis
Exposure to large databases, BI applications, data quality and performance tuning
Excellent written and spoken communication skills
Experience with Hadoop-based technologies such as HBase, Pig, Hive and Spark
Strong proven ability in building high-performance, highly available and scalable data solutions using Oracle and/or Hadoop-based technologies
Knowledge of data warehousing concepts.
Strong sense of ownership, urgency, and drive
Strong troubleshooting and problem solving skills
Experience with Amazon Web Services",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
883,DATA ANALYST,"posted by Mahima Gaur

2 - 5 years Delhi

Job Description
Experience in data processing
Experience in data cleaning and data tabulation activities
Strong analytical, communication and team management skills
Strong understanding of data management using SPSS and research techniques
Competency in a Tabulation software (decipher / wincross / quantum etc), Excel, Powerpoint
Ability to summarize findings, draw conclusions, and put together a presentation using Powerpoint
Role Category : Data Analyst

Employment Type : Permanent Job, Full Time",4.9,"Knowledge Excel Services.
4.9",New Delhi,"New Delhi, India",1 to 50 employees,2007,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
884,Data Engineer,"Key skills : Python , Spark , SQL , Pyspark • AWS platform used for the work • Strong experience in SQL is mandatory • Good familiarity of AWS landscape • Good experience in collecting business requirements & design them as per requirement from customer • Should able to work independently & interact business users & technical stakeholders • Strong communication skills both oral & written. • Should work as an individual resources",3.5,"Larsen & Toubro Infotech Limited
3.5",India,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
885,Big Data Engineer,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
886,Client Data Analyst,"At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.
What is the Client Data Analyst – Client Analytics group responsible for?
This team manages business data to ensure accurate, timely, consistent and compliant data. Their contributions deliver quality data that is easily accessible and can be trusted. Key downstream capabilities such as reporting and analytics depend on this as well as operational data access on various systems. The Data Management Team is a support function that acts as an advocate and a point of contact for Sales and Marketing data.

What are the ongoing responsibilities of an Client Data Analyst ?
Understand the data flow, key consumption and production of data as well as context within the enterprise:
Build positive relationships with teams, especially the key data consumers and analytics. Take the time to increase knowledge of how they run their business and incorporate sales data into daily work
Connect regularly with each sales office to understand current issues and challenges. Probe the business and validate against other sales offices to understand the scope and priority of the issue
Make recommendations on how data unifications and flow can be used to improve business tasks. Liaise business partners to deliver solutions (reports, processes, technology) that add value.

Provide data management subject matter expertise. Appreciate the connection and data flow between applications and other corporate systems. Be able to clearly articulate the data needs and move initiatives forward by collaborating with business partners:
Actively participate in meetings with business partners to ensure that priorities are clearly understood, information is regularly shared and that key participants are “kept in the loop”
Provide context and background on issues. Collaborate on ideas for progressing initiatives. Ensure appropriate resources are involved to take initiatives forward
Provide insights and expertise to scope statements and requirements documentation
Actively consult or participate in the user acceptance testing process (test cases, documentation, testing execution, etc.)
Ensure business needs remain aligned with overall corporate initiatives and deliver the benefits as originally intended

Monitor the integrity of data and usefulness of reports. Ensure the information available within systems is accurate and up-to-date. Proactively seek data cleansing opportunities and evolve data to better support. Document and maintain ongoing processes for reporting and data clean-up:
Partner with all key data consumers to gain a solid understanding of usage and challenges around data. Establish processes for prioritization of enhancements, especially with the analytics groups
Provide 1st level support for data issues and data maintenance for owned data
Verify and execute data loads into our internal sales systems and ensure any upstream systems accurately receive their data

Increase awareness and promote data management capabilities. Share best practices and provide coaching to local offices on how to access and incorporate output into sales tasks. Encourage IAS leaders to leverage data to make more informed, strategic decisions:
Clearly articulate the goals and core services of the data management team. Proactively promote this information within IAS and ensure business partners understand the data management role within the organization
Share best practices and provides guidance on data capabilities. Reinforces ownership and accountability for data accuracy
Seek opportunities to share the benefits of leveraging sales data to make more informed business decisions

What ideal qualifications, skills & experience would help someone to be Successful?

Knowledge, Education And Experience:
Four year bachelor’s degree required (majors of preference include: business, computer science, mathematics) Advanced degree a plus
Understanding of the Franklin Templeton business model, how FT makes money, the sales process, how technology fits in with the business, etc. Knowledge of the GAS (Global Advisory Services) structure
Experience working through multiple business fiscal cycles; exposure and/or direct experience with project management and/or sales-related-capacity required
Prior work experience related to analytics, sales, marketing and/or international a must. Level will not be granted based on years of experience but will be determined by the employee’s ability to meet each job activity as outlined the ‘typical/expected focus by level
Skills And Abilities:
Ability to communicate effectively with all levels of management; ability to tailor communication style based on audience; ability to get others to want to collaborate with you; strong facilitation skills
Excellent writing skills (for presentations, documentation, etc.)
Working knowledge of the CRM, MDM, Excel, SQL, Power BI, Tableau, Business Objects, and Microsoft Products (PPT, Power Apps, Doc, Visio)
Ability to absorb and interpret large quantities of data; apply trend analysis and knowledge of the business to develop a meaningful and digestible summary with the appropriate level of detail
Ability to take a larger problem and break down the individual components; identify how to go about solving the problem and who to involve in the process
Ability to present recommended solutions to a variety of issues and problems (solutions that are consistent with organization objectives)
Must be extremely detail-oriented (managing lists, tasks/to-dos, etc.) good with follow through on own items; good with following up with others on outstanding item

What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.

Highlights of our benefits include:

Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.",3.8,"Franklin Templeton Investments
3.8",Hyderabad,"San Mateo, CA",5001 to 10000 employees,1947,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Fidelity Investments, Vanguard"
887,Data Analyst,"Roles and Responsibilities:
Extracting, transforming and inputting data sets from various resources. Creating predictive models, translating non-technical aspects into quantifiable tasks. Analysis and representation of output data, highlight and explain trends and patterns, error elimination, using advanced statistical methods (regression, probability distribution, clusters etc.) to provide accurate results.
Data collection, Data Mining, Report generation, Problem identification and solution formulation Market analysis and establishing trends, Strategy development and implementation

Skills:
Extremely good analytical skills.
Good working knowledge of all MS-Office products, especially Advance Excel, Word, PowerPoint, MS-access.
Statistical tools and methods.

Interested candidates can send the updated resume on satish.mehra@exelaonline.com or call on 7722028636
00-7.00 Years",2.6,"Exela Technologies
2.6",Pune,"Irving, TX",10000+ employees,2017,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"SourceHOV, BancTec, Transcentra"
888,Data Modeler,"• Minimum 5-8 years of working experience as Data modeler.
• Data modelling experience in designing.
• Minimum 2-3 years real time experience in Erwin tool is mandatory.
• Experience in normalized modeling techniques.
• Experience in designing the Start schema.
• Experience working in ORACLE.
• Experience with database design, capacity planning, performance tuning and query optimization.
• Experience in working with Bank or Banking and Finance or Financial domain.
• Excellent communication skills with leadership quality.

Job Segment:
Database, Oracle, ERP, Technology",3.5,"LTI
3.5",Mumbai,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
889,Machine Learning Engineer,"Looking for Data Scientists with Python/R Programming skills.
Specific experience in AI areas like Statistical Machine learning / Deep learning / Natural Language Processing (NLP)/ Operations Research (Optimization) will be an advantage.Individual in this role is expected to work with multiple stakeholders and teams

Qualifications and Requirements:-
Previous working experience as a Machine Learning/ Data Scientist for 2 years
MA in Computer Science or similar relevant field
Hands on experience with MALLET
In depth knowledge of Apache Tomcat/Open Source
Excellent project and time management skills
Attention to detail
Outstanding problem solving and analytical skills",-1,Tekolutions.ai,India,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
890,Data Science Internship,"About the company:
SkillBit is a leading staffing and recruitment company engaged in talent searching assignments for skilled and talented candidates for the industry.

About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Working on data science algorithms and AI concepts 2. Using Python or R for web scraping 3. Building AI models using Python, machine learning, and deep learning algorithms 4. Processing of unstructured/structured data

Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 6th Jun'20 and 11th Jul'20
are available for duration of 1 month
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply

Number of internships/jobs available: 3

Categories: Data Science",-1,SkillBit,Pune,-1,-1,-1,-1,-1,-1,-1,-1
891,Data Engineer,"As a data engineer at TEAL, you'll be taking the plunge into a rich data lake that includes everything from satellite data to legal court orders. You'll be hustling and getting your hands dirty with every part of the data pipeline always having an implicit appreciation for how all of this data will ultimately power a revolutionary real estate risk platform.

Your day-to-day will include either all or some of the following:

Constantly scoping out new data sources to complement existing ones
Creating and maintaining distributed web scrapers using Python, RabbitMQ and other technologies
Architecting and managing data pipelines where data flows into multiple end-points including, but not limited to, Postgres, MongoDB and Apache Solr
Documenting workflows and constantly iterating to create better data infrastructure.

We'd love it if you:
Are proficient in Python or any other object-oriented language
Have worked with large (millions to hundreds of millions of rows in a SQL database) interdisciplinary datasets
Have scraped difficult websites and have some experience working with various data APIs
Are patient and methodical with unstructured and messy data
Are always hungry to learn newer and better technologies to make the data ecosystem faster, smoother and less silo-ed

Extra brownie points if you:
Have some experience working with large-scale search indexing
Have performed geospatial analyses in some capacity
Have created and managed data lakes in the cloud
Culture

To explore our culture and the values we embody click here

Testimonials
Testimonial

My experience at TEAL surpassed all my expectations from the get-go. I was asked to help solve one of the most daunting problems in the Indian real estate market. Every day while working on a subset of the problem, the ideas that I brought to the table were shaped into cohesive solutions by a collaborative team effort. At TEAL I was exposed to the most cutting edge technologies such as Cloud Computing, Big Data, ML and Data Science. The growth opportunities at TEAL are tremendous, If you are innovative and can demonstrate the will to realize your ideas, TEAL is an amazing organization to work for.
Gyan Vardhan, Data Science Intern
I had interned as a Data Scientist at Terra Economics and Analytics Lab during its early days, it was a rich learning experience working with a multi-disciplinary team who are extremely passionate about building a decision support platform for the insanely complicated realty market in India. It was exciting and challenging to work on mining huge volumes of property records; extracting patterns from the data, building data pipelines and brainstorming on building the core system. TEAL offers a very healthy work environment coupled with insanely talented people working together in an exciting setting.
Naga Anjaneyulu, Data Science Intern
I worked as a full-time Data science intern at TEAL. During this period, I got an opportunity to leverage my skillsets while also learning new technologies, working on tasks assigned to me. The company operates on the latest tech-stacks and gives opportunities to learn as much as you want. The work environment is challenging, the team at TEAL is super supportive and new ideas are always welcome. It has all the good perks of a startup; creativity and innovation, casual work atmosphere and a collaborative approach to solving problems. Personally, I loved working there, my experience was fantastic!
Archana Parmar, Data Science Intern
As a second-year college student, I was looking for an internship that would allow me to delve deeper into research and work with big data, TEAL gave me the perfect opportunity to do so, enabling me to develop proficiency in research and analysis. As a research analyst intern, I collated and cleaned data and helped in the preparation of reports and presentations, and I had members helping me at every stage of this process. This collaborative environment allowed me to cultivate my skills and also learn from my peers. The holy trinity of Rohan, Kshitij, and Shreyas served as not only excellent mentors and bosses but also as friends, helping me at every stage and giving us all food and ice cream to keep us going!
Arush Mehra, Research Intern
Internships are a crucial part of one’s early career. The internship experience at TEAL was a thrilling rollercoaster ride to say the least! It was more than implementing a standard model or building an already though out concept into reality. It was about finding the solution to a unique and open-ended problem.It was exciting to work on addressing a problem with far -reaching real world applications.Moreover, the work environment had the perfect balance of casual yet professional which kept you focused and stress free at the same time. Out of every 100 startups in India only 2 of them succeed, but there are very few like TEAL India which are bound to make it big at such an early stage.
Divyanshu Agarwal, NLP Intern",4.7,"Terra Economics & Analytics Lab (TEAL)
4.7",New Delhi,"Bengaluru, India",1 to 50 employees,2018,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
892,Senior Consultant - ModellingOps Data Engineer,"Job Title: Senior Consultant - ModellingOps Data Engineer
Location: TRIL GTC
GCL: D1

JOB DESCRIPTION:

AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. The Science & Enabling Units IT is AZs global IT capability function supporting key business areas operating out of sites across the US, UK, Sweden, India & Mexico.

We are looking for AI Ops consultant who will leverage tools & technology best practices to improve delivery performance & data engineering capabilities in the D&A space.

ROLES & RESPONSIBILITIES:

7-10 years of experience in IT Operations involving Data Science, Artificial Intelligence-Machine Learning and Predictive Analytics. Experience in architecting and implementation of end-to-end AIOPs solutions through ELK stack, Splunk. Experience in applying statistical methods, analysis, pattern recognition and modeling on IT Operational data using ELK machine learning. Experience in extracting meaning full data from incoming data streams from different sources through RegEx, Grok etc. Hands-on experience in applying machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc in the IT Operation domain. Experience with machine learning and statistical programming languages - Python, R etc. Experience in assessing the existing IT environment and providing recommendations to reduce the critical applications impacting incidents. Experience in exploring and identifying areas where manual tasks can be automated in IT environment. Experience with various Enterprise IT monitoring solutions including Infrastructure monitoring, Application Performance Monitoring, Network Monitoring, Cloud monitoring etc. Experience in IT Service Management including Service Desk, Incident Management, Change Management, CMDB etc. Excellent knowledge on various IT infrastructure components that includes Server Infrastructure, middle ware, database and application architectures and Cloud Components. Experience/knowledge on Infra monitoring tools - NOI, Zabbix, AppDynamics, Datadog, SCOM, SolarWinds etc. and Service Management tools -IBM Control Desk, BMC Remedy, ServiceNow etc. Experience/Knowledge on BI tools Knowledge on distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc. Knowledge on other programming languages/scripting: Python, Java, JavaScript, etc. ( Added Advantage ) Good analytical skills, strong communication skills are must. Client facing experience is an added advantage. Excellent experience in understanding the problem statement, architect and designing the solution

MANDATORY SKILLS:
Significant experience with AWS cloud environments, working knowledge of Google and Azure platforms. Knowledge of Kubernetes, S3, EC2, Sagemaker, Athena, RDS and Glue is essential.
Experience provisioning computational resources in a variety of Cloud environments using Infrastructure as Code.
Experience with best practice of data transport and storage within cloud system.
Experience building large scale data processing pipelines. e. g. Spark and SQL.
Experience with containers and microservice architectures e.g. Kubernetes, Docker and serverless approaches.
Excellent working knowledge in DevOps, using continuous integration and continuous development.
Use of Data Science modelling tools e.g. R, Python, SAS and Data Science notebooks (e.g. Jupyter).
Good written and verbal skills, fluent English
DESIERED SKILLS:
Agile practices, especially being a SCRUM Master
EDUCATIONAL BACKGROUND: B.E/B.Tech/MCA

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",3.9,"AstraZeneca
3.9",Chennai,"Cambridge, United Kingdom",10000+ employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Roche, GlaxoSmithKline, Novartis"
893,DATA ENGINEER,"JOB DESCRIPTION
As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements, and also research new uses for data acquisition. You should also know the ins and outs of the industry such as data mining practices, algorithms, and how data can be used.

DESIRED CANDIDATE PROFILE
An ideal candidate must possess prior experience leading a project.

Candidates must have:
> Experience in Hive, Spark, Scala, AWS DynamoDB, HBase, AWS Glue, Talend, Kafka, Snowflake ETL
> Strong experience in a BI/Data Warehouse environment with involvement in design, development, implementation, troubleshooting and support of ETL process using ETL tool.
> Experience in developing Data Marts, Data warehousing and Operational Data Store (ODS) on any of the databases or Hadoop environments.
> Experience in database like MS SQL, MySQL, Oracle, PostgreSQL
> Good to have programming experience in writing Complex Stored Procedures, Queries, Views, User Defined Functions, Cursors and Common Table Expressions using SQL or T-SQL.
> Experience in Performance Tuning and Query Optimization by Indexing, Partitioning and De-normalization.
> Experience in Developing a framework for ingesting data into Data lake
> Good database knowledge, analytical thinking
> Design, construct, install, test and maintain data management systems.
> Build high-performance algorithms, predictive models, and prototypes.
> Develop set processes for data mining, data modeling, and data production.
> Experience with cloud services: AWS (EC2, EMR, S3, Athena) and scripting languages like Python, /PySpark/R/SAS
> Install/update disaster recovery procedures.
> Experience in Agile Application Development & Scrum methodologies is preferred
> Ability to supervise and mentor junior developers on the team.
> Must be self-motivated and work well pulling people together in addition to being able to pull people together technically
> Demonstrated proficiency of troubleshooting techniques and detail-oriented problem diagnosis
> Ability to handle responsibility, is self-directed, with strong organizational and documentation skills
> Ability to work independently and efficiently under aggressive deadlines to meet project commitments
> Excellent verbal and written communication skills

EDUCATION
UG - B.Tech/B.E. - Computers, Electronics/Telecommunication, Diploma - Computers, Electronics/Telecommunication, B.Sc - Computers, BCA - Computers) AND (PG - M.Tech - Computers, Electronics/Telecommunication, MCA - Computers, M.Sc - Electronics, Computers) AND ( Doctorate - Any Doctorate - Any Specialization, Doctorate Not Required).

OTHER DETAILS
Number of vacancies: 4
Experience: 3 years
Location: Cochin

If you have a passion towards technology and coding, then we have the right job for you. Kindly forward your resumes to
Email: jobs@mjsofttech.com
Phone: 0484-2421245 / 928 720 7160",4.0,"MJ Softtech
4.0",Kochi,"Cochin, India",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
894,Data Engineer,"Education/ Experience and Skill Requirement
4+ years of relevant experience in
Experience working with both relational and NoSQL databases.
Strong coding skills; Python (preferred) /R/Java/Scala
Experience in developing Data warehousing technologies Experience with AWS or equivalent cloud services preferred
Experience in BigData technologies (Hadoop, HDFS, MapReduce, Spark, Hive, HBase etc) will be valuable
Knowledge of Machine Learning a big plus (Random Forest, Decision Trees, SVM, NLP, Gradient Boosting, Supervised/Unsupervised Learning, Clustering, classification and regression modeling).
Responsibilities
Proficiency with several years’ experience in more than one of Python, R, Java, Scala, or robust Linux shell scripting
Implementation experience with data warehouse architecture & design, ETL design/development, and Analytics
Knowledge of general cloud architecture and cloud strategies especially around AWS services and concepts such as S3 object stores, RDS databases, EC2, Glacier, Lambda, IAM, enterprise security, data security, DevOps, replication and disaster recovery
Well versed with data mining & exploration, NLP and visualization
Understanding of data modeling, data integration, and data representation (metadata, OWL, ontologies)
Developing data marts and data management using SQL
Creating powerful visual outcomes
Independently manage daily client communication, especially over calls
Manage client deadlines, ensure quality of the deliverables, attention to detail
Experience/understanding of corporate finance data from company filings is desirable",3.6,"Copal Partners
3.6",Bengaluru,"New York, NY",10000+ employees,1900,Company - Public,Financial Analytics & Research,Finance,₹100 to ₹500 billion (INR),-1
895,Data Engineer,"Job Description / Responsibilities
Build workflows to ensure data extraction quality and storage into our backend data store
Architect, build and train ML/AI models that can predict outcomes and report on anomalies.
Design data pipelines to perform ETL on content/data from multiple types of source systems.
Create data analytics views using RDBMS/Key-Value stores, on private and public/cloud
Create software that is well tested, maintainable, extensible and scales out with large data

Minimum Qualifications:
2+ years of software development with Python
2+ years of SQL (MySQL/Postgres) and Key-Value databases
1+ years of experience with scikit
2+ years of experience in data extraction, data transformation using custom Python/Java
Experience working with MapReduce/Hadoop/kafka/Elastic stack
Experience with Node backend and React/Redux
Experience working with git/mercurial, Amazon/Google cloud, Linux/LAMP stack
Experience in testing or test driven development
Experience with Data science and Machine Learning algorithm development

Location:
Hyderabad/Bangalore

Package:
Highly competitive to match experience and capability",3.7,"TVS
3.7",Bengaluru,"Chennai, India",5001 to 10000 employees,-1,Company - Private,Accounting,Accounting & Legal,₹100 to ₹500 billion (INR),-1
896,Data Engineer,"Permanent position with US based client of iFlex.
Work Location: Bangalore
Experience Level: 2+ Years

Role:
As part of our global team you will work on the data platform reporting to the Data Engineering Lead. Your role includes specification, development, test and rollout of features on our data platform. You are expected to contribute to the vision, understand our product roadmap, integrate business value andclient experience and contribute to build an engineering culture within the team. This initiative is of critical important to the success of the organization and our roadmap, for instance, services like liquidity analytics, billing, client onboarding, reporting and others will rely on the data platform. Accurate, granular, complete and timely data will be our key differentiating factor and competitive advantage in the market place. We expect the successful candidate to deliver high quality software and to be passionate about data engineering..

Responsibility / Qualification:
Managing multiple tasks and use sound judgment when prioritizing.
Collaborating with global cross functional team in building customer-centric products.
Analyzing existing software implementations to identify areas of improvement and provide deadline estimates for implementing new features.
Updating and maintain documentation for team processes, best practices and software runbooks.
Establishing trusted partnerships with peers, product heads, and executive level stakeholders.
We are looking for someone who is passionate about technology and engineering.
Exceptional analytical skills and ability to apply knowledge and experience in decision-making to arrive at creative and commercial solutions.
Ability to leverage technology to deliver business value.
You are independent and comfortable in a fast paced, ambiguous and often multi-directional work environment.

Preferred Qualifications:
B.S. or higher in Computer Science.
Minimum 2 years of relevant professional experience using a modern programming language (preferably Java/Scala).
Experience leveraging test driven development technics.
Comfort with Agile operating models.
Team oriented.
Strong interpersonal and communication skills.
Energetic, self-directed, and self-motivated.
Experience with microservice architecture.
Experience with Kafka, MongoDB, Hadoop, Cassandra.
Experience with AWS.
Experience in Financial Services or Fintech.",-1,IFLEX,Bengaluru,"Moscow, Russia",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
897,CIEL/SEL/1941: Sr data scientist,"Mandatory skills required -
Databases (SQL, Oracle, Any RDBMS) - Should have working knowledge of atleast one database
PL/SQL Programming Languages
R, Python (Any One)
Inferential Statistics - Hypothesis, p-value, R2, RMSE, MAPE etc
Exploratory Data Analysis
Machine Learning Algorithms - Should have in-depth knowledge and implementation of atleast one algorithm

Responsibilities
: Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the why & how of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions

Education
Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics
Experience
Minimum years of related experience required: 3 years
Preferred years of experience: 5 years
Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desirable.

Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
898,Data Engineer,Data Engineer,3.6,"Bookmyshow
3.6",Mumbai,"Mumbai, India",1001 to 5000 employees,2007,Company - Private,Ticket Sales,"Arts, Entertainment & Recreation",Unknown / Non-Applicable,-1
899,Data Analyst,"Required Skills & Experience

We are looking for a Data Analyst Executive
Eligible Qualifications : B. Tech, BCA, M.Tech, MCA
Experience : 3-5 years, fresher’s can also be considered
Location of Job : Gurgaon/Connaught Place, New Delhi
Technicals Skills

Following technical skills are pre-requisite:
Well versed with Software development methodologies, such as SDLC (Software Development Life Cycle), DDLC (Document Development Life Cycle).
Database schema design and implementation
Should have worked in either of technologies Sql Query/ Tableau/ Excel (Macros)/ Access (Query) writing for data analytics.
For planning and coordinating activities, organizations remain in invariant communication with one another and the data transfer has to be performed efficiently and smoothly as possible.
He/ She should manage the execution of the technologies, help the businesses in utilizing the systems, and should be well versed with the basics of computer systems such as Networking, Installation of necessary software and hardware.
Ability to determine the interrelationships between solutions and requirements.
Ability to think analytically and should be a problem solver and logic building should be very strong.
Good interpersonal skills to form effective working relationships with people at all levels.
Excellent communication and presentation skills and strong written & oral English skills.
To know more about us visit us www.sspl.net.in or write to us at admin@sspl.net.in",-1,Substratal Solutions,Connaught Place,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
900,Artificial Intelligence Scientists,"Experience 2- 4 Years
Salary 4 LPA - 6 LPA
Job Location Chennai

Industry:
IT-Software / Software Services

Keywords:
Artificial Intelligence

About Job:
Must have Excellent knowledge in AI / Machine learning (Mandatory).
Machine learning frameworks like keras, tensor flow etc.
And also other big data tools like Hadoop etc, Must know R and python.
Good understanding in SDLC & Business cycle.",4.0,"Careerera
4.0",Chennai,"Wayland, MA",501 to 1000 employees,-1,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
901,Senior Data Engineer,"About Us

upGrad is an online education platform building the careers of tomorrow by offering the most industry-relevant programs in an immersive learning experience. Our mission is to create a new digital-first learning experience to deliver tangible career impact to individuals at scale. upGrad currently offers programs in Data Science, Machine Learning, Product Management, Digital Marketing, and Entrepreneurship, etc. upGrad is looking for people passionate about management and education to help design learning programs for working professionals to stay sharp and stay relevant and help build the careers of tomorrow.
upGrad was awarded the Best Tech for Education by IAMAI for 2018-19
upGrad was also ranked as one of the LinkedIn Top Startups 2018: The 25 most sought-after startups in India
upGrad was earlier selected as one of the top ten most innovative companies in India by FastCompany.
We were also covered by the Financial Times along with other disruptors in Ed-Tech
upGrad is the official education partner for Government of India - Startup India program
Our program with IIIT B has been ranked #1 program in the country in the domain of Artificial Intelligence and Machine Learning
About the Role

We are looking for a Data Engineer to help us scale the existing data infrastructure and in parallel work on building the next generation data platform for analytics at scale, machine learning infrastructure and data validation systems.
In this role, you will be responsible for communicating effectively with data consumers to fine-tune data platform systems (existing or new), taking ownership and delivering high performing systems and data pipelines, and helping the team scale them up, to endure ever growing traffic.
This is a growing team, which makes for many opportunities to be involved directly with product management, development, sales, and support teams. Everybody on the team is passionate about their work and we’re looking for similarly motivated “get stuff done” kind of people to join us!

Roles & Responsibilities
Engineer data pipelines (batch and real-time ) that aids in creation of data-driven products for our platform
Design, develop and maintain a robust and scalable data-warehouse and data lake
Work closely alongside Product managers and data-scientists to bring the various datasets together and cater to our business intelligence and analytics use-cases
Design and develop solutions using data science techniques ranging from statistics, algorithms to machine learning
Perform hands-on devops work to keep the Data platform secure and reliable
Skills Required
Bachelor's degree in Computer Science, Information Systems, or related engineering discipline
6 + years’ experience with ETL, Data Mining, Data Modeling, and working with large-scale datasets
6+ years’ experience with an object-oriented programming language such as Python, Scala, Java, etc
Extremely proficient in writing performant SQL working with large data volumes
Experience with map-reduce, Spark, Kafka, Presto, and the ecosystem.
Experience in building automated analytical systems utilizing large data sets.
Experience with designing, scaling and optimizing cloud based data warehouses (like AWS Redshift) and data lakes
Familiarity with AWS technologies preferred
Qualification – B.Tech/M.Tech/MCA(IT/Computer Science)

Years of Exp – 6-9",3.5,"upGrad Education Private Limited
3.5",Mumbai,"Mumbai, India",501 to 1000 employees,2015,Company - Private,Education Training Services,Education,₹1 to ₹5 billion (INR),"Udacity, General Assembly, Springboard"
902,BBRC-Genomics-Associate Scientist,"JOB DESCRIPTION

Designation: Associate Scientist

Job Location: Bangalore

Department: Translational Medicine- Translational Sciences

About Syngene

Incorporated in 1993, Syngene International Ltd. is an innovation-focused global discovery, development and manufacturing organization providing integrated scientific services to the pharmaceutical, biotechnology, nutrition, animal health, consumer goods and specialty chemical industries around the world. Syngene’ s clientele includes world leaders such as Bristol-Myers Squibb, Baxter, Amgen, GSK, Merck KGaA and Herbalife. Its innovative culture is driven by the passion of its 4240- strong team of scientists who work with clients from around the world to solve their scientific problems, improve R&D productivity, speed up time to market and lower the cost of innovation .

Job Purpose:
To play a key role in TM-TS, develop an early-stage research strategy, initiate and lead discovery programs while managing ongoing programs in TM-TS. The role will work part of TMTS, and work with internal and external collaborators .

Key Responsibilities:
Experience in isolating DNA and RNA from blood, tissues and FFPE samples and cell lines. Experience with optimization of extraction protocols and for parameters like yield, input sample quantities and sample types is important.
Expertise in PCR, qPCR, cDNA/gDNA library preparation. Exposure to microarray techniques.
Proficiency in preparation of libraries for Next Generation Sequencing of transcriptome and genome, with significant experience in optimization of parameters like input RNA/DNA quantities and sample type
Experience with single cell RNA-seq will be plus.
Experience with various NGS protocols (DNA Amplicon based, hybrid capture based low input, degraded DNA and RNA samples e.g. FFPE samples.
Strong understanding of experimental design and statistical principles behind experimental design and differential gene expression. Experience with analysis of single cell RNA-sequencing data will be a plus

Educational Qualification:
M.Sc or M. Tech in Biotechnology, Molecular biology or Biological Sciences,

Technical/functional Skills:
DNA/ RNA Isolation, Expertise in PCR, qPCR, Experience in NGS protocols

Experience:
2 to 5 Years

Behavioral Skills:
A proactive team player.
Ensure completion of experiments and generate accurate and reproducible data from experiments.
Ability to work independently, prioritize tasks and work on multiple projects simultaneously with; comfortable working in a dynamic environment with changing requirements.
Good oral and written communication and presentation skills to work in a multi-disciplinary team
Equal Opportunity Employer:
It is the policy of Syngene to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by applicable legislation or local law. In addition, Syngene will provide reasonable accommodations for qualified individuals with disabilities.",3.5,"Syngene
3.5",India,"BENGALURU, India",1001 to 5000 employees,1994,Unknown,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
903,Applied Scientist 1,"Position Requirements:
Master's degree in Computer Science, Computer or Electrical Engineer, Mathematics, or a related field plus at least one year of experience in the job offered or related occupations of Software Engineer, Software Developer, or a related occupation. Employer will accept a Bachelor’s degree and five years of experience in the job offered or a related occupation as equivalent to the Master’s degree and one year of experience. One year of experience in the job offered or related occupation must involve designing and developing large-scale, multi-tiered, distributed software applications, tools, systems and services using Java, Object Oriented Design and Distributed Programming].

Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, Oracle/Berkeley databases, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills

Amazon Selling Partner Services team drives the Selling On Amazon business and develops solutions that enable millions of sellers around the world to sell on Amazon's Marketplaces. More than half of shipments for Amazon customers are generated from this business. The team is focused on building a technology platform that will support the explosive business growth in existing markets, streamline the business for Amazon and the Selling partners and launch business in new markets and establish a fair marketplace.

Our team is seeking engineers with broad technical skills to help us optimize how we synthesize massive amounts of data and complex business rules into mission critical financial information. As a member of this team you will employ object oriented techniques in Java, and DynamoB, PostGres and ElasticSearch skills to help us support Amazon's next generation of selling partner services. Along the way you'll gain and leverage a unique understanding of how Amazon.com works; from the numerous software systems that comprise the website's back-end, to the details of our business model, and the relationships we're establishing with an ever-growing network of selling partners who depend on Amazon.com to run their businesses.

The ideal candidate will draw upon exemplary analytical, critical thinking, and problem solving skills, and a passion for maintaining highly reliable, distributed systems which operate 24/7/365. Successful members of this team collaborate effectively with internal end-users, aggressive cross-functional software development teams, and technical support/sustaining engineering teams to solve problems and deliver successfully against high operational standards of system availability and reliability. We look for engineers who are excellent communicators, self-motivated, flexible, hardworking, and who like to have fun!

Position Responsibilities:
Participate in the design, development, implementation, testing and documentation of large-scale, multi-tiered, distributed software applications, tools, systems and services using [Java, Object Oriented Design and Distributed Programming]. Translate functional requirements into robust, scalable, supportable solutions that work well within the overall system architecture. Participate in the full development cycle, end-to-end, from design, implementation, and testing to documentation, delivery and maintenance. Produce comprehensive, usable software documentation. Evaluate and make decisions around the use of new or existing software products and tools.

Preferred Qualifications
Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
904,Senior Clinical Data Analyst,"About Novotech:

Novotech is internationally recognised as the leading independent and full-service contract research organisation (CRO) in the Asia Pacific region. We provide a wide range of clinical development services across all research phases and therapeutic areas and have been instrumental in the success of hundreds of Phase I – IV clinical trials throughout the Asia Pacific. Powered by the highest quality people, Novotech strives to set the benchmark for both business and clinical trial performance. Our people are one of our key strengths. We value our people and recognise the work they do. We are lucky to have the best people and talent from across the Asia Pacific region work together to deliver to clinical trial success for our clients. Our people and those we look to recruit have an attitude of making things happen. They are problem solvers, driven with a focus on delivering quality, accountability and a high level of performance.

Brief Position Description:

As part of Novotech’s Biometrics unit, the Senior Data Analyst (SDA) is responsible for all data analysis and business intelligence activities related to study related clinical and operational data. The SDA acts as primary point of contact for all data analysis matters to the study team and is responsible for the timely delivery of quality outputs following all applicable regulatory, compliance, best practice and operational procedures.

Minimum Qualifications & Experience:

Graduate in information science, data science or life science-related field, or similar. More than five years’ experience in a senior role related to data science, data analysis, clinical data management or clinical data programming in a pharmaceutical company, CRO or EDC software provider.

Responsibilities
The Senior Data Analyst (SDA) is responsible for providing technical, procedural (SOPs) and planning leadership across multiple projects assigned to the data analyst team members ensuring that they deliver in accordance with SOPs, programming best practices, and the timelines agreed within the Project Team.
Collaborate with cross-functional stakeholders to implement data science solutions to solve business needs using available technological solutions.
Scope data analysis effort for projects and project manage all data analysis activities across multiple projects for different study stakeholders.
Gather study requirements from data management for data review and external data reconciliation and provide guidance on appropriate outputs (dashboards, visualisations, listings, reports).
Extract, assess, integrate, transform data sources to provide data visualisation outputs for analytics.
Design and develop prototypes and final versions of data outputs (dashboards, reports, visualisations, listings) using Business intelligence tools and Data Visualisation tools.
Design and develop standard dashboards and content for different audiences.
Analyse, manipulate and understand data from multiple sources to present and create dashboards and reports to make business decisions.
Assist teams on best-practice for data visualisation dashboard development.
Educate teams on how to use all the features of applicable data visualisation platform in conjunction with data visualisation dashboards.
SME for the data visualisation development and assisting team members.
Identify and communicate project risks and maintain documentation within project files as appropriate
Represent data analysis group at internal / external meetings as appropriate.
Assess and implement new data analysis, BI and data visualisation processes and technologies.
Take an active role in the development of best practices, process improvement, quality control and governance related to all data analysis matters.
Provide training and mentoring to Data Analysis of team members in SOPs, software applications, and best practices.
Provide Subject Matter Expertise on all data analysis and visualisation related activities.
Attributes and Skills

Expert knowledge of clinical study data structures and schemas of EDC databases. Expert knowledge in data processing activities such as extracting, integrating, transforming and presenting data. Statistical Programming skills in Python, R or similar. Knowledge of SQL and EDC systems. Working knowledge of Spotfire, Power BI, Tableau or other data review and visualisation tool. Ability to gather business requirements from multiple stakeholders and clients and provide guidance on the use of appropriate data visualisations.

Experience mentoring and training others. Awareness of regulatory and compliance issues and understanding of the application of SOPs and Quality Control to daily activities. Excellent analytical, communication and problem-solving skills.

Opportunities and Benefits:

To deliver clinical trial and research excellence for our clients, our people are 'best in class'.

At Novotech, we seek and nurture people with exceptional talent. We are committed to providing our people with regular internal and external training, a competitive bonus structure and a supportive work environment. We are also focused on providing our people with a wide variety of career growth and development opportunities.

For more information about where your next career step at Novotech might take you, visit http://novotech-cro.com/novotech-careers",4.5,"Novotech
4.5",Bengaluru,"Sydney, Australia",501 to 1000 employees,1996,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
905,Data Engineer,"Data Engineer Responsibilities:
Liaising with coworkers and clients to elucidate the requirements for each task.
Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed.
Reformulating existing frameworks to optimize their functioning.
Testing such structures to ensure that they are fit for use.
Preparing raw data for manipulation by Data Scientists.
Detecting and correcting errors in your work.
Ensuring that your work remains backed up and readily accessible to relevant coworkers.
Remaining up-to-date with industry standards and technological advancements that will improve the quality of your outputs.
Data Engineer Requirements:
Bachelor's degree in Data Engineering, Big Data Analytics, Computer Engineering, or related field.
Master's degree in a relevant field is advantageous.
Proven experience as a Data Engineer, Software Developer, or similar.
Expert proficiency in Python, C++, Java, R, and SQL.
Familiarity with Hadoop or suitable equivalent.
Excellent analytical and problem-solving skills.
A knack for independent and group work.
Scrupulous approach to duties.
Capacity to successfully manage a pipeline of duties with minimal supervision.
Job Type: Full-time

Salary: ₹360,000.00 to ₹870,000.00 /year

Experience:
total work: 2 years (Preferred)
Data Engineer: 1 year (Preferred)
Education:
Diploma (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,Futurious Technologies,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
906,Quantitative Analyst,"The successful candidate will be a highly analytical individual with hands on programming skills. The candidate will work closely with the research team and clients towards the ongoing development and integration of new investment strategies, models and tools on Axle

Location

Mumbai
Responsibilities

Perform daily/weekly/monthly tasks of performance and risk reporting
Develop and automate investment processes and strategies via VBA and Matlab
Develop tools to integrate trading decision systems with risk management systems
Ad hoc tasks (such as operational tasks, internal documentation tasks and preparation of marketing materials)
Skills/Experience

Excellent programming skills in Matlab/Excel-VBA
Thorough with financial concepts and calculations like Drawdown, VaR, Eloss etc.
Understanding of financial market products like options, futures, FX forwards etc.
Working knowledge of Bloomberg is preferred
Should be self-driven and detail oriented with an analytical mindset
Should be a proactive and quick learner; a team player showing enthusiasm and drive to accomplish results in a fast paced environment
Min. 2 years of relevant work experience
Qualifications

B.Tech/M.Tech/MBA/CFA/FRM",5.0,"B&B Analytics
5.0",Mumbai,"Zug, Switzerland",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
907,Analyst - Data Scientist,"Job Summary

Experience:
3 - 5 Years

Location:
Mumbai

Designation:
Analyst - Data Scientist

Degree:
BE-Comp/IT, BE-Other, BTech-Comp/IT, BTech-Other, ME-Comp/IT, ME-Other, MTech-Comp/IT, MTech-Other, PhD-Comp/IT, PhD-Other

Educational Level:
Graduate/Bachelors

Industrial Type:
IT-Software/Software Services

Functional Area:
IT Software - Application Programming / Maintenance

Key Skills:
Data Scientist

Job Post Date:
Thursday, March 19, 2020

Company Description

We are capability centre based in Mumbai, initially started as a back-office operational support to the UK business unit.

However, over the recent years, we have significantly increased the breadth and depth of our capabilities and offerings to keep pace with the changing needs of the Group. These include Digital & Knowledge Services, Finance and Actuarial, Information Technology (IT), Customer Service, Risk and Audit.

Our core purpose is to be a strategic partner to company, enabling growth by delivering change and driving synergies through a highly capable and agile workforce.

With our diversified service offerings we provide our people with exciting opportunities to grow personally and professionally.

Company is a leading savings and investments business serving around 5.5 million retail customers and more than 800 institutional clients.

It-s innovative asset management and customer solutions are supported by extensive investment capabilities, an international distribution network and two strong brands.

Job Description

3 – 5 yrs experience as Data Scientist
Should have at-least 1 end-to-end ML project experience
Very high proficiency in R or Python
Excellent in forecasting methods like simple exponential smoothing, multiplicative seasonal indexes, simple and weighted moving averages and time series forecasting methods
Exposure to with advanced deep learning techniques such as LSTM. CNN, Dense neural networks as well as neural networks design and implementation through tools like tensorflow, keras, pytorch, deepai or equivalent.
Good SQL experience",3.8,"Sampoorna Computer People
3.8",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
908,Data Lake Developer,"For Us, It's A Mission

At Mylan, we mean it when we say we work every day to provide access to high quality medicines to the world's 7 billion people. If you are unconventional, relentless and passionate. If you believe in doing what's right, not what's easy. If you are a doer and have a passion for serving others, we want to talk to you.

Make a Difference

At Mylan, each person has the ability to make a difference. From the providers who sell and market our products, to the producers who develop and manufacture them and finally to our business partners who support the providers and producers, we all have a mission critical role. Here's how this role will help:

ESSENTIAL DUTIES AND RESPONSIBILITIES
To perform this job successfully, an individual must satisfactorily perform each essential duty. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential duties.
1. Create and maintain optimal data pipeline architecture on Azure platform.
2. Develop batch processing solutions by using Data Factory and Azure Databricks.
3. Delivering a Data Warehouse in the Azure Cloud.
4. Design relational and non-relational data stores on Azure.
5. Identify, design, and implement internal process improvements : automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc..
6. Developing Big Data Solutions with Azure Machine Learning.
7. Strong interaction with business departments to provide consultative support for digitization efforts, as well as close collaboration with the Business Technology management, focused on future innovation topics.
8. Participate and lead in design sessions, demos and prototype sessions, testing and training workshops with business users and other IT colleagues.
9. Design & Build for any API Development or SQL DB development.
10. Providing service management, orchestration, monitoring and management requirements of Azure cloud platform.
11. Create data tools / products for analytics and data scientist team members that assist them in building and innovative solutions that drive tangible business value.
12. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
13. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
14. Design security for source data access. Chose the appropriate authentication mechanism, (ie Azure Active Directory (Azure AD), etc).
15. Design for real-time processing by using Stream Analytics and Azure Databricks.

Make Our Values Your Values

Mylan hires only the best. People who thrive in a culture of innovation and empowerment. People who are active learners and have a positive attitude. People who are leaders and know that by working together we can run faster, reach higher and achieve more. By doing so, we will continue to set new standards in health care. Here are the minimum qualifications and essential functions for this position:

QUALIFICATIONS

The qualifications listed below are representative of the minimum knowledge, skill, and/or ability required.

SKILLS AND ABILITIES

1. 10 years of experience in Microsoft technologies including SQL.

2. At least 5 years as a Sr Developer with at least 3 years hands on experience as Azure Data Engineer building large scale Azure data solutions.

3. At least 5 years of experience in Azure based data solutions.

4. At least 3 years of experience on working with large projects including the most recent project in the cloud (Azure) or on prem with a focus on Azure Data services.

5. At least 5 years of Hands-on administration, configuration management, monitoring, performance tuning of Hadoop/Distributed platforms.

6. At least 5 years of demonstrated experience at least in the most recent 2 years of designing and delivering solutions using Cortana Intelligence suite of analytics services part of Microsoft Azure including Azure Machine Learning Studio, HDInsight, Polybase, Azure Data Lake Analytics, Azure Data Warehouse, Streaming Analytics, Data Catalog, R/R Studio

7. Experience in designing and building logics required for optimal extraction, transformation, and loading of data from a wide variety of data sources

8. Experience within Data Security design, including but not limited to:

a. Choosing the appropriate authentication mechanism, such as Azure Active Directory (Azure AD)

b. Defining strategies for data encryption for data at rest and in transit

9. Experience partnering with Business Analysts and Data Scientists to enable effective and efficient data preparation and delivery

10. Experienced in vendor management and working with 3rd parties onshore & offshore.

11. Experience working in a global team.

12. Experience working in an Analytics / Big Data solutions on MS Azure Cloud

13. Experience with code management tools, automated testing

14. Experience creating and maintaining optimal data pipeline architecture on Azure platform

15. Experience developing batch and real-time processing solutions by using Data Factory and Azure Databricks

16. Familiar with AGILE and Azure DevOps methodology

17. Hands on PoC capabilities are needed to prove a particular architecture concept

18. Azure Native Services experience across Data Fabric and Service Fabric

19. Experience in Application modernization from legacy on-premise data architecture platform technology stack to modernized Azure Cloud base Architecture.

20. Experience with Git, NoSQL Data Solutions, Microsoft Azure, HD Insights, Azure ML, DataBricks ML Flow, R or Python.

21. Must have excellent communication skills.

EDUCATION/EXPERIENCE (Note: Please select one)

Minimum of a Bachelor's degree in Computer Science and Engineering is preferred with minimum 10 years of experience. However, a combination of experience and/or education will be taken into consideration

Why Mylan?

If you want to be part of a global health care company that is making a difference and changing lives, Mylan may be the place for you. With a workforce of more than 35,000 worldwide, we can make a difference. We encourage you to visit Mylan.com to learn more about our unconventional culture, our approach to doing business and how we plan to set new standards in health care.

Mylan offers competitive salary, excellent benefits and an environment conducive to professional growth and advancement. All qualified applicants will receive consideration for employment without regard to their disability or protected veteran status. Mylan is an Equal Opportunity Employer, Minorities/Female/Disabled/Veteran.",3.8,"Mylan Inc.
3.8",Bengaluru,"Hatfield, United Kingdom",10000+ employees,1961,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
909,Off Campus Recruitment - Quantitative Researcher,"Description:
Graviton is a privately funded quantitative trading firm striving for excellence in financial markets' research. We are seeking fresh talent from the top IIT's to join us as Quantitative Researchers for our team in Gurgaon.If you are a student graduating in 2020 from Computer Science , Electrical or Maths Stats Computing streams with a greater than 8 CGPA please apply here.

This role is open to students from campuses that we could not visit this year. Please check your individual placement policy restrictions before applying.

Graviton trades across a multitude of asset classes and trading venues using a gamut of concepts and techniques ranging from time series analysis, filtering, classification, stochastic models, pattern recognition to statistical inference analysing terabytes of data to come up with ideas to identify pricing anomalies in financial markets.

As a Quantitative researcher your responsibilities will include

Develop new or improve existing trading models using in-house platforms

Use advanced mathematical techniques to model and predict market movements

Analyse large financial datasets to identify trading opportunities

Provide real time analytical support to experienced traders

Requirements :
Possess a degree in a highly analytical field, such as Engineering, Mathematics, Computer Science from IITs schools

Quantitative bend of mind

A working knowledge of Linux/Unix

Programming experience, preferably in C++ or C

Strong interest in learning about financial markets.

Have a strong work ethic

Hard Working

Benefits:
Our open and casual work culture gives you the space to innovate and deliver. Our cubicle free offices , disdain for bureaucracy and insistence to hire the very best creates a melting pot for great ideas and technology innovations. Everyone on the team is approachable, there is nothing better than working with friends!

Our perks have you covered.

Competitive compensation

6 weeks of paid vacation

Monthly after work parties

Catered breakfast and lunch

Fully stocked kitchen

Gym membership

International team outing",5.0,"Graviton Research Capital LLP
5.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2014,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
910,Data Engineer,"Zauba Technologies is a startup based in Bangalore. Zauba's services are used by leading companies in India. Zauba is powered by a young and passionate team. We are looking for individuals who would like to be a part of our founding team.

As a Data Engineer and as a part of founding team, you will be expected to visualise and develop disruptive data products. Eventually you would be responsible for entire project lifecycle of products you would visualize. Your rewards will be directly proportional to the value you generate.

Job Responsibilities
Design and development of robust, scalable and highly efficient data engineering solutions for structured and unstructured data (Including gathering and processing raw data at scale, writing scripts, web scraping, calling APIs, writing SQL queries, etc.)
Develop processes for text mining and extraction of information from unstructured data
Design, architect and develop efficient data pipelines around the data collected
Take ownership of existing web product and applications
Design and implement data models that scale across the enterprise
Take ownership of existing data workflows and processes
Enhance scalability, performance, and stability of existing infrastructure
Work closely with other team members to integrate your innovations and algorithms into our production systems

Essentials
Java/Python - Intermediate to advanced level
SQL - Advanced
MySQL Intermediate to advanced level
Regex - Basic to intermediate level
Linux Basic to intermediate level

Good to have
Hadoop/Spark
R
MongoDB

Must have qualities
Skills to learn new skills quickly
Desire to create disruptive products and services
Passion - not just to work in startups but to take them to next level
Above average programming aptitude
Be passionate about producing high quality engineering deliverables
Be productive working independently or collaboratively
Have an eye for building efficient processes
Be self motivated
Proactively take ownership

Interested?

Send your resume to hr@zaubacorp.com",3.8,"Zauba Corp
3.8",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 million (INR),-1
911,Quantitative Research,"We are looking for highly trained professionals who are interested in applying advanced mathematical quantitative methods to the modeling of global financial markets. You would be joining a group made up of highly proficient individuals from various scientific disciplines. We have a spectrum of opportunities for individuals with the right scientific skills. Experience in finance is not required.

The ideal research candidate will have:
A Ph.D. in Computer Science, Mathematics, Physics, Statistics, or a related technical discipline.

A demonstrated capacity to do first-class research.

Computer programming skills.

An intense interest in applying quantitative analysis to solve difficult problems.

Send us a copy of your resume to
careers@dolatcapital.com

For internship opportunities, please send us a copy of your resume to
careers@dolatcapital.com",4.0,"Dolat Capital
4.0",Mumbai,"Mumbai, India",51 to 200 employees,1970,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
912,Data Engineer,"Bachelor’s degree in Computer Science or related field
5+ years relevant experience
5+ years experience with SQL, SQL Tuning, Oracle, OLAP, Big Data Technologies
5+ years experience developing end-to-end Business Intelligence solutions: data modeling, ETL and reporting
Experience with Java and experience with scripting languages like Perl, Python, Unix shell scripts,VBA and MS Excel
Proficiency with Linux and systems administration
Proven ability at looking at solutions in unconventional ways. Sees opportunities to innovate and can lead the way.
Top notch communication (verbal and written) and interpersonal skills to convey key insights from complex analysis in summarized business terms and an ability to effectively communicate with technical teams.
Ability to work with shifting deadlines in a fast paced environment.
Operations Finance Technology team, responsible for building technical solutions for multi-billion WW Operational Cost analytic including Inbound cost (Receiving / PO), variable Cost, fixed cost, outbound (Customer Shipments / Transportation), and Customer Service, is looking for a Data Engineer.

As a data engineer, you will get the exciting opportunity to work on very large data sets in one of the world's largest and most complex data warehouse environments. You will work closely with the business teams in analysis on various cost savings initiatives, many non-standard and unique business problems and use creative-problem solving to deliver actionable output.
You will be responsible for designing and implementing an analytical environment using third-party and in-house reporting tools, modeling metadata, building reports and dashboards. You will have an opportunity to work with leading edge technologies like Redshift, Hadoop/Hive/Pig. You will be writing scalable queries and tuning performance on queries running over billion of rows of data.

You should be analytical, have an extremely high level of customer focus and a passion for process improvement. You should be motivated self-starter that can work independently in a fast paced, ambiguous environment. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions.
Bachelors in Computer Science or related field
Practical Knowledge of Linux or Unix shell scripting
Experience in working with business customers to drive requirements analysis
Exposure to large databases, BI applications, data quality and performance tuning
Excellent written and spoken communication skills
Experience with Hadoop-based technologies such as HBase, Pig, Hive and Spark
Strong proven ability in building high-performance, highly available and scalable data solutions using Oracle and/or Hadoop-based technologies
Knowledge of data warehousing concepts.
Strong sense of ownership, urgency, and drive
Strong troubleshooting and problem solving skills
Experience with Amazon Web Services",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
913,DATA ANALYST,"posted by Mahima Gaur

2 - 5 years Delhi

Job Description
Experience in data processing
Experience in data cleaning and data tabulation activities
Strong analytical, communication and team management skills
Strong understanding of data management using SPSS and research techniques
Competency in a Tabulation software (decipher / wincross / quantum etc), Excel, Powerpoint
Ability to summarize findings, draw conclusions, and put together a presentation using Powerpoint
Role Category : Data Analyst

Employment Type : Permanent Job, Full Time",4.9,"Knowledge Excel Services.
4.9",New Delhi,"New Delhi, India",1 to 50 employees,2007,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
914,Data Engineer,"Key skills : Python , Spark , SQL , Pyspark • AWS platform used for the work • Strong experience in SQL is mandatory • Good familiarity of AWS landscape • Good experience in collecting business requirements & design them as per requirement from customer • Should able to work independently & interact business users & technical stakeholders • Strong communication skills both oral & written. • Should work as an individual resources",3.5,"Larsen & Toubro Infotech Limited
3.5",India,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
915,Big Data Engineer,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
916,Client Data Analyst,"At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.
What is the Client Data Analyst – Client Analytics group responsible for?
This team manages business data to ensure accurate, timely, consistent and compliant data. Their contributions deliver quality data that is easily accessible and can be trusted. Key downstream capabilities such as reporting and analytics depend on this as well as operational data access on various systems. The Data Management Team is a support function that acts as an advocate and a point of contact for Sales and Marketing data.

What are the ongoing responsibilities of an Client Data Analyst ?
Understand the data flow, key consumption and production of data as well as context within the enterprise:
Build positive relationships with teams, especially the key data consumers and analytics. Take the time to increase knowledge of how they run their business and incorporate sales data into daily work
Connect regularly with each sales office to understand current issues and challenges. Probe the business and validate against other sales offices to understand the scope and priority of the issue
Make recommendations on how data unifications and flow can be used to improve business tasks. Liaise business partners to deliver solutions (reports, processes, technology) that add value.

Provide data management subject matter expertise. Appreciate the connection and data flow between applications and other corporate systems. Be able to clearly articulate the data needs and move initiatives forward by collaborating with business partners:
Actively participate in meetings with business partners to ensure that priorities are clearly understood, information is regularly shared and that key participants are “kept in the loop”
Provide context and background on issues. Collaborate on ideas for progressing initiatives. Ensure appropriate resources are involved to take initiatives forward
Provide insights and expertise to scope statements and requirements documentation
Actively consult or participate in the user acceptance testing process (test cases, documentation, testing execution, etc.)
Ensure business needs remain aligned with overall corporate initiatives and deliver the benefits as originally intended

Monitor the integrity of data and usefulness of reports. Ensure the information available within systems is accurate and up-to-date. Proactively seek data cleansing opportunities and evolve data to better support. Document and maintain ongoing processes for reporting and data clean-up:
Partner with all key data consumers to gain a solid understanding of usage and challenges around data. Establish processes for prioritization of enhancements, especially with the analytics groups
Provide 1st level support for data issues and data maintenance for owned data
Verify and execute data loads into our internal sales systems and ensure any upstream systems accurately receive their data

Increase awareness and promote data management capabilities. Share best practices and provide coaching to local offices on how to access and incorporate output into sales tasks. Encourage IAS leaders to leverage data to make more informed, strategic decisions:
Clearly articulate the goals and core services of the data management team. Proactively promote this information within IAS and ensure business partners understand the data management role within the organization
Share best practices and provides guidance on data capabilities. Reinforces ownership and accountability for data accuracy
Seek opportunities to share the benefits of leveraging sales data to make more informed business decisions

What ideal qualifications, skills & experience would help someone to be Successful?

Knowledge, Education And Experience:
Four year bachelor’s degree required (majors of preference include: business, computer science, mathematics) Advanced degree a plus
Understanding of the Franklin Templeton business model, how FT makes money, the sales process, how technology fits in with the business, etc. Knowledge of the GAS (Global Advisory Services) structure
Experience working through multiple business fiscal cycles; exposure and/or direct experience with project management and/or sales-related-capacity required
Prior work experience related to analytics, sales, marketing and/or international a must. Level will not be granted based on years of experience but will be determined by the employee’s ability to meet each job activity as outlined the ‘typical/expected focus by level
Skills And Abilities:
Ability to communicate effectively with all levels of management; ability to tailor communication style based on audience; ability to get others to want to collaborate with you; strong facilitation skills
Excellent writing skills (for presentations, documentation, etc.)
Working knowledge of the CRM, MDM, Excel, SQL, Power BI, Tableau, Business Objects, and Microsoft Products (PPT, Power Apps, Doc, Visio)
Ability to absorb and interpret large quantities of data; apply trend analysis and knowledge of the business to develop a meaningful and digestible summary with the appropriate level of detail
Ability to take a larger problem and break down the individual components; identify how to go about solving the problem and who to involve in the process
Ability to present recommended solutions to a variety of issues and problems (solutions that are consistent with organization objectives)
Must be extremely detail-oriented (managing lists, tasks/to-dos, etc.) good with follow through on own items; good with following up with others on outstanding item

What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.

Highlights of our benefits include:

Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.",3.8,"Franklin Templeton Investments
3.8",Hyderabad,"San Mateo, CA",5001 to 10000 employees,1947,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Fidelity Investments, Vanguard"
917,Data Analyst,"Roles and Responsibilities:
Extracting, transforming and inputting data sets from various resources. Creating predictive models, translating non-technical aspects into quantifiable tasks. Analysis and representation of output data, highlight and explain trends and patterns, error elimination, using advanced statistical methods (regression, probability distribution, clusters etc.) to provide accurate results.
Data collection, Data Mining, Report generation, Problem identification and solution formulation Market analysis and establishing trends, Strategy development and implementation

Skills:
Extremely good analytical skills.
Good working knowledge of all MS-Office products, especially Advance Excel, Word, PowerPoint, MS-access.
Statistical tools and methods.

Interested candidates can send the updated resume on satish.mehra@exelaonline.com or call on 7722028636
00-7.00 Years",2.6,"Exela Technologies
2.6",Pune,"Irving, TX",10000+ employees,2017,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"SourceHOV, BancTec, Transcentra"
918,Data Modeler,"• Minimum 5-8 years of working experience as Data modeler.
• Data modelling experience in designing.
• Minimum 2-3 years real time experience in Erwin tool is mandatory.
• Experience in normalized modeling techniques.
• Experience in designing the Start schema.
• Experience working in ORACLE.
• Experience with database design, capacity planning, performance tuning and query optimization.
• Experience in working with Bank or Banking and Finance or Financial domain.
• Excellent communication skills with leadership quality.

Job Segment:
Database, Oracle, ERP, Technology",3.5,"LTI
3.5",Mumbai,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
919,Machine Learning Engineer,"Looking for Data Scientists with Python/R Programming skills.
Specific experience in AI areas like Statistical Machine learning / Deep learning / Natural Language Processing (NLP)/ Operations Research (Optimization) will be an advantage.Individual in this role is expected to work with multiple stakeholders and teams

Qualifications and Requirements:-
Previous working experience as a Machine Learning/ Data Scientist for 2 years
MA in Computer Science or similar relevant field
Hands on experience with MALLET
In depth knowledge of Apache Tomcat/Open Source
Excellent project and time management skills
Attention to detail
Outstanding problem solving and analytical skills",-1,Tekolutions.ai,India,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
920,Data Science Internship,"About the company:
SkillBit is a leading staffing and recruitment company engaged in talent searching assignments for skilled and talented candidates for the industry.

About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Working on data science algorithms and AI concepts 2. Using Python or R for web scraping 3. Building AI models using Python, machine learning, and deep learning algorithms 4. Processing of unstructured/structured data

Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 6th Jun'20 and 11th Jul'20
are available for duration of 1 month
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply

Number of internships/jobs available: 3

Categories: Data Science",-1,SkillBit,Pune,-1,-1,-1,-1,-1,-1,-1,-1
921,Data Engineer,"As a data engineer at TEAL, you'll be taking the plunge into a rich data lake that includes everything from satellite data to legal court orders. You'll be hustling and getting your hands dirty with every part of the data pipeline always having an implicit appreciation for how all of this data will ultimately power a revolutionary real estate risk platform.

Your day-to-day will include either all or some of the following:

Constantly scoping out new data sources to complement existing ones
Creating and maintaining distributed web scrapers using Python, RabbitMQ and other technologies
Architecting and managing data pipelines where data flows into multiple end-points including, but not limited to, Postgres, MongoDB and Apache Solr
Documenting workflows and constantly iterating to create better data infrastructure.

We'd love it if you:
Are proficient in Python or any other object-oriented language
Have worked with large (millions to hundreds of millions of rows in a SQL database) interdisciplinary datasets
Have scraped difficult websites and have some experience working with various data APIs
Are patient and methodical with unstructured and messy data
Are always hungry to learn newer and better technologies to make the data ecosystem faster, smoother and less silo-ed

Extra brownie points if you:
Have some experience working with large-scale search indexing
Have performed geospatial analyses in some capacity
Have created and managed data lakes in the cloud
Culture

To explore our culture and the values we embody click here

Testimonials
Testimonial

My experience at TEAL surpassed all my expectations from the get-go. I was asked to help solve one of the most daunting problems in the Indian real estate market. Every day while working on a subset of the problem, the ideas that I brought to the table were shaped into cohesive solutions by a collaborative team effort. At TEAL I was exposed to the most cutting edge technologies such as Cloud Computing, Big Data, ML and Data Science. The growth opportunities at TEAL are tremendous, If you are innovative and can demonstrate the will to realize your ideas, TEAL is an amazing organization to work for.
Gyan Vardhan, Data Science Intern
I had interned as a Data Scientist at Terra Economics and Analytics Lab during its early days, it was a rich learning experience working with a multi-disciplinary team who are extremely passionate about building a decision support platform for the insanely complicated realty market in India. It was exciting and challenging to work on mining huge volumes of property records; extracting patterns from the data, building data pipelines and brainstorming on building the core system. TEAL offers a very healthy work environment coupled with insanely talented people working together in an exciting setting.
Naga Anjaneyulu, Data Science Intern
I worked as a full-time Data science intern at TEAL. During this period, I got an opportunity to leverage my skillsets while also learning new technologies, working on tasks assigned to me. The company operates on the latest tech-stacks and gives opportunities to learn as much as you want. The work environment is challenging, the team at TEAL is super supportive and new ideas are always welcome. It has all the good perks of a startup; creativity and innovation, casual work atmosphere and a collaborative approach to solving problems. Personally, I loved working there, my experience was fantastic!
Archana Parmar, Data Science Intern
As a second-year college student, I was looking for an internship that would allow me to delve deeper into research and work with big data, TEAL gave me the perfect opportunity to do so, enabling me to develop proficiency in research and analysis. As a research analyst intern, I collated and cleaned data and helped in the preparation of reports and presentations, and I had members helping me at every stage of this process. This collaborative environment allowed me to cultivate my skills and also learn from my peers. The holy trinity of Rohan, Kshitij, and Shreyas served as not only excellent mentors and bosses but also as friends, helping me at every stage and giving us all food and ice cream to keep us going!
Arush Mehra, Research Intern
Internships are a crucial part of one’s early career. The internship experience at TEAL was a thrilling rollercoaster ride to say the least! It was more than implementing a standard model or building an already though out concept into reality. It was about finding the solution to a unique and open-ended problem.It was exciting to work on addressing a problem with far -reaching real world applications.Moreover, the work environment had the perfect balance of casual yet professional which kept you focused and stress free at the same time. Out of every 100 startups in India only 2 of them succeed, but there are very few like TEAL India which are bound to make it big at such an early stage.
Divyanshu Agarwal, NLP Intern",4.7,"Terra Economics & Analytics Lab (TEAL)
4.7",New Delhi,"Bengaluru, India",1 to 50 employees,2018,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
922,Senior Consultant - ModellingOps Data Engineer,"Job Title: Senior Consultant - ModellingOps Data Engineer
Location: TRIL GTC
GCL: D1

JOB DESCRIPTION:

AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. The Science & Enabling Units IT is AZs global IT capability function supporting key business areas operating out of sites across the US, UK, Sweden, India & Mexico.

We are looking for AI Ops consultant who will leverage tools & technology best practices to improve delivery performance & data engineering capabilities in the D&A space.

ROLES & RESPONSIBILITIES:

7-10 years of experience in IT Operations involving Data Science, Artificial Intelligence-Machine Learning and Predictive Analytics. Experience in architecting and implementation of end-to-end AIOPs solutions through ELK stack, Splunk. Experience in applying statistical methods, analysis, pattern recognition and modeling on IT Operational data using ELK machine learning. Experience in extracting meaning full data from incoming data streams from different sources through RegEx, Grok etc. Hands-on experience in applying machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc in the IT Operation domain. Experience with machine learning and statistical programming languages - Python, R etc. Experience in assessing the existing IT environment and providing recommendations to reduce the critical applications impacting incidents. Experience in exploring and identifying areas where manual tasks can be automated in IT environment. Experience with various Enterprise IT monitoring solutions including Infrastructure monitoring, Application Performance Monitoring, Network Monitoring, Cloud monitoring etc. Experience in IT Service Management including Service Desk, Incident Management, Change Management, CMDB etc. Excellent knowledge on various IT infrastructure components that includes Server Infrastructure, middle ware, database and application architectures and Cloud Components. Experience/knowledge on Infra monitoring tools - NOI, Zabbix, AppDynamics, Datadog, SCOM, SolarWinds etc. and Service Management tools -IBM Control Desk, BMC Remedy, ServiceNow etc. Experience/Knowledge on BI tools Knowledge on distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc. Knowledge on other programming languages/scripting: Python, Java, JavaScript, etc. ( Added Advantage ) Good analytical skills, strong communication skills are must. Client facing experience is an added advantage. Excellent experience in understanding the problem statement, architect and designing the solution

MANDATORY SKILLS:
Significant experience with AWS cloud environments, working knowledge of Google and Azure platforms. Knowledge of Kubernetes, S3, EC2, Sagemaker, Athena, RDS and Glue is essential.
Experience provisioning computational resources in a variety of Cloud environments using Infrastructure as Code.
Experience with best practice of data transport and storage within cloud system.
Experience building large scale data processing pipelines. e. g. Spark and SQL.
Experience with containers and microservice architectures e.g. Kubernetes, Docker and serverless approaches.
Excellent working knowledge in DevOps, using continuous integration and continuous development.
Use of Data Science modelling tools e.g. R, Python, SAS and Data Science notebooks (e.g. Jupyter).
Good written and verbal skills, fluent English
DESIERED SKILLS:
Agile practices, especially being a SCRUM Master
EDUCATIONAL BACKGROUND: B.E/B.Tech/MCA

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",3.9,"AstraZeneca
3.9",Chennai,"Cambridge, United Kingdom",10000+ employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Roche, GlaxoSmithKline, Novartis"
923,DATA ENGINEER,"JOB DESCRIPTION
As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements, and also research new uses for data acquisition. You should also know the ins and outs of the industry such as data mining practices, algorithms, and how data can be used.

DESIRED CANDIDATE PROFILE
An ideal candidate must possess prior experience leading a project.

Candidates must have:
> Experience in Hive, Spark, Scala, AWS DynamoDB, HBase, AWS Glue, Talend, Kafka, Snowflake ETL
> Strong experience in a BI/Data Warehouse environment with involvement in design, development, implementation, troubleshooting and support of ETL process using ETL tool.
> Experience in developing Data Marts, Data warehousing and Operational Data Store (ODS) on any of the databases or Hadoop environments.
> Experience in database like MS SQL, MySQL, Oracle, PostgreSQL
> Good to have programming experience in writing Complex Stored Procedures, Queries, Views, User Defined Functions, Cursors and Common Table Expressions using SQL or T-SQL.
> Experience in Performance Tuning and Query Optimization by Indexing, Partitioning and De-normalization.
> Experience in Developing a framework for ingesting data into Data lake
> Good database knowledge, analytical thinking
> Design, construct, install, test and maintain data management systems.
> Build high-performance algorithms, predictive models, and prototypes.
> Develop set processes for data mining, data modeling, and data production.
> Experience with cloud services: AWS (EC2, EMR, S3, Athena) and scripting languages like Python, /PySpark/R/SAS
> Install/update disaster recovery procedures.
> Experience in Agile Application Development & Scrum methodologies is preferred
> Ability to supervise and mentor junior developers on the team.
> Must be self-motivated and work well pulling people together in addition to being able to pull people together technically
> Demonstrated proficiency of troubleshooting techniques and detail-oriented problem diagnosis
> Ability to handle responsibility, is self-directed, with strong organizational and documentation skills
> Ability to work independently and efficiently under aggressive deadlines to meet project commitments
> Excellent verbal and written communication skills

EDUCATION
UG - B.Tech/B.E. - Computers, Electronics/Telecommunication, Diploma - Computers, Electronics/Telecommunication, B.Sc - Computers, BCA - Computers) AND (PG - M.Tech - Computers, Electronics/Telecommunication, MCA - Computers, M.Sc - Electronics, Computers) AND ( Doctorate - Any Doctorate - Any Specialization, Doctorate Not Required).

OTHER DETAILS
Number of vacancies: 4
Experience: 3 years
Location: Cochin

If you have a passion towards technology and coding, then we have the right job for you. Kindly forward your resumes to
Email: jobs@mjsofttech.com
Phone: 0484-2421245 / 928 720 7160",4.0,"MJ Softtech
4.0",Kochi,"Cochin, India",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
924,Data Engineer,"Education/ Experience and Skill Requirement
4+ years of relevant experience in
Experience working with both relational and NoSQL databases.
Strong coding skills; Python (preferred) /R/Java/Scala
Experience in developing Data warehousing technologies Experience with AWS or equivalent cloud services preferred
Experience in BigData technologies (Hadoop, HDFS, MapReduce, Spark, Hive, HBase etc) will be valuable
Knowledge of Machine Learning a big plus (Random Forest, Decision Trees, SVM, NLP, Gradient Boosting, Supervised/Unsupervised Learning, Clustering, classification and regression modeling).
Responsibilities
Proficiency with several years’ experience in more than one of Python, R, Java, Scala, or robust Linux shell scripting
Implementation experience with data warehouse architecture & design, ETL design/development, and Analytics
Knowledge of general cloud architecture and cloud strategies especially around AWS services and concepts such as S3 object stores, RDS databases, EC2, Glacier, Lambda, IAM, enterprise security, data security, DevOps, replication and disaster recovery
Well versed with data mining & exploration, NLP and visualization
Understanding of data modeling, data integration, and data representation (metadata, OWL, ontologies)
Developing data marts and data management using SQL
Creating powerful visual outcomes
Independently manage daily client communication, especially over calls
Manage client deadlines, ensure quality of the deliverables, attention to detail
Experience/understanding of corporate finance data from company filings is desirable",3.6,"Copal Partners
3.6",Bengaluru,"New York, NY",10000+ employees,1900,Company - Public,Financial Analytics & Research,Finance,₹100 to ₹500 billion (INR),-1
925,Data Engineer,"Job Description / Responsibilities
Build workflows to ensure data extraction quality and storage into our backend data store
Architect, build and train ML/AI models that can predict outcomes and report on anomalies.
Design data pipelines to perform ETL on content/data from multiple types of source systems.
Create data analytics views using RDBMS/Key-Value stores, on private and public/cloud
Create software that is well tested, maintainable, extensible and scales out with large data

Minimum Qualifications:
2+ years of software development with Python
2+ years of SQL (MySQL/Postgres) and Key-Value databases
1+ years of experience with scikit
2+ years of experience in data extraction, data transformation using custom Python/Java
Experience working with MapReduce/Hadoop/kafka/Elastic stack
Experience with Node backend and React/Redux
Experience working with git/mercurial, Amazon/Google cloud, Linux/LAMP stack
Experience in testing or test driven development
Experience with Data science and Machine Learning algorithm development

Location:
Hyderabad/Bangalore

Package:
Highly competitive to match experience and capability",3.7,"TVS
3.7",Bengaluru,"Chennai, India",5001 to 10000 employees,-1,Company - Private,Accounting,Accounting & Legal,₹100 to ₹500 billion (INR),-1
926,Data Engineer,"Permanent position with US based client of iFlex.
Work Location: Bangalore
Experience Level: 2+ Years

Role:
As part of our global team you will work on the data platform reporting to the Data Engineering Lead. Your role includes specification, development, test and rollout of features on our data platform. You are expected to contribute to the vision, understand our product roadmap, integrate business value andclient experience and contribute to build an engineering culture within the team. This initiative is of critical important to the success of the organization and our roadmap, for instance, services like liquidity analytics, billing, client onboarding, reporting and others will rely on the data platform. Accurate, granular, complete and timely data will be our key differentiating factor and competitive advantage in the market place. We expect the successful candidate to deliver high quality software and to be passionate about data engineering..

Responsibility / Qualification:
Managing multiple tasks and use sound judgment when prioritizing.
Collaborating with global cross functional team in building customer-centric products.
Analyzing existing software implementations to identify areas of improvement and provide deadline estimates for implementing new features.
Updating and maintain documentation for team processes, best practices and software runbooks.
Establishing trusted partnerships with peers, product heads, and executive level stakeholders.
We are looking for someone who is passionate about technology and engineering.
Exceptional analytical skills and ability to apply knowledge and experience in decision-making to arrive at creative and commercial solutions.
Ability to leverage technology to deliver business value.
You are independent and comfortable in a fast paced, ambiguous and often multi-directional work environment.

Preferred Qualifications:
B.S. or higher in Computer Science.
Minimum 2 years of relevant professional experience using a modern programming language (preferably Java/Scala).
Experience leveraging test driven development technics.
Comfort with Agile operating models.
Team oriented.
Strong interpersonal and communication skills.
Energetic, self-directed, and self-motivated.
Experience with microservice architecture.
Experience with Kafka, MongoDB, Hadoop, Cassandra.
Experience with AWS.
Experience in Financial Services or Fintech.",-1,IFLEX,Bengaluru,"Moscow, Russia",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
927,CIEL/SEL/1941: Sr data scientist,"Mandatory skills required -
Databases (SQL, Oracle, Any RDBMS) - Should have working knowledge of atleast one database
PL/SQL Programming Languages
R, Python (Any One)
Inferential Statistics - Hypothesis, p-value, R2, RMSE, MAPE etc
Exploratory Data Analysis
Machine Learning Algorithms - Should have in-depth knowledge and implementation of atleast one algorithm

Responsibilities
: Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the why & how of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions

Education
Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics
Experience
Minimum years of related experience required: 3 years
Preferred years of experience: 5 years
Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desirable.

Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
928,Data Engineer,Data Engineer,3.6,"Bookmyshow
3.6",Mumbai,"Mumbai, India",1001 to 5000 employees,2007,Company - Private,Ticket Sales,"Arts, Entertainment & Recreation",Unknown / Non-Applicable,-1
929,Data Analyst,"Required Skills & Experience

We are looking for a Data Analyst Executive
Eligible Qualifications : B. Tech, BCA, M.Tech, MCA
Experience : 3-5 years, fresher’s can also be considered
Location of Job : Gurgaon/Connaught Place, New Delhi
Technicals Skills

Following technical skills are pre-requisite:
Well versed with Software development methodologies, such as SDLC (Software Development Life Cycle), DDLC (Document Development Life Cycle).
Database schema design and implementation
Should have worked in either of technologies Sql Query/ Tableau/ Excel (Macros)/ Access (Query) writing for data analytics.
For planning and coordinating activities, organizations remain in invariant communication with one another and the data transfer has to be performed efficiently and smoothly as possible.
He/ She should manage the execution of the technologies, help the businesses in utilizing the systems, and should be well versed with the basics of computer systems such as Networking, Installation of necessary software and hardware.
Ability to determine the interrelationships between solutions and requirements.
Ability to think analytically and should be a problem solver and logic building should be very strong.
Good interpersonal skills to form effective working relationships with people at all levels.
Excellent communication and presentation skills and strong written & oral English skills.
To know more about us visit us www.sspl.net.in or write to us at admin@sspl.net.in",-1,Substratal Solutions,Connaught Place,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
930,Artificial Intelligence Scientists,"Experience 2- 4 Years
Salary 4 LPA - 6 LPA
Job Location Chennai

Industry:
IT-Software / Software Services

Keywords:
Artificial Intelligence

About Job:
Must have Excellent knowledge in AI / Machine learning (Mandatory).
Machine learning frameworks like keras, tensor flow etc.
And also other big data tools like Hadoop etc, Must know R and python.
Good understanding in SDLC & Business cycle.",4.0,"Careerera
4.0",Chennai,"Wayland, MA",501 to 1000 employees,-1,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
931,Senior Data Engineer,"About Us

upGrad is an online education platform building the careers of tomorrow by offering the most industry-relevant programs in an immersive learning experience. Our mission is to create a new digital-first learning experience to deliver tangible career impact to individuals at scale. upGrad currently offers programs in Data Science, Machine Learning, Product Management, Digital Marketing, and Entrepreneurship, etc. upGrad is looking for people passionate about management and education to help design learning programs for working professionals to stay sharp and stay relevant and help build the careers of tomorrow.
upGrad was awarded the Best Tech for Education by IAMAI for 2018-19
upGrad was also ranked as one of the LinkedIn Top Startups 2018: The 25 most sought-after startups in India
upGrad was earlier selected as one of the top ten most innovative companies in India by FastCompany.
We were also covered by the Financial Times along with other disruptors in Ed-Tech
upGrad is the official education partner for Government of India - Startup India program
Our program with IIIT B has been ranked #1 program in the country in the domain of Artificial Intelligence and Machine Learning
About the Role

We are looking for a Data Engineer to help us scale the existing data infrastructure and in parallel work on building the next generation data platform for analytics at scale, machine learning infrastructure and data validation systems.
In this role, you will be responsible for communicating effectively with data consumers to fine-tune data platform systems (existing or new), taking ownership and delivering high performing systems and data pipelines, and helping the team scale them up, to endure ever growing traffic.
This is a growing team, which makes for many opportunities to be involved directly with product management, development, sales, and support teams. Everybody on the team is passionate about their work and we’re looking for similarly motivated “get stuff done” kind of people to join us!

Roles & Responsibilities
Engineer data pipelines (batch and real-time ) that aids in creation of data-driven products for our platform
Design, develop and maintain a robust and scalable data-warehouse and data lake
Work closely alongside Product managers and data-scientists to bring the various datasets together and cater to our business intelligence and analytics use-cases
Design and develop solutions using data science techniques ranging from statistics, algorithms to machine learning
Perform hands-on devops work to keep the Data platform secure and reliable
Skills Required
Bachelor's degree in Computer Science, Information Systems, or related engineering discipline
6 + years’ experience with ETL, Data Mining, Data Modeling, and working with large-scale datasets
6+ years’ experience with an object-oriented programming language such as Python, Scala, Java, etc
Extremely proficient in writing performant SQL working with large data volumes
Experience with map-reduce, Spark, Kafka, Presto, and the ecosystem.
Experience in building automated analytical systems utilizing large data sets.
Experience with designing, scaling and optimizing cloud based data warehouses (like AWS Redshift) and data lakes
Familiarity with AWS technologies preferred
Qualification – B.Tech/M.Tech/MCA(IT/Computer Science)

Years of Exp – 6-9",3.5,"upGrad Education Private Limited
3.5",Mumbai,"Mumbai, India",501 to 1000 employees,2015,Company - Private,Education Training Services,Education,₹1 to ₹5 billion (INR),"Udacity, General Assembly, Springboard"
932,BBRC-Genomics-Associate Scientist,"JOB DESCRIPTION

Designation: Associate Scientist

Job Location: Bangalore

Department: Translational Medicine- Translational Sciences

About Syngene

Incorporated in 1993, Syngene International Ltd. is an innovation-focused global discovery, development and manufacturing organization providing integrated scientific services to the pharmaceutical, biotechnology, nutrition, animal health, consumer goods and specialty chemical industries around the world. Syngene’ s clientele includes world leaders such as Bristol-Myers Squibb, Baxter, Amgen, GSK, Merck KGaA and Herbalife. Its innovative culture is driven by the passion of its 4240- strong team of scientists who work with clients from around the world to solve their scientific problems, improve R&D productivity, speed up time to market and lower the cost of innovation .

Job Purpose:
To play a key role in TM-TS, develop an early-stage research strategy, initiate and lead discovery programs while managing ongoing programs in TM-TS. The role will work part of TMTS, and work with internal and external collaborators .

Key Responsibilities:
Experience in isolating DNA and RNA from blood, tissues and FFPE samples and cell lines. Experience with optimization of extraction protocols and for parameters like yield, input sample quantities and sample types is important.
Expertise in PCR, qPCR, cDNA/gDNA library preparation. Exposure to microarray techniques.
Proficiency in preparation of libraries for Next Generation Sequencing of transcriptome and genome, with significant experience in optimization of parameters like input RNA/DNA quantities and sample type
Experience with single cell RNA-seq will be plus.
Experience with various NGS protocols (DNA Amplicon based, hybrid capture based low input, degraded DNA and RNA samples e.g. FFPE samples.
Strong understanding of experimental design and statistical principles behind experimental design and differential gene expression. Experience with analysis of single cell RNA-sequencing data will be a plus

Educational Qualification:
M.Sc or M. Tech in Biotechnology, Molecular biology or Biological Sciences,

Technical/functional Skills:
DNA/ RNA Isolation, Expertise in PCR, qPCR, Experience in NGS protocols

Experience:
2 to 5 Years

Behavioral Skills:
A proactive team player.
Ensure completion of experiments and generate accurate and reproducible data from experiments.
Ability to work independently, prioritize tasks and work on multiple projects simultaneously with; comfortable working in a dynamic environment with changing requirements.
Good oral and written communication and presentation skills to work in a multi-disciplinary team
Equal Opportunity Employer:
It is the policy of Syngene to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by applicable legislation or local law. In addition, Syngene will provide reasonable accommodations for qualified individuals with disabilities.",3.5,"Syngene
3.5",India,"BENGALURU, India",1001 to 5000 employees,1994,Unknown,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
933,Applied Scientist 1,"Position Requirements:
Master's degree in Computer Science, Computer or Electrical Engineer, Mathematics, or a related field plus at least one year of experience in the job offered or related occupations of Software Engineer, Software Developer, or a related occupation. Employer will accept a Bachelor’s degree and five years of experience in the job offered or a related occupation as equivalent to the Master’s degree and one year of experience. One year of experience in the job offered or related occupation must involve designing and developing large-scale, multi-tiered, distributed software applications, tools, systems and services using Java, Object Oriented Design and Distributed Programming].

Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, Oracle/Berkeley databases, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills

Amazon Selling Partner Services team drives the Selling On Amazon business and develops solutions that enable millions of sellers around the world to sell on Amazon's Marketplaces. More than half of shipments for Amazon customers are generated from this business. The team is focused on building a technology platform that will support the explosive business growth in existing markets, streamline the business for Amazon and the Selling partners and launch business in new markets and establish a fair marketplace.

Our team is seeking engineers with broad technical skills to help us optimize how we synthesize massive amounts of data and complex business rules into mission critical financial information. As a member of this team you will employ object oriented techniques in Java, and DynamoB, PostGres and ElasticSearch skills to help us support Amazon's next generation of selling partner services. Along the way you'll gain and leverage a unique understanding of how Amazon.com works; from the numerous software systems that comprise the website's back-end, to the details of our business model, and the relationships we're establishing with an ever-growing network of selling partners who depend on Amazon.com to run their businesses.

The ideal candidate will draw upon exemplary analytical, critical thinking, and problem solving skills, and a passion for maintaining highly reliable, distributed systems which operate 24/7/365. Successful members of this team collaborate effectively with internal end-users, aggressive cross-functional software development teams, and technical support/sustaining engineering teams to solve problems and deliver successfully against high operational standards of system availability and reliability. We look for engineers who are excellent communicators, self-motivated, flexible, hardworking, and who like to have fun!

Position Responsibilities:
Participate in the design, development, implementation, testing and documentation of large-scale, multi-tiered, distributed software applications, tools, systems and services using [Java, Object Oriented Design and Distributed Programming]. Translate functional requirements into robust, scalable, supportable solutions that work well within the overall system architecture. Participate in the full development cycle, end-to-end, from design, implementation, and testing to documentation, delivery and maintenance. Produce comprehensive, usable software documentation. Evaluate and make decisions around the use of new or existing software products and tools.

Preferred Qualifications
Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
934,Senior Clinical Data Analyst,"About Novotech:

Novotech is internationally recognised as the leading independent and full-service contract research organisation (CRO) in the Asia Pacific region. We provide a wide range of clinical development services across all research phases and therapeutic areas and have been instrumental in the success of hundreds of Phase I – IV clinical trials throughout the Asia Pacific. Powered by the highest quality people, Novotech strives to set the benchmark for both business and clinical trial performance. Our people are one of our key strengths. We value our people and recognise the work they do. We are lucky to have the best people and talent from across the Asia Pacific region work together to deliver to clinical trial success for our clients. Our people and those we look to recruit have an attitude of making things happen. They are problem solvers, driven with a focus on delivering quality, accountability and a high level of performance.

Brief Position Description:

As part of Novotech’s Biometrics unit, the Senior Data Analyst (SDA) is responsible for all data analysis and business intelligence activities related to study related clinical and operational data. The SDA acts as primary point of contact for all data analysis matters to the study team and is responsible for the timely delivery of quality outputs following all applicable regulatory, compliance, best practice and operational procedures.

Minimum Qualifications & Experience:

Graduate in information science, data science or life science-related field, or similar. More than five years’ experience in a senior role related to data science, data analysis, clinical data management or clinical data programming in a pharmaceutical company, CRO or EDC software provider.

Responsibilities
The Senior Data Analyst (SDA) is responsible for providing technical, procedural (SOPs) and planning leadership across multiple projects assigned to the data analyst team members ensuring that they deliver in accordance with SOPs, programming best practices, and the timelines agreed within the Project Team.
Collaborate with cross-functional stakeholders to implement data science solutions to solve business needs using available technological solutions.
Scope data analysis effort for projects and project manage all data analysis activities across multiple projects for different study stakeholders.
Gather study requirements from data management for data review and external data reconciliation and provide guidance on appropriate outputs (dashboards, visualisations, listings, reports).
Extract, assess, integrate, transform data sources to provide data visualisation outputs for analytics.
Design and develop prototypes and final versions of data outputs (dashboards, reports, visualisations, listings) using Business intelligence tools and Data Visualisation tools.
Design and develop standard dashboards and content for different audiences.
Analyse, manipulate and understand data from multiple sources to present and create dashboards and reports to make business decisions.
Assist teams on best-practice for data visualisation dashboard development.
Educate teams on how to use all the features of applicable data visualisation platform in conjunction with data visualisation dashboards.
SME for the data visualisation development and assisting team members.
Identify and communicate project risks and maintain documentation within project files as appropriate
Represent data analysis group at internal / external meetings as appropriate.
Assess and implement new data analysis, BI and data visualisation processes and technologies.
Take an active role in the development of best practices, process improvement, quality control and governance related to all data analysis matters.
Provide training and mentoring to Data Analysis of team members in SOPs, software applications, and best practices.
Provide Subject Matter Expertise on all data analysis and visualisation related activities.
Attributes and Skills

Expert knowledge of clinical study data structures and schemas of EDC databases. Expert knowledge in data processing activities such as extracting, integrating, transforming and presenting data. Statistical Programming skills in Python, R or similar. Knowledge of SQL and EDC systems. Working knowledge of Spotfire, Power BI, Tableau or other data review and visualisation tool. Ability to gather business requirements from multiple stakeholders and clients and provide guidance on the use of appropriate data visualisations.

Experience mentoring and training others. Awareness of regulatory and compliance issues and understanding of the application of SOPs and Quality Control to daily activities. Excellent analytical, communication and problem-solving skills.

Opportunities and Benefits:

To deliver clinical trial and research excellence for our clients, our people are 'best in class'.

At Novotech, we seek and nurture people with exceptional talent. We are committed to providing our people with regular internal and external training, a competitive bonus structure and a supportive work environment. We are also focused on providing our people with a wide variety of career growth and development opportunities.

For more information about where your next career step at Novotech might take you, visit http://novotech-cro.com/novotech-careers",4.5,"Novotech
4.5",Bengaluru,"Sydney, Australia",501 to 1000 employees,1996,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
935,Data Engineer,"Data Engineer Responsibilities:
Liaising with coworkers and clients to elucidate the requirements for each task.
Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed.
Reformulating existing frameworks to optimize their functioning.
Testing such structures to ensure that they are fit for use.
Preparing raw data for manipulation by Data Scientists.
Detecting and correcting errors in your work.
Ensuring that your work remains backed up and readily accessible to relevant coworkers.
Remaining up-to-date with industry standards and technological advancements that will improve the quality of your outputs.
Data Engineer Requirements:
Bachelor's degree in Data Engineering, Big Data Analytics, Computer Engineering, or related field.
Master's degree in a relevant field is advantageous.
Proven experience as a Data Engineer, Software Developer, or similar.
Expert proficiency in Python, C++, Java, R, and SQL.
Familiarity with Hadoop or suitable equivalent.
Excellent analytical and problem-solving skills.
A knack for independent and group work.
Scrupulous approach to duties.
Capacity to successfully manage a pipeline of duties with minimal supervision.
Job Type: Full-time

Salary: ₹360,000.00 to ₹870,000.00 /year

Experience:
total work: 2 years (Preferred)
Data Engineer: 1 year (Preferred)
Education:
Diploma (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,Futurious Technologies,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
936,Quantitative Analyst,"The successful candidate will be a highly analytical individual with hands on programming skills. The candidate will work closely with the research team and clients towards the ongoing development and integration of new investment strategies, models and tools on Axle

Location

Mumbai
Responsibilities

Perform daily/weekly/monthly tasks of performance and risk reporting
Develop and automate investment processes and strategies via VBA and Matlab
Develop tools to integrate trading decision systems with risk management systems
Ad hoc tasks (such as operational tasks, internal documentation tasks and preparation of marketing materials)
Skills/Experience

Excellent programming skills in Matlab/Excel-VBA
Thorough with financial concepts and calculations like Drawdown, VaR, Eloss etc.
Understanding of financial market products like options, futures, FX forwards etc.
Working knowledge of Bloomberg is preferred
Should be self-driven and detail oriented with an analytical mindset
Should be a proactive and quick learner; a team player showing enthusiasm and drive to accomplish results in a fast paced environment
Min. 2 years of relevant work experience
Qualifications

B.Tech/M.Tech/MBA/CFA/FRM",5.0,"B&B Analytics
5.0",Mumbai,"Zug, Switzerland",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
937,Analyst - Data Scientist,"Job Summary

Experience:
3 - 5 Years

Location:
Mumbai

Designation:
Analyst - Data Scientist

Degree:
BE-Comp/IT, BE-Other, BTech-Comp/IT, BTech-Other, ME-Comp/IT, ME-Other, MTech-Comp/IT, MTech-Other, PhD-Comp/IT, PhD-Other

Educational Level:
Graduate/Bachelors

Industrial Type:
IT-Software/Software Services

Functional Area:
IT Software - Application Programming / Maintenance

Key Skills:
Data Scientist

Job Post Date:
Thursday, March 19, 2020

Company Description

We are capability centre based in Mumbai, initially started as a back-office operational support to the UK business unit.

However, over the recent years, we have significantly increased the breadth and depth of our capabilities and offerings to keep pace with the changing needs of the Group. These include Digital & Knowledge Services, Finance and Actuarial, Information Technology (IT), Customer Service, Risk and Audit.

Our core purpose is to be a strategic partner to company, enabling growth by delivering change and driving synergies through a highly capable and agile workforce.

With our diversified service offerings we provide our people with exciting opportunities to grow personally and professionally.

Company is a leading savings and investments business serving around 5.5 million retail customers and more than 800 institutional clients.

It-s innovative asset management and customer solutions are supported by extensive investment capabilities, an international distribution network and two strong brands.

Job Description

3 – 5 yrs experience as Data Scientist
Should have at-least 1 end-to-end ML project experience
Very high proficiency in R or Python
Excellent in forecasting methods like simple exponential smoothing, multiplicative seasonal indexes, simple and weighted moving averages and time series forecasting methods
Exposure to with advanced deep learning techniques such as LSTM. CNN, Dense neural networks as well as neural networks design and implementation through tools like tensorflow, keras, pytorch, deepai or equivalent.
Good SQL experience",3.8,"Sampoorna Computer People
3.8",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
938,Data Lake Developer,"For Us, It's A Mission

At Mylan, we mean it when we say we work every day to provide access to high quality medicines to the world's 7 billion people. If you are unconventional, relentless and passionate. If you believe in doing what's right, not what's easy. If you are a doer and have a passion for serving others, we want to talk to you.

Make a Difference

At Mylan, each person has the ability to make a difference. From the providers who sell and market our products, to the producers who develop and manufacture them and finally to our business partners who support the providers and producers, we all have a mission critical role. Here's how this role will help:

ESSENTIAL DUTIES AND RESPONSIBILITIES
To perform this job successfully, an individual must satisfactorily perform each essential duty. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential duties.
1. Create and maintain optimal data pipeline architecture on Azure platform.
2. Develop batch processing solutions by using Data Factory and Azure Databricks.
3. Delivering a Data Warehouse in the Azure Cloud.
4. Design relational and non-relational data stores on Azure.
5. Identify, design, and implement internal process improvements : automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc..
6. Developing Big Data Solutions with Azure Machine Learning.
7. Strong interaction with business departments to provide consultative support for digitization efforts, as well as close collaboration with the Business Technology management, focused on future innovation topics.
8. Participate and lead in design sessions, demos and prototype sessions, testing and training workshops with business users and other IT colleagues.
9. Design & Build for any API Development or SQL DB development.
10. Providing service management, orchestration, monitoring and management requirements of Azure cloud platform.
11. Create data tools / products for analytics and data scientist team members that assist them in building and innovative solutions that drive tangible business value.
12. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
13. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
14. Design security for source data access. Chose the appropriate authentication mechanism, (ie Azure Active Directory (Azure AD), etc).
15. Design for real-time processing by using Stream Analytics and Azure Databricks.

Make Our Values Your Values

Mylan hires only the best. People who thrive in a culture of innovation and empowerment. People who are active learners and have a positive attitude. People who are leaders and know that by working together we can run faster, reach higher and achieve more. By doing so, we will continue to set new standards in health care. Here are the minimum qualifications and essential functions for this position:

QUALIFICATIONS

The qualifications listed below are representative of the minimum knowledge, skill, and/or ability required.

SKILLS AND ABILITIES

1. 10 years of experience in Microsoft technologies including SQL.

2. At least 5 years as a Sr Developer with at least 3 years hands on experience as Azure Data Engineer building large scale Azure data solutions.

3. At least 5 years of experience in Azure based data solutions.

4. At least 3 years of experience on working with large projects including the most recent project in the cloud (Azure) or on prem with a focus on Azure Data services.

5. At least 5 years of Hands-on administration, configuration management, monitoring, performance tuning of Hadoop/Distributed platforms.

6. At least 5 years of demonstrated experience at least in the most recent 2 years of designing and delivering solutions using Cortana Intelligence suite of analytics services part of Microsoft Azure including Azure Machine Learning Studio, HDInsight, Polybase, Azure Data Lake Analytics, Azure Data Warehouse, Streaming Analytics, Data Catalog, R/R Studio

7. Experience in designing and building logics required for optimal extraction, transformation, and loading of data from a wide variety of data sources

8. Experience within Data Security design, including but not limited to:

a. Choosing the appropriate authentication mechanism, such as Azure Active Directory (Azure AD)

b. Defining strategies for data encryption for data at rest and in transit

9. Experience partnering with Business Analysts and Data Scientists to enable effective and efficient data preparation and delivery

10. Experienced in vendor management and working with 3rd parties onshore & offshore.

11. Experience working in a global team.

12. Experience working in an Analytics / Big Data solutions on MS Azure Cloud

13. Experience with code management tools, automated testing

14. Experience creating and maintaining optimal data pipeline architecture on Azure platform

15. Experience developing batch and real-time processing solutions by using Data Factory and Azure Databricks

16. Familiar with AGILE and Azure DevOps methodology

17. Hands on PoC capabilities are needed to prove a particular architecture concept

18. Azure Native Services experience across Data Fabric and Service Fabric

19. Experience in Application modernization from legacy on-premise data architecture platform technology stack to modernized Azure Cloud base Architecture.

20. Experience with Git, NoSQL Data Solutions, Microsoft Azure, HD Insights, Azure ML, DataBricks ML Flow, R or Python.

21. Must have excellent communication skills.

EDUCATION/EXPERIENCE (Note: Please select one)

Minimum of a Bachelor's degree in Computer Science and Engineering is preferred with minimum 10 years of experience. However, a combination of experience and/or education will be taken into consideration

Why Mylan?

If you want to be part of a global health care company that is making a difference and changing lives, Mylan may be the place for you. With a workforce of more than 35,000 worldwide, we can make a difference. We encourage you to visit Mylan.com to learn more about our unconventional culture, our approach to doing business and how we plan to set new standards in health care.

Mylan offers competitive salary, excellent benefits and an environment conducive to professional growth and advancement. All qualified applicants will receive consideration for employment without regard to their disability or protected veteran status. Mylan is an Equal Opportunity Employer, Minorities/Female/Disabled/Veteran.",3.8,"Mylan Inc.
3.8",Bengaluru,"Hatfield, United Kingdom",10000+ employees,1961,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
939,Off Campus Recruitment - Quantitative Researcher,"Description:
Graviton is a privately funded quantitative trading firm striving for excellence in financial markets' research. We are seeking fresh talent from the top IIT's to join us as Quantitative Researchers for our team in Gurgaon.If you are a student graduating in 2020 from Computer Science , Electrical or Maths Stats Computing streams with a greater than 8 CGPA please apply here.

This role is open to students from campuses that we could not visit this year. Please check your individual placement policy restrictions before applying.

Graviton trades across a multitude of asset classes and trading venues using a gamut of concepts and techniques ranging from time series analysis, filtering, classification, stochastic models, pattern recognition to statistical inference analysing terabytes of data to come up with ideas to identify pricing anomalies in financial markets.

As a Quantitative researcher your responsibilities will include

Develop new or improve existing trading models using in-house platforms

Use advanced mathematical techniques to model and predict market movements

Analyse large financial datasets to identify trading opportunities

Provide real time analytical support to experienced traders

Requirements :
Possess a degree in a highly analytical field, such as Engineering, Mathematics, Computer Science from IITs schools

Quantitative bend of mind

A working knowledge of Linux/Unix

Programming experience, preferably in C++ or C

Strong interest in learning about financial markets.

Have a strong work ethic

Hard Working

Benefits:
Our open and casual work culture gives you the space to innovate and deliver. Our cubicle free offices , disdain for bureaucracy and insistence to hire the very best creates a melting pot for great ideas and technology innovations. Everyone on the team is approachable, there is nothing better than working with friends!

Our perks have you covered.

Competitive compensation

6 weeks of paid vacation

Monthly after work parties

Catered breakfast and lunch

Fully stocked kitchen

Gym membership

International team outing",5.0,"Graviton Research Capital LLP
5.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2014,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
940,Data Engineer,"Zauba Technologies is a startup based in Bangalore. Zauba's services are used by leading companies in India. Zauba is powered by a young and passionate team. We are looking for individuals who would like to be a part of our founding team.

As a Data Engineer and as a part of founding team, you will be expected to visualise and develop disruptive data products. Eventually you would be responsible for entire project lifecycle of products you would visualize. Your rewards will be directly proportional to the value you generate.

Job Responsibilities
Design and development of robust, scalable and highly efficient data engineering solutions for structured and unstructured data (Including gathering and processing raw data at scale, writing scripts, web scraping, calling APIs, writing SQL queries, etc.)
Develop processes for text mining and extraction of information from unstructured data
Design, architect and develop efficient data pipelines around the data collected
Take ownership of existing web product and applications
Design and implement data models that scale across the enterprise
Take ownership of existing data workflows and processes
Enhance scalability, performance, and stability of existing infrastructure
Work closely with other team members to integrate your innovations and algorithms into our production systems

Essentials
Java/Python - Intermediate to advanced level
SQL - Advanced
MySQL Intermediate to advanced level
Regex - Basic to intermediate level
Linux Basic to intermediate level

Good to have
Hadoop/Spark
R
MongoDB

Must have qualities
Skills to learn new skills quickly
Desire to create disruptive products and services
Passion - not just to work in startups but to take them to next level
Above average programming aptitude
Be passionate about producing high quality engineering deliverables
Be productive working independently or collaboratively
Have an eye for building efficient processes
Be self motivated
Proactively take ownership

Interested?

Send your resume to hr@zaubacorp.com",3.8,"Zauba Corp
3.8",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 million (INR),-1
941,Quantitative Research,"We are looking for highly trained professionals who are interested in applying advanced mathematical quantitative methods to the modeling of global financial markets. You would be joining a group made up of highly proficient individuals from various scientific disciplines. We have a spectrum of opportunities for individuals with the right scientific skills. Experience in finance is not required.

The ideal research candidate will have:
A Ph.D. in Computer Science, Mathematics, Physics, Statistics, or a related technical discipline.

A demonstrated capacity to do first-class research.

Computer programming skills.

An intense interest in applying quantitative analysis to solve difficult problems.

Send us a copy of your resume to
careers@dolatcapital.com

For internship opportunities, please send us a copy of your resume to
careers@dolatcapital.com",4.0,"Dolat Capital
4.0",Mumbai,"Mumbai, India",51 to 200 employees,1970,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
942,Data Engineer,"Bachelor’s degree in Computer Science or related field
5+ years relevant experience
5+ years experience with SQL, SQL Tuning, Oracle, OLAP, Big Data Technologies
5+ years experience developing end-to-end Business Intelligence solutions: data modeling, ETL and reporting
Experience with Java and experience with scripting languages like Perl, Python, Unix shell scripts,VBA and MS Excel
Proficiency with Linux and systems administration
Proven ability at looking at solutions in unconventional ways. Sees opportunities to innovate and can lead the way.
Top notch communication (verbal and written) and interpersonal skills to convey key insights from complex analysis in summarized business terms and an ability to effectively communicate with technical teams.
Ability to work with shifting deadlines in a fast paced environment.
Operations Finance Technology team, responsible for building technical solutions for multi-billion WW Operational Cost analytic including Inbound cost (Receiving / PO), variable Cost, fixed cost, outbound (Customer Shipments / Transportation), and Customer Service, is looking for a Data Engineer.

As a data engineer, you will get the exciting opportunity to work on very large data sets in one of the world's largest and most complex data warehouse environments. You will work closely with the business teams in analysis on various cost savings initiatives, many non-standard and unique business problems and use creative-problem solving to deliver actionable output.
You will be responsible for designing and implementing an analytical environment using third-party and in-house reporting tools, modeling metadata, building reports and dashboards. You will have an opportunity to work with leading edge technologies like Redshift, Hadoop/Hive/Pig. You will be writing scalable queries and tuning performance on queries running over billion of rows of data.

You should be analytical, have an extremely high level of customer focus and a passion for process improvement. You should be motivated self-starter that can work independently in a fast paced, ambiguous environment. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions.
Bachelors in Computer Science or related field
Practical Knowledge of Linux or Unix shell scripting
Experience in working with business customers to drive requirements analysis
Exposure to large databases, BI applications, data quality and performance tuning
Excellent written and spoken communication skills
Experience with Hadoop-based technologies such as HBase, Pig, Hive and Spark
Strong proven ability in building high-performance, highly available and scalable data solutions using Oracle and/or Hadoop-based technologies
Knowledge of data warehousing concepts.
Strong sense of ownership, urgency, and drive
Strong troubleshooting and problem solving skills
Experience with Amazon Web Services",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
943,DATA ANALYST,"posted by Mahima Gaur

2 - 5 years Delhi

Job Description
Experience in data processing
Experience in data cleaning and data tabulation activities
Strong analytical, communication and team management skills
Strong understanding of data management using SPSS and research techniques
Competency in a Tabulation software (decipher / wincross / quantum etc), Excel, Powerpoint
Ability to summarize findings, draw conclusions, and put together a presentation using Powerpoint
Role Category : Data Analyst

Employment Type : Permanent Job, Full Time",4.9,"Knowledge Excel Services.
4.9",New Delhi,"New Delhi, India",1 to 50 employees,2007,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
944,Data Engineer,"Key skills : Python , Spark , SQL , Pyspark • AWS platform used for the work • Strong experience in SQL is mandatory • Good familiarity of AWS landscape • Good experience in collecting business requirements & design them as per requirement from customer • Should able to work independently & interact business users & technical stakeholders • Strong communication skills both oral & written. • Should work as an individual resources",3.5,"Larsen & Toubro Infotech Limited
3.5",India,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
945,Big Data Engineer,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
946,Client Data Analyst,"At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.
What is the Client Data Analyst – Client Analytics group responsible for?
This team manages business data to ensure accurate, timely, consistent and compliant data. Their contributions deliver quality data that is easily accessible and can be trusted. Key downstream capabilities such as reporting and analytics depend on this as well as operational data access on various systems. The Data Management Team is a support function that acts as an advocate and a point of contact for Sales and Marketing data.

What are the ongoing responsibilities of an Client Data Analyst ?
Understand the data flow, key consumption and production of data as well as context within the enterprise:
Build positive relationships with teams, especially the key data consumers and analytics. Take the time to increase knowledge of how they run their business and incorporate sales data into daily work
Connect regularly with each sales office to understand current issues and challenges. Probe the business and validate against other sales offices to understand the scope and priority of the issue
Make recommendations on how data unifications and flow can be used to improve business tasks. Liaise business partners to deliver solutions (reports, processes, technology) that add value.

Provide data management subject matter expertise. Appreciate the connection and data flow between applications and other corporate systems. Be able to clearly articulate the data needs and move initiatives forward by collaborating with business partners:
Actively participate in meetings with business partners to ensure that priorities are clearly understood, information is regularly shared and that key participants are “kept in the loop”
Provide context and background on issues. Collaborate on ideas for progressing initiatives. Ensure appropriate resources are involved to take initiatives forward
Provide insights and expertise to scope statements and requirements documentation
Actively consult or participate in the user acceptance testing process (test cases, documentation, testing execution, etc.)
Ensure business needs remain aligned with overall corporate initiatives and deliver the benefits as originally intended

Monitor the integrity of data and usefulness of reports. Ensure the information available within systems is accurate and up-to-date. Proactively seek data cleansing opportunities and evolve data to better support. Document and maintain ongoing processes for reporting and data clean-up:
Partner with all key data consumers to gain a solid understanding of usage and challenges around data. Establish processes for prioritization of enhancements, especially with the analytics groups
Provide 1st level support for data issues and data maintenance for owned data
Verify and execute data loads into our internal sales systems and ensure any upstream systems accurately receive their data

Increase awareness and promote data management capabilities. Share best practices and provide coaching to local offices on how to access and incorporate output into sales tasks. Encourage IAS leaders to leverage data to make more informed, strategic decisions:
Clearly articulate the goals and core services of the data management team. Proactively promote this information within IAS and ensure business partners understand the data management role within the organization
Share best practices and provides guidance on data capabilities. Reinforces ownership and accountability for data accuracy
Seek opportunities to share the benefits of leveraging sales data to make more informed business decisions

What ideal qualifications, skills & experience would help someone to be Successful?

Knowledge, Education And Experience:
Four year bachelor’s degree required (majors of preference include: business, computer science, mathematics) Advanced degree a plus
Understanding of the Franklin Templeton business model, how FT makes money, the sales process, how technology fits in with the business, etc. Knowledge of the GAS (Global Advisory Services) structure
Experience working through multiple business fiscal cycles; exposure and/or direct experience with project management and/or sales-related-capacity required
Prior work experience related to analytics, sales, marketing and/or international a must. Level will not be granted based on years of experience but will be determined by the employee’s ability to meet each job activity as outlined the ‘typical/expected focus by level
Skills And Abilities:
Ability to communicate effectively with all levels of management; ability to tailor communication style based on audience; ability to get others to want to collaborate with you; strong facilitation skills
Excellent writing skills (for presentations, documentation, etc.)
Working knowledge of the CRM, MDM, Excel, SQL, Power BI, Tableau, Business Objects, and Microsoft Products (PPT, Power Apps, Doc, Visio)
Ability to absorb and interpret large quantities of data; apply trend analysis and knowledge of the business to develop a meaningful and digestible summary with the appropriate level of detail
Ability to take a larger problem and break down the individual components; identify how to go about solving the problem and who to involve in the process
Ability to present recommended solutions to a variety of issues and problems (solutions that are consistent with organization objectives)
Must be extremely detail-oriented (managing lists, tasks/to-dos, etc.) good with follow through on own items; good with following up with others on outstanding item

What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.

Highlights of our benefits include:

Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.",3.8,"Franklin Templeton Investments
3.8",Hyderabad,"San Mateo, CA",5001 to 10000 employees,1947,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Fidelity Investments, Vanguard"
947,Data Analyst,"Roles and Responsibilities:
Extracting, transforming and inputting data sets from various resources. Creating predictive models, translating non-technical aspects into quantifiable tasks. Analysis and representation of output data, highlight and explain trends and patterns, error elimination, using advanced statistical methods (regression, probability distribution, clusters etc.) to provide accurate results.
Data collection, Data Mining, Report generation, Problem identification and solution formulation Market analysis and establishing trends, Strategy development and implementation

Skills:
Extremely good analytical skills.
Good working knowledge of all MS-Office products, especially Advance Excel, Word, PowerPoint, MS-access.
Statistical tools and methods.

Interested candidates can send the updated resume on satish.mehra@exelaonline.com or call on 7722028636
00-7.00 Years",2.6,"Exela Technologies
2.6",Pune,"Irving, TX",10000+ employees,2017,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"SourceHOV, BancTec, Transcentra"
948,Data Modeler,"• Minimum 5-8 years of working experience as Data modeler.
• Data modelling experience in designing.
• Minimum 2-3 years real time experience in Erwin tool is mandatory.
• Experience in normalized modeling techniques.
• Experience in designing the Start schema.
• Experience working in ORACLE.
• Experience with database design, capacity planning, performance tuning and query optimization.
• Experience in working with Bank or Banking and Finance or Financial domain.
• Excellent communication skills with leadership quality.

Job Segment:
Database, Oracle, ERP, Technology",3.5,"LTI
3.5",Mumbai,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
949,Machine Learning Engineer,"Looking for Data Scientists with Python/R Programming skills.
Specific experience in AI areas like Statistical Machine learning / Deep learning / Natural Language Processing (NLP)/ Operations Research (Optimization) will be an advantage.Individual in this role is expected to work with multiple stakeholders and teams

Qualifications and Requirements:-
Previous working experience as a Machine Learning/ Data Scientist for 2 years
MA in Computer Science or similar relevant field
Hands on experience with MALLET
In depth knowledge of Apache Tomcat/Open Source
Excellent project and time management skills
Attention to detail
Outstanding problem solving and analytical skills",-1,Tekolutions.ai,India,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
950,Data Science Internship,"About the company:
SkillBit is a leading staffing and recruitment company engaged in talent searching assignments for skilled and talented candidates for the industry.

About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Working on data science algorithms and AI concepts 2. Using Python or R for web scraping 3. Building AI models using Python, machine learning, and deep learning algorithms 4. Processing of unstructured/structured data

Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 6th Jun'20 and 11th Jul'20
are available for duration of 1 month
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply

Number of internships/jobs available: 3

Categories: Data Science",-1,SkillBit,Pune,-1,-1,-1,-1,-1,-1,-1,-1
951,Data Engineer,"As a data engineer at TEAL, you'll be taking the plunge into a rich data lake that includes everything from satellite data to legal court orders. You'll be hustling and getting your hands dirty with every part of the data pipeline always having an implicit appreciation for how all of this data will ultimately power a revolutionary real estate risk platform.

Your day-to-day will include either all or some of the following:

Constantly scoping out new data sources to complement existing ones
Creating and maintaining distributed web scrapers using Python, RabbitMQ and other technologies
Architecting and managing data pipelines where data flows into multiple end-points including, but not limited to, Postgres, MongoDB and Apache Solr
Documenting workflows and constantly iterating to create better data infrastructure.

We'd love it if you:
Are proficient in Python or any other object-oriented language
Have worked with large (millions to hundreds of millions of rows in a SQL database) interdisciplinary datasets
Have scraped difficult websites and have some experience working with various data APIs
Are patient and methodical with unstructured and messy data
Are always hungry to learn newer and better technologies to make the data ecosystem faster, smoother and less silo-ed

Extra brownie points if you:
Have some experience working with large-scale search indexing
Have performed geospatial analyses in some capacity
Have created and managed data lakes in the cloud
Culture

To explore our culture and the values we embody click here

Testimonials
Testimonial

My experience at TEAL surpassed all my expectations from the get-go. I was asked to help solve one of the most daunting problems in the Indian real estate market. Every day while working on a subset of the problem, the ideas that I brought to the table were shaped into cohesive solutions by a collaborative team effort. At TEAL I was exposed to the most cutting edge technologies such as Cloud Computing, Big Data, ML and Data Science. The growth opportunities at TEAL are tremendous, If you are innovative and can demonstrate the will to realize your ideas, TEAL is an amazing organization to work for.
Gyan Vardhan, Data Science Intern
I had interned as a Data Scientist at Terra Economics and Analytics Lab during its early days, it was a rich learning experience working with a multi-disciplinary team who are extremely passionate about building a decision support platform for the insanely complicated realty market in India. It was exciting and challenging to work on mining huge volumes of property records; extracting patterns from the data, building data pipelines and brainstorming on building the core system. TEAL offers a very healthy work environment coupled with insanely talented people working together in an exciting setting.
Naga Anjaneyulu, Data Science Intern
I worked as a full-time Data science intern at TEAL. During this period, I got an opportunity to leverage my skillsets while also learning new technologies, working on tasks assigned to me. The company operates on the latest tech-stacks and gives opportunities to learn as much as you want. The work environment is challenging, the team at TEAL is super supportive and new ideas are always welcome. It has all the good perks of a startup; creativity and innovation, casual work atmosphere and a collaborative approach to solving problems. Personally, I loved working there, my experience was fantastic!
Archana Parmar, Data Science Intern
As a second-year college student, I was looking for an internship that would allow me to delve deeper into research and work with big data, TEAL gave me the perfect opportunity to do so, enabling me to develop proficiency in research and analysis. As a research analyst intern, I collated and cleaned data and helped in the preparation of reports and presentations, and I had members helping me at every stage of this process. This collaborative environment allowed me to cultivate my skills and also learn from my peers. The holy trinity of Rohan, Kshitij, and Shreyas served as not only excellent mentors and bosses but also as friends, helping me at every stage and giving us all food and ice cream to keep us going!
Arush Mehra, Research Intern
Internships are a crucial part of one’s early career. The internship experience at TEAL was a thrilling rollercoaster ride to say the least! It was more than implementing a standard model or building an already though out concept into reality. It was about finding the solution to a unique and open-ended problem.It was exciting to work on addressing a problem with far -reaching real world applications.Moreover, the work environment had the perfect balance of casual yet professional which kept you focused and stress free at the same time. Out of every 100 startups in India only 2 of them succeed, but there are very few like TEAL India which are bound to make it big at such an early stage.
Divyanshu Agarwal, NLP Intern",4.7,"Terra Economics & Analytics Lab (TEAL)
4.7",New Delhi,"Bengaluru, India",1 to 50 employees,2018,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
952,Senior Consultant - ModellingOps Data Engineer,"Job Title: Senior Consultant - ModellingOps Data Engineer
Location: TRIL GTC
GCL: D1

JOB DESCRIPTION:

AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. The Science & Enabling Units IT is AZs global IT capability function supporting key business areas operating out of sites across the US, UK, Sweden, India & Mexico.

We are looking for AI Ops consultant who will leverage tools & technology best practices to improve delivery performance & data engineering capabilities in the D&A space.

ROLES & RESPONSIBILITIES:

7-10 years of experience in IT Operations involving Data Science, Artificial Intelligence-Machine Learning and Predictive Analytics. Experience in architecting and implementation of end-to-end AIOPs solutions through ELK stack, Splunk. Experience in applying statistical methods, analysis, pattern recognition and modeling on IT Operational data using ELK machine learning. Experience in extracting meaning full data from incoming data streams from different sources through RegEx, Grok etc. Hands-on experience in applying machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc in the IT Operation domain. Experience with machine learning and statistical programming languages - Python, R etc. Experience in assessing the existing IT environment and providing recommendations to reduce the critical applications impacting incidents. Experience in exploring and identifying areas where manual tasks can be automated in IT environment. Experience with various Enterprise IT monitoring solutions including Infrastructure monitoring, Application Performance Monitoring, Network Monitoring, Cloud monitoring etc. Experience in IT Service Management including Service Desk, Incident Management, Change Management, CMDB etc. Excellent knowledge on various IT infrastructure components that includes Server Infrastructure, middle ware, database and application architectures and Cloud Components. Experience/knowledge on Infra monitoring tools - NOI, Zabbix, AppDynamics, Datadog, SCOM, SolarWinds etc. and Service Management tools -IBM Control Desk, BMC Remedy, ServiceNow etc. Experience/Knowledge on BI tools Knowledge on distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc. Knowledge on other programming languages/scripting: Python, Java, JavaScript, etc. ( Added Advantage ) Good analytical skills, strong communication skills are must. Client facing experience is an added advantage. Excellent experience in understanding the problem statement, architect and designing the solution

MANDATORY SKILLS:
Significant experience with AWS cloud environments, working knowledge of Google and Azure platforms. Knowledge of Kubernetes, S3, EC2, Sagemaker, Athena, RDS and Glue is essential.
Experience provisioning computational resources in a variety of Cloud environments using Infrastructure as Code.
Experience with best practice of data transport and storage within cloud system.
Experience building large scale data processing pipelines. e. g. Spark and SQL.
Experience with containers and microservice architectures e.g. Kubernetes, Docker and serverless approaches.
Excellent working knowledge in DevOps, using continuous integration and continuous development.
Use of Data Science modelling tools e.g. R, Python, SAS and Data Science notebooks (e.g. Jupyter).
Good written and verbal skills, fluent English
DESIERED SKILLS:
Agile practices, especially being a SCRUM Master
EDUCATIONAL BACKGROUND: B.E/B.Tech/MCA

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",3.9,"AstraZeneca
3.9",Chennai,"Cambridge, United Kingdom",10000+ employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Roche, GlaxoSmithKline, Novartis"
953,DATA ENGINEER,"JOB DESCRIPTION
As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements, and also research new uses for data acquisition. You should also know the ins and outs of the industry such as data mining practices, algorithms, and how data can be used.

DESIRED CANDIDATE PROFILE
An ideal candidate must possess prior experience leading a project.

Candidates must have:
> Experience in Hive, Spark, Scala, AWS DynamoDB, HBase, AWS Glue, Talend, Kafka, Snowflake ETL
> Strong experience in a BI/Data Warehouse environment with involvement in design, development, implementation, troubleshooting and support of ETL process using ETL tool.
> Experience in developing Data Marts, Data warehousing and Operational Data Store (ODS) on any of the databases or Hadoop environments.
> Experience in database like MS SQL, MySQL, Oracle, PostgreSQL
> Good to have programming experience in writing Complex Stored Procedures, Queries, Views, User Defined Functions, Cursors and Common Table Expressions using SQL or T-SQL.
> Experience in Performance Tuning and Query Optimization by Indexing, Partitioning and De-normalization.
> Experience in Developing a framework for ingesting data into Data lake
> Good database knowledge, analytical thinking
> Design, construct, install, test and maintain data management systems.
> Build high-performance algorithms, predictive models, and prototypes.
> Develop set processes for data mining, data modeling, and data production.
> Experience with cloud services: AWS (EC2, EMR, S3, Athena) and scripting languages like Python, /PySpark/R/SAS
> Install/update disaster recovery procedures.
> Experience in Agile Application Development & Scrum methodologies is preferred
> Ability to supervise and mentor junior developers on the team.
> Must be self-motivated and work well pulling people together in addition to being able to pull people together technically
> Demonstrated proficiency of troubleshooting techniques and detail-oriented problem diagnosis
> Ability to handle responsibility, is self-directed, with strong organizational and documentation skills
> Ability to work independently and efficiently under aggressive deadlines to meet project commitments
> Excellent verbal and written communication skills

EDUCATION
UG - B.Tech/B.E. - Computers, Electronics/Telecommunication, Diploma - Computers, Electronics/Telecommunication, B.Sc - Computers, BCA - Computers) AND (PG - M.Tech - Computers, Electronics/Telecommunication, MCA - Computers, M.Sc - Electronics, Computers) AND ( Doctorate - Any Doctorate - Any Specialization, Doctorate Not Required).

OTHER DETAILS
Number of vacancies: 4
Experience: 3 years
Location: Cochin

If you have a passion towards technology and coding, then we have the right job for you. Kindly forward your resumes to
Email: jobs@mjsofttech.com
Phone: 0484-2421245 / 928 720 7160",4.0,"MJ Softtech
4.0",Kochi,"Cochin, India",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
954,Data Engineer,"Education/ Experience and Skill Requirement
4+ years of relevant experience in
Experience working with both relational and NoSQL databases.
Strong coding skills; Python (preferred) /R/Java/Scala
Experience in developing Data warehousing technologies Experience with AWS or equivalent cloud services preferred
Experience in BigData technologies (Hadoop, HDFS, MapReduce, Spark, Hive, HBase etc) will be valuable
Knowledge of Machine Learning a big plus (Random Forest, Decision Trees, SVM, NLP, Gradient Boosting, Supervised/Unsupervised Learning, Clustering, classification and regression modeling).
Responsibilities
Proficiency with several years’ experience in more than one of Python, R, Java, Scala, or robust Linux shell scripting
Implementation experience with data warehouse architecture & design, ETL design/development, and Analytics
Knowledge of general cloud architecture and cloud strategies especially around AWS services and concepts such as S3 object stores, RDS databases, EC2, Glacier, Lambda, IAM, enterprise security, data security, DevOps, replication and disaster recovery
Well versed with data mining & exploration, NLP and visualization
Understanding of data modeling, data integration, and data representation (metadata, OWL, ontologies)
Developing data marts and data management using SQL
Creating powerful visual outcomes
Independently manage daily client communication, especially over calls
Manage client deadlines, ensure quality of the deliverables, attention to detail
Experience/understanding of corporate finance data from company filings is desirable",3.6,"Copal Partners
3.6",Bengaluru,"New York, NY",10000+ employees,1900,Company - Public,Financial Analytics & Research,Finance,₹100 to ₹500 billion (INR),-1
955,Data Engineer,"Job Description / Responsibilities
Build workflows to ensure data extraction quality and storage into our backend data store
Architect, build and train ML/AI models that can predict outcomes and report on anomalies.
Design data pipelines to perform ETL on content/data from multiple types of source systems.
Create data analytics views using RDBMS/Key-Value stores, on private and public/cloud
Create software that is well tested, maintainable, extensible and scales out with large data

Minimum Qualifications:
2+ years of software development with Python
2+ years of SQL (MySQL/Postgres) and Key-Value databases
1+ years of experience with scikit
2+ years of experience in data extraction, data transformation using custom Python/Java
Experience working with MapReduce/Hadoop/kafka/Elastic stack
Experience with Node backend and React/Redux
Experience working with git/mercurial, Amazon/Google cloud, Linux/LAMP stack
Experience in testing or test driven development
Experience with Data science and Machine Learning algorithm development

Location:
Hyderabad/Bangalore

Package:
Highly competitive to match experience and capability",3.7,"TVS
3.7",Bengaluru,"Chennai, India",5001 to 10000 employees,-1,Company - Private,Accounting,Accounting & Legal,₹100 to ₹500 billion (INR),-1
956,Data Engineer,"Permanent position with US based client of iFlex.
Work Location: Bangalore
Experience Level: 2+ Years

Role:
As part of our global team you will work on the data platform reporting to the Data Engineering Lead. Your role includes specification, development, test and rollout of features on our data platform. You are expected to contribute to the vision, understand our product roadmap, integrate business value andclient experience and contribute to build an engineering culture within the team. This initiative is of critical important to the success of the organization and our roadmap, for instance, services like liquidity analytics, billing, client onboarding, reporting and others will rely on the data platform. Accurate, granular, complete and timely data will be our key differentiating factor and competitive advantage in the market place. We expect the successful candidate to deliver high quality software and to be passionate about data engineering..

Responsibility / Qualification:
Managing multiple tasks and use sound judgment when prioritizing.
Collaborating with global cross functional team in building customer-centric products.
Analyzing existing software implementations to identify areas of improvement and provide deadline estimates for implementing new features.
Updating and maintain documentation for team processes, best practices and software runbooks.
Establishing trusted partnerships with peers, product heads, and executive level stakeholders.
We are looking for someone who is passionate about technology and engineering.
Exceptional analytical skills and ability to apply knowledge and experience in decision-making to arrive at creative and commercial solutions.
Ability to leverage technology to deliver business value.
You are independent and comfortable in a fast paced, ambiguous and often multi-directional work environment.

Preferred Qualifications:
B.S. or higher in Computer Science.
Minimum 2 years of relevant professional experience using a modern programming language (preferably Java/Scala).
Experience leveraging test driven development technics.
Comfort with Agile operating models.
Team oriented.
Strong interpersonal and communication skills.
Energetic, self-directed, and self-motivated.
Experience with microservice architecture.
Experience with Kafka, MongoDB, Hadoop, Cassandra.
Experience with AWS.
Experience in Financial Services or Fintech.",-1,IFLEX,Bengaluru,"Moscow, Russia",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
957,CIEL/SEL/1941: Sr data scientist,"Mandatory skills required -
Databases (SQL, Oracle, Any RDBMS) - Should have working knowledge of atleast one database
PL/SQL Programming Languages
R, Python (Any One)
Inferential Statistics - Hypothesis, p-value, R2, RMSE, MAPE etc
Exploratory Data Analysis
Machine Learning Algorithms - Should have in-depth knowledge and implementation of atleast one algorithm

Responsibilities
: Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the why & how of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions

Education
Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics
Experience
Minimum years of related experience required: 3 years
Preferred years of experience: 5 years
Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desirable.

Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
958,Data Engineer,Data Engineer,3.6,"Bookmyshow
3.6",Mumbai,"Mumbai, India",1001 to 5000 employees,2007,Company - Private,Ticket Sales,"Arts, Entertainment & Recreation",Unknown / Non-Applicable,-1
959,Data Analyst,"Required Skills & Experience

We are looking for a Data Analyst Executive
Eligible Qualifications : B. Tech, BCA, M.Tech, MCA
Experience : 3-5 years, fresher’s can also be considered
Location of Job : Gurgaon/Connaught Place, New Delhi
Technicals Skills

Following technical skills are pre-requisite:
Well versed with Software development methodologies, such as SDLC (Software Development Life Cycle), DDLC (Document Development Life Cycle).
Database schema design and implementation
Should have worked in either of technologies Sql Query/ Tableau/ Excel (Macros)/ Access (Query) writing for data analytics.
For planning and coordinating activities, organizations remain in invariant communication with one another and the data transfer has to be performed efficiently and smoothly as possible.
He/ She should manage the execution of the technologies, help the businesses in utilizing the systems, and should be well versed with the basics of computer systems such as Networking, Installation of necessary software and hardware.
Ability to determine the interrelationships between solutions and requirements.
Ability to think analytically and should be a problem solver and logic building should be very strong.
Good interpersonal skills to form effective working relationships with people at all levels.
Excellent communication and presentation skills and strong written & oral English skills.
To know more about us visit us www.sspl.net.in or write to us at admin@sspl.net.in",-1,Substratal Solutions,Connaught Place,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
960,Artificial Intelligence Scientists,"Experience 2- 4 Years
Salary 4 LPA - 6 LPA
Job Location Chennai

Industry:
IT-Software / Software Services

Keywords:
Artificial Intelligence

About Job:
Must have Excellent knowledge in AI / Machine learning (Mandatory).
Machine learning frameworks like keras, tensor flow etc.
And also other big data tools like Hadoop etc, Must know R and python.
Good understanding in SDLC & Business cycle.",4.0,"Careerera
4.0",Chennai,"Wayland, MA",501 to 1000 employees,-1,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
961,Senior Data Engineer,"About Us

upGrad is an online education platform building the careers of tomorrow by offering the most industry-relevant programs in an immersive learning experience. Our mission is to create a new digital-first learning experience to deliver tangible career impact to individuals at scale. upGrad currently offers programs in Data Science, Machine Learning, Product Management, Digital Marketing, and Entrepreneurship, etc. upGrad is looking for people passionate about management and education to help design learning programs for working professionals to stay sharp and stay relevant and help build the careers of tomorrow.
upGrad was awarded the Best Tech for Education by IAMAI for 2018-19
upGrad was also ranked as one of the LinkedIn Top Startups 2018: The 25 most sought-after startups in India
upGrad was earlier selected as one of the top ten most innovative companies in India by FastCompany.
We were also covered by the Financial Times along with other disruptors in Ed-Tech
upGrad is the official education partner for Government of India - Startup India program
Our program with IIIT B has been ranked #1 program in the country in the domain of Artificial Intelligence and Machine Learning
About the Role

We are looking for a Data Engineer to help us scale the existing data infrastructure and in parallel work on building the next generation data platform for analytics at scale, machine learning infrastructure and data validation systems.
In this role, you will be responsible for communicating effectively with data consumers to fine-tune data platform systems (existing or new), taking ownership and delivering high performing systems and data pipelines, and helping the team scale them up, to endure ever growing traffic.
This is a growing team, which makes for many opportunities to be involved directly with product management, development, sales, and support teams. Everybody on the team is passionate about their work and we’re looking for similarly motivated “get stuff done” kind of people to join us!

Roles & Responsibilities
Engineer data pipelines (batch and real-time ) that aids in creation of data-driven products for our platform
Design, develop and maintain a robust and scalable data-warehouse and data lake
Work closely alongside Product managers and data-scientists to bring the various datasets together and cater to our business intelligence and analytics use-cases
Design and develop solutions using data science techniques ranging from statistics, algorithms to machine learning
Perform hands-on devops work to keep the Data platform secure and reliable
Skills Required
Bachelor's degree in Computer Science, Information Systems, or related engineering discipline
6 + years’ experience with ETL, Data Mining, Data Modeling, and working with large-scale datasets
6+ years’ experience with an object-oriented programming language such as Python, Scala, Java, etc
Extremely proficient in writing performant SQL working with large data volumes
Experience with map-reduce, Spark, Kafka, Presto, and the ecosystem.
Experience in building automated analytical systems utilizing large data sets.
Experience with designing, scaling and optimizing cloud based data warehouses (like AWS Redshift) and data lakes
Familiarity with AWS technologies preferred
Qualification – B.Tech/M.Tech/MCA(IT/Computer Science)

Years of Exp – 6-9",3.5,"upGrad Education Private Limited
3.5",Mumbai,"Mumbai, India",501 to 1000 employees,2015,Company - Private,Education Training Services,Education,₹1 to ₹5 billion (INR),"Udacity, General Assembly, Springboard"
962,BBRC-Genomics-Associate Scientist,"JOB DESCRIPTION

Designation: Associate Scientist

Job Location: Bangalore

Department: Translational Medicine- Translational Sciences

About Syngene

Incorporated in 1993, Syngene International Ltd. is an innovation-focused global discovery, development and manufacturing organization providing integrated scientific services to the pharmaceutical, biotechnology, nutrition, animal health, consumer goods and specialty chemical industries around the world. Syngene’ s clientele includes world leaders such as Bristol-Myers Squibb, Baxter, Amgen, GSK, Merck KGaA and Herbalife. Its innovative culture is driven by the passion of its 4240- strong team of scientists who work with clients from around the world to solve their scientific problems, improve R&D productivity, speed up time to market and lower the cost of innovation .

Job Purpose:
To play a key role in TM-TS, develop an early-stage research strategy, initiate and lead discovery programs while managing ongoing programs in TM-TS. The role will work part of TMTS, and work with internal and external collaborators .

Key Responsibilities:
Experience in isolating DNA and RNA from blood, tissues and FFPE samples and cell lines. Experience with optimization of extraction protocols and for parameters like yield, input sample quantities and sample types is important.
Expertise in PCR, qPCR, cDNA/gDNA library preparation. Exposure to microarray techniques.
Proficiency in preparation of libraries for Next Generation Sequencing of transcriptome and genome, with significant experience in optimization of parameters like input RNA/DNA quantities and sample type
Experience with single cell RNA-seq will be plus.
Experience with various NGS protocols (DNA Amplicon based, hybrid capture based low input, degraded DNA and RNA samples e.g. FFPE samples.
Strong understanding of experimental design and statistical principles behind experimental design and differential gene expression. Experience with analysis of single cell RNA-sequencing data will be a plus

Educational Qualification:
M.Sc or M. Tech in Biotechnology, Molecular biology or Biological Sciences,

Technical/functional Skills:
DNA/ RNA Isolation, Expertise in PCR, qPCR, Experience in NGS protocols

Experience:
2 to 5 Years

Behavioral Skills:
A proactive team player.
Ensure completion of experiments and generate accurate and reproducible data from experiments.
Ability to work independently, prioritize tasks and work on multiple projects simultaneously with; comfortable working in a dynamic environment with changing requirements.
Good oral and written communication and presentation skills to work in a multi-disciplinary team
Equal Opportunity Employer:
It is the policy of Syngene to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by applicable legislation or local law. In addition, Syngene will provide reasonable accommodations for qualified individuals with disabilities.",3.5,"Syngene
3.5",India,"BENGALURU, India",1001 to 5000 employees,1994,Unknown,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
963,Applied Scientist 1,"Position Requirements:
Master's degree in Computer Science, Computer or Electrical Engineer, Mathematics, or a related field plus at least one year of experience in the job offered or related occupations of Software Engineer, Software Developer, or a related occupation. Employer will accept a Bachelor’s degree and five years of experience in the job offered or a related occupation as equivalent to the Master’s degree and one year of experience. One year of experience in the job offered or related occupation must involve designing and developing large-scale, multi-tiered, distributed software applications, tools, systems and services using Java, Object Oriented Design and Distributed Programming].

Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, Oracle/Berkeley databases, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills

Amazon Selling Partner Services team drives the Selling On Amazon business and develops solutions that enable millions of sellers around the world to sell on Amazon's Marketplaces. More than half of shipments for Amazon customers are generated from this business. The team is focused on building a technology platform that will support the explosive business growth in existing markets, streamline the business for Amazon and the Selling partners and launch business in new markets and establish a fair marketplace.

Our team is seeking engineers with broad technical skills to help us optimize how we synthesize massive amounts of data and complex business rules into mission critical financial information. As a member of this team you will employ object oriented techniques in Java, and DynamoB, PostGres and ElasticSearch skills to help us support Amazon's next generation of selling partner services. Along the way you'll gain and leverage a unique understanding of how Amazon.com works; from the numerous software systems that comprise the website's back-end, to the details of our business model, and the relationships we're establishing with an ever-growing network of selling partners who depend on Amazon.com to run their businesses.

The ideal candidate will draw upon exemplary analytical, critical thinking, and problem solving skills, and a passion for maintaining highly reliable, distributed systems which operate 24/7/365. Successful members of this team collaborate effectively with internal end-users, aggressive cross-functional software development teams, and technical support/sustaining engineering teams to solve problems and deliver successfully against high operational standards of system availability and reliability. We look for engineers who are excellent communicators, self-motivated, flexible, hardworking, and who like to have fun!

Position Responsibilities:
Participate in the design, development, implementation, testing and documentation of large-scale, multi-tiered, distributed software applications, tools, systems and services using [Java, Object Oriented Design and Distributed Programming]. Translate functional requirements into robust, scalable, supportable solutions that work well within the overall system architecture. Participate in the full development cycle, end-to-end, from design, implementation, and testing to documentation, delivery and maintenance. Produce comprehensive, usable software documentation. Evaluate and make decisions around the use of new or existing software products and tools.

Preferred Qualifications
Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
964,Senior Clinical Data Analyst,"About Novotech:

Novotech is internationally recognised as the leading independent and full-service contract research organisation (CRO) in the Asia Pacific region. We provide a wide range of clinical development services across all research phases and therapeutic areas and have been instrumental in the success of hundreds of Phase I – IV clinical trials throughout the Asia Pacific. Powered by the highest quality people, Novotech strives to set the benchmark for both business and clinical trial performance. Our people are one of our key strengths. We value our people and recognise the work they do. We are lucky to have the best people and talent from across the Asia Pacific region work together to deliver to clinical trial success for our clients. Our people and those we look to recruit have an attitude of making things happen. They are problem solvers, driven with a focus on delivering quality, accountability and a high level of performance.

Brief Position Description:

As part of Novotech’s Biometrics unit, the Senior Data Analyst (SDA) is responsible for all data analysis and business intelligence activities related to study related clinical and operational data. The SDA acts as primary point of contact for all data analysis matters to the study team and is responsible for the timely delivery of quality outputs following all applicable regulatory, compliance, best practice and operational procedures.

Minimum Qualifications & Experience:

Graduate in information science, data science or life science-related field, or similar. More than five years’ experience in a senior role related to data science, data analysis, clinical data management or clinical data programming in a pharmaceutical company, CRO or EDC software provider.

Responsibilities
The Senior Data Analyst (SDA) is responsible for providing technical, procedural (SOPs) and planning leadership across multiple projects assigned to the data analyst team members ensuring that they deliver in accordance with SOPs, programming best practices, and the timelines agreed within the Project Team.
Collaborate with cross-functional stakeholders to implement data science solutions to solve business needs using available technological solutions.
Scope data analysis effort for projects and project manage all data analysis activities across multiple projects for different study stakeholders.
Gather study requirements from data management for data review and external data reconciliation and provide guidance on appropriate outputs (dashboards, visualisations, listings, reports).
Extract, assess, integrate, transform data sources to provide data visualisation outputs for analytics.
Design and develop prototypes and final versions of data outputs (dashboards, reports, visualisations, listings) using Business intelligence tools and Data Visualisation tools.
Design and develop standard dashboards and content for different audiences.
Analyse, manipulate and understand data from multiple sources to present and create dashboards and reports to make business decisions.
Assist teams on best-practice for data visualisation dashboard development.
Educate teams on how to use all the features of applicable data visualisation platform in conjunction with data visualisation dashboards.
SME for the data visualisation development and assisting team members.
Identify and communicate project risks and maintain documentation within project files as appropriate
Represent data analysis group at internal / external meetings as appropriate.
Assess and implement new data analysis, BI and data visualisation processes and technologies.
Take an active role in the development of best practices, process improvement, quality control and governance related to all data analysis matters.
Provide training and mentoring to Data Analysis of team members in SOPs, software applications, and best practices.
Provide Subject Matter Expertise on all data analysis and visualisation related activities.
Attributes and Skills

Expert knowledge of clinical study data structures and schemas of EDC databases. Expert knowledge in data processing activities such as extracting, integrating, transforming and presenting data. Statistical Programming skills in Python, R or similar. Knowledge of SQL and EDC systems. Working knowledge of Spotfire, Power BI, Tableau or other data review and visualisation tool. Ability to gather business requirements from multiple stakeholders and clients and provide guidance on the use of appropriate data visualisations.

Experience mentoring and training others. Awareness of regulatory and compliance issues and understanding of the application of SOPs and Quality Control to daily activities. Excellent analytical, communication and problem-solving skills.

Opportunities and Benefits:

To deliver clinical trial and research excellence for our clients, our people are 'best in class'.

At Novotech, we seek and nurture people with exceptional talent. We are committed to providing our people with regular internal and external training, a competitive bonus structure and a supportive work environment. We are also focused on providing our people with a wide variety of career growth and development opportunities.

For more information about where your next career step at Novotech might take you, visit http://novotech-cro.com/novotech-careers",4.5,"Novotech
4.5",Bengaluru,"Sydney, Australia",501 to 1000 employees,1996,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
965,Data Engineer,"Data Engineer Responsibilities:
Liaising with coworkers and clients to elucidate the requirements for each task.
Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed.
Reformulating existing frameworks to optimize their functioning.
Testing such structures to ensure that they are fit for use.
Preparing raw data for manipulation by Data Scientists.
Detecting and correcting errors in your work.
Ensuring that your work remains backed up and readily accessible to relevant coworkers.
Remaining up-to-date with industry standards and technological advancements that will improve the quality of your outputs.
Data Engineer Requirements:
Bachelor's degree in Data Engineering, Big Data Analytics, Computer Engineering, or related field.
Master's degree in a relevant field is advantageous.
Proven experience as a Data Engineer, Software Developer, or similar.
Expert proficiency in Python, C++, Java, R, and SQL.
Familiarity with Hadoop or suitable equivalent.
Excellent analytical and problem-solving skills.
A knack for independent and group work.
Scrupulous approach to duties.
Capacity to successfully manage a pipeline of duties with minimal supervision.
Job Type: Full-time

Salary: ₹360,000.00 to ₹870,000.00 /year

Experience:
total work: 2 years (Preferred)
Data Engineer: 1 year (Preferred)
Education:
Diploma (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,Futurious Technologies,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
966,Quantitative Analyst,"The successful candidate will be a highly analytical individual with hands on programming skills. The candidate will work closely with the research team and clients towards the ongoing development and integration of new investment strategies, models and tools on Axle

Location

Mumbai
Responsibilities

Perform daily/weekly/monthly tasks of performance and risk reporting
Develop and automate investment processes and strategies via VBA and Matlab
Develop tools to integrate trading decision systems with risk management systems
Ad hoc tasks (such as operational tasks, internal documentation tasks and preparation of marketing materials)
Skills/Experience

Excellent programming skills in Matlab/Excel-VBA
Thorough with financial concepts and calculations like Drawdown, VaR, Eloss etc.
Understanding of financial market products like options, futures, FX forwards etc.
Working knowledge of Bloomberg is preferred
Should be self-driven and detail oriented with an analytical mindset
Should be a proactive and quick learner; a team player showing enthusiasm and drive to accomplish results in a fast paced environment
Min. 2 years of relevant work experience
Qualifications

B.Tech/M.Tech/MBA/CFA/FRM",5.0,"B&B Analytics
5.0",Mumbai,"Zug, Switzerland",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
967,Analyst - Data Scientist,"Job Summary

Experience:
3 - 5 Years

Location:
Mumbai

Designation:
Analyst - Data Scientist

Degree:
BE-Comp/IT, BE-Other, BTech-Comp/IT, BTech-Other, ME-Comp/IT, ME-Other, MTech-Comp/IT, MTech-Other, PhD-Comp/IT, PhD-Other

Educational Level:
Graduate/Bachelors

Industrial Type:
IT-Software/Software Services

Functional Area:
IT Software - Application Programming / Maintenance

Key Skills:
Data Scientist

Job Post Date:
Thursday, March 19, 2020

Company Description

We are capability centre based in Mumbai, initially started as a back-office operational support to the UK business unit.

However, over the recent years, we have significantly increased the breadth and depth of our capabilities and offerings to keep pace with the changing needs of the Group. These include Digital & Knowledge Services, Finance and Actuarial, Information Technology (IT), Customer Service, Risk and Audit.

Our core purpose is to be a strategic partner to company, enabling growth by delivering change and driving synergies through a highly capable and agile workforce.

With our diversified service offerings we provide our people with exciting opportunities to grow personally and professionally.

Company is a leading savings and investments business serving around 5.5 million retail customers and more than 800 institutional clients.

It-s innovative asset management and customer solutions are supported by extensive investment capabilities, an international distribution network and two strong brands.

Job Description

3 – 5 yrs experience as Data Scientist
Should have at-least 1 end-to-end ML project experience
Very high proficiency in R or Python
Excellent in forecasting methods like simple exponential smoothing, multiplicative seasonal indexes, simple and weighted moving averages and time series forecasting methods
Exposure to with advanced deep learning techniques such as LSTM. CNN, Dense neural networks as well as neural networks design and implementation through tools like tensorflow, keras, pytorch, deepai or equivalent.
Good SQL experience",3.8,"Sampoorna Computer People
3.8",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
968,Data Lake Developer,"For Us, It's A Mission

At Mylan, we mean it when we say we work every day to provide access to high quality medicines to the world's 7 billion people. If you are unconventional, relentless and passionate. If you believe in doing what's right, not what's easy. If you are a doer and have a passion for serving others, we want to talk to you.

Make a Difference

At Mylan, each person has the ability to make a difference. From the providers who sell and market our products, to the producers who develop and manufacture them and finally to our business partners who support the providers and producers, we all have a mission critical role. Here's how this role will help:

ESSENTIAL DUTIES AND RESPONSIBILITIES
To perform this job successfully, an individual must satisfactorily perform each essential duty. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential duties.
1. Create and maintain optimal data pipeline architecture on Azure platform.
2. Develop batch processing solutions by using Data Factory and Azure Databricks.
3. Delivering a Data Warehouse in the Azure Cloud.
4. Design relational and non-relational data stores on Azure.
5. Identify, design, and implement internal process improvements : automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc..
6. Developing Big Data Solutions with Azure Machine Learning.
7. Strong interaction with business departments to provide consultative support for digitization efforts, as well as close collaboration with the Business Technology management, focused on future innovation topics.
8. Participate and lead in design sessions, demos and prototype sessions, testing and training workshops with business users and other IT colleagues.
9. Design & Build for any API Development or SQL DB development.
10. Providing service management, orchestration, monitoring and management requirements of Azure cloud platform.
11. Create data tools / products for analytics and data scientist team members that assist them in building and innovative solutions that drive tangible business value.
12. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
13. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
14. Design security for source data access. Chose the appropriate authentication mechanism, (ie Azure Active Directory (Azure AD), etc).
15. Design for real-time processing by using Stream Analytics and Azure Databricks.

Make Our Values Your Values

Mylan hires only the best. People who thrive in a culture of innovation and empowerment. People who are active learners and have a positive attitude. People who are leaders and know that by working together we can run faster, reach higher and achieve more. By doing so, we will continue to set new standards in health care. Here are the minimum qualifications and essential functions for this position:

QUALIFICATIONS

The qualifications listed below are representative of the minimum knowledge, skill, and/or ability required.

SKILLS AND ABILITIES

1. 10 years of experience in Microsoft technologies including SQL.

2. At least 5 years as a Sr Developer with at least 3 years hands on experience as Azure Data Engineer building large scale Azure data solutions.

3. At least 5 years of experience in Azure based data solutions.

4. At least 3 years of experience on working with large projects including the most recent project in the cloud (Azure) or on prem with a focus on Azure Data services.

5. At least 5 years of Hands-on administration, configuration management, monitoring, performance tuning of Hadoop/Distributed platforms.

6. At least 5 years of demonstrated experience at least in the most recent 2 years of designing and delivering solutions using Cortana Intelligence suite of analytics services part of Microsoft Azure including Azure Machine Learning Studio, HDInsight, Polybase, Azure Data Lake Analytics, Azure Data Warehouse, Streaming Analytics, Data Catalog, R/R Studio

7. Experience in designing and building logics required for optimal extraction, transformation, and loading of data from a wide variety of data sources

8. Experience within Data Security design, including but not limited to:

a. Choosing the appropriate authentication mechanism, such as Azure Active Directory (Azure AD)

b. Defining strategies for data encryption for data at rest and in transit

9. Experience partnering with Business Analysts and Data Scientists to enable effective and efficient data preparation and delivery

10. Experienced in vendor management and working with 3rd parties onshore & offshore.

11. Experience working in a global team.

12. Experience working in an Analytics / Big Data solutions on MS Azure Cloud

13. Experience with code management tools, automated testing

14. Experience creating and maintaining optimal data pipeline architecture on Azure platform

15. Experience developing batch and real-time processing solutions by using Data Factory and Azure Databricks

16. Familiar with AGILE and Azure DevOps methodology

17. Hands on PoC capabilities are needed to prove a particular architecture concept

18. Azure Native Services experience across Data Fabric and Service Fabric

19. Experience in Application modernization from legacy on-premise data architecture platform technology stack to modernized Azure Cloud base Architecture.

20. Experience with Git, NoSQL Data Solutions, Microsoft Azure, HD Insights, Azure ML, DataBricks ML Flow, R or Python.

21. Must have excellent communication skills.

EDUCATION/EXPERIENCE (Note: Please select one)

Minimum of a Bachelor's degree in Computer Science and Engineering is preferred with minimum 10 years of experience. However, a combination of experience and/or education will be taken into consideration

Why Mylan?

If you want to be part of a global health care company that is making a difference and changing lives, Mylan may be the place for you. With a workforce of more than 35,000 worldwide, we can make a difference. We encourage you to visit Mylan.com to learn more about our unconventional culture, our approach to doing business and how we plan to set new standards in health care.

Mylan offers competitive salary, excellent benefits and an environment conducive to professional growth and advancement. All qualified applicants will receive consideration for employment without regard to their disability or protected veteran status. Mylan is an Equal Opportunity Employer, Minorities/Female/Disabled/Veteran.",3.8,"Mylan Inc.
3.8",Bengaluru,"Hatfield, United Kingdom",10000+ employees,1961,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
969,Off Campus Recruitment - Quantitative Researcher,"Description:
Graviton is a privately funded quantitative trading firm striving for excellence in financial markets' research. We are seeking fresh talent from the top IIT's to join us as Quantitative Researchers for our team in Gurgaon.If you are a student graduating in 2020 from Computer Science , Electrical or Maths Stats Computing streams with a greater than 8 CGPA please apply here.

This role is open to students from campuses that we could not visit this year. Please check your individual placement policy restrictions before applying.

Graviton trades across a multitude of asset classes and trading venues using a gamut of concepts and techniques ranging from time series analysis, filtering, classification, stochastic models, pattern recognition to statistical inference analysing terabytes of data to come up with ideas to identify pricing anomalies in financial markets.

As a Quantitative researcher your responsibilities will include

Develop new or improve existing trading models using in-house platforms

Use advanced mathematical techniques to model and predict market movements

Analyse large financial datasets to identify trading opportunities

Provide real time analytical support to experienced traders

Requirements :
Possess a degree in a highly analytical field, such as Engineering, Mathematics, Computer Science from IITs schools

Quantitative bend of mind

A working knowledge of Linux/Unix

Programming experience, preferably in C++ or C

Strong interest in learning about financial markets.

Have a strong work ethic

Hard Working

Benefits:
Our open and casual work culture gives you the space to innovate and deliver. Our cubicle free offices , disdain for bureaucracy and insistence to hire the very best creates a melting pot for great ideas and technology innovations. Everyone on the team is approachable, there is nothing better than working with friends!

Our perks have you covered.

Competitive compensation

6 weeks of paid vacation

Monthly after work parties

Catered breakfast and lunch

Fully stocked kitchen

Gym membership

International team outing",5.0,"Graviton Research Capital LLP
5.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2014,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
970,Data Engineer,"Zauba Technologies is a startup based in Bangalore. Zauba's services are used by leading companies in India. Zauba is powered by a young and passionate team. We are looking for individuals who would like to be a part of our founding team.

As a Data Engineer and as a part of founding team, you will be expected to visualise and develop disruptive data products. Eventually you would be responsible for entire project lifecycle of products you would visualize. Your rewards will be directly proportional to the value you generate.

Job Responsibilities
Design and development of robust, scalable and highly efficient data engineering solutions for structured and unstructured data (Including gathering and processing raw data at scale, writing scripts, web scraping, calling APIs, writing SQL queries, etc.)
Develop processes for text mining and extraction of information from unstructured data
Design, architect and develop efficient data pipelines around the data collected
Take ownership of existing web product and applications
Design and implement data models that scale across the enterprise
Take ownership of existing data workflows and processes
Enhance scalability, performance, and stability of existing infrastructure
Work closely with other team members to integrate your innovations and algorithms into our production systems

Essentials
Java/Python - Intermediate to advanced level
SQL - Advanced
MySQL Intermediate to advanced level
Regex - Basic to intermediate level
Linux Basic to intermediate level

Good to have
Hadoop/Spark
R
MongoDB

Must have qualities
Skills to learn new skills quickly
Desire to create disruptive products and services
Passion - not just to work in startups but to take them to next level
Above average programming aptitude
Be passionate about producing high quality engineering deliverables
Be productive working independently or collaboratively
Have an eye for building efficient processes
Be self motivated
Proactively take ownership

Interested?

Send your resume to hr@zaubacorp.com",3.8,"Zauba Corp
3.8",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 million (INR),-1
971,Quantitative Research,"We are looking for highly trained professionals who are interested in applying advanced mathematical quantitative methods to the modeling of global financial markets. You would be joining a group made up of highly proficient individuals from various scientific disciplines. We have a spectrum of opportunities for individuals with the right scientific skills. Experience in finance is not required.

The ideal research candidate will have:
A Ph.D. in Computer Science, Mathematics, Physics, Statistics, or a related technical discipline.

A demonstrated capacity to do first-class research.

Computer programming skills.

An intense interest in applying quantitative analysis to solve difficult problems.

Send us a copy of your resume to
careers@dolatcapital.com

For internship opportunities, please send us a copy of your resume to
careers@dolatcapital.com",4.0,"Dolat Capital
4.0",Mumbai,"Mumbai, India",51 to 200 employees,1970,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
972,Data Engineer,"Bachelor’s degree in Computer Science or related field
5+ years relevant experience
5+ years experience with SQL, SQL Tuning, Oracle, OLAP, Big Data Technologies
5+ years experience developing end-to-end Business Intelligence solutions: data modeling, ETL and reporting
Experience with Java and experience with scripting languages like Perl, Python, Unix shell scripts,VBA and MS Excel
Proficiency with Linux and systems administration
Proven ability at looking at solutions in unconventional ways. Sees opportunities to innovate and can lead the way.
Top notch communication (verbal and written) and interpersonal skills to convey key insights from complex analysis in summarized business terms and an ability to effectively communicate with technical teams.
Ability to work with shifting deadlines in a fast paced environment.
Operations Finance Technology team, responsible for building technical solutions for multi-billion WW Operational Cost analytic including Inbound cost (Receiving / PO), variable Cost, fixed cost, outbound (Customer Shipments / Transportation), and Customer Service, is looking for a Data Engineer.

As a data engineer, you will get the exciting opportunity to work on very large data sets in one of the world's largest and most complex data warehouse environments. You will work closely with the business teams in analysis on various cost savings initiatives, many non-standard and unique business problems and use creative-problem solving to deliver actionable output.
You will be responsible for designing and implementing an analytical environment using third-party and in-house reporting tools, modeling metadata, building reports and dashboards. You will have an opportunity to work with leading edge technologies like Redshift, Hadoop/Hive/Pig. You will be writing scalable queries and tuning performance on queries running over billion of rows of data.

You should be analytical, have an extremely high level of customer focus and a passion for process improvement. You should be motivated self-starter that can work independently in a fast paced, ambiguous environment. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions.
Bachelors in Computer Science or related field
Practical Knowledge of Linux or Unix shell scripting
Experience in working with business customers to drive requirements analysis
Exposure to large databases, BI applications, data quality and performance tuning
Excellent written and spoken communication skills
Experience with Hadoop-based technologies such as HBase, Pig, Hive and Spark
Strong proven ability in building high-performance, highly available and scalable data solutions using Oracle and/or Hadoop-based technologies
Knowledge of data warehousing concepts.
Strong sense of ownership, urgency, and drive
Strong troubleshooting and problem solving skills
Experience with Amazon Web Services",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
973,DATA ANALYST,"posted by Mahima Gaur

2 - 5 years Delhi

Job Description
Experience in data processing
Experience in data cleaning and data tabulation activities
Strong analytical, communication and team management skills
Strong understanding of data management using SPSS and research techniques
Competency in a Tabulation software (decipher / wincross / quantum etc), Excel, Powerpoint
Ability to summarize findings, draw conclusions, and put together a presentation using Powerpoint
Role Category : Data Analyst

Employment Type : Permanent Job, Full Time",4.9,"Knowledge Excel Services.
4.9",New Delhi,"New Delhi, India",1 to 50 employees,2007,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
974,Data Engineer,"Key skills : Python , Spark , SQL , Pyspark • AWS platform used for the work • Strong experience in SQL is mandatory • Good familiarity of AWS landscape • Good experience in collecting business requirements & design them as per requirement from customer • Should able to work independently & interact business users & technical stakeholders • Strong communication skills both oral & written. • Should work as an individual resources",3.5,"Larsen & Toubro Infotech Limited
3.5",India,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
975,Big Data Engineer,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
976,Client Data Analyst,"At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.
What is the Client Data Analyst – Client Analytics group responsible for?
This team manages business data to ensure accurate, timely, consistent and compliant data. Their contributions deliver quality data that is easily accessible and can be trusted. Key downstream capabilities such as reporting and analytics depend on this as well as operational data access on various systems. The Data Management Team is a support function that acts as an advocate and a point of contact for Sales and Marketing data.

What are the ongoing responsibilities of an Client Data Analyst ?
Understand the data flow, key consumption and production of data as well as context within the enterprise:
Build positive relationships with teams, especially the key data consumers and analytics. Take the time to increase knowledge of how they run their business and incorporate sales data into daily work
Connect regularly with each sales office to understand current issues and challenges. Probe the business and validate against other sales offices to understand the scope and priority of the issue
Make recommendations on how data unifications and flow can be used to improve business tasks. Liaise business partners to deliver solutions (reports, processes, technology) that add value.

Provide data management subject matter expertise. Appreciate the connection and data flow between applications and other corporate systems. Be able to clearly articulate the data needs and move initiatives forward by collaborating with business partners:
Actively participate in meetings with business partners to ensure that priorities are clearly understood, information is regularly shared and that key participants are “kept in the loop”
Provide context and background on issues. Collaborate on ideas for progressing initiatives. Ensure appropriate resources are involved to take initiatives forward
Provide insights and expertise to scope statements and requirements documentation
Actively consult or participate in the user acceptance testing process (test cases, documentation, testing execution, etc.)
Ensure business needs remain aligned with overall corporate initiatives and deliver the benefits as originally intended

Monitor the integrity of data and usefulness of reports. Ensure the information available within systems is accurate and up-to-date. Proactively seek data cleansing opportunities and evolve data to better support. Document and maintain ongoing processes for reporting and data clean-up:
Partner with all key data consumers to gain a solid understanding of usage and challenges around data. Establish processes for prioritization of enhancements, especially with the analytics groups
Provide 1st level support for data issues and data maintenance for owned data
Verify and execute data loads into our internal sales systems and ensure any upstream systems accurately receive their data

Increase awareness and promote data management capabilities. Share best practices and provide coaching to local offices on how to access and incorporate output into sales tasks. Encourage IAS leaders to leverage data to make more informed, strategic decisions:
Clearly articulate the goals and core services of the data management team. Proactively promote this information within IAS and ensure business partners understand the data management role within the organization
Share best practices and provides guidance on data capabilities. Reinforces ownership and accountability for data accuracy
Seek opportunities to share the benefits of leveraging sales data to make more informed business decisions

What ideal qualifications, skills & experience would help someone to be Successful?

Knowledge, Education And Experience:
Four year bachelor’s degree required (majors of preference include: business, computer science, mathematics) Advanced degree a plus
Understanding of the Franklin Templeton business model, how FT makes money, the sales process, how technology fits in with the business, etc. Knowledge of the GAS (Global Advisory Services) structure
Experience working through multiple business fiscal cycles; exposure and/or direct experience with project management and/or sales-related-capacity required
Prior work experience related to analytics, sales, marketing and/or international a must. Level will not be granted based on years of experience but will be determined by the employee’s ability to meet each job activity as outlined the ‘typical/expected focus by level
Skills And Abilities:
Ability to communicate effectively with all levels of management; ability to tailor communication style based on audience; ability to get others to want to collaborate with you; strong facilitation skills
Excellent writing skills (for presentations, documentation, etc.)
Working knowledge of the CRM, MDM, Excel, SQL, Power BI, Tableau, Business Objects, and Microsoft Products (PPT, Power Apps, Doc, Visio)
Ability to absorb and interpret large quantities of data; apply trend analysis and knowledge of the business to develop a meaningful and digestible summary with the appropriate level of detail
Ability to take a larger problem and break down the individual components; identify how to go about solving the problem and who to involve in the process
Ability to present recommended solutions to a variety of issues and problems (solutions that are consistent with organization objectives)
Must be extremely detail-oriented (managing lists, tasks/to-dos, etc.) good with follow through on own items; good with following up with others on outstanding item

What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.

Highlights of our benefits include:

Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.",3.8,"Franklin Templeton Investments
3.8",Hyderabad,"San Mateo, CA",5001 to 10000 employees,1947,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Fidelity Investments, Vanguard"
977,Data Analyst,"Roles and Responsibilities:
Extracting, transforming and inputting data sets from various resources. Creating predictive models, translating non-technical aspects into quantifiable tasks. Analysis and representation of output data, highlight and explain trends and patterns, error elimination, using advanced statistical methods (regression, probability distribution, clusters etc.) to provide accurate results.
Data collection, Data Mining, Report generation, Problem identification and solution formulation Market analysis and establishing trends, Strategy development and implementation

Skills:
Extremely good analytical skills.
Good working knowledge of all MS-Office products, especially Advance Excel, Word, PowerPoint, MS-access.
Statistical tools and methods.

Interested candidates can send the updated resume on satish.mehra@exelaonline.com or call on 7722028636
00-7.00 Years",2.6,"Exela Technologies
2.6",Pune,"Irving, TX",10000+ employees,2017,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"SourceHOV, BancTec, Transcentra"
978,Data Modeler,"• Minimum 5-8 years of working experience as Data modeler.
• Data modelling experience in designing.
• Minimum 2-3 years real time experience in Erwin tool is mandatory.
• Experience in normalized modeling techniques.
• Experience in designing the Start schema.
• Experience working in ORACLE.
• Experience with database design, capacity planning, performance tuning and query optimization.
• Experience in working with Bank or Banking and Finance or Financial domain.
• Excellent communication skills with leadership quality.

Job Segment:
Database, Oracle, ERP, Technology",3.5,"LTI
3.5",Mumbai,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
979,Machine Learning Engineer,"Looking for Data Scientists with Python/R Programming skills.
Specific experience in AI areas like Statistical Machine learning / Deep learning / Natural Language Processing (NLP)/ Operations Research (Optimization) will be an advantage.Individual in this role is expected to work with multiple stakeholders and teams

Qualifications and Requirements:-
Previous working experience as a Machine Learning/ Data Scientist for 2 years
MA in Computer Science or similar relevant field
Hands on experience with MALLET
In depth knowledge of Apache Tomcat/Open Source
Excellent project and time management skills
Attention to detail
Outstanding problem solving and analytical skills",-1,Tekolutions.ai,India,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
980,Data Science Internship,"About the company:
SkillBit is a leading staffing and recruitment company engaged in talent searching assignments for skilled and talented candidates for the industry.

About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Working on data science algorithms and AI concepts 2. Using Python or R for web scraping 3. Building AI models using Python, machine learning, and deep learning algorithms 4. Processing of unstructured/structured data

Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 6th Jun'20 and 11th Jul'20
are available for duration of 1 month
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply

Number of internships/jobs available: 3

Categories: Data Science",-1,SkillBit,Pune,-1,-1,-1,-1,-1,-1,-1,-1
981,Data Engineer,"As a data engineer at TEAL, you'll be taking the plunge into a rich data lake that includes everything from satellite data to legal court orders. You'll be hustling and getting your hands dirty with every part of the data pipeline always having an implicit appreciation for how all of this data will ultimately power a revolutionary real estate risk platform.

Your day-to-day will include either all or some of the following:

Constantly scoping out new data sources to complement existing ones
Creating and maintaining distributed web scrapers using Python, RabbitMQ and other technologies
Architecting and managing data pipelines where data flows into multiple end-points including, but not limited to, Postgres, MongoDB and Apache Solr
Documenting workflows and constantly iterating to create better data infrastructure.

We'd love it if you:
Are proficient in Python or any other object-oriented language
Have worked with large (millions to hundreds of millions of rows in a SQL database) interdisciplinary datasets
Have scraped difficult websites and have some experience working with various data APIs
Are patient and methodical with unstructured and messy data
Are always hungry to learn newer and better technologies to make the data ecosystem faster, smoother and less silo-ed

Extra brownie points if you:
Have some experience working with large-scale search indexing
Have performed geospatial analyses in some capacity
Have created and managed data lakes in the cloud
Culture

To explore our culture and the values we embody click here

Testimonials
Testimonial

My experience at TEAL surpassed all my expectations from the get-go. I was asked to help solve one of the most daunting problems in the Indian real estate market. Every day while working on a subset of the problem, the ideas that I brought to the table were shaped into cohesive solutions by a collaborative team effort. At TEAL I was exposed to the most cutting edge technologies such as Cloud Computing, Big Data, ML and Data Science. The growth opportunities at TEAL are tremendous, If you are innovative and can demonstrate the will to realize your ideas, TEAL is an amazing organization to work for.
Gyan Vardhan, Data Science Intern
I had interned as a Data Scientist at Terra Economics and Analytics Lab during its early days, it was a rich learning experience working with a multi-disciplinary team who are extremely passionate about building a decision support platform for the insanely complicated realty market in India. It was exciting and challenging to work on mining huge volumes of property records; extracting patterns from the data, building data pipelines and brainstorming on building the core system. TEAL offers a very healthy work environment coupled with insanely talented people working together in an exciting setting.
Naga Anjaneyulu, Data Science Intern
I worked as a full-time Data science intern at TEAL. During this period, I got an opportunity to leverage my skillsets while also learning new technologies, working on tasks assigned to me. The company operates on the latest tech-stacks and gives opportunities to learn as much as you want. The work environment is challenging, the team at TEAL is super supportive and new ideas are always welcome. It has all the good perks of a startup; creativity and innovation, casual work atmosphere and a collaborative approach to solving problems. Personally, I loved working there, my experience was fantastic!
Archana Parmar, Data Science Intern
As a second-year college student, I was looking for an internship that would allow me to delve deeper into research and work with big data, TEAL gave me the perfect opportunity to do so, enabling me to develop proficiency in research and analysis. As a research analyst intern, I collated and cleaned data and helped in the preparation of reports and presentations, and I had members helping me at every stage of this process. This collaborative environment allowed me to cultivate my skills and also learn from my peers. The holy trinity of Rohan, Kshitij, and Shreyas served as not only excellent mentors and bosses but also as friends, helping me at every stage and giving us all food and ice cream to keep us going!
Arush Mehra, Research Intern
Internships are a crucial part of one’s early career. The internship experience at TEAL was a thrilling rollercoaster ride to say the least! It was more than implementing a standard model or building an already though out concept into reality. It was about finding the solution to a unique and open-ended problem.It was exciting to work on addressing a problem with far -reaching real world applications.Moreover, the work environment had the perfect balance of casual yet professional which kept you focused and stress free at the same time. Out of every 100 startups in India only 2 of them succeed, but there are very few like TEAL India which are bound to make it big at such an early stage.
Divyanshu Agarwal, NLP Intern",4.7,"Terra Economics & Analytics Lab (TEAL)
4.7",New Delhi,"Bengaluru, India",1 to 50 employees,2018,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
982,Senior Consultant - ModellingOps Data Engineer,"Job Title: Senior Consultant - ModellingOps Data Engineer
Location: TRIL GTC
GCL: D1

JOB DESCRIPTION:

AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. The Science & Enabling Units IT is AZs global IT capability function supporting key business areas operating out of sites across the US, UK, Sweden, India & Mexico.

We are looking for AI Ops consultant who will leverage tools & technology best practices to improve delivery performance & data engineering capabilities in the D&A space.

ROLES & RESPONSIBILITIES:

7-10 years of experience in IT Operations involving Data Science, Artificial Intelligence-Machine Learning and Predictive Analytics. Experience in architecting and implementation of end-to-end AIOPs solutions through ELK stack, Splunk. Experience in applying statistical methods, analysis, pattern recognition and modeling on IT Operational data using ELK machine learning. Experience in extracting meaning full data from incoming data streams from different sources through RegEx, Grok etc. Hands-on experience in applying machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc in the IT Operation domain. Experience with machine learning and statistical programming languages - Python, R etc. Experience in assessing the existing IT environment and providing recommendations to reduce the critical applications impacting incidents. Experience in exploring and identifying areas where manual tasks can be automated in IT environment. Experience with various Enterprise IT monitoring solutions including Infrastructure monitoring, Application Performance Monitoring, Network Monitoring, Cloud monitoring etc. Experience in IT Service Management including Service Desk, Incident Management, Change Management, CMDB etc. Excellent knowledge on various IT infrastructure components that includes Server Infrastructure, middle ware, database and application architectures and Cloud Components. Experience/knowledge on Infra monitoring tools - NOI, Zabbix, AppDynamics, Datadog, SCOM, SolarWinds etc. and Service Management tools -IBM Control Desk, BMC Remedy, ServiceNow etc. Experience/Knowledge on BI tools Knowledge on distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc. Knowledge on other programming languages/scripting: Python, Java, JavaScript, etc. ( Added Advantage ) Good analytical skills, strong communication skills are must. Client facing experience is an added advantage. Excellent experience in understanding the problem statement, architect and designing the solution

MANDATORY SKILLS:
Significant experience with AWS cloud environments, working knowledge of Google and Azure platforms. Knowledge of Kubernetes, S3, EC2, Sagemaker, Athena, RDS and Glue is essential.
Experience provisioning computational resources in a variety of Cloud environments using Infrastructure as Code.
Experience with best practice of data transport and storage within cloud system.
Experience building large scale data processing pipelines. e. g. Spark and SQL.
Experience with containers and microservice architectures e.g. Kubernetes, Docker and serverless approaches.
Excellent working knowledge in DevOps, using continuous integration and continuous development.
Use of Data Science modelling tools e.g. R, Python, SAS and Data Science notebooks (e.g. Jupyter).
Good written and verbal skills, fluent English
DESIERED SKILLS:
Agile practices, especially being a SCRUM Master
EDUCATIONAL BACKGROUND: B.E/B.Tech/MCA

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",3.9,"AstraZeneca
3.9",Chennai,"Cambridge, United Kingdom",10000+ employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Roche, GlaxoSmithKline, Novartis"
983,DATA ENGINEER,"JOB DESCRIPTION
As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements, and also research new uses for data acquisition. You should also know the ins and outs of the industry such as data mining practices, algorithms, and how data can be used.

DESIRED CANDIDATE PROFILE
An ideal candidate must possess prior experience leading a project.

Candidates must have:
> Experience in Hive, Spark, Scala, AWS DynamoDB, HBase, AWS Glue, Talend, Kafka, Snowflake ETL
> Strong experience in a BI/Data Warehouse environment with involvement in design, development, implementation, troubleshooting and support of ETL process using ETL tool.
> Experience in developing Data Marts, Data warehousing and Operational Data Store (ODS) on any of the databases or Hadoop environments.
> Experience in database like MS SQL, MySQL, Oracle, PostgreSQL
> Good to have programming experience in writing Complex Stored Procedures, Queries, Views, User Defined Functions, Cursors and Common Table Expressions using SQL or T-SQL.
> Experience in Performance Tuning and Query Optimization by Indexing, Partitioning and De-normalization.
> Experience in Developing a framework for ingesting data into Data lake
> Good database knowledge, analytical thinking
> Design, construct, install, test and maintain data management systems.
> Build high-performance algorithms, predictive models, and prototypes.
> Develop set processes for data mining, data modeling, and data production.
> Experience with cloud services: AWS (EC2, EMR, S3, Athena) and scripting languages like Python, /PySpark/R/SAS
> Install/update disaster recovery procedures.
> Experience in Agile Application Development & Scrum methodologies is preferred
> Ability to supervise and mentor junior developers on the team.
> Must be self-motivated and work well pulling people together in addition to being able to pull people together technically
> Demonstrated proficiency of troubleshooting techniques and detail-oriented problem diagnosis
> Ability to handle responsibility, is self-directed, with strong organizational and documentation skills
> Ability to work independently and efficiently under aggressive deadlines to meet project commitments
> Excellent verbal and written communication skills

EDUCATION
UG - B.Tech/B.E. - Computers, Electronics/Telecommunication, Diploma - Computers, Electronics/Telecommunication, B.Sc - Computers, BCA - Computers) AND (PG - M.Tech - Computers, Electronics/Telecommunication, MCA - Computers, M.Sc - Electronics, Computers) AND ( Doctorate - Any Doctorate - Any Specialization, Doctorate Not Required).

OTHER DETAILS
Number of vacancies: 4
Experience: 3 years
Location: Cochin

If you have a passion towards technology and coding, then we have the right job for you. Kindly forward your resumes to
Email: jobs@mjsofttech.com
Phone: 0484-2421245 / 928 720 7160",4.0,"MJ Softtech
4.0",Kochi,"Cochin, India",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
984,Data Engineer,"Education/ Experience and Skill Requirement
4+ years of relevant experience in
Experience working with both relational and NoSQL databases.
Strong coding skills; Python (preferred) /R/Java/Scala
Experience in developing Data warehousing technologies Experience with AWS or equivalent cloud services preferred
Experience in BigData technologies (Hadoop, HDFS, MapReduce, Spark, Hive, HBase etc) will be valuable
Knowledge of Machine Learning a big plus (Random Forest, Decision Trees, SVM, NLP, Gradient Boosting, Supervised/Unsupervised Learning, Clustering, classification and regression modeling).
Responsibilities
Proficiency with several years’ experience in more than one of Python, R, Java, Scala, or robust Linux shell scripting
Implementation experience with data warehouse architecture & design, ETL design/development, and Analytics
Knowledge of general cloud architecture and cloud strategies especially around AWS services and concepts such as S3 object stores, RDS databases, EC2, Glacier, Lambda, IAM, enterprise security, data security, DevOps, replication and disaster recovery
Well versed with data mining & exploration, NLP and visualization
Understanding of data modeling, data integration, and data representation (metadata, OWL, ontologies)
Developing data marts and data management using SQL
Creating powerful visual outcomes
Independently manage daily client communication, especially over calls
Manage client deadlines, ensure quality of the deliverables, attention to detail
Experience/understanding of corporate finance data from company filings is desirable",3.6,"Copal Partners
3.6",Bengaluru,"New York, NY",10000+ employees,1900,Company - Public,Financial Analytics & Research,Finance,₹100 to ₹500 billion (INR),-1
985,Data Engineer,"Job Description / Responsibilities
Build workflows to ensure data extraction quality and storage into our backend data store
Architect, build and train ML/AI models that can predict outcomes and report on anomalies.
Design data pipelines to perform ETL on content/data from multiple types of source systems.
Create data analytics views using RDBMS/Key-Value stores, on private and public/cloud
Create software that is well tested, maintainable, extensible and scales out with large data

Minimum Qualifications:
2+ years of software development with Python
2+ years of SQL (MySQL/Postgres) and Key-Value databases
1+ years of experience with scikit
2+ years of experience in data extraction, data transformation using custom Python/Java
Experience working with MapReduce/Hadoop/kafka/Elastic stack
Experience with Node backend and React/Redux
Experience working with git/mercurial, Amazon/Google cloud, Linux/LAMP stack
Experience in testing or test driven development
Experience with Data science and Machine Learning algorithm development

Location:
Hyderabad/Bangalore

Package:
Highly competitive to match experience and capability",3.7,"TVS
3.7",Bengaluru,"Chennai, India",5001 to 10000 employees,-1,Company - Private,Accounting,Accounting & Legal,₹100 to ₹500 billion (INR),-1
986,Data Engineer,"Permanent position with US based client of iFlex.
Work Location: Bangalore
Experience Level: 2+ Years

Role:
As part of our global team you will work on the data platform reporting to the Data Engineering Lead. Your role includes specification, development, test and rollout of features on our data platform. You are expected to contribute to the vision, understand our product roadmap, integrate business value andclient experience and contribute to build an engineering culture within the team. This initiative is of critical important to the success of the organization and our roadmap, for instance, services like liquidity analytics, billing, client onboarding, reporting and others will rely on the data platform. Accurate, granular, complete and timely data will be our key differentiating factor and competitive advantage in the market place. We expect the successful candidate to deliver high quality software and to be passionate about data engineering..

Responsibility / Qualification:
Managing multiple tasks and use sound judgment when prioritizing.
Collaborating with global cross functional team in building customer-centric products.
Analyzing existing software implementations to identify areas of improvement and provide deadline estimates for implementing new features.
Updating and maintain documentation for team processes, best practices and software runbooks.
Establishing trusted partnerships with peers, product heads, and executive level stakeholders.
We are looking for someone who is passionate about technology and engineering.
Exceptional analytical skills and ability to apply knowledge and experience in decision-making to arrive at creative and commercial solutions.
Ability to leverage technology to deliver business value.
You are independent and comfortable in a fast paced, ambiguous and often multi-directional work environment.

Preferred Qualifications:
B.S. or higher in Computer Science.
Minimum 2 years of relevant professional experience using a modern programming language (preferably Java/Scala).
Experience leveraging test driven development technics.
Comfort with Agile operating models.
Team oriented.
Strong interpersonal and communication skills.
Energetic, self-directed, and self-motivated.
Experience with microservice architecture.
Experience with Kafka, MongoDB, Hadoop, Cassandra.
Experience with AWS.
Experience in Financial Services or Fintech.",-1,IFLEX,Bengaluru,"Moscow, Russia",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
987,CIEL/SEL/1941: Sr data scientist,"Mandatory skills required -
Databases (SQL, Oracle, Any RDBMS) - Should have working knowledge of atleast one database
PL/SQL Programming Languages
R, Python (Any One)
Inferential Statistics - Hypothesis, p-value, R2, RMSE, MAPE etc
Exploratory Data Analysis
Machine Learning Algorithms - Should have in-depth knowledge and implementation of atleast one algorithm

Responsibilities
: Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the why & how of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions

Education
Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics
Experience
Minimum years of related experience required: 3 years
Preferred years of experience: 5 years
Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desirable.

Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
988,Data Engineer,Data Engineer,3.6,"Bookmyshow
3.6",Mumbai,"Mumbai, India",1001 to 5000 employees,2007,Company - Private,Ticket Sales,"Arts, Entertainment & Recreation",Unknown / Non-Applicable,-1
989,Data Analyst,"Required Skills & Experience

We are looking for a Data Analyst Executive
Eligible Qualifications : B. Tech, BCA, M.Tech, MCA
Experience : 3-5 years, fresher’s can also be considered
Location of Job : Gurgaon/Connaught Place, New Delhi
Technicals Skills

Following technical skills are pre-requisite:
Well versed with Software development methodologies, such as SDLC (Software Development Life Cycle), DDLC (Document Development Life Cycle).
Database schema design and implementation
Should have worked in either of technologies Sql Query/ Tableau/ Excel (Macros)/ Access (Query) writing for data analytics.
For planning and coordinating activities, organizations remain in invariant communication with one another and the data transfer has to be performed efficiently and smoothly as possible.
He/ She should manage the execution of the technologies, help the businesses in utilizing the systems, and should be well versed with the basics of computer systems such as Networking, Installation of necessary software and hardware.
Ability to determine the interrelationships between solutions and requirements.
Ability to think analytically and should be a problem solver and logic building should be very strong.
Good interpersonal skills to form effective working relationships with people at all levels.
Excellent communication and presentation skills and strong written & oral English skills.
To know more about us visit us www.sspl.net.in or write to us at admin@sspl.net.in",-1,Substratal Solutions,Connaught Place,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
990,Artificial Intelligence Scientists,"Experience 2- 4 Years
Salary 4 LPA - 6 LPA
Job Location Chennai

Industry:
IT-Software / Software Services

Keywords:
Artificial Intelligence

About Job:
Must have Excellent knowledge in AI / Machine learning (Mandatory).
Machine learning frameworks like keras, tensor flow etc.
And also other big data tools like Hadoop etc, Must know R and python.
Good understanding in SDLC & Business cycle.",4.0,"Careerera
4.0",Chennai,"Wayland, MA",501 to 1000 employees,-1,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
991,Senior Data Engineer,"About Us

upGrad is an online education platform building the careers of tomorrow by offering the most industry-relevant programs in an immersive learning experience. Our mission is to create a new digital-first learning experience to deliver tangible career impact to individuals at scale. upGrad currently offers programs in Data Science, Machine Learning, Product Management, Digital Marketing, and Entrepreneurship, etc. upGrad is looking for people passionate about management and education to help design learning programs for working professionals to stay sharp and stay relevant and help build the careers of tomorrow.
upGrad was awarded the Best Tech for Education by IAMAI for 2018-19
upGrad was also ranked as one of the LinkedIn Top Startups 2018: The 25 most sought-after startups in India
upGrad was earlier selected as one of the top ten most innovative companies in India by FastCompany.
We were also covered by the Financial Times along with other disruptors in Ed-Tech
upGrad is the official education partner for Government of India - Startup India program
Our program with IIIT B has been ranked #1 program in the country in the domain of Artificial Intelligence and Machine Learning
About the Role

We are looking for a Data Engineer to help us scale the existing data infrastructure and in parallel work on building the next generation data platform for analytics at scale, machine learning infrastructure and data validation systems.
In this role, you will be responsible for communicating effectively with data consumers to fine-tune data platform systems (existing or new), taking ownership and delivering high performing systems and data pipelines, and helping the team scale them up, to endure ever growing traffic.
This is a growing team, which makes for many opportunities to be involved directly with product management, development, sales, and support teams. Everybody on the team is passionate about their work and we’re looking for similarly motivated “get stuff done” kind of people to join us!

Roles & Responsibilities
Engineer data pipelines (batch and real-time ) that aids in creation of data-driven products for our platform
Design, develop and maintain a robust and scalable data-warehouse and data lake
Work closely alongside Product managers and data-scientists to bring the various datasets together and cater to our business intelligence and analytics use-cases
Design and develop solutions using data science techniques ranging from statistics, algorithms to machine learning
Perform hands-on devops work to keep the Data platform secure and reliable
Skills Required
Bachelor's degree in Computer Science, Information Systems, or related engineering discipline
6 + years’ experience with ETL, Data Mining, Data Modeling, and working with large-scale datasets
6+ years’ experience with an object-oriented programming language such as Python, Scala, Java, etc
Extremely proficient in writing performant SQL working with large data volumes
Experience with map-reduce, Spark, Kafka, Presto, and the ecosystem.
Experience in building automated analytical systems utilizing large data sets.
Experience with designing, scaling and optimizing cloud based data warehouses (like AWS Redshift) and data lakes
Familiarity with AWS technologies preferred
Qualification – B.Tech/M.Tech/MCA(IT/Computer Science)

Years of Exp – 6-9",3.5,"upGrad Education Private Limited
3.5",Mumbai,"Mumbai, India",501 to 1000 employees,2015,Company - Private,Education Training Services,Education,₹1 to ₹5 billion (INR),"Udacity, General Assembly, Springboard"
992,BBRC-Genomics-Associate Scientist,"JOB DESCRIPTION

Designation: Associate Scientist

Job Location: Bangalore

Department: Translational Medicine- Translational Sciences

About Syngene

Incorporated in 1993, Syngene International Ltd. is an innovation-focused global discovery, development and manufacturing organization providing integrated scientific services to the pharmaceutical, biotechnology, nutrition, animal health, consumer goods and specialty chemical industries around the world. Syngene’ s clientele includes world leaders such as Bristol-Myers Squibb, Baxter, Amgen, GSK, Merck KGaA and Herbalife. Its innovative culture is driven by the passion of its 4240- strong team of scientists who work with clients from around the world to solve their scientific problems, improve R&D productivity, speed up time to market and lower the cost of innovation .

Job Purpose:
To play a key role in TM-TS, develop an early-stage research strategy, initiate and lead discovery programs while managing ongoing programs in TM-TS. The role will work part of TMTS, and work with internal and external collaborators .

Key Responsibilities:
Experience in isolating DNA and RNA from blood, tissues and FFPE samples and cell lines. Experience with optimization of extraction protocols and for parameters like yield, input sample quantities and sample types is important.
Expertise in PCR, qPCR, cDNA/gDNA library preparation. Exposure to microarray techniques.
Proficiency in preparation of libraries for Next Generation Sequencing of transcriptome and genome, with significant experience in optimization of parameters like input RNA/DNA quantities and sample type
Experience with single cell RNA-seq will be plus.
Experience with various NGS protocols (DNA Amplicon based, hybrid capture based low input, degraded DNA and RNA samples e.g. FFPE samples.
Strong understanding of experimental design and statistical principles behind experimental design and differential gene expression. Experience with analysis of single cell RNA-sequencing data will be a plus

Educational Qualification:
M.Sc or M. Tech in Biotechnology, Molecular biology or Biological Sciences,

Technical/functional Skills:
DNA/ RNA Isolation, Expertise in PCR, qPCR, Experience in NGS protocols

Experience:
2 to 5 Years

Behavioral Skills:
A proactive team player.
Ensure completion of experiments and generate accurate and reproducible data from experiments.
Ability to work independently, prioritize tasks and work on multiple projects simultaneously with; comfortable working in a dynamic environment with changing requirements.
Good oral and written communication and presentation skills to work in a multi-disciplinary team
Equal Opportunity Employer:
It is the policy of Syngene to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by applicable legislation or local law. In addition, Syngene will provide reasonable accommodations for qualified individuals with disabilities.",3.5,"Syngene
3.5",India,"BENGALURU, India",1001 to 5000 employees,1994,Unknown,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
993,Applied Scientist 1,"Position Requirements:
Master's degree in Computer Science, Computer or Electrical Engineer, Mathematics, or a related field plus at least one year of experience in the job offered or related occupations of Software Engineer, Software Developer, or a related occupation. Employer will accept a Bachelor’s degree and five years of experience in the job offered or a related occupation as equivalent to the Master’s degree and one year of experience. One year of experience in the job offered or related occupation must involve designing and developing large-scale, multi-tiered, distributed software applications, tools, systems and services using Java, Object Oriented Design and Distributed Programming].

Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, Oracle/Berkeley databases, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills

Amazon Selling Partner Services team drives the Selling On Amazon business and develops solutions that enable millions of sellers around the world to sell on Amazon's Marketplaces. More than half of shipments for Amazon customers are generated from this business. The team is focused on building a technology platform that will support the explosive business growth in existing markets, streamline the business for Amazon and the Selling partners and launch business in new markets and establish a fair marketplace.

Our team is seeking engineers with broad technical skills to help us optimize how we synthesize massive amounts of data and complex business rules into mission critical financial information. As a member of this team you will employ object oriented techniques in Java, and DynamoB, PostGres and ElasticSearch skills to help us support Amazon's next generation of selling partner services. Along the way you'll gain and leverage a unique understanding of how Amazon.com works; from the numerous software systems that comprise the website's back-end, to the details of our business model, and the relationships we're establishing with an ever-growing network of selling partners who depend on Amazon.com to run their businesses.

The ideal candidate will draw upon exemplary analytical, critical thinking, and problem solving skills, and a passion for maintaining highly reliable, distributed systems which operate 24/7/365. Successful members of this team collaborate effectively with internal end-users, aggressive cross-functional software development teams, and technical support/sustaining engineering teams to solve problems and deliver successfully against high operational standards of system availability and reliability. We look for engineers who are excellent communicators, self-motivated, flexible, hardworking, and who like to have fun!

Position Responsibilities:
Participate in the design, development, implementation, testing and documentation of large-scale, multi-tiered, distributed software applications, tools, systems and services using [Java, Object Oriented Design and Distributed Programming]. Translate functional requirements into robust, scalable, supportable solutions that work well within the overall system architecture. Participate in the full development cycle, end-to-end, from design, implementation, and testing to documentation, delivery and maintenance. Produce comprehensive, usable software documentation. Evaluate and make decisions around the use of new or existing software products and tools.

Preferred Qualifications
Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
994,Senior Clinical Data Analyst,"About Novotech:

Novotech is internationally recognised as the leading independent and full-service contract research organisation (CRO) in the Asia Pacific region. We provide a wide range of clinical development services across all research phases and therapeutic areas and have been instrumental in the success of hundreds of Phase I – IV clinical trials throughout the Asia Pacific. Powered by the highest quality people, Novotech strives to set the benchmark for both business and clinical trial performance. Our people are one of our key strengths. We value our people and recognise the work they do. We are lucky to have the best people and talent from across the Asia Pacific region work together to deliver to clinical trial success for our clients. Our people and those we look to recruit have an attitude of making things happen. They are problem solvers, driven with a focus on delivering quality, accountability and a high level of performance.

Brief Position Description:

As part of Novotech’s Biometrics unit, the Senior Data Analyst (SDA) is responsible for all data analysis and business intelligence activities related to study related clinical and operational data. The SDA acts as primary point of contact for all data analysis matters to the study team and is responsible for the timely delivery of quality outputs following all applicable regulatory, compliance, best practice and operational procedures.

Minimum Qualifications & Experience:

Graduate in information science, data science or life science-related field, or similar. More than five years’ experience in a senior role related to data science, data analysis, clinical data management or clinical data programming in a pharmaceutical company, CRO or EDC software provider.

Responsibilities
The Senior Data Analyst (SDA) is responsible for providing technical, procedural (SOPs) and planning leadership across multiple projects assigned to the data analyst team members ensuring that they deliver in accordance with SOPs, programming best practices, and the timelines agreed within the Project Team.
Collaborate with cross-functional stakeholders to implement data science solutions to solve business needs using available technological solutions.
Scope data analysis effort for projects and project manage all data analysis activities across multiple projects for different study stakeholders.
Gather study requirements from data management for data review and external data reconciliation and provide guidance on appropriate outputs (dashboards, visualisations, listings, reports).
Extract, assess, integrate, transform data sources to provide data visualisation outputs for analytics.
Design and develop prototypes and final versions of data outputs (dashboards, reports, visualisations, listings) using Business intelligence tools and Data Visualisation tools.
Design and develop standard dashboards and content for different audiences.
Analyse, manipulate and understand data from multiple sources to present and create dashboards and reports to make business decisions.
Assist teams on best-practice for data visualisation dashboard development.
Educate teams on how to use all the features of applicable data visualisation platform in conjunction with data visualisation dashboards.
SME for the data visualisation development and assisting team members.
Identify and communicate project risks and maintain documentation within project files as appropriate
Represent data analysis group at internal / external meetings as appropriate.
Assess and implement new data analysis, BI and data visualisation processes and technologies.
Take an active role in the development of best practices, process improvement, quality control and governance related to all data analysis matters.
Provide training and mentoring to Data Analysis of team members in SOPs, software applications, and best practices.
Provide Subject Matter Expertise on all data analysis and visualisation related activities.
Attributes and Skills

Expert knowledge of clinical study data structures and schemas of EDC databases. Expert knowledge in data processing activities such as extracting, integrating, transforming and presenting data. Statistical Programming skills in Python, R or similar. Knowledge of SQL and EDC systems. Working knowledge of Spotfire, Power BI, Tableau or other data review and visualisation tool. Ability to gather business requirements from multiple stakeholders and clients and provide guidance on the use of appropriate data visualisations.

Experience mentoring and training others. Awareness of regulatory and compliance issues and understanding of the application of SOPs and Quality Control to daily activities. Excellent analytical, communication and problem-solving skills.

Opportunities and Benefits:

To deliver clinical trial and research excellence for our clients, our people are 'best in class'.

At Novotech, we seek and nurture people with exceptional talent. We are committed to providing our people with regular internal and external training, a competitive bonus structure and a supportive work environment. We are also focused on providing our people with a wide variety of career growth and development opportunities.

For more information about where your next career step at Novotech might take you, visit http://novotech-cro.com/novotech-careers",4.5,"Novotech
4.5",Bengaluru,"Sydney, Australia",501 to 1000 employees,1996,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
995,Data Engineer,"Data Engineer Responsibilities:
Liaising with coworkers and clients to elucidate the requirements for each task.
Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed.
Reformulating existing frameworks to optimize their functioning.
Testing such structures to ensure that they are fit for use.
Preparing raw data for manipulation by Data Scientists.
Detecting and correcting errors in your work.
Ensuring that your work remains backed up and readily accessible to relevant coworkers.
Remaining up-to-date with industry standards and technological advancements that will improve the quality of your outputs.
Data Engineer Requirements:
Bachelor's degree in Data Engineering, Big Data Analytics, Computer Engineering, or related field.
Master's degree in a relevant field is advantageous.
Proven experience as a Data Engineer, Software Developer, or similar.
Expert proficiency in Python, C++, Java, R, and SQL.
Familiarity with Hadoop or suitable equivalent.
Excellent analytical and problem-solving skills.
A knack for independent and group work.
Scrupulous approach to duties.
Capacity to successfully manage a pipeline of duties with minimal supervision.
Job Type: Full-time

Salary: ₹360,000.00 to ₹870,000.00 /year

Experience:
total work: 2 years (Preferred)
Data Engineer: 1 year (Preferred)
Education:
Diploma (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,Futurious Technologies,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
996,Quantitative Analyst,"The successful candidate will be a highly analytical individual with hands on programming skills. The candidate will work closely with the research team and clients towards the ongoing development and integration of new investment strategies, models and tools on Axle

Location

Mumbai
Responsibilities

Perform daily/weekly/monthly tasks of performance and risk reporting
Develop and automate investment processes and strategies via VBA and Matlab
Develop tools to integrate trading decision systems with risk management systems
Ad hoc tasks (such as operational tasks, internal documentation tasks and preparation of marketing materials)
Skills/Experience

Excellent programming skills in Matlab/Excel-VBA
Thorough with financial concepts and calculations like Drawdown, VaR, Eloss etc.
Understanding of financial market products like options, futures, FX forwards etc.
Working knowledge of Bloomberg is preferred
Should be self-driven and detail oriented with an analytical mindset
Should be a proactive and quick learner; a team player showing enthusiasm and drive to accomplish results in a fast paced environment
Min. 2 years of relevant work experience
Qualifications

B.Tech/M.Tech/MBA/CFA/FRM",5.0,"B&B Analytics
5.0",Mumbai,"Zug, Switzerland",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
997,Analyst - Data Scientist,"Job Summary

Experience:
3 - 5 Years

Location:
Mumbai

Designation:
Analyst - Data Scientist

Degree:
BE-Comp/IT, BE-Other, BTech-Comp/IT, BTech-Other, ME-Comp/IT, ME-Other, MTech-Comp/IT, MTech-Other, PhD-Comp/IT, PhD-Other

Educational Level:
Graduate/Bachelors

Industrial Type:
IT-Software/Software Services

Functional Area:
IT Software - Application Programming / Maintenance

Key Skills:
Data Scientist

Job Post Date:
Thursday, March 19, 2020

Company Description

We are capability centre based in Mumbai, initially started as a back-office operational support to the UK business unit.

However, over the recent years, we have significantly increased the breadth and depth of our capabilities and offerings to keep pace with the changing needs of the Group. These include Digital & Knowledge Services, Finance and Actuarial, Information Technology (IT), Customer Service, Risk and Audit.

Our core purpose is to be a strategic partner to company, enabling growth by delivering change and driving synergies through a highly capable and agile workforce.

With our diversified service offerings we provide our people with exciting opportunities to grow personally and professionally.

Company is a leading savings and investments business serving around 5.5 million retail customers and more than 800 institutional clients.

It-s innovative asset management and customer solutions are supported by extensive investment capabilities, an international distribution network and two strong brands.

Job Description

3 – 5 yrs experience as Data Scientist
Should have at-least 1 end-to-end ML project experience
Very high proficiency in R or Python
Excellent in forecasting methods like simple exponential smoothing, multiplicative seasonal indexes, simple and weighted moving averages and time series forecasting methods
Exposure to with advanced deep learning techniques such as LSTM. CNN, Dense neural networks as well as neural networks design and implementation through tools like tensorflow, keras, pytorch, deepai or equivalent.
Good SQL experience",3.8,"Sampoorna Computer People
3.8",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
998,Data Lake Developer,"For Us, It's A Mission

At Mylan, we mean it when we say we work every day to provide access to high quality medicines to the world's 7 billion people. If you are unconventional, relentless and passionate. If you believe in doing what's right, not what's easy. If you are a doer and have a passion for serving others, we want to talk to you.

Make a Difference

At Mylan, each person has the ability to make a difference. From the providers who sell and market our products, to the producers who develop and manufacture them and finally to our business partners who support the providers and producers, we all have a mission critical role. Here's how this role will help:

ESSENTIAL DUTIES AND RESPONSIBILITIES
To perform this job successfully, an individual must satisfactorily perform each essential duty. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential duties.
1. Create and maintain optimal data pipeline architecture on Azure platform.
2. Develop batch processing solutions by using Data Factory and Azure Databricks.
3. Delivering a Data Warehouse in the Azure Cloud.
4. Design relational and non-relational data stores on Azure.
5. Identify, design, and implement internal process improvements : automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc..
6. Developing Big Data Solutions with Azure Machine Learning.
7. Strong interaction with business departments to provide consultative support for digitization efforts, as well as close collaboration with the Business Technology management, focused on future innovation topics.
8. Participate and lead in design sessions, demos and prototype sessions, testing and training workshops with business users and other IT colleagues.
9. Design & Build for any API Development or SQL DB development.
10. Providing service management, orchestration, monitoring and management requirements of Azure cloud platform.
11. Create data tools / products for analytics and data scientist team members that assist them in building and innovative solutions that drive tangible business value.
12. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
13. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
14. Design security for source data access. Chose the appropriate authentication mechanism, (ie Azure Active Directory (Azure AD), etc).
15. Design for real-time processing by using Stream Analytics and Azure Databricks.

Make Our Values Your Values

Mylan hires only the best. People who thrive in a culture of innovation and empowerment. People who are active learners and have a positive attitude. People who are leaders and know that by working together we can run faster, reach higher and achieve more. By doing so, we will continue to set new standards in health care. Here are the minimum qualifications and essential functions for this position:

QUALIFICATIONS

The qualifications listed below are representative of the minimum knowledge, skill, and/or ability required.

SKILLS AND ABILITIES

1. 10 years of experience in Microsoft technologies including SQL.

2. At least 5 years as a Sr Developer with at least 3 years hands on experience as Azure Data Engineer building large scale Azure data solutions.

3. At least 5 years of experience in Azure based data solutions.

4. At least 3 years of experience on working with large projects including the most recent project in the cloud (Azure) or on prem with a focus on Azure Data services.

5. At least 5 years of Hands-on administration, configuration management, monitoring, performance tuning of Hadoop/Distributed platforms.

6. At least 5 years of demonstrated experience at least in the most recent 2 years of designing and delivering solutions using Cortana Intelligence suite of analytics services part of Microsoft Azure including Azure Machine Learning Studio, HDInsight, Polybase, Azure Data Lake Analytics, Azure Data Warehouse, Streaming Analytics, Data Catalog, R/R Studio

7. Experience in designing and building logics required for optimal extraction, transformation, and loading of data from a wide variety of data sources

8. Experience within Data Security design, including but not limited to:

a. Choosing the appropriate authentication mechanism, such as Azure Active Directory (Azure AD)

b. Defining strategies for data encryption for data at rest and in transit

9. Experience partnering with Business Analysts and Data Scientists to enable effective and efficient data preparation and delivery

10. Experienced in vendor management and working with 3rd parties onshore & offshore.

11. Experience working in a global team.

12. Experience working in an Analytics / Big Data solutions on MS Azure Cloud

13. Experience with code management tools, automated testing

14. Experience creating and maintaining optimal data pipeline architecture on Azure platform

15. Experience developing batch and real-time processing solutions by using Data Factory and Azure Databricks

16. Familiar with AGILE and Azure DevOps methodology

17. Hands on PoC capabilities are needed to prove a particular architecture concept

18. Azure Native Services experience across Data Fabric and Service Fabric

19. Experience in Application modernization from legacy on-premise data architecture platform technology stack to modernized Azure Cloud base Architecture.

20. Experience with Git, NoSQL Data Solutions, Microsoft Azure, HD Insights, Azure ML, DataBricks ML Flow, R or Python.

21. Must have excellent communication skills.

EDUCATION/EXPERIENCE (Note: Please select one)

Minimum of a Bachelor's degree in Computer Science and Engineering is preferred with minimum 10 years of experience. However, a combination of experience and/or education will be taken into consideration

Why Mylan?

If you want to be part of a global health care company that is making a difference and changing lives, Mylan may be the place for you. With a workforce of more than 35,000 worldwide, we can make a difference. We encourage you to visit Mylan.com to learn more about our unconventional culture, our approach to doing business and how we plan to set new standards in health care.

Mylan offers competitive salary, excellent benefits and an environment conducive to professional growth and advancement. All qualified applicants will receive consideration for employment without regard to their disability or protected veteran status. Mylan is an Equal Opportunity Employer, Minorities/Female/Disabled/Veteran.",3.8,"Mylan Inc.
3.8",Bengaluru,"Hatfield, United Kingdom",10000+ employees,1961,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
999,Off Campus Recruitment - Quantitative Researcher,"Description:
Graviton is a privately funded quantitative trading firm striving for excellence in financial markets' research. We are seeking fresh talent from the top IIT's to join us as Quantitative Researchers for our team in Gurgaon.If you are a student graduating in 2020 from Computer Science , Electrical or Maths Stats Computing streams with a greater than 8 CGPA please apply here.

This role is open to students from campuses that we could not visit this year. Please check your individual placement policy restrictions before applying.

Graviton trades across a multitude of asset classes and trading venues using a gamut of concepts and techniques ranging from time series analysis, filtering, classification, stochastic models, pattern recognition to statistical inference analysing terabytes of data to come up with ideas to identify pricing anomalies in financial markets.

As a Quantitative researcher your responsibilities will include

Develop new or improve existing trading models using in-house platforms

Use advanced mathematical techniques to model and predict market movements

Analyse large financial datasets to identify trading opportunities

Provide real time analytical support to experienced traders

Requirements :
Possess a degree in a highly analytical field, such as Engineering, Mathematics, Computer Science from IITs schools

Quantitative bend of mind

A working knowledge of Linux/Unix

Programming experience, preferably in C++ or C

Strong interest in learning about financial markets.

Have a strong work ethic

Hard Working

Benefits:
Our open and casual work culture gives you the space to innovate and deliver. Our cubicle free offices , disdain for bureaucracy and insistence to hire the very best creates a melting pot for great ideas and technology innovations. Everyone on the team is approachable, there is nothing better than working with friends!

Our perks have you covered.

Competitive compensation

6 weeks of paid vacation

Monthly after work parties

Catered breakfast and lunch

Fully stocked kitchen

Gym membership

International team outing",5.0,"Graviton Research Capital LLP
5.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2014,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1000,Data Engineer,"Zauba Technologies is a startup based in Bangalore. Zauba's services are used by leading companies in India. Zauba is powered by a young and passionate team. We are looking for individuals who would like to be a part of our founding team.

As a Data Engineer and as a part of founding team, you will be expected to visualise and develop disruptive data products. Eventually you would be responsible for entire project lifecycle of products you would visualize. Your rewards will be directly proportional to the value you generate.

Job Responsibilities
Design and development of robust, scalable and highly efficient data engineering solutions for structured and unstructured data (Including gathering and processing raw data at scale, writing scripts, web scraping, calling APIs, writing SQL queries, etc.)
Develop processes for text mining and extraction of information from unstructured data
Design, architect and develop efficient data pipelines around the data collected
Take ownership of existing web product and applications
Design and implement data models that scale across the enterprise
Take ownership of existing data workflows and processes
Enhance scalability, performance, and stability of existing infrastructure
Work closely with other team members to integrate your innovations and algorithms into our production systems

Essentials
Java/Python - Intermediate to advanced level
SQL - Advanced
MySQL Intermediate to advanced level
Regex - Basic to intermediate level
Linux Basic to intermediate level

Good to have
Hadoop/Spark
R
MongoDB

Must have qualities
Skills to learn new skills quickly
Desire to create disruptive products and services
Passion - not just to work in startups but to take them to next level
Above average programming aptitude
Be passionate about producing high quality engineering deliverables
Be productive working independently or collaboratively
Have an eye for building efficient processes
Be self motivated
Proactively take ownership

Interested?

Send your resume to hr@zaubacorp.com",3.8,"Zauba Corp
3.8",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 million (INR),-1
1001,Quantitative Research,"We are looking for highly trained professionals who are interested in applying advanced mathematical quantitative methods to the modeling of global financial markets. You would be joining a group made up of highly proficient individuals from various scientific disciplines. We have a spectrum of opportunities for individuals with the right scientific skills. Experience in finance is not required.

The ideal research candidate will have:
A Ph.D. in Computer Science, Mathematics, Physics, Statistics, or a related technical discipline.

A demonstrated capacity to do first-class research.

Computer programming skills.

An intense interest in applying quantitative analysis to solve difficult problems.

Send us a copy of your resume to
careers@dolatcapital.com

For internship opportunities, please send us a copy of your resume to
careers@dolatcapital.com",4.0,"Dolat Capital
4.0",Mumbai,"Mumbai, India",51 to 200 employees,1970,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1002,Data Engineer,"Bachelor’s degree in Computer Science or related field
5+ years relevant experience
5+ years experience with SQL, SQL Tuning, Oracle, OLAP, Big Data Technologies
5+ years experience developing end-to-end Business Intelligence solutions: data modeling, ETL and reporting
Experience with Java and experience with scripting languages like Perl, Python, Unix shell scripts,VBA and MS Excel
Proficiency with Linux and systems administration
Proven ability at looking at solutions in unconventional ways. Sees opportunities to innovate and can lead the way.
Top notch communication (verbal and written) and interpersonal skills to convey key insights from complex analysis in summarized business terms and an ability to effectively communicate with technical teams.
Ability to work with shifting deadlines in a fast paced environment.
Operations Finance Technology team, responsible for building technical solutions for multi-billion WW Operational Cost analytic including Inbound cost (Receiving / PO), variable Cost, fixed cost, outbound (Customer Shipments / Transportation), and Customer Service, is looking for a Data Engineer.

As a data engineer, you will get the exciting opportunity to work on very large data sets in one of the world's largest and most complex data warehouse environments. You will work closely with the business teams in analysis on various cost savings initiatives, many non-standard and unique business problems and use creative-problem solving to deliver actionable output.
You will be responsible for designing and implementing an analytical environment using third-party and in-house reporting tools, modeling metadata, building reports and dashboards. You will have an opportunity to work with leading edge technologies like Redshift, Hadoop/Hive/Pig. You will be writing scalable queries and tuning performance on queries running over billion of rows of data.

You should be analytical, have an extremely high level of customer focus and a passion for process improvement. You should be motivated self-starter that can work independently in a fast paced, ambiguous environment. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions.
Bachelors in Computer Science or related field
Practical Knowledge of Linux or Unix shell scripting
Experience in working with business customers to drive requirements analysis
Exposure to large databases, BI applications, data quality and performance tuning
Excellent written and spoken communication skills
Experience with Hadoop-based technologies such as HBase, Pig, Hive and Spark
Strong proven ability in building high-performance, highly available and scalable data solutions using Oracle and/or Hadoop-based technologies
Knowledge of data warehousing concepts.
Strong sense of ownership, urgency, and drive
Strong troubleshooting and problem solving skills
Experience with Amazon Web Services",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1003,DATA ANALYST,"posted by Mahima Gaur

2 - 5 years Delhi

Job Description
Experience in data processing
Experience in data cleaning and data tabulation activities
Strong analytical, communication and team management skills
Strong understanding of data management using SPSS and research techniques
Competency in a Tabulation software (decipher / wincross / quantum etc), Excel, Powerpoint
Ability to summarize findings, draw conclusions, and put together a presentation using Powerpoint
Role Category : Data Analyst

Employment Type : Permanent Job, Full Time",4.9,"Knowledge Excel Services.
4.9",New Delhi,"New Delhi, India",1 to 50 employees,2007,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
1004,Data Engineer,"Key skills : Python , Spark , SQL , Pyspark • AWS platform used for the work • Strong experience in SQL is mandatory • Good familiarity of AWS landscape • Good experience in collecting business requirements & design them as per requirement from customer • Should able to work independently & interact business users & technical stakeholders • Strong communication skills both oral & written. • Should work as an individual resources",3.5,"Larsen & Toubro Infotech Limited
3.5",India,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1005,Big Data Engineer,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
1006,Client Data Analyst,"At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.
What is the Client Data Analyst – Client Analytics group responsible for?
This team manages business data to ensure accurate, timely, consistent and compliant data. Their contributions deliver quality data that is easily accessible and can be trusted. Key downstream capabilities such as reporting and analytics depend on this as well as operational data access on various systems. The Data Management Team is a support function that acts as an advocate and a point of contact for Sales and Marketing data.

What are the ongoing responsibilities of an Client Data Analyst ?
Understand the data flow, key consumption and production of data as well as context within the enterprise:
Build positive relationships with teams, especially the key data consumers and analytics. Take the time to increase knowledge of how they run their business and incorporate sales data into daily work
Connect regularly with each sales office to understand current issues and challenges. Probe the business and validate against other sales offices to understand the scope and priority of the issue
Make recommendations on how data unifications and flow can be used to improve business tasks. Liaise business partners to deliver solutions (reports, processes, technology) that add value.

Provide data management subject matter expertise. Appreciate the connection and data flow between applications and other corporate systems. Be able to clearly articulate the data needs and move initiatives forward by collaborating with business partners:
Actively participate in meetings with business partners to ensure that priorities are clearly understood, information is regularly shared and that key participants are “kept in the loop”
Provide context and background on issues. Collaborate on ideas for progressing initiatives. Ensure appropriate resources are involved to take initiatives forward
Provide insights and expertise to scope statements and requirements documentation
Actively consult or participate in the user acceptance testing process (test cases, documentation, testing execution, etc.)
Ensure business needs remain aligned with overall corporate initiatives and deliver the benefits as originally intended

Monitor the integrity of data and usefulness of reports. Ensure the information available within systems is accurate and up-to-date. Proactively seek data cleansing opportunities and evolve data to better support. Document and maintain ongoing processes for reporting and data clean-up:
Partner with all key data consumers to gain a solid understanding of usage and challenges around data. Establish processes for prioritization of enhancements, especially with the analytics groups
Provide 1st level support for data issues and data maintenance for owned data
Verify and execute data loads into our internal sales systems and ensure any upstream systems accurately receive their data

Increase awareness and promote data management capabilities. Share best practices and provide coaching to local offices on how to access and incorporate output into sales tasks. Encourage IAS leaders to leverage data to make more informed, strategic decisions:
Clearly articulate the goals and core services of the data management team. Proactively promote this information within IAS and ensure business partners understand the data management role within the organization
Share best practices and provides guidance on data capabilities. Reinforces ownership and accountability for data accuracy
Seek opportunities to share the benefits of leveraging sales data to make more informed business decisions

What ideal qualifications, skills & experience would help someone to be Successful?

Knowledge, Education And Experience:
Four year bachelor’s degree required (majors of preference include: business, computer science, mathematics) Advanced degree a plus
Understanding of the Franklin Templeton business model, how FT makes money, the sales process, how technology fits in with the business, etc. Knowledge of the GAS (Global Advisory Services) structure
Experience working through multiple business fiscal cycles; exposure and/or direct experience with project management and/or sales-related-capacity required
Prior work experience related to analytics, sales, marketing and/or international a must. Level will not be granted based on years of experience but will be determined by the employee’s ability to meet each job activity as outlined the ‘typical/expected focus by level
Skills And Abilities:
Ability to communicate effectively with all levels of management; ability to tailor communication style based on audience; ability to get others to want to collaborate with you; strong facilitation skills
Excellent writing skills (for presentations, documentation, etc.)
Working knowledge of the CRM, MDM, Excel, SQL, Power BI, Tableau, Business Objects, and Microsoft Products (PPT, Power Apps, Doc, Visio)
Ability to absorb and interpret large quantities of data; apply trend analysis and knowledge of the business to develop a meaningful and digestible summary with the appropriate level of detail
Ability to take a larger problem and break down the individual components; identify how to go about solving the problem and who to involve in the process
Ability to present recommended solutions to a variety of issues and problems (solutions that are consistent with organization objectives)
Must be extremely detail-oriented (managing lists, tasks/to-dos, etc.) good with follow through on own items; good with following up with others on outstanding item

What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.

Highlights of our benefits include:

Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.",3.8,"Franklin Templeton Investments
3.8",Hyderabad,"San Mateo, CA",5001 to 10000 employees,1947,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Fidelity Investments, Vanguard"
1007,Data Analyst,"Roles and Responsibilities:
Extracting, transforming and inputting data sets from various resources. Creating predictive models, translating non-technical aspects into quantifiable tasks. Analysis and representation of output data, highlight and explain trends and patterns, error elimination, using advanced statistical methods (regression, probability distribution, clusters etc.) to provide accurate results.
Data collection, Data Mining, Report generation, Problem identification and solution formulation Market analysis and establishing trends, Strategy development and implementation

Skills:
Extremely good analytical skills.
Good working knowledge of all MS-Office products, especially Advance Excel, Word, PowerPoint, MS-access.
Statistical tools and methods.

Interested candidates can send the updated resume on satish.mehra@exelaonline.com or call on 7722028636
00-7.00 Years",2.6,"Exela Technologies
2.6",Pune,"Irving, TX",10000+ employees,2017,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"SourceHOV, BancTec, Transcentra"
1008,Data Modeler,"• Minimum 5-8 years of working experience as Data modeler.
• Data modelling experience in designing.
• Minimum 2-3 years real time experience in Erwin tool is mandatory.
• Experience in normalized modeling techniques.
• Experience in designing the Start schema.
• Experience working in ORACLE.
• Experience with database design, capacity planning, performance tuning and query optimization.
• Experience in working with Bank or Banking and Finance or Financial domain.
• Excellent communication skills with leadership quality.

Job Segment:
Database, Oracle, ERP, Technology",3.5,"LTI
3.5",Mumbai,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1009,Machine Learning Engineer,"Looking for Data Scientists with Python/R Programming skills.
Specific experience in AI areas like Statistical Machine learning / Deep learning / Natural Language Processing (NLP)/ Operations Research (Optimization) will be an advantage.Individual in this role is expected to work with multiple stakeholders and teams

Qualifications and Requirements:-
Previous working experience as a Machine Learning/ Data Scientist for 2 years
MA in Computer Science or similar relevant field
Hands on experience with MALLET
In depth knowledge of Apache Tomcat/Open Source
Excellent project and time management skills
Attention to detail
Outstanding problem solving and analytical skills",-1,Tekolutions.ai,India,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1010,Data Science Internship,"About the company:
SkillBit is a leading staffing and recruitment company engaged in talent searching assignments for skilled and talented candidates for the industry.

About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Working on data science algorithms and AI concepts 2. Using Python or R for web scraping 3. Building AI models using Python, machine learning, and deep learning algorithms 4. Processing of unstructured/structured data

Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 6th Jun'20 and 11th Jul'20
are available for duration of 1 month
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply

Number of internships/jobs available: 3

Categories: Data Science",-1,SkillBit,Pune,-1,-1,-1,-1,-1,-1,-1,-1
1011,Data Engineer,"As a data engineer at TEAL, you'll be taking the plunge into a rich data lake that includes everything from satellite data to legal court orders. You'll be hustling and getting your hands dirty with every part of the data pipeline always having an implicit appreciation for how all of this data will ultimately power a revolutionary real estate risk platform.

Your day-to-day will include either all or some of the following:

Constantly scoping out new data sources to complement existing ones
Creating and maintaining distributed web scrapers using Python, RabbitMQ and other technologies
Architecting and managing data pipelines where data flows into multiple end-points including, but not limited to, Postgres, MongoDB and Apache Solr
Documenting workflows and constantly iterating to create better data infrastructure.

We'd love it if you:
Are proficient in Python or any other object-oriented language
Have worked with large (millions to hundreds of millions of rows in a SQL database) interdisciplinary datasets
Have scraped difficult websites and have some experience working with various data APIs
Are patient and methodical with unstructured and messy data
Are always hungry to learn newer and better technologies to make the data ecosystem faster, smoother and less silo-ed

Extra brownie points if you:
Have some experience working with large-scale search indexing
Have performed geospatial analyses in some capacity
Have created and managed data lakes in the cloud
Culture

To explore our culture and the values we embody click here

Testimonials
Testimonial

My experience at TEAL surpassed all my expectations from the get-go. I was asked to help solve one of the most daunting problems in the Indian real estate market. Every day while working on a subset of the problem, the ideas that I brought to the table were shaped into cohesive solutions by a collaborative team effort. At TEAL I was exposed to the most cutting edge technologies such as Cloud Computing, Big Data, ML and Data Science. The growth opportunities at TEAL are tremendous, If you are innovative and can demonstrate the will to realize your ideas, TEAL is an amazing organization to work for.
Gyan Vardhan, Data Science Intern
I had interned as a Data Scientist at Terra Economics and Analytics Lab during its early days, it was a rich learning experience working with a multi-disciplinary team who are extremely passionate about building a decision support platform for the insanely complicated realty market in India. It was exciting and challenging to work on mining huge volumes of property records; extracting patterns from the data, building data pipelines and brainstorming on building the core system. TEAL offers a very healthy work environment coupled with insanely talented people working together in an exciting setting.
Naga Anjaneyulu, Data Science Intern
I worked as a full-time Data science intern at TEAL. During this period, I got an opportunity to leverage my skillsets while also learning new technologies, working on tasks assigned to me. The company operates on the latest tech-stacks and gives opportunities to learn as much as you want. The work environment is challenging, the team at TEAL is super supportive and new ideas are always welcome. It has all the good perks of a startup; creativity and innovation, casual work atmosphere and a collaborative approach to solving problems. Personally, I loved working there, my experience was fantastic!
Archana Parmar, Data Science Intern
As a second-year college student, I was looking for an internship that would allow me to delve deeper into research and work with big data, TEAL gave me the perfect opportunity to do so, enabling me to develop proficiency in research and analysis. As a research analyst intern, I collated and cleaned data and helped in the preparation of reports and presentations, and I had members helping me at every stage of this process. This collaborative environment allowed me to cultivate my skills and also learn from my peers. The holy trinity of Rohan, Kshitij, and Shreyas served as not only excellent mentors and bosses but also as friends, helping me at every stage and giving us all food and ice cream to keep us going!
Arush Mehra, Research Intern
Internships are a crucial part of one’s early career. The internship experience at TEAL was a thrilling rollercoaster ride to say the least! It was more than implementing a standard model or building an already though out concept into reality. It was about finding the solution to a unique and open-ended problem.It was exciting to work on addressing a problem with far -reaching real world applications.Moreover, the work environment had the perfect balance of casual yet professional which kept you focused and stress free at the same time. Out of every 100 startups in India only 2 of them succeed, but there are very few like TEAL India which are bound to make it big at such an early stage.
Divyanshu Agarwal, NLP Intern",4.7,"Terra Economics & Analytics Lab (TEAL)
4.7",New Delhi,"Bengaluru, India",1 to 50 employees,2018,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
1012,Senior Consultant - ModellingOps Data Engineer,"Job Title: Senior Consultant - ModellingOps Data Engineer
Location: TRIL GTC
GCL: D1

JOB DESCRIPTION:

AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. The Science & Enabling Units IT is AZs global IT capability function supporting key business areas operating out of sites across the US, UK, Sweden, India & Mexico.

We are looking for AI Ops consultant who will leverage tools & technology best practices to improve delivery performance & data engineering capabilities in the D&A space.

ROLES & RESPONSIBILITIES:

7-10 years of experience in IT Operations involving Data Science, Artificial Intelligence-Machine Learning and Predictive Analytics. Experience in architecting and implementation of end-to-end AIOPs solutions through ELK stack, Splunk. Experience in applying statistical methods, analysis, pattern recognition and modeling on IT Operational data using ELK machine learning. Experience in extracting meaning full data from incoming data streams from different sources through RegEx, Grok etc. Hands-on experience in applying machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc in the IT Operation domain. Experience with machine learning and statistical programming languages - Python, R etc. Experience in assessing the existing IT environment and providing recommendations to reduce the critical applications impacting incidents. Experience in exploring and identifying areas where manual tasks can be automated in IT environment. Experience with various Enterprise IT monitoring solutions including Infrastructure monitoring, Application Performance Monitoring, Network Monitoring, Cloud monitoring etc. Experience in IT Service Management including Service Desk, Incident Management, Change Management, CMDB etc. Excellent knowledge on various IT infrastructure components that includes Server Infrastructure, middle ware, database and application architectures and Cloud Components. Experience/knowledge on Infra monitoring tools - NOI, Zabbix, AppDynamics, Datadog, SCOM, SolarWinds etc. and Service Management tools -IBM Control Desk, BMC Remedy, ServiceNow etc. Experience/Knowledge on BI tools Knowledge on distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc. Knowledge on other programming languages/scripting: Python, Java, JavaScript, etc. ( Added Advantage ) Good analytical skills, strong communication skills are must. Client facing experience is an added advantage. Excellent experience in understanding the problem statement, architect and designing the solution

MANDATORY SKILLS:
Significant experience with AWS cloud environments, working knowledge of Google and Azure platforms. Knowledge of Kubernetes, S3, EC2, Sagemaker, Athena, RDS and Glue is essential.
Experience provisioning computational resources in a variety of Cloud environments using Infrastructure as Code.
Experience with best practice of data transport and storage within cloud system.
Experience building large scale data processing pipelines. e. g. Spark and SQL.
Experience with containers and microservice architectures e.g. Kubernetes, Docker and serverless approaches.
Excellent working knowledge in DevOps, using continuous integration and continuous development.
Use of Data Science modelling tools e.g. R, Python, SAS and Data Science notebooks (e.g. Jupyter).
Good written and verbal skills, fluent English
DESIERED SKILLS:
Agile practices, especially being a SCRUM Master
EDUCATIONAL BACKGROUND: B.E/B.Tech/MCA

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",3.9,"AstraZeneca
3.9",Chennai,"Cambridge, United Kingdom",10000+ employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Roche, GlaxoSmithKline, Novartis"
1013,DATA ENGINEER,"JOB DESCRIPTION
As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements, and also research new uses for data acquisition. You should also know the ins and outs of the industry such as data mining practices, algorithms, and how data can be used.

DESIRED CANDIDATE PROFILE
An ideal candidate must possess prior experience leading a project.

Candidates must have:
> Experience in Hive, Spark, Scala, AWS DynamoDB, HBase, AWS Glue, Talend, Kafka, Snowflake ETL
> Strong experience in a BI/Data Warehouse environment with involvement in design, development, implementation, troubleshooting and support of ETL process using ETL tool.
> Experience in developing Data Marts, Data warehousing and Operational Data Store (ODS) on any of the databases or Hadoop environments.
> Experience in database like MS SQL, MySQL, Oracle, PostgreSQL
> Good to have programming experience in writing Complex Stored Procedures, Queries, Views, User Defined Functions, Cursors and Common Table Expressions using SQL or T-SQL.
> Experience in Performance Tuning and Query Optimization by Indexing, Partitioning and De-normalization.
> Experience in Developing a framework for ingesting data into Data lake
> Good database knowledge, analytical thinking
> Design, construct, install, test and maintain data management systems.
> Build high-performance algorithms, predictive models, and prototypes.
> Develop set processes for data mining, data modeling, and data production.
> Experience with cloud services: AWS (EC2, EMR, S3, Athena) and scripting languages like Python, /PySpark/R/SAS
> Install/update disaster recovery procedures.
> Experience in Agile Application Development & Scrum methodologies is preferred
> Ability to supervise and mentor junior developers on the team.
> Must be self-motivated and work well pulling people together in addition to being able to pull people together technically
> Demonstrated proficiency of troubleshooting techniques and detail-oriented problem diagnosis
> Ability to handle responsibility, is self-directed, with strong organizational and documentation skills
> Ability to work independently and efficiently under aggressive deadlines to meet project commitments
> Excellent verbal and written communication skills

EDUCATION
UG - B.Tech/B.E. - Computers, Electronics/Telecommunication, Diploma - Computers, Electronics/Telecommunication, B.Sc - Computers, BCA - Computers) AND (PG - M.Tech - Computers, Electronics/Telecommunication, MCA - Computers, M.Sc - Electronics, Computers) AND ( Doctorate - Any Doctorate - Any Specialization, Doctorate Not Required).

OTHER DETAILS
Number of vacancies: 4
Experience: 3 years
Location: Cochin

If you have a passion towards technology and coding, then we have the right job for you. Kindly forward your resumes to
Email: jobs@mjsofttech.com
Phone: 0484-2421245 / 928 720 7160",4.0,"MJ Softtech
4.0",Kochi,"Cochin, India",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
1014,Data Engineer,"Education/ Experience and Skill Requirement
4+ years of relevant experience in
Experience working with both relational and NoSQL databases.
Strong coding skills; Python (preferred) /R/Java/Scala
Experience in developing Data warehousing technologies Experience with AWS or equivalent cloud services preferred
Experience in BigData technologies (Hadoop, HDFS, MapReduce, Spark, Hive, HBase etc) will be valuable
Knowledge of Machine Learning a big plus (Random Forest, Decision Trees, SVM, NLP, Gradient Boosting, Supervised/Unsupervised Learning, Clustering, classification and regression modeling).
Responsibilities
Proficiency with several years’ experience in more than one of Python, R, Java, Scala, or robust Linux shell scripting
Implementation experience with data warehouse architecture & design, ETL design/development, and Analytics
Knowledge of general cloud architecture and cloud strategies especially around AWS services and concepts such as S3 object stores, RDS databases, EC2, Glacier, Lambda, IAM, enterprise security, data security, DevOps, replication and disaster recovery
Well versed with data mining & exploration, NLP and visualization
Understanding of data modeling, data integration, and data representation (metadata, OWL, ontologies)
Developing data marts and data management using SQL
Creating powerful visual outcomes
Independently manage daily client communication, especially over calls
Manage client deadlines, ensure quality of the deliverables, attention to detail
Experience/understanding of corporate finance data from company filings is desirable",3.6,"Copal Partners
3.6",Bengaluru,"New York, NY",10000+ employees,1900,Company - Public,Financial Analytics & Research,Finance,₹100 to ₹500 billion (INR),-1
1015,Data Engineer,"Job Description / Responsibilities
Build workflows to ensure data extraction quality and storage into our backend data store
Architect, build and train ML/AI models that can predict outcomes and report on anomalies.
Design data pipelines to perform ETL on content/data from multiple types of source systems.
Create data analytics views using RDBMS/Key-Value stores, on private and public/cloud
Create software that is well tested, maintainable, extensible and scales out with large data

Minimum Qualifications:
2+ years of software development with Python
2+ years of SQL (MySQL/Postgres) and Key-Value databases
1+ years of experience with scikit
2+ years of experience in data extraction, data transformation using custom Python/Java
Experience working with MapReduce/Hadoop/kafka/Elastic stack
Experience with Node backend and React/Redux
Experience working with git/mercurial, Amazon/Google cloud, Linux/LAMP stack
Experience in testing or test driven development
Experience with Data science and Machine Learning algorithm development

Location:
Hyderabad/Bangalore

Package:
Highly competitive to match experience and capability",3.7,"TVS
3.7",Bengaluru,"Chennai, India",5001 to 10000 employees,-1,Company - Private,Accounting,Accounting & Legal,₹100 to ₹500 billion (INR),-1
1016,Data Engineer,"Permanent position with US based client of iFlex.
Work Location: Bangalore
Experience Level: 2+ Years

Role:
As part of our global team you will work on the data platform reporting to the Data Engineering Lead. Your role includes specification, development, test and rollout of features on our data platform. You are expected to contribute to the vision, understand our product roadmap, integrate business value andclient experience and contribute to build an engineering culture within the team. This initiative is of critical important to the success of the organization and our roadmap, for instance, services like liquidity analytics, billing, client onboarding, reporting and others will rely on the data platform. Accurate, granular, complete and timely data will be our key differentiating factor and competitive advantage in the market place. We expect the successful candidate to deliver high quality software and to be passionate about data engineering..

Responsibility / Qualification:
Managing multiple tasks and use sound judgment when prioritizing.
Collaborating with global cross functional team in building customer-centric products.
Analyzing existing software implementations to identify areas of improvement and provide deadline estimates for implementing new features.
Updating and maintain documentation for team processes, best practices and software runbooks.
Establishing trusted partnerships with peers, product heads, and executive level stakeholders.
We are looking for someone who is passionate about technology and engineering.
Exceptional analytical skills and ability to apply knowledge and experience in decision-making to arrive at creative and commercial solutions.
Ability to leverage technology to deliver business value.
You are independent and comfortable in a fast paced, ambiguous and often multi-directional work environment.

Preferred Qualifications:
B.S. or higher in Computer Science.
Minimum 2 years of relevant professional experience using a modern programming language (preferably Java/Scala).
Experience leveraging test driven development technics.
Comfort with Agile operating models.
Team oriented.
Strong interpersonal and communication skills.
Energetic, self-directed, and self-motivated.
Experience with microservice architecture.
Experience with Kafka, MongoDB, Hadoop, Cassandra.
Experience with AWS.
Experience in Financial Services or Fintech.",-1,IFLEX,Bengaluru,"Moscow, Russia",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1017,CIEL/SEL/1941: Sr data scientist,"Mandatory skills required -
Databases (SQL, Oracle, Any RDBMS) - Should have working knowledge of atleast one database
PL/SQL Programming Languages
R, Python (Any One)
Inferential Statistics - Hypothesis, p-value, R2, RMSE, MAPE etc
Exploratory Data Analysis
Machine Learning Algorithms - Should have in-depth knowledge and implementation of atleast one algorithm

Responsibilities
: Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the why & how of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions

Education
Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics
Experience
Minimum years of related experience required: 3 years
Preferred years of experience: 5 years
Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desirable.

Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
1018,Data Engineer,Data Engineer,3.6,"Bookmyshow
3.6",Mumbai,"Mumbai, India",1001 to 5000 employees,2007,Company - Private,Ticket Sales,"Arts, Entertainment & Recreation",Unknown / Non-Applicable,-1
1019,Data Analyst,"Required Skills & Experience

We are looking for a Data Analyst Executive
Eligible Qualifications : B. Tech, BCA, M.Tech, MCA
Experience : 3-5 years, fresher’s can also be considered
Location of Job : Gurgaon/Connaught Place, New Delhi
Technicals Skills

Following technical skills are pre-requisite:
Well versed with Software development methodologies, such as SDLC (Software Development Life Cycle), DDLC (Document Development Life Cycle).
Database schema design and implementation
Should have worked in either of technologies Sql Query/ Tableau/ Excel (Macros)/ Access (Query) writing for data analytics.
For planning and coordinating activities, organizations remain in invariant communication with one another and the data transfer has to be performed efficiently and smoothly as possible.
He/ She should manage the execution of the technologies, help the businesses in utilizing the systems, and should be well versed with the basics of computer systems such as Networking, Installation of necessary software and hardware.
Ability to determine the interrelationships between solutions and requirements.
Ability to think analytically and should be a problem solver and logic building should be very strong.
Good interpersonal skills to form effective working relationships with people at all levels.
Excellent communication and presentation skills and strong written & oral English skills.
To know more about us visit us www.sspl.net.in or write to us at admin@sspl.net.in",-1,Substratal Solutions,Connaught Place,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1020,Artificial Intelligence Scientists,"Experience 2- 4 Years
Salary 4 LPA - 6 LPA
Job Location Chennai

Industry:
IT-Software / Software Services

Keywords:
Artificial Intelligence

About Job:
Must have Excellent knowledge in AI / Machine learning (Mandatory).
Machine learning frameworks like keras, tensor flow etc.
And also other big data tools like Hadoop etc, Must know R and python.
Good understanding in SDLC & Business cycle.",4.0,"Careerera
4.0",Chennai,"Wayland, MA",501 to 1000 employees,-1,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
1021,Senior Data Engineer,"About Us

upGrad is an online education platform building the careers of tomorrow by offering the most industry-relevant programs in an immersive learning experience. Our mission is to create a new digital-first learning experience to deliver tangible career impact to individuals at scale. upGrad currently offers programs in Data Science, Machine Learning, Product Management, Digital Marketing, and Entrepreneurship, etc. upGrad is looking for people passionate about management and education to help design learning programs for working professionals to stay sharp and stay relevant and help build the careers of tomorrow.
upGrad was awarded the Best Tech for Education by IAMAI for 2018-19
upGrad was also ranked as one of the LinkedIn Top Startups 2018: The 25 most sought-after startups in India
upGrad was earlier selected as one of the top ten most innovative companies in India by FastCompany.
We were also covered by the Financial Times along with other disruptors in Ed-Tech
upGrad is the official education partner for Government of India - Startup India program
Our program with IIIT B has been ranked #1 program in the country in the domain of Artificial Intelligence and Machine Learning
About the Role

We are looking for a Data Engineer to help us scale the existing data infrastructure and in parallel work on building the next generation data platform for analytics at scale, machine learning infrastructure and data validation systems.
In this role, you will be responsible for communicating effectively with data consumers to fine-tune data platform systems (existing or new), taking ownership and delivering high performing systems and data pipelines, and helping the team scale them up, to endure ever growing traffic.
This is a growing team, which makes for many opportunities to be involved directly with product management, development, sales, and support teams. Everybody on the team is passionate about their work and we’re looking for similarly motivated “get stuff done” kind of people to join us!

Roles & Responsibilities
Engineer data pipelines (batch and real-time ) that aids in creation of data-driven products for our platform
Design, develop and maintain a robust and scalable data-warehouse and data lake
Work closely alongside Product managers and data-scientists to bring the various datasets together and cater to our business intelligence and analytics use-cases
Design and develop solutions using data science techniques ranging from statistics, algorithms to machine learning
Perform hands-on devops work to keep the Data platform secure and reliable
Skills Required
Bachelor's degree in Computer Science, Information Systems, or related engineering discipline
6 + years’ experience with ETL, Data Mining, Data Modeling, and working with large-scale datasets
6+ years’ experience with an object-oriented programming language such as Python, Scala, Java, etc
Extremely proficient in writing performant SQL working with large data volumes
Experience with map-reduce, Spark, Kafka, Presto, and the ecosystem.
Experience in building automated analytical systems utilizing large data sets.
Experience with designing, scaling and optimizing cloud based data warehouses (like AWS Redshift) and data lakes
Familiarity with AWS technologies preferred
Qualification – B.Tech/M.Tech/MCA(IT/Computer Science)

Years of Exp – 6-9",3.5,"upGrad Education Private Limited
3.5",Mumbai,"Mumbai, India",501 to 1000 employees,2015,Company - Private,Education Training Services,Education,₹1 to ₹5 billion (INR),"Udacity, General Assembly, Springboard"
1022,BBRC-Genomics-Associate Scientist,"JOB DESCRIPTION

Designation: Associate Scientist

Job Location: Bangalore

Department: Translational Medicine- Translational Sciences

About Syngene

Incorporated in 1993, Syngene International Ltd. is an innovation-focused global discovery, development and manufacturing organization providing integrated scientific services to the pharmaceutical, biotechnology, nutrition, animal health, consumer goods and specialty chemical industries around the world. Syngene’ s clientele includes world leaders such as Bristol-Myers Squibb, Baxter, Amgen, GSK, Merck KGaA and Herbalife. Its innovative culture is driven by the passion of its 4240- strong team of scientists who work with clients from around the world to solve their scientific problems, improve R&D productivity, speed up time to market and lower the cost of innovation .

Job Purpose:
To play a key role in TM-TS, develop an early-stage research strategy, initiate and lead discovery programs while managing ongoing programs in TM-TS. The role will work part of TMTS, and work with internal and external collaborators .

Key Responsibilities:
Experience in isolating DNA and RNA from blood, tissues and FFPE samples and cell lines. Experience with optimization of extraction protocols and for parameters like yield, input sample quantities and sample types is important.
Expertise in PCR, qPCR, cDNA/gDNA library preparation. Exposure to microarray techniques.
Proficiency in preparation of libraries for Next Generation Sequencing of transcriptome and genome, with significant experience in optimization of parameters like input RNA/DNA quantities and sample type
Experience with single cell RNA-seq will be plus.
Experience with various NGS protocols (DNA Amplicon based, hybrid capture based low input, degraded DNA and RNA samples e.g. FFPE samples.
Strong understanding of experimental design and statistical principles behind experimental design and differential gene expression. Experience with analysis of single cell RNA-sequencing data will be a plus

Educational Qualification:
M.Sc or M. Tech in Biotechnology, Molecular biology or Biological Sciences,

Technical/functional Skills:
DNA/ RNA Isolation, Expertise in PCR, qPCR, Experience in NGS protocols

Experience:
2 to 5 Years

Behavioral Skills:
A proactive team player.
Ensure completion of experiments and generate accurate and reproducible data from experiments.
Ability to work independently, prioritize tasks and work on multiple projects simultaneously with; comfortable working in a dynamic environment with changing requirements.
Good oral and written communication and presentation skills to work in a multi-disciplinary team
Equal Opportunity Employer:
It is the policy of Syngene to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by applicable legislation or local law. In addition, Syngene will provide reasonable accommodations for qualified individuals with disabilities.",3.5,"Syngene
3.5",India,"BENGALURU, India",1001 to 5000 employees,1994,Unknown,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1023,Applied Scientist 1,"Position Requirements:
Master's degree in Computer Science, Computer or Electrical Engineer, Mathematics, or a related field plus at least one year of experience in the job offered or related occupations of Software Engineer, Software Developer, or a related occupation. Employer will accept a Bachelor’s degree and five years of experience in the job offered or a related occupation as equivalent to the Master’s degree and one year of experience. One year of experience in the job offered or related occupation must involve designing and developing large-scale, multi-tiered, distributed software applications, tools, systems and services using Java, Object Oriented Design and Distributed Programming].

Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, Oracle/Berkeley databases, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills

Amazon Selling Partner Services team drives the Selling On Amazon business and develops solutions that enable millions of sellers around the world to sell on Amazon's Marketplaces. More than half of shipments for Amazon customers are generated from this business. The team is focused on building a technology platform that will support the explosive business growth in existing markets, streamline the business for Amazon and the Selling partners and launch business in new markets and establish a fair marketplace.

Our team is seeking engineers with broad technical skills to help us optimize how we synthesize massive amounts of data and complex business rules into mission critical financial information. As a member of this team you will employ object oriented techniques in Java, and DynamoB, PostGres and ElasticSearch skills to help us support Amazon's next generation of selling partner services. Along the way you'll gain and leverage a unique understanding of how Amazon.com works; from the numerous software systems that comprise the website's back-end, to the details of our business model, and the relationships we're establishing with an ever-growing network of selling partners who depend on Amazon.com to run their businesses.

The ideal candidate will draw upon exemplary analytical, critical thinking, and problem solving skills, and a passion for maintaining highly reliable, distributed systems which operate 24/7/365. Successful members of this team collaborate effectively with internal end-users, aggressive cross-functional software development teams, and technical support/sustaining engineering teams to solve problems and deliver successfully against high operational standards of system availability and reliability. We look for engineers who are excellent communicators, self-motivated, flexible, hardworking, and who like to have fun!

Position Responsibilities:
Participate in the design, development, implementation, testing and documentation of large-scale, multi-tiered, distributed software applications, tools, systems and services using [Java, Object Oriented Design and Distributed Programming]. Translate functional requirements into robust, scalable, supportable solutions that work well within the overall system architecture. Participate in the full development cycle, end-to-end, from design, implementation, and testing to documentation, delivery and maintenance. Produce comprehensive, usable software documentation. Evaluate and make decisions around the use of new or existing software products and tools.

Preferred Qualifications
Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1024,Senior Clinical Data Analyst,"About Novotech:

Novotech is internationally recognised as the leading independent and full-service contract research organisation (CRO) in the Asia Pacific region. We provide a wide range of clinical development services across all research phases and therapeutic areas and have been instrumental in the success of hundreds of Phase I – IV clinical trials throughout the Asia Pacific. Powered by the highest quality people, Novotech strives to set the benchmark for both business and clinical trial performance. Our people are one of our key strengths. We value our people and recognise the work they do. We are lucky to have the best people and talent from across the Asia Pacific region work together to deliver to clinical trial success for our clients. Our people and those we look to recruit have an attitude of making things happen. They are problem solvers, driven with a focus on delivering quality, accountability and a high level of performance.

Brief Position Description:

As part of Novotech’s Biometrics unit, the Senior Data Analyst (SDA) is responsible for all data analysis and business intelligence activities related to study related clinical and operational data. The SDA acts as primary point of contact for all data analysis matters to the study team and is responsible for the timely delivery of quality outputs following all applicable regulatory, compliance, best practice and operational procedures.

Minimum Qualifications & Experience:

Graduate in information science, data science or life science-related field, or similar. More than five years’ experience in a senior role related to data science, data analysis, clinical data management or clinical data programming in a pharmaceutical company, CRO or EDC software provider.

Responsibilities
The Senior Data Analyst (SDA) is responsible for providing technical, procedural (SOPs) and planning leadership across multiple projects assigned to the data analyst team members ensuring that they deliver in accordance with SOPs, programming best practices, and the timelines agreed within the Project Team.
Collaborate with cross-functional stakeholders to implement data science solutions to solve business needs using available technological solutions.
Scope data analysis effort for projects and project manage all data analysis activities across multiple projects for different study stakeholders.
Gather study requirements from data management for data review and external data reconciliation and provide guidance on appropriate outputs (dashboards, visualisations, listings, reports).
Extract, assess, integrate, transform data sources to provide data visualisation outputs for analytics.
Design and develop prototypes and final versions of data outputs (dashboards, reports, visualisations, listings) using Business intelligence tools and Data Visualisation tools.
Design and develop standard dashboards and content for different audiences.
Analyse, manipulate and understand data from multiple sources to present and create dashboards and reports to make business decisions.
Assist teams on best-practice for data visualisation dashboard development.
Educate teams on how to use all the features of applicable data visualisation platform in conjunction with data visualisation dashboards.
SME for the data visualisation development and assisting team members.
Identify and communicate project risks and maintain documentation within project files as appropriate
Represent data analysis group at internal / external meetings as appropriate.
Assess and implement new data analysis, BI and data visualisation processes and technologies.
Take an active role in the development of best practices, process improvement, quality control and governance related to all data analysis matters.
Provide training and mentoring to Data Analysis of team members in SOPs, software applications, and best practices.
Provide Subject Matter Expertise on all data analysis and visualisation related activities.
Attributes and Skills

Expert knowledge of clinical study data structures and schemas of EDC databases. Expert knowledge in data processing activities such as extracting, integrating, transforming and presenting data. Statistical Programming skills in Python, R or similar. Knowledge of SQL and EDC systems. Working knowledge of Spotfire, Power BI, Tableau or other data review and visualisation tool. Ability to gather business requirements from multiple stakeholders and clients and provide guidance on the use of appropriate data visualisations.

Experience mentoring and training others. Awareness of regulatory and compliance issues and understanding of the application of SOPs and Quality Control to daily activities. Excellent analytical, communication and problem-solving skills.

Opportunities and Benefits:

To deliver clinical trial and research excellence for our clients, our people are 'best in class'.

At Novotech, we seek and nurture people with exceptional talent. We are committed to providing our people with regular internal and external training, a competitive bonus structure and a supportive work environment. We are also focused on providing our people with a wide variety of career growth and development opportunities.

For more information about where your next career step at Novotech might take you, visit http://novotech-cro.com/novotech-careers",4.5,"Novotech
4.5",Bengaluru,"Sydney, Australia",501 to 1000 employees,1996,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
1025,Data Engineer,"Data Engineer Responsibilities:
Liaising with coworkers and clients to elucidate the requirements for each task.
Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed.
Reformulating existing frameworks to optimize their functioning.
Testing such structures to ensure that they are fit for use.
Preparing raw data for manipulation by Data Scientists.
Detecting and correcting errors in your work.
Ensuring that your work remains backed up and readily accessible to relevant coworkers.
Remaining up-to-date with industry standards and technological advancements that will improve the quality of your outputs.
Data Engineer Requirements:
Bachelor's degree in Data Engineering, Big Data Analytics, Computer Engineering, or related field.
Master's degree in a relevant field is advantageous.
Proven experience as a Data Engineer, Software Developer, or similar.
Expert proficiency in Python, C++, Java, R, and SQL.
Familiarity with Hadoop or suitable equivalent.
Excellent analytical and problem-solving skills.
A knack for independent and group work.
Scrupulous approach to duties.
Capacity to successfully manage a pipeline of duties with minimal supervision.
Job Type: Full-time

Salary: ₹360,000.00 to ₹870,000.00 /year

Experience:
total work: 2 years (Preferred)
Data Engineer: 1 year (Preferred)
Education:
Diploma (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,Futurious Technologies,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1026,Quantitative Analyst,"The successful candidate will be a highly analytical individual with hands on programming skills. The candidate will work closely with the research team and clients towards the ongoing development and integration of new investment strategies, models and tools on Axle

Location

Mumbai
Responsibilities

Perform daily/weekly/monthly tasks of performance and risk reporting
Develop and automate investment processes and strategies via VBA and Matlab
Develop tools to integrate trading decision systems with risk management systems
Ad hoc tasks (such as operational tasks, internal documentation tasks and preparation of marketing materials)
Skills/Experience

Excellent programming skills in Matlab/Excel-VBA
Thorough with financial concepts and calculations like Drawdown, VaR, Eloss etc.
Understanding of financial market products like options, futures, FX forwards etc.
Working knowledge of Bloomberg is preferred
Should be self-driven and detail oriented with an analytical mindset
Should be a proactive and quick learner; a team player showing enthusiasm and drive to accomplish results in a fast paced environment
Min. 2 years of relevant work experience
Qualifications

B.Tech/M.Tech/MBA/CFA/FRM",5.0,"B&B Analytics
5.0",Mumbai,"Zug, Switzerland",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1027,Analyst - Data Scientist,"Job Summary

Experience:
3 - 5 Years

Location:
Mumbai

Designation:
Analyst - Data Scientist

Degree:
BE-Comp/IT, BE-Other, BTech-Comp/IT, BTech-Other, ME-Comp/IT, ME-Other, MTech-Comp/IT, MTech-Other, PhD-Comp/IT, PhD-Other

Educational Level:
Graduate/Bachelors

Industrial Type:
IT-Software/Software Services

Functional Area:
IT Software - Application Programming / Maintenance

Key Skills:
Data Scientist

Job Post Date:
Thursday, March 19, 2020

Company Description

We are capability centre based in Mumbai, initially started as a back-office operational support to the UK business unit.

However, over the recent years, we have significantly increased the breadth and depth of our capabilities and offerings to keep pace with the changing needs of the Group. These include Digital & Knowledge Services, Finance and Actuarial, Information Technology (IT), Customer Service, Risk and Audit.

Our core purpose is to be a strategic partner to company, enabling growth by delivering change and driving synergies through a highly capable and agile workforce.

With our diversified service offerings we provide our people with exciting opportunities to grow personally and professionally.

Company is a leading savings and investments business serving around 5.5 million retail customers and more than 800 institutional clients.

It-s innovative asset management and customer solutions are supported by extensive investment capabilities, an international distribution network and two strong brands.

Job Description

3 – 5 yrs experience as Data Scientist
Should have at-least 1 end-to-end ML project experience
Very high proficiency in R or Python
Excellent in forecasting methods like simple exponential smoothing, multiplicative seasonal indexes, simple and weighted moving averages and time series forecasting methods
Exposure to with advanced deep learning techniques such as LSTM. CNN, Dense neural networks as well as neural networks design and implementation through tools like tensorflow, keras, pytorch, deepai or equivalent.
Good SQL experience",3.8,"Sampoorna Computer People
3.8",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
1028,Data Lake Developer,"For Us, It's A Mission

At Mylan, we mean it when we say we work every day to provide access to high quality medicines to the world's 7 billion people. If you are unconventional, relentless and passionate. If you believe in doing what's right, not what's easy. If you are a doer and have a passion for serving others, we want to talk to you.

Make a Difference

At Mylan, each person has the ability to make a difference. From the providers who sell and market our products, to the producers who develop and manufacture them and finally to our business partners who support the providers and producers, we all have a mission critical role. Here's how this role will help:

ESSENTIAL DUTIES AND RESPONSIBILITIES
To perform this job successfully, an individual must satisfactorily perform each essential duty. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential duties.
1. Create and maintain optimal data pipeline architecture on Azure platform.
2. Develop batch processing solutions by using Data Factory and Azure Databricks.
3. Delivering a Data Warehouse in the Azure Cloud.
4. Design relational and non-relational data stores on Azure.
5. Identify, design, and implement internal process improvements : automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc..
6. Developing Big Data Solutions with Azure Machine Learning.
7. Strong interaction with business departments to provide consultative support for digitization efforts, as well as close collaboration with the Business Technology management, focused on future innovation topics.
8. Participate and lead in design sessions, demos and prototype sessions, testing and training workshops with business users and other IT colleagues.
9. Design & Build for any API Development or SQL DB development.
10. Providing service management, orchestration, monitoring and management requirements of Azure cloud platform.
11. Create data tools / products for analytics and data scientist team members that assist them in building and innovative solutions that drive tangible business value.
12. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
13. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
14. Design security for source data access. Chose the appropriate authentication mechanism, (ie Azure Active Directory (Azure AD), etc).
15. Design for real-time processing by using Stream Analytics and Azure Databricks.

Make Our Values Your Values

Mylan hires only the best. People who thrive in a culture of innovation and empowerment. People who are active learners and have a positive attitude. People who are leaders and know that by working together we can run faster, reach higher and achieve more. By doing so, we will continue to set new standards in health care. Here are the minimum qualifications and essential functions for this position:

QUALIFICATIONS

The qualifications listed below are representative of the minimum knowledge, skill, and/or ability required.

SKILLS AND ABILITIES

1. 10 years of experience in Microsoft technologies including SQL.

2. At least 5 years as a Sr Developer with at least 3 years hands on experience as Azure Data Engineer building large scale Azure data solutions.

3. At least 5 years of experience in Azure based data solutions.

4. At least 3 years of experience on working with large projects including the most recent project in the cloud (Azure) or on prem with a focus on Azure Data services.

5. At least 5 years of Hands-on administration, configuration management, monitoring, performance tuning of Hadoop/Distributed platforms.

6. At least 5 years of demonstrated experience at least in the most recent 2 years of designing and delivering solutions using Cortana Intelligence suite of analytics services part of Microsoft Azure including Azure Machine Learning Studio, HDInsight, Polybase, Azure Data Lake Analytics, Azure Data Warehouse, Streaming Analytics, Data Catalog, R/R Studio

7. Experience in designing and building logics required for optimal extraction, transformation, and loading of data from a wide variety of data sources

8. Experience within Data Security design, including but not limited to:

a. Choosing the appropriate authentication mechanism, such as Azure Active Directory (Azure AD)

b. Defining strategies for data encryption for data at rest and in transit

9. Experience partnering with Business Analysts and Data Scientists to enable effective and efficient data preparation and delivery

10. Experienced in vendor management and working with 3rd parties onshore & offshore.

11. Experience working in a global team.

12. Experience working in an Analytics / Big Data solutions on MS Azure Cloud

13. Experience with code management tools, automated testing

14. Experience creating and maintaining optimal data pipeline architecture on Azure platform

15. Experience developing batch and real-time processing solutions by using Data Factory and Azure Databricks

16. Familiar with AGILE and Azure DevOps methodology

17. Hands on PoC capabilities are needed to prove a particular architecture concept

18. Azure Native Services experience across Data Fabric and Service Fabric

19. Experience in Application modernization from legacy on-premise data architecture platform technology stack to modernized Azure Cloud base Architecture.

20. Experience with Git, NoSQL Data Solutions, Microsoft Azure, HD Insights, Azure ML, DataBricks ML Flow, R or Python.

21. Must have excellent communication skills.

EDUCATION/EXPERIENCE (Note: Please select one)

Minimum of a Bachelor's degree in Computer Science and Engineering is preferred with minimum 10 years of experience. However, a combination of experience and/or education will be taken into consideration

Why Mylan?

If you want to be part of a global health care company that is making a difference and changing lives, Mylan may be the place for you. With a workforce of more than 35,000 worldwide, we can make a difference. We encourage you to visit Mylan.com to learn more about our unconventional culture, our approach to doing business and how we plan to set new standards in health care.

Mylan offers competitive salary, excellent benefits and an environment conducive to professional growth and advancement. All qualified applicants will receive consideration for employment without regard to their disability or protected veteran status. Mylan is an Equal Opportunity Employer, Minorities/Female/Disabled/Veteran.",3.8,"Mylan Inc.
3.8",Bengaluru,"Hatfield, United Kingdom",10000+ employees,1961,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1029,Off Campus Recruitment - Quantitative Researcher,"Description:
Graviton is a privately funded quantitative trading firm striving for excellence in financial markets' research. We are seeking fresh talent from the top IIT's to join us as Quantitative Researchers for our team in Gurgaon.If you are a student graduating in 2020 from Computer Science , Electrical or Maths Stats Computing streams with a greater than 8 CGPA please apply here.

This role is open to students from campuses that we could not visit this year. Please check your individual placement policy restrictions before applying.

Graviton trades across a multitude of asset classes and trading venues using a gamut of concepts and techniques ranging from time series analysis, filtering, classification, stochastic models, pattern recognition to statistical inference analysing terabytes of data to come up with ideas to identify pricing anomalies in financial markets.

As a Quantitative researcher your responsibilities will include

Develop new or improve existing trading models using in-house platforms

Use advanced mathematical techniques to model and predict market movements

Analyse large financial datasets to identify trading opportunities

Provide real time analytical support to experienced traders

Requirements :
Possess a degree in a highly analytical field, such as Engineering, Mathematics, Computer Science from IITs schools

Quantitative bend of mind

A working knowledge of Linux/Unix

Programming experience, preferably in C++ or C

Strong interest in learning about financial markets.

Have a strong work ethic

Hard Working

Benefits:
Our open and casual work culture gives you the space to innovate and deliver. Our cubicle free offices , disdain for bureaucracy and insistence to hire the very best creates a melting pot for great ideas and technology innovations. Everyone on the team is approachable, there is nothing better than working with friends!

Our perks have you covered.

Competitive compensation

6 weeks of paid vacation

Monthly after work parties

Catered breakfast and lunch

Fully stocked kitchen

Gym membership

International team outing",5.0,"Graviton Research Capital LLP
5.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2014,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1030,Data Engineer,"Zauba Technologies is a startup based in Bangalore. Zauba's services are used by leading companies in India. Zauba is powered by a young and passionate team. We are looking for individuals who would like to be a part of our founding team.

As a Data Engineer and as a part of founding team, you will be expected to visualise and develop disruptive data products. Eventually you would be responsible for entire project lifecycle of products you would visualize. Your rewards will be directly proportional to the value you generate.

Job Responsibilities
Design and development of robust, scalable and highly efficient data engineering solutions for structured and unstructured data (Including gathering and processing raw data at scale, writing scripts, web scraping, calling APIs, writing SQL queries, etc.)
Develop processes for text mining and extraction of information from unstructured data
Design, architect and develop efficient data pipelines around the data collected
Take ownership of existing web product and applications
Design and implement data models that scale across the enterprise
Take ownership of existing data workflows and processes
Enhance scalability, performance, and stability of existing infrastructure
Work closely with other team members to integrate your innovations and algorithms into our production systems

Essentials
Java/Python - Intermediate to advanced level
SQL - Advanced
MySQL Intermediate to advanced level
Regex - Basic to intermediate level
Linux Basic to intermediate level

Good to have
Hadoop/Spark
R
MongoDB

Must have qualities
Skills to learn new skills quickly
Desire to create disruptive products and services
Passion - not just to work in startups but to take them to next level
Above average programming aptitude
Be passionate about producing high quality engineering deliverables
Be productive working independently or collaboratively
Have an eye for building efficient processes
Be self motivated
Proactively take ownership

Interested?

Send your resume to hr@zaubacorp.com",3.8,"Zauba Corp
3.8",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 million (INR),-1
1031,Quantitative Research,"We are looking for highly trained professionals who are interested in applying advanced mathematical quantitative methods to the modeling of global financial markets. You would be joining a group made up of highly proficient individuals from various scientific disciplines. We have a spectrum of opportunities for individuals with the right scientific skills. Experience in finance is not required.

The ideal research candidate will have:
A Ph.D. in Computer Science, Mathematics, Physics, Statistics, or a related technical discipline.

A demonstrated capacity to do first-class research.

Computer programming skills.

An intense interest in applying quantitative analysis to solve difficult problems.

Send us a copy of your resume to
careers@dolatcapital.com

For internship opportunities, please send us a copy of your resume to
careers@dolatcapital.com",4.0,"Dolat Capital
4.0",Mumbai,"Mumbai, India",51 to 200 employees,1970,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1032,Data Engineer,"Bachelor’s degree in Computer Science or related field
5+ years relevant experience
5+ years experience with SQL, SQL Tuning, Oracle, OLAP, Big Data Technologies
5+ years experience developing end-to-end Business Intelligence solutions: data modeling, ETL and reporting
Experience with Java and experience with scripting languages like Perl, Python, Unix shell scripts,VBA and MS Excel
Proficiency with Linux and systems administration
Proven ability at looking at solutions in unconventional ways. Sees opportunities to innovate and can lead the way.
Top notch communication (verbal and written) and interpersonal skills to convey key insights from complex analysis in summarized business terms and an ability to effectively communicate with technical teams.
Ability to work with shifting deadlines in a fast paced environment.
Operations Finance Technology team, responsible for building technical solutions for multi-billion WW Operational Cost analytic including Inbound cost (Receiving / PO), variable Cost, fixed cost, outbound (Customer Shipments / Transportation), and Customer Service, is looking for a Data Engineer.

As a data engineer, you will get the exciting opportunity to work on very large data sets in one of the world's largest and most complex data warehouse environments. You will work closely with the business teams in analysis on various cost savings initiatives, many non-standard and unique business problems and use creative-problem solving to deliver actionable output.
You will be responsible for designing and implementing an analytical environment using third-party and in-house reporting tools, modeling metadata, building reports and dashboards. You will have an opportunity to work with leading edge technologies like Redshift, Hadoop/Hive/Pig. You will be writing scalable queries and tuning performance on queries running over billion of rows of data.

You should be analytical, have an extremely high level of customer focus and a passion for process improvement. You should be motivated self-starter that can work independently in a fast paced, ambiguous environment. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions.
Bachelors in Computer Science or related field
Practical Knowledge of Linux or Unix shell scripting
Experience in working with business customers to drive requirements analysis
Exposure to large databases, BI applications, data quality and performance tuning
Excellent written and spoken communication skills
Experience with Hadoop-based technologies such as HBase, Pig, Hive and Spark
Strong proven ability in building high-performance, highly available and scalable data solutions using Oracle and/or Hadoop-based technologies
Knowledge of data warehousing concepts.
Strong sense of ownership, urgency, and drive
Strong troubleshooting and problem solving skills
Experience with Amazon Web Services",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1033,DATA ANALYST,"posted by Mahima Gaur

2 - 5 years Delhi

Job Description
Experience in data processing
Experience in data cleaning and data tabulation activities
Strong analytical, communication and team management skills
Strong understanding of data management using SPSS and research techniques
Competency in a Tabulation software (decipher / wincross / quantum etc), Excel, Powerpoint
Ability to summarize findings, draw conclusions, and put together a presentation using Powerpoint
Role Category : Data Analyst

Employment Type : Permanent Job, Full Time",4.9,"Knowledge Excel Services.
4.9",New Delhi,"New Delhi, India",1 to 50 employees,2007,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
1034,Data Engineer,"Key skills : Python , Spark , SQL , Pyspark • AWS platform used for the work • Strong experience in SQL is mandatory • Good familiarity of AWS landscape • Good experience in collecting business requirements & design them as per requirement from customer • Should able to work independently & interact business users & technical stakeholders • Strong communication skills both oral & written. • Should work as an individual resources",3.5,"Larsen & Toubro Infotech Limited
3.5",India,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1035,Big Data Engineer,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
1036,Client Data Analyst,"At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.
What is the Client Data Analyst – Client Analytics group responsible for?
This team manages business data to ensure accurate, timely, consistent and compliant data. Their contributions deliver quality data that is easily accessible and can be trusted. Key downstream capabilities such as reporting and analytics depend on this as well as operational data access on various systems. The Data Management Team is a support function that acts as an advocate and a point of contact for Sales and Marketing data.

What are the ongoing responsibilities of an Client Data Analyst ?
Understand the data flow, key consumption and production of data as well as context within the enterprise:
Build positive relationships with teams, especially the key data consumers and analytics. Take the time to increase knowledge of how they run their business and incorporate sales data into daily work
Connect regularly with each sales office to understand current issues and challenges. Probe the business and validate against other sales offices to understand the scope and priority of the issue
Make recommendations on how data unifications and flow can be used to improve business tasks. Liaise business partners to deliver solutions (reports, processes, technology) that add value.

Provide data management subject matter expertise. Appreciate the connection and data flow between applications and other corporate systems. Be able to clearly articulate the data needs and move initiatives forward by collaborating with business partners:
Actively participate in meetings with business partners to ensure that priorities are clearly understood, information is regularly shared and that key participants are “kept in the loop”
Provide context and background on issues. Collaborate on ideas for progressing initiatives. Ensure appropriate resources are involved to take initiatives forward
Provide insights and expertise to scope statements and requirements documentation
Actively consult or participate in the user acceptance testing process (test cases, documentation, testing execution, etc.)
Ensure business needs remain aligned with overall corporate initiatives and deliver the benefits as originally intended

Monitor the integrity of data and usefulness of reports. Ensure the information available within systems is accurate and up-to-date. Proactively seek data cleansing opportunities and evolve data to better support. Document and maintain ongoing processes for reporting and data clean-up:
Partner with all key data consumers to gain a solid understanding of usage and challenges around data. Establish processes for prioritization of enhancements, especially with the analytics groups
Provide 1st level support for data issues and data maintenance for owned data
Verify and execute data loads into our internal sales systems and ensure any upstream systems accurately receive their data

Increase awareness and promote data management capabilities. Share best practices and provide coaching to local offices on how to access and incorporate output into sales tasks. Encourage IAS leaders to leverage data to make more informed, strategic decisions:
Clearly articulate the goals and core services of the data management team. Proactively promote this information within IAS and ensure business partners understand the data management role within the organization
Share best practices and provides guidance on data capabilities. Reinforces ownership and accountability for data accuracy
Seek opportunities to share the benefits of leveraging sales data to make more informed business decisions

What ideal qualifications, skills & experience would help someone to be Successful?

Knowledge, Education And Experience:
Four year bachelor’s degree required (majors of preference include: business, computer science, mathematics) Advanced degree a plus
Understanding of the Franklin Templeton business model, how FT makes money, the sales process, how technology fits in with the business, etc. Knowledge of the GAS (Global Advisory Services) structure
Experience working through multiple business fiscal cycles; exposure and/or direct experience with project management and/or sales-related-capacity required
Prior work experience related to analytics, sales, marketing and/or international a must. Level will not be granted based on years of experience but will be determined by the employee’s ability to meet each job activity as outlined the ‘typical/expected focus by level
Skills And Abilities:
Ability to communicate effectively with all levels of management; ability to tailor communication style based on audience; ability to get others to want to collaborate with you; strong facilitation skills
Excellent writing skills (for presentations, documentation, etc.)
Working knowledge of the CRM, MDM, Excel, SQL, Power BI, Tableau, Business Objects, and Microsoft Products (PPT, Power Apps, Doc, Visio)
Ability to absorb and interpret large quantities of data; apply trend analysis and knowledge of the business to develop a meaningful and digestible summary with the appropriate level of detail
Ability to take a larger problem and break down the individual components; identify how to go about solving the problem and who to involve in the process
Ability to present recommended solutions to a variety of issues and problems (solutions that are consistent with organization objectives)
Must be extremely detail-oriented (managing lists, tasks/to-dos, etc.) good with follow through on own items; good with following up with others on outstanding item

What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.

Highlights of our benefits include:

Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.",3.8,"Franklin Templeton Investments
3.8",Hyderabad,"San Mateo, CA",5001 to 10000 employees,1947,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Fidelity Investments, Vanguard"
1037,Data Analyst,"Roles and Responsibilities:
Extracting, transforming and inputting data sets from various resources. Creating predictive models, translating non-technical aspects into quantifiable tasks. Analysis and representation of output data, highlight and explain trends and patterns, error elimination, using advanced statistical methods (regression, probability distribution, clusters etc.) to provide accurate results.
Data collection, Data Mining, Report generation, Problem identification and solution formulation Market analysis and establishing trends, Strategy development and implementation

Skills:
Extremely good analytical skills.
Good working knowledge of all MS-Office products, especially Advance Excel, Word, PowerPoint, MS-access.
Statistical tools and methods.

Interested candidates can send the updated resume on satish.mehra@exelaonline.com or call on 7722028636
00-7.00 Years",2.6,"Exela Technologies
2.6",Pune,"Irving, TX",10000+ employees,2017,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"SourceHOV, BancTec, Transcentra"
1038,Data Modeler,"• Minimum 5-8 years of working experience as Data modeler.
• Data modelling experience in designing.
• Minimum 2-3 years real time experience in Erwin tool is mandatory.
• Experience in normalized modeling techniques.
• Experience in designing the Start schema.
• Experience working in ORACLE.
• Experience with database design, capacity planning, performance tuning and query optimization.
• Experience in working with Bank or Banking and Finance or Financial domain.
• Excellent communication skills with leadership quality.

Job Segment:
Database, Oracle, ERP, Technology",3.5,"LTI
3.5",Mumbai,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1039,Machine Learning Engineer,"Looking for Data Scientists with Python/R Programming skills.
Specific experience in AI areas like Statistical Machine learning / Deep learning / Natural Language Processing (NLP)/ Operations Research (Optimization) will be an advantage.Individual in this role is expected to work with multiple stakeholders and teams

Qualifications and Requirements:-
Previous working experience as a Machine Learning/ Data Scientist for 2 years
MA in Computer Science or similar relevant field
Hands on experience with MALLET
In depth knowledge of Apache Tomcat/Open Source
Excellent project and time management skills
Attention to detail
Outstanding problem solving and analytical skills",-1,Tekolutions.ai,India,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1040,Data Science Internship,"About the company:
SkillBit is a leading staffing and recruitment company engaged in talent searching assignments for skilled and talented candidates for the industry.

About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Working on data science algorithms and AI concepts 2. Using Python or R for web scraping 3. Building AI models using Python, machine learning, and deep learning algorithms 4. Processing of unstructured/structured data

Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 6th Jun'20 and 11th Jul'20
are available for duration of 1 month
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply

Number of internships/jobs available: 3

Categories: Data Science",-1,SkillBit,Pune,-1,-1,-1,-1,-1,-1,-1,-1
1041,Data Engineer,"As a data engineer at TEAL, you'll be taking the plunge into a rich data lake that includes everything from satellite data to legal court orders. You'll be hustling and getting your hands dirty with every part of the data pipeline always having an implicit appreciation for how all of this data will ultimately power a revolutionary real estate risk platform.

Your day-to-day will include either all or some of the following:

Constantly scoping out new data sources to complement existing ones
Creating and maintaining distributed web scrapers using Python, RabbitMQ and other technologies
Architecting and managing data pipelines where data flows into multiple end-points including, but not limited to, Postgres, MongoDB and Apache Solr
Documenting workflows and constantly iterating to create better data infrastructure.

We'd love it if you:
Are proficient in Python or any other object-oriented language
Have worked with large (millions to hundreds of millions of rows in a SQL database) interdisciplinary datasets
Have scraped difficult websites and have some experience working with various data APIs
Are patient and methodical with unstructured and messy data
Are always hungry to learn newer and better technologies to make the data ecosystem faster, smoother and less silo-ed

Extra brownie points if you:
Have some experience working with large-scale search indexing
Have performed geospatial analyses in some capacity
Have created and managed data lakes in the cloud
Culture

To explore our culture and the values we embody click here

Testimonials
Testimonial

My experience at TEAL surpassed all my expectations from the get-go. I was asked to help solve one of the most daunting problems in the Indian real estate market. Every day while working on a subset of the problem, the ideas that I brought to the table were shaped into cohesive solutions by a collaborative team effort. At TEAL I was exposed to the most cutting edge technologies such as Cloud Computing, Big Data, ML and Data Science. The growth opportunities at TEAL are tremendous, If you are innovative and can demonstrate the will to realize your ideas, TEAL is an amazing organization to work for.
Gyan Vardhan, Data Science Intern
I had interned as a Data Scientist at Terra Economics and Analytics Lab during its early days, it was a rich learning experience working with a multi-disciplinary team who are extremely passionate about building a decision support platform for the insanely complicated realty market in India. It was exciting and challenging to work on mining huge volumes of property records; extracting patterns from the data, building data pipelines and brainstorming on building the core system. TEAL offers a very healthy work environment coupled with insanely talented people working together in an exciting setting.
Naga Anjaneyulu, Data Science Intern
I worked as a full-time Data science intern at TEAL. During this period, I got an opportunity to leverage my skillsets while also learning new technologies, working on tasks assigned to me. The company operates on the latest tech-stacks and gives opportunities to learn as much as you want. The work environment is challenging, the team at TEAL is super supportive and new ideas are always welcome. It has all the good perks of a startup; creativity and innovation, casual work atmosphere and a collaborative approach to solving problems. Personally, I loved working there, my experience was fantastic!
Archana Parmar, Data Science Intern
As a second-year college student, I was looking for an internship that would allow me to delve deeper into research and work with big data, TEAL gave me the perfect opportunity to do so, enabling me to develop proficiency in research and analysis. As a research analyst intern, I collated and cleaned data and helped in the preparation of reports and presentations, and I had members helping me at every stage of this process. This collaborative environment allowed me to cultivate my skills and also learn from my peers. The holy trinity of Rohan, Kshitij, and Shreyas served as not only excellent mentors and bosses but also as friends, helping me at every stage and giving us all food and ice cream to keep us going!
Arush Mehra, Research Intern
Internships are a crucial part of one’s early career. The internship experience at TEAL was a thrilling rollercoaster ride to say the least! It was more than implementing a standard model or building an already though out concept into reality. It was about finding the solution to a unique and open-ended problem.It was exciting to work on addressing a problem with far -reaching real world applications.Moreover, the work environment had the perfect balance of casual yet professional which kept you focused and stress free at the same time. Out of every 100 startups in India only 2 of them succeed, but there are very few like TEAL India which are bound to make it big at such an early stage.
Divyanshu Agarwal, NLP Intern",4.7,"Terra Economics & Analytics Lab (TEAL)
4.7",New Delhi,"Bengaluru, India",1 to 50 employees,2018,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
1042,Senior Consultant - ModellingOps Data Engineer,"Job Title: Senior Consultant - ModellingOps Data Engineer
Location: TRIL GTC
GCL: D1

JOB DESCRIPTION:

AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. The Science & Enabling Units IT is AZs global IT capability function supporting key business areas operating out of sites across the US, UK, Sweden, India & Mexico.

We are looking for AI Ops consultant who will leverage tools & technology best practices to improve delivery performance & data engineering capabilities in the D&A space.

ROLES & RESPONSIBILITIES:

7-10 years of experience in IT Operations involving Data Science, Artificial Intelligence-Machine Learning and Predictive Analytics. Experience in architecting and implementation of end-to-end AIOPs solutions through ELK stack, Splunk. Experience in applying statistical methods, analysis, pattern recognition and modeling on IT Operational data using ELK machine learning. Experience in extracting meaning full data from incoming data streams from different sources through RegEx, Grok etc. Hands-on experience in applying machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc in the IT Operation domain. Experience with machine learning and statistical programming languages - Python, R etc. Experience in assessing the existing IT environment and providing recommendations to reduce the critical applications impacting incidents. Experience in exploring and identifying areas where manual tasks can be automated in IT environment. Experience with various Enterprise IT monitoring solutions including Infrastructure monitoring, Application Performance Monitoring, Network Monitoring, Cloud monitoring etc. Experience in IT Service Management including Service Desk, Incident Management, Change Management, CMDB etc. Excellent knowledge on various IT infrastructure components that includes Server Infrastructure, middle ware, database and application architectures and Cloud Components. Experience/knowledge on Infra monitoring tools - NOI, Zabbix, AppDynamics, Datadog, SCOM, SolarWinds etc. and Service Management tools -IBM Control Desk, BMC Remedy, ServiceNow etc. Experience/Knowledge on BI tools Knowledge on distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc. Knowledge on other programming languages/scripting: Python, Java, JavaScript, etc. ( Added Advantage ) Good analytical skills, strong communication skills are must. Client facing experience is an added advantage. Excellent experience in understanding the problem statement, architect and designing the solution

MANDATORY SKILLS:
Significant experience with AWS cloud environments, working knowledge of Google and Azure platforms. Knowledge of Kubernetes, S3, EC2, Sagemaker, Athena, RDS and Glue is essential.
Experience provisioning computational resources in a variety of Cloud environments using Infrastructure as Code.
Experience with best practice of data transport and storage within cloud system.
Experience building large scale data processing pipelines. e. g. Spark and SQL.
Experience with containers and microservice architectures e.g. Kubernetes, Docker and serverless approaches.
Excellent working knowledge in DevOps, using continuous integration and continuous development.
Use of Data Science modelling tools e.g. R, Python, SAS and Data Science notebooks (e.g. Jupyter).
Good written and verbal skills, fluent English
DESIERED SKILLS:
Agile practices, especially being a SCRUM Master
EDUCATIONAL BACKGROUND: B.E/B.Tech/MCA

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",3.9,"AstraZeneca
3.9",Chennai,"Cambridge, United Kingdom",10000+ employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Roche, GlaxoSmithKline, Novartis"
1043,DATA ENGINEER,"JOB DESCRIPTION
As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements, and also research new uses for data acquisition. You should also know the ins and outs of the industry such as data mining practices, algorithms, and how data can be used.

DESIRED CANDIDATE PROFILE
An ideal candidate must possess prior experience leading a project.

Candidates must have:
> Experience in Hive, Spark, Scala, AWS DynamoDB, HBase, AWS Glue, Talend, Kafka, Snowflake ETL
> Strong experience in a BI/Data Warehouse environment with involvement in design, development, implementation, troubleshooting and support of ETL process using ETL tool.
> Experience in developing Data Marts, Data warehousing and Operational Data Store (ODS) on any of the databases or Hadoop environments.
> Experience in database like MS SQL, MySQL, Oracle, PostgreSQL
> Good to have programming experience in writing Complex Stored Procedures, Queries, Views, User Defined Functions, Cursors and Common Table Expressions using SQL or T-SQL.
> Experience in Performance Tuning and Query Optimization by Indexing, Partitioning and De-normalization.
> Experience in Developing a framework for ingesting data into Data lake
> Good database knowledge, analytical thinking
> Design, construct, install, test and maintain data management systems.
> Build high-performance algorithms, predictive models, and prototypes.
> Develop set processes for data mining, data modeling, and data production.
> Experience with cloud services: AWS (EC2, EMR, S3, Athena) and scripting languages like Python, /PySpark/R/SAS
> Install/update disaster recovery procedures.
> Experience in Agile Application Development & Scrum methodologies is preferred
> Ability to supervise and mentor junior developers on the team.
> Must be self-motivated and work well pulling people together in addition to being able to pull people together technically
> Demonstrated proficiency of troubleshooting techniques and detail-oriented problem diagnosis
> Ability to handle responsibility, is self-directed, with strong organizational and documentation skills
> Ability to work independently and efficiently under aggressive deadlines to meet project commitments
> Excellent verbal and written communication skills

EDUCATION
UG - B.Tech/B.E. - Computers, Electronics/Telecommunication, Diploma - Computers, Electronics/Telecommunication, B.Sc - Computers, BCA - Computers) AND (PG - M.Tech - Computers, Electronics/Telecommunication, MCA - Computers, M.Sc - Electronics, Computers) AND ( Doctorate - Any Doctorate - Any Specialization, Doctorate Not Required).

OTHER DETAILS
Number of vacancies: 4
Experience: 3 years
Location: Cochin

If you have a passion towards technology and coding, then we have the right job for you. Kindly forward your resumes to
Email: jobs@mjsofttech.com
Phone: 0484-2421245 / 928 720 7160",4.0,"MJ Softtech
4.0",Kochi,"Cochin, India",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
1044,Data Engineer,"Education/ Experience and Skill Requirement
4+ years of relevant experience in
Experience working with both relational and NoSQL databases.
Strong coding skills; Python (preferred) /R/Java/Scala
Experience in developing Data warehousing technologies Experience with AWS or equivalent cloud services preferred
Experience in BigData technologies (Hadoop, HDFS, MapReduce, Spark, Hive, HBase etc) will be valuable
Knowledge of Machine Learning a big plus (Random Forest, Decision Trees, SVM, NLP, Gradient Boosting, Supervised/Unsupervised Learning, Clustering, classification and regression modeling).
Responsibilities
Proficiency with several years’ experience in more than one of Python, R, Java, Scala, or robust Linux shell scripting
Implementation experience with data warehouse architecture & design, ETL design/development, and Analytics
Knowledge of general cloud architecture and cloud strategies especially around AWS services and concepts such as S3 object stores, RDS databases, EC2, Glacier, Lambda, IAM, enterprise security, data security, DevOps, replication and disaster recovery
Well versed with data mining & exploration, NLP and visualization
Understanding of data modeling, data integration, and data representation (metadata, OWL, ontologies)
Developing data marts and data management using SQL
Creating powerful visual outcomes
Independently manage daily client communication, especially over calls
Manage client deadlines, ensure quality of the deliverables, attention to detail
Experience/understanding of corporate finance data from company filings is desirable",3.6,"Copal Partners
3.6",Bengaluru,"New York, NY",10000+ employees,1900,Company - Public,Financial Analytics & Research,Finance,₹100 to ₹500 billion (INR),-1
1045,Data Engineer,"Job Description / Responsibilities
Build workflows to ensure data extraction quality and storage into our backend data store
Architect, build and train ML/AI models that can predict outcomes and report on anomalies.
Design data pipelines to perform ETL on content/data from multiple types of source systems.
Create data analytics views using RDBMS/Key-Value stores, on private and public/cloud
Create software that is well tested, maintainable, extensible and scales out with large data

Minimum Qualifications:
2+ years of software development with Python
2+ years of SQL (MySQL/Postgres) and Key-Value databases
1+ years of experience with scikit
2+ years of experience in data extraction, data transformation using custom Python/Java
Experience working with MapReduce/Hadoop/kafka/Elastic stack
Experience with Node backend and React/Redux
Experience working with git/mercurial, Amazon/Google cloud, Linux/LAMP stack
Experience in testing or test driven development
Experience with Data science and Machine Learning algorithm development

Location:
Hyderabad/Bangalore

Package:
Highly competitive to match experience and capability",3.7,"TVS
3.7",Bengaluru,"Chennai, India",5001 to 10000 employees,-1,Company - Private,Accounting,Accounting & Legal,₹100 to ₹500 billion (INR),-1
1046,Data Engineer,"Permanent position with US based client of iFlex.
Work Location: Bangalore
Experience Level: 2+ Years

Role:
As part of our global team you will work on the data platform reporting to the Data Engineering Lead. Your role includes specification, development, test and rollout of features on our data platform. You are expected to contribute to the vision, understand our product roadmap, integrate business value andclient experience and contribute to build an engineering culture within the team. This initiative is of critical important to the success of the organization and our roadmap, for instance, services like liquidity analytics, billing, client onboarding, reporting and others will rely on the data platform. Accurate, granular, complete and timely data will be our key differentiating factor and competitive advantage in the market place. We expect the successful candidate to deliver high quality software and to be passionate about data engineering..

Responsibility / Qualification:
Managing multiple tasks and use sound judgment when prioritizing.
Collaborating with global cross functional team in building customer-centric products.
Analyzing existing software implementations to identify areas of improvement and provide deadline estimates for implementing new features.
Updating and maintain documentation for team processes, best practices and software runbooks.
Establishing trusted partnerships with peers, product heads, and executive level stakeholders.
We are looking for someone who is passionate about technology and engineering.
Exceptional analytical skills and ability to apply knowledge and experience in decision-making to arrive at creative and commercial solutions.
Ability to leverage technology to deliver business value.
You are independent and comfortable in a fast paced, ambiguous and often multi-directional work environment.

Preferred Qualifications:
B.S. or higher in Computer Science.
Minimum 2 years of relevant professional experience using a modern programming language (preferably Java/Scala).
Experience leveraging test driven development technics.
Comfort with Agile operating models.
Team oriented.
Strong interpersonal and communication skills.
Energetic, self-directed, and self-motivated.
Experience with microservice architecture.
Experience with Kafka, MongoDB, Hadoop, Cassandra.
Experience with AWS.
Experience in Financial Services or Fintech.",-1,IFLEX,Bengaluru,"Moscow, Russia",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1047,CIEL/SEL/1941: Sr data scientist,"Mandatory skills required -
Databases (SQL, Oracle, Any RDBMS) - Should have working knowledge of atleast one database
PL/SQL Programming Languages
R, Python (Any One)
Inferential Statistics - Hypothesis, p-value, R2, RMSE, MAPE etc
Exploratory Data Analysis
Machine Learning Algorithms - Should have in-depth knowledge and implementation of atleast one algorithm

Responsibilities
: Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the why & how of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions

Education
Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics
Experience
Minimum years of related experience required: 3 years
Preferred years of experience: 5 years
Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desirable.

Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
1048,Data Engineer,Data Engineer,3.6,"Bookmyshow
3.6",Mumbai,"Mumbai, India",1001 to 5000 employees,2007,Company - Private,Ticket Sales,"Arts, Entertainment & Recreation",Unknown / Non-Applicable,-1
1049,Data Analyst,"Required Skills & Experience

We are looking for a Data Analyst Executive
Eligible Qualifications : B. Tech, BCA, M.Tech, MCA
Experience : 3-5 years, fresher’s can also be considered
Location of Job : Gurgaon/Connaught Place, New Delhi
Technicals Skills

Following technical skills are pre-requisite:
Well versed with Software development methodologies, such as SDLC (Software Development Life Cycle), DDLC (Document Development Life Cycle).
Database schema design and implementation
Should have worked in either of technologies Sql Query/ Tableau/ Excel (Macros)/ Access (Query) writing for data analytics.
For planning and coordinating activities, organizations remain in invariant communication with one another and the data transfer has to be performed efficiently and smoothly as possible.
He/ She should manage the execution of the technologies, help the businesses in utilizing the systems, and should be well versed with the basics of computer systems such as Networking, Installation of necessary software and hardware.
Ability to determine the interrelationships between solutions and requirements.
Ability to think analytically and should be a problem solver and logic building should be very strong.
Good interpersonal skills to form effective working relationships with people at all levels.
Excellent communication and presentation skills and strong written & oral English skills.
To know more about us visit us www.sspl.net.in or write to us at admin@sspl.net.in",-1,Substratal Solutions,Connaught Place,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1050,Artificial Intelligence Scientists,"Experience 2- 4 Years
Salary 4 LPA - 6 LPA
Job Location Chennai

Industry:
IT-Software / Software Services

Keywords:
Artificial Intelligence

About Job:
Must have Excellent knowledge in AI / Machine learning (Mandatory).
Machine learning frameworks like keras, tensor flow etc.
And also other big data tools like Hadoop etc, Must know R and python.
Good understanding in SDLC & Business cycle.",4.0,"Careerera
4.0",Chennai,"Wayland, MA",501 to 1000 employees,-1,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
1051,Senior Data Engineer,"About Us

upGrad is an online education platform building the careers of tomorrow by offering the most industry-relevant programs in an immersive learning experience. Our mission is to create a new digital-first learning experience to deliver tangible career impact to individuals at scale. upGrad currently offers programs in Data Science, Machine Learning, Product Management, Digital Marketing, and Entrepreneurship, etc. upGrad is looking for people passionate about management and education to help design learning programs for working professionals to stay sharp and stay relevant and help build the careers of tomorrow.
upGrad was awarded the Best Tech for Education by IAMAI for 2018-19
upGrad was also ranked as one of the LinkedIn Top Startups 2018: The 25 most sought-after startups in India
upGrad was earlier selected as one of the top ten most innovative companies in India by FastCompany.
We were also covered by the Financial Times along with other disruptors in Ed-Tech
upGrad is the official education partner for Government of India - Startup India program
Our program with IIIT B has been ranked #1 program in the country in the domain of Artificial Intelligence and Machine Learning
About the Role

We are looking for a Data Engineer to help us scale the existing data infrastructure and in parallel work on building the next generation data platform for analytics at scale, machine learning infrastructure and data validation systems.
In this role, you will be responsible for communicating effectively with data consumers to fine-tune data platform systems (existing or new), taking ownership and delivering high performing systems and data pipelines, and helping the team scale them up, to endure ever growing traffic.
This is a growing team, which makes for many opportunities to be involved directly with product management, development, sales, and support teams. Everybody on the team is passionate about their work and we’re looking for similarly motivated “get stuff done” kind of people to join us!

Roles & Responsibilities
Engineer data pipelines (batch and real-time ) that aids in creation of data-driven products for our platform
Design, develop and maintain a robust and scalable data-warehouse and data lake
Work closely alongside Product managers and data-scientists to bring the various datasets together and cater to our business intelligence and analytics use-cases
Design and develop solutions using data science techniques ranging from statistics, algorithms to machine learning
Perform hands-on devops work to keep the Data platform secure and reliable
Skills Required
Bachelor's degree in Computer Science, Information Systems, or related engineering discipline
6 + years’ experience with ETL, Data Mining, Data Modeling, and working with large-scale datasets
6+ years’ experience with an object-oriented programming language such as Python, Scala, Java, etc
Extremely proficient in writing performant SQL working with large data volumes
Experience with map-reduce, Spark, Kafka, Presto, and the ecosystem.
Experience in building automated analytical systems utilizing large data sets.
Experience with designing, scaling and optimizing cloud based data warehouses (like AWS Redshift) and data lakes
Familiarity with AWS technologies preferred
Qualification – B.Tech/M.Tech/MCA(IT/Computer Science)

Years of Exp – 6-9",3.5,"upGrad Education Private Limited
3.5",Mumbai,"Mumbai, India",501 to 1000 employees,2015,Company - Private,Education Training Services,Education,₹1 to ₹5 billion (INR),"Udacity, General Assembly, Springboard"
1052,BBRC-Genomics-Associate Scientist,"JOB DESCRIPTION

Designation: Associate Scientist

Job Location: Bangalore

Department: Translational Medicine- Translational Sciences

About Syngene

Incorporated in 1993, Syngene International Ltd. is an innovation-focused global discovery, development and manufacturing organization providing integrated scientific services to the pharmaceutical, biotechnology, nutrition, animal health, consumer goods and specialty chemical industries around the world. Syngene’ s clientele includes world leaders such as Bristol-Myers Squibb, Baxter, Amgen, GSK, Merck KGaA and Herbalife. Its innovative culture is driven by the passion of its 4240- strong team of scientists who work with clients from around the world to solve their scientific problems, improve R&D productivity, speed up time to market and lower the cost of innovation .

Job Purpose:
To play a key role in TM-TS, develop an early-stage research strategy, initiate and lead discovery programs while managing ongoing programs in TM-TS. The role will work part of TMTS, and work with internal and external collaborators .

Key Responsibilities:
Experience in isolating DNA and RNA from blood, tissues and FFPE samples and cell lines. Experience with optimization of extraction protocols and for parameters like yield, input sample quantities and sample types is important.
Expertise in PCR, qPCR, cDNA/gDNA library preparation. Exposure to microarray techniques.
Proficiency in preparation of libraries for Next Generation Sequencing of transcriptome and genome, with significant experience in optimization of parameters like input RNA/DNA quantities and sample type
Experience with single cell RNA-seq will be plus.
Experience with various NGS protocols (DNA Amplicon based, hybrid capture based low input, degraded DNA and RNA samples e.g. FFPE samples.
Strong understanding of experimental design and statistical principles behind experimental design and differential gene expression. Experience with analysis of single cell RNA-sequencing data will be a plus

Educational Qualification:
M.Sc or M. Tech in Biotechnology, Molecular biology or Biological Sciences,

Technical/functional Skills:
DNA/ RNA Isolation, Expertise in PCR, qPCR, Experience in NGS protocols

Experience:
2 to 5 Years

Behavioral Skills:
A proactive team player.
Ensure completion of experiments and generate accurate and reproducible data from experiments.
Ability to work independently, prioritize tasks and work on multiple projects simultaneously with; comfortable working in a dynamic environment with changing requirements.
Good oral and written communication and presentation skills to work in a multi-disciplinary team
Equal Opportunity Employer:
It is the policy of Syngene to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by applicable legislation or local law. In addition, Syngene will provide reasonable accommodations for qualified individuals with disabilities.",3.5,"Syngene
3.5",India,"BENGALURU, India",1001 to 5000 employees,1994,Unknown,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1053,Applied Scientist 1,"Position Requirements:
Master's degree in Computer Science, Computer or Electrical Engineer, Mathematics, or a related field plus at least one year of experience in the job offered or related occupations of Software Engineer, Software Developer, or a related occupation. Employer will accept a Bachelor’s degree and five years of experience in the job offered or a related occupation as equivalent to the Master’s degree and one year of experience. One year of experience in the job offered or related occupation must involve designing and developing large-scale, multi-tiered, distributed software applications, tools, systems and services using Java, Object Oriented Design and Distributed Programming].

Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, Oracle/Berkeley databases, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills

Amazon Selling Partner Services team drives the Selling On Amazon business and develops solutions that enable millions of sellers around the world to sell on Amazon's Marketplaces. More than half of shipments for Amazon customers are generated from this business. The team is focused on building a technology platform that will support the explosive business growth in existing markets, streamline the business for Amazon and the Selling partners and launch business in new markets and establish a fair marketplace.

Our team is seeking engineers with broad technical skills to help us optimize how we synthesize massive amounts of data and complex business rules into mission critical financial information. As a member of this team you will employ object oriented techniques in Java, and DynamoB, PostGres and ElasticSearch skills to help us support Amazon's next generation of selling partner services. Along the way you'll gain and leverage a unique understanding of how Amazon.com works; from the numerous software systems that comprise the website's back-end, to the details of our business model, and the relationships we're establishing with an ever-growing network of selling partners who depend on Amazon.com to run their businesses.

The ideal candidate will draw upon exemplary analytical, critical thinking, and problem solving skills, and a passion for maintaining highly reliable, distributed systems which operate 24/7/365. Successful members of this team collaborate effectively with internal end-users, aggressive cross-functional software development teams, and technical support/sustaining engineering teams to solve problems and deliver successfully against high operational standards of system availability and reliability. We look for engineers who are excellent communicators, self-motivated, flexible, hardworking, and who like to have fun!

Position Responsibilities:
Participate in the design, development, implementation, testing and documentation of large-scale, multi-tiered, distributed software applications, tools, systems and services using [Java, Object Oriented Design and Distributed Programming]. Translate functional requirements into robust, scalable, supportable solutions that work well within the overall system architecture. Participate in the full development cycle, end-to-end, from design, implementation, and testing to documentation, delivery and maintenance. Produce comprehensive, usable software documentation. Evaluate and make decisions around the use of new or existing software products and tools.

Preferred Qualifications
Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1054,Senior Clinical Data Analyst,"About Novotech:

Novotech is internationally recognised as the leading independent and full-service contract research organisation (CRO) in the Asia Pacific region. We provide a wide range of clinical development services across all research phases and therapeutic areas and have been instrumental in the success of hundreds of Phase I – IV clinical trials throughout the Asia Pacific. Powered by the highest quality people, Novotech strives to set the benchmark for both business and clinical trial performance. Our people are one of our key strengths. We value our people and recognise the work they do. We are lucky to have the best people and talent from across the Asia Pacific region work together to deliver to clinical trial success for our clients. Our people and those we look to recruit have an attitude of making things happen. They are problem solvers, driven with a focus on delivering quality, accountability and a high level of performance.

Brief Position Description:

As part of Novotech’s Biometrics unit, the Senior Data Analyst (SDA) is responsible for all data analysis and business intelligence activities related to study related clinical and operational data. The SDA acts as primary point of contact for all data analysis matters to the study team and is responsible for the timely delivery of quality outputs following all applicable regulatory, compliance, best practice and operational procedures.

Minimum Qualifications & Experience:

Graduate in information science, data science or life science-related field, or similar. More than five years’ experience in a senior role related to data science, data analysis, clinical data management or clinical data programming in a pharmaceutical company, CRO or EDC software provider.

Responsibilities
The Senior Data Analyst (SDA) is responsible for providing technical, procedural (SOPs) and planning leadership across multiple projects assigned to the data analyst team members ensuring that they deliver in accordance with SOPs, programming best practices, and the timelines agreed within the Project Team.
Collaborate with cross-functional stakeholders to implement data science solutions to solve business needs using available technological solutions.
Scope data analysis effort for projects and project manage all data analysis activities across multiple projects for different study stakeholders.
Gather study requirements from data management for data review and external data reconciliation and provide guidance on appropriate outputs (dashboards, visualisations, listings, reports).
Extract, assess, integrate, transform data sources to provide data visualisation outputs for analytics.
Design and develop prototypes and final versions of data outputs (dashboards, reports, visualisations, listings) using Business intelligence tools and Data Visualisation tools.
Design and develop standard dashboards and content for different audiences.
Analyse, manipulate and understand data from multiple sources to present and create dashboards and reports to make business decisions.
Assist teams on best-practice for data visualisation dashboard development.
Educate teams on how to use all the features of applicable data visualisation platform in conjunction with data visualisation dashboards.
SME for the data visualisation development and assisting team members.
Identify and communicate project risks and maintain documentation within project files as appropriate
Represent data analysis group at internal / external meetings as appropriate.
Assess and implement new data analysis, BI and data visualisation processes and technologies.
Take an active role in the development of best practices, process improvement, quality control and governance related to all data analysis matters.
Provide training and mentoring to Data Analysis of team members in SOPs, software applications, and best practices.
Provide Subject Matter Expertise on all data analysis and visualisation related activities.
Attributes and Skills

Expert knowledge of clinical study data structures and schemas of EDC databases. Expert knowledge in data processing activities such as extracting, integrating, transforming and presenting data. Statistical Programming skills in Python, R or similar. Knowledge of SQL and EDC systems. Working knowledge of Spotfire, Power BI, Tableau or other data review and visualisation tool. Ability to gather business requirements from multiple stakeholders and clients and provide guidance on the use of appropriate data visualisations.

Experience mentoring and training others. Awareness of regulatory and compliance issues and understanding of the application of SOPs and Quality Control to daily activities. Excellent analytical, communication and problem-solving skills.

Opportunities and Benefits:

To deliver clinical trial and research excellence for our clients, our people are 'best in class'.

At Novotech, we seek and nurture people with exceptional talent. We are committed to providing our people with regular internal and external training, a competitive bonus structure and a supportive work environment. We are also focused on providing our people with a wide variety of career growth and development opportunities.

For more information about where your next career step at Novotech might take you, visit http://novotech-cro.com/novotech-careers",4.5,"Novotech
4.5",Bengaluru,"Sydney, Australia",501 to 1000 employees,1996,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
1055,Data Engineer,"Data Engineer Responsibilities:
Liaising with coworkers and clients to elucidate the requirements for each task.
Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed.
Reformulating existing frameworks to optimize their functioning.
Testing such structures to ensure that they are fit for use.
Preparing raw data for manipulation by Data Scientists.
Detecting and correcting errors in your work.
Ensuring that your work remains backed up and readily accessible to relevant coworkers.
Remaining up-to-date with industry standards and technological advancements that will improve the quality of your outputs.
Data Engineer Requirements:
Bachelor's degree in Data Engineering, Big Data Analytics, Computer Engineering, or related field.
Master's degree in a relevant field is advantageous.
Proven experience as a Data Engineer, Software Developer, or similar.
Expert proficiency in Python, C++, Java, R, and SQL.
Familiarity with Hadoop or suitable equivalent.
Excellent analytical and problem-solving skills.
A knack for independent and group work.
Scrupulous approach to duties.
Capacity to successfully manage a pipeline of duties with minimal supervision.
Job Type: Full-time

Salary: ₹360,000.00 to ₹870,000.00 /year

Experience:
total work: 2 years (Preferred)
Data Engineer: 1 year (Preferred)
Education:
Diploma (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,Futurious Technologies,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1056,Quantitative Analyst,"The successful candidate will be a highly analytical individual with hands on programming skills. The candidate will work closely with the research team and clients towards the ongoing development and integration of new investment strategies, models and tools on Axle

Location

Mumbai
Responsibilities

Perform daily/weekly/monthly tasks of performance and risk reporting
Develop and automate investment processes and strategies via VBA and Matlab
Develop tools to integrate trading decision systems with risk management systems
Ad hoc tasks (such as operational tasks, internal documentation tasks and preparation of marketing materials)
Skills/Experience

Excellent programming skills in Matlab/Excel-VBA
Thorough with financial concepts and calculations like Drawdown, VaR, Eloss etc.
Understanding of financial market products like options, futures, FX forwards etc.
Working knowledge of Bloomberg is preferred
Should be self-driven and detail oriented with an analytical mindset
Should be a proactive and quick learner; a team player showing enthusiasm and drive to accomplish results in a fast paced environment
Min. 2 years of relevant work experience
Qualifications

B.Tech/M.Tech/MBA/CFA/FRM",5.0,"B&B Analytics
5.0",Mumbai,"Zug, Switzerland",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1057,Analyst - Data Scientist,"Job Summary

Experience:
3 - 5 Years

Location:
Mumbai

Designation:
Analyst - Data Scientist

Degree:
BE-Comp/IT, BE-Other, BTech-Comp/IT, BTech-Other, ME-Comp/IT, ME-Other, MTech-Comp/IT, MTech-Other, PhD-Comp/IT, PhD-Other

Educational Level:
Graduate/Bachelors

Industrial Type:
IT-Software/Software Services

Functional Area:
IT Software - Application Programming / Maintenance

Key Skills:
Data Scientist

Job Post Date:
Thursday, March 19, 2020

Company Description

We are capability centre based in Mumbai, initially started as a back-office operational support to the UK business unit.

However, over the recent years, we have significantly increased the breadth and depth of our capabilities and offerings to keep pace with the changing needs of the Group. These include Digital & Knowledge Services, Finance and Actuarial, Information Technology (IT), Customer Service, Risk and Audit.

Our core purpose is to be a strategic partner to company, enabling growth by delivering change and driving synergies through a highly capable and agile workforce.

With our diversified service offerings we provide our people with exciting opportunities to grow personally and professionally.

Company is a leading savings and investments business serving around 5.5 million retail customers and more than 800 institutional clients.

It-s innovative asset management and customer solutions are supported by extensive investment capabilities, an international distribution network and two strong brands.

Job Description

3 – 5 yrs experience as Data Scientist
Should have at-least 1 end-to-end ML project experience
Very high proficiency in R or Python
Excellent in forecasting methods like simple exponential smoothing, multiplicative seasonal indexes, simple and weighted moving averages and time series forecasting methods
Exposure to with advanced deep learning techniques such as LSTM. CNN, Dense neural networks as well as neural networks design and implementation through tools like tensorflow, keras, pytorch, deepai or equivalent.
Good SQL experience",3.8,"Sampoorna Computer People
3.8",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
1058,Data Lake Developer,"For Us, It's A Mission

At Mylan, we mean it when we say we work every day to provide access to high quality medicines to the world's 7 billion people. If you are unconventional, relentless and passionate. If you believe in doing what's right, not what's easy. If you are a doer and have a passion for serving others, we want to talk to you.

Make a Difference

At Mylan, each person has the ability to make a difference. From the providers who sell and market our products, to the producers who develop and manufacture them and finally to our business partners who support the providers and producers, we all have a mission critical role. Here's how this role will help:

ESSENTIAL DUTIES AND RESPONSIBILITIES
To perform this job successfully, an individual must satisfactorily perform each essential duty. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential duties.
1. Create and maintain optimal data pipeline architecture on Azure platform.
2. Develop batch processing solutions by using Data Factory and Azure Databricks.
3. Delivering a Data Warehouse in the Azure Cloud.
4. Design relational and non-relational data stores on Azure.
5. Identify, design, and implement internal process improvements : automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc..
6. Developing Big Data Solutions with Azure Machine Learning.
7. Strong interaction with business departments to provide consultative support for digitization efforts, as well as close collaboration with the Business Technology management, focused on future innovation topics.
8. Participate and lead in design sessions, demos and prototype sessions, testing and training workshops with business users and other IT colleagues.
9. Design & Build for any API Development or SQL DB development.
10. Providing service management, orchestration, monitoring and management requirements of Azure cloud platform.
11. Create data tools / products for analytics and data scientist team members that assist them in building and innovative solutions that drive tangible business value.
12. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
13. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
14. Design security for source data access. Chose the appropriate authentication mechanism, (ie Azure Active Directory (Azure AD), etc).
15. Design for real-time processing by using Stream Analytics and Azure Databricks.

Make Our Values Your Values

Mylan hires only the best. People who thrive in a culture of innovation and empowerment. People who are active learners and have a positive attitude. People who are leaders and know that by working together we can run faster, reach higher and achieve more. By doing so, we will continue to set new standards in health care. Here are the minimum qualifications and essential functions for this position:

QUALIFICATIONS

The qualifications listed below are representative of the minimum knowledge, skill, and/or ability required.

SKILLS AND ABILITIES

1. 10 years of experience in Microsoft technologies including SQL.

2. At least 5 years as a Sr Developer with at least 3 years hands on experience as Azure Data Engineer building large scale Azure data solutions.

3. At least 5 years of experience in Azure based data solutions.

4. At least 3 years of experience on working with large projects including the most recent project in the cloud (Azure) or on prem with a focus on Azure Data services.

5. At least 5 years of Hands-on administration, configuration management, monitoring, performance tuning of Hadoop/Distributed platforms.

6. At least 5 years of demonstrated experience at least in the most recent 2 years of designing and delivering solutions using Cortana Intelligence suite of analytics services part of Microsoft Azure including Azure Machine Learning Studio, HDInsight, Polybase, Azure Data Lake Analytics, Azure Data Warehouse, Streaming Analytics, Data Catalog, R/R Studio

7. Experience in designing and building logics required for optimal extraction, transformation, and loading of data from a wide variety of data sources

8. Experience within Data Security design, including but not limited to:

a. Choosing the appropriate authentication mechanism, such as Azure Active Directory (Azure AD)

b. Defining strategies for data encryption for data at rest and in transit

9. Experience partnering with Business Analysts and Data Scientists to enable effective and efficient data preparation and delivery

10. Experienced in vendor management and working with 3rd parties onshore & offshore.

11. Experience working in a global team.

12. Experience working in an Analytics / Big Data solutions on MS Azure Cloud

13. Experience with code management tools, automated testing

14. Experience creating and maintaining optimal data pipeline architecture on Azure platform

15. Experience developing batch and real-time processing solutions by using Data Factory and Azure Databricks

16. Familiar with AGILE and Azure DevOps methodology

17. Hands on PoC capabilities are needed to prove a particular architecture concept

18. Azure Native Services experience across Data Fabric and Service Fabric

19. Experience in Application modernization from legacy on-premise data architecture platform technology stack to modernized Azure Cloud base Architecture.

20. Experience with Git, NoSQL Data Solutions, Microsoft Azure, HD Insights, Azure ML, DataBricks ML Flow, R or Python.

21. Must have excellent communication skills.

EDUCATION/EXPERIENCE (Note: Please select one)

Minimum of a Bachelor's degree in Computer Science and Engineering is preferred with minimum 10 years of experience. However, a combination of experience and/or education will be taken into consideration

Why Mylan?

If you want to be part of a global health care company that is making a difference and changing lives, Mylan may be the place for you. With a workforce of more than 35,000 worldwide, we can make a difference. We encourage you to visit Mylan.com to learn more about our unconventional culture, our approach to doing business and how we plan to set new standards in health care.

Mylan offers competitive salary, excellent benefits and an environment conducive to professional growth and advancement. All qualified applicants will receive consideration for employment without regard to their disability or protected veteran status. Mylan is an Equal Opportunity Employer, Minorities/Female/Disabled/Veteran.",3.8,"Mylan Inc.
3.8",Bengaluru,"Hatfield, United Kingdom",10000+ employees,1961,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1059,Off Campus Recruitment - Quantitative Researcher,"Description:
Graviton is a privately funded quantitative trading firm striving for excellence in financial markets' research. We are seeking fresh talent from the top IIT's to join us as Quantitative Researchers for our team in Gurgaon.If you are a student graduating in 2020 from Computer Science , Electrical or Maths Stats Computing streams with a greater than 8 CGPA please apply here.

This role is open to students from campuses that we could not visit this year. Please check your individual placement policy restrictions before applying.

Graviton trades across a multitude of asset classes and trading venues using a gamut of concepts and techniques ranging from time series analysis, filtering, classification, stochastic models, pattern recognition to statistical inference analysing terabytes of data to come up with ideas to identify pricing anomalies in financial markets.

As a Quantitative researcher your responsibilities will include

Develop new or improve existing trading models using in-house platforms

Use advanced mathematical techniques to model and predict market movements

Analyse large financial datasets to identify trading opportunities

Provide real time analytical support to experienced traders

Requirements :
Possess a degree in a highly analytical field, such as Engineering, Mathematics, Computer Science from IITs schools

Quantitative bend of mind

A working knowledge of Linux/Unix

Programming experience, preferably in C++ or C

Strong interest in learning about financial markets.

Have a strong work ethic

Hard Working

Benefits:
Our open and casual work culture gives you the space to innovate and deliver. Our cubicle free offices , disdain for bureaucracy and insistence to hire the very best creates a melting pot for great ideas and technology innovations. Everyone on the team is approachable, there is nothing better than working with friends!

Our perks have you covered.

Competitive compensation

6 weeks of paid vacation

Monthly after work parties

Catered breakfast and lunch

Fully stocked kitchen

Gym membership

International team outing",5.0,"Graviton Research Capital LLP
5.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2014,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1060,Data Engineer,"Zauba Technologies is a startup based in Bangalore. Zauba's services are used by leading companies in India. Zauba is powered by a young and passionate team. We are looking for individuals who would like to be a part of our founding team.

As a Data Engineer and as a part of founding team, you will be expected to visualise and develop disruptive data products. Eventually you would be responsible for entire project lifecycle of products you would visualize. Your rewards will be directly proportional to the value you generate.

Job Responsibilities
Design and development of robust, scalable and highly efficient data engineering solutions for structured and unstructured data (Including gathering and processing raw data at scale, writing scripts, web scraping, calling APIs, writing SQL queries, etc.)
Develop processes for text mining and extraction of information from unstructured data
Design, architect and develop efficient data pipelines around the data collected
Take ownership of existing web product and applications
Design and implement data models that scale across the enterprise
Take ownership of existing data workflows and processes
Enhance scalability, performance, and stability of existing infrastructure
Work closely with other team members to integrate your innovations and algorithms into our production systems

Essentials
Java/Python - Intermediate to advanced level
SQL - Advanced
MySQL Intermediate to advanced level
Regex - Basic to intermediate level
Linux Basic to intermediate level

Good to have
Hadoop/Spark
R
MongoDB

Must have qualities
Skills to learn new skills quickly
Desire to create disruptive products and services
Passion - not just to work in startups but to take them to next level
Above average programming aptitude
Be passionate about producing high quality engineering deliverables
Be productive working independently or collaboratively
Have an eye for building efficient processes
Be self motivated
Proactively take ownership

Interested?

Send your resume to hr@zaubacorp.com",3.8,"Zauba Corp
3.8",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 million (INR),-1
1061,Quantitative Research,"We are looking for highly trained professionals who are interested in applying advanced mathematical quantitative methods to the modeling of global financial markets. You would be joining a group made up of highly proficient individuals from various scientific disciplines. We have a spectrum of opportunities for individuals with the right scientific skills. Experience in finance is not required.

The ideal research candidate will have:
A Ph.D. in Computer Science, Mathematics, Physics, Statistics, or a related technical discipline.

A demonstrated capacity to do first-class research.

Computer programming skills.

An intense interest in applying quantitative analysis to solve difficult problems.

Send us a copy of your resume to
careers@dolatcapital.com

For internship opportunities, please send us a copy of your resume to
careers@dolatcapital.com",4.0,"Dolat Capital
4.0",Mumbai,"Mumbai, India",51 to 200 employees,1970,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1062,Data Engineer,"Bachelor’s degree in Computer Science or related field
5+ years relevant experience
5+ years experience with SQL, SQL Tuning, Oracle, OLAP, Big Data Technologies
5+ years experience developing end-to-end Business Intelligence solutions: data modeling, ETL and reporting
Experience with Java and experience with scripting languages like Perl, Python, Unix shell scripts,VBA and MS Excel
Proficiency with Linux and systems administration
Proven ability at looking at solutions in unconventional ways. Sees opportunities to innovate and can lead the way.
Top notch communication (verbal and written) and interpersonal skills to convey key insights from complex analysis in summarized business terms and an ability to effectively communicate with technical teams.
Ability to work with shifting deadlines in a fast paced environment.
Operations Finance Technology team, responsible for building technical solutions for multi-billion WW Operational Cost analytic including Inbound cost (Receiving / PO), variable Cost, fixed cost, outbound (Customer Shipments / Transportation), and Customer Service, is looking for a Data Engineer.

As a data engineer, you will get the exciting opportunity to work on very large data sets in one of the world's largest and most complex data warehouse environments. You will work closely with the business teams in analysis on various cost savings initiatives, many non-standard and unique business problems and use creative-problem solving to deliver actionable output.
You will be responsible for designing and implementing an analytical environment using third-party and in-house reporting tools, modeling metadata, building reports and dashboards. You will have an opportunity to work with leading edge technologies like Redshift, Hadoop/Hive/Pig. You will be writing scalable queries and tuning performance on queries running over billion of rows of data.

You should be analytical, have an extremely high level of customer focus and a passion for process improvement. You should be motivated self-starter that can work independently in a fast paced, ambiguous environment. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions.
Bachelors in Computer Science or related field
Practical Knowledge of Linux or Unix shell scripting
Experience in working with business customers to drive requirements analysis
Exposure to large databases, BI applications, data quality and performance tuning
Excellent written and spoken communication skills
Experience with Hadoop-based technologies such as HBase, Pig, Hive and Spark
Strong proven ability in building high-performance, highly available and scalable data solutions using Oracle and/or Hadoop-based technologies
Knowledge of data warehousing concepts.
Strong sense of ownership, urgency, and drive
Strong troubleshooting and problem solving skills
Experience with Amazon Web Services",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1063,DATA ANALYST,"posted by Mahima Gaur

2 - 5 years Delhi

Job Description
Experience in data processing
Experience in data cleaning and data tabulation activities
Strong analytical, communication and team management skills
Strong understanding of data management using SPSS and research techniques
Competency in a Tabulation software (decipher / wincross / quantum etc), Excel, Powerpoint
Ability to summarize findings, draw conclusions, and put together a presentation using Powerpoint
Role Category : Data Analyst

Employment Type : Permanent Job, Full Time",4.9,"Knowledge Excel Services.
4.9",New Delhi,"New Delhi, India",1 to 50 employees,2007,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
1064,Data Engineer,"Key skills : Python , Spark , SQL , Pyspark • AWS platform used for the work • Strong experience in SQL is mandatory • Good familiarity of AWS landscape • Good experience in collecting business requirements & design them as per requirement from customer • Should able to work independently & interact business users & technical stakeholders • Strong communication skills both oral & written. • Should work as an individual resources",3.5,"Larsen & Toubro Infotech Limited
3.5",India,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1065,Big Data Engineer,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
1066,Client Data Analyst,"At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.
What is the Client Data Analyst – Client Analytics group responsible for?
This team manages business data to ensure accurate, timely, consistent and compliant data. Their contributions deliver quality data that is easily accessible and can be trusted. Key downstream capabilities such as reporting and analytics depend on this as well as operational data access on various systems. The Data Management Team is a support function that acts as an advocate and a point of contact for Sales and Marketing data.

What are the ongoing responsibilities of an Client Data Analyst ?
Understand the data flow, key consumption and production of data as well as context within the enterprise:
Build positive relationships with teams, especially the key data consumers and analytics. Take the time to increase knowledge of how they run their business and incorporate sales data into daily work
Connect regularly with each sales office to understand current issues and challenges. Probe the business and validate against other sales offices to understand the scope and priority of the issue
Make recommendations on how data unifications and flow can be used to improve business tasks. Liaise business partners to deliver solutions (reports, processes, technology) that add value.

Provide data management subject matter expertise. Appreciate the connection and data flow between applications and other corporate systems. Be able to clearly articulate the data needs and move initiatives forward by collaborating with business partners:
Actively participate in meetings with business partners to ensure that priorities are clearly understood, information is regularly shared and that key participants are “kept in the loop”
Provide context and background on issues. Collaborate on ideas for progressing initiatives. Ensure appropriate resources are involved to take initiatives forward
Provide insights and expertise to scope statements and requirements documentation
Actively consult or participate in the user acceptance testing process (test cases, documentation, testing execution, etc.)
Ensure business needs remain aligned with overall corporate initiatives and deliver the benefits as originally intended

Monitor the integrity of data and usefulness of reports. Ensure the information available within systems is accurate and up-to-date. Proactively seek data cleansing opportunities and evolve data to better support. Document and maintain ongoing processes for reporting and data clean-up:
Partner with all key data consumers to gain a solid understanding of usage and challenges around data. Establish processes for prioritization of enhancements, especially with the analytics groups
Provide 1st level support for data issues and data maintenance for owned data
Verify and execute data loads into our internal sales systems and ensure any upstream systems accurately receive their data

Increase awareness and promote data management capabilities. Share best practices and provide coaching to local offices on how to access and incorporate output into sales tasks. Encourage IAS leaders to leverage data to make more informed, strategic decisions:
Clearly articulate the goals and core services of the data management team. Proactively promote this information within IAS and ensure business partners understand the data management role within the organization
Share best practices and provides guidance on data capabilities. Reinforces ownership and accountability for data accuracy
Seek opportunities to share the benefits of leveraging sales data to make more informed business decisions

What ideal qualifications, skills & experience would help someone to be Successful?

Knowledge, Education And Experience:
Four year bachelor’s degree required (majors of preference include: business, computer science, mathematics) Advanced degree a plus
Understanding of the Franklin Templeton business model, how FT makes money, the sales process, how technology fits in with the business, etc. Knowledge of the GAS (Global Advisory Services) structure
Experience working through multiple business fiscal cycles; exposure and/or direct experience with project management and/or sales-related-capacity required
Prior work experience related to analytics, sales, marketing and/or international a must. Level will not be granted based on years of experience but will be determined by the employee’s ability to meet each job activity as outlined the ‘typical/expected focus by level
Skills And Abilities:
Ability to communicate effectively with all levels of management; ability to tailor communication style based on audience; ability to get others to want to collaborate with you; strong facilitation skills
Excellent writing skills (for presentations, documentation, etc.)
Working knowledge of the CRM, MDM, Excel, SQL, Power BI, Tableau, Business Objects, and Microsoft Products (PPT, Power Apps, Doc, Visio)
Ability to absorb and interpret large quantities of data; apply trend analysis and knowledge of the business to develop a meaningful and digestible summary with the appropriate level of detail
Ability to take a larger problem and break down the individual components; identify how to go about solving the problem and who to involve in the process
Ability to present recommended solutions to a variety of issues and problems (solutions that are consistent with organization objectives)
Must be extremely detail-oriented (managing lists, tasks/to-dos, etc.) good with follow through on own items; good with following up with others on outstanding item

What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.

Highlights of our benefits include:

Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.",3.8,"Franklin Templeton Investments
3.8",Hyderabad,"San Mateo, CA",5001 to 10000 employees,1947,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Fidelity Investments, Vanguard"
1067,Data Analyst,"Roles and Responsibilities:
Extracting, transforming and inputting data sets from various resources. Creating predictive models, translating non-technical aspects into quantifiable tasks. Analysis and representation of output data, highlight and explain trends and patterns, error elimination, using advanced statistical methods (regression, probability distribution, clusters etc.) to provide accurate results.
Data collection, Data Mining, Report generation, Problem identification and solution formulation Market analysis and establishing trends, Strategy development and implementation

Skills:
Extremely good analytical skills.
Good working knowledge of all MS-Office products, especially Advance Excel, Word, PowerPoint, MS-access.
Statistical tools and methods.

Interested candidates can send the updated resume on satish.mehra@exelaonline.com or call on 7722028636
00-7.00 Years",2.6,"Exela Technologies
2.6",Pune,"Irving, TX",10000+ employees,2017,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"SourceHOV, BancTec, Transcentra"
1068,Data Modeler,"• Minimum 5-8 years of working experience as Data modeler.
• Data modelling experience in designing.
• Minimum 2-3 years real time experience in Erwin tool is mandatory.
• Experience in normalized modeling techniques.
• Experience in designing the Start schema.
• Experience working in ORACLE.
• Experience with database design, capacity planning, performance tuning and query optimization.
• Experience in working with Bank or Banking and Finance or Financial domain.
• Excellent communication skills with leadership quality.

Job Segment:
Database, Oracle, ERP, Technology",3.5,"LTI
3.5",Mumbai,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1069,Machine Learning Engineer,"Looking for Data Scientists with Python/R Programming skills.
Specific experience in AI areas like Statistical Machine learning / Deep learning / Natural Language Processing (NLP)/ Operations Research (Optimization) will be an advantage.Individual in this role is expected to work with multiple stakeholders and teams

Qualifications and Requirements:-
Previous working experience as a Machine Learning/ Data Scientist for 2 years
MA in Computer Science or similar relevant field
Hands on experience with MALLET
In depth knowledge of Apache Tomcat/Open Source
Excellent project and time management skills
Attention to detail
Outstanding problem solving and analytical skills",-1,Tekolutions.ai,India,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1070,Data Science Internship,"About the company:
SkillBit is a leading staffing and recruitment company engaged in talent searching assignments for skilled and talented candidates for the industry.

About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Working on data science algorithms and AI concepts 2. Using Python or R for web scraping 3. Building AI models using Python, machine learning, and deep learning algorithms 4. Processing of unstructured/structured data

Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 6th Jun'20 and 11th Jul'20
are available for duration of 1 month
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply

Number of internships/jobs available: 3

Categories: Data Science",-1,SkillBit,Pune,-1,-1,-1,-1,-1,-1,-1,-1
1071,Data Engineer,"As a data engineer at TEAL, you'll be taking the plunge into a rich data lake that includes everything from satellite data to legal court orders. You'll be hustling and getting your hands dirty with every part of the data pipeline always having an implicit appreciation for how all of this data will ultimately power a revolutionary real estate risk platform.

Your day-to-day will include either all or some of the following:

Constantly scoping out new data sources to complement existing ones
Creating and maintaining distributed web scrapers using Python, RabbitMQ and other technologies
Architecting and managing data pipelines where data flows into multiple end-points including, but not limited to, Postgres, MongoDB and Apache Solr
Documenting workflows and constantly iterating to create better data infrastructure.

We'd love it if you:
Are proficient in Python or any other object-oriented language
Have worked with large (millions to hundreds of millions of rows in a SQL database) interdisciplinary datasets
Have scraped difficult websites and have some experience working with various data APIs
Are patient and methodical with unstructured and messy data
Are always hungry to learn newer and better technologies to make the data ecosystem faster, smoother and less silo-ed

Extra brownie points if you:
Have some experience working with large-scale search indexing
Have performed geospatial analyses in some capacity
Have created and managed data lakes in the cloud
Culture

To explore our culture and the values we embody click here

Testimonials
Testimonial

My experience at TEAL surpassed all my expectations from the get-go. I was asked to help solve one of the most daunting problems in the Indian real estate market. Every day while working on a subset of the problem, the ideas that I brought to the table were shaped into cohesive solutions by a collaborative team effort. At TEAL I was exposed to the most cutting edge technologies such as Cloud Computing, Big Data, ML and Data Science. The growth opportunities at TEAL are tremendous, If you are innovative and can demonstrate the will to realize your ideas, TEAL is an amazing organization to work for.
Gyan Vardhan, Data Science Intern
I had interned as a Data Scientist at Terra Economics and Analytics Lab during its early days, it was a rich learning experience working with a multi-disciplinary team who are extremely passionate about building a decision support platform for the insanely complicated realty market in India. It was exciting and challenging to work on mining huge volumes of property records; extracting patterns from the data, building data pipelines and brainstorming on building the core system. TEAL offers a very healthy work environment coupled with insanely talented people working together in an exciting setting.
Naga Anjaneyulu, Data Science Intern
I worked as a full-time Data science intern at TEAL. During this period, I got an opportunity to leverage my skillsets while also learning new technologies, working on tasks assigned to me. The company operates on the latest tech-stacks and gives opportunities to learn as much as you want. The work environment is challenging, the team at TEAL is super supportive and new ideas are always welcome. It has all the good perks of a startup; creativity and innovation, casual work atmosphere and a collaborative approach to solving problems. Personally, I loved working there, my experience was fantastic!
Archana Parmar, Data Science Intern
As a second-year college student, I was looking for an internship that would allow me to delve deeper into research and work with big data, TEAL gave me the perfect opportunity to do so, enabling me to develop proficiency in research and analysis. As a research analyst intern, I collated and cleaned data and helped in the preparation of reports and presentations, and I had members helping me at every stage of this process. This collaborative environment allowed me to cultivate my skills and also learn from my peers. The holy trinity of Rohan, Kshitij, and Shreyas served as not only excellent mentors and bosses but also as friends, helping me at every stage and giving us all food and ice cream to keep us going!
Arush Mehra, Research Intern
Internships are a crucial part of one’s early career. The internship experience at TEAL was a thrilling rollercoaster ride to say the least! It was more than implementing a standard model or building an already though out concept into reality. It was about finding the solution to a unique and open-ended problem.It was exciting to work on addressing a problem with far -reaching real world applications.Moreover, the work environment had the perfect balance of casual yet professional which kept you focused and stress free at the same time. Out of every 100 startups in India only 2 of them succeed, but there are very few like TEAL India which are bound to make it big at such an early stage.
Divyanshu Agarwal, NLP Intern",4.7,"Terra Economics & Analytics Lab (TEAL)
4.7",New Delhi,"Bengaluru, India",1 to 50 employees,2018,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
1072,Senior Consultant - ModellingOps Data Engineer,"Job Title: Senior Consultant - ModellingOps Data Engineer
Location: TRIL GTC
GCL: D1

JOB DESCRIPTION:

AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. The Science & Enabling Units IT is AZs global IT capability function supporting key business areas operating out of sites across the US, UK, Sweden, India & Mexico.

We are looking for AI Ops consultant who will leverage tools & technology best practices to improve delivery performance & data engineering capabilities in the D&A space.

ROLES & RESPONSIBILITIES:

7-10 years of experience in IT Operations involving Data Science, Artificial Intelligence-Machine Learning and Predictive Analytics. Experience in architecting and implementation of end-to-end AIOPs solutions through ELK stack, Splunk. Experience in applying statistical methods, analysis, pattern recognition and modeling on IT Operational data using ELK machine learning. Experience in extracting meaning full data from incoming data streams from different sources through RegEx, Grok etc. Hands-on experience in applying machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc in the IT Operation domain. Experience with machine learning and statistical programming languages - Python, R etc. Experience in assessing the existing IT environment and providing recommendations to reduce the critical applications impacting incidents. Experience in exploring and identifying areas where manual tasks can be automated in IT environment. Experience with various Enterprise IT monitoring solutions including Infrastructure monitoring, Application Performance Monitoring, Network Monitoring, Cloud monitoring etc. Experience in IT Service Management including Service Desk, Incident Management, Change Management, CMDB etc. Excellent knowledge on various IT infrastructure components that includes Server Infrastructure, middle ware, database and application architectures and Cloud Components. Experience/knowledge on Infra monitoring tools - NOI, Zabbix, AppDynamics, Datadog, SCOM, SolarWinds etc. and Service Management tools -IBM Control Desk, BMC Remedy, ServiceNow etc. Experience/Knowledge on BI tools Knowledge on distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc. Knowledge on other programming languages/scripting: Python, Java, JavaScript, etc. ( Added Advantage ) Good analytical skills, strong communication skills are must. Client facing experience is an added advantage. Excellent experience in understanding the problem statement, architect and designing the solution

MANDATORY SKILLS:
Significant experience with AWS cloud environments, working knowledge of Google and Azure platforms. Knowledge of Kubernetes, S3, EC2, Sagemaker, Athena, RDS and Glue is essential.
Experience provisioning computational resources in a variety of Cloud environments using Infrastructure as Code.
Experience with best practice of data transport and storage within cloud system.
Experience building large scale data processing pipelines. e. g. Spark and SQL.
Experience with containers and microservice architectures e.g. Kubernetes, Docker and serverless approaches.
Excellent working knowledge in DevOps, using continuous integration and continuous development.
Use of Data Science modelling tools e.g. R, Python, SAS and Data Science notebooks (e.g. Jupyter).
Good written and verbal skills, fluent English
DESIERED SKILLS:
Agile practices, especially being a SCRUM Master
EDUCATIONAL BACKGROUND: B.E/B.Tech/MCA

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",3.9,"AstraZeneca
3.9",Chennai,"Cambridge, United Kingdom",10000+ employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Roche, GlaxoSmithKline, Novartis"
1073,DATA ENGINEER,"JOB DESCRIPTION
As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements, and also research new uses for data acquisition. You should also know the ins and outs of the industry such as data mining practices, algorithms, and how data can be used.

DESIRED CANDIDATE PROFILE
An ideal candidate must possess prior experience leading a project.

Candidates must have:
> Experience in Hive, Spark, Scala, AWS DynamoDB, HBase, AWS Glue, Talend, Kafka, Snowflake ETL
> Strong experience in a BI/Data Warehouse environment with involvement in design, development, implementation, troubleshooting and support of ETL process using ETL tool.
> Experience in developing Data Marts, Data warehousing and Operational Data Store (ODS) on any of the databases or Hadoop environments.
> Experience in database like MS SQL, MySQL, Oracle, PostgreSQL
> Good to have programming experience in writing Complex Stored Procedures, Queries, Views, User Defined Functions, Cursors and Common Table Expressions using SQL or T-SQL.
> Experience in Performance Tuning and Query Optimization by Indexing, Partitioning and De-normalization.
> Experience in Developing a framework for ingesting data into Data lake
> Good database knowledge, analytical thinking
> Design, construct, install, test and maintain data management systems.
> Build high-performance algorithms, predictive models, and prototypes.
> Develop set processes for data mining, data modeling, and data production.
> Experience with cloud services: AWS (EC2, EMR, S3, Athena) and scripting languages like Python, /PySpark/R/SAS
> Install/update disaster recovery procedures.
> Experience in Agile Application Development & Scrum methodologies is preferred
> Ability to supervise and mentor junior developers on the team.
> Must be self-motivated and work well pulling people together in addition to being able to pull people together technically
> Demonstrated proficiency of troubleshooting techniques and detail-oriented problem diagnosis
> Ability to handle responsibility, is self-directed, with strong organizational and documentation skills
> Ability to work independently and efficiently under aggressive deadlines to meet project commitments
> Excellent verbal and written communication skills

EDUCATION
UG - B.Tech/B.E. - Computers, Electronics/Telecommunication, Diploma - Computers, Electronics/Telecommunication, B.Sc - Computers, BCA - Computers) AND (PG - M.Tech - Computers, Electronics/Telecommunication, MCA - Computers, M.Sc - Electronics, Computers) AND ( Doctorate - Any Doctorate - Any Specialization, Doctorate Not Required).

OTHER DETAILS
Number of vacancies: 4
Experience: 3 years
Location: Cochin

If you have a passion towards technology and coding, then we have the right job for you. Kindly forward your resumes to
Email: jobs@mjsofttech.com
Phone: 0484-2421245 / 928 720 7160",4.0,"MJ Softtech
4.0",Kochi,"Cochin, India",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
1074,Data Engineer,"Education/ Experience and Skill Requirement
4+ years of relevant experience in
Experience working with both relational and NoSQL databases.
Strong coding skills; Python (preferred) /R/Java/Scala
Experience in developing Data warehousing technologies Experience with AWS or equivalent cloud services preferred
Experience in BigData technologies (Hadoop, HDFS, MapReduce, Spark, Hive, HBase etc) will be valuable
Knowledge of Machine Learning a big plus (Random Forest, Decision Trees, SVM, NLP, Gradient Boosting, Supervised/Unsupervised Learning, Clustering, classification and regression modeling).
Responsibilities
Proficiency with several years’ experience in more than one of Python, R, Java, Scala, or robust Linux shell scripting
Implementation experience with data warehouse architecture & design, ETL design/development, and Analytics
Knowledge of general cloud architecture and cloud strategies especially around AWS services and concepts such as S3 object stores, RDS databases, EC2, Glacier, Lambda, IAM, enterprise security, data security, DevOps, replication and disaster recovery
Well versed with data mining & exploration, NLP and visualization
Understanding of data modeling, data integration, and data representation (metadata, OWL, ontologies)
Developing data marts and data management using SQL
Creating powerful visual outcomes
Independently manage daily client communication, especially over calls
Manage client deadlines, ensure quality of the deliverables, attention to detail
Experience/understanding of corporate finance data from company filings is desirable",3.6,"Copal Partners
3.6",Bengaluru,"New York, NY",10000+ employees,1900,Company - Public,Financial Analytics & Research,Finance,₹100 to ₹500 billion (INR),-1
1075,Data Engineer,"Job Description / Responsibilities
Build workflows to ensure data extraction quality and storage into our backend data store
Architect, build and train ML/AI models that can predict outcomes and report on anomalies.
Design data pipelines to perform ETL on content/data from multiple types of source systems.
Create data analytics views using RDBMS/Key-Value stores, on private and public/cloud
Create software that is well tested, maintainable, extensible and scales out with large data

Minimum Qualifications:
2+ years of software development with Python
2+ years of SQL (MySQL/Postgres) and Key-Value databases
1+ years of experience with scikit
2+ years of experience in data extraction, data transformation using custom Python/Java
Experience working with MapReduce/Hadoop/kafka/Elastic stack
Experience with Node backend and React/Redux
Experience working with git/mercurial, Amazon/Google cloud, Linux/LAMP stack
Experience in testing or test driven development
Experience with Data science and Machine Learning algorithm development

Location:
Hyderabad/Bangalore

Package:
Highly competitive to match experience and capability",3.7,"TVS
3.7",Bengaluru,"Chennai, India",5001 to 10000 employees,-1,Company - Private,Accounting,Accounting & Legal,₹100 to ₹500 billion (INR),-1
1076,Data Engineer,"Permanent position with US based client of iFlex.
Work Location: Bangalore
Experience Level: 2+ Years

Role:
As part of our global team you will work on the data platform reporting to the Data Engineering Lead. Your role includes specification, development, test and rollout of features on our data platform. You are expected to contribute to the vision, understand our product roadmap, integrate business value andclient experience and contribute to build an engineering culture within the team. This initiative is of critical important to the success of the organization and our roadmap, for instance, services like liquidity analytics, billing, client onboarding, reporting and others will rely on the data platform. Accurate, granular, complete and timely data will be our key differentiating factor and competitive advantage in the market place. We expect the successful candidate to deliver high quality software and to be passionate about data engineering..

Responsibility / Qualification:
Managing multiple tasks and use sound judgment when prioritizing.
Collaborating with global cross functional team in building customer-centric products.
Analyzing existing software implementations to identify areas of improvement and provide deadline estimates for implementing new features.
Updating and maintain documentation for team processes, best practices and software runbooks.
Establishing trusted partnerships with peers, product heads, and executive level stakeholders.
We are looking for someone who is passionate about technology and engineering.
Exceptional analytical skills and ability to apply knowledge and experience in decision-making to arrive at creative and commercial solutions.
Ability to leverage technology to deliver business value.
You are independent and comfortable in a fast paced, ambiguous and often multi-directional work environment.

Preferred Qualifications:
B.S. or higher in Computer Science.
Minimum 2 years of relevant professional experience using a modern programming language (preferably Java/Scala).
Experience leveraging test driven development technics.
Comfort with Agile operating models.
Team oriented.
Strong interpersonal and communication skills.
Energetic, self-directed, and self-motivated.
Experience with microservice architecture.
Experience with Kafka, MongoDB, Hadoop, Cassandra.
Experience with AWS.
Experience in Financial Services or Fintech.",-1,IFLEX,Bengaluru,"Moscow, Russia",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1077,CIEL/SEL/1941: Sr data scientist,"Mandatory skills required -
Databases (SQL, Oracle, Any RDBMS) - Should have working knowledge of atleast one database
PL/SQL Programming Languages
R, Python (Any One)
Inferential Statistics - Hypothesis, p-value, R2, RMSE, MAPE etc
Exploratory Data Analysis
Machine Learning Algorithms - Should have in-depth knowledge and implementation of atleast one algorithm

Responsibilities
: Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the why & how of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions

Education
Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics
Experience
Minimum years of related experience required: 3 years
Preferred years of experience: 5 years
Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desirable.

Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
1078,Data Engineer,Data Engineer,3.6,"Bookmyshow
3.6",Mumbai,"Mumbai, India",1001 to 5000 employees,2007,Company - Private,Ticket Sales,"Arts, Entertainment & Recreation",Unknown / Non-Applicable,-1
1079,Data Analyst,"Required Skills & Experience

We are looking for a Data Analyst Executive
Eligible Qualifications : B. Tech, BCA, M.Tech, MCA
Experience : 3-5 years, fresher’s can also be considered
Location of Job : Gurgaon/Connaught Place, New Delhi
Technicals Skills

Following technical skills are pre-requisite:
Well versed with Software development methodologies, such as SDLC (Software Development Life Cycle), DDLC (Document Development Life Cycle).
Database schema design and implementation
Should have worked in either of technologies Sql Query/ Tableau/ Excel (Macros)/ Access (Query) writing for data analytics.
For planning and coordinating activities, organizations remain in invariant communication with one another and the data transfer has to be performed efficiently and smoothly as possible.
He/ She should manage the execution of the technologies, help the businesses in utilizing the systems, and should be well versed with the basics of computer systems such as Networking, Installation of necessary software and hardware.
Ability to determine the interrelationships between solutions and requirements.
Ability to think analytically and should be a problem solver and logic building should be very strong.
Good interpersonal skills to form effective working relationships with people at all levels.
Excellent communication and presentation skills and strong written & oral English skills.
To know more about us visit us www.sspl.net.in or write to us at admin@sspl.net.in",-1,Substratal Solutions,Connaught Place,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1080,Artificial Intelligence Scientists,"Experience 2- 4 Years
Salary 4 LPA - 6 LPA
Job Location Chennai

Industry:
IT-Software / Software Services

Keywords:
Artificial Intelligence

About Job:
Must have Excellent knowledge in AI / Machine learning (Mandatory).
Machine learning frameworks like keras, tensor flow etc.
And also other big data tools like Hadoop etc, Must know R and python.
Good understanding in SDLC & Business cycle.",4.0,"Careerera
4.0",Chennai,"Wayland, MA",501 to 1000 employees,-1,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
1081,Senior Data Engineer,"About Us

upGrad is an online education platform building the careers of tomorrow by offering the most industry-relevant programs in an immersive learning experience. Our mission is to create a new digital-first learning experience to deliver tangible career impact to individuals at scale. upGrad currently offers programs in Data Science, Machine Learning, Product Management, Digital Marketing, and Entrepreneurship, etc. upGrad is looking for people passionate about management and education to help design learning programs for working professionals to stay sharp and stay relevant and help build the careers of tomorrow.
upGrad was awarded the Best Tech for Education by IAMAI for 2018-19
upGrad was also ranked as one of the LinkedIn Top Startups 2018: The 25 most sought-after startups in India
upGrad was earlier selected as one of the top ten most innovative companies in India by FastCompany.
We were also covered by the Financial Times along with other disruptors in Ed-Tech
upGrad is the official education partner for Government of India - Startup India program
Our program with IIIT B has been ranked #1 program in the country in the domain of Artificial Intelligence and Machine Learning
About the Role

We are looking for a Data Engineer to help us scale the existing data infrastructure and in parallel work on building the next generation data platform for analytics at scale, machine learning infrastructure and data validation systems.
In this role, you will be responsible for communicating effectively with data consumers to fine-tune data platform systems (existing or new), taking ownership and delivering high performing systems and data pipelines, and helping the team scale them up, to endure ever growing traffic.
This is a growing team, which makes for many opportunities to be involved directly with product management, development, sales, and support teams. Everybody on the team is passionate about their work and we’re looking for similarly motivated “get stuff done” kind of people to join us!

Roles & Responsibilities
Engineer data pipelines (batch and real-time ) that aids in creation of data-driven products for our platform
Design, develop and maintain a robust and scalable data-warehouse and data lake
Work closely alongside Product managers and data-scientists to bring the various datasets together and cater to our business intelligence and analytics use-cases
Design and develop solutions using data science techniques ranging from statistics, algorithms to machine learning
Perform hands-on devops work to keep the Data platform secure and reliable
Skills Required
Bachelor's degree in Computer Science, Information Systems, or related engineering discipline
6 + years’ experience with ETL, Data Mining, Data Modeling, and working with large-scale datasets
6+ years’ experience with an object-oriented programming language such as Python, Scala, Java, etc
Extremely proficient in writing performant SQL working with large data volumes
Experience with map-reduce, Spark, Kafka, Presto, and the ecosystem.
Experience in building automated analytical systems utilizing large data sets.
Experience with designing, scaling and optimizing cloud based data warehouses (like AWS Redshift) and data lakes
Familiarity with AWS technologies preferred
Qualification – B.Tech/M.Tech/MCA(IT/Computer Science)

Years of Exp – 6-9",3.5,"upGrad Education Private Limited
3.5",Mumbai,"Mumbai, India",501 to 1000 employees,2015,Company - Private,Education Training Services,Education,₹1 to ₹5 billion (INR),"Udacity, General Assembly, Springboard"
1082,BBRC-Genomics-Associate Scientist,"JOB DESCRIPTION

Designation: Associate Scientist

Job Location: Bangalore

Department: Translational Medicine- Translational Sciences

About Syngene

Incorporated in 1993, Syngene International Ltd. is an innovation-focused global discovery, development and manufacturing organization providing integrated scientific services to the pharmaceutical, biotechnology, nutrition, animal health, consumer goods and specialty chemical industries around the world. Syngene’ s clientele includes world leaders such as Bristol-Myers Squibb, Baxter, Amgen, GSK, Merck KGaA and Herbalife. Its innovative culture is driven by the passion of its 4240- strong team of scientists who work with clients from around the world to solve their scientific problems, improve R&D productivity, speed up time to market and lower the cost of innovation .

Job Purpose:
To play a key role in TM-TS, develop an early-stage research strategy, initiate and lead discovery programs while managing ongoing programs in TM-TS. The role will work part of TMTS, and work with internal and external collaborators .

Key Responsibilities:
Experience in isolating DNA and RNA from blood, tissues and FFPE samples and cell lines. Experience with optimization of extraction protocols and for parameters like yield, input sample quantities and sample types is important.
Expertise in PCR, qPCR, cDNA/gDNA library preparation. Exposure to microarray techniques.
Proficiency in preparation of libraries for Next Generation Sequencing of transcriptome and genome, with significant experience in optimization of parameters like input RNA/DNA quantities and sample type
Experience with single cell RNA-seq will be plus.
Experience with various NGS protocols (DNA Amplicon based, hybrid capture based low input, degraded DNA and RNA samples e.g. FFPE samples.
Strong understanding of experimental design and statistical principles behind experimental design and differential gene expression. Experience with analysis of single cell RNA-sequencing data will be a plus

Educational Qualification:
M.Sc or M. Tech in Biotechnology, Molecular biology or Biological Sciences,

Technical/functional Skills:
DNA/ RNA Isolation, Expertise in PCR, qPCR, Experience in NGS protocols

Experience:
2 to 5 Years

Behavioral Skills:
A proactive team player.
Ensure completion of experiments and generate accurate and reproducible data from experiments.
Ability to work independently, prioritize tasks and work on multiple projects simultaneously with; comfortable working in a dynamic environment with changing requirements.
Good oral and written communication and presentation skills to work in a multi-disciplinary team
Equal Opportunity Employer:
It is the policy of Syngene to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by applicable legislation or local law. In addition, Syngene will provide reasonable accommodations for qualified individuals with disabilities.",3.5,"Syngene
3.5",India,"BENGALURU, India",1001 to 5000 employees,1994,Unknown,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1083,Applied Scientist 1,"Position Requirements:
Master's degree in Computer Science, Computer or Electrical Engineer, Mathematics, or a related field plus at least one year of experience in the job offered or related occupations of Software Engineer, Software Developer, or a related occupation. Employer will accept a Bachelor’s degree and five years of experience in the job offered or a related occupation as equivalent to the Master’s degree and one year of experience. One year of experience in the job offered or related occupation must involve designing and developing large-scale, multi-tiered, distributed software applications, tools, systems and services using Java, Object Oriented Design and Distributed Programming].

Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, Oracle/Berkeley databases, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills

Amazon Selling Partner Services team drives the Selling On Amazon business and develops solutions that enable millions of sellers around the world to sell on Amazon's Marketplaces. More than half of shipments for Amazon customers are generated from this business. The team is focused on building a technology platform that will support the explosive business growth in existing markets, streamline the business for Amazon and the Selling partners and launch business in new markets and establish a fair marketplace.

Our team is seeking engineers with broad technical skills to help us optimize how we synthesize massive amounts of data and complex business rules into mission critical financial information. As a member of this team you will employ object oriented techniques in Java, and DynamoB, PostGres and ElasticSearch skills to help us support Amazon's next generation of selling partner services. Along the way you'll gain and leverage a unique understanding of how Amazon.com works; from the numerous software systems that comprise the website's back-end, to the details of our business model, and the relationships we're establishing with an ever-growing network of selling partners who depend on Amazon.com to run their businesses.

The ideal candidate will draw upon exemplary analytical, critical thinking, and problem solving skills, and a passion for maintaining highly reliable, distributed systems which operate 24/7/365. Successful members of this team collaborate effectively with internal end-users, aggressive cross-functional software development teams, and technical support/sustaining engineering teams to solve problems and deliver successfully against high operational standards of system availability and reliability. We look for engineers who are excellent communicators, self-motivated, flexible, hardworking, and who like to have fun!

Position Responsibilities:
Participate in the design, development, implementation, testing and documentation of large-scale, multi-tiered, distributed software applications, tools, systems and services using [Java, Object Oriented Design and Distributed Programming]. Translate functional requirements into robust, scalable, supportable solutions that work well within the overall system architecture. Participate in the full development cycle, end-to-end, from design, implementation, and testing to documentation, delivery and maintenance. Produce comprehensive, usable software documentation. Evaluate and make decisions around the use of new or existing software products and tools.

Preferred Qualifications
Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1084,Senior Clinical Data Analyst,"About Novotech:

Novotech is internationally recognised as the leading independent and full-service contract research organisation (CRO) in the Asia Pacific region. We provide a wide range of clinical development services across all research phases and therapeutic areas and have been instrumental in the success of hundreds of Phase I – IV clinical trials throughout the Asia Pacific. Powered by the highest quality people, Novotech strives to set the benchmark for both business and clinical trial performance. Our people are one of our key strengths. We value our people and recognise the work they do. We are lucky to have the best people and talent from across the Asia Pacific region work together to deliver to clinical trial success for our clients. Our people and those we look to recruit have an attitude of making things happen. They are problem solvers, driven with a focus on delivering quality, accountability and a high level of performance.

Brief Position Description:

As part of Novotech’s Biometrics unit, the Senior Data Analyst (SDA) is responsible for all data analysis and business intelligence activities related to study related clinical and operational data. The SDA acts as primary point of contact for all data analysis matters to the study team and is responsible for the timely delivery of quality outputs following all applicable regulatory, compliance, best practice and operational procedures.

Minimum Qualifications & Experience:

Graduate in information science, data science or life science-related field, or similar. More than five years’ experience in a senior role related to data science, data analysis, clinical data management or clinical data programming in a pharmaceutical company, CRO or EDC software provider.

Responsibilities
The Senior Data Analyst (SDA) is responsible for providing technical, procedural (SOPs) and planning leadership across multiple projects assigned to the data analyst team members ensuring that they deliver in accordance with SOPs, programming best practices, and the timelines agreed within the Project Team.
Collaborate with cross-functional stakeholders to implement data science solutions to solve business needs using available technological solutions.
Scope data analysis effort for projects and project manage all data analysis activities across multiple projects for different study stakeholders.
Gather study requirements from data management for data review and external data reconciliation and provide guidance on appropriate outputs (dashboards, visualisations, listings, reports).
Extract, assess, integrate, transform data sources to provide data visualisation outputs for analytics.
Design and develop prototypes and final versions of data outputs (dashboards, reports, visualisations, listings) using Business intelligence tools and Data Visualisation tools.
Design and develop standard dashboards and content for different audiences.
Analyse, manipulate and understand data from multiple sources to present and create dashboards and reports to make business decisions.
Assist teams on best-practice for data visualisation dashboard development.
Educate teams on how to use all the features of applicable data visualisation platform in conjunction with data visualisation dashboards.
SME for the data visualisation development and assisting team members.
Identify and communicate project risks and maintain documentation within project files as appropriate
Represent data analysis group at internal / external meetings as appropriate.
Assess and implement new data analysis, BI and data visualisation processes and technologies.
Take an active role in the development of best practices, process improvement, quality control and governance related to all data analysis matters.
Provide training and mentoring to Data Analysis of team members in SOPs, software applications, and best practices.
Provide Subject Matter Expertise on all data analysis and visualisation related activities.
Attributes and Skills

Expert knowledge of clinical study data structures and schemas of EDC databases. Expert knowledge in data processing activities such as extracting, integrating, transforming and presenting data. Statistical Programming skills in Python, R or similar. Knowledge of SQL and EDC systems. Working knowledge of Spotfire, Power BI, Tableau or other data review and visualisation tool. Ability to gather business requirements from multiple stakeholders and clients and provide guidance on the use of appropriate data visualisations.

Experience mentoring and training others. Awareness of regulatory and compliance issues and understanding of the application of SOPs and Quality Control to daily activities. Excellent analytical, communication and problem-solving skills.

Opportunities and Benefits:

To deliver clinical trial and research excellence for our clients, our people are 'best in class'.

At Novotech, we seek and nurture people with exceptional talent. We are committed to providing our people with regular internal and external training, a competitive bonus structure and a supportive work environment. We are also focused on providing our people with a wide variety of career growth and development opportunities.

For more information about where your next career step at Novotech might take you, visit http://novotech-cro.com/novotech-careers",4.5,"Novotech
4.5",Bengaluru,"Sydney, Australia",501 to 1000 employees,1996,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
1085,Data Engineer,"Data Engineer Responsibilities:
Liaising with coworkers and clients to elucidate the requirements for each task.
Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed.
Reformulating existing frameworks to optimize their functioning.
Testing such structures to ensure that they are fit for use.
Preparing raw data for manipulation by Data Scientists.
Detecting and correcting errors in your work.
Ensuring that your work remains backed up and readily accessible to relevant coworkers.
Remaining up-to-date with industry standards and technological advancements that will improve the quality of your outputs.
Data Engineer Requirements:
Bachelor's degree in Data Engineering, Big Data Analytics, Computer Engineering, or related field.
Master's degree in a relevant field is advantageous.
Proven experience as a Data Engineer, Software Developer, or similar.
Expert proficiency in Python, C++, Java, R, and SQL.
Familiarity with Hadoop or suitable equivalent.
Excellent analytical and problem-solving skills.
A knack for independent and group work.
Scrupulous approach to duties.
Capacity to successfully manage a pipeline of duties with minimal supervision.
Job Type: Full-time

Salary: ₹360,000.00 to ₹870,000.00 /year

Experience:
total work: 2 years (Preferred)
Data Engineer: 1 year (Preferred)
Education:
Diploma (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,Futurious Technologies,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1086,Quantitative Analyst,"The successful candidate will be a highly analytical individual with hands on programming skills. The candidate will work closely with the research team and clients towards the ongoing development and integration of new investment strategies, models and tools on Axle

Location

Mumbai
Responsibilities

Perform daily/weekly/monthly tasks of performance and risk reporting
Develop and automate investment processes and strategies via VBA and Matlab
Develop tools to integrate trading decision systems with risk management systems
Ad hoc tasks (such as operational tasks, internal documentation tasks and preparation of marketing materials)
Skills/Experience

Excellent programming skills in Matlab/Excel-VBA
Thorough with financial concepts and calculations like Drawdown, VaR, Eloss etc.
Understanding of financial market products like options, futures, FX forwards etc.
Working knowledge of Bloomberg is preferred
Should be self-driven and detail oriented with an analytical mindset
Should be a proactive and quick learner; a team player showing enthusiasm and drive to accomplish results in a fast paced environment
Min. 2 years of relevant work experience
Qualifications

B.Tech/M.Tech/MBA/CFA/FRM",5.0,"B&B Analytics
5.0",Mumbai,"Zug, Switzerland",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1087,Analyst - Data Scientist,"Job Summary

Experience:
3 - 5 Years

Location:
Mumbai

Designation:
Analyst - Data Scientist

Degree:
BE-Comp/IT, BE-Other, BTech-Comp/IT, BTech-Other, ME-Comp/IT, ME-Other, MTech-Comp/IT, MTech-Other, PhD-Comp/IT, PhD-Other

Educational Level:
Graduate/Bachelors

Industrial Type:
IT-Software/Software Services

Functional Area:
IT Software - Application Programming / Maintenance

Key Skills:
Data Scientist

Job Post Date:
Thursday, March 19, 2020

Company Description

We are capability centre based in Mumbai, initially started as a back-office operational support to the UK business unit.

However, over the recent years, we have significantly increased the breadth and depth of our capabilities and offerings to keep pace with the changing needs of the Group. These include Digital & Knowledge Services, Finance and Actuarial, Information Technology (IT), Customer Service, Risk and Audit.

Our core purpose is to be a strategic partner to company, enabling growth by delivering change and driving synergies through a highly capable and agile workforce.

With our diversified service offerings we provide our people with exciting opportunities to grow personally and professionally.

Company is a leading savings and investments business serving around 5.5 million retail customers and more than 800 institutional clients.

It-s innovative asset management and customer solutions are supported by extensive investment capabilities, an international distribution network and two strong brands.

Job Description

3 – 5 yrs experience as Data Scientist
Should have at-least 1 end-to-end ML project experience
Very high proficiency in R or Python
Excellent in forecasting methods like simple exponential smoothing, multiplicative seasonal indexes, simple and weighted moving averages and time series forecasting methods
Exposure to with advanced deep learning techniques such as LSTM. CNN, Dense neural networks as well as neural networks design and implementation through tools like tensorflow, keras, pytorch, deepai or equivalent.
Good SQL experience",3.8,"Sampoorna Computer People
3.8",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
1088,Data Lake Developer,"For Us, It's A Mission

At Mylan, we mean it when we say we work every day to provide access to high quality medicines to the world's 7 billion people. If you are unconventional, relentless and passionate. If you believe in doing what's right, not what's easy. If you are a doer and have a passion for serving others, we want to talk to you.

Make a Difference

At Mylan, each person has the ability to make a difference. From the providers who sell and market our products, to the producers who develop and manufacture them and finally to our business partners who support the providers and producers, we all have a mission critical role. Here's how this role will help:

ESSENTIAL DUTIES AND RESPONSIBILITIES
To perform this job successfully, an individual must satisfactorily perform each essential duty. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential duties.
1. Create and maintain optimal data pipeline architecture on Azure platform.
2. Develop batch processing solutions by using Data Factory and Azure Databricks.
3. Delivering a Data Warehouse in the Azure Cloud.
4. Design relational and non-relational data stores on Azure.
5. Identify, design, and implement internal process improvements : automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc..
6. Developing Big Data Solutions with Azure Machine Learning.
7. Strong interaction with business departments to provide consultative support for digitization efforts, as well as close collaboration with the Business Technology management, focused on future innovation topics.
8. Participate and lead in design sessions, demos and prototype sessions, testing and training workshops with business users and other IT colleagues.
9. Design & Build for any API Development or SQL DB development.
10. Providing service management, orchestration, monitoring and management requirements of Azure cloud platform.
11. Create data tools / products for analytics and data scientist team members that assist them in building and innovative solutions that drive tangible business value.
12. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
13. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
14. Design security for source data access. Chose the appropriate authentication mechanism, (ie Azure Active Directory (Azure AD), etc).
15. Design for real-time processing by using Stream Analytics and Azure Databricks.

Make Our Values Your Values

Mylan hires only the best. People who thrive in a culture of innovation and empowerment. People who are active learners and have a positive attitude. People who are leaders and know that by working together we can run faster, reach higher and achieve more. By doing so, we will continue to set new standards in health care. Here are the minimum qualifications and essential functions for this position:

QUALIFICATIONS

The qualifications listed below are representative of the minimum knowledge, skill, and/or ability required.

SKILLS AND ABILITIES

1. 10 years of experience in Microsoft technologies including SQL.

2. At least 5 years as a Sr Developer with at least 3 years hands on experience as Azure Data Engineer building large scale Azure data solutions.

3. At least 5 years of experience in Azure based data solutions.

4. At least 3 years of experience on working with large projects including the most recent project in the cloud (Azure) or on prem with a focus on Azure Data services.

5. At least 5 years of Hands-on administration, configuration management, monitoring, performance tuning of Hadoop/Distributed platforms.

6. At least 5 years of demonstrated experience at least in the most recent 2 years of designing and delivering solutions using Cortana Intelligence suite of analytics services part of Microsoft Azure including Azure Machine Learning Studio, HDInsight, Polybase, Azure Data Lake Analytics, Azure Data Warehouse, Streaming Analytics, Data Catalog, R/R Studio

7. Experience in designing and building logics required for optimal extraction, transformation, and loading of data from a wide variety of data sources

8. Experience within Data Security design, including but not limited to:

a. Choosing the appropriate authentication mechanism, such as Azure Active Directory (Azure AD)

b. Defining strategies for data encryption for data at rest and in transit

9. Experience partnering with Business Analysts and Data Scientists to enable effective and efficient data preparation and delivery

10. Experienced in vendor management and working with 3rd parties onshore & offshore.

11. Experience working in a global team.

12. Experience working in an Analytics / Big Data solutions on MS Azure Cloud

13. Experience with code management tools, automated testing

14. Experience creating and maintaining optimal data pipeline architecture on Azure platform

15. Experience developing batch and real-time processing solutions by using Data Factory and Azure Databricks

16. Familiar with AGILE and Azure DevOps methodology

17. Hands on PoC capabilities are needed to prove a particular architecture concept

18. Azure Native Services experience across Data Fabric and Service Fabric

19. Experience in Application modernization from legacy on-premise data architecture platform technology stack to modernized Azure Cloud base Architecture.

20. Experience with Git, NoSQL Data Solutions, Microsoft Azure, HD Insights, Azure ML, DataBricks ML Flow, R or Python.

21. Must have excellent communication skills.

EDUCATION/EXPERIENCE (Note: Please select one)

Minimum of a Bachelor's degree in Computer Science and Engineering is preferred with minimum 10 years of experience. However, a combination of experience and/or education will be taken into consideration

Why Mylan?

If you want to be part of a global health care company that is making a difference and changing lives, Mylan may be the place for you. With a workforce of more than 35,000 worldwide, we can make a difference. We encourage you to visit Mylan.com to learn more about our unconventional culture, our approach to doing business and how we plan to set new standards in health care.

Mylan offers competitive salary, excellent benefits and an environment conducive to professional growth and advancement. All qualified applicants will receive consideration for employment without regard to their disability or protected veteran status. Mylan is an Equal Opportunity Employer, Minorities/Female/Disabled/Veteran.",3.8,"Mylan Inc.
3.8",Bengaluru,"Hatfield, United Kingdom",10000+ employees,1961,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1089,Off Campus Recruitment - Quantitative Researcher,"Description:
Graviton is a privately funded quantitative trading firm striving for excellence in financial markets' research. We are seeking fresh talent from the top IIT's to join us as Quantitative Researchers for our team in Gurgaon.If you are a student graduating in 2020 from Computer Science , Electrical or Maths Stats Computing streams with a greater than 8 CGPA please apply here.

This role is open to students from campuses that we could not visit this year. Please check your individual placement policy restrictions before applying.

Graviton trades across a multitude of asset classes and trading venues using a gamut of concepts and techniques ranging from time series analysis, filtering, classification, stochastic models, pattern recognition to statistical inference analysing terabytes of data to come up with ideas to identify pricing anomalies in financial markets.

As a Quantitative researcher your responsibilities will include

Develop new or improve existing trading models using in-house platforms

Use advanced mathematical techniques to model and predict market movements

Analyse large financial datasets to identify trading opportunities

Provide real time analytical support to experienced traders

Requirements :
Possess a degree in a highly analytical field, such as Engineering, Mathematics, Computer Science from IITs schools

Quantitative bend of mind

A working knowledge of Linux/Unix

Programming experience, preferably in C++ or C

Strong interest in learning about financial markets.

Have a strong work ethic

Hard Working

Benefits:
Our open and casual work culture gives you the space to innovate and deliver. Our cubicle free offices , disdain for bureaucracy and insistence to hire the very best creates a melting pot for great ideas and technology innovations. Everyone on the team is approachable, there is nothing better than working with friends!

Our perks have you covered.

Competitive compensation

6 weeks of paid vacation

Monthly after work parties

Catered breakfast and lunch

Fully stocked kitchen

Gym membership

International team outing",5.0,"Graviton Research Capital LLP
5.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2014,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1090,Data Engineer,"Zauba Technologies is a startup based in Bangalore. Zauba's services are used by leading companies in India. Zauba is powered by a young and passionate team. We are looking for individuals who would like to be a part of our founding team.

As a Data Engineer and as a part of founding team, you will be expected to visualise and develop disruptive data products. Eventually you would be responsible for entire project lifecycle of products you would visualize. Your rewards will be directly proportional to the value you generate.

Job Responsibilities
Design and development of robust, scalable and highly efficient data engineering solutions for structured and unstructured data (Including gathering and processing raw data at scale, writing scripts, web scraping, calling APIs, writing SQL queries, etc.)
Develop processes for text mining and extraction of information from unstructured data
Design, architect and develop efficient data pipelines around the data collected
Take ownership of existing web product and applications
Design and implement data models that scale across the enterprise
Take ownership of existing data workflows and processes
Enhance scalability, performance, and stability of existing infrastructure
Work closely with other team members to integrate your innovations and algorithms into our production systems

Essentials
Java/Python - Intermediate to advanced level
SQL - Advanced
MySQL Intermediate to advanced level
Regex - Basic to intermediate level
Linux Basic to intermediate level

Good to have
Hadoop/Spark
R
MongoDB

Must have qualities
Skills to learn new skills quickly
Desire to create disruptive products and services
Passion - not just to work in startups but to take them to next level
Above average programming aptitude
Be passionate about producing high quality engineering deliverables
Be productive working independently or collaboratively
Have an eye for building efficient processes
Be self motivated
Proactively take ownership

Interested?

Send your resume to hr@zaubacorp.com",3.8,"Zauba Corp
3.8",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 million (INR),-1
1091,Quantitative Research,"We are looking for highly trained professionals who are interested in applying advanced mathematical quantitative methods to the modeling of global financial markets. You would be joining a group made up of highly proficient individuals from various scientific disciplines. We have a spectrum of opportunities for individuals with the right scientific skills. Experience in finance is not required.

The ideal research candidate will have:
A Ph.D. in Computer Science, Mathematics, Physics, Statistics, or a related technical discipline.

A demonstrated capacity to do first-class research.

Computer programming skills.

An intense interest in applying quantitative analysis to solve difficult problems.

Send us a copy of your resume to
careers@dolatcapital.com

For internship opportunities, please send us a copy of your resume to
careers@dolatcapital.com",4.0,"Dolat Capital
4.0",Mumbai,"Mumbai, India",51 to 200 employees,1970,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1092,Data Engineer,"Bachelor’s degree in Computer Science or related field
5+ years relevant experience
5+ years experience with SQL, SQL Tuning, Oracle, OLAP, Big Data Technologies
5+ years experience developing end-to-end Business Intelligence solutions: data modeling, ETL and reporting
Experience with Java and experience with scripting languages like Perl, Python, Unix shell scripts,VBA and MS Excel
Proficiency with Linux and systems administration
Proven ability at looking at solutions in unconventional ways. Sees opportunities to innovate and can lead the way.
Top notch communication (verbal and written) and interpersonal skills to convey key insights from complex analysis in summarized business terms and an ability to effectively communicate with technical teams.
Ability to work with shifting deadlines in a fast paced environment.
Operations Finance Technology team, responsible for building technical solutions for multi-billion WW Operational Cost analytic including Inbound cost (Receiving / PO), variable Cost, fixed cost, outbound (Customer Shipments / Transportation), and Customer Service, is looking for a Data Engineer.

As a data engineer, you will get the exciting opportunity to work on very large data sets in one of the world's largest and most complex data warehouse environments. You will work closely with the business teams in analysis on various cost savings initiatives, many non-standard and unique business problems and use creative-problem solving to deliver actionable output.
You will be responsible for designing and implementing an analytical environment using third-party and in-house reporting tools, modeling metadata, building reports and dashboards. You will have an opportunity to work with leading edge technologies like Redshift, Hadoop/Hive/Pig. You will be writing scalable queries and tuning performance on queries running over billion of rows of data.

You should be analytical, have an extremely high level of customer focus and a passion for process improvement. You should be motivated self-starter that can work independently in a fast paced, ambiguous environment. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions.
Bachelors in Computer Science or related field
Practical Knowledge of Linux or Unix shell scripting
Experience in working with business customers to drive requirements analysis
Exposure to large databases, BI applications, data quality and performance tuning
Excellent written and spoken communication skills
Experience with Hadoop-based technologies such as HBase, Pig, Hive and Spark
Strong proven ability in building high-performance, highly available and scalable data solutions using Oracle and/or Hadoop-based technologies
Knowledge of data warehousing concepts.
Strong sense of ownership, urgency, and drive
Strong troubleshooting and problem solving skills
Experience with Amazon Web Services",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1093,DATA ANALYST,"posted by Mahima Gaur

2 - 5 years Delhi

Job Description
Experience in data processing
Experience in data cleaning and data tabulation activities
Strong analytical, communication and team management skills
Strong understanding of data management using SPSS and research techniques
Competency in a Tabulation software (decipher / wincross / quantum etc), Excel, Powerpoint
Ability to summarize findings, draw conclusions, and put together a presentation using Powerpoint
Role Category : Data Analyst

Employment Type : Permanent Job, Full Time",4.9,"Knowledge Excel Services.
4.9",New Delhi,"New Delhi, India",1 to 50 employees,2007,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
1094,Data Engineer,"Key skills : Python , Spark , SQL , Pyspark • AWS platform used for the work • Strong experience in SQL is mandatory • Good familiarity of AWS landscape • Good experience in collecting business requirements & design them as per requirement from customer • Should able to work independently & interact business users & technical stakeholders • Strong communication skills both oral & written. • Should work as an individual resources",3.5,"Larsen & Toubro Infotech Limited
3.5",India,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1095,Big Data Engineer,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
1096,Client Data Analyst,"At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.
What is the Client Data Analyst – Client Analytics group responsible for?
This team manages business data to ensure accurate, timely, consistent and compliant data. Their contributions deliver quality data that is easily accessible and can be trusted. Key downstream capabilities such as reporting and analytics depend on this as well as operational data access on various systems. The Data Management Team is a support function that acts as an advocate and a point of contact for Sales and Marketing data.

What are the ongoing responsibilities of an Client Data Analyst ?
Understand the data flow, key consumption and production of data as well as context within the enterprise:
Build positive relationships with teams, especially the key data consumers and analytics. Take the time to increase knowledge of how they run their business and incorporate sales data into daily work
Connect regularly with each sales office to understand current issues and challenges. Probe the business and validate against other sales offices to understand the scope and priority of the issue
Make recommendations on how data unifications and flow can be used to improve business tasks. Liaise business partners to deliver solutions (reports, processes, technology) that add value.

Provide data management subject matter expertise. Appreciate the connection and data flow between applications and other corporate systems. Be able to clearly articulate the data needs and move initiatives forward by collaborating with business partners:
Actively participate in meetings with business partners to ensure that priorities are clearly understood, information is regularly shared and that key participants are “kept in the loop”
Provide context and background on issues. Collaborate on ideas for progressing initiatives. Ensure appropriate resources are involved to take initiatives forward
Provide insights and expertise to scope statements and requirements documentation
Actively consult or participate in the user acceptance testing process (test cases, documentation, testing execution, etc.)
Ensure business needs remain aligned with overall corporate initiatives and deliver the benefits as originally intended

Monitor the integrity of data and usefulness of reports. Ensure the information available within systems is accurate and up-to-date. Proactively seek data cleansing opportunities and evolve data to better support. Document and maintain ongoing processes for reporting and data clean-up:
Partner with all key data consumers to gain a solid understanding of usage and challenges around data. Establish processes for prioritization of enhancements, especially with the analytics groups
Provide 1st level support for data issues and data maintenance for owned data
Verify and execute data loads into our internal sales systems and ensure any upstream systems accurately receive their data

Increase awareness and promote data management capabilities. Share best practices and provide coaching to local offices on how to access and incorporate output into sales tasks. Encourage IAS leaders to leverage data to make more informed, strategic decisions:
Clearly articulate the goals and core services of the data management team. Proactively promote this information within IAS and ensure business partners understand the data management role within the organization
Share best practices and provides guidance on data capabilities. Reinforces ownership and accountability for data accuracy
Seek opportunities to share the benefits of leveraging sales data to make more informed business decisions

What ideal qualifications, skills & experience would help someone to be Successful?

Knowledge, Education And Experience:
Four year bachelor’s degree required (majors of preference include: business, computer science, mathematics) Advanced degree a plus
Understanding of the Franklin Templeton business model, how FT makes money, the sales process, how technology fits in with the business, etc. Knowledge of the GAS (Global Advisory Services) structure
Experience working through multiple business fiscal cycles; exposure and/or direct experience with project management and/or sales-related-capacity required
Prior work experience related to analytics, sales, marketing and/or international a must. Level will not be granted based on years of experience but will be determined by the employee’s ability to meet each job activity as outlined the ‘typical/expected focus by level
Skills And Abilities:
Ability to communicate effectively with all levels of management; ability to tailor communication style based on audience; ability to get others to want to collaborate with you; strong facilitation skills
Excellent writing skills (for presentations, documentation, etc.)
Working knowledge of the CRM, MDM, Excel, SQL, Power BI, Tableau, Business Objects, and Microsoft Products (PPT, Power Apps, Doc, Visio)
Ability to absorb and interpret large quantities of data; apply trend analysis and knowledge of the business to develop a meaningful and digestible summary with the appropriate level of detail
Ability to take a larger problem and break down the individual components; identify how to go about solving the problem and who to involve in the process
Ability to present recommended solutions to a variety of issues and problems (solutions that are consistent with organization objectives)
Must be extremely detail-oriented (managing lists, tasks/to-dos, etc.) good with follow through on own items; good with following up with others on outstanding item

What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.

Highlights of our benefits include:

Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.",3.8,"Franklin Templeton Investments
3.8",Hyderabad,"San Mateo, CA",5001 to 10000 employees,1947,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Fidelity Investments, Vanguard"
1097,Data Analyst,"Roles and Responsibilities:
Extracting, transforming and inputting data sets from various resources. Creating predictive models, translating non-technical aspects into quantifiable tasks. Analysis and representation of output data, highlight and explain trends and patterns, error elimination, using advanced statistical methods (regression, probability distribution, clusters etc.) to provide accurate results.
Data collection, Data Mining, Report generation, Problem identification and solution formulation Market analysis and establishing trends, Strategy development and implementation

Skills:
Extremely good analytical skills.
Good working knowledge of all MS-Office products, especially Advance Excel, Word, PowerPoint, MS-access.
Statistical tools and methods.

Interested candidates can send the updated resume on satish.mehra@exelaonline.com or call on 7722028636
00-7.00 Years",2.6,"Exela Technologies
2.6",Pune,"Irving, TX",10000+ employees,2017,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"SourceHOV, BancTec, Transcentra"
1098,Data Modeler,"• Minimum 5-8 years of working experience as Data modeler.
• Data modelling experience in designing.
• Minimum 2-3 years real time experience in Erwin tool is mandatory.
• Experience in normalized modeling techniques.
• Experience in designing the Start schema.
• Experience working in ORACLE.
• Experience with database design, capacity planning, performance tuning and query optimization.
• Experience in working with Bank or Banking and Finance or Financial domain.
• Excellent communication skills with leadership quality.

Job Segment:
Database, Oracle, ERP, Technology",3.5,"LTI
3.5",Mumbai,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1099,Machine Learning Engineer,"Looking for Data Scientists with Python/R Programming skills.
Specific experience in AI areas like Statistical Machine learning / Deep learning / Natural Language Processing (NLP)/ Operations Research (Optimization) will be an advantage.Individual in this role is expected to work with multiple stakeholders and teams

Qualifications and Requirements:-
Previous working experience as a Machine Learning/ Data Scientist for 2 years
MA in Computer Science or similar relevant field
Hands on experience with MALLET
In depth knowledge of Apache Tomcat/Open Source
Excellent project and time management skills
Attention to detail
Outstanding problem solving and analytical skills",-1,Tekolutions.ai,India,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1100,Data Science Internship,"About the company:
SkillBit is a leading staffing and recruitment company engaged in talent searching assignments for skilled and talented candidates for the industry.

About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Working on data science algorithms and AI concepts 2. Using Python or R for web scraping 3. Building AI models using Python, machine learning, and deep learning algorithms 4. Processing of unstructured/structured data

Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 6th Jun'20 and 11th Jul'20
are available for duration of 1 month
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply

Number of internships/jobs available: 3

Categories: Data Science",-1,SkillBit,Pune,-1,-1,-1,-1,-1,-1,-1,-1
1101,Data Engineer,"As a data engineer at TEAL, you'll be taking the plunge into a rich data lake that includes everything from satellite data to legal court orders. You'll be hustling and getting your hands dirty with every part of the data pipeline always having an implicit appreciation for how all of this data will ultimately power a revolutionary real estate risk platform.

Your day-to-day will include either all or some of the following:

Constantly scoping out new data sources to complement existing ones
Creating and maintaining distributed web scrapers using Python, RabbitMQ and other technologies
Architecting and managing data pipelines where data flows into multiple end-points including, but not limited to, Postgres, MongoDB and Apache Solr
Documenting workflows and constantly iterating to create better data infrastructure.

We'd love it if you:
Are proficient in Python or any other object-oriented language
Have worked with large (millions to hundreds of millions of rows in a SQL database) interdisciplinary datasets
Have scraped difficult websites and have some experience working with various data APIs
Are patient and methodical with unstructured and messy data
Are always hungry to learn newer and better technologies to make the data ecosystem faster, smoother and less silo-ed

Extra brownie points if you:
Have some experience working with large-scale search indexing
Have performed geospatial analyses in some capacity
Have created and managed data lakes in the cloud
Culture

To explore our culture and the values we embody click here

Testimonials
Testimonial

My experience at TEAL surpassed all my expectations from the get-go. I was asked to help solve one of the most daunting problems in the Indian real estate market. Every day while working on a subset of the problem, the ideas that I brought to the table were shaped into cohesive solutions by a collaborative team effort. At TEAL I was exposed to the most cutting edge technologies such as Cloud Computing, Big Data, ML and Data Science. The growth opportunities at TEAL are tremendous, If you are innovative and can demonstrate the will to realize your ideas, TEAL is an amazing organization to work for.
Gyan Vardhan, Data Science Intern
I had interned as a Data Scientist at Terra Economics and Analytics Lab during its early days, it was a rich learning experience working with a multi-disciplinary team who are extremely passionate about building a decision support platform for the insanely complicated realty market in India. It was exciting and challenging to work on mining huge volumes of property records; extracting patterns from the data, building data pipelines and brainstorming on building the core system. TEAL offers a very healthy work environment coupled with insanely talented people working together in an exciting setting.
Naga Anjaneyulu, Data Science Intern
I worked as a full-time Data science intern at TEAL. During this period, I got an opportunity to leverage my skillsets while also learning new technologies, working on tasks assigned to me. The company operates on the latest tech-stacks and gives opportunities to learn as much as you want. The work environment is challenging, the team at TEAL is super supportive and new ideas are always welcome. It has all the good perks of a startup; creativity and innovation, casual work atmosphere and a collaborative approach to solving problems. Personally, I loved working there, my experience was fantastic!
Archana Parmar, Data Science Intern
As a second-year college student, I was looking for an internship that would allow me to delve deeper into research and work with big data, TEAL gave me the perfect opportunity to do so, enabling me to develop proficiency in research and analysis. As a research analyst intern, I collated and cleaned data and helped in the preparation of reports and presentations, and I had members helping me at every stage of this process. This collaborative environment allowed me to cultivate my skills and also learn from my peers. The holy trinity of Rohan, Kshitij, and Shreyas served as not only excellent mentors and bosses but also as friends, helping me at every stage and giving us all food and ice cream to keep us going!
Arush Mehra, Research Intern
Internships are a crucial part of one’s early career. The internship experience at TEAL was a thrilling rollercoaster ride to say the least! It was more than implementing a standard model or building an already though out concept into reality. It was about finding the solution to a unique and open-ended problem.It was exciting to work on addressing a problem with far -reaching real world applications.Moreover, the work environment had the perfect balance of casual yet professional which kept you focused and stress free at the same time. Out of every 100 startups in India only 2 of them succeed, but there are very few like TEAL India which are bound to make it big at such an early stage.
Divyanshu Agarwal, NLP Intern",4.7,"Terra Economics & Analytics Lab (TEAL)
4.7",New Delhi,"Bengaluru, India",1 to 50 employees,2018,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
1102,Senior Consultant - ModellingOps Data Engineer,"Job Title: Senior Consultant - ModellingOps Data Engineer
Location: TRIL GTC
GCL: D1

JOB DESCRIPTION:

AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. The Science & Enabling Units IT is AZs global IT capability function supporting key business areas operating out of sites across the US, UK, Sweden, India & Mexico.

We are looking for AI Ops consultant who will leverage tools & technology best practices to improve delivery performance & data engineering capabilities in the D&A space.

ROLES & RESPONSIBILITIES:

7-10 years of experience in IT Operations involving Data Science, Artificial Intelligence-Machine Learning and Predictive Analytics. Experience in architecting and implementation of end-to-end AIOPs solutions through ELK stack, Splunk. Experience in applying statistical methods, analysis, pattern recognition and modeling on IT Operational data using ELK machine learning. Experience in extracting meaning full data from incoming data streams from different sources through RegEx, Grok etc. Hands-on experience in applying machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc in the IT Operation domain. Experience with machine learning and statistical programming languages - Python, R etc. Experience in assessing the existing IT environment and providing recommendations to reduce the critical applications impacting incidents. Experience in exploring and identifying areas where manual tasks can be automated in IT environment. Experience with various Enterprise IT monitoring solutions including Infrastructure monitoring, Application Performance Monitoring, Network Monitoring, Cloud monitoring etc. Experience in IT Service Management including Service Desk, Incident Management, Change Management, CMDB etc. Excellent knowledge on various IT infrastructure components that includes Server Infrastructure, middle ware, database and application architectures and Cloud Components. Experience/knowledge on Infra monitoring tools - NOI, Zabbix, AppDynamics, Datadog, SCOM, SolarWinds etc. and Service Management tools -IBM Control Desk, BMC Remedy, ServiceNow etc. Experience/Knowledge on BI tools Knowledge on distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc. Knowledge on other programming languages/scripting: Python, Java, JavaScript, etc. ( Added Advantage ) Good analytical skills, strong communication skills are must. Client facing experience is an added advantage. Excellent experience in understanding the problem statement, architect and designing the solution

MANDATORY SKILLS:
Significant experience with AWS cloud environments, working knowledge of Google and Azure platforms. Knowledge of Kubernetes, S3, EC2, Sagemaker, Athena, RDS and Glue is essential.
Experience provisioning computational resources in a variety of Cloud environments using Infrastructure as Code.
Experience with best practice of data transport and storage within cloud system.
Experience building large scale data processing pipelines. e. g. Spark and SQL.
Experience with containers and microservice architectures e.g. Kubernetes, Docker and serverless approaches.
Excellent working knowledge in DevOps, using continuous integration and continuous development.
Use of Data Science modelling tools e.g. R, Python, SAS and Data Science notebooks (e.g. Jupyter).
Good written and verbal skills, fluent English
DESIERED SKILLS:
Agile practices, especially being a SCRUM Master
EDUCATIONAL BACKGROUND: B.E/B.Tech/MCA

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",3.9,"AstraZeneca
3.9",Chennai,"Cambridge, United Kingdom",10000+ employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Roche, GlaxoSmithKline, Novartis"
1103,DATA ENGINEER,"JOB DESCRIPTION
As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements, and also research new uses for data acquisition. You should also know the ins and outs of the industry such as data mining practices, algorithms, and how data can be used.

DESIRED CANDIDATE PROFILE
An ideal candidate must possess prior experience leading a project.

Candidates must have:
> Experience in Hive, Spark, Scala, AWS DynamoDB, HBase, AWS Glue, Talend, Kafka, Snowflake ETL
> Strong experience in a BI/Data Warehouse environment with involvement in design, development, implementation, troubleshooting and support of ETL process using ETL tool.
> Experience in developing Data Marts, Data warehousing and Operational Data Store (ODS) on any of the databases or Hadoop environments.
> Experience in database like MS SQL, MySQL, Oracle, PostgreSQL
> Good to have programming experience in writing Complex Stored Procedures, Queries, Views, User Defined Functions, Cursors and Common Table Expressions using SQL or T-SQL.
> Experience in Performance Tuning and Query Optimization by Indexing, Partitioning and De-normalization.
> Experience in Developing a framework for ingesting data into Data lake
> Good database knowledge, analytical thinking
> Design, construct, install, test and maintain data management systems.
> Build high-performance algorithms, predictive models, and prototypes.
> Develop set processes for data mining, data modeling, and data production.
> Experience with cloud services: AWS (EC2, EMR, S3, Athena) and scripting languages like Python, /PySpark/R/SAS
> Install/update disaster recovery procedures.
> Experience in Agile Application Development & Scrum methodologies is preferred
> Ability to supervise and mentor junior developers on the team.
> Must be self-motivated and work well pulling people together in addition to being able to pull people together technically
> Demonstrated proficiency of troubleshooting techniques and detail-oriented problem diagnosis
> Ability to handle responsibility, is self-directed, with strong organizational and documentation skills
> Ability to work independently and efficiently under aggressive deadlines to meet project commitments
> Excellent verbal and written communication skills

EDUCATION
UG - B.Tech/B.E. - Computers, Electronics/Telecommunication, Diploma - Computers, Electronics/Telecommunication, B.Sc - Computers, BCA - Computers) AND (PG - M.Tech - Computers, Electronics/Telecommunication, MCA - Computers, M.Sc - Electronics, Computers) AND ( Doctorate - Any Doctorate - Any Specialization, Doctorate Not Required).

OTHER DETAILS
Number of vacancies: 4
Experience: 3 years
Location: Cochin

If you have a passion towards technology and coding, then we have the right job for you. Kindly forward your resumes to
Email: jobs@mjsofttech.com
Phone: 0484-2421245 / 928 720 7160",4.0,"MJ Softtech
4.0",Kochi,"Cochin, India",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
1104,Data Engineer,"Education/ Experience and Skill Requirement
4+ years of relevant experience in
Experience working with both relational and NoSQL databases.
Strong coding skills; Python (preferred) /R/Java/Scala
Experience in developing Data warehousing technologies Experience with AWS or equivalent cloud services preferred
Experience in BigData technologies (Hadoop, HDFS, MapReduce, Spark, Hive, HBase etc) will be valuable
Knowledge of Machine Learning a big plus (Random Forest, Decision Trees, SVM, NLP, Gradient Boosting, Supervised/Unsupervised Learning, Clustering, classification and regression modeling).
Responsibilities
Proficiency with several years’ experience in more than one of Python, R, Java, Scala, or robust Linux shell scripting
Implementation experience with data warehouse architecture & design, ETL design/development, and Analytics
Knowledge of general cloud architecture and cloud strategies especially around AWS services and concepts such as S3 object stores, RDS databases, EC2, Glacier, Lambda, IAM, enterprise security, data security, DevOps, replication and disaster recovery
Well versed with data mining & exploration, NLP and visualization
Understanding of data modeling, data integration, and data representation (metadata, OWL, ontologies)
Developing data marts and data management using SQL
Creating powerful visual outcomes
Independently manage daily client communication, especially over calls
Manage client deadlines, ensure quality of the deliverables, attention to detail
Experience/understanding of corporate finance data from company filings is desirable",3.6,"Copal Partners
3.6",Bengaluru,"New York, NY",10000+ employees,1900,Company - Public,Financial Analytics & Research,Finance,₹100 to ₹500 billion (INR),-1
1105,Data Engineer,"Job Description / Responsibilities
Build workflows to ensure data extraction quality and storage into our backend data store
Architect, build and train ML/AI models that can predict outcomes and report on anomalies.
Design data pipelines to perform ETL on content/data from multiple types of source systems.
Create data analytics views using RDBMS/Key-Value stores, on private and public/cloud
Create software that is well tested, maintainable, extensible and scales out with large data

Minimum Qualifications:
2+ years of software development with Python
2+ years of SQL (MySQL/Postgres) and Key-Value databases
1+ years of experience with scikit
2+ years of experience in data extraction, data transformation using custom Python/Java
Experience working with MapReduce/Hadoop/kafka/Elastic stack
Experience with Node backend and React/Redux
Experience working with git/mercurial, Amazon/Google cloud, Linux/LAMP stack
Experience in testing or test driven development
Experience with Data science and Machine Learning algorithm development

Location:
Hyderabad/Bangalore

Package:
Highly competitive to match experience and capability",3.7,"TVS
3.7",Bengaluru,"Chennai, India",5001 to 10000 employees,-1,Company - Private,Accounting,Accounting & Legal,₹100 to ₹500 billion (INR),-1
1106,Data Engineer,"Permanent position with US based client of iFlex.
Work Location: Bangalore
Experience Level: 2+ Years

Role:
As part of our global team you will work on the data platform reporting to the Data Engineering Lead. Your role includes specification, development, test and rollout of features on our data platform. You are expected to contribute to the vision, understand our product roadmap, integrate business value andclient experience and contribute to build an engineering culture within the team. This initiative is of critical important to the success of the organization and our roadmap, for instance, services like liquidity analytics, billing, client onboarding, reporting and others will rely on the data platform. Accurate, granular, complete and timely data will be our key differentiating factor and competitive advantage in the market place. We expect the successful candidate to deliver high quality software and to be passionate about data engineering..

Responsibility / Qualification:
Managing multiple tasks and use sound judgment when prioritizing.
Collaborating with global cross functional team in building customer-centric products.
Analyzing existing software implementations to identify areas of improvement and provide deadline estimates for implementing new features.
Updating and maintain documentation for team processes, best practices and software runbooks.
Establishing trusted partnerships with peers, product heads, and executive level stakeholders.
We are looking for someone who is passionate about technology and engineering.
Exceptional analytical skills and ability to apply knowledge and experience in decision-making to arrive at creative and commercial solutions.
Ability to leverage technology to deliver business value.
You are independent and comfortable in a fast paced, ambiguous and often multi-directional work environment.

Preferred Qualifications:
B.S. or higher in Computer Science.
Minimum 2 years of relevant professional experience using a modern programming language (preferably Java/Scala).
Experience leveraging test driven development technics.
Comfort with Agile operating models.
Team oriented.
Strong interpersonal and communication skills.
Energetic, self-directed, and self-motivated.
Experience with microservice architecture.
Experience with Kafka, MongoDB, Hadoop, Cassandra.
Experience with AWS.
Experience in Financial Services or Fintech.",-1,IFLEX,Bengaluru,"Moscow, Russia",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1107,CIEL/SEL/1941: Sr data scientist,"Mandatory skills required -
Databases (SQL, Oracle, Any RDBMS) - Should have working knowledge of atleast one database
PL/SQL Programming Languages
R, Python (Any One)
Inferential Statistics - Hypothesis, p-value, R2, RMSE, MAPE etc
Exploratory Data Analysis
Machine Learning Algorithms - Should have in-depth knowledge and implementation of atleast one algorithm

Responsibilities
: Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the why & how of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions

Education
Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics
Experience
Minimum years of related experience required: 3 years
Preferred years of experience: 5 years
Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desirable.

Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
1108,Data Engineer,Data Engineer,3.6,"Bookmyshow
3.6",Mumbai,"Mumbai, India",1001 to 5000 employees,2007,Company - Private,Ticket Sales,"Arts, Entertainment & Recreation",Unknown / Non-Applicable,-1
1109,Data Analyst,"Required Skills & Experience

We are looking for a Data Analyst Executive
Eligible Qualifications : B. Tech, BCA, M.Tech, MCA
Experience : 3-5 years, fresher’s can also be considered
Location of Job : Gurgaon/Connaught Place, New Delhi
Technicals Skills

Following technical skills are pre-requisite:
Well versed with Software development methodologies, such as SDLC (Software Development Life Cycle), DDLC (Document Development Life Cycle).
Database schema design and implementation
Should have worked in either of technologies Sql Query/ Tableau/ Excel (Macros)/ Access (Query) writing for data analytics.
For planning and coordinating activities, organizations remain in invariant communication with one another and the data transfer has to be performed efficiently and smoothly as possible.
He/ She should manage the execution of the technologies, help the businesses in utilizing the systems, and should be well versed with the basics of computer systems such as Networking, Installation of necessary software and hardware.
Ability to determine the interrelationships between solutions and requirements.
Ability to think analytically and should be a problem solver and logic building should be very strong.
Good interpersonal skills to form effective working relationships with people at all levels.
Excellent communication and presentation skills and strong written & oral English skills.
To know more about us visit us www.sspl.net.in or write to us at admin@sspl.net.in",-1,Substratal Solutions,Connaught Place,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1110,Artificial Intelligence Scientists,"Experience 2- 4 Years
Salary 4 LPA - 6 LPA
Job Location Chennai

Industry:
IT-Software / Software Services

Keywords:
Artificial Intelligence

About Job:
Must have Excellent knowledge in AI / Machine learning (Mandatory).
Machine learning frameworks like keras, tensor flow etc.
And also other big data tools like Hadoop etc, Must know R and python.
Good understanding in SDLC & Business cycle.",4.0,"Careerera
4.0",Chennai,"Wayland, MA",501 to 1000 employees,-1,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
1111,Senior Data Engineer,"About Us

upGrad is an online education platform building the careers of tomorrow by offering the most industry-relevant programs in an immersive learning experience. Our mission is to create a new digital-first learning experience to deliver tangible career impact to individuals at scale. upGrad currently offers programs in Data Science, Machine Learning, Product Management, Digital Marketing, and Entrepreneurship, etc. upGrad is looking for people passionate about management and education to help design learning programs for working professionals to stay sharp and stay relevant and help build the careers of tomorrow.
upGrad was awarded the Best Tech for Education by IAMAI for 2018-19
upGrad was also ranked as one of the LinkedIn Top Startups 2018: The 25 most sought-after startups in India
upGrad was earlier selected as one of the top ten most innovative companies in India by FastCompany.
We were also covered by the Financial Times along with other disruptors in Ed-Tech
upGrad is the official education partner for Government of India - Startup India program
Our program with IIIT B has been ranked #1 program in the country in the domain of Artificial Intelligence and Machine Learning
About the Role

We are looking for a Data Engineer to help us scale the existing data infrastructure and in parallel work on building the next generation data platform for analytics at scale, machine learning infrastructure and data validation systems.
In this role, you will be responsible for communicating effectively with data consumers to fine-tune data platform systems (existing or new), taking ownership and delivering high performing systems and data pipelines, and helping the team scale them up, to endure ever growing traffic.
This is a growing team, which makes for many opportunities to be involved directly with product management, development, sales, and support teams. Everybody on the team is passionate about their work and we’re looking for similarly motivated “get stuff done” kind of people to join us!

Roles & Responsibilities
Engineer data pipelines (batch and real-time ) that aids in creation of data-driven products for our platform
Design, develop and maintain a robust and scalable data-warehouse and data lake
Work closely alongside Product managers and data-scientists to bring the various datasets together and cater to our business intelligence and analytics use-cases
Design and develop solutions using data science techniques ranging from statistics, algorithms to machine learning
Perform hands-on devops work to keep the Data platform secure and reliable
Skills Required
Bachelor's degree in Computer Science, Information Systems, or related engineering discipline
6 + years’ experience with ETL, Data Mining, Data Modeling, and working with large-scale datasets
6+ years’ experience with an object-oriented programming language such as Python, Scala, Java, etc
Extremely proficient in writing performant SQL working with large data volumes
Experience with map-reduce, Spark, Kafka, Presto, and the ecosystem.
Experience in building automated analytical systems utilizing large data sets.
Experience with designing, scaling and optimizing cloud based data warehouses (like AWS Redshift) and data lakes
Familiarity with AWS technologies preferred
Qualification – B.Tech/M.Tech/MCA(IT/Computer Science)

Years of Exp – 6-9",3.5,"upGrad Education Private Limited
3.5",Mumbai,"Mumbai, India",501 to 1000 employees,2015,Company - Private,Education Training Services,Education,₹1 to ₹5 billion (INR),"Udacity, General Assembly, Springboard"
1112,BBRC-Genomics-Associate Scientist,"JOB DESCRIPTION

Designation: Associate Scientist

Job Location: Bangalore

Department: Translational Medicine- Translational Sciences

About Syngene

Incorporated in 1993, Syngene International Ltd. is an innovation-focused global discovery, development and manufacturing organization providing integrated scientific services to the pharmaceutical, biotechnology, nutrition, animal health, consumer goods and specialty chemical industries around the world. Syngene’ s clientele includes world leaders such as Bristol-Myers Squibb, Baxter, Amgen, GSK, Merck KGaA and Herbalife. Its innovative culture is driven by the passion of its 4240- strong team of scientists who work with clients from around the world to solve their scientific problems, improve R&D productivity, speed up time to market and lower the cost of innovation .

Job Purpose:
To play a key role in TM-TS, develop an early-stage research strategy, initiate and lead discovery programs while managing ongoing programs in TM-TS. The role will work part of TMTS, and work with internal and external collaborators .

Key Responsibilities:
Experience in isolating DNA and RNA from blood, tissues and FFPE samples and cell lines. Experience with optimization of extraction protocols and for parameters like yield, input sample quantities and sample types is important.
Expertise in PCR, qPCR, cDNA/gDNA library preparation. Exposure to microarray techniques.
Proficiency in preparation of libraries for Next Generation Sequencing of transcriptome and genome, with significant experience in optimization of parameters like input RNA/DNA quantities and sample type
Experience with single cell RNA-seq will be plus.
Experience with various NGS protocols (DNA Amplicon based, hybrid capture based low input, degraded DNA and RNA samples e.g. FFPE samples.
Strong understanding of experimental design and statistical principles behind experimental design and differential gene expression. Experience with analysis of single cell RNA-sequencing data will be a plus

Educational Qualification:
M.Sc or M. Tech in Biotechnology, Molecular biology or Biological Sciences,

Technical/functional Skills:
DNA/ RNA Isolation, Expertise in PCR, qPCR, Experience in NGS protocols

Experience:
2 to 5 Years

Behavioral Skills:
A proactive team player.
Ensure completion of experiments and generate accurate and reproducible data from experiments.
Ability to work independently, prioritize tasks and work on multiple projects simultaneously with; comfortable working in a dynamic environment with changing requirements.
Good oral and written communication and presentation skills to work in a multi-disciplinary team
Equal Opportunity Employer:
It is the policy of Syngene to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by applicable legislation or local law. In addition, Syngene will provide reasonable accommodations for qualified individuals with disabilities.",3.5,"Syngene
3.5",India,"BENGALURU, India",1001 to 5000 employees,1994,Unknown,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1113,Applied Scientist 1,"Position Requirements:
Master's degree in Computer Science, Computer or Electrical Engineer, Mathematics, or a related field plus at least one year of experience in the job offered or related occupations of Software Engineer, Software Developer, or a related occupation. Employer will accept a Bachelor’s degree and five years of experience in the job offered or a related occupation as equivalent to the Master’s degree and one year of experience. One year of experience in the job offered or related occupation must involve designing and developing large-scale, multi-tiered, distributed software applications, tools, systems and services using Java, Object Oriented Design and Distributed Programming].

Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, Oracle/Berkeley databases, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills

Amazon Selling Partner Services team drives the Selling On Amazon business and develops solutions that enable millions of sellers around the world to sell on Amazon's Marketplaces. More than half of shipments for Amazon customers are generated from this business. The team is focused on building a technology platform that will support the explosive business growth in existing markets, streamline the business for Amazon and the Selling partners and launch business in new markets and establish a fair marketplace.

Our team is seeking engineers with broad technical skills to help us optimize how we synthesize massive amounts of data and complex business rules into mission critical financial information. As a member of this team you will employ object oriented techniques in Java, and DynamoB, PostGres and ElasticSearch skills to help us support Amazon's next generation of selling partner services. Along the way you'll gain and leverage a unique understanding of how Amazon.com works; from the numerous software systems that comprise the website's back-end, to the details of our business model, and the relationships we're establishing with an ever-growing network of selling partners who depend on Amazon.com to run their businesses.

The ideal candidate will draw upon exemplary analytical, critical thinking, and problem solving skills, and a passion for maintaining highly reliable, distributed systems which operate 24/7/365. Successful members of this team collaborate effectively with internal end-users, aggressive cross-functional software development teams, and technical support/sustaining engineering teams to solve problems and deliver successfully against high operational standards of system availability and reliability. We look for engineers who are excellent communicators, self-motivated, flexible, hardworking, and who like to have fun!

Position Responsibilities:
Participate in the design, development, implementation, testing and documentation of large-scale, multi-tiered, distributed software applications, tools, systems and services using [Java, Object Oriented Design and Distributed Programming]. Translate functional requirements into robust, scalable, supportable solutions that work well within the overall system architecture. Participate in the full development cycle, end-to-end, from design, implementation, and testing to documentation, delivery and maintenance. Produce comprehensive, usable software documentation. Evaluate and make decisions around the use of new or existing software products and tools.

Preferred Qualifications
Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1114,Senior Clinical Data Analyst,"About Novotech:

Novotech is internationally recognised as the leading independent and full-service contract research organisation (CRO) in the Asia Pacific region. We provide a wide range of clinical development services across all research phases and therapeutic areas and have been instrumental in the success of hundreds of Phase I – IV clinical trials throughout the Asia Pacific. Powered by the highest quality people, Novotech strives to set the benchmark for both business and clinical trial performance. Our people are one of our key strengths. We value our people and recognise the work they do. We are lucky to have the best people and talent from across the Asia Pacific region work together to deliver to clinical trial success for our clients. Our people and those we look to recruit have an attitude of making things happen. They are problem solvers, driven with a focus on delivering quality, accountability and a high level of performance.

Brief Position Description:

As part of Novotech’s Biometrics unit, the Senior Data Analyst (SDA) is responsible for all data analysis and business intelligence activities related to study related clinical and operational data. The SDA acts as primary point of contact for all data analysis matters to the study team and is responsible for the timely delivery of quality outputs following all applicable regulatory, compliance, best practice and operational procedures.

Minimum Qualifications & Experience:

Graduate in information science, data science or life science-related field, or similar. More than five years’ experience in a senior role related to data science, data analysis, clinical data management or clinical data programming in a pharmaceutical company, CRO or EDC software provider.

Responsibilities
The Senior Data Analyst (SDA) is responsible for providing technical, procedural (SOPs) and planning leadership across multiple projects assigned to the data analyst team members ensuring that they deliver in accordance with SOPs, programming best practices, and the timelines agreed within the Project Team.
Collaborate with cross-functional stakeholders to implement data science solutions to solve business needs using available technological solutions.
Scope data analysis effort for projects and project manage all data analysis activities across multiple projects for different study stakeholders.
Gather study requirements from data management for data review and external data reconciliation and provide guidance on appropriate outputs (dashboards, visualisations, listings, reports).
Extract, assess, integrate, transform data sources to provide data visualisation outputs for analytics.
Design and develop prototypes and final versions of data outputs (dashboards, reports, visualisations, listings) using Business intelligence tools and Data Visualisation tools.
Design and develop standard dashboards and content for different audiences.
Analyse, manipulate and understand data from multiple sources to present and create dashboards and reports to make business decisions.
Assist teams on best-practice for data visualisation dashboard development.
Educate teams on how to use all the features of applicable data visualisation platform in conjunction with data visualisation dashboards.
SME for the data visualisation development and assisting team members.
Identify and communicate project risks and maintain documentation within project files as appropriate
Represent data analysis group at internal / external meetings as appropriate.
Assess and implement new data analysis, BI and data visualisation processes and technologies.
Take an active role in the development of best practices, process improvement, quality control and governance related to all data analysis matters.
Provide training and mentoring to Data Analysis of team members in SOPs, software applications, and best practices.
Provide Subject Matter Expertise on all data analysis and visualisation related activities.
Attributes and Skills

Expert knowledge of clinical study data structures and schemas of EDC databases. Expert knowledge in data processing activities such as extracting, integrating, transforming and presenting data. Statistical Programming skills in Python, R or similar. Knowledge of SQL and EDC systems. Working knowledge of Spotfire, Power BI, Tableau or other data review and visualisation tool. Ability to gather business requirements from multiple stakeholders and clients and provide guidance on the use of appropriate data visualisations.

Experience mentoring and training others. Awareness of regulatory and compliance issues and understanding of the application of SOPs and Quality Control to daily activities. Excellent analytical, communication and problem-solving skills.

Opportunities and Benefits:

To deliver clinical trial and research excellence for our clients, our people are 'best in class'.

At Novotech, we seek and nurture people with exceptional talent. We are committed to providing our people with regular internal and external training, a competitive bonus structure and a supportive work environment. We are also focused on providing our people with a wide variety of career growth and development opportunities.

For more information about where your next career step at Novotech might take you, visit http://novotech-cro.com/novotech-careers",4.5,"Novotech
4.5",Bengaluru,"Sydney, Australia",501 to 1000 employees,1996,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
1115,Data Engineer,"Data Engineer Responsibilities:
Liaising with coworkers and clients to elucidate the requirements for each task.
Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed.
Reformulating existing frameworks to optimize their functioning.
Testing such structures to ensure that they are fit for use.
Preparing raw data for manipulation by Data Scientists.
Detecting and correcting errors in your work.
Ensuring that your work remains backed up and readily accessible to relevant coworkers.
Remaining up-to-date with industry standards and technological advancements that will improve the quality of your outputs.
Data Engineer Requirements:
Bachelor's degree in Data Engineering, Big Data Analytics, Computer Engineering, or related field.
Master's degree in a relevant field is advantageous.
Proven experience as a Data Engineer, Software Developer, or similar.
Expert proficiency in Python, C++, Java, R, and SQL.
Familiarity with Hadoop or suitable equivalent.
Excellent analytical and problem-solving skills.
A knack for independent and group work.
Scrupulous approach to duties.
Capacity to successfully manage a pipeline of duties with minimal supervision.
Job Type: Full-time

Salary: ₹360,000.00 to ₹870,000.00 /year

Experience:
total work: 2 years (Preferred)
Data Engineer: 1 year (Preferred)
Education:
Diploma (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,Futurious Technologies,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1116,Quantitative Analyst,"The successful candidate will be a highly analytical individual with hands on programming skills. The candidate will work closely with the research team and clients towards the ongoing development and integration of new investment strategies, models and tools on Axle

Location

Mumbai
Responsibilities

Perform daily/weekly/monthly tasks of performance and risk reporting
Develop and automate investment processes and strategies via VBA and Matlab
Develop tools to integrate trading decision systems with risk management systems
Ad hoc tasks (such as operational tasks, internal documentation tasks and preparation of marketing materials)
Skills/Experience

Excellent programming skills in Matlab/Excel-VBA
Thorough with financial concepts and calculations like Drawdown, VaR, Eloss etc.
Understanding of financial market products like options, futures, FX forwards etc.
Working knowledge of Bloomberg is preferred
Should be self-driven and detail oriented with an analytical mindset
Should be a proactive and quick learner; a team player showing enthusiasm and drive to accomplish results in a fast paced environment
Min. 2 years of relevant work experience
Qualifications

B.Tech/M.Tech/MBA/CFA/FRM",5.0,"B&B Analytics
5.0",Mumbai,"Zug, Switzerland",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1117,Analyst - Data Scientist,"Job Summary

Experience:
3 - 5 Years

Location:
Mumbai

Designation:
Analyst - Data Scientist

Degree:
BE-Comp/IT, BE-Other, BTech-Comp/IT, BTech-Other, ME-Comp/IT, ME-Other, MTech-Comp/IT, MTech-Other, PhD-Comp/IT, PhD-Other

Educational Level:
Graduate/Bachelors

Industrial Type:
IT-Software/Software Services

Functional Area:
IT Software - Application Programming / Maintenance

Key Skills:
Data Scientist

Job Post Date:
Thursday, March 19, 2020

Company Description

We are capability centre based in Mumbai, initially started as a back-office operational support to the UK business unit.

However, over the recent years, we have significantly increased the breadth and depth of our capabilities and offerings to keep pace with the changing needs of the Group. These include Digital & Knowledge Services, Finance and Actuarial, Information Technology (IT), Customer Service, Risk and Audit.

Our core purpose is to be a strategic partner to company, enabling growth by delivering change and driving synergies through a highly capable and agile workforce.

With our diversified service offerings we provide our people with exciting opportunities to grow personally and professionally.

Company is a leading savings and investments business serving around 5.5 million retail customers and more than 800 institutional clients.

It-s innovative asset management and customer solutions are supported by extensive investment capabilities, an international distribution network and two strong brands.

Job Description

3 – 5 yrs experience as Data Scientist
Should have at-least 1 end-to-end ML project experience
Very high proficiency in R or Python
Excellent in forecasting methods like simple exponential smoothing, multiplicative seasonal indexes, simple and weighted moving averages and time series forecasting methods
Exposure to with advanced deep learning techniques such as LSTM. CNN, Dense neural networks as well as neural networks design and implementation through tools like tensorflow, keras, pytorch, deepai or equivalent.
Good SQL experience",3.8,"Sampoorna Computer People
3.8",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
1118,Data Lake Developer,"For Us, It's A Mission

At Mylan, we mean it when we say we work every day to provide access to high quality medicines to the world's 7 billion people. If you are unconventional, relentless and passionate. If you believe in doing what's right, not what's easy. If you are a doer and have a passion for serving others, we want to talk to you.

Make a Difference

At Mylan, each person has the ability to make a difference. From the providers who sell and market our products, to the producers who develop and manufacture them and finally to our business partners who support the providers and producers, we all have a mission critical role. Here's how this role will help:

ESSENTIAL DUTIES AND RESPONSIBILITIES
To perform this job successfully, an individual must satisfactorily perform each essential duty. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential duties.
1. Create and maintain optimal data pipeline architecture on Azure platform.
2. Develop batch processing solutions by using Data Factory and Azure Databricks.
3. Delivering a Data Warehouse in the Azure Cloud.
4. Design relational and non-relational data stores on Azure.
5. Identify, design, and implement internal process improvements : automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc..
6. Developing Big Data Solutions with Azure Machine Learning.
7. Strong interaction with business departments to provide consultative support for digitization efforts, as well as close collaboration with the Business Technology management, focused on future innovation topics.
8. Participate and lead in design sessions, demos and prototype sessions, testing and training workshops with business users and other IT colleagues.
9. Design & Build for any API Development or SQL DB development.
10. Providing service management, orchestration, monitoring and management requirements of Azure cloud platform.
11. Create data tools / products for analytics and data scientist team members that assist them in building and innovative solutions that drive tangible business value.
12. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
13. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
14. Design security for source data access. Chose the appropriate authentication mechanism, (ie Azure Active Directory (Azure AD), etc).
15. Design for real-time processing by using Stream Analytics and Azure Databricks.

Make Our Values Your Values

Mylan hires only the best. People who thrive in a culture of innovation and empowerment. People who are active learners and have a positive attitude. People who are leaders and know that by working together we can run faster, reach higher and achieve more. By doing so, we will continue to set new standards in health care. Here are the minimum qualifications and essential functions for this position:

QUALIFICATIONS

The qualifications listed below are representative of the minimum knowledge, skill, and/or ability required.

SKILLS AND ABILITIES

1. 10 years of experience in Microsoft technologies including SQL.

2. At least 5 years as a Sr Developer with at least 3 years hands on experience as Azure Data Engineer building large scale Azure data solutions.

3. At least 5 years of experience in Azure based data solutions.

4. At least 3 years of experience on working with large projects including the most recent project in the cloud (Azure) or on prem with a focus on Azure Data services.

5. At least 5 years of Hands-on administration, configuration management, monitoring, performance tuning of Hadoop/Distributed platforms.

6. At least 5 years of demonstrated experience at least in the most recent 2 years of designing and delivering solutions using Cortana Intelligence suite of analytics services part of Microsoft Azure including Azure Machine Learning Studio, HDInsight, Polybase, Azure Data Lake Analytics, Azure Data Warehouse, Streaming Analytics, Data Catalog, R/R Studio

7. Experience in designing and building logics required for optimal extraction, transformation, and loading of data from a wide variety of data sources

8. Experience within Data Security design, including but not limited to:

a. Choosing the appropriate authentication mechanism, such as Azure Active Directory (Azure AD)

b. Defining strategies for data encryption for data at rest and in transit

9. Experience partnering with Business Analysts and Data Scientists to enable effective and efficient data preparation and delivery

10. Experienced in vendor management and working with 3rd parties onshore & offshore.

11. Experience working in a global team.

12. Experience working in an Analytics / Big Data solutions on MS Azure Cloud

13. Experience with code management tools, automated testing

14. Experience creating and maintaining optimal data pipeline architecture on Azure platform

15. Experience developing batch and real-time processing solutions by using Data Factory and Azure Databricks

16. Familiar with AGILE and Azure DevOps methodology

17. Hands on PoC capabilities are needed to prove a particular architecture concept

18. Azure Native Services experience across Data Fabric and Service Fabric

19. Experience in Application modernization from legacy on-premise data architecture platform technology stack to modernized Azure Cloud base Architecture.

20. Experience with Git, NoSQL Data Solutions, Microsoft Azure, HD Insights, Azure ML, DataBricks ML Flow, R or Python.

21. Must have excellent communication skills.

EDUCATION/EXPERIENCE (Note: Please select one)

Minimum of a Bachelor's degree in Computer Science and Engineering is preferred with minimum 10 years of experience. However, a combination of experience and/or education will be taken into consideration

Why Mylan?

If you want to be part of a global health care company that is making a difference and changing lives, Mylan may be the place for you. With a workforce of more than 35,000 worldwide, we can make a difference. We encourage you to visit Mylan.com to learn more about our unconventional culture, our approach to doing business and how we plan to set new standards in health care.

Mylan offers competitive salary, excellent benefits and an environment conducive to professional growth and advancement. All qualified applicants will receive consideration for employment without regard to their disability or protected veteran status. Mylan is an Equal Opportunity Employer, Minorities/Female/Disabled/Veteran.",3.8,"Mylan Inc.
3.8",Bengaluru,"Hatfield, United Kingdom",10000+ employees,1961,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1119,Off Campus Recruitment - Quantitative Researcher,"Description:
Graviton is a privately funded quantitative trading firm striving for excellence in financial markets' research. We are seeking fresh talent from the top IIT's to join us as Quantitative Researchers for our team in Gurgaon.If you are a student graduating in 2020 from Computer Science , Electrical or Maths Stats Computing streams with a greater than 8 CGPA please apply here.

This role is open to students from campuses that we could not visit this year. Please check your individual placement policy restrictions before applying.

Graviton trades across a multitude of asset classes and trading venues using a gamut of concepts and techniques ranging from time series analysis, filtering, classification, stochastic models, pattern recognition to statistical inference analysing terabytes of data to come up with ideas to identify pricing anomalies in financial markets.

As a Quantitative researcher your responsibilities will include

Develop new or improve existing trading models using in-house platforms

Use advanced mathematical techniques to model and predict market movements

Analyse large financial datasets to identify trading opportunities

Provide real time analytical support to experienced traders

Requirements :
Possess a degree in a highly analytical field, such as Engineering, Mathematics, Computer Science from IITs schools

Quantitative bend of mind

A working knowledge of Linux/Unix

Programming experience, preferably in C++ or C

Strong interest in learning about financial markets.

Have a strong work ethic

Hard Working

Benefits:
Our open and casual work culture gives you the space to innovate and deliver. Our cubicle free offices , disdain for bureaucracy and insistence to hire the very best creates a melting pot for great ideas and technology innovations. Everyone on the team is approachable, there is nothing better than working with friends!

Our perks have you covered.

Competitive compensation

6 weeks of paid vacation

Monthly after work parties

Catered breakfast and lunch

Fully stocked kitchen

Gym membership

International team outing",5.0,"Graviton Research Capital LLP
5.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2014,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1120,Data Engineer,"Zauba Technologies is a startup based in Bangalore. Zauba's services are used by leading companies in India. Zauba is powered by a young and passionate team. We are looking for individuals who would like to be a part of our founding team.

As a Data Engineer and as a part of founding team, you will be expected to visualise and develop disruptive data products. Eventually you would be responsible for entire project lifecycle of products you would visualize. Your rewards will be directly proportional to the value you generate.

Job Responsibilities
Design and development of robust, scalable and highly efficient data engineering solutions for structured and unstructured data (Including gathering and processing raw data at scale, writing scripts, web scraping, calling APIs, writing SQL queries, etc.)
Develop processes for text mining and extraction of information from unstructured data
Design, architect and develop efficient data pipelines around the data collected
Take ownership of existing web product and applications
Design and implement data models that scale across the enterprise
Take ownership of existing data workflows and processes
Enhance scalability, performance, and stability of existing infrastructure
Work closely with other team members to integrate your innovations and algorithms into our production systems

Essentials
Java/Python - Intermediate to advanced level
SQL - Advanced
MySQL Intermediate to advanced level
Regex - Basic to intermediate level
Linux Basic to intermediate level

Good to have
Hadoop/Spark
R
MongoDB

Must have qualities
Skills to learn new skills quickly
Desire to create disruptive products and services
Passion - not just to work in startups but to take them to next level
Above average programming aptitude
Be passionate about producing high quality engineering deliverables
Be productive working independently or collaboratively
Have an eye for building efficient processes
Be self motivated
Proactively take ownership

Interested?

Send your resume to hr@zaubacorp.com",3.8,"Zauba Corp
3.8",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 million (INR),-1
1121,Quantitative Research,"We are looking for highly trained professionals who are interested in applying advanced mathematical quantitative methods to the modeling of global financial markets. You would be joining a group made up of highly proficient individuals from various scientific disciplines. We have a spectrum of opportunities for individuals with the right scientific skills. Experience in finance is not required.

The ideal research candidate will have:
A Ph.D. in Computer Science, Mathematics, Physics, Statistics, or a related technical discipline.

A demonstrated capacity to do first-class research.

Computer programming skills.

An intense interest in applying quantitative analysis to solve difficult problems.

Send us a copy of your resume to
careers@dolatcapital.com

For internship opportunities, please send us a copy of your resume to
careers@dolatcapital.com",4.0,"Dolat Capital
4.0",Mumbai,"Mumbai, India",51 to 200 employees,1970,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1122,Data Engineer,"Bachelor’s degree in Computer Science or related field
5+ years relevant experience
5+ years experience with SQL, SQL Tuning, Oracle, OLAP, Big Data Technologies
5+ years experience developing end-to-end Business Intelligence solutions: data modeling, ETL and reporting
Experience with Java and experience with scripting languages like Perl, Python, Unix shell scripts,VBA and MS Excel
Proficiency with Linux and systems administration
Proven ability at looking at solutions in unconventional ways. Sees opportunities to innovate and can lead the way.
Top notch communication (verbal and written) and interpersonal skills to convey key insights from complex analysis in summarized business terms and an ability to effectively communicate with technical teams.
Ability to work with shifting deadlines in a fast paced environment.
Operations Finance Technology team, responsible for building technical solutions for multi-billion WW Operational Cost analytic including Inbound cost (Receiving / PO), variable Cost, fixed cost, outbound (Customer Shipments / Transportation), and Customer Service, is looking for a Data Engineer.

As a data engineer, you will get the exciting opportunity to work on very large data sets in one of the world's largest and most complex data warehouse environments. You will work closely with the business teams in analysis on various cost savings initiatives, many non-standard and unique business problems and use creative-problem solving to deliver actionable output.
You will be responsible for designing and implementing an analytical environment using third-party and in-house reporting tools, modeling metadata, building reports and dashboards. You will have an opportunity to work with leading edge technologies like Redshift, Hadoop/Hive/Pig. You will be writing scalable queries and tuning performance on queries running over billion of rows of data.

You should be analytical, have an extremely high level of customer focus and a passion for process improvement. You should be motivated self-starter that can work independently in a fast paced, ambiguous environment. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions.
Bachelors in Computer Science or related field
Practical Knowledge of Linux or Unix shell scripting
Experience in working with business customers to drive requirements analysis
Exposure to large databases, BI applications, data quality and performance tuning
Excellent written and spoken communication skills
Experience with Hadoop-based technologies such as HBase, Pig, Hive and Spark
Strong proven ability in building high-performance, highly available and scalable data solutions using Oracle and/or Hadoop-based technologies
Knowledge of data warehousing concepts.
Strong sense of ownership, urgency, and drive
Strong troubleshooting and problem solving skills
Experience with Amazon Web Services",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1123,DATA ANALYST,"posted by Mahima Gaur

2 - 5 years Delhi

Job Description
Experience in data processing
Experience in data cleaning and data tabulation activities
Strong analytical, communication and team management skills
Strong understanding of data management using SPSS and research techniques
Competency in a Tabulation software (decipher / wincross / quantum etc), Excel, Powerpoint
Ability to summarize findings, draw conclusions, and put together a presentation using Powerpoint
Role Category : Data Analyst

Employment Type : Permanent Job, Full Time",4.9,"Knowledge Excel Services.
4.9",New Delhi,"New Delhi, India",1 to 50 employees,2007,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
1124,Data Engineer,"Key skills : Python , Spark , SQL , Pyspark • AWS platform used for the work • Strong experience in SQL is mandatory • Good familiarity of AWS landscape • Good experience in collecting business requirements & design them as per requirement from customer • Should able to work independently & interact business users & technical stakeholders • Strong communication skills both oral & written. • Should work as an individual resources",3.5,"Larsen & Toubro Infotech Limited
3.5",India,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1125,Big Data Engineer,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
1126,Client Data Analyst,"At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.
What is the Client Data Analyst – Client Analytics group responsible for?
This team manages business data to ensure accurate, timely, consistent and compliant data. Their contributions deliver quality data that is easily accessible and can be trusted. Key downstream capabilities such as reporting and analytics depend on this as well as operational data access on various systems. The Data Management Team is a support function that acts as an advocate and a point of contact for Sales and Marketing data.

What are the ongoing responsibilities of an Client Data Analyst ?
Understand the data flow, key consumption and production of data as well as context within the enterprise:
Build positive relationships with teams, especially the key data consumers and analytics. Take the time to increase knowledge of how they run their business and incorporate sales data into daily work
Connect regularly with each sales office to understand current issues and challenges. Probe the business and validate against other sales offices to understand the scope and priority of the issue
Make recommendations on how data unifications and flow can be used to improve business tasks. Liaise business partners to deliver solutions (reports, processes, technology) that add value.

Provide data management subject matter expertise. Appreciate the connection and data flow between applications and other corporate systems. Be able to clearly articulate the data needs and move initiatives forward by collaborating with business partners:
Actively participate in meetings with business partners to ensure that priorities are clearly understood, information is regularly shared and that key participants are “kept in the loop”
Provide context and background on issues. Collaborate on ideas for progressing initiatives. Ensure appropriate resources are involved to take initiatives forward
Provide insights and expertise to scope statements and requirements documentation
Actively consult or participate in the user acceptance testing process (test cases, documentation, testing execution, etc.)
Ensure business needs remain aligned with overall corporate initiatives and deliver the benefits as originally intended

Monitor the integrity of data and usefulness of reports. Ensure the information available within systems is accurate and up-to-date. Proactively seek data cleansing opportunities and evolve data to better support. Document and maintain ongoing processes for reporting and data clean-up:
Partner with all key data consumers to gain a solid understanding of usage and challenges around data. Establish processes for prioritization of enhancements, especially with the analytics groups
Provide 1st level support for data issues and data maintenance for owned data
Verify and execute data loads into our internal sales systems and ensure any upstream systems accurately receive their data

Increase awareness and promote data management capabilities. Share best practices and provide coaching to local offices on how to access and incorporate output into sales tasks. Encourage IAS leaders to leverage data to make more informed, strategic decisions:
Clearly articulate the goals and core services of the data management team. Proactively promote this information within IAS and ensure business partners understand the data management role within the organization
Share best practices and provides guidance on data capabilities. Reinforces ownership and accountability for data accuracy
Seek opportunities to share the benefits of leveraging sales data to make more informed business decisions

What ideal qualifications, skills & experience would help someone to be Successful?

Knowledge, Education And Experience:
Four year bachelor’s degree required (majors of preference include: business, computer science, mathematics) Advanced degree a plus
Understanding of the Franklin Templeton business model, how FT makes money, the sales process, how technology fits in with the business, etc. Knowledge of the GAS (Global Advisory Services) structure
Experience working through multiple business fiscal cycles; exposure and/or direct experience with project management and/or sales-related-capacity required
Prior work experience related to analytics, sales, marketing and/or international a must. Level will not be granted based on years of experience but will be determined by the employee’s ability to meet each job activity as outlined the ‘typical/expected focus by level
Skills And Abilities:
Ability to communicate effectively with all levels of management; ability to tailor communication style based on audience; ability to get others to want to collaborate with you; strong facilitation skills
Excellent writing skills (for presentations, documentation, etc.)
Working knowledge of the CRM, MDM, Excel, SQL, Power BI, Tableau, Business Objects, and Microsoft Products (PPT, Power Apps, Doc, Visio)
Ability to absorb and interpret large quantities of data; apply trend analysis and knowledge of the business to develop a meaningful and digestible summary with the appropriate level of detail
Ability to take a larger problem and break down the individual components; identify how to go about solving the problem and who to involve in the process
Ability to present recommended solutions to a variety of issues and problems (solutions that are consistent with organization objectives)
Must be extremely detail-oriented (managing lists, tasks/to-dos, etc.) good with follow through on own items; good with following up with others on outstanding item

What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.

Highlights of our benefits include:

Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.",3.8,"Franklin Templeton Investments
3.8",Hyderabad,"San Mateo, CA",5001 to 10000 employees,1947,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Fidelity Investments, Vanguard"
1127,Data Analyst,"Roles and Responsibilities:
Extracting, transforming and inputting data sets from various resources. Creating predictive models, translating non-technical aspects into quantifiable tasks. Analysis and representation of output data, highlight and explain trends and patterns, error elimination, using advanced statistical methods (regression, probability distribution, clusters etc.) to provide accurate results.
Data collection, Data Mining, Report generation, Problem identification and solution formulation Market analysis and establishing trends, Strategy development and implementation

Skills:
Extremely good analytical skills.
Good working knowledge of all MS-Office products, especially Advance Excel, Word, PowerPoint, MS-access.
Statistical tools and methods.

Interested candidates can send the updated resume on satish.mehra@exelaonline.com or call on 7722028636
00-7.00 Years",2.6,"Exela Technologies
2.6",Pune,"Irving, TX",10000+ employees,2017,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"SourceHOV, BancTec, Transcentra"
1128,Data Modeler,"• Minimum 5-8 years of working experience as Data modeler.
• Data modelling experience in designing.
• Minimum 2-3 years real time experience in Erwin tool is mandatory.
• Experience in normalized modeling techniques.
• Experience in designing the Start schema.
• Experience working in ORACLE.
• Experience with database design, capacity planning, performance tuning and query optimization.
• Experience in working with Bank or Banking and Finance or Financial domain.
• Excellent communication skills with leadership quality.

Job Segment:
Database, Oracle, ERP, Technology",3.5,"LTI
3.5",Mumbai,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1129,Machine Learning Engineer,"Looking for Data Scientists with Python/R Programming skills.
Specific experience in AI areas like Statistical Machine learning / Deep learning / Natural Language Processing (NLP)/ Operations Research (Optimization) will be an advantage.Individual in this role is expected to work with multiple stakeholders and teams

Qualifications and Requirements:-
Previous working experience as a Machine Learning/ Data Scientist for 2 years
MA in Computer Science or similar relevant field
Hands on experience with MALLET
In depth knowledge of Apache Tomcat/Open Source
Excellent project and time management skills
Attention to detail
Outstanding problem solving and analytical skills",-1,Tekolutions.ai,India,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1130,Data Science Internship,"About the company:
SkillBit is a leading staffing and recruitment company engaged in talent searching assignments for skilled and talented candidates for the industry.

About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Working on data science algorithms and AI concepts 2. Using Python or R for web scraping 3. Building AI models using Python, machine learning, and deep learning algorithms 4. Processing of unstructured/structured data

Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 6th Jun'20 and 11th Jul'20
are available for duration of 1 month
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply

Number of internships/jobs available: 3

Categories: Data Science",-1,SkillBit,Pune,-1,-1,-1,-1,-1,-1,-1,-1
1131,Data Engineer,"As a data engineer at TEAL, you'll be taking the plunge into a rich data lake that includes everything from satellite data to legal court orders. You'll be hustling and getting your hands dirty with every part of the data pipeline always having an implicit appreciation for how all of this data will ultimately power a revolutionary real estate risk platform.

Your day-to-day will include either all or some of the following:

Constantly scoping out new data sources to complement existing ones
Creating and maintaining distributed web scrapers using Python, RabbitMQ and other technologies
Architecting and managing data pipelines where data flows into multiple end-points including, but not limited to, Postgres, MongoDB and Apache Solr
Documenting workflows and constantly iterating to create better data infrastructure.

We'd love it if you:
Are proficient in Python or any other object-oriented language
Have worked with large (millions to hundreds of millions of rows in a SQL database) interdisciplinary datasets
Have scraped difficult websites and have some experience working with various data APIs
Are patient and methodical with unstructured and messy data
Are always hungry to learn newer and better technologies to make the data ecosystem faster, smoother and less silo-ed

Extra brownie points if you:
Have some experience working with large-scale search indexing
Have performed geospatial analyses in some capacity
Have created and managed data lakes in the cloud
Culture

To explore our culture and the values we embody click here

Testimonials
Testimonial

My experience at TEAL surpassed all my expectations from the get-go. I was asked to help solve one of the most daunting problems in the Indian real estate market. Every day while working on a subset of the problem, the ideas that I brought to the table were shaped into cohesive solutions by a collaborative team effort. At TEAL I was exposed to the most cutting edge technologies such as Cloud Computing, Big Data, ML and Data Science. The growth opportunities at TEAL are tremendous, If you are innovative and can demonstrate the will to realize your ideas, TEAL is an amazing organization to work for.
Gyan Vardhan, Data Science Intern
I had interned as a Data Scientist at Terra Economics and Analytics Lab during its early days, it was a rich learning experience working with a multi-disciplinary team who are extremely passionate about building a decision support platform for the insanely complicated realty market in India. It was exciting and challenging to work on mining huge volumes of property records; extracting patterns from the data, building data pipelines and brainstorming on building the core system. TEAL offers a very healthy work environment coupled with insanely talented people working together in an exciting setting.
Naga Anjaneyulu, Data Science Intern
I worked as a full-time Data science intern at TEAL. During this period, I got an opportunity to leverage my skillsets while also learning new technologies, working on tasks assigned to me. The company operates on the latest tech-stacks and gives opportunities to learn as much as you want. The work environment is challenging, the team at TEAL is super supportive and new ideas are always welcome. It has all the good perks of a startup; creativity and innovation, casual work atmosphere and a collaborative approach to solving problems. Personally, I loved working there, my experience was fantastic!
Archana Parmar, Data Science Intern
As a second-year college student, I was looking for an internship that would allow me to delve deeper into research and work with big data, TEAL gave me the perfect opportunity to do so, enabling me to develop proficiency in research and analysis. As a research analyst intern, I collated and cleaned data and helped in the preparation of reports and presentations, and I had members helping me at every stage of this process. This collaborative environment allowed me to cultivate my skills and also learn from my peers. The holy trinity of Rohan, Kshitij, and Shreyas served as not only excellent mentors and bosses but also as friends, helping me at every stage and giving us all food and ice cream to keep us going!
Arush Mehra, Research Intern
Internships are a crucial part of one’s early career. The internship experience at TEAL was a thrilling rollercoaster ride to say the least! It was more than implementing a standard model or building an already though out concept into reality. It was about finding the solution to a unique and open-ended problem.It was exciting to work on addressing a problem with far -reaching real world applications.Moreover, the work environment had the perfect balance of casual yet professional which kept you focused and stress free at the same time. Out of every 100 startups in India only 2 of them succeed, but there are very few like TEAL India which are bound to make it big at such an early stage.
Divyanshu Agarwal, NLP Intern",4.7,"Terra Economics & Analytics Lab (TEAL)
4.7",New Delhi,"Bengaluru, India",1 to 50 employees,2018,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
1132,Senior Consultant - ModellingOps Data Engineer,"Job Title: Senior Consultant - ModellingOps Data Engineer
Location: TRIL GTC
GCL: D1

JOB DESCRIPTION:

AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. The Science & Enabling Units IT is AZs global IT capability function supporting key business areas operating out of sites across the US, UK, Sweden, India & Mexico.

We are looking for AI Ops consultant who will leverage tools & technology best practices to improve delivery performance & data engineering capabilities in the D&A space.

ROLES & RESPONSIBILITIES:

7-10 years of experience in IT Operations involving Data Science, Artificial Intelligence-Machine Learning and Predictive Analytics. Experience in architecting and implementation of end-to-end AIOPs solutions through ELK stack, Splunk. Experience in applying statistical methods, analysis, pattern recognition and modeling on IT Operational data using ELK machine learning. Experience in extracting meaning full data from incoming data streams from different sources through RegEx, Grok etc. Hands-on experience in applying machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc in the IT Operation domain. Experience with machine learning and statistical programming languages - Python, R etc. Experience in assessing the existing IT environment and providing recommendations to reduce the critical applications impacting incidents. Experience in exploring and identifying areas where manual tasks can be automated in IT environment. Experience with various Enterprise IT monitoring solutions including Infrastructure monitoring, Application Performance Monitoring, Network Monitoring, Cloud monitoring etc. Experience in IT Service Management including Service Desk, Incident Management, Change Management, CMDB etc. Excellent knowledge on various IT infrastructure components that includes Server Infrastructure, middle ware, database and application architectures and Cloud Components. Experience/knowledge on Infra monitoring tools - NOI, Zabbix, AppDynamics, Datadog, SCOM, SolarWinds etc. and Service Management tools -IBM Control Desk, BMC Remedy, ServiceNow etc. Experience/Knowledge on BI tools Knowledge on distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc. Knowledge on other programming languages/scripting: Python, Java, JavaScript, etc. ( Added Advantage ) Good analytical skills, strong communication skills are must. Client facing experience is an added advantage. Excellent experience in understanding the problem statement, architect and designing the solution

MANDATORY SKILLS:
Significant experience with AWS cloud environments, working knowledge of Google and Azure platforms. Knowledge of Kubernetes, S3, EC2, Sagemaker, Athena, RDS and Glue is essential.
Experience provisioning computational resources in a variety of Cloud environments using Infrastructure as Code.
Experience with best practice of data transport and storage within cloud system.
Experience building large scale data processing pipelines. e. g. Spark and SQL.
Experience with containers and microservice architectures e.g. Kubernetes, Docker and serverless approaches.
Excellent working knowledge in DevOps, using continuous integration and continuous development.
Use of Data Science modelling tools e.g. R, Python, SAS and Data Science notebooks (e.g. Jupyter).
Good written and verbal skills, fluent English
DESIERED SKILLS:
Agile practices, especially being a SCRUM Master
EDUCATIONAL BACKGROUND: B.E/B.Tech/MCA

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",3.9,"AstraZeneca
3.9",Chennai,"Cambridge, United Kingdom",10000+ employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Roche, GlaxoSmithKline, Novartis"
1133,DATA ENGINEER,"JOB DESCRIPTION
As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements, and also research new uses for data acquisition. You should also know the ins and outs of the industry such as data mining practices, algorithms, and how data can be used.

DESIRED CANDIDATE PROFILE
An ideal candidate must possess prior experience leading a project.

Candidates must have:
> Experience in Hive, Spark, Scala, AWS DynamoDB, HBase, AWS Glue, Talend, Kafka, Snowflake ETL
> Strong experience in a BI/Data Warehouse environment with involvement in design, development, implementation, troubleshooting and support of ETL process using ETL tool.
> Experience in developing Data Marts, Data warehousing and Operational Data Store (ODS) on any of the databases or Hadoop environments.
> Experience in database like MS SQL, MySQL, Oracle, PostgreSQL
> Good to have programming experience in writing Complex Stored Procedures, Queries, Views, User Defined Functions, Cursors and Common Table Expressions using SQL or T-SQL.
> Experience in Performance Tuning and Query Optimization by Indexing, Partitioning and De-normalization.
> Experience in Developing a framework for ingesting data into Data lake
> Good database knowledge, analytical thinking
> Design, construct, install, test and maintain data management systems.
> Build high-performance algorithms, predictive models, and prototypes.
> Develop set processes for data mining, data modeling, and data production.
> Experience with cloud services: AWS (EC2, EMR, S3, Athena) and scripting languages like Python, /PySpark/R/SAS
> Install/update disaster recovery procedures.
> Experience in Agile Application Development & Scrum methodologies is preferred
> Ability to supervise and mentor junior developers on the team.
> Must be self-motivated and work well pulling people together in addition to being able to pull people together technically
> Demonstrated proficiency of troubleshooting techniques and detail-oriented problem diagnosis
> Ability to handle responsibility, is self-directed, with strong organizational and documentation skills
> Ability to work independently and efficiently under aggressive deadlines to meet project commitments
> Excellent verbal and written communication skills

EDUCATION
UG - B.Tech/B.E. - Computers, Electronics/Telecommunication, Diploma - Computers, Electronics/Telecommunication, B.Sc - Computers, BCA - Computers) AND (PG - M.Tech - Computers, Electronics/Telecommunication, MCA - Computers, M.Sc - Electronics, Computers) AND ( Doctorate - Any Doctorate - Any Specialization, Doctorate Not Required).

OTHER DETAILS
Number of vacancies: 4
Experience: 3 years
Location: Cochin

If you have a passion towards technology and coding, then we have the right job for you. Kindly forward your resumes to
Email: jobs@mjsofttech.com
Phone: 0484-2421245 / 928 720 7160",4.0,"MJ Softtech
4.0",Kochi,"Cochin, India",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
1134,Data Engineer,"Education/ Experience and Skill Requirement
4+ years of relevant experience in
Experience working with both relational and NoSQL databases.
Strong coding skills; Python (preferred) /R/Java/Scala
Experience in developing Data warehousing technologies Experience with AWS or equivalent cloud services preferred
Experience in BigData technologies (Hadoop, HDFS, MapReduce, Spark, Hive, HBase etc) will be valuable
Knowledge of Machine Learning a big plus (Random Forest, Decision Trees, SVM, NLP, Gradient Boosting, Supervised/Unsupervised Learning, Clustering, classification and regression modeling).
Responsibilities
Proficiency with several years’ experience in more than one of Python, R, Java, Scala, or robust Linux shell scripting
Implementation experience with data warehouse architecture & design, ETL design/development, and Analytics
Knowledge of general cloud architecture and cloud strategies especially around AWS services and concepts such as S3 object stores, RDS databases, EC2, Glacier, Lambda, IAM, enterprise security, data security, DevOps, replication and disaster recovery
Well versed with data mining & exploration, NLP and visualization
Understanding of data modeling, data integration, and data representation (metadata, OWL, ontologies)
Developing data marts and data management using SQL
Creating powerful visual outcomes
Independently manage daily client communication, especially over calls
Manage client deadlines, ensure quality of the deliverables, attention to detail
Experience/understanding of corporate finance data from company filings is desirable",3.6,"Copal Partners
3.6",Bengaluru,"New York, NY",10000+ employees,1900,Company - Public,Financial Analytics & Research,Finance,₹100 to ₹500 billion (INR),-1
1135,Data Engineer,"Job Description / Responsibilities
Build workflows to ensure data extraction quality and storage into our backend data store
Architect, build and train ML/AI models that can predict outcomes and report on anomalies.
Design data pipelines to perform ETL on content/data from multiple types of source systems.
Create data analytics views using RDBMS/Key-Value stores, on private and public/cloud
Create software that is well tested, maintainable, extensible and scales out with large data

Minimum Qualifications:
2+ years of software development with Python
2+ years of SQL (MySQL/Postgres) and Key-Value databases
1+ years of experience with scikit
2+ years of experience in data extraction, data transformation using custom Python/Java
Experience working with MapReduce/Hadoop/kafka/Elastic stack
Experience with Node backend and React/Redux
Experience working with git/mercurial, Amazon/Google cloud, Linux/LAMP stack
Experience in testing or test driven development
Experience with Data science and Machine Learning algorithm development

Location:
Hyderabad/Bangalore

Package:
Highly competitive to match experience and capability",3.7,"TVS
3.7",Bengaluru,"Chennai, India",5001 to 10000 employees,-1,Company - Private,Accounting,Accounting & Legal,₹100 to ₹500 billion (INR),-1
1136,Data Engineer,"Permanent position with US based client of iFlex.
Work Location: Bangalore
Experience Level: 2+ Years

Role:
As part of our global team you will work on the data platform reporting to the Data Engineering Lead. Your role includes specification, development, test and rollout of features on our data platform. You are expected to contribute to the vision, understand our product roadmap, integrate business value andclient experience and contribute to build an engineering culture within the team. This initiative is of critical important to the success of the organization and our roadmap, for instance, services like liquidity analytics, billing, client onboarding, reporting and others will rely on the data platform. Accurate, granular, complete and timely data will be our key differentiating factor and competitive advantage in the market place. We expect the successful candidate to deliver high quality software and to be passionate about data engineering..

Responsibility / Qualification:
Managing multiple tasks and use sound judgment when prioritizing.
Collaborating with global cross functional team in building customer-centric products.
Analyzing existing software implementations to identify areas of improvement and provide deadline estimates for implementing new features.
Updating and maintain documentation for team processes, best practices and software runbooks.
Establishing trusted partnerships with peers, product heads, and executive level stakeholders.
We are looking for someone who is passionate about technology and engineering.
Exceptional analytical skills and ability to apply knowledge and experience in decision-making to arrive at creative and commercial solutions.
Ability to leverage technology to deliver business value.
You are independent and comfortable in a fast paced, ambiguous and often multi-directional work environment.

Preferred Qualifications:
B.S. or higher in Computer Science.
Minimum 2 years of relevant professional experience using a modern programming language (preferably Java/Scala).
Experience leveraging test driven development technics.
Comfort with Agile operating models.
Team oriented.
Strong interpersonal and communication skills.
Energetic, self-directed, and self-motivated.
Experience with microservice architecture.
Experience with Kafka, MongoDB, Hadoop, Cassandra.
Experience with AWS.
Experience in Financial Services or Fintech.",-1,IFLEX,Bengaluru,"Moscow, Russia",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1137,CIEL/SEL/1941: Sr data scientist,"Mandatory skills required -
Databases (SQL, Oracle, Any RDBMS) - Should have working knowledge of atleast one database
PL/SQL Programming Languages
R, Python (Any One)
Inferential Statistics - Hypothesis, p-value, R2, RMSE, MAPE etc
Exploratory Data Analysis
Machine Learning Algorithms - Should have in-depth knowledge and implementation of atleast one algorithm

Responsibilities
: Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the why & how of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions

Education
Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics
Experience
Minimum years of related experience required: 3 years
Preferred years of experience: 5 years
Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desirable.

Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
1138,Data Engineer,Data Engineer,3.6,"Bookmyshow
3.6",Mumbai,"Mumbai, India",1001 to 5000 employees,2007,Company - Private,Ticket Sales,"Arts, Entertainment & Recreation",Unknown / Non-Applicable,-1
1139,Data Analyst,"Required Skills & Experience

We are looking for a Data Analyst Executive
Eligible Qualifications : B. Tech, BCA, M.Tech, MCA
Experience : 3-5 years, fresher’s can also be considered
Location of Job : Gurgaon/Connaught Place, New Delhi
Technicals Skills

Following technical skills are pre-requisite:
Well versed with Software development methodologies, such as SDLC (Software Development Life Cycle), DDLC (Document Development Life Cycle).
Database schema design and implementation
Should have worked in either of technologies Sql Query/ Tableau/ Excel (Macros)/ Access (Query) writing for data analytics.
For planning and coordinating activities, organizations remain in invariant communication with one another and the data transfer has to be performed efficiently and smoothly as possible.
He/ She should manage the execution of the technologies, help the businesses in utilizing the systems, and should be well versed with the basics of computer systems such as Networking, Installation of necessary software and hardware.
Ability to determine the interrelationships between solutions and requirements.
Ability to think analytically and should be a problem solver and logic building should be very strong.
Good interpersonal skills to form effective working relationships with people at all levels.
Excellent communication and presentation skills and strong written & oral English skills.
To know more about us visit us www.sspl.net.in or write to us at admin@sspl.net.in",-1,Substratal Solutions,Connaught Place,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1140,Artificial Intelligence Scientists,"Experience 2- 4 Years
Salary 4 LPA - 6 LPA
Job Location Chennai

Industry:
IT-Software / Software Services

Keywords:
Artificial Intelligence

About Job:
Must have Excellent knowledge in AI / Machine learning (Mandatory).
Machine learning frameworks like keras, tensor flow etc.
And also other big data tools like Hadoop etc, Must know R and python.
Good understanding in SDLC & Business cycle.",4.0,"Careerera
4.0",Chennai,"Wayland, MA",501 to 1000 employees,-1,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
1141,Senior Data Engineer,"About Us

upGrad is an online education platform building the careers of tomorrow by offering the most industry-relevant programs in an immersive learning experience. Our mission is to create a new digital-first learning experience to deliver tangible career impact to individuals at scale. upGrad currently offers programs in Data Science, Machine Learning, Product Management, Digital Marketing, and Entrepreneurship, etc. upGrad is looking for people passionate about management and education to help design learning programs for working professionals to stay sharp and stay relevant and help build the careers of tomorrow.
upGrad was awarded the Best Tech for Education by IAMAI for 2018-19
upGrad was also ranked as one of the LinkedIn Top Startups 2018: The 25 most sought-after startups in India
upGrad was earlier selected as one of the top ten most innovative companies in India by FastCompany.
We were also covered by the Financial Times along with other disruptors in Ed-Tech
upGrad is the official education partner for Government of India - Startup India program
Our program with IIIT B has been ranked #1 program in the country in the domain of Artificial Intelligence and Machine Learning
About the Role

We are looking for a Data Engineer to help us scale the existing data infrastructure and in parallel work on building the next generation data platform for analytics at scale, machine learning infrastructure and data validation systems.
In this role, you will be responsible for communicating effectively with data consumers to fine-tune data platform systems (existing or new), taking ownership and delivering high performing systems and data pipelines, and helping the team scale them up, to endure ever growing traffic.
This is a growing team, which makes for many opportunities to be involved directly with product management, development, sales, and support teams. Everybody on the team is passionate about their work and we’re looking for similarly motivated “get stuff done” kind of people to join us!

Roles & Responsibilities
Engineer data pipelines (batch and real-time ) that aids in creation of data-driven products for our platform
Design, develop and maintain a robust and scalable data-warehouse and data lake
Work closely alongside Product managers and data-scientists to bring the various datasets together and cater to our business intelligence and analytics use-cases
Design and develop solutions using data science techniques ranging from statistics, algorithms to machine learning
Perform hands-on devops work to keep the Data platform secure and reliable
Skills Required
Bachelor's degree in Computer Science, Information Systems, or related engineering discipline
6 + years’ experience with ETL, Data Mining, Data Modeling, and working with large-scale datasets
6+ years’ experience with an object-oriented programming language such as Python, Scala, Java, etc
Extremely proficient in writing performant SQL working with large data volumes
Experience with map-reduce, Spark, Kafka, Presto, and the ecosystem.
Experience in building automated analytical systems utilizing large data sets.
Experience with designing, scaling and optimizing cloud based data warehouses (like AWS Redshift) and data lakes
Familiarity with AWS technologies preferred
Qualification – B.Tech/M.Tech/MCA(IT/Computer Science)

Years of Exp – 6-9",3.5,"upGrad Education Private Limited
3.5",Mumbai,"Mumbai, India",501 to 1000 employees,2015,Company - Private,Education Training Services,Education,₹1 to ₹5 billion (INR),"Udacity, General Assembly, Springboard"
1142,BBRC-Genomics-Associate Scientist,"JOB DESCRIPTION

Designation: Associate Scientist

Job Location: Bangalore

Department: Translational Medicine- Translational Sciences

About Syngene

Incorporated in 1993, Syngene International Ltd. is an innovation-focused global discovery, development and manufacturing organization providing integrated scientific services to the pharmaceutical, biotechnology, nutrition, animal health, consumer goods and specialty chemical industries around the world. Syngene’ s clientele includes world leaders such as Bristol-Myers Squibb, Baxter, Amgen, GSK, Merck KGaA and Herbalife. Its innovative culture is driven by the passion of its 4240- strong team of scientists who work with clients from around the world to solve their scientific problems, improve R&D productivity, speed up time to market and lower the cost of innovation .

Job Purpose:
To play a key role in TM-TS, develop an early-stage research strategy, initiate and lead discovery programs while managing ongoing programs in TM-TS. The role will work part of TMTS, and work with internal and external collaborators .

Key Responsibilities:
Experience in isolating DNA and RNA from blood, tissues and FFPE samples and cell lines. Experience with optimization of extraction protocols and for parameters like yield, input sample quantities and sample types is important.
Expertise in PCR, qPCR, cDNA/gDNA library preparation. Exposure to microarray techniques.
Proficiency in preparation of libraries for Next Generation Sequencing of transcriptome and genome, with significant experience in optimization of parameters like input RNA/DNA quantities and sample type
Experience with single cell RNA-seq will be plus.
Experience with various NGS protocols (DNA Amplicon based, hybrid capture based low input, degraded DNA and RNA samples e.g. FFPE samples.
Strong understanding of experimental design and statistical principles behind experimental design and differential gene expression. Experience with analysis of single cell RNA-sequencing data will be a plus

Educational Qualification:
M.Sc or M. Tech in Biotechnology, Molecular biology or Biological Sciences,

Technical/functional Skills:
DNA/ RNA Isolation, Expertise in PCR, qPCR, Experience in NGS protocols

Experience:
2 to 5 Years

Behavioral Skills:
A proactive team player.
Ensure completion of experiments and generate accurate and reproducible data from experiments.
Ability to work independently, prioritize tasks and work on multiple projects simultaneously with; comfortable working in a dynamic environment with changing requirements.
Good oral and written communication and presentation skills to work in a multi-disciplinary team
Equal Opportunity Employer:
It is the policy of Syngene to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by applicable legislation or local law. In addition, Syngene will provide reasonable accommodations for qualified individuals with disabilities.",3.5,"Syngene
3.5",India,"BENGALURU, India",1001 to 5000 employees,1994,Unknown,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1143,Applied Scientist 1,"Position Requirements:
Master's degree in Computer Science, Computer or Electrical Engineer, Mathematics, or a related field plus at least one year of experience in the job offered or related occupations of Software Engineer, Software Developer, or a related occupation. Employer will accept a Bachelor’s degree and five years of experience in the job offered or a related occupation as equivalent to the Master’s degree and one year of experience. One year of experience in the job offered or related occupation must involve designing and developing large-scale, multi-tiered, distributed software applications, tools, systems and services using Java, Object Oriented Design and Distributed Programming].

Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, Oracle/Berkeley databases, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills

Amazon Selling Partner Services team drives the Selling On Amazon business and develops solutions that enable millions of sellers around the world to sell on Amazon's Marketplaces. More than half of shipments for Amazon customers are generated from this business. The team is focused on building a technology platform that will support the explosive business growth in existing markets, streamline the business for Amazon and the Selling partners and launch business in new markets and establish a fair marketplace.

Our team is seeking engineers with broad technical skills to help us optimize how we synthesize massive amounts of data and complex business rules into mission critical financial information. As a member of this team you will employ object oriented techniques in Java, and DynamoB, PostGres and ElasticSearch skills to help us support Amazon's next generation of selling partner services. Along the way you'll gain and leverage a unique understanding of how Amazon.com works; from the numerous software systems that comprise the website's back-end, to the details of our business model, and the relationships we're establishing with an ever-growing network of selling partners who depend on Amazon.com to run their businesses.

The ideal candidate will draw upon exemplary analytical, critical thinking, and problem solving skills, and a passion for maintaining highly reliable, distributed systems which operate 24/7/365. Successful members of this team collaborate effectively with internal end-users, aggressive cross-functional software development teams, and technical support/sustaining engineering teams to solve problems and deliver successfully against high operational standards of system availability and reliability. We look for engineers who are excellent communicators, self-motivated, flexible, hardworking, and who like to have fun!

Position Responsibilities:
Participate in the design, development, implementation, testing and documentation of large-scale, multi-tiered, distributed software applications, tools, systems and services using [Java, Object Oriented Design and Distributed Programming]. Translate functional requirements into robust, scalable, supportable solutions that work well within the overall system architecture. Participate in the full development cycle, end-to-end, from design, implementation, and testing to documentation, delivery and maintenance. Produce comprehensive, usable software documentation. Evaluate and make decisions around the use of new or existing software products and tools.

Preferred Qualifications
Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1144,Senior Clinical Data Analyst,"About Novotech:

Novotech is internationally recognised as the leading independent and full-service contract research organisation (CRO) in the Asia Pacific region. We provide a wide range of clinical development services across all research phases and therapeutic areas and have been instrumental in the success of hundreds of Phase I – IV clinical trials throughout the Asia Pacific. Powered by the highest quality people, Novotech strives to set the benchmark for both business and clinical trial performance. Our people are one of our key strengths. We value our people and recognise the work they do. We are lucky to have the best people and talent from across the Asia Pacific region work together to deliver to clinical trial success for our clients. Our people and those we look to recruit have an attitude of making things happen. They are problem solvers, driven with a focus on delivering quality, accountability and a high level of performance.

Brief Position Description:

As part of Novotech’s Biometrics unit, the Senior Data Analyst (SDA) is responsible for all data analysis and business intelligence activities related to study related clinical and operational data. The SDA acts as primary point of contact for all data analysis matters to the study team and is responsible for the timely delivery of quality outputs following all applicable regulatory, compliance, best practice and operational procedures.

Minimum Qualifications & Experience:

Graduate in information science, data science or life science-related field, or similar. More than five years’ experience in a senior role related to data science, data analysis, clinical data management or clinical data programming in a pharmaceutical company, CRO or EDC software provider.

Responsibilities
The Senior Data Analyst (SDA) is responsible for providing technical, procedural (SOPs) and planning leadership across multiple projects assigned to the data analyst team members ensuring that they deliver in accordance with SOPs, programming best practices, and the timelines agreed within the Project Team.
Collaborate with cross-functional stakeholders to implement data science solutions to solve business needs using available technological solutions.
Scope data analysis effort for projects and project manage all data analysis activities across multiple projects for different study stakeholders.
Gather study requirements from data management for data review and external data reconciliation and provide guidance on appropriate outputs (dashboards, visualisations, listings, reports).
Extract, assess, integrate, transform data sources to provide data visualisation outputs for analytics.
Design and develop prototypes and final versions of data outputs (dashboards, reports, visualisations, listings) using Business intelligence tools and Data Visualisation tools.
Design and develop standard dashboards and content for different audiences.
Analyse, manipulate and understand data from multiple sources to present and create dashboards and reports to make business decisions.
Assist teams on best-practice for data visualisation dashboard development.
Educate teams on how to use all the features of applicable data visualisation platform in conjunction with data visualisation dashboards.
SME for the data visualisation development and assisting team members.
Identify and communicate project risks and maintain documentation within project files as appropriate
Represent data analysis group at internal / external meetings as appropriate.
Assess and implement new data analysis, BI and data visualisation processes and technologies.
Take an active role in the development of best practices, process improvement, quality control and governance related to all data analysis matters.
Provide training and mentoring to Data Analysis of team members in SOPs, software applications, and best practices.
Provide Subject Matter Expertise on all data analysis and visualisation related activities.
Attributes and Skills

Expert knowledge of clinical study data structures and schemas of EDC databases. Expert knowledge in data processing activities such as extracting, integrating, transforming and presenting data. Statistical Programming skills in Python, R or similar. Knowledge of SQL and EDC systems. Working knowledge of Spotfire, Power BI, Tableau or other data review and visualisation tool. Ability to gather business requirements from multiple stakeholders and clients and provide guidance on the use of appropriate data visualisations.

Experience mentoring and training others. Awareness of regulatory and compliance issues and understanding of the application of SOPs and Quality Control to daily activities. Excellent analytical, communication and problem-solving skills.

Opportunities and Benefits:

To deliver clinical trial and research excellence for our clients, our people are 'best in class'.

At Novotech, we seek and nurture people with exceptional talent. We are committed to providing our people with regular internal and external training, a competitive bonus structure and a supportive work environment. We are also focused on providing our people with a wide variety of career growth and development opportunities.

For more information about where your next career step at Novotech might take you, visit http://novotech-cro.com/novotech-careers",4.5,"Novotech
4.5",Bengaluru,"Sydney, Australia",501 to 1000 employees,1996,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
1145,Data Engineer,"Data Engineer Responsibilities:
Liaising with coworkers and clients to elucidate the requirements for each task.
Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed.
Reformulating existing frameworks to optimize their functioning.
Testing such structures to ensure that they are fit for use.
Preparing raw data for manipulation by Data Scientists.
Detecting and correcting errors in your work.
Ensuring that your work remains backed up and readily accessible to relevant coworkers.
Remaining up-to-date with industry standards and technological advancements that will improve the quality of your outputs.
Data Engineer Requirements:
Bachelor's degree in Data Engineering, Big Data Analytics, Computer Engineering, or related field.
Master's degree in a relevant field is advantageous.
Proven experience as a Data Engineer, Software Developer, or similar.
Expert proficiency in Python, C++, Java, R, and SQL.
Familiarity with Hadoop or suitable equivalent.
Excellent analytical and problem-solving skills.
A knack for independent and group work.
Scrupulous approach to duties.
Capacity to successfully manage a pipeline of duties with minimal supervision.
Job Type: Full-time

Salary: ₹360,000.00 to ₹870,000.00 /year

Experience:
total work: 2 years (Preferred)
Data Engineer: 1 year (Preferred)
Education:
Diploma (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,Futurious Technologies,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1146,Quantitative Analyst,"The successful candidate will be a highly analytical individual with hands on programming skills. The candidate will work closely with the research team and clients towards the ongoing development and integration of new investment strategies, models and tools on Axle

Location

Mumbai
Responsibilities

Perform daily/weekly/monthly tasks of performance and risk reporting
Develop and automate investment processes and strategies via VBA and Matlab
Develop tools to integrate trading decision systems with risk management systems
Ad hoc tasks (such as operational tasks, internal documentation tasks and preparation of marketing materials)
Skills/Experience

Excellent programming skills in Matlab/Excel-VBA
Thorough with financial concepts and calculations like Drawdown, VaR, Eloss etc.
Understanding of financial market products like options, futures, FX forwards etc.
Working knowledge of Bloomberg is preferred
Should be self-driven and detail oriented with an analytical mindset
Should be a proactive and quick learner; a team player showing enthusiasm and drive to accomplish results in a fast paced environment
Min. 2 years of relevant work experience
Qualifications

B.Tech/M.Tech/MBA/CFA/FRM",5.0,"B&B Analytics
5.0",Mumbai,"Zug, Switzerland",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1147,Analyst - Data Scientist,"Job Summary

Experience:
3 - 5 Years

Location:
Mumbai

Designation:
Analyst - Data Scientist

Degree:
BE-Comp/IT, BE-Other, BTech-Comp/IT, BTech-Other, ME-Comp/IT, ME-Other, MTech-Comp/IT, MTech-Other, PhD-Comp/IT, PhD-Other

Educational Level:
Graduate/Bachelors

Industrial Type:
IT-Software/Software Services

Functional Area:
IT Software - Application Programming / Maintenance

Key Skills:
Data Scientist

Job Post Date:
Thursday, March 19, 2020

Company Description

We are capability centre based in Mumbai, initially started as a back-office operational support to the UK business unit.

However, over the recent years, we have significantly increased the breadth and depth of our capabilities and offerings to keep pace with the changing needs of the Group. These include Digital & Knowledge Services, Finance and Actuarial, Information Technology (IT), Customer Service, Risk and Audit.

Our core purpose is to be a strategic partner to company, enabling growth by delivering change and driving synergies through a highly capable and agile workforce.

With our diversified service offerings we provide our people with exciting opportunities to grow personally and professionally.

Company is a leading savings and investments business serving around 5.5 million retail customers and more than 800 institutional clients.

It-s innovative asset management and customer solutions are supported by extensive investment capabilities, an international distribution network and two strong brands.

Job Description

3 – 5 yrs experience as Data Scientist
Should have at-least 1 end-to-end ML project experience
Very high proficiency in R or Python
Excellent in forecasting methods like simple exponential smoothing, multiplicative seasonal indexes, simple and weighted moving averages and time series forecasting methods
Exposure to with advanced deep learning techniques such as LSTM. CNN, Dense neural networks as well as neural networks design and implementation through tools like tensorflow, keras, pytorch, deepai or equivalent.
Good SQL experience",3.8,"Sampoorna Computer People
3.8",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
1148,Data Lake Developer,"For Us, It's A Mission

At Mylan, we mean it when we say we work every day to provide access to high quality medicines to the world's 7 billion people. If you are unconventional, relentless and passionate. If you believe in doing what's right, not what's easy. If you are a doer and have a passion for serving others, we want to talk to you.

Make a Difference

At Mylan, each person has the ability to make a difference. From the providers who sell and market our products, to the producers who develop and manufacture them and finally to our business partners who support the providers and producers, we all have a mission critical role. Here's how this role will help:

ESSENTIAL DUTIES AND RESPONSIBILITIES
To perform this job successfully, an individual must satisfactorily perform each essential duty. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential duties.
1. Create and maintain optimal data pipeline architecture on Azure platform.
2. Develop batch processing solutions by using Data Factory and Azure Databricks.
3. Delivering a Data Warehouse in the Azure Cloud.
4. Design relational and non-relational data stores on Azure.
5. Identify, design, and implement internal process improvements : automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc..
6. Developing Big Data Solutions with Azure Machine Learning.
7. Strong interaction with business departments to provide consultative support for digitization efforts, as well as close collaboration with the Business Technology management, focused on future innovation topics.
8. Participate and lead in design sessions, demos and prototype sessions, testing and training workshops with business users and other IT colleagues.
9. Design & Build for any API Development or SQL DB development.
10. Providing service management, orchestration, monitoring and management requirements of Azure cloud platform.
11. Create data tools / products for analytics and data scientist team members that assist them in building and innovative solutions that drive tangible business value.
12. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
13. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
14. Design security for source data access. Chose the appropriate authentication mechanism, (ie Azure Active Directory (Azure AD), etc).
15. Design for real-time processing by using Stream Analytics and Azure Databricks.

Make Our Values Your Values

Mylan hires only the best. People who thrive in a culture of innovation and empowerment. People who are active learners and have a positive attitude. People who are leaders and know that by working together we can run faster, reach higher and achieve more. By doing so, we will continue to set new standards in health care. Here are the minimum qualifications and essential functions for this position:

QUALIFICATIONS

The qualifications listed below are representative of the minimum knowledge, skill, and/or ability required.

SKILLS AND ABILITIES

1. 10 years of experience in Microsoft technologies including SQL.

2. At least 5 years as a Sr Developer with at least 3 years hands on experience as Azure Data Engineer building large scale Azure data solutions.

3. At least 5 years of experience in Azure based data solutions.

4. At least 3 years of experience on working with large projects including the most recent project in the cloud (Azure) or on prem with a focus on Azure Data services.

5. At least 5 years of Hands-on administration, configuration management, monitoring, performance tuning of Hadoop/Distributed platforms.

6. At least 5 years of demonstrated experience at least in the most recent 2 years of designing and delivering solutions using Cortana Intelligence suite of analytics services part of Microsoft Azure including Azure Machine Learning Studio, HDInsight, Polybase, Azure Data Lake Analytics, Azure Data Warehouse, Streaming Analytics, Data Catalog, R/R Studio

7. Experience in designing and building logics required for optimal extraction, transformation, and loading of data from a wide variety of data sources

8. Experience within Data Security design, including but not limited to:

a. Choosing the appropriate authentication mechanism, such as Azure Active Directory (Azure AD)

b. Defining strategies for data encryption for data at rest and in transit

9. Experience partnering with Business Analysts and Data Scientists to enable effective and efficient data preparation and delivery

10. Experienced in vendor management and working with 3rd parties onshore & offshore.

11. Experience working in a global team.

12. Experience working in an Analytics / Big Data solutions on MS Azure Cloud

13. Experience with code management tools, automated testing

14. Experience creating and maintaining optimal data pipeline architecture on Azure platform

15. Experience developing batch and real-time processing solutions by using Data Factory and Azure Databricks

16. Familiar with AGILE and Azure DevOps methodology

17. Hands on PoC capabilities are needed to prove a particular architecture concept

18. Azure Native Services experience across Data Fabric and Service Fabric

19. Experience in Application modernization from legacy on-premise data architecture platform technology stack to modernized Azure Cloud base Architecture.

20. Experience with Git, NoSQL Data Solutions, Microsoft Azure, HD Insights, Azure ML, DataBricks ML Flow, R or Python.

21. Must have excellent communication skills.

EDUCATION/EXPERIENCE (Note: Please select one)

Minimum of a Bachelor's degree in Computer Science and Engineering is preferred with minimum 10 years of experience. However, a combination of experience and/or education will be taken into consideration

Why Mylan?

If you want to be part of a global health care company that is making a difference and changing lives, Mylan may be the place for you. With a workforce of more than 35,000 worldwide, we can make a difference. We encourage you to visit Mylan.com to learn more about our unconventional culture, our approach to doing business and how we plan to set new standards in health care.

Mylan offers competitive salary, excellent benefits and an environment conducive to professional growth and advancement. All qualified applicants will receive consideration for employment without regard to their disability or protected veteran status. Mylan is an Equal Opportunity Employer, Minorities/Female/Disabled/Veteran.",3.8,"Mylan Inc.
3.8",Bengaluru,"Hatfield, United Kingdom",10000+ employees,1961,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1149,Off Campus Recruitment - Quantitative Researcher,"Description:
Graviton is a privately funded quantitative trading firm striving for excellence in financial markets' research. We are seeking fresh talent from the top IIT's to join us as Quantitative Researchers for our team in Gurgaon.If you are a student graduating in 2020 from Computer Science , Electrical or Maths Stats Computing streams with a greater than 8 CGPA please apply here.

This role is open to students from campuses that we could not visit this year. Please check your individual placement policy restrictions before applying.

Graviton trades across a multitude of asset classes and trading venues using a gamut of concepts and techniques ranging from time series analysis, filtering, classification, stochastic models, pattern recognition to statistical inference analysing terabytes of data to come up with ideas to identify pricing anomalies in financial markets.

As a Quantitative researcher your responsibilities will include

Develop new or improve existing trading models using in-house platforms

Use advanced mathematical techniques to model and predict market movements

Analyse large financial datasets to identify trading opportunities

Provide real time analytical support to experienced traders

Requirements :
Possess a degree in a highly analytical field, such as Engineering, Mathematics, Computer Science from IITs schools

Quantitative bend of mind

A working knowledge of Linux/Unix

Programming experience, preferably in C++ or C

Strong interest in learning about financial markets.

Have a strong work ethic

Hard Working

Benefits:
Our open and casual work culture gives you the space to innovate and deliver. Our cubicle free offices , disdain for bureaucracy and insistence to hire the very best creates a melting pot for great ideas and technology innovations. Everyone on the team is approachable, there is nothing better than working with friends!

Our perks have you covered.

Competitive compensation

6 weeks of paid vacation

Monthly after work parties

Catered breakfast and lunch

Fully stocked kitchen

Gym membership

International team outing",5.0,"Graviton Research Capital LLP
5.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2014,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1150,Data Engineer,"Zauba Technologies is a startup based in Bangalore. Zauba's services are used by leading companies in India. Zauba is powered by a young and passionate team. We are looking for individuals who would like to be a part of our founding team.

As a Data Engineer and as a part of founding team, you will be expected to visualise and develop disruptive data products. Eventually you would be responsible for entire project lifecycle of products you would visualize. Your rewards will be directly proportional to the value you generate.

Job Responsibilities
Design and development of robust, scalable and highly efficient data engineering solutions for structured and unstructured data (Including gathering and processing raw data at scale, writing scripts, web scraping, calling APIs, writing SQL queries, etc.)
Develop processes for text mining and extraction of information from unstructured data
Design, architect and develop efficient data pipelines around the data collected
Take ownership of existing web product and applications
Design and implement data models that scale across the enterprise
Take ownership of existing data workflows and processes
Enhance scalability, performance, and stability of existing infrastructure
Work closely with other team members to integrate your innovations and algorithms into our production systems

Essentials
Java/Python - Intermediate to advanced level
SQL - Advanced
MySQL Intermediate to advanced level
Regex - Basic to intermediate level
Linux Basic to intermediate level

Good to have
Hadoop/Spark
R
MongoDB

Must have qualities
Skills to learn new skills quickly
Desire to create disruptive products and services
Passion - not just to work in startups but to take them to next level
Above average programming aptitude
Be passionate about producing high quality engineering deliverables
Be productive working independently or collaboratively
Have an eye for building efficient processes
Be self motivated
Proactively take ownership

Interested?

Send your resume to hr@zaubacorp.com",3.8,"Zauba Corp
3.8",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 million (INR),-1
1151,Quantitative Research,"We are looking for highly trained professionals who are interested in applying advanced mathematical quantitative methods to the modeling of global financial markets. You would be joining a group made up of highly proficient individuals from various scientific disciplines. We have a spectrum of opportunities for individuals with the right scientific skills. Experience in finance is not required.

The ideal research candidate will have:
A Ph.D. in Computer Science, Mathematics, Physics, Statistics, or a related technical discipline.

A demonstrated capacity to do first-class research.

Computer programming skills.

An intense interest in applying quantitative analysis to solve difficult problems.

Send us a copy of your resume to
careers@dolatcapital.com

For internship opportunities, please send us a copy of your resume to
careers@dolatcapital.com",4.0,"Dolat Capital
4.0",Mumbai,"Mumbai, India",51 to 200 employees,1970,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1152,Data Engineer,"Bachelor’s degree in Computer Science or related field
5+ years relevant experience
5+ years experience with SQL, SQL Tuning, Oracle, OLAP, Big Data Technologies
5+ years experience developing end-to-end Business Intelligence solutions: data modeling, ETL and reporting
Experience with Java and experience with scripting languages like Perl, Python, Unix shell scripts,VBA and MS Excel
Proficiency with Linux and systems administration
Proven ability at looking at solutions in unconventional ways. Sees opportunities to innovate and can lead the way.
Top notch communication (verbal and written) and interpersonal skills to convey key insights from complex analysis in summarized business terms and an ability to effectively communicate with technical teams.
Ability to work with shifting deadlines in a fast paced environment.
Operations Finance Technology team, responsible for building technical solutions for multi-billion WW Operational Cost analytic including Inbound cost (Receiving / PO), variable Cost, fixed cost, outbound (Customer Shipments / Transportation), and Customer Service, is looking for a Data Engineer.

As a data engineer, you will get the exciting opportunity to work on very large data sets in one of the world's largest and most complex data warehouse environments. You will work closely with the business teams in analysis on various cost savings initiatives, many non-standard and unique business problems and use creative-problem solving to deliver actionable output.
You will be responsible for designing and implementing an analytical environment using third-party and in-house reporting tools, modeling metadata, building reports and dashboards. You will have an opportunity to work with leading edge technologies like Redshift, Hadoop/Hive/Pig. You will be writing scalable queries and tuning performance on queries running over billion of rows of data.

You should be analytical, have an extremely high level of customer focus and a passion for process improvement. You should be motivated self-starter that can work independently in a fast paced, ambiguous environment. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions.
Bachelors in Computer Science or related field
Practical Knowledge of Linux or Unix shell scripting
Experience in working with business customers to drive requirements analysis
Exposure to large databases, BI applications, data quality and performance tuning
Excellent written and spoken communication skills
Experience with Hadoop-based technologies such as HBase, Pig, Hive and Spark
Strong proven ability in building high-performance, highly available and scalable data solutions using Oracle and/or Hadoop-based technologies
Knowledge of data warehousing concepts.
Strong sense of ownership, urgency, and drive
Strong troubleshooting and problem solving skills
Experience with Amazon Web Services",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1153,DATA ANALYST,"posted by Mahima Gaur

2 - 5 years Delhi

Job Description
Experience in data processing
Experience in data cleaning and data tabulation activities
Strong analytical, communication and team management skills
Strong understanding of data management using SPSS and research techniques
Competency in a Tabulation software (decipher / wincross / quantum etc), Excel, Powerpoint
Ability to summarize findings, draw conclusions, and put together a presentation using Powerpoint
Role Category : Data Analyst

Employment Type : Permanent Job, Full Time",4.9,"Knowledge Excel Services.
4.9",New Delhi,"New Delhi, India",1 to 50 employees,2007,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
1154,Data Engineer,"Key skills : Python , Spark , SQL , Pyspark • AWS platform used for the work • Strong experience in SQL is mandatory • Good familiarity of AWS landscape • Good experience in collecting business requirements & design them as per requirement from customer • Should able to work independently & interact business users & technical stakeholders • Strong communication skills both oral & written. • Should work as an individual resources",3.5,"Larsen & Toubro Infotech Limited
3.5",India,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1155,Big Data Engineer,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
1156,Client Data Analyst,"At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.
What is the Client Data Analyst – Client Analytics group responsible for?
This team manages business data to ensure accurate, timely, consistent and compliant data. Their contributions deliver quality data that is easily accessible and can be trusted. Key downstream capabilities such as reporting and analytics depend on this as well as operational data access on various systems. The Data Management Team is a support function that acts as an advocate and a point of contact for Sales and Marketing data.

What are the ongoing responsibilities of an Client Data Analyst ?
Understand the data flow, key consumption and production of data as well as context within the enterprise:
Build positive relationships with teams, especially the key data consumers and analytics. Take the time to increase knowledge of how they run their business and incorporate sales data into daily work
Connect regularly with each sales office to understand current issues and challenges. Probe the business and validate against other sales offices to understand the scope and priority of the issue
Make recommendations on how data unifications and flow can be used to improve business tasks. Liaise business partners to deliver solutions (reports, processes, technology) that add value.

Provide data management subject matter expertise. Appreciate the connection and data flow between applications and other corporate systems. Be able to clearly articulate the data needs and move initiatives forward by collaborating with business partners:
Actively participate in meetings with business partners to ensure that priorities are clearly understood, information is regularly shared and that key participants are “kept in the loop”
Provide context and background on issues. Collaborate on ideas for progressing initiatives. Ensure appropriate resources are involved to take initiatives forward
Provide insights and expertise to scope statements and requirements documentation
Actively consult or participate in the user acceptance testing process (test cases, documentation, testing execution, etc.)
Ensure business needs remain aligned with overall corporate initiatives and deliver the benefits as originally intended

Monitor the integrity of data and usefulness of reports. Ensure the information available within systems is accurate and up-to-date. Proactively seek data cleansing opportunities and evolve data to better support. Document and maintain ongoing processes for reporting and data clean-up:
Partner with all key data consumers to gain a solid understanding of usage and challenges around data. Establish processes for prioritization of enhancements, especially with the analytics groups
Provide 1st level support for data issues and data maintenance for owned data
Verify and execute data loads into our internal sales systems and ensure any upstream systems accurately receive their data

Increase awareness and promote data management capabilities. Share best practices and provide coaching to local offices on how to access and incorporate output into sales tasks. Encourage IAS leaders to leverage data to make more informed, strategic decisions:
Clearly articulate the goals and core services of the data management team. Proactively promote this information within IAS and ensure business partners understand the data management role within the organization
Share best practices and provides guidance on data capabilities. Reinforces ownership and accountability for data accuracy
Seek opportunities to share the benefits of leveraging sales data to make more informed business decisions

What ideal qualifications, skills & experience would help someone to be Successful?

Knowledge, Education And Experience:
Four year bachelor’s degree required (majors of preference include: business, computer science, mathematics) Advanced degree a plus
Understanding of the Franklin Templeton business model, how FT makes money, the sales process, how technology fits in with the business, etc. Knowledge of the GAS (Global Advisory Services) structure
Experience working through multiple business fiscal cycles; exposure and/or direct experience with project management and/or sales-related-capacity required
Prior work experience related to analytics, sales, marketing and/or international a must. Level will not be granted based on years of experience but will be determined by the employee’s ability to meet each job activity as outlined the ‘typical/expected focus by level
Skills And Abilities:
Ability to communicate effectively with all levels of management; ability to tailor communication style based on audience; ability to get others to want to collaborate with you; strong facilitation skills
Excellent writing skills (for presentations, documentation, etc.)
Working knowledge of the CRM, MDM, Excel, SQL, Power BI, Tableau, Business Objects, and Microsoft Products (PPT, Power Apps, Doc, Visio)
Ability to absorb and interpret large quantities of data; apply trend analysis and knowledge of the business to develop a meaningful and digestible summary with the appropriate level of detail
Ability to take a larger problem and break down the individual components; identify how to go about solving the problem and who to involve in the process
Ability to present recommended solutions to a variety of issues and problems (solutions that are consistent with organization objectives)
Must be extremely detail-oriented (managing lists, tasks/to-dos, etc.) good with follow through on own items; good with following up with others on outstanding item

What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.

Highlights of our benefits include:

Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.",3.8,"Franklin Templeton Investments
3.8",Hyderabad,"San Mateo, CA",5001 to 10000 employees,1947,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Fidelity Investments, Vanguard"
1157,Data Analyst,"Roles and Responsibilities:
Extracting, transforming and inputting data sets from various resources. Creating predictive models, translating non-technical aspects into quantifiable tasks. Analysis and representation of output data, highlight and explain trends and patterns, error elimination, using advanced statistical methods (regression, probability distribution, clusters etc.) to provide accurate results.
Data collection, Data Mining, Report generation, Problem identification and solution formulation Market analysis and establishing trends, Strategy development and implementation

Skills:
Extremely good analytical skills.
Good working knowledge of all MS-Office products, especially Advance Excel, Word, PowerPoint, MS-access.
Statistical tools and methods.

Interested candidates can send the updated resume on satish.mehra@exelaonline.com or call on 7722028636
00-7.00 Years",2.6,"Exela Technologies
2.6",Pune,"Irving, TX",10000+ employees,2017,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"SourceHOV, BancTec, Transcentra"
1158,Data Modeler,"• Minimum 5-8 years of working experience as Data modeler.
• Data modelling experience in designing.
• Minimum 2-3 years real time experience in Erwin tool is mandatory.
• Experience in normalized modeling techniques.
• Experience in designing the Start schema.
• Experience working in ORACLE.
• Experience with database design, capacity planning, performance tuning and query optimization.
• Experience in working with Bank or Banking and Finance or Financial domain.
• Excellent communication skills with leadership quality.

Job Segment:
Database, Oracle, ERP, Technology",3.5,"LTI
3.5",Mumbai,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1159,Machine Learning Engineer,"Looking for Data Scientists with Python/R Programming skills.
Specific experience in AI areas like Statistical Machine learning / Deep learning / Natural Language Processing (NLP)/ Operations Research (Optimization) will be an advantage.Individual in this role is expected to work with multiple stakeholders and teams

Qualifications and Requirements:-
Previous working experience as a Machine Learning/ Data Scientist for 2 years
MA in Computer Science or similar relevant field
Hands on experience with MALLET
In depth knowledge of Apache Tomcat/Open Source
Excellent project and time management skills
Attention to detail
Outstanding problem solving and analytical skills",-1,Tekolutions.ai,India,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1160,Data Science Internship,"About the company:
SkillBit is a leading staffing and recruitment company engaged in talent searching assignments for skilled and talented candidates for the industry.

About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Working on data science algorithms and AI concepts 2. Using Python or R for web scraping 3. Building AI models using Python, machine learning, and deep learning algorithms 4. Processing of unstructured/structured data

Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 6th Jun'20 and 11th Jul'20
are available for duration of 1 month
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply

Number of internships/jobs available: 3

Categories: Data Science",-1,SkillBit,Pune,-1,-1,-1,-1,-1,-1,-1,-1
1161,Data Engineer,"As a data engineer at TEAL, you'll be taking the plunge into a rich data lake that includes everything from satellite data to legal court orders. You'll be hustling and getting your hands dirty with every part of the data pipeline always having an implicit appreciation for how all of this data will ultimately power a revolutionary real estate risk platform.

Your day-to-day will include either all or some of the following:

Constantly scoping out new data sources to complement existing ones
Creating and maintaining distributed web scrapers using Python, RabbitMQ and other technologies
Architecting and managing data pipelines where data flows into multiple end-points including, but not limited to, Postgres, MongoDB and Apache Solr
Documenting workflows and constantly iterating to create better data infrastructure.

We'd love it if you:
Are proficient in Python or any other object-oriented language
Have worked with large (millions to hundreds of millions of rows in a SQL database) interdisciplinary datasets
Have scraped difficult websites and have some experience working with various data APIs
Are patient and methodical with unstructured and messy data
Are always hungry to learn newer and better technologies to make the data ecosystem faster, smoother and less silo-ed

Extra brownie points if you:
Have some experience working with large-scale search indexing
Have performed geospatial analyses in some capacity
Have created and managed data lakes in the cloud
Culture

To explore our culture and the values we embody click here

Testimonials
Testimonial

My experience at TEAL surpassed all my expectations from the get-go. I was asked to help solve one of the most daunting problems in the Indian real estate market. Every day while working on a subset of the problem, the ideas that I brought to the table were shaped into cohesive solutions by a collaborative team effort. At TEAL I was exposed to the most cutting edge technologies such as Cloud Computing, Big Data, ML and Data Science. The growth opportunities at TEAL are tremendous, If you are innovative and can demonstrate the will to realize your ideas, TEAL is an amazing organization to work for.
Gyan Vardhan, Data Science Intern
I had interned as a Data Scientist at Terra Economics and Analytics Lab during its early days, it was a rich learning experience working with a multi-disciplinary team who are extremely passionate about building a decision support platform for the insanely complicated realty market in India. It was exciting and challenging to work on mining huge volumes of property records; extracting patterns from the data, building data pipelines and brainstorming on building the core system. TEAL offers a very healthy work environment coupled with insanely talented people working together in an exciting setting.
Naga Anjaneyulu, Data Science Intern
I worked as a full-time Data science intern at TEAL. During this period, I got an opportunity to leverage my skillsets while also learning new technologies, working on tasks assigned to me. The company operates on the latest tech-stacks and gives opportunities to learn as much as you want. The work environment is challenging, the team at TEAL is super supportive and new ideas are always welcome. It has all the good perks of a startup; creativity and innovation, casual work atmosphere and a collaborative approach to solving problems. Personally, I loved working there, my experience was fantastic!
Archana Parmar, Data Science Intern
As a second-year college student, I was looking for an internship that would allow me to delve deeper into research and work with big data, TEAL gave me the perfect opportunity to do so, enabling me to develop proficiency in research and analysis. As a research analyst intern, I collated and cleaned data and helped in the preparation of reports and presentations, and I had members helping me at every stage of this process. This collaborative environment allowed me to cultivate my skills and also learn from my peers. The holy trinity of Rohan, Kshitij, and Shreyas served as not only excellent mentors and bosses but also as friends, helping me at every stage and giving us all food and ice cream to keep us going!
Arush Mehra, Research Intern
Internships are a crucial part of one’s early career. The internship experience at TEAL was a thrilling rollercoaster ride to say the least! It was more than implementing a standard model or building an already though out concept into reality. It was about finding the solution to a unique and open-ended problem.It was exciting to work on addressing a problem with far -reaching real world applications.Moreover, the work environment had the perfect balance of casual yet professional which kept you focused and stress free at the same time. Out of every 100 startups in India only 2 of them succeed, but there are very few like TEAL India which are bound to make it big at such an early stage.
Divyanshu Agarwal, NLP Intern",4.7,"Terra Economics & Analytics Lab (TEAL)
4.7",New Delhi,"Bengaluru, India",1 to 50 employees,2018,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
1162,Senior Consultant - ModellingOps Data Engineer,"Job Title: Senior Consultant - ModellingOps Data Engineer
Location: TRIL GTC
GCL: D1

JOB DESCRIPTION:

AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. The Science & Enabling Units IT is AZs global IT capability function supporting key business areas operating out of sites across the US, UK, Sweden, India & Mexico.

We are looking for AI Ops consultant who will leverage tools & technology best practices to improve delivery performance & data engineering capabilities in the D&A space.

ROLES & RESPONSIBILITIES:

7-10 years of experience in IT Operations involving Data Science, Artificial Intelligence-Machine Learning and Predictive Analytics. Experience in architecting and implementation of end-to-end AIOPs solutions through ELK stack, Splunk. Experience in applying statistical methods, analysis, pattern recognition and modeling on IT Operational data using ELK machine learning. Experience in extracting meaning full data from incoming data streams from different sources through RegEx, Grok etc. Hands-on experience in applying machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc in the IT Operation domain. Experience with machine learning and statistical programming languages - Python, R etc. Experience in assessing the existing IT environment and providing recommendations to reduce the critical applications impacting incidents. Experience in exploring and identifying areas where manual tasks can be automated in IT environment. Experience with various Enterprise IT monitoring solutions including Infrastructure monitoring, Application Performance Monitoring, Network Monitoring, Cloud monitoring etc. Experience in IT Service Management including Service Desk, Incident Management, Change Management, CMDB etc. Excellent knowledge on various IT infrastructure components that includes Server Infrastructure, middle ware, database and application architectures and Cloud Components. Experience/knowledge on Infra monitoring tools - NOI, Zabbix, AppDynamics, Datadog, SCOM, SolarWinds etc. and Service Management tools -IBM Control Desk, BMC Remedy, ServiceNow etc. Experience/Knowledge on BI tools Knowledge on distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc. Knowledge on other programming languages/scripting: Python, Java, JavaScript, etc. ( Added Advantage ) Good analytical skills, strong communication skills are must. Client facing experience is an added advantage. Excellent experience in understanding the problem statement, architect and designing the solution

MANDATORY SKILLS:
Significant experience with AWS cloud environments, working knowledge of Google and Azure platforms. Knowledge of Kubernetes, S3, EC2, Sagemaker, Athena, RDS and Glue is essential.
Experience provisioning computational resources in a variety of Cloud environments using Infrastructure as Code.
Experience with best practice of data transport and storage within cloud system.
Experience building large scale data processing pipelines. e. g. Spark and SQL.
Experience with containers and microservice architectures e.g. Kubernetes, Docker and serverless approaches.
Excellent working knowledge in DevOps, using continuous integration and continuous development.
Use of Data Science modelling tools e.g. R, Python, SAS and Data Science notebooks (e.g. Jupyter).
Good written and verbal skills, fluent English
DESIERED SKILLS:
Agile practices, especially being a SCRUM Master
EDUCATIONAL BACKGROUND: B.E/B.Tech/MCA

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",3.9,"AstraZeneca
3.9",Chennai,"Cambridge, United Kingdom",10000+ employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Roche, GlaxoSmithKline, Novartis"
1163,DATA ENGINEER,"JOB DESCRIPTION
As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements, and also research new uses for data acquisition. You should also know the ins and outs of the industry such as data mining practices, algorithms, and how data can be used.

DESIRED CANDIDATE PROFILE
An ideal candidate must possess prior experience leading a project.

Candidates must have:
> Experience in Hive, Spark, Scala, AWS DynamoDB, HBase, AWS Glue, Talend, Kafka, Snowflake ETL
> Strong experience in a BI/Data Warehouse environment with involvement in design, development, implementation, troubleshooting and support of ETL process using ETL tool.
> Experience in developing Data Marts, Data warehousing and Operational Data Store (ODS) on any of the databases or Hadoop environments.
> Experience in database like MS SQL, MySQL, Oracle, PostgreSQL
> Good to have programming experience in writing Complex Stored Procedures, Queries, Views, User Defined Functions, Cursors and Common Table Expressions using SQL or T-SQL.
> Experience in Performance Tuning and Query Optimization by Indexing, Partitioning and De-normalization.
> Experience in Developing a framework for ingesting data into Data lake
> Good database knowledge, analytical thinking
> Design, construct, install, test and maintain data management systems.
> Build high-performance algorithms, predictive models, and prototypes.
> Develop set processes for data mining, data modeling, and data production.
> Experience with cloud services: AWS (EC2, EMR, S3, Athena) and scripting languages like Python, /PySpark/R/SAS
> Install/update disaster recovery procedures.
> Experience in Agile Application Development & Scrum methodologies is preferred
> Ability to supervise and mentor junior developers on the team.
> Must be self-motivated and work well pulling people together in addition to being able to pull people together technically
> Demonstrated proficiency of troubleshooting techniques and detail-oriented problem diagnosis
> Ability to handle responsibility, is self-directed, with strong organizational and documentation skills
> Ability to work independently and efficiently under aggressive deadlines to meet project commitments
> Excellent verbal and written communication skills

EDUCATION
UG - B.Tech/B.E. - Computers, Electronics/Telecommunication, Diploma - Computers, Electronics/Telecommunication, B.Sc - Computers, BCA - Computers) AND (PG - M.Tech - Computers, Electronics/Telecommunication, MCA - Computers, M.Sc - Electronics, Computers) AND ( Doctorate - Any Doctorate - Any Specialization, Doctorate Not Required).

OTHER DETAILS
Number of vacancies: 4
Experience: 3 years
Location: Cochin

If you have a passion towards technology and coding, then we have the right job for you. Kindly forward your resumes to
Email: jobs@mjsofttech.com
Phone: 0484-2421245 / 928 720 7160",4.0,"MJ Softtech
4.0",Kochi,"Cochin, India",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
1164,Data Engineer,"Education/ Experience and Skill Requirement
4+ years of relevant experience in
Experience working with both relational and NoSQL databases.
Strong coding skills; Python (preferred) /R/Java/Scala
Experience in developing Data warehousing technologies Experience with AWS or equivalent cloud services preferred
Experience in BigData technologies (Hadoop, HDFS, MapReduce, Spark, Hive, HBase etc) will be valuable
Knowledge of Machine Learning a big plus (Random Forest, Decision Trees, SVM, NLP, Gradient Boosting, Supervised/Unsupervised Learning, Clustering, classification and regression modeling).
Responsibilities
Proficiency with several years’ experience in more than one of Python, R, Java, Scala, or robust Linux shell scripting
Implementation experience with data warehouse architecture & design, ETL design/development, and Analytics
Knowledge of general cloud architecture and cloud strategies especially around AWS services and concepts such as S3 object stores, RDS databases, EC2, Glacier, Lambda, IAM, enterprise security, data security, DevOps, replication and disaster recovery
Well versed with data mining & exploration, NLP and visualization
Understanding of data modeling, data integration, and data representation (metadata, OWL, ontologies)
Developing data marts and data management using SQL
Creating powerful visual outcomes
Independently manage daily client communication, especially over calls
Manage client deadlines, ensure quality of the deliverables, attention to detail
Experience/understanding of corporate finance data from company filings is desirable",3.6,"Copal Partners
3.6",Bengaluru,"New York, NY",10000+ employees,1900,Company - Public,Financial Analytics & Research,Finance,₹100 to ₹500 billion (INR),-1
1165,Data Engineer,"Job Description / Responsibilities
Build workflows to ensure data extraction quality and storage into our backend data store
Architect, build and train ML/AI models that can predict outcomes and report on anomalies.
Design data pipelines to perform ETL on content/data from multiple types of source systems.
Create data analytics views using RDBMS/Key-Value stores, on private and public/cloud
Create software that is well tested, maintainable, extensible and scales out with large data

Minimum Qualifications:
2+ years of software development with Python
2+ years of SQL (MySQL/Postgres) and Key-Value databases
1+ years of experience with scikit
2+ years of experience in data extraction, data transformation using custom Python/Java
Experience working with MapReduce/Hadoop/kafka/Elastic stack
Experience with Node backend and React/Redux
Experience working with git/mercurial, Amazon/Google cloud, Linux/LAMP stack
Experience in testing or test driven development
Experience with Data science and Machine Learning algorithm development

Location:
Hyderabad/Bangalore

Package:
Highly competitive to match experience and capability",3.7,"TVS
3.7",Bengaluru,"Chennai, India",5001 to 10000 employees,-1,Company - Private,Accounting,Accounting & Legal,₹100 to ₹500 billion (INR),-1
1166,Data Engineer,"Permanent position with US based client of iFlex.
Work Location: Bangalore
Experience Level: 2+ Years

Role:
As part of our global team you will work on the data platform reporting to the Data Engineering Lead. Your role includes specification, development, test and rollout of features on our data platform. You are expected to contribute to the vision, understand our product roadmap, integrate business value andclient experience and contribute to build an engineering culture within the team. This initiative is of critical important to the success of the organization and our roadmap, for instance, services like liquidity analytics, billing, client onboarding, reporting and others will rely on the data platform. Accurate, granular, complete and timely data will be our key differentiating factor and competitive advantage in the market place. We expect the successful candidate to deliver high quality software and to be passionate about data engineering..

Responsibility / Qualification:
Managing multiple tasks and use sound judgment when prioritizing.
Collaborating with global cross functional team in building customer-centric products.
Analyzing existing software implementations to identify areas of improvement and provide deadline estimates for implementing new features.
Updating and maintain documentation for team processes, best practices and software runbooks.
Establishing trusted partnerships with peers, product heads, and executive level stakeholders.
We are looking for someone who is passionate about technology and engineering.
Exceptional analytical skills and ability to apply knowledge and experience in decision-making to arrive at creative and commercial solutions.
Ability to leverage technology to deliver business value.
You are independent and comfortable in a fast paced, ambiguous and often multi-directional work environment.

Preferred Qualifications:
B.S. or higher in Computer Science.
Minimum 2 years of relevant professional experience using a modern programming language (preferably Java/Scala).
Experience leveraging test driven development technics.
Comfort with Agile operating models.
Team oriented.
Strong interpersonal and communication skills.
Energetic, self-directed, and self-motivated.
Experience with microservice architecture.
Experience with Kafka, MongoDB, Hadoop, Cassandra.
Experience with AWS.
Experience in Financial Services or Fintech.",-1,IFLEX,Bengaluru,"Moscow, Russia",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1167,CIEL/SEL/1941: Sr data scientist,"Mandatory skills required -
Databases (SQL, Oracle, Any RDBMS) - Should have working knowledge of atleast one database
PL/SQL Programming Languages
R, Python (Any One)
Inferential Statistics - Hypothesis, p-value, R2, RMSE, MAPE etc
Exploratory Data Analysis
Machine Learning Algorithms - Should have in-depth knowledge and implementation of atleast one algorithm

Responsibilities
: Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the why & how of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions

Education
Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics
Experience
Minimum years of related experience required: 3 years
Preferred years of experience: 5 years
Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desirable.

Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
1168,Data Engineer,Data Engineer,3.6,"Bookmyshow
3.6",Mumbai,"Mumbai, India",1001 to 5000 employees,2007,Company - Private,Ticket Sales,"Arts, Entertainment & Recreation",Unknown / Non-Applicable,-1
1169,Data Analyst,"Required Skills & Experience

We are looking for a Data Analyst Executive
Eligible Qualifications : B. Tech, BCA, M.Tech, MCA
Experience : 3-5 years, fresher’s can also be considered
Location of Job : Gurgaon/Connaught Place, New Delhi
Technicals Skills

Following technical skills are pre-requisite:
Well versed with Software development methodologies, such as SDLC (Software Development Life Cycle), DDLC (Document Development Life Cycle).
Database schema design and implementation
Should have worked in either of technologies Sql Query/ Tableau/ Excel (Macros)/ Access (Query) writing for data analytics.
For planning and coordinating activities, organizations remain in invariant communication with one another and the data transfer has to be performed efficiently and smoothly as possible.
He/ She should manage the execution of the technologies, help the businesses in utilizing the systems, and should be well versed with the basics of computer systems such as Networking, Installation of necessary software and hardware.
Ability to determine the interrelationships between solutions and requirements.
Ability to think analytically and should be a problem solver and logic building should be very strong.
Good interpersonal skills to form effective working relationships with people at all levels.
Excellent communication and presentation skills and strong written & oral English skills.
To know more about us visit us www.sspl.net.in or write to us at admin@sspl.net.in",-1,Substratal Solutions,Connaught Place,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1170,Artificial Intelligence Scientists,"Experience 2- 4 Years
Salary 4 LPA - 6 LPA
Job Location Chennai

Industry:
IT-Software / Software Services

Keywords:
Artificial Intelligence

About Job:
Must have Excellent knowledge in AI / Machine learning (Mandatory).
Machine learning frameworks like keras, tensor flow etc.
And also other big data tools like Hadoop etc, Must know R and python.
Good understanding in SDLC & Business cycle.",4.0,"Careerera
4.0",Chennai,"Wayland, MA",501 to 1000 employees,-1,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
1171,Senior Data Engineer,"About Us

upGrad is an online education platform building the careers of tomorrow by offering the most industry-relevant programs in an immersive learning experience. Our mission is to create a new digital-first learning experience to deliver tangible career impact to individuals at scale. upGrad currently offers programs in Data Science, Machine Learning, Product Management, Digital Marketing, and Entrepreneurship, etc. upGrad is looking for people passionate about management and education to help design learning programs for working professionals to stay sharp and stay relevant and help build the careers of tomorrow.
upGrad was awarded the Best Tech for Education by IAMAI for 2018-19
upGrad was also ranked as one of the LinkedIn Top Startups 2018: The 25 most sought-after startups in India
upGrad was earlier selected as one of the top ten most innovative companies in India by FastCompany.
We were also covered by the Financial Times along with other disruptors in Ed-Tech
upGrad is the official education partner for Government of India - Startup India program
Our program with IIIT B has been ranked #1 program in the country in the domain of Artificial Intelligence and Machine Learning
About the Role

We are looking for a Data Engineer to help us scale the existing data infrastructure and in parallel work on building the next generation data platform for analytics at scale, machine learning infrastructure and data validation systems.
In this role, you will be responsible for communicating effectively with data consumers to fine-tune data platform systems (existing or new), taking ownership and delivering high performing systems and data pipelines, and helping the team scale them up, to endure ever growing traffic.
This is a growing team, which makes for many opportunities to be involved directly with product management, development, sales, and support teams. Everybody on the team is passionate about their work and we’re looking for similarly motivated “get stuff done” kind of people to join us!

Roles & Responsibilities
Engineer data pipelines (batch and real-time ) that aids in creation of data-driven products for our platform
Design, develop and maintain a robust and scalable data-warehouse and data lake
Work closely alongside Product managers and data-scientists to bring the various datasets together and cater to our business intelligence and analytics use-cases
Design and develop solutions using data science techniques ranging from statistics, algorithms to machine learning
Perform hands-on devops work to keep the Data platform secure and reliable
Skills Required
Bachelor's degree in Computer Science, Information Systems, or related engineering discipline
6 + years’ experience with ETL, Data Mining, Data Modeling, and working with large-scale datasets
6+ years’ experience with an object-oriented programming language such as Python, Scala, Java, etc
Extremely proficient in writing performant SQL working with large data volumes
Experience with map-reduce, Spark, Kafka, Presto, and the ecosystem.
Experience in building automated analytical systems utilizing large data sets.
Experience with designing, scaling and optimizing cloud based data warehouses (like AWS Redshift) and data lakes
Familiarity with AWS technologies preferred
Qualification – B.Tech/M.Tech/MCA(IT/Computer Science)

Years of Exp – 6-9",3.5,"upGrad Education Private Limited
3.5",Mumbai,"Mumbai, India",501 to 1000 employees,2015,Company - Private,Education Training Services,Education,₹1 to ₹5 billion (INR),"Udacity, General Assembly, Springboard"
1172,BBRC-Genomics-Associate Scientist,"JOB DESCRIPTION

Designation: Associate Scientist

Job Location: Bangalore

Department: Translational Medicine- Translational Sciences

About Syngene

Incorporated in 1993, Syngene International Ltd. is an innovation-focused global discovery, development and manufacturing organization providing integrated scientific services to the pharmaceutical, biotechnology, nutrition, animal health, consumer goods and specialty chemical industries around the world. Syngene’ s clientele includes world leaders such as Bristol-Myers Squibb, Baxter, Amgen, GSK, Merck KGaA and Herbalife. Its innovative culture is driven by the passion of its 4240- strong team of scientists who work with clients from around the world to solve their scientific problems, improve R&D productivity, speed up time to market and lower the cost of innovation .

Job Purpose:
To play a key role in TM-TS, develop an early-stage research strategy, initiate and lead discovery programs while managing ongoing programs in TM-TS. The role will work part of TMTS, and work with internal and external collaborators .

Key Responsibilities:
Experience in isolating DNA and RNA from blood, tissues and FFPE samples and cell lines. Experience with optimization of extraction protocols and for parameters like yield, input sample quantities and sample types is important.
Expertise in PCR, qPCR, cDNA/gDNA library preparation. Exposure to microarray techniques.
Proficiency in preparation of libraries for Next Generation Sequencing of transcriptome and genome, with significant experience in optimization of parameters like input RNA/DNA quantities and sample type
Experience with single cell RNA-seq will be plus.
Experience with various NGS protocols (DNA Amplicon based, hybrid capture based low input, degraded DNA and RNA samples e.g. FFPE samples.
Strong understanding of experimental design and statistical principles behind experimental design and differential gene expression. Experience with analysis of single cell RNA-sequencing data will be a plus

Educational Qualification:
M.Sc or M. Tech in Biotechnology, Molecular biology or Biological Sciences,

Technical/functional Skills:
DNA/ RNA Isolation, Expertise in PCR, qPCR, Experience in NGS protocols

Experience:
2 to 5 Years

Behavioral Skills:
A proactive team player.
Ensure completion of experiments and generate accurate and reproducible data from experiments.
Ability to work independently, prioritize tasks and work on multiple projects simultaneously with; comfortable working in a dynamic environment with changing requirements.
Good oral and written communication and presentation skills to work in a multi-disciplinary team
Equal Opportunity Employer:
It is the policy of Syngene to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by applicable legislation or local law. In addition, Syngene will provide reasonable accommodations for qualified individuals with disabilities.",3.5,"Syngene
3.5",India,"BENGALURU, India",1001 to 5000 employees,1994,Unknown,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1173,Applied Scientist 1,"Position Requirements:
Master's degree in Computer Science, Computer or Electrical Engineer, Mathematics, or a related field plus at least one year of experience in the job offered or related occupations of Software Engineer, Software Developer, or a related occupation. Employer will accept a Bachelor’s degree and five years of experience in the job offered or a related occupation as equivalent to the Master’s degree and one year of experience. One year of experience in the job offered or related occupation must involve designing and developing large-scale, multi-tiered, distributed software applications, tools, systems and services using Java, Object Oriented Design and Distributed Programming].

Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, Oracle/Berkeley databases, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills

Amazon Selling Partner Services team drives the Selling On Amazon business and develops solutions that enable millions of sellers around the world to sell on Amazon's Marketplaces. More than half of shipments for Amazon customers are generated from this business. The team is focused on building a technology platform that will support the explosive business growth in existing markets, streamline the business for Amazon and the Selling partners and launch business in new markets and establish a fair marketplace.

Our team is seeking engineers with broad technical skills to help us optimize how we synthesize massive amounts of data and complex business rules into mission critical financial information. As a member of this team you will employ object oriented techniques in Java, and DynamoB, PostGres and ElasticSearch skills to help us support Amazon's next generation of selling partner services. Along the way you'll gain and leverage a unique understanding of how Amazon.com works; from the numerous software systems that comprise the website's back-end, to the details of our business model, and the relationships we're establishing with an ever-growing network of selling partners who depend on Amazon.com to run their businesses.

The ideal candidate will draw upon exemplary analytical, critical thinking, and problem solving skills, and a passion for maintaining highly reliable, distributed systems which operate 24/7/365. Successful members of this team collaborate effectively with internal end-users, aggressive cross-functional software development teams, and technical support/sustaining engineering teams to solve problems and deliver successfully against high operational standards of system availability and reliability. We look for engineers who are excellent communicators, self-motivated, flexible, hardworking, and who like to have fun!

Position Responsibilities:
Participate in the design, development, implementation, testing and documentation of large-scale, multi-tiered, distributed software applications, tools, systems and services using [Java, Object Oriented Design and Distributed Programming]. Translate functional requirements into robust, scalable, supportable solutions that work well within the overall system architecture. Participate in the full development cycle, end-to-end, from design, implementation, and testing to documentation, delivery and maintenance. Produce comprehensive, usable software documentation. Evaluate and make decisions around the use of new or existing software products and tools.

Preferred Qualifications
Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1174,Senior Clinical Data Analyst,"About Novotech:

Novotech is internationally recognised as the leading independent and full-service contract research organisation (CRO) in the Asia Pacific region. We provide a wide range of clinical development services across all research phases and therapeutic areas and have been instrumental in the success of hundreds of Phase I – IV clinical trials throughout the Asia Pacific. Powered by the highest quality people, Novotech strives to set the benchmark for both business and clinical trial performance. Our people are one of our key strengths. We value our people and recognise the work they do. We are lucky to have the best people and talent from across the Asia Pacific region work together to deliver to clinical trial success for our clients. Our people and those we look to recruit have an attitude of making things happen. They are problem solvers, driven with a focus on delivering quality, accountability and a high level of performance.

Brief Position Description:

As part of Novotech’s Biometrics unit, the Senior Data Analyst (SDA) is responsible for all data analysis and business intelligence activities related to study related clinical and operational data. The SDA acts as primary point of contact for all data analysis matters to the study team and is responsible for the timely delivery of quality outputs following all applicable regulatory, compliance, best practice and operational procedures.

Minimum Qualifications & Experience:

Graduate in information science, data science or life science-related field, or similar. More than five years’ experience in a senior role related to data science, data analysis, clinical data management or clinical data programming in a pharmaceutical company, CRO or EDC software provider.

Responsibilities
The Senior Data Analyst (SDA) is responsible for providing technical, procedural (SOPs) and planning leadership across multiple projects assigned to the data analyst team members ensuring that they deliver in accordance with SOPs, programming best practices, and the timelines agreed within the Project Team.
Collaborate with cross-functional stakeholders to implement data science solutions to solve business needs using available technological solutions.
Scope data analysis effort for projects and project manage all data analysis activities across multiple projects for different study stakeholders.
Gather study requirements from data management for data review and external data reconciliation and provide guidance on appropriate outputs (dashboards, visualisations, listings, reports).
Extract, assess, integrate, transform data sources to provide data visualisation outputs for analytics.
Design and develop prototypes and final versions of data outputs (dashboards, reports, visualisations, listings) using Business intelligence tools and Data Visualisation tools.
Design and develop standard dashboards and content for different audiences.
Analyse, manipulate and understand data from multiple sources to present and create dashboards and reports to make business decisions.
Assist teams on best-practice for data visualisation dashboard development.
Educate teams on how to use all the features of applicable data visualisation platform in conjunction with data visualisation dashboards.
SME for the data visualisation development and assisting team members.
Identify and communicate project risks and maintain documentation within project files as appropriate
Represent data analysis group at internal / external meetings as appropriate.
Assess and implement new data analysis, BI and data visualisation processes and technologies.
Take an active role in the development of best practices, process improvement, quality control and governance related to all data analysis matters.
Provide training and mentoring to Data Analysis of team members in SOPs, software applications, and best practices.
Provide Subject Matter Expertise on all data analysis and visualisation related activities.
Attributes and Skills

Expert knowledge of clinical study data structures and schemas of EDC databases. Expert knowledge in data processing activities such as extracting, integrating, transforming and presenting data. Statistical Programming skills in Python, R or similar. Knowledge of SQL and EDC systems. Working knowledge of Spotfire, Power BI, Tableau or other data review and visualisation tool. Ability to gather business requirements from multiple stakeholders and clients and provide guidance on the use of appropriate data visualisations.

Experience mentoring and training others. Awareness of regulatory and compliance issues and understanding of the application of SOPs and Quality Control to daily activities. Excellent analytical, communication and problem-solving skills.

Opportunities and Benefits:

To deliver clinical trial and research excellence for our clients, our people are 'best in class'.

At Novotech, we seek and nurture people with exceptional talent. We are committed to providing our people with regular internal and external training, a competitive bonus structure and a supportive work environment. We are also focused on providing our people with a wide variety of career growth and development opportunities.

For more information about where your next career step at Novotech might take you, visit http://novotech-cro.com/novotech-careers",4.5,"Novotech
4.5",Bengaluru,"Sydney, Australia",501 to 1000 employees,1996,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
1175,Data Engineer,"Data Engineer Responsibilities:
Liaising with coworkers and clients to elucidate the requirements for each task.
Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed.
Reformulating existing frameworks to optimize their functioning.
Testing such structures to ensure that they are fit for use.
Preparing raw data for manipulation by Data Scientists.
Detecting and correcting errors in your work.
Ensuring that your work remains backed up and readily accessible to relevant coworkers.
Remaining up-to-date with industry standards and technological advancements that will improve the quality of your outputs.
Data Engineer Requirements:
Bachelor's degree in Data Engineering, Big Data Analytics, Computer Engineering, or related field.
Master's degree in a relevant field is advantageous.
Proven experience as a Data Engineer, Software Developer, or similar.
Expert proficiency in Python, C++, Java, R, and SQL.
Familiarity with Hadoop or suitable equivalent.
Excellent analytical and problem-solving skills.
A knack for independent and group work.
Scrupulous approach to duties.
Capacity to successfully manage a pipeline of duties with minimal supervision.
Job Type: Full-time

Salary: ₹360,000.00 to ₹870,000.00 /year

Experience:
total work: 2 years (Preferred)
Data Engineer: 1 year (Preferred)
Education:
Diploma (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,Futurious Technologies,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1176,Quantitative Analyst,"The successful candidate will be a highly analytical individual with hands on programming skills. The candidate will work closely with the research team and clients towards the ongoing development and integration of new investment strategies, models and tools on Axle

Location

Mumbai
Responsibilities

Perform daily/weekly/monthly tasks of performance and risk reporting
Develop and automate investment processes and strategies via VBA and Matlab
Develop tools to integrate trading decision systems with risk management systems
Ad hoc tasks (such as operational tasks, internal documentation tasks and preparation of marketing materials)
Skills/Experience

Excellent programming skills in Matlab/Excel-VBA
Thorough with financial concepts and calculations like Drawdown, VaR, Eloss etc.
Understanding of financial market products like options, futures, FX forwards etc.
Working knowledge of Bloomberg is preferred
Should be self-driven and detail oriented with an analytical mindset
Should be a proactive and quick learner; a team player showing enthusiasm and drive to accomplish results in a fast paced environment
Min. 2 years of relevant work experience
Qualifications

B.Tech/M.Tech/MBA/CFA/FRM",5.0,"B&B Analytics
5.0",Mumbai,"Zug, Switzerland",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1177,Analyst - Data Scientist,"Job Summary

Experience:
3 - 5 Years

Location:
Mumbai

Designation:
Analyst - Data Scientist

Degree:
BE-Comp/IT, BE-Other, BTech-Comp/IT, BTech-Other, ME-Comp/IT, ME-Other, MTech-Comp/IT, MTech-Other, PhD-Comp/IT, PhD-Other

Educational Level:
Graduate/Bachelors

Industrial Type:
IT-Software/Software Services

Functional Area:
IT Software - Application Programming / Maintenance

Key Skills:
Data Scientist

Job Post Date:
Thursday, March 19, 2020

Company Description

We are capability centre based in Mumbai, initially started as a back-office operational support to the UK business unit.

However, over the recent years, we have significantly increased the breadth and depth of our capabilities and offerings to keep pace with the changing needs of the Group. These include Digital & Knowledge Services, Finance and Actuarial, Information Technology (IT), Customer Service, Risk and Audit.

Our core purpose is to be a strategic partner to company, enabling growth by delivering change and driving synergies through a highly capable and agile workforce.

With our diversified service offerings we provide our people with exciting opportunities to grow personally and professionally.

Company is a leading savings and investments business serving around 5.5 million retail customers and more than 800 institutional clients.

It-s innovative asset management and customer solutions are supported by extensive investment capabilities, an international distribution network and two strong brands.

Job Description

3 – 5 yrs experience as Data Scientist
Should have at-least 1 end-to-end ML project experience
Very high proficiency in R or Python
Excellent in forecasting methods like simple exponential smoothing, multiplicative seasonal indexes, simple and weighted moving averages and time series forecasting methods
Exposure to with advanced deep learning techniques such as LSTM. CNN, Dense neural networks as well as neural networks design and implementation through tools like tensorflow, keras, pytorch, deepai or equivalent.
Good SQL experience",3.8,"Sampoorna Computer People
3.8",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
1178,Data Lake Developer,"For Us, It's A Mission

At Mylan, we mean it when we say we work every day to provide access to high quality medicines to the world's 7 billion people. If you are unconventional, relentless and passionate. If you believe in doing what's right, not what's easy. If you are a doer and have a passion for serving others, we want to talk to you.

Make a Difference

At Mylan, each person has the ability to make a difference. From the providers who sell and market our products, to the producers who develop and manufacture them and finally to our business partners who support the providers and producers, we all have a mission critical role. Here's how this role will help:

ESSENTIAL DUTIES AND RESPONSIBILITIES
To perform this job successfully, an individual must satisfactorily perform each essential duty. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential duties.
1. Create and maintain optimal data pipeline architecture on Azure platform.
2. Develop batch processing solutions by using Data Factory and Azure Databricks.
3. Delivering a Data Warehouse in the Azure Cloud.
4. Design relational and non-relational data stores on Azure.
5. Identify, design, and implement internal process improvements : automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc..
6. Developing Big Data Solutions with Azure Machine Learning.
7. Strong interaction with business departments to provide consultative support for digitization efforts, as well as close collaboration with the Business Technology management, focused on future innovation topics.
8. Participate and lead in design sessions, demos and prototype sessions, testing and training workshops with business users and other IT colleagues.
9. Design & Build for any API Development or SQL DB development.
10. Providing service management, orchestration, monitoring and management requirements of Azure cloud platform.
11. Create data tools / products for analytics and data scientist team members that assist them in building and innovative solutions that drive tangible business value.
12. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
13. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
14. Design security for source data access. Chose the appropriate authentication mechanism, (ie Azure Active Directory (Azure AD), etc).
15. Design for real-time processing by using Stream Analytics and Azure Databricks.

Make Our Values Your Values

Mylan hires only the best. People who thrive in a culture of innovation and empowerment. People who are active learners and have a positive attitude. People who are leaders and know that by working together we can run faster, reach higher and achieve more. By doing so, we will continue to set new standards in health care. Here are the minimum qualifications and essential functions for this position:

QUALIFICATIONS

The qualifications listed below are representative of the minimum knowledge, skill, and/or ability required.

SKILLS AND ABILITIES

1. 10 years of experience in Microsoft technologies including SQL.

2. At least 5 years as a Sr Developer with at least 3 years hands on experience as Azure Data Engineer building large scale Azure data solutions.

3. At least 5 years of experience in Azure based data solutions.

4. At least 3 years of experience on working with large projects including the most recent project in the cloud (Azure) or on prem with a focus on Azure Data services.

5. At least 5 years of Hands-on administration, configuration management, monitoring, performance tuning of Hadoop/Distributed platforms.

6. At least 5 years of demonstrated experience at least in the most recent 2 years of designing and delivering solutions using Cortana Intelligence suite of analytics services part of Microsoft Azure including Azure Machine Learning Studio, HDInsight, Polybase, Azure Data Lake Analytics, Azure Data Warehouse, Streaming Analytics, Data Catalog, R/R Studio

7. Experience in designing and building logics required for optimal extraction, transformation, and loading of data from a wide variety of data sources

8. Experience within Data Security design, including but not limited to:

a. Choosing the appropriate authentication mechanism, such as Azure Active Directory (Azure AD)

b. Defining strategies for data encryption for data at rest and in transit

9. Experience partnering with Business Analysts and Data Scientists to enable effective and efficient data preparation and delivery

10. Experienced in vendor management and working with 3rd parties onshore & offshore.

11. Experience working in a global team.

12. Experience working in an Analytics / Big Data solutions on MS Azure Cloud

13. Experience with code management tools, automated testing

14. Experience creating and maintaining optimal data pipeline architecture on Azure platform

15. Experience developing batch and real-time processing solutions by using Data Factory and Azure Databricks

16. Familiar with AGILE and Azure DevOps methodology

17. Hands on PoC capabilities are needed to prove a particular architecture concept

18. Azure Native Services experience across Data Fabric and Service Fabric

19. Experience in Application modernization from legacy on-premise data architecture platform technology stack to modernized Azure Cloud base Architecture.

20. Experience with Git, NoSQL Data Solutions, Microsoft Azure, HD Insights, Azure ML, DataBricks ML Flow, R or Python.

21. Must have excellent communication skills.

EDUCATION/EXPERIENCE (Note: Please select one)

Minimum of a Bachelor's degree in Computer Science and Engineering is preferred with minimum 10 years of experience. However, a combination of experience and/or education will be taken into consideration

Why Mylan?

If you want to be part of a global health care company that is making a difference and changing lives, Mylan may be the place for you. With a workforce of more than 35,000 worldwide, we can make a difference. We encourage you to visit Mylan.com to learn more about our unconventional culture, our approach to doing business and how we plan to set new standards in health care.

Mylan offers competitive salary, excellent benefits and an environment conducive to professional growth and advancement. All qualified applicants will receive consideration for employment without regard to their disability or protected veteran status. Mylan is an Equal Opportunity Employer, Minorities/Female/Disabled/Veteran.",3.8,"Mylan Inc.
3.8",Bengaluru,"Hatfield, United Kingdom",10000+ employees,1961,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1179,Off Campus Recruitment - Quantitative Researcher,"Description:
Graviton is a privately funded quantitative trading firm striving for excellence in financial markets' research. We are seeking fresh talent from the top IIT's to join us as Quantitative Researchers for our team in Gurgaon.If you are a student graduating in 2020 from Computer Science , Electrical or Maths Stats Computing streams with a greater than 8 CGPA please apply here.

This role is open to students from campuses that we could not visit this year. Please check your individual placement policy restrictions before applying.

Graviton trades across a multitude of asset classes and trading venues using a gamut of concepts and techniques ranging from time series analysis, filtering, classification, stochastic models, pattern recognition to statistical inference analysing terabytes of data to come up with ideas to identify pricing anomalies in financial markets.

As a Quantitative researcher your responsibilities will include

Develop new or improve existing trading models using in-house platforms

Use advanced mathematical techniques to model and predict market movements

Analyse large financial datasets to identify trading opportunities

Provide real time analytical support to experienced traders

Requirements :
Possess a degree in a highly analytical field, such as Engineering, Mathematics, Computer Science from IITs schools

Quantitative bend of mind

A working knowledge of Linux/Unix

Programming experience, preferably in C++ or C

Strong interest in learning about financial markets.

Have a strong work ethic

Hard Working

Benefits:
Our open and casual work culture gives you the space to innovate and deliver. Our cubicle free offices , disdain for bureaucracy and insistence to hire the very best creates a melting pot for great ideas and technology innovations. Everyone on the team is approachable, there is nothing better than working with friends!

Our perks have you covered.

Competitive compensation

6 weeks of paid vacation

Monthly after work parties

Catered breakfast and lunch

Fully stocked kitchen

Gym membership

International team outing",5.0,"Graviton Research Capital LLP
5.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2014,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1180,Data Engineer,"Zauba Technologies is a startup based in Bangalore. Zauba's services are used by leading companies in India. Zauba is powered by a young and passionate team. We are looking for individuals who would like to be a part of our founding team.

As a Data Engineer and as a part of founding team, you will be expected to visualise and develop disruptive data products. Eventually you would be responsible for entire project lifecycle of products you would visualize. Your rewards will be directly proportional to the value you generate.

Job Responsibilities
Design and development of robust, scalable and highly efficient data engineering solutions for structured and unstructured data (Including gathering and processing raw data at scale, writing scripts, web scraping, calling APIs, writing SQL queries, etc.)
Develop processes for text mining and extraction of information from unstructured data
Design, architect and develop efficient data pipelines around the data collected
Take ownership of existing web product and applications
Design and implement data models that scale across the enterprise
Take ownership of existing data workflows and processes
Enhance scalability, performance, and stability of existing infrastructure
Work closely with other team members to integrate your innovations and algorithms into our production systems

Essentials
Java/Python - Intermediate to advanced level
SQL - Advanced
MySQL Intermediate to advanced level
Regex - Basic to intermediate level
Linux Basic to intermediate level

Good to have
Hadoop/Spark
R
MongoDB

Must have qualities
Skills to learn new skills quickly
Desire to create disruptive products and services
Passion - not just to work in startups but to take them to next level
Above average programming aptitude
Be passionate about producing high quality engineering deliverables
Be productive working independently or collaboratively
Have an eye for building efficient processes
Be self motivated
Proactively take ownership

Interested?

Send your resume to hr@zaubacorp.com",3.8,"Zauba Corp
3.8",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 million (INR),-1
1181,Quantitative Research,"We are looking for highly trained professionals who are interested in applying advanced mathematical quantitative methods to the modeling of global financial markets. You would be joining a group made up of highly proficient individuals from various scientific disciplines. We have a spectrum of opportunities for individuals with the right scientific skills. Experience in finance is not required.

The ideal research candidate will have:
A Ph.D. in Computer Science, Mathematics, Physics, Statistics, or a related technical discipline.

A demonstrated capacity to do first-class research.

Computer programming skills.

An intense interest in applying quantitative analysis to solve difficult problems.

Send us a copy of your resume to
careers@dolatcapital.com

For internship opportunities, please send us a copy of your resume to
careers@dolatcapital.com",4.0,"Dolat Capital
4.0",Mumbai,"Mumbai, India",51 to 200 employees,1970,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1182,Data Engineer,"Bachelor’s degree in Computer Science or related field
5+ years relevant experience
5+ years experience with SQL, SQL Tuning, Oracle, OLAP, Big Data Technologies
5+ years experience developing end-to-end Business Intelligence solutions: data modeling, ETL and reporting
Experience with Java and experience with scripting languages like Perl, Python, Unix shell scripts,VBA and MS Excel
Proficiency with Linux and systems administration
Proven ability at looking at solutions in unconventional ways. Sees opportunities to innovate and can lead the way.
Top notch communication (verbal and written) and interpersonal skills to convey key insights from complex analysis in summarized business terms and an ability to effectively communicate with technical teams.
Ability to work with shifting deadlines in a fast paced environment.
Operations Finance Technology team, responsible for building technical solutions for multi-billion WW Operational Cost analytic including Inbound cost (Receiving / PO), variable Cost, fixed cost, outbound (Customer Shipments / Transportation), and Customer Service, is looking for a Data Engineer.

As a data engineer, you will get the exciting opportunity to work on very large data sets in one of the world's largest and most complex data warehouse environments. You will work closely with the business teams in analysis on various cost savings initiatives, many non-standard and unique business problems and use creative-problem solving to deliver actionable output.
You will be responsible for designing and implementing an analytical environment using third-party and in-house reporting tools, modeling metadata, building reports and dashboards. You will have an opportunity to work with leading edge technologies like Redshift, Hadoop/Hive/Pig. You will be writing scalable queries and tuning performance on queries running over billion of rows of data.

You should be analytical, have an extremely high level of customer focus and a passion for process improvement. You should be motivated self-starter that can work independently in a fast paced, ambiguous environment. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions.
Bachelors in Computer Science or related field
Practical Knowledge of Linux or Unix shell scripting
Experience in working with business customers to drive requirements analysis
Exposure to large databases, BI applications, data quality and performance tuning
Excellent written and spoken communication skills
Experience with Hadoop-based technologies such as HBase, Pig, Hive and Spark
Strong proven ability in building high-performance, highly available and scalable data solutions using Oracle and/or Hadoop-based technologies
Knowledge of data warehousing concepts.
Strong sense of ownership, urgency, and drive
Strong troubleshooting and problem solving skills
Experience with Amazon Web Services",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1183,DATA ANALYST,"posted by Mahima Gaur

2 - 5 years Delhi

Job Description
Experience in data processing
Experience in data cleaning and data tabulation activities
Strong analytical, communication and team management skills
Strong understanding of data management using SPSS and research techniques
Competency in a Tabulation software (decipher / wincross / quantum etc), Excel, Powerpoint
Ability to summarize findings, draw conclusions, and put together a presentation using Powerpoint
Role Category : Data Analyst

Employment Type : Permanent Job, Full Time",4.9,"Knowledge Excel Services.
4.9",New Delhi,"New Delhi, India",1 to 50 employees,2007,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
1184,Data Engineer,"Key skills : Python , Spark , SQL , Pyspark • AWS platform used for the work • Strong experience in SQL is mandatory • Good familiarity of AWS landscape • Good experience in collecting business requirements & design them as per requirement from customer • Should able to work independently & interact business users & technical stakeholders • Strong communication skills both oral & written. • Should work as an individual resources",3.5,"Larsen & Toubro Infotech Limited
3.5",India,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1185,Big Data Engineer,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
1186,Client Data Analyst,"At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.
What is the Client Data Analyst – Client Analytics group responsible for?
This team manages business data to ensure accurate, timely, consistent and compliant data. Their contributions deliver quality data that is easily accessible and can be trusted. Key downstream capabilities such as reporting and analytics depend on this as well as operational data access on various systems. The Data Management Team is a support function that acts as an advocate and a point of contact for Sales and Marketing data.

What are the ongoing responsibilities of an Client Data Analyst ?
Understand the data flow, key consumption and production of data as well as context within the enterprise:
Build positive relationships with teams, especially the key data consumers and analytics. Take the time to increase knowledge of how they run their business and incorporate sales data into daily work
Connect regularly with each sales office to understand current issues and challenges. Probe the business and validate against other sales offices to understand the scope and priority of the issue
Make recommendations on how data unifications and flow can be used to improve business tasks. Liaise business partners to deliver solutions (reports, processes, technology) that add value.

Provide data management subject matter expertise. Appreciate the connection and data flow between applications and other corporate systems. Be able to clearly articulate the data needs and move initiatives forward by collaborating with business partners:
Actively participate in meetings with business partners to ensure that priorities are clearly understood, information is regularly shared and that key participants are “kept in the loop”
Provide context and background on issues. Collaborate on ideas for progressing initiatives. Ensure appropriate resources are involved to take initiatives forward
Provide insights and expertise to scope statements and requirements documentation
Actively consult or participate in the user acceptance testing process (test cases, documentation, testing execution, etc.)
Ensure business needs remain aligned with overall corporate initiatives and deliver the benefits as originally intended

Monitor the integrity of data and usefulness of reports. Ensure the information available within systems is accurate and up-to-date. Proactively seek data cleansing opportunities and evolve data to better support. Document and maintain ongoing processes for reporting and data clean-up:
Partner with all key data consumers to gain a solid understanding of usage and challenges around data. Establish processes for prioritization of enhancements, especially with the analytics groups
Provide 1st level support for data issues and data maintenance for owned data
Verify and execute data loads into our internal sales systems and ensure any upstream systems accurately receive their data

Increase awareness and promote data management capabilities. Share best practices and provide coaching to local offices on how to access and incorporate output into sales tasks. Encourage IAS leaders to leverage data to make more informed, strategic decisions:
Clearly articulate the goals and core services of the data management team. Proactively promote this information within IAS and ensure business partners understand the data management role within the organization
Share best practices and provides guidance on data capabilities. Reinforces ownership and accountability for data accuracy
Seek opportunities to share the benefits of leveraging sales data to make more informed business decisions

What ideal qualifications, skills & experience would help someone to be Successful?

Knowledge, Education And Experience:
Four year bachelor’s degree required (majors of preference include: business, computer science, mathematics) Advanced degree a plus
Understanding of the Franklin Templeton business model, how FT makes money, the sales process, how technology fits in with the business, etc. Knowledge of the GAS (Global Advisory Services) structure
Experience working through multiple business fiscal cycles; exposure and/or direct experience with project management and/or sales-related-capacity required
Prior work experience related to analytics, sales, marketing and/or international a must. Level will not be granted based on years of experience but will be determined by the employee’s ability to meet each job activity as outlined the ‘typical/expected focus by level
Skills And Abilities:
Ability to communicate effectively with all levels of management; ability to tailor communication style based on audience; ability to get others to want to collaborate with you; strong facilitation skills
Excellent writing skills (for presentations, documentation, etc.)
Working knowledge of the CRM, MDM, Excel, SQL, Power BI, Tableau, Business Objects, and Microsoft Products (PPT, Power Apps, Doc, Visio)
Ability to absorb and interpret large quantities of data; apply trend analysis and knowledge of the business to develop a meaningful and digestible summary with the appropriate level of detail
Ability to take a larger problem and break down the individual components; identify how to go about solving the problem and who to involve in the process
Ability to present recommended solutions to a variety of issues and problems (solutions that are consistent with organization objectives)
Must be extremely detail-oriented (managing lists, tasks/to-dos, etc.) good with follow through on own items; good with following up with others on outstanding item

What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.

Highlights of our benefits include:

Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.",3.8,"Franklin Templeton Investments
3.8",Hyderabad,"San Mateo, CA",5001 to 10000 employees,1947,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Fidelity Investments, Vanguard"
1187,Data Analyst,"Roles and Responsibilities:
Extracting, transforming and inputting data sets from various resources. Creating predictive models, translating non-technical aspects into quantifiable tasks. Analysis and representation of output data, highlight and explain trends and patterns, error elimination, using advanced statistical methods (regression, probability distribution, clusters etc.) to provide accurate results.
Data collection, Data Mining, Report generation, Problem identification and solution formulation Market analysis and establishing trends, Strategy development and implementation

Skills:
Extremely good analytical skills.
Good working knowledge of all MS-Office products, especially Advance Excel, Word, PowerPoint, MS-access.
Statistical tools and methods.

Interested candidates can send the updated resume on satish.mehra@exelaonline.com or call on 7722028636
00-7.00 Years",2.6,"Exela Technologies
2.6",Pune,"Irving, TX",10000+ employees,2017,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"SourceHOV, BancTec, Transcentra"
1188,Data Modeler,"• Minimum 5-8 years of working experience as Data modeler.
• Data modelling experience in designing.
• Minimum 2-3 years real time experience in Erwin tool is mandatory.
• Experience in normalized modeling techniques.
• Experience in designing the Start schema.
• Experience working in ORACLE.
• Experience with database design, capacity planning, performance tuning and query optimization.
• Experience in working with Bank or Banking and Finance or Financial domain.
• Excellent communication skills with leadership quality.

Job Segment:
Database, Oracle, ERP, Technology",3.5,"LTI
3.5",Mumbai,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1189,Machine Learning Engineer,"Looking for Data Scientists with Python/R Programming skills.
Specific experience in AI areas like Statistical Machine learning / Deep learning / Natural Language Processing (NLP)/ Operations Research (Optimization) will be an advantage.Individual in this role is expected to work with multiple stakeholders and teams

Qualifications and Requirements:-
Previous working experience as a Machine Learning/ Data Scientist for 2 years
MA in Computer Science or similar relevant field
Hands on experience with MALLET
In depth knowledge of Apache Tomcat/Open Source
Excellent project and time management skills
Attention to detail
Outstanding problem solving and analytical skills",-1,Tekolutions.ai,India,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1190,Data Science Internship,"About the company:
SkillBit is a leading staffing and recruitment company engaged in talent searching assignments for skilled and talented candidates for the industry.

About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Working on data science algorithms and AI concepts 2. Using Python or R for web scraping 3. Building AI models using Python, machine learning, and deep learning algorithms 4. Processing of unstructured/structured data

Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 6th Jun'20 and 11th Jul'20
are available for duration of 1 month
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply

Number of internships/jobs available: 3

Categories: Data Science",-1,SkillBit,Pune,-1,-1,-1,-1,-1,-1,-1,-1
1191,Data Engineer,"As a data engineer at TEAL, you'll be taking the plunge into a rich data lake that includes everything from satellite data to legal court orders. You'll be hustling and getting your hands dirty with every part of the data pipeline always having an implicit appreciation for how all of this data will ultimately power a revolutionary real estate risk platform.

Your day-to-day will include either all or some of the following:

Constantly scoping out new data sources to complement existing ones
Creating and maintaining distributed web scrapers using Python, RabbitMQ and other technologies
Architecting and managing data pipelines where data flows into multiple end-points including, but not limited to, Postgres, MongoDB and Apache Solr
Documenting workflows and constantly iterating to create better data infrastructure.

We'd love it if you:
Are proficient in Python or any other object-oriented language
Have worked with large (millions to hundreds of millions of rows in a SQL database) interdisciplinary datasets
Have scraped difficult websites and have some experience working with various data APIs
Are patient and methodical with unstructured and messy data
Are always hungry to learn newer and better technologies to make the data ecosystem faster, smoother and less silo-ed

Extra brownie points if you:
Have some experience working with large-scale search indexing
Have performed geospatial analyses in some capacity
Have created and managed data lakes in the cloud
Culture

To explore our culture and the values we embody click here

Testimonials
Testimonial

My experience at TEAL surpassed all my expectations from the get-go. I was asked to help solve one of the most daunting problems in the Indian real estate market. Every day while working on a subset of the problem, the ideas that I brought to the table were shaped into cohesive solutions by a collaborative team effort. At TEAL I was exposed to the most cutting edge technologies such as Cloud Computing, Big Data, ML and Data Science. The growth opportunities at TEAL are tremendous, If you are innovative and can demonstrate the will to realize your ideas, TEAL is an amazing organization to work for.
Gyan Vardhan, Data Science Intern
I had interned as a Data Scientist at Terra Economics and Analytics Lab during its early days, it was a rich learning experience working with a multi-disciplinary team who are extremely passionate about building a decision support platform for the insanely complicated realty market in India. It was exciting and challenging to work on mining huge volumes of property records; extracting patterns from the data, building data pipelines and brainstorming on building the core system. TEAL offers a very healthy work environment coupled with insanely talented people working together in an exciting setting.
Naga Anjaneyulu, Data Science Intern
I worked as a full-time Data science intern at TEAL. During this period, I got an opportunity to leverage my skillsets while also learning new technologies, working on tasks assigned to me. The company operates on the latest tech-stacks and gives opportunities to learn as much as you want. The work environment is challenging, the team at TEAL is super supportive and new ideas are always welcome. It has all the good perks of a startup; creativity and innovation, casual work atmosphere and a collaborative approach to solving problems. Personally, I loved working there, my experience was fantastic!
Archana Parmar, Data Science Intern
As a second-year college student, I was looking for an internship that would allow me to delve deeper into research and work with big data, TEAL gave me the perfect opportunity to do so, enabling me to develop proficiency in research and analysis. As a research analyst intern, I collated and cleaned data and helped in the preparation of reports and presentations, and I had members helping me at every stage of this process. This collaborative environment allowed me to cultivate my skills and also learn from my peers. The holy trinity of Rohan, Kshitij, and Shreyas served as not only excellent mentors and bosses but also as friends, helping me at every stage and giving us all food and ice cream to keep us going!
Arush Mehra, Research Intern
Internships are a crucial part of one’s early career. The internship experience at TEAL was a thrilling rollercoaster ride to say the least! It was more than implementing a standard model or building an already though out concept into reality. It was about finding the solution to a unique and open-ended problem.It was exciting to work on addressing a problem with far -reaching real world applications.Moreover, the work environment had the perfect balance of casual yet professional which kept you focused and stress free at the same time. Out of every 100 startups in India only 2 of them succeed, but there are very few like TEAL India which are bound to make it big at such an early stage.
Divyanshu Agarwal, NLP Intern",4.7,"Terra Economics & Analytics Lab (TEAL)
4.7",New Delhi,"Bengaluru, India",1 to 50 employees,2018,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
1192,Senior Consultant - ModellingOps Data Engineer,"Job Title: Senior Consultant - ModellingOps Data Engineer
Location: TRIL GTC
GCL: D1

JOB DESCRIPTION:

AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. The Science & Enabling Units IT is AZs global IT capability function supporting key business areas operating out of sites across the US, UK, Sweden, India & Mexico.

We are looking for AI Ops consultant who will leverage tools & technology best practices to improve delivery performance & data engineering capabilities in the D&A space.

ROLES & RESPONSIBILITIES:

7-10 years of experience in IT Operations involving Data Science, Artificial Intelligence-Machine Learning and Predictive Analytics. Experience in architecting and implementation of end-to-end AIOPs solutions through ELK stack, Splunk. Experience in applying statistical methods, analysis, pattern recognition and modeling on IT Operational data using ELK machine learning. Experience in extracting meaning full data from incoming data streams from different sources through RegEx, Grok etc. Hands-on experience in applying machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc in the IT Operation domain. Experience with machine learning and statistical programming languages - Python, R etc. Experience in assessing the existing IT environment and providing recommendations to reduce the critical applications impacting incidents. Experience in exploring and identifying areas where manual tasks can be automated in IT environment. Experience with various Enterprise IT monitoring solutions including Infrastructure monitoring, Application Performance Monitoring, Network Monitoring, Cloud monitoring etc. Experience in IT Service Management including Service Desk, Incident Management, Change Management, CMDB etc. Excellent knowledge on various IT infrastructure components that includes Server Infrastructure, middle ware, database and application architectures and Cloud Components. Experience/knowledge on Infra monitoring tools - NOI, Zabbix, AppDynamics, Datadog, SCOM, SolarWinds etc. and Service Management tools -IBM Control Desk, BMC Remedy, ServiceNow etc. Experience/Knowledge on BI tools Knowledge on distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc. Knowledge on other programming languages/scripting: Python, Java, JavaScript, etc. ( Added Advantage ) Good analytical skills, strong communication skills are must. Client facing experience is an added advantage. Excellent experience in understanding the problem statement, architect and designing the solution

MANDATORY SKILLS:
Significant experience with AWS cloud environments, working knowledge of Google and Azure platforms. Knowledge of Kubernetes, S3, EC2, Sagemaker, Athena, RDS and Glue is essential.
Experience provisioning computational resources in a variety of Cloud environments using Infrastructure as Code.
Experience with best practice of data transport and storage within cloud system.
Experience building large scale data processing pipelines. e. g. Spark and SQL.
Experience with containers and microservice architectures e.g. Kubernetes, Docker and serverless approaches.
Excellent working knowledge in DevOps, using continuous integration and continuous development.
Use of Data Science modelling tools e.g. R, Python, SAS and Data Science notebooks (e.g. Jupyter).
Good written and verbal skills, fluent English
DESIERED SKILLS:
Agile practices, especially being a SCRUM Master
EDUCATIONAL BACKGROUND: B.E/B.Tech/MCA

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",3.9,"AstraZeneca
3.9",Chennai,"Cambridge, United Kingdom",10000+ employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Roche, GlaxoSmithKline, Novartis"
1193,DATA ENGINEER,"JOB DESCRIPTION
As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements, and also research new uses for data acquisition. You should also know the ins and outs of the industry such as data mining practices, algorithms, and how data can be used.

DESIRED CANDIDATE PROFILE
An ideal candidate must possess prior experience leading a project.

Candidates must have:
> Experience in Hive, Spark, Scala, AWS DynamoDB, HBase, AWS Glue, Talend, Kafka, Snowflake ETL
> Strong experience in a BI/Data Warehouse environment with involvement in design, development, implementation, troubleshooting and support of ETL process using ETL tool.
> Experience in developing Data Marts, Data warehousing and Operational Data Store (ODS) on any of the databases or Hadoop environments.
> Experience in database like MS SQL, MySQL, Oracle, PostgreSQL
> Good to have programming experience in writing Complex Stored Procedures, Queries, Views, User Defined Functions, Cursors and Common Table Expressions using SQL or T-SQL.
> Experience in Performance Tuning and Query Optimization by Indexing, Partitioning and De-normalization.
> Experience in Developing a framework for ingesting data into Data lake
> Good database knowledge, analytical thinking
> Design, construct, install, test and maintain data management systems.
> Build high-performance algorithms, predictive models, and prototypes.
> Develop set processes for data mining, data modeling, and data production.
> Experience with cloud services: AWS (EC2, EMR, S3, Athena) and scripting languages like Python, /PySpark/R/SAS
> Install/update disaster recovery procedures.
> Experience in Agile Application Development & Scrum methodologies is preferred
> Ability to supervise and mentor junior developers on the team.
> Must be self-motivated and work well pulling people together in addition to being able to pull people together technically
> Demonstrated proficiency of troubleshooting techniques and detail-oriented problem diagnosis
> Ability to handle responsibility, is self-directed, with strong organizational and documentation skills
> Ability to work independently and efficiently under aggressive deadlines to meet project commitments
> Excellent verbal and written communication skills

EDUCATION
UG - B.Tech/B.E. - Computers, Electronics/Telecommunication, Diploma - Computers, Electronics/Telecommunication, B.Sc - Computers, BCA - Computers) AND (PG - M.Tech - Computers, Electronics/Telecommunication, MCA - Computers, M.Sc - Electronics, Computers) AND ( Doctorate - Any Doctorate - Any Specialization, Doctorate Not Required).

OTHER DETAILS
Number of vacancies: 4
Experience: 3 years
Location: Cochin

If you have a passion towards technology and coding, then we have the right job for you. Kindly forward your resumes to
Email: jobs@mjsofttech.com
Phone: 0484-2421245 / 928 720 7160",4.0,"MJ Softtech
4.0",Kochi,"Cochin, India",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
1194,Data Engineer,"Education/ Experience and Skill Requirement
4+ years of relevant experience in
Experience working with both relational and NoSQL databases.
Strong coding skills; Python (preferred) /R/Java/Scala
Experience in developing Data warehousing technologies Experience with AWS or equivalent cloud services preferred
Experience in BigData technologies (Hadoop, HDFS, MapReduce, Spark, Hive, HBase etc) will be valuable
Knowledge of Machine Learning a big plus (Random Forest, Decision Trees, SVM, NLP, Gradient Boosting, Supervised/Unsupervised Learning, Clustering, classification and regression modeling).
Responsibilities
Proficiency with several years’ experience in more than one of Python, R, Java, Scala, or robust Linux shell scripting
Implementation experience with data warehouse architecture & design, ETL design/development, and Analytics
Knowledge of general cloud architecture and cloud strategies especially around AWS services and concepts such as S3 object stores, RDS databases, EC2, Glacier, Lambda, IAM, enterprise security, data security, DevOps, replication and disaster recovery
Well versed with data mining & exploration, NLP and visualization
Understanding of data modeling, data integration, and data representation (metadata, OWL, ontologies)
Developing data marts and data management using SQL
Creating powerful visual outcomes
Independently manage daily client communication, especially over calls
Manage client deadlines, ensure quality of the deliverables, attention to detail
Experience/understanding of corporate finance data from company filings is desirable",3.6,"Copal Partners
3.6",Bengaluru,"New York, NY",10000+ employees,1900,Company - Public,Financial Analytics & Research,Finance,₹100 to ₹500 billion (INR),-1
1195,Data Engineer,"Job Description / Responsibilities
Build workflows to ensure data extraction quality and storage into our backend data store
Architect, build and train ML/AI models that can predict outcomes and report on anomalies.
Design data pipelines to perform ETL on content/data from multiple types of source systems.
Create data analytics views using RDBMS/Key-Value stores, on private and public/cloud
Create software that is well tested, maintainable, extensible and scales out with large data

Minimum Qualifications:
2+ years of software development with Python
2+ years of SQL (MySQL/Postgres) and Key-Value databases
1+ years of experience with scikit
2+ years of experience in data extraction, data transformation using custom Python/Java
Experience working with MapReduce/Hadoop/kafka/Elastic stack
Experience with Node backend and React/Redux
Experience working with git/mercurial, Amazon/Google cloud, Linux/LAMP stack
Experience in testing or test driven development
Experience with Data science and Machine Learning algorithm development

Location:
Hyderabad/Bangalore

Package:
Highly competitive to match experience and capability",3.7,"TVS
3.7",Bengaluru,"Chennai, India",5001 to 10000 employees,-1,Company - Private,Accounting,Accounting & Legal,₹100 to ₹500 billion (INR),-1
1196,Data Engineer,"Permanent position with US based client of iFlex.
Work Location: Bangalore
Experience Level: 2+ Years

Role:
As part of our global team you will work on the data platform reporting to the Data Engineering Lead. Your role includes specification, development, test and rollout of features on our data platform. You are expected to contribute to the vision, understand our product roadmap, integrate business value andclient experience and contribute to build an engineering culture within the team. This initiative is of critical important to the success of the organization and our roadmap, for instance, services like liquidity analytics, billing, client onboarding, reporting and others will rely on the data platform. Accurate, granular, complete and timely data will be our key differentiating factor and competitive advantage in the market place. We expect the successful candidate to deliver high quality software and to be passionate about data engineering..

Responsibility / Qualification:
Managing multiple tasks and use sound judgment when prioritizing.
Collaborating with global cross functional team in building customer-centric products.
Analyzing existing software implementations to identify areas of improvement and provide deadline estimates for implementing new features.
Updating and maintain documentation for team processes, best practices and software runbooks.
Establishing trusted partnerships with peers, product heads, and executive level stakeholders.
We are looking for someone who is passionate about technology and engineering.
Exceptional analytical skills and ability to apply knowledge and experience in decision-making to arrive at creative and commercial solutions.
Ability to leverage technology to deliver business value.
You are independent and comfortable in a fast paced, ambiguous and often multi-directional work environment.

Preferred Qualifications:
B.S. or higher in Computer Science.
Minimum 2 years of relevant professional experience using a modern programming language (preferably Java/Scala).
Experience leveraging test driven development technics.
Comfort with Agile operating models.
Team oriented.
Strong interpersonal and communication skills.
Energetic, self-directed, and self-motivated.
Experience with microservice architecture.
Experience with Kafka, MongoDB, Hadoop, Cassandra.
Experience with AWS.
Experience in Financial Services or Fintech.",-1,IFLEX,Bengaluru,"Moscow, Russia",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1197,CIEL/SEL/1941: Sr data scientist,"Mandatory skills required -
Databases (SQL, Oracle, Any RDBMS) - Should have working knowledge of atleast one database
PL/SQL Programming Languages
R, Python (Any One)
Inferential Statistics - Hypothesis, p-value, R2, RMSE, MAPE etc
Exploratory Data Analysis
Machine Learning Algorithms - Should have in-depth knowledge and implementation of atleast one algorithm

Responsibilities
: Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the why & how of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions

Education
Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics
Experience
Minimum years of related experience required: 3 years
Preferred years of experience: 5 years
Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desirable.

Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
1198,Data Engineer,Data Engineer,3.6,"Bookmyshow
3.6",Mumbai,"Mumbai, India",1001 to 5000 employees,2007,Company - Private,Ticket Sales,"Arts, Entertainment & Recreation",Unknown / Non-Applicable,-1
1199,Data Analyst,"Required Skills & Experience

We are looking for a Data Analyst Executive
Eligible Qualifications : B. Tech, BCA, M.Tech, MCA
Experience : 3-5 years, fresher’s can also be considered
Location of Job : Gurgaon/Connaught Place, New Delhi
Technicals Skills

Following technical skills are pre-requisite:
Well versed with Software development methodologies, such as SDLC (Software Development Life Cycle), DDLC (Document Development Life Cycle).
Database schema design and implementation
Should have worked in either of technologies Sql Query/ Tableau/ Excel (Macros)/ Access (Query) writing for data analytics.
For planning and coordinating activities, organizations remain in invariant communication with one another and the data transfer has to be performed efficiently and smoothly as possible.
He/ She should manage the execution of the technologies, help the businesses in utilizing the systems, and should be well versed with the basics of computer systems such as Networking, Installation of necessary software and hardware.
Ability to determine the interrelationships between solutions and requirements.
Ability to think analytically and should be a problem solver and logic building should be very strong.
Good interpersonal skills to form effective working relationships with people at all levels.
Excellent communication and presentation skills and strong written & oral English skills.
To know more about us visit us www.sspl.net.in or write to us at admin@sspl.net.in",-1,Substratal Solutions,Connaught Place,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1200,Artificial Intelligence Scientists,"Experience 2- 4 Years
Salary 4 LPA - 6 LPA
Job Location Chennai

Industry:
IT-Software / Software Services

Keywords:
Artificial Intelligence

About Job:
Must have Excellent knowledge in AI / Machine learning (Mandatory).
Machine learning frameworks like keras, tensor flow etc.
And also other big data tools like Hadoop etc, Must know R and python.
Good understanding in SDLC & Business cycle.",4.0,"Careerera
4.0",Chennai,"Wayland, MA",501 to 1000 employees,-1,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
1201,Senior Data Engineer,"About Us

upGrad is an online education platform building the careers of tomorrow by offering the most industry-relevant programs in an immersive learning experience. Our mission is to create a new digital-first learning experience to deliver tangible career impact to individuals at scale. upGrad currently offers programs in Data Science, Machine Learning, Product Management, Digital Marketing, and Entrepreneurship, etc. upGrad is looking for people passionate about management and education to help design learning programs for working professionals to stay sharp and stay relevant and help build the careers of tomorrow.
upGrad was awarded the Best Tech for Education by IAMAI for 2018-19
upGrad was also ranked as one of the LinkedIn Top Startups 2018: The 25 most sought-after startups in India
upGrad was earlier selected as one of the top ten most innovative companies in India by FastCompany.
We were also covered by the Financial Times along with other disruptors in Ed-Tech
upGrad is the official education partner for Government of India - Startup India program
Our program with IIIT B has been ranked #1 program in the country in the domain of Artificial Intelligence and Machine Learning
About the Role

We are looking for a Data Engineer to help us scale the existing data infrastructure and in parallel work on building the next generation data platform for analytics at scale, machine learning infrastructure and data validation systems.
In this role, you will be responsible for communicating effectively with data consumers to fine-tune data platform systems (existing or new), taking ownership and delivering high performing systems and data pipelines, and helping the team scale them up, to endure ever growing traffic.
This is a growing team, which makes for many opportunities to be involved directly with product management, development, sales, and support teams. Everybody on the team is passionate about their work and we’re looking for similarly motivated “get stuff done” kind of people to join us!

Roles & Responsibilities
Engineer data pipelines (batch and real-time ) that aids in creation of data-driven products for our platform
Design, develop and maintain a robust and scalable data-warehouse and data lake
Work closely alongside Product managers and data-scientists to bring the various datasets together and cater to our business intelligence and analytics use-cases
Design and develop solutions using data science techniques ranging from statistics, algorithms to machine learning
Perform hands-on devops work to keep the Data platform secure and reliable
Skills Required
Bachelor's degree in Computer Science, Information Systems, or related engineering discipline
6 + years’ experience with ETL, Data Mining, Data Modeling, and working with large-scale datasets
6+ years’ experience with an object-oriented programming language such as Python, Scala, Java, etc
Extremely proficient in writing performant SQL working with large data volumes
Experience with map-reduce, Spark, Kafka, Presto, and the ecosystem.
Experience in building automated analytical systems utilizing large data sets.
Experience with designing, scaling and optimizing cloud based data warehouses (like AWS Redshift) and data lakes
Familiarity with AWS technologies preferred
Qualification – B.Tech/M.Tech/MCA(IT/Computer Science)

Years of Exp – 6-9",3.5,"upGrad Education Private Limited
3.5",Mumbai,"Mumbai, India",501 to 1000 employees,2015,Company - Private,Education Training Services,Education,₹1 to ₹5 billion (INR),"Udacity, General Assembly, Springboard"
1202,BBRC-Genomics-Associate Scientist,"JOB DESCRIPTION

Designation: Associate Scientist

Job Location: Bangalore

Department: Translational Medicine- Translational Sciences

About Syngene

Incorporated in 1993, Syngene International Ltd. is an innovation-focused global discovery, development and manufacturing organization providing integrated scientific services to the pharmaceutical, biotechnology, nutrition, animal health, consumer goods and specialty chemical industries around the world. Syngene’ s clientele includes world leaders such as Bristol-Myers Squibb, Baxter, Amgen, GSK, Merck KGaA and Herbalife. Its innovative culture is driven by the passion of its 4240- strong team of scientists who work with clients from around the world to solve their scientific problems, improve R&D productivity, speed up time to market and lower the cost of innovation .

Job Purpose:
To play a key role in TM-TS, develop an early-stage research strategy, initiate and lead discovery programs while managing ongoing programs in TM-TS. The role will work part of TMTS, and work with internal and external collaborators .

Key Responsibilities:
Experience in isolating DNA and RNA from blood, tissues and FFPE samples and cell lines. Experience with optimization of extraction protocols and for parameters like yield, input sample quantities and sample types is important.
Expertise in PCR, qPCR, cDNA/gDNA library preparation. Exposure to microarray techniques.
Proficiency in preparation of libraries for Next Generation Sequencing of transcriptome and genome, with significant experience in optimization of parameters like input RNA/DNA quantities and sample type
Experience with single cell RNA-seq will be plus.
Experience with various NGS protocols (DNA Amplicon based, hybrid capture based low input, degraded DNA and RNA samples e.g. FFPE samples.
Strong understanding of experimental design and statistical principles behind experimental design and differential gene expression. Experience with analysis of single cell RNA-sequencing data will be a plus

Educational Qualification:
M.Sc or M. Tech in Biotechnology, Molecular biology or Biological Sciences,

Technical/functional Skills:
DNA/ RNA Isolation, Expertise in PCR, qPCR, Experience in NGS protocols

Experience:
2 to 5 Years

Behavioral Skills:
A proactive team player.
Ensure completion of experiments and generate accurate and reproducible data from experiments.
Ability to work independently, prioritize tasks and work on multiple projects simultaneously with; comfortable working in a dynamic environment with changing requirements.
Good oral and written communication and presentation skills to work in a multi-disciplinary team
Equal Opportunity Employer:
It is the policy of Syngene to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by applicable legislation or local law. In addition, Syngene will provide reasonable accommodations for qualified individuals with disabilities.",3.5,"Syngene
3.5",India,"BENGALURU, India",1001 to 5000 employees,1994,Unknown,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1203,Applied Scientist 1,"Position Requirements:
Master's degree in Computer Science, Computer or Electrical Engineer, Mathematics, or a related field plus at least one year of experience in the job offered or related occupations of Software Engineer, Software Developer, or a related occupation. Employer will accept a Bachelor’s degree and five years of experience in the job offered or a related occupation as equivalent to the Master’s degree and one year of experience. One year of experience in the job offered or related occupation must involve designing and developing large-scale, multi-tiered, distributed software applications, tools, systems and services using Java, Object Oriented Design and Distributed Programming].

Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, Oracle/Berkeley databases, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills

Amazon Selling Partner Services team drives the Selling On Amazon business and develops solutions that enable millions of sellers around the world to sell on Amazon's Marketplaces. More than half of shipments for Amazon customers are generated from this business. The team is focused on building a technology platform that will support the explosive business growth in existing markets, streamline the business for Amazon and the Selling partners and launch business in new markets and establish a fair marketplace.

Our team is seeking engineers with broad technical skills to help us optimize how we synthesize massive amounts of data and complex business rules into mission critical financial information. As a member of this team you will employ object oriented techniques in Java, and DynamoB, PostGres and ElasticSearch skills to help us support Amazon's next generation of selling partner services. Along the way you'll gain and leverage a unique understanding of how Amazon.com works; from the numerous software systems that comprise the website's back-end, to the details of our business model, and the relationships we're establishing with an ever-growing network of selling partners who depend on Amazon.com to run their businesses.

The ideal candidate will draw upon exemplary analytical, critical thinking, and problem solving skills, and a passion for maintaining highly reliable, distributed systems which operate 24/7/365. Successful members of this team collaborate effectively with internal end-users, aggressive cross-functional software development teams, and technical support/sustaining engineering teams to solve problems and deliver successfully against high operational standards of system availability and reliability. We look for engineers who are excellent communicators, self-motivated, flexible, hardworking, and who like to have fun!

Position Responsibilities:
Participate in the design, development, implementation, testing and documentation of large-scale, multi-tiered, distributed software applications, tools, systems and services using [Java, Object Oriented Design and Distributed Programming]. Translate functional requirements into robust, scalable, supportable solutions that work well within the overall system architecture. Participate in the full development cycle, end-to-end, from design, implementation, and testing to documentation, delivery and maintenance. Produce comprehensive, usable software documentation. Evaluate and make decisions around the use of new or existing software products and tools.

Preferred Qualifications
Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1204,Senior Clinical Data Analyst,"About Novotech:

Novotech is internationally recognised as the leading independent and full-service contract research organisation (CRO) in the Asia Pacific region. We provide a wide range of clinical development services across all research phases and therapeutic areas and have been instrumental in the success of hundreds of Phase I – IV clinical trials throughout the Asia Pacific. Powered by the highest quality people, Novotech strives to set the benchmark for both business and clinical trial performance. Our people are one of our key strengths. We value our people and recognise the work they do. We are lucky to have the best people and talent from across the Asia Pacific region work together to deliver to clinical trial success for our clients. Our people and those we look to recruit have an attitude of making things happen. They are problem solvers, driven with a focus on delivering quality, accountability and a high level of performance.

Brief Position Description:

As part of Novotech’s Biometrics unit, the Senior Data Analyst (SDA) is responsible for all data analysis and business intelligence activities related to study related clinical and operational data. The SDA acts as primary point of contact for all data analysis matters to the study team and is responsible for the timely delivery of quality outputs following all applicable regulatory, compliance, best practice and operational procedures.

Minimum Qualifications & Experience:

Graduate in information science, data science or life science-related field, or similar. More than five years’ experience in a senior role related to data science, data analysis, clinical data management or clinical data programming in a pharmaceutical company, CRO or EDC software provider.

Responsibilities
The Senior Data Analyst (SDA) is responsible for providing technical, procedural (SOPs) and planning leadership across multiple projects assigned to the data analyst team members ensuring that they deliver in accordance with SOPs, programming best practices, and the timelines agreed within the Project Team.
Collaborate with cross-functional stakeholders to implement data science solutions to solve business needs using available technological solutions.
Scope data analysis effort for projects and project manage all data analysis activities across multiple projects for different study stakeholders.
Gather study requirements from data management for data review and external data reconciliation and provide guidance on appropriate outputs (dashboards, visualisations, listings, reports).
Extract, assess, integrate, transform data sources to provide data visualisation outputs for analytics.
Design and develop prototypes and final versions of data outputs (dashboards, reports, visualisations, listings) using Business intelligence tools and Data Visualisation tools.
Design and develop standard dashboards and content for different audiences.
Analyse, manipulate and understand data from multiple sources to present and create dashboards and reports to make business decisions.
Assist teams on best-practice for data visualisation dashboard development.
Educate teams on how to use all the features of applicable data visualisation platform in conjunction with data visualisation dashboards.
SME for the data visualisation development and assisting team members.
Identify and communicate project risks and maintain documentation within project files as appropriate
Represent data analysis group at internal / external meetings as appropriate.
Assess and implement new data analysis, BI and data visualisation processes and technologies.
Take an active role in the development of best practices, process improvement, quality control and governance related to all data analysis matters.
Provide training and mentoring to Data Analysis of team members in SOPs, software applications, and best practices.
Provide Subject Matter Expertise on all data analysis and visualisation related activities.
Attributes and Skills

Expert knowledge of clinical study data structures and schemas of EDC databases. Expert knowledge in data processing activities such as extracting, integrating, transforming and presenting data. Statistical Programming skills in Python, R or similar. Knowledge of SQL and EDC systems. Working knowledge of Spotfire, Power BI, Tableau or other data review and visualisation tool. Ability to gather business requirements from multiple stakeholders and clients and provide guidance on the use of appropriate data visualisations.

Experience mentoring and training others. Awareness of regulatory and compliance issues and understanding of the application of SOPs and Quality Control to daily activities. Excellent analytical, communication and problem-solving skills.

Opportunities and Benefits:

To deliver clinical trial and research excellence for our clients, our people are 'best in class'.

At Novotech, we seek and nurture people with exceptional talent. We are committed to providing our people with regular internal and external training, a competitive bonus structure and a supportive work environment. We are also focused on providing our people with a wide variety of career growth and development opportunities.

For more information about where your next career step at Novotech might take you, visit http://novotech-cro.com/novotech-careers",4.5,"Novotech
4.5",Bengaluru,"Sydney, Australia",501 to 1000 employees,1996,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
1205,Data Engineer,"Data Engineer Responsibilities:
Liaising with coworkers and clients to elucidate the requirements for each task.
Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed.
Reformulating existing frameworks to optimize their functioning.
Testing such structures to ensure that they are fit for use.
Preparing raw data for manipulation by Data Scientists.
Detecting and correcting errors in your work.
Ensuring that your work remains backed up and readily accessible to relevant coworkers.
Remaining up-to-date with industry standards and technological advancements that will improve the quality of your outputs.
Data Engineer Requirements:
Bachelor's degree in Data Engineering, Big Data Analytics, Computer Engineering, or related field.
Master's degree in a relevant field is advantageous.
Proven experience as a Data Engineer, Software Developer, or similar.
Expert proficiency in Python, C++, Java, R, and SQL.
Familiarity with Hadoop or suitable equivalent.
Excellent analytical and problem-solving skills.
A knack for independent and group work.
Scrupulous approach to duties.
Capacity to successfully manage a pipeline of duties with minimal supervision.
Job Type: Full-time

Salary: ₹360,000.00 to ₹870,000.00 /year

Experience:
total work: 2 years (Preferred)
Data Engineer: 1 year (Preferred)
Education:
Diploma (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,Futurious Technologies,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1206,Quantitative Analyst,"The successful candidate will be a highly analytical individual with hands on programming skills. The candidate will work closely with the research team and clients towards the ongoing development and integration of new investment strategies, models and tools on Axle

Location

Mumbai
Responsibilities

Perform daily/weekly/monthly tasks of performance and risk reporting
Develop and automate investment processes and strategies via VBA and Matlab
Develop tools to integrate trading decision systems with risk management systems
Ad hoc tasks (such as operational tasks, internal documentation tasks and preparation of marketing materials)
Skills/Experience

Excellent programming skills in Matlab/Excel-VBA
Thorough with financial concepts and calculations like Drawdown, VaR, Eloss etc.
Understanding of financial market products like options, futures, FX forwards etc.
Working knowledge of Bloomberg is preferred
Should be self-driven and detail oriented with an analytical mindset
Should be a proactive and quick learner; a team player showing enthusiasm and drive to accomplish results in a fast paced environment
Min. 2 years of relevant work experience
Qualifications

B.Tech/M.Tech/MBA/CFA/FRM",5.0,"B&B Analytics
5.0",Mumbai,"Zug, Switzerland",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1207,Analyst - Data Scientist,"Job Summary

Experience:
3 - 5 Years

Location:
Mumbai

Designation:
Analyst - Data Scientist

Degree:
BE-Comp/IT, BE-Other, BTech-Comp/IT, BTech-Other, ME-Comp/IT, ME-Other, MTech-Comp/IT, MTech-Other, PhD-Comp/IT, PhD-Other

Educational Level:
Graduate/Bachelors

Industrial Type:
IT-Software/Software Services

Functional Area:
IT Software - Application Programming / Maintenance

Key Skills:
Data Scientist

Job Post Date:
Thursday, March 19, 2020

Company Description

We are capability centre based in Mumbai, initially started as a back-office operational support to the UK business unit.

However, over the recent years, we have significantly increased the breadth and depth of our capabilities and offerings to keep pace with the changing needs of the Group. These include Digital & Knowledge Services, Finance and Actuarial, Information Technology (IT), Customer Service, Risk and Audit.

Our core purpose is to be a strategic partner to company, enabling growth by delivering change and driving synergies through a highly capable and agile workforce.

With our diversified service offerings we provide our people with exciting opportunities to grow personally and professionally.

Company is a leading savings and investments business serving around 5.5 million retail customers and more than 800 institutional clients.

It-s innovative asset management and customer solutions are supported by extensive investment capabilities, an international distribution network and two strong brands.

Job Description

3 – 5 yrs experience as Data Scientist
Should have at-least 1 end-to-end ML project experience
Very high proficiency in R or Python
Excellent in forecasting methods like simple exponential smoothing, multiplicative seasonal indexes, simple and weighted moving averages and time series forecasting methods
Exposure to with advanced deep learning techniques such as LSTM. CNN, Dense neural networks as well as neural networks design and implementation through tools like tensorflow, keras, pytorch, deepai or equivalent.
Good SQL experience",3.8,"Sampoorna Computer People
3.8",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
1208,Data Lake Developer,"For Us, It's A Mission

At Mylan, we mean it when we say we work every day to provide access to high quality medicines to the world's 7 billion people. If you are unconventional, relentless and passionate. If you believe in doing what's right, not what's easy. If you are a doer and have a passion for serving others, we want to talk to you.

Make a Difference

At Mylan, each person has the ability to make a difference. From the providers who sell and market our products, to the producers who develop and manufacture them and finally to our business partners who support the providers and producers, we all have a mission critical role. Here's how this role will help:

ESSENTIAL DUTIES AND RESPONSIBILITIES
To perform this job successfully, an individual must satisfactorily perform each essential duty. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential duties.
1. Create and maintain optimal data pipeline architecture on Azure platform.
2. Develop batch processing solutions by using Data Factory and Azure Databricks.
3. Delivering a Data Warehouse in the Azure Cloud.
4. Design relational and non-relational data stores on Azure.
5. Identify, design, and implement internal process improvements : automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc..
6. Developing Big Data Solutions with Azure Machine Learning.
7. Strong interaction with business departments to provide consultative support for digitization efforts, as well as close collaboration with the Business Technology management, focused on future innovation topics.
8. Participate and lead in design sessions, demos and prototype sessions, testing and training workshops with business users and other IT colleagues.
9. Design & Build for any API Development or SQL DB development.
10. Providing service management, orchestration, monitoring and management requirements of Azure cloud platform.
11. Create data tools / products for analytics and data scientist team members that assist them in building and innovative solutions that drive tangible business value.
12. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
13. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
14. Design security for source data access. Chose the appropriate authentication mechanism, (ie Azure Active Directory (Azure AD), etc).
15. Design for real-time processing by using Stream Analytics and Azure Databricks.

Make Our Values Your Values

Mylan hires only the best. People who thrive in a culture of innovation and empowerment. People who are active learners and have a positive attitude. People who are leaders and know that by working together we can run faster, reach higher and achieve more. By doing so, we will continue to set new standards in health care. Here are the minimum qualifications and essential functions for this position:

QUALIFICATIONS

The qualifications listed below are representative of the minimum knowledge, skill, and/or ability required.

SKILLS AND ABILITIES

1. 10 years of experience in Microsoft technologies including SQL.

2. At least 5 years as a Sr Developer with at least 3 years hands on experience as Azure Data Engineer building large scale Azure data solutions.

3. At least 5 years of experience in Azure based data solutions.

4. At least 3 years of experience on working with large projects including the most recent project in the cloud (Azure) or on prem with a focus on Azure Data services.

5. At least 5 years of Hands-on administration, configuration management, monitoring, performance tuning of Hadoop/Distributed platforms.

6. At least 5 years of demonstrated experience at least in the most recent 2 years of designing and delivering solutions using Cortana Intelligence suite of analytics services part of Microsoft Azure including Azure Machine Learning Studio, HDInsight, Polybase, Azure Data Lake Analytics, Azure Data Warehouse, Streaming Analytics, Data Catalog, R/R Studio

7. Experience in designing and building logics required for optimal extraction, transformation, and loading of data from a wide variety of data sources

8. Experience within Data Security design, including but not limited to:

a. Choosing the appropriate authentication mechanism, such as Azure Active Directory (Azure AD)

b. Defining strategies for data encryption for data at rest and in transit

9. Experience partnering with Business Analysts and Data Scientists to enable effective and efficient data preparation and delivery

10. Experienced in vendor management and working with 3rd parties onshore & offshore.

11. Experience working in a global team.

12. Experience working in an Analytics / Big Data solutions on MS Azure Cloud

13. Experience with code management tools, automated testing

14. Experience creating and maintaining optimal data pipeline architecture on Azure platform

15. Experience developing batch and real-time processing solutions by using Data Factory and Azure Databricks

16. Familiar with AGILE and Azure DevOps methodology

17. Hands on PoC capabilities are needed to prove a particular architecture concept

18. Azure Native Services experience across Data Fabric and Service Fabric

19. Experience in Application modernization from legacy on-premise data architecture platform technology stack to modernized Azure Cloud base Architecture.

20. Experience with Git, NoSQL Data Solutions, Microsoft Azure, HD Insights, Azure ML, DataBricks ML Flow, R or Python.

21. Must have excellent communication skills.

EDUCATION/EXPERIENCE (Note: Please select one)

Minimum of a Bachelor's degree in Computer Science and Engineering is preferred with minimum 10 years of experience. However, a combination of experience and/or education will be taken into consideration

Why Mylan?

If you want to be part of a global health care company that is making a difference and changing lives, Mylan may be the place for you. With a workforce of more than 35,000 worldwide, we can make a difference. We encourage you to visit Mylan.com to learn more about our unconventional culture, our approach to doing business and how we plan to set new standards in health care.

Mylan offers competitive salary, excellent benefits and an environment conducive to professional growth and advancement. All qualified applicants will receive consideration for employment without regard to their disability or protected veteran status. Mylan is an Equal Opportunity Employer, Minorities/Female/Disabled/Veteran.",3.8,"Mylan Inc.
3.8",Bengaluru,"Hatfield, United Kingdom",10000+ employees,1961,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1209,Off Campus Recruitment - Quantitative Researcher,"Description:
Graviton is a privately funded quantitative trading firm striving for excellence in financial markets' research. We are seeking fresh talent from the top IIT's to join us as Quantitative Researchers for our team in Gurgaon.If you are a student graduating in 2020 from Computer Science , Electrical or Maths Stats Computing streams with a greater than 8 CGPA please apply here.

This role is open to students from campuses that we could not visit this year. Please check your individual placement policy restrictions before applying.

Graviton trades across a multitude of asset classes and trading venues using a gamut of concepts and techniques ranging from time series analysis, filtering, classification, stochastic models, pattern recognition to statistical inference analysing terabytes of data to come up with ideas to identify pricing anomalies in financial markets.

As a Quantitative researcher your responsibilities will include

Develop new or improve existing trading models using in-house platforms

Use advanced mathematical techniques to model and predict market movements

Analyse large financial datasets to identify trading opportunities

Provide real time analytical support to experienced traders

Requirements :
Possess a degree in a highly analytical field, such as Engineering, Mathematics, Computer Science from IITs schools

Quantitative bend of mind

A working knowledge of Linux/Unix

Programming experience, preferably in C++ or C

Strong interest in learning about financial markets.

Have a strong work ethic

Hard Working

Benefits:
Our open and casual work culture gives you the space to innovate and deliver. Our cubicle free offices , disdain for bureaucracy and insistence to hire the very best creates a melting pot for great ideas and technology innovations. Everyone on the team is approachable, there is nothing better than working with friends!

Our perks have you covered.

Competitive compensation

6 weeks of paid vacation

Monthly after work parties

Catered breakfast and lunch

Fully stocked kitchen

Gym membership

International team outing",5.0,"Graviton Research Capital LLP
5.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2014,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1210,Data Engineer,"Zauba Technologies is a startup based in Bangalore. Zauba's services are used by leading companies in India. Zauba is powered by a young and passionate team. We are looking for individuals who would like to be a part of our founding team.

As a Data Engineer and as a part of founding team, you will be expected to visualise and develop disruptive data products. Eventually you would be responsible for entire project lifecycle of products you would visualize. Your rewards will be directly proportional to the value you generate.

Job Responsibilities
Design and development of robust, scalable and highly efficient data engineering solutions for structured and unstructured data (Including gathering and processing raw data at scale, writing scripts, web scraping, calling APIs, writing SQL queries, etc.)
Develop processes for text mining and extraction of information from unstructured data
Design, architect and develop efficient data pipelines around the data collected
Take ownership of existing web product and applications
Design and implement data models that scale across the enterprise
Take ownership of existing data workflows and processes
Enhance scalability, performance, and stability of existing infrastructure
Work closely with other team members to integrate your innovations and algorithms into our production systems

Essentials
Java/Python - Intermediate to advanced level
SQL - Advanced
MySQL Intermediate to advanced level
Regex - Basic to intermediate level
Linux Basic to intermediate level

Good to have
Hadoop/Spark
R
MongoDB

Must have qualities
Skills to learn new skills quickly
Desire to create disruptive products and services
Passion - not just to work in startups but to take them to next level
Above average programming aptitude
Be passionate about producing high quality engineering deliverables
Be productive working independently or collaboratively
Have an eye for building efficient processes
Be self motivated
Proactively take ownership

Interested?

Send your resume to hr@zaubacorp.com",3.8,"Zauba Corp
3.8",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 million (INR),-1
1211,Quantitative Research,"We are looking for highly trained professionals who are interested in applying advanced mathematical quantitative methods to the modeling of global financial markets. You would be joining a group made up of highly proficient individuals from various scientific disciplines. We have a spectrum of opportunities for individuals with the right scientific skills. Experience in finance is not required.

The ideal research candidate will have:
A Ph.D. in Computer Science, Mathematics, Physics, Statistics, or a related technical discipline.

A demonstrated capacity to do first-class research.

Computer programming skills.

An intense interest in applying quantitative analysis to solve difficult problems.

Send us a copy of your resume to
careers@dolatcapital.com

For internship opportunities, please send us a copy of your resume to
careers@dolatcapital.com",4.0,"Dolat Capital
4.0",Mumbai,"Mumbai, India",51 to 200 employees,1970,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1212,Data Engineer,"Bachelor’s degree in Computer Science or related field
5+ years relevant experience
5+ years experience with SQL, SQL Tuning, Oracle, OLAP, Big Data Technologies
5+ years experience developing end-to-end Business Intelligence solutions: data modeling, ETL and reporting
Experience with Java and experience with scripting languages like Perl, Python, Unix shell scripts,VBA and MS Excel
Proficiency with Linux and systems administration
Proven ability at looking at solutions in unconventional ways. Sees opportunities to innovate and can lead the way.
Top notch communication (verbal and written) and interpersonal skills to convey key insights from complex analysis in summarized business terms and an ability to effectively communicate with technical teams.
Ability to work with shifting deadlines in a fast paced environment.
Operations Finance Technology team, responsible for building technical solutions for multi-billion WW Operational Cost analytic including Inbound cost (Receiving / PO), variable Cost, fixed cost, outbound (Customer Shipments / Transportation), and Customer Service, is looking for a Data Engineer.

As a data engineer, you will get the exciting opportunity to work on very large data sets in one of the world's largest and most complex data warehouse environments. You will work closely with the business teams in analysis on various cost savings initiatives, many non-standard and unique business problems and use creative-problem solving to deliver actionable output.
You will be responsible for designing and implementing an analytical environment using third-party and in-house reporting tools, modeling metadata, building reports and dashboards. You will have an opportunity to work with leading edge technologies like Redshift, Hadoop/Hive/Pig. You will be writing scalable queries and tuning performance on queries running over billion of rows of data.

You should be analytical, have an extremely high level of customer focus and a passion for process improvement. You should be motivated self-starter that can work independently in a fast paced, ambiguous environment. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions.
Bachelors in Computer Science or related field
Practical Knowledge of Linux or Unix shell scripting
Experience in working with business customers to drive requirements analysis
Exposure to large databases, BI applications, data quality and performance tuning
Excellent written and spoken communication skills
Experience with Hadoop-based technologies such as HBase, Pig, Hive and Spark
Strong proven ability in building high-performance, highly available and scalable data solutions using Oracle and/or Hadoop-based technologies
Knowledge of data warehousing concepts.
Strong sense of ownership, urgency, and drive
Strong troubleshooting and problem solving skills
Experience with Amazon Web Services",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1213,DATA ANALYST,"posted by Mahima Gaur

2 - 5 years Delhi

Job Description
Experience in data processing
Experience in data cleaning and data tabulation activities
Strong analytical, communication and team management skills
Strong understanding of data management using SPSS and research techniques
Competency in a Tabulation software (decipher / wincross / quantum etc), Excel, Powerpoint
Ability to summarize findings, draw conclusions, and put together a presentation using Powerpoint
Role Category : Data Analyst

Employment Type : Permanent Job, Full Time",4.9,"Knowledge Excel Services.
4.9",New Delhi,"New Delhi, India",1 to 50 employees,2007,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
1214,Data Engineer,"Key skills : Python , Spark , SQL , Pyspark • AWS platform used for the work • Strong experience in SQL is mandatory • Good familiarity of AWS landscape • Good experience in collecting business requirements & design them as per requirement from customer • Should able to work independently & interact business users & technical stakeholders • Strong communication skills both oral & written. • Should work as an individual resources",3.5,"Larsen & Toubro Infotech Limited
3.5",India,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1215,Big Data Engineer,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
1216,Client Data Analyst,"At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.
What is the Client Data Analyst – Client Analytics group responsible for?
This team manages business data to ensure accurate, timely, consistent and compliant data. Their contributions deliver quality data that is easily accessible and can be trusted. Key downstream capabilities such as reporting and analytics depend on this as well as operational data access on various systems. The Data Management Team is a support function that acts as an advocate and a point of contact for Sales and Marketing data.

What are the ongoing responsibilities of an Client Data Analyst ?
Understand the data flow, key consumption and production of data as well as context within the enterprise:
Build positive relationships with teams, especially the key data consumers and analytics. Take the time to increase knowledge of how they run their business and incorporate sales data into daily work
Connect regularly with each sales office to understand current issues and challenges. Probe the business and validate against other sales offices to understand the scope and priority of the issue
Make recommendations on how data unifications and flow can be used to improve business tasks. Liaise business partners to deliver solutions (reports, processes, technology) that add value.

Provide data management subject matter expertise. Appreciate the connection and data flow between applications and other corporate systems. Be able to clearly articulate the data needs and move initiatives forward by collaborating with business partners:
Actively participate in meetings with business partners to ensure that priorities are clearly understood, information is regularly shared and that key participants are “kept in the loop”
Provide context and background on issues. Collaborate on ideas for progressing initiatives. Ensure appropriate resources are involved to take initiatives forward
Provide insights and expertise to scope statements and requirements documentation
Actively consult or participate in the user acceptance testing process (test cases, documentation, testing execution, etc.)
Ensure business needs remain aligned with overall corporate initiatives and deliver the benefits as originally intended

Monitor the integrity of data and usefulness of reports. Ensure the information available within systems is accurate and up-to-date. Proactively seek data cleansing opportunities and evolve data to better support. Document and maintain ongoing processes for reporting and data clean-up:
Partner with all key data consumers to gain a solid understanding of usage and challenges around data. Establish processes for prioritization of enhancements, especially with the analytics groups
Provide 1st level support for data issues and data maintenance for owned data
Verify and execute data loads into our internal sales systems and ensure any upstream systems accurately receive their data

Increase awareness and promote data management capabilities. Share best practices and provide coaching to local offices on how to access and incorporate output into sales tasks. Encourage IAS leaders to leverage data to make more informed, strategic decisions:
Clearly articulate the goals and core services of the data management team. Proactively promote this information within IAS and ensure business partners understand the data management role within the organization
Share best practices and provides guidance on data capabilities. Reinforces ownership and accountability for data accuracy
Seek opportunities to share the benefits of leveraging sales data to make more informed business decisions

What ideal qualifications, skills & experience would help someone to be Successful?

Knowledge, Education And Experience:
Four year bachelor’s degree required (majors of preference include: business, computer science, mathematics) Advanced degree a plus
Understanding of the Franklin Templeton business model, how FT makes money, the sales process, how technology fits in with the business, etc. Knowledge of the GAS (Global Advisory Services) structure
Experience working through multiple business fiscal cycles; exposure and/or direct experience with project management and/or sales-related-capacity required
Prior work experience related to analytics, sales, marketing and/or international a must. Level will not be granted based on years of experience but will be determined by the employee’s ability to meet each job activity as outlined the ‘typical/expected focus by level
Skills And Abilities:
Ability to communicate effectively with all levels of management; ability to tailor communication style based on audience; ability to get others to want to collaborate with you; strong facilitation skills
Excellent writing skills (for presentations, documentation, etc.)
Working knowledge of the CRM, MDM, Excel, SQL, Power BI, Tableau, Business Objects, and Microsoft Products (PPT, Power Apps, Doc, Visio)
Ability to absorb and interpret large quantities of data; apply trend analysis and knowledge of the business to develop a meaningful and digestible summary with the appropriate level of detail
Ability to take a larger problem and break down the individual components; identify how to go about solving the problem and who to involve in the process
Ability to present recommended solutions to a variety of issues and problems (solutions that are consistent with organization objectives)
Must be extremely detail-oriented (managing lists, tasks/to-dos, etc.) good with follow through on own items; good with following up with others on outstanding item

What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.

Highlights of our benefits include:

Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.",3.8,"Franklin Templeton Investments
3.8",Hyderabad,"San Mateo, CA",5001 to 10000 employees,1947,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Fidelity Investments, Vanguard"
1217,Data Analyst,"Roles and Responsibilities:
Extracting, transforming and inputting data sets from various resources. Creating predictive models, translating non-technical aspects into quantifiable tasks. Analysis and representation of output data, highlight and explain trends and patterns, error elimination, using advanced statistical methods (regression, probability distribution, clusters etc.) to provide accurate results.
Data collection, Data Mining, Report generation, Problem identification and solution formulation Market analysis and establishing trends, Strategy development and implementation

Skills:
Extremely good analytical skills.
Good working knowledge of all MS-Office products, especially Advance Excel, Word, PowerPoint, MS-access.
Statistical tools and methods.

Interested candidates can send the updated resume on satish.mehra@exelaonline.com or call on 7722028636
00-7.00 Years",2.6,"Exela Technologies
2.6",Pune,"Irving, TX",10000+ employees,2017,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"SourceHOV, BancTec, Transcentra"
1218,Data Modeler,"• Minimum 5-8 years of working experience as Data modeler.
• Data modelling experience in designing.
• Minimum 2-3 years real time experience in Erwin tool is mandatory.
• Experience in normalized modeling techniques.
• Experience in designing the Start schema.
• Experience working in ORACLE.
• Experience with database design, capacity planning, performance tuning and query optimization.
• Experience in working with Bank or Banking and Finance or Financial domain.
• Excellent communication skills with leadership quality.

Job Segment:
Database, Oracle, ERP, Technology",3.5,"LTI
3.5",Mumbai,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1219,Machine Learning Engineer,"Looking for Data Scientists with Python/R Programming skills.
Specific experience in AI areas like Statistical Machine learning / Deep learning / Natural Language Processing (NLP)/ Operations Research (Optimization) will be an advantage.Individual in this role is expected to work with multiple stakeholders and teams

Qualifications and Requirements:-
Previous working experience as a Machine Learning/ Data Scientist for 2 years
MA in Computer Science or similar relevant field
Hands on experience with MALLET
In depth knowledge of Apache Tomcat/Open Source
Excellent project and time management skills
Attention to detail
Outstanding problem solving and analytical skills",-1,Tekolutions.ai,India,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1220,Data Science Internship,"About the company:
SkillBit is a leading staffing and recruitment company engaged in talent searching assignments for skilled and talented candidates for the industry.

About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Working on data science algorithms and AI concepts 2. Using Python or R for web scraping 3. Building AI models using Python, machine learning, and deep learning algorithms 4. Processing of unstructured/structured data

Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 6th Jun'20 and 11th Jul'20
are available for duration of 1 month
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply

Number of internships/jobs available: 3

Categories: Data Science",-1,SkillBit,Pune,-1,-1,-1,-1,-1,-1,-1,-1
1221,Data Engineer,"As a data engineer at TEAL, you'll be taking the plunge into a rich data lake that includes everything from satellite data to legal court orders. You'll be hustling and getting your hands dirty with every part of the data pipeline always having an implicit appreciation for how all of this data will ultimately power a revolutionary real estate risk platform.

Your day-to-day will include either all or some of the following:

Constantly scoping out new data sources to complement existing ones
Creating and maintaining distributed web scrapers using Python, RabbitMQ and other technologies
Architecting and managing data pipelines where data flows into multiple end-points including, but not limited to, Postgres, MongoDB and Apache Solr
Documenting workflows and constantly iterating to create better data infrastructure.

We'd love it if you:
Are proficient in Python or any other object-oriented language
Have worked with large (millions to hundreds of millions of rows in a SQL database) interdisciplinary datasets
Have scraped difficult websites and have some experience working with various data APIs
Are patient and methodical with unstructured and messy data
Are always hungry to learn newer and better technologies to make the data ecosystem faster, smoother and less silo-ed

Extra brownie points if you:
Have some experience working with large-scale search indexing
Have performed geospatial analyses in some capacity
Have created and managed data lakes in the cloud
Culture

To explore our culture and the values we embody click here

Testimonials
Testimonial

My experience at TEAL surpassed all my expectations from the get-go. I was asked to help solve one of the most daunting problems in the Indian real estate market. Every day while working on a subset of the problem, the ideas that I brought to the table were shaped into cohesive solutions by a collaborative team effort. At TEAL I was exposed to the most cutting edge technologies such as Cloud Computing, Big Data, ML and Data Science. The growth opportunities at TEAL are tremendous, If you are innovative and can demonstrate the will to realize your ideas, TEAL is an amazing organization to work for.
Gyan Vardhan, Data Science Intern
I had interned as a Data Scientist at Terra Economics and Analytics Lab during its early days, it was a rich learning experience working with a multi-disciplinary team who are extremely passionate about building a decision support platform for the insanely complicated realty market in India. It was exciting and challenging to work on mining huge volumes of property records; extracting patterns from the data, building data pipelines and brainstorming on building the core system. TEAL offers a very healthy work environment coupled with insanely talented people working together in an exciting setting.
Naga Anjaneyulu, Data Science Intern
I worked as a full-time Data science intern at TEAL. During this period, I got an opportunity to leverage my skillsets while also learning new technologies, working on tasks assigned to me. The company operates on the latest tech-stacks and gives opportunities to learn as much as you want. The work environment is challenging, the team at TEAL is super supportive and new ideas are always welcome. It has all the good perks of a startup; creativity and innovation, casual work atmosphere and a collaborative approach to solving problems. Personally, I loved working there, my experience was fantastic!
Archana Parmar, Data Science Intern
As a second-year college student, I was looking for an internship that would allow me to delve deeper into research and work with big data, TEAL gave me the perfect opportunity to do so, enabling me to develop proficiency in research and analysis. As a research analyst intern, I collated and cleaned data and helped in the preparation of reports and presentations, and I had members helping me at every stage of this process. This collaborative environment allowed me to cultivate my skills and also learn from my peers. The holy trinity of Rohan, Kshitij, and Shreyas served as not only excellent mentors and bosses but also as friends, helping me at every stage and giving us all food and ice cream to keep us going!
Arush Mehra, Research Intern
Internships are a crucial part of one’s early career. The internship experience at TEAL was a thrilling rollercoaster ride to say the least! It was more than implementing a standard model or building an already though out concept into reality. It was about finding the solution to a unique and open-ended problem.It was exciting to work on addressing a problem with far -reaching real world applications.Moreover, the work environment had the perfect balance of casual yet professional which kept you focused and stress free at the same time. Out of every 100 startups in India only 2 of them succeed, but there are very few like TEAL India which are bound to make it big at such an early stage.
Divyanshu Agarwal, NLP Intern",4.7,"Terra Economics & Analytics Lab (TEAL)
4.7",New Delhi,"Bengaluru, India",1 to 50 employees,2018,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
1222,Senior Consultant - ModellingOps Data Engineer,"Job Title: Senior Consultant - ModellingOps Data Engineer
Location: TRIL GTC
GCL: D1

JOB DESCRIPTION:

AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. The Science & Enabling Units IT is AZs global IT capability function supporting key business areas operating out of sites across the US, UK, Sweden, India & Mexico.

We are looking for AI Ops consultant who will leverage tools & technology best practices to improve delivery performance & data engineering capabilities in the D&A space.

ROLES & RESPONSIBILITIES:

7-10 years of experience in IT Operations involving Data Science, Artificial Intelligence-Machine Learning and Predictive Analytics. Experience in architecting and implementation of end-to-end AIOPs solutions through ELK stack, Splunk. Experience in applying statistical methods, analysis, pattern recognition and modeling on IT Operational data using ELK machine learning. Experience in extracting meaning full data from incoming data streams from different sources through RegEx, Grok etc. Hands-on experience in applying machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc in the IT Operation domain. Experience with machine learning and statistical programming languages - Python, R etc. Experience in assessing the existing IT environment and providing recommendations to reduce the critical applications impacting incidents. Experience in exploring and identifying areas where manual tasks can be automated in IT environment. Experience with various Enterprise IT monitoring solutions including Infrastructure monitoring, Application Performance Monitoring, Network Monitoring, Cloud monitoring etc. Experience in IT Service Management including Service Desk, Incident Management, Change Management, CMDB etc. Excellent knowledge on various IT infrastructure components that includes Server Infrastructure, middle ware, database and application architectures and Cloud Components. Experience/knowledge on Infra monitoring tools - NOI, Zabbix, AppDynamics, Datadog, SCOM, SolarWinds etc. and Service Management tools -IBM Control Desk, BMC Remedy, ServiceNow etc. Experience/Knowledge on BI tools Knowledge on distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc. Knowledge on other programming languages/scripting: Python, Java, JavaScript, etc. ( Added Advantage ) Good analytical skills, strong communication skills are must. Client facing experience is an added advantage. Excellent experience in understanding the problem statement, architect and designing the solution

MANDATORY SKILLS:
Significant experience with AWS cloud environments, working knowledge of Google and Azure platforms. Knowledge of Kubernetes, S3, EC2, Sagemaker, Athena, RDS and Glue is essential.
Experience provisioning computational resources in a variety of Cloud environments using Infrastructure as Code.
Experience with best practice of data transport and storage within cloud system.
Experience building large scale data processing pipelines. e. g. Spark and SQL.
Experience with containers and microservice architectures e.g. Kubernetes, Docker and serverless approaches.
Excellent working knowledge in DevOps, using continuous integration and continuous development.
Use of Data Science modelling tools e.g. R, Python, SAS and Data Science notebooks (e.g. Jupyter).
Good written and verbal skills, fluent English
DESIERED SKILLS:
Agile practices, especially being a SCRUM Master
EDUCATIONAL BACKGROUND: B.E/B.Tech/MCA

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",3.9,"AstraZeneca
3.9",Chennai,"Cambridge, United Kingdom",10000+ employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Roche, GlaxoSmithKline, Novartis"
1223,DATA ENGINEER,"JOB DESCRIPTION
As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements, and also research new uses for data acquisition. You should also know the ins and outs of the industry such as data mining practices, algorithms, and how data can be used.

DESIRED CANDIDATE PROFILE
An ideal candidate must possess prior experience leading a project.

Candidates must have:
> Experience in Hive, Spark, Scala, AWS DynamoDB, HBase, AWS Glue, Talend, Kafka, Snowflake ETL
> Strong experience in a BI/Data Warehouse environment with involvement in design, development, implementation, troubleshooting and support of ETL process using ETL tool.
> Experience in developing Data Marts, Data warehousing and Operational Data Store (ODS) on any of the databases or Hadoop environments.
> Experience in database like MS SQL, MySQL, Oracle, PostgreSQL
> Good to have programming experience in writing Complex Stored Procedures, Queries, Views, User Defined Functions, Cursors and Common Table Expressions using SQL or T-SQL.
> Experience in Performance Tuning and Query Optimization by Indexing, Partitioning and De-normalization.
> Experience in Developing a framework for ingesting data into Data lake
> Good database knowledge, analytical thinking
> Design, construct, install, test and maintain data management systems.
> Build high-performance algorithms, predictive models, and prototypes.
> Develop set processes for data mining, data modeling, and data production.
> Experience with cloud services: AWS (EC2, EMR, S3, Athena) and scripting languages like Python, /PySpark/R/SAS
> Install/update disaster recovery procedures.
> Experience in Agile Application Development & Scrum methodologies is preferred
> Ability to supervise and mentor junior developers on the team.
> Must be self-motivated and work well pulling people together in addition to being able to pull people together technically
> Demonstrated proficiency of troubleshooting techniques and detail-oriented problem diagnosis
> Ability to handle responsibility, is self-directed, with strong organizational and documentation skills
> Ability to work independently and efficiently under aggressive deadlines to meet project commitments
> Excellent verbal and written communication skills

EDUCATION
UG - B.Tech/B.E. - Computers, Electronics/Telecommunication, Diploma - Computers, Electronics/Telecommunication, B.Sc - Computers, BCA - Computers) AND (PG - M.Tech - Computers, Electronics/Telecommunication, MCA - Computers, M.Sc - Electronics, Computers) AND ( Doctorate - Any Doctorate - Any Specialization, Doctorate Not Required).

OTHER DETAILS
Number of vacancies: 4
Experience: 3 years
Location: Cochin

If you have a passion towards technology and coding, then we have the right job for you. Kindly forward your resumes to
Email: jobs@mjsofttech.com
Phone: 0484-2421245 / 928 720 7160",4.0,"MJ Softtech
4.0",Kochi,"Cochin, India",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
1224,Data Engineer,"Education/ Experience and Skill Requirement
4+ years of relevant experience in
Experience working with both relational and NoSQL databases.
Strong coding skills; Python (preferred) /R/Java/Scala
Experience in developing Data warehousing technologies Experience with AWS or equivalent cloud services preferred
Experience in BigData technologies (Hadoop, HDFS, MapReduce, Spark, Hive, HBase etc) will be valuable
Knowledge of Machine Learning a big plus (Random Forest, Decision Trees, SVM, NLP, Gradient Boosting, Supervised/Unsupervised Learning, Clustering, classification and regression modeling).
Responsibilities
Proficiency with several years’ experience in more than one of Python, R, Java, Scala, or robust Linux shell scripting
Implementation experience with data warehouse architecture & design, ETL design/development, and Analytics
Knowledge of general cloud architecture and cloud strategies especially around AWS services and concepts such as S3 object stores, RDS databases, EC2, Glacier, Lambda, IAM, enterprise security, data security, DevOps, replication and disaster recovery
Well versed with data mining & exploration, NLP and visualization
Understanding of data modeling, data integration, and data representation (metadata, OWL, ontologies)
Developing data marts and data management using SQL
Creating powerful visual outcomes
Independently manage daily client communication, especially over calls
Manage client deadlines, ensure quality of the deliverables, attention to detail
Experience/understanding of corporate finance data from company filings is desirable",3.6,"Copal Partners
3.6",Bengaluru,"New York, NY",10000+ employees,1900,Company - Public,Financial Analytics & Research,Finance,₹100 to ₹500 billion (INR),-1
1225,Data Engineer,"Job Description / Responsibilities
Build workflows to ensure data extraction quality and storage into our backend data store
Architect, build and train ML/AI models that can predict outcomes and report on anomalies.
Design data pipelines to perform ETL on content/data from multiple types of source systems.
Create data analytics views using RDBMS/Key-Value stores, on private and public/cloud
Create software that is well tested, maintainable, extensible and scales out with large data

Minimum Qualifications:
2+ years of software development with Python
2+ years of SQL (MySQL/Postgres) and Key-Value databases
1+ years of experience with scikit
2+ years of experience in data extraction, data transformation using custom Python/Java
Experience working with MapReduce/Hadoop/kafka/Elastic stack
Experience with Node backend and React/Redux
Experience working with git/mercurial, Amazon/Google cloud, Linux/LAMP stack
Experience in testing or test driven development
Experience with Data science and Machine Learning algorithm development

Location:
Hyderabad/Bangalore

Package:
Highly competitive to match experience and capability",3.7,"TVS
3.7",Bengaluru,"Chennai, India",5001 to 10000 employees,-1,Company - Private,Accounting,Accounting & Legal,₹100 to ₹500 billion (INR),-1
1226,Data Engineer,"Permanent position with US based client of iFlex.
Work Location: Bangalore
Experience Level: 2+ Years

Role:
As part of our global team you will work on the data platform reporting to the Data Engineering Lead. Your role includes specification, development, test and rollout of features on our data platform. You are expected to contribute to the vision, understand our product roadmap, integrate business value andclient experience and contribute to build an engineering culture within the team. This initiative is of critical important to the success of the organization and our roadmap, for instance, services like liquidity analytics, billing, client onboarding, reporting and others will rely on the data platform. Accurate, granular, complete and timely data will be our key differentiating factor and competitive advantage in the market place. We expect the successful candidate to deliver high quality software and to be passionate about data engineering..

Responsibility / Qualification:
Managing multiple tasks and use sound judgment when prioritizing.
Collaborating with global cross functional team in building customer-centric products.
Analyzing existing software implementations to identify areas of improvement and provide deadline estimates for implementing new features.
Updating and maintain documentation for team processes, best practices and software runbooks.
Establishing trusted partnerships with peers, product heads, and executive level stakeholders.
We are looking for someone who is passionate about technology and engineering.
Exceptional analytical skills and ability to apply knowledge and experience in decision-making to arrive at creative and commercial solutions.
Ability to leverage technology to deliver business value.
You are independent and comfortable in a fast paced, ambiguous and often multi-directional work environment.

Preferred Qualifications:
B.S. or higher in Computer Science.
Minimum 2 years of relevant professional experience using a modern programming language (preferably Java/Scala).
Experience leveraging test driven development technics.
Comfort with Agile operating models.
Team oriented.
Strong interpersonal and communication skills.
Energetic, self-directed, and self-motivated.
Experience with microservice architecture.
Experience with Kafka, MongoDB, Hadoop, Cassandra.
Experience with AWS.
Experience in Financial Services or Fintech.",-1,IFLEX,Bengaluru,"Moscow, Russia",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1227,CIEL/SEL/1941: Sr data scientist,"Mandatory skills required -
Databases (SQL, Oracle, Any RDBMS) - Should have working knowledge of atleast one database
PL/SQL Programming Languages
R, Python (Any One)
Inferential Statistics - Hypothesis, p-value, R2, RMSE, MAPE etc
Exploratory Data Analysis
Machine Learning Algorithms - Should have in-depth knowledge and implementation of atleast one algorithm

Responsibilities
: Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the why & how of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions

Education
Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics
Experience
Minimum years of related experience required: 3 years
Preferred years of experience: 5 years
Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desirable.

Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
1228,Data Engineer,Data Engineer,3.6,"Bookmyshow
3.6",Mumbai,"Mumbai, India",1001 to 5000 employees,2007,Company - Private,Ticket Sales,"Arts, Entertainment & Recreation",Unknown / Non-Applicable,-1
1229,Data Analyst,"Required Skills & Experience

We are looking for a Data Analyst Executive
Eligible Qualifications : B. Tech, BCA, M.Tech, MCA
Experience : 3-5 years, fresher’s can also be considered
Location of Job : Gurgaon/Connaught Place, New Delhi
Technicals Skills

Following technical skills are pre-requisite:
Well versed with Software development methodologies, such as SDLC (Software Development Life Cycle), DDLC (Document Development Life Cycle).
Database schema design and implementation
Should have worked in either of technologies Sql Query/ Tableau/ Excel (Macros)/ Access (Query) writing for data analytics.
For planning and coordinating activities, organizations remain in invariant communication with one another and the data transfer has to be performed efficiently and smoothly as possible.
He/ She should manage the execution of the technologies, help the businesses in utilizing the systems, and should be well versed with the basics of computer systems such as Networking, Installation of necessary software and hardware.
Ability to determine the interrelationships between solutions and requirements.
Ability to think analytically and should be a problem solver and logic building should be very strong.
Good interpersonal skills to form effective working relationships with people at all levels.
Excellent communication and presentation skills and strong written & oral English skills.
To know more about us visit us www.sspl.net.in or write to us at admin@sspl.net.in",-1,Substratal Solutions,Connaught Place,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1230,Artificial Intelligence Scientists,"Experience 2- 4 Years
Salary 4 LPA - 6 LPA
Job Location Chennai

Industry:
IT-Software / Software Services

Keywords:
Artificial Intelligence

About Job:
Must have Excellent knowledge in AI / Machine learning (Mandatory).
Machine learning frameworks like keras, tensor flow etc.
And also other big data tools like Hadoop etc, Must know R and python.
Good understanding in SDLC & Business cycle.",4.0,"Careerera
4.0",Chennai,"Wayland, MA",501 to 1000 employees,-1,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
1231,Senior Data Engineer,"About Us

upGrad is an online education platform building the careers of tomorrow by offering the most industry-relevant programs in an immersive learning experience. Our mission is to create a new digital-first learning experience to deliver tangible career impact to individuals at scale. upGrad currently offers programs in Data Science, Machine Learning, Product Management, Digital Marketing, and Entrepreneurship, etc. upGrad is looking for people passionate about management and education to help design learning programs for working professionals to stay sharp and stay relevant and help build the careers of tomorrow.
upGrad was awarded the Best Tech for Education by IAMAI for 2018-19
upGrad was also ranked as one of the LinkedIn Top Startups 2018: The 25 most sought-after startups in India
upGrad was earlier selected as one of the top ten most innovative companies in India by FastCompany.
We were also covered by the Financial Times along with other disruptors in Ed-Tech
upGrad is the official education partner for Government of India - Startup India program
Our program with IIIT B has been ranked #1 program in the country in the domain of Artificial Intelligence and Machine Learning
About the Role

We are looking for a Data Engineer to help us scale the existing data infrastructure and in parallel work on building the next generation data platform for analytics at scale, machine learning infrastructure and data validation systems.
In this role, you will be responsible for communicating effectively with data consumers to fine-tune data platform systems (existing or new), taking ownership and delivering high performing systems and data pipelines, and helping the team scale them up, to endure ever growing traffic.
This is a growing team, which makes for many opportunities to be involved directly with product management, development, sales, and support teams. Everybody on the team is passionate about their work and we’re looking for similarly motivated “get stuff done” kind of people to join us!

Roles & Responsibilities
Engineer data pipelines (batch and real-time ) that aids in creation of data-driven products for our platform
Design, develop and maintain a robust and scalable data-warehouse and data lake
Work closely alongside Product managers and data-scientists to bring the various datasets together and cater to our business intelligence and analytics use-cases
Design and develop solutions using data science techniques ranging from statistics, algorithms to machine learning
Perform hands-on devops work to keep the Data platform secure and reliable
Skills Required
Bachelor's degree in Computer Science, Information Systems, or related engineering discipline
6 + years’ experience with ETL, Data Mining, Data Modeling, and working with large-scale datasets
6+ years’ experience with an object-oriented programming language such as Python, Scala, Java, etc
Extremely proficient in writing performant SQL working with large data volumes
Experience with map-reduce, Spark, Kafka, Presto, and the ecosystem.
Experience in building automated analytical systems utilizing large data sets.
Experience with designing, scaling and optimizing cloud based data warehouses (like AWS Redshift) and data lakes
Familiarity with AWS technologies preferred
Qualification – B.Tech/M.Tech/MCA(IT/Computer Science)

Years of Exp – 6-9",3.5,"upGrad Education Private Limited
3.5",Mumbai,"Mumbai, India",501 to 1000 employees,2015,Company - Private,Education Training Services,Education,₹1 to ₹5 billion (INR),"Udacity, General Assembly, Springboard"
1232,BBRC-Genomics-Associate Scientist,"JOB DESCRIPTION

Designation: Associate Scientist

Job Location: Bangalore

Department: Translational Medicine- Translational Sciences

About Syngene

Incorporated in 1993, Syngene International Ltd. is an innovation-focused global discovery, development and manufacturing organization providing integrated scientific services to the pharmaceutical, biotechnology, nutrition, animal health, consumer goods and specialty chemical industries around the world. Syngene’ s clientele includes world leaders such as Bristol-Myers Squibb, Baxter, Amgen, GSK, Merck KGaA and Herbalife. Its innovative culture is driven by the passion of its 4240- strong team of scientists who work with clients from around the world to solve their scientific problems, improve R&D productivity, speed up time to market and lower the cost of innovation .

Job Purpose:
To play a key role in TM-TS, develop an early-stage research strategy, initiate and lead discovery programs while managing ongoing programs in TM-TS. The role will work part of TMTS, and work with internal and external collaborators .

Key Responsibilities:
Experience in isolating DNA and RNA from blood, tissues and FFPE samples and cell lines. Experience with optimization of extraction protocols and for parameters like yield, input sample quantities and sample types is important.
Expertise in PCR, qPCR, cDNA/gDNA library preparation. Exposure to microarray techniques.
Proficiency in preparation of libraries for Next Generation Sequencing of transcriptome and genome, with significant experience in optimization of parameters like input RNA/DNA quantities and sample type
Experience with single cell RNA-seq will be plus.
Experience with various NGS protocols (DNA Amplicon based, hybrid capture based low input, degraded DNA and RNA samples e.g. FFPE samples.
Strong understanding of experimental design and statistical principles behind experimental design and differential gene expression. Experience with analysis of single cell RNA-sequencing data will be a plus

Educational Qualification:
M.Sc or M. Tech in Biotechnology, Molecular biology or Biological Sciences,

Technical/functional Skills:
DNA/ RNA Isolation, Expertise in PCR, qPCR, Experience in NGS protocols

Experience:
2 to 5 Years

Behavioral Skills:
A proactive team player.
Ensure completion of experiments and generate accurate and reproducible data from experiments.
Ability to work independently, prioritize tasks and work on multiple projects simultaneously with; comfortable working in a dynamic environment with changing requirements.
Good oral and written communication and presentation skills to work in a multi-disciplinary team
Equal Opportunity Employer:
It is the policy of Syngene to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by applicable legislation or local law. In addition, Syngene will provide reasonable accommodations for qualified individuals with disabilities.",3.5,"Syngene
3.5",India,"BENGALURU, India",1001 to 5000 employees,1994,Unknown,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1233,Applied Scientist 1,"Position Requirements:
Master's degree in Computer Science, Computer or Electrical Engineer, Mathematics, or a related field plus at least one year of experience in the job offered or related occupations of Software Engineer, Software Developer, or a related occupation. Employer will accept a Bachelor’s degree and five years of experience in the job offered or a related occupation as equivalent to the Master’s degree and one year of experience. One year of experience in the job offered or related occupation must involve designing and developing large-scale, multi-tiered, distributed software applications, tools, systems and services using Java, Object Oriented Design and Distributed Programming].

Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, Oracle/Berkeley databases, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills

Amazon Selling Partner Services team drives the Selling On Amazon business and develops solutions that enable millions of sellers around the world to sell on Amazon's Marketplaces. More than half of shipments for Amazon customers are generated from this business. The team is focused on building a technology platform that will support the explosive business growth in existing markets, streamline the business for Amazon and the Selling partners and launch business in new markets and establish a fair marketplace.

Our team is seeking engineers with broad technical skills to help us optimize how we synthesize massive amounts of data and complex business rules into mission critical financial information. As a member of this team you will employ object oriented techniques in Java, and DynamoB, PostGres and ElasticSearch skills to help us support Amazon's next generation of selling partner services. Along the way you'll gain and leverage a unique understanding of how Amazon.com works; from the numerous software systems that comprise the website's back-end, to the details of our business model, and the relationships we're establishing with an ever-growing network of selling partners who depend on Amazon.com to run their businesses.

The ideal candidate will draw upon exemplary analytical, critical thinking, and problem solving skills, and a passion for maintaining highly reliable, distributed systems which operate 24/7/365. Successful members of this team collaborate effectively with internal end-users, aggressive cross-functional software development teams, and technical support/sustaining engineering teams to solve problems and deliver successfully against high operational standards of system availability and reliability. We look for engineers who are excellent communicators, self-motivated, flexible, hardworking, and who like to have fun!

Position Responsibilities:
Participate in the design, development, implementation, testing and documentation of large-scale, multi-tiered, distributed software applications, tools, systems and services using [Java, Object Oriented Design and Distributed Programming]. Translate functional requirements into robust, scalable, supportable solutions that work well within the overall system architecture. Participate in the full development cycle, end-to-end, from design, implementation, and testing to documentation, delivery and maintenance. Produce comprehensive, usable software documentation. Evaluate and make decisions around the use of new or existing software products and tools.

Preferred Qualifications
Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1234,Senior Clinical Data Analyst,"About Novotech:

Novotech is internationally recognised as the leading independent and full-service contract research organisation (CRO) in the Asia Pacific region. We provide a wide range of clinical development services across all research phases and therapeutic areas and have been instrumental in the success of hundreds of Phase I – IV clinical trials throughout the Asia Pacific. Powered by the highest quality people, Novotech strives to set the benchmark for both business and clinical trial performance. Our people are one of our key strengths. We value our people and recognise the work they do. We are lucky to have the best people and talent from across the Asia Pacific region work together to deliver to clinical trial success for our clients. Our people and those we look to recruit have an attitude of making things happen. They are problem solvers, driven with a focus on delivering quality, accountability and a high level of performance.

Brief Position Description:

As part of Novotech’s Biometrics unit, the Senior Data Analyst (SDA) is responsible for all data analysis and business intelligence activities related to study related clinical and operational data. The SDA acts as primary point of contact for all data analysis matters to the study team and is responsible for the timely delivery of quality outputs following all applicable regulatory, compliance, best practice and operational procedures.

Minimum Qualifications & Experience:

Graduate in information science, data science or life science-related field, or similar. More than five years’ experience in a senior role related to data science, data analysis, clinical data management or clinical data programming in a pharmaceutical company, CRO or EDC software provider.

Responsibilities
The Senior Data Analyst (SDA) is responsible for providing technical, procedural (SOPs) and planning leadership across multiple projects assigned to the data analyst team members ensuring that they deliver in accordance with SOPs, programming best practices, and the timelines agreed within the Project Team.
Collaborate with cross-functional stakeholders to implement data science solutions to solve business needs using available technological solutions.
Scope data analysis effort for projects and project manage all data analysis activities across multiple projects for different study stakeholders.
Gather study requirements from data management for data review and external data reconciliation and provide guidance on appropriate outputs (dashboards, visualisations, listings, reports).
Extract, assess, integrate, transform data sources to provide data visualisation outputs for analytics.
Design and develop prototypes and final versions of data outputs (dashboards, reports, visualisations, listings) using Business intelligence tools and Data Visualisation tools.
Design and develop standard dashboards and content for different audiences.
Analyse, manipulate and understand data from multiple sources to present and create dashboards and reports to make business decisions.
Assist teams on best-practice for data visualisation dashboard development.
Educate teams on how to use all the features of applicable data visualisation platform in conjunction with data visualisation dashboards.
SME for the data visualisation development and assisting team members.
Identify and communicate project risks and maintain documentation within project files as appropriate
Represent data analysis group at internal / external meetings as appropriate.
Assess and implement new data analysis, BI and data visualisation processes and technologies.
Take an active role in the development of best practices, process improvement, quality control and governance related to all data analysis matters.
Provide training and mentoring to Data Analysis of team members in SOPs, software applications, and best practices.
Provide Subject Matter Expertise on all data analysis and visualisation related activities.
Attributes and Skills

Expert knowledge of clinical study data structures and schemas of EDC databases. Expert knowledge in data processing activities such as extracting, integrating, transforming and presenting data. Statistical Programming skills in Python, R or similar. Knowledge of SQL and EDC systems. Working knowledge of Spotfire, Power BI, Tableau or other data review and visualisation tool. Ability to gather business requirements from multiple stakeholders and clients and provide guidance on the use of appropriate data visualisations.

Experience mentoring and training others. Awareness of regulatory and compliance issues and understanding of the application of SOPs and Quality Control to daily activities. Excellent analytical, communication and problem-solving skills.

Opportunities and Benefits:

To deliver clinical trial and research excellence for our clients, our people are 'best in class'.

At Novotech, we seek and nurture people with exceptional talent. We are committed to providing our people with regular internal and external training, a competitive bonus structure and a supportive work environment. We are also focused on providing our people with a wide variety of career growth and development opportunities.

For more information about where your next career step at Novotech might take you, visit http://novotech-cro.com/novotech-careers",4.5,"Novotech
4.5",Bengaluru,"Sydney, Australia",501 to 1000 employees,1996,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
1235,Data Engineer,"Data Engineer Responsibilities:
Liaising with coworkers and clients to elucidate the requirements for each task.
Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed.
Reformulating existing frameworks to optimize their functioning.
Testing such structures to ensure that they are fit for use.
Preparing raw data for manipulation by Data Scientists.
Detecting and correcting errors in your work.
Ensuring that your work remains backed up and readily accessible to relevant coworkers.
Remaining up-to-date with industry standards and technological advancements that will improve the quality of your outputs.
Data Engineer Requirements:
Bachelor's degree in Data Engineering, Big Data Analytics, Computer Engineering, or related field.
Master's degree in a relevant field is advantageous.
Proven experience as a Data Engineer, Software Developer, or similar.
Expert proficiency in Python, C++, Java, R, and SQL.
Familiarity with Hadoop or suitable equivalent.
Excellent analytical and problem-solving skills.
A knack for independent and group work.
Scrupulous approach to duties.
Capacity to successfully manage a pipeline of duties with minimal supervision.
Job Type: Full-time

Salary: ₹360,000.00 to ₹870,000.00 /year

Experience:
total work: 2 years (Preferred)
Data Engineer: 1 year (Preferred)
Education:
Diploma (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,Futurious Technologies,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1236,Quantitative Analyst,"The successful candidate will be a highly analytical individual with hands on programming skills. The candidate will work closely with the research team and clients towards the ongoing development and integration of new investment strategies, models and tools on Axle

Location

Mumbai
Responsibilities

Perform daily/weekly/monthly tasks of performance and risk reporting
Develop and automate investment processes and strategies via VBA and Matlab
Develop tools to integrate trading decision systems with risk management systems
Ad hoc tasks (such as operational tasks, internal documentation tasks and preparation of marketing materials)
Skills/Experience

Excellent programming skills in Matlab/Excel-VBA
Thorough with financial concepts and calculations like Drawdown, VaR, Eloss etc.
Understanding of financial market products like options, futures, FX forwards etc.
Working knowledge of Bloomberg is preferred
Should be self-driven and detail oriented with an analytical mindset
Should be a proactive and quick learner; a team player showing enthusiasm and drive to accomplish results in a fast paced environment
Min. 2 years of relevant work experience
Qualifications

B.Tech/M.Tech/MBA/CFA/FRM",5.0,"B&B Analytics
5.0",Mumbai,"Zug, Switzerland",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1237,Analyst - Data Scientist,"Job Summary

Experience:
3 - 5 Years

Location:
Mumbai

Designation:
Analyst - Data Scientist

Degree:
BE-Comp/IT, BE-Other, BTech-Comp/IT, BTech-Other, ME-Comp/IT, ME-Other, MTech-Comp/IT, MTech-Other, PhD-Comp/IT, PhD-Other

Educational Level:
Graduate/Bachelors

Industrial Type:
IT-Software/Software Services

Functional Area:
IT Software - Application Programming / Maintenance

Key Skills:
Data Scientist

Job Post Date:
Thursday, March 19, 2020

Company Description

We are capability centre based in Mumbai, initially started as a back-office operational support to the UK business unit.

However, over the recent years, we have significantly increased the breadth and depth of our capabilities and offerings to keep pace with the changing needs of the Group. These include Digital & Knowledge Services, Finance and Actuarial, Information Technology (IT), Customer Service, Risk and Audit.

Our core purpose is to be a strategic partner to company, enabling growth by delivering change and driving synergies through a highly capable and agile workforce.

With our diversified service offerings we provide our people with exciting opportunities to grow personally and professionally.

Company is a leading savings and investments business serving around 5.5 million retail customers and more than 800 institutional clients.

It-s innovative asset management and customer solutions are supported by extensive investment capabilities, an international distribution network and two strong brands.

Job Description

3 – 5 yrs experience as Data Scientist
Should have at-least 1 end-to-end ML project experience
Very high proficiency in R or Python
Excellent in forecasting methods like simple exponential smoothing, multiplicative seasonal indexes, simple and weighted moving averages and time series forecasting methods
Exposure to with advanced deep learning techniques such as LSTM. CNN, Dense neural networks as well as neural networks design and implementation through tools like tensorflow, keras, pytorch, deepai or equivalent.
Good SQL experience",3.8,"Sampoorna Computer People
3.8",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
1238,Data Lake Developer,"For Us, It's A Mission

At Mylan, we mean it when we say we work every day to provide access to high quality medicines to the world's 7 billion people. If you are unconventional, relentless and passionate. If you believe in doing what's right, not what's easy. If you are a doer and have a passion for serving others, we want to talk to you.

Make a Difference

At Mylan, each person has the ability to make a difference. From the providers who sell and market our products, to the producers who develop and manufacture them and finally to our business partners who support the providers and producers, we all have a mission critical role. Here's how this role will help:

ESSENTIAL DUTIES AND RESPONSIBILITIES
To perform this job successfully, an individual must satisfactorily perform each essential duty. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential duties.
1. Create and maintain optimal data pipeline architecture on Azure platform.
2. Develop batch processing solutions by using Data Factory and Azure Databricks.
3. Delivering a Data Warehouse in the Azure Cloud.
4. Design relational and non-relational data stores on Azure.
5. Identify, design, and implement internal process improvements : automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc..
6. Developing Big Data Solutions with Azure Machine Learning.
7. Strong interaction with business departments to provide consultative support for digitization efforts, as well as close collaboration with the Business Technology management, focused on future innovation topics.
8. Participate and lead in design sessions, demos and prototype sessions, testing and training workshops with business users and other IT colleagues.
9. Design & Build for any API Development or SQL DB development.
10. Providing service management, orchestration, monitoring and management requirements of Azure cloud platform.
11. Create data tools / products for analytics and data scientist team members that assist them in building and innovative solutions that drive tangible business value.
12. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
13. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
14. Design security for source data access. Chose the appropriate authentication mechanism, (ie Azure Active Directory (Azure AD), etc).
15. Design for real-time processing by using Stream Analytics and Azure Databricks.

Make Our Values Your Values

Mylan hires only the best. People who thrive in a culture of innovation and empowerment. People who are active learners and have a positive attitude. People who are leaders and know that by working together we can run faster, reach higher and achieve more. By doing so, we will continue to set new standards in health care. Here are the minimum qualifications and essential functions for this position:

QUALIFICATIONS

The qualifications listed below are representative of the minimum knowledge, skill, and/or ability required.

SKILLS AND ABILITIES

1. 10 years of experience in Microsoft technologies including SQL.

2. At least 5 years as a Sr Developer with at least 3 years hands on experience as Azure Data Engineer building large scale Azure data solutions.

3. At least 5 years of experience in Azure based data solutions.

4. At least 3 years of experience on working with large projects including the most recent project in the cloud (Azure) or on prem with a focus on Azure Data services.

5. At least 5 years of Hands-on administration, configuration management, monitoring, performance tuning of Hadoop/Distributed platforms.

6. At least 5 years of demonstrated experience at least in the most recent 2 years of designing and delivering solutions using Cortana Intelligence suite of analytics services part of Microsoft Azure including Azure Machine Learning Studio, HDInsight, Polybase, Azure Data Lake Analytics, Azure Data Warehouse, Streaming Analytics, Data Catalog, R/R Studio

7. Experience in designing and building logics required for optimal extraction, transformation, and loading of data from a wide variety of data sources

8. Experience within Data Security design, including but not limited to:

a. Choosing the appropriate authentication mechanism, such as Azure Active Directory (Azure AD)

b. Defining strategies for data encryption for data at rest and in transit

9. Experience partnering with Business Analysts and Data Scientists to enable effective and efficient data preparation and delivery

10. Experienced in vendor management and working with 3rd parties onshore & offshore.

11. Experience working in a global team.

12. Experience working in an Analytics / Big Data solutions on MS Azure Cloud

13. Experience with code management tools, automated testing

14. Experience creating and maintaining optimal data pipeline architecture on Azure platform

15. Experience developing batch and real-time processing solutions by using Data Factory and Azure Databricks

16. Familiar with AGILE and Azure DevOps methodology

17. Hands on PoC capabilities are needed to prove a particular architecture concept

18. Azure Native Services experience across Data Fabric and Service Fabric

19. Experience in Application modernization from legacy on-premise data architecture platform technology stack to modernized Azure Cloud base Architecture.

20. Experience with Git, NoSQL Data Solutions, Microsoft Azure, HD Insights, Azure ML, DataBricks ML Flow, R or Python.

21. Must have excellent communication skills.

EDUCATION/EXPERIENCE (Note: Please select one)

Minimum of a Bachelor's degree in Computer Science and Engineering is preferred with minimum 10 years of experience. However, a combination of experience and/or education will be taken into consideration

Why Mylan?

If you want to be part of a global health care company that is making a difference and changing lives, Mylan may be the place for you. With a workforce of more than 35,000 worldwide, we can make a difference. We encourage you to visit Mylan.com to learn more about our unconventional culture, our approach to doing business and how we plan to set new standards in health care.

Mylan offers competitive salary, excellent benefits and an environment conducive to professional growth and advancement. All qualified applicants will receive consideration for employment without regard to their disability or protected veteran status. Mylan is an Equal Opportunity Employer, Minorities/Female/Disabled/Veteran.",3.8,"Mylan Inc.
3.8",Bengaluru,"Hatfield, United Kingdom",10000+ employees,1961,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1239,Off Campus Recruitment - Quantitative Researcher,"Description:
Graviton is a privately funded quantitative trading firm striving for excellence in financial markets' research. We are seeking fresh talent from the top IIT's to join us as Quantitative Researchers for our team in Gurgaon.If you are a student graduating in 2020 from Computer Science , Electrical or Maths Stats Computing streams with a greater than 8 CGPA please apply here.

This role is open to students from campuses that we could not visit this year. Please check your individual placement policy restrictions before applying.

Graviton trades across a multitude of asset classes and trading venues using a gamut of concepts and techniques ranging from time series analysis, filtering, classification, stochastic models, pattern recognition to statistical inference analysing terabytes of data to come up with ideas to identify pricing anomalies in financial markets.

As a Quantitative researcher your responsibilities will include

Develop new or improve existing trading models using in-house platforms

Use advanced mathematical techniques to model and predict market movements

Analyse large financial datasets to identify trading opportunities

Provide real time analytical support to experienced traders

Requirements :
Possess a degree in a highly analytical field, such as Engineering, Mathematics, Computer Science from IITs schools

Quantitative bend of mind

A working knowledge of Linux/Unix

Programming experience, preferably in C++ or C

Strong interest in learning about financial markets.

Have a strong work ethic

Hard Working

Benefits:
Our open and casual work culture gives you the space to innovate and deliver. Our cubicle free offices , disdain for bureaucracy and insistence to hire the very best creates a melting pot for great ideas and technology innovations. Everyone on the team is approachable, there is nothing better than working with friends!

Our perks have you covered.

Competitive compensation

6 weeks of paid vacation

Monthly after work parties

Catered breakfast and lunch

Fully stocked kitchen

Gym membership

International team outing",5.0,"Graviton Research Capital LLP
5.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2014,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1240,Data Engineer,"Zauba Technologies is a startup based in Bangalore. Zauba's services are used by leading companies in India. Zauba is powered by a young and passionate team. We are looking for individuals who would like to be a part of our founding team.

As a Data Engineer and as a part of founding team, you will be expected to visualise and develop disruptive data products. Eventually you would be responsible for entire project lifecycle of products you would visualize. Your rewards will be directly proportional to the value you generate.

Job Responsibilities
Design and development of robust, scalable and highly efficient data engineering solutions for structured and unstructured data (Including gathering and processing raw data at scale, writing scripts, web scraping, calling APIs, writing SQL queries, etc.)
Develop processes for text mining and extraction of information from unstructured data
Design, architect and develop efficient data pipelines around the data collected
Take ownership of existing web product and applications
Design and implement data models that scale across the enterprise
Take ownership of existing data workflows and processes
Enhance scalability, performance, and stability of existing infrastructure
Work closely with other team members to integrate your innovations and algorithms into our production systems

Essentials
Java/Python - Intermediate to advanced level
SQL - Advanced
MySQL Intermediate to advanced level
Regex - Basic to intermediate level
Linux Basic to intermediate level

Good to have
Hadoop/Spark
R
MongoDB

Must have qualities
Skills to learn new skills quickly
Desire to create disruptive products and services
Passion - not just to work in startups but to take them to next level
Above average programming aptitude
Be passionate about producing high quality engineering deliverables
Be productive working independently or collaboratively
Have an eye for building efficient processes
Be self motivated
Proactively take ownership

Interested?

Send your resume to hr@zaubacorp.com",3.8,"Zauba Corp
3.8",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 million (INR),-1
1241,Quantitative Research,"We are looking for highly trained professionals who are interested in applying advanced mathematical quantitative methods to the modeling of global financial markets. You would be joining a group made up of highly proficient individuals from various scientific disciplines. We have a spectrum of opportunities for individuals with the right scientific skills. Experience in finance is not required.

The ideal research candidate will have:
A Ph.D. in Computer Science, Mathematics, Physics, Statistics, or a related technical discipline.

A demonstrated capacity to do first-class research.

Computer programming skills.

An intense interest in applying quantitative analysis to solve difficult problems.

Send us a copy of your resume to
careers@dolatcapital.com

For internship opportunities, please send us a copy of your resume to
careers@dolatcapital.com",4.0,"Dolat Capital
4.0",Mumbai,"Mumbai, India",51 to 200 employees,1970,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1242,Data Engineer,"Bachelor’s degree in Computer Science or related field
5+ years relevant experience
5+ years experience with SQL, SQL Tuning, Oracle, OLAP, Big Data Technologies
5+ years experience developing end-to-end Business Intelligence solutions: data modeling, ETL and reporting
Experience with Java and experience with scripting languages like Perl, Python, Unix shell scripts,VBA and MS Excel
Proficiency with Linux and systems administration
Proven ability at looking at solutions in unconventional ways. Sees opportunities to innovate and can lead the way.
Top notch communication (verbal and written) and interpersonal skills to convey key insights from complex analysis in summarized business terms and an ability to effectively communicate with technical teams.
Ability to work with shifting deadlines in a fast paced environment.
Operations Finance Technology team, responsible for building technical solutions for multi-billion WW Operational Cost analytic including Inbound cost (Receiving / PO), variable Cost, fixed cost, outbound (Customer Shipments / Transportation), and Customer Service, is looking for a Data Engineer.

As a data engineer, you will get the exciting opportunity to work on very large data sets in one of the world's largest and most complex data warehouse environments. You will work closely with the business teams in analysis on various cost savings initiatives, many non-standard and unique business problems and use creative-problem solving to deliver actionable output.
You will be responsible for designing and implementing an analytical environment using third-party and in-house reporting tools, modeling metadata, building reports and dashboards. You will have an opportunity to work with leading edge technologies like Redshift, Hadoop/Hive/Pig. You will be writing scalable queries and tuning performance on queries running over billion of rows of data.

You should be analytical, have an extremely high level of customer focus and a passion for process improvement. You should be motivated self-starter that can work independently in a fast paced, ambiguous environment. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions.
Bachelors in Computer Science or related field
Practical Knowledge of Linux or Unix shell scripting
Experience in working with business customers to drive requirements analysis
Exposure to large databases, BI applications, data quality and performance tuning
Excellent written and spoken communication skills
Experience with Hadoop-based technologies such as HBase, Pig, Hive and Spark
Strong proven ability in building high-performance, highly available and scalable data solutions using Oracle and/or Hadoop-based technologies
Knowledge of data warehousing concepts.
Strong sense of ownership, urgency, and drive
Strong troubleshooting and problem solving skills
Experience with Amazon Web Services",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1243,DATA ANALYST,"posted by Mahima Gaur

2 - 5 years Delhi

Job Description
Experience in data processing
Experience in data cleaning and data tabulation activities
Strong analytical, communication and team management skills
Strong understanding of data management using SPSS and research techniques
Competency in a Tabulation software (decipher / wincross / quantum etc), Excel, Powerpoint
Ability to summarize findings, draw conclusions, and put together a presentation using Powerpoint
Role Category : Data Analyst

Employment Type : Permanent Job, Full Time",4.9,"Knowledge Excel Services.
4.9",New Delhi,"New Delhi, India",1 to 50 employees,2007,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
1244,Data Engineer,"Key skills : Python , Spark , SQL , Pyspark • AWS platform used for the work • Strong experience in SQL is mandatory • Good familiarity of AWS landscape • Good experience in collecting business requirements & design them as per requirement from customer • Should able to work independently & interact business users & technical stakeholders • Strong communication skills both oral & written. • Should work as an individual resources",3.5,"Larsen & Toubro Infotech Limited
3.5",India,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1245,Big Data Engineer,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
1246,Client Data Analyst,"At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.
What is the Client Data Analyst – Client Analytics group responsible for?
This team manages business data to ensure accurate, timely, consistent and compliant data. Their contributions deliver quality data that is easily accessible and can be trusted. Key downstream capabilities such as reporting and analytics depend on this as well as operational data access on various systems. The Data Management Team is a support function that acts as an advocate and a point of contact for Sales and Marketing data.

What are the ongoing responsibilities of an Client Data Analyst ?
Understand the data flow, key consumption and production of data as well as context within the enterprise:
Build positive relationships with teams, especially the key data consumers and analytics. Take the time to increase knowledge of how they run their business and incorporate sales data into daily work
Connect regularly with each sales office to understand current issues and challenges. Probe the business and validate against other sales offices to understand the scope and priority of the issue
Make recommendations on how data unifications and flow can be used to improve business tasks. Liaise business partners to deliver solutions (reports, processes, technology) that add value.

Provide data management subject matter expertise. Appreciate the connection and data flow between applications and other corporate systems. Be able to clearly articulate the data needs and move initiatives forward by collaborating with business partners:
Actively participate in meetings with business partners to ensure that priorities are clearly understood, information is regularly shared and that key participants are “kept in the loop”
Provide context and background on issues. Collaborate on ideas for progressing initiatives. Ensure appropriate resources are involved to take initiatives forward
Provide insights and expertise to scope statements and requirements documentation
Actively consult or participate in the user acceptance testing process (test cases, documentation, testing execution, etc.)
Ensure business needs remain aligned with overall corporate initiatives and deliver the benefits as originally intended

Monitor the integrity of data and usefulness of reports. Ensure the information available within systems is accurate and up-to-date. Proactively seek data cleansing opportunities and evolve data to better support. Document and maintain ongoing processes for reporting and data clean-up:
Partner with all key data consumers to gain a solid understanding of usage and challenges around data. Establish processes for prioritization of enhancements, especially with the analytics groups
Provide 1st level support for data issues and data maintenance for owned data
Verify and execute data loads into our internal sales systems and ensure any upstream systems accurately receive their data

Increase awareness and promote data management capabilities. Share best practices and provide coaching to local offices on how to access and incorporate output into sales tasks. Encourage IAS leaders to leverage data to make more informed, strategic decisions:
Clearly articulate the goals and core services of the data management team. Proactively promote this information within IAS and ensure business partners understand the data management role within the organization
Share best practices and provides guidance on data capabilities. Reinforces ownership and accountability for data accuracy
Seek opportunities to share the benefits of leveraging sales data to make more informed business decisions

What ideal qualifications, skills & experience would help someone to be Successful?

Knowledge, Education And Experience:
Four year bachelor’s degree required (majors of preference include: business, computer science, mathematics) Advanced degree a plus
Understanding of the Franklin Templeton business model, how FT makes money, the sales process, how technology fits in with the business, etc. Knowledge of the GAS (Global Advisory Services) structure
Experience working through multiple business fiscal cycles; exposure and/or direct experience with project management and/or sales-related-capacity required
Prior work experience related to analytics, sales, marketing and/or international a must. Level will not be granted based on years of experience but will be determined by the employee’s ability to meet each job activity as outlined the ‘typical/expected focus by level
Skills And Abilities:
Ability to communicate effectively with all levels of management; ability to tailor communication style based on audience; ability to get others to want to collaborate with you; strong facilitation skills
Excellent writing skills (for presentations, documentation, etc.)
Working knowledge of the CRM, MDM, Excel, SQL, Power BI, Tableau, Business Objects, and Microsoft Products (PPT, Power Apps, Doc, Visio)
Ability to absorb and interpret large quantities of data; apply trend analysis and knowledge of the business to develop a meaningful and digestible summary with the appropriate level of detail
Ability to take a larger problem and break down the individual components; identify how to go about solving the problem and who to involve in the process
Ability to present recommended solutions to a variety of issues and problems (solutions that are consistent with organization objectives)
Must be extremely detail-oriented (managing lists, tasks/to-dos, etc.) good with follow through on own items; good with following up with others on outstanding item

What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.

Highlights of our benefits include:

Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.",3.8,"Franklin Templeton Investments
3.8",Hyderabad,"San Mateo, CA",5001 to 10000 employees,1947,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Fidelity Investments, Vanguard"
1247,Data Analyst,"Roles and Responsibilities:
Extracting, transforming and inputting data sets from various resources. Creating predictive models, translating non-technical aspects into quantifiable tasks. Analysis and representation of output data, highlight and explain trends and patterns, error elimination, using advanced statistical methods (regression, probability distribution, clusters etc.) to provide accurate results.
Data collection, Data Mining, Report generation, Problem identification and solution formulation Market analysis and establishing trends, Strategy development and implementation

Skills:
Extremely good analytical skills.
Good working knowledge of all MS-Office products, especially Advance Excel, Word, PowerPoint, MS-access.
Statistical tools and methods.

Interested candidates can send the updated resume on satish.mehra@exelaonline.com or call on 7722028636
00-7.00 Years",2.6,"Exela Technologies
2.6",Pune,"Irving, TX",10000+ employees,2017,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"SourceHOV, BancTec, Transcentra"
1248,Data Modeler,"• Minimum 5-8 years of working experience as Data modeler.
• Data modelling experience in designing.
• Minimum 2-3 years real time experience in Erwin tool is mandatory.
• Experience in normalized modeling techniques.
• Experience in designing the Start schema.
• Experience working in ORACLE.
• Experience with database design, capacity planning, performance tuning and query optimization.
• Experience in working with Bank or Banking and Finance or Financial domain.
• Excellent communication skills with leadership quality.

Job Segment:
Database, Oracle, ERP, Technology",3.5,"LTI
3.5",Mumbai,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1249,Machine Learning Engineer,"Looking for Data Scientists with Python/R Programming skills.
Specific experience in AI areas like Statistical Machine learning / Deep learning / Natural Language Processing (NLP)/ Operations Research (Optimization) will be an advantage.Individual in this role is expected to work with multiple stakeholders and teams

Qualifications and Requirements:-
Previous working experience as a Machine Learning/ Data Scientist for 2 years
MA in Computer Science or similar relevant field
Hands on experience with MALLET
In depth knowledge of Apache Tomcat/Open Source
Excellent project and time management skills
Attention to detail
Outstanding problem solving and analytical skills",-1,Tekolutions.ai,India,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1250,Data Science Internship,"About the company:
SkillBit is a leading staffing and recruitment company engaged in talent searching assignments for skilled and talented candidates for the industry.

About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Working on data science algorithms and AI concepts 2. Using Python or R for web scraping 3. Building AI models using Python, machine learning, and deep learning algorithms 4. Processing of unstructured/structured data

Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 6th Jun'20 and 11th Jul'20
are available for duration of 1 month
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply

Number of internships/jobs available: 3

Categories: Data Science",-1,SkillBit,Pune,-1,-1,-1,-1,-1,-1,-1,-1
1251,Data Engineer,"As a data engineer at TEAL, you'll be taking the plunge into a rich data lake that includes everything from satellite data to legal court orders. You'll be hustling and getting your hands dirty with every part of the data pipeline always having an implicit appreciation for how all of this data will ultimately power a revolutionary real estate risk platform.

Your day-to-day will include either all or some of the following:

Constantly scoping out new data sources to complement existing ones
Creating and maintaining distributed web scrapers using Python, RabbitMQ and other technologies
Architecting and managing data pipelines where data flows into multiple end-points including, but not limited to, Postgres, MongoDB and Apache Solr
Documenting workflows and constantly iterating to create better data infrastructure.

We'd love it if you:
Are proficient in Python or any other object-oriented language
Have worked with large (millions to hundreds of millions of rows in a SQL database) interdisciplinary datasets
Have scraped difficult websites and have some experience working with various data APIs
Are patient and methodical with unstructured and messy data
Are always hungry to learn newer and better technologies to make the data ecosystem faster, smoother and less silo-ed

Extra brownie points if you:
Have some experience working with large-scale search indexing
Have performed geospatial analyses in some capacity
Have created and managed data lakes in the cloud
Culture

To explore our culture and the values we embody click here

Testimonials
Testimonial

My experience at TEAL surpassed all my expectations from the get-go. I was asked to help solve one of the most daunting problems in the Indian real estate market. Every day while working on a subset of the problem, the ideas that I brought to the table were shaped into cohesive solutions by a collaborative team effort. At TEAL I was exposed to the most cutting edge technologies such as Cloud Computing, Big Data, ML and Data Science. The growth opportunities at TEAL are tremendous, If you are innovative and can demonstrate the will to realize your ideas, TEAL is an amazing organization to work for.
Gyan Vardhan, Data Science Intern
I had interned as a Data Scientist at Terra Economics and Analytics Lab during its early days, it was a rich learning experience working with a multi-disciplinary team who are extremely passionate about building a decision support platform for the insanely complicated realty market in India. It was exciting and challenging to work on mining huge volumes of property records; extracting patterns from the data, building data pipelines and brainstorming on building the core system. TEAL offers a very healthy work environment coupled with insanely talented people working together in an exciting setting.
Naga Anjaneyulu, Data Science Intern
I worked as a full-time Data science intern at TEAL. During this period, I got an opportunity to leverage my skillsets while also learning new technologies, working on tasks assigned to me. The company operates on the latest tech-stacks and gives opportunities to learn as much as you want. The work environment is challenging, the team at TEAL is super supportive and new ideas are always welcome. It has all the good perks of a startup; creativity and innovation, casual work atmosphere and a collaborative approach to solving problems. Personally, I loved working there, my experience was fantastic!
Archana Parmar, Data Science Intern
As a second-year college student, I was looking for an internship that would allow me to delve deeper into research and work with big data, TEAL gave me the perfect opportunity to do so, enabling me to develop proficiency in research and analysis. As a research analyst intern, I collated and cleaned data and helped in the preparation of reports and presentations, and I had members helping me at every stage of this process. This collaborative environment allowed me to cultivate my skills and also learn from my peers. The holy trinity of Rohan, Kshitij, and Shreyas served as not only excellent mentors and bosses but also as friends, helping me at every stage and giving us all food and ice cream to keep us going!
Arush Mehra, Research Intern
Internships are a crucial part of one’s early career. The internship experience at TEAL was a thrilling rollercoaster ride to say the least! It was more than implementing a standard model or building an already though out concept into reality. It was about finding the solution to a unique and open-ended problem.It was exciting to work on addressing a problem with far -reaching real world applications.Moreover, the work environment had the perfect balance of casual yet professional which kept you focused and stress free at the same time. Out of every 100 startups in India only 2 of them succeed, but there are very few like TEAL India which are bound to make it big at such an early stage.
Divyanshu Agarwal, NLP Intern",4.7,"Terra Economics & Analytics Lab (TEAL)
4.7",New Delhi,"Bengaluru, India",1 to 50 employees,2018,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
1252,Senior Consultant - ModellingOps Data Engineer,"Job Title: Senior Consultant - ModellingOps Data Engineer
Location: TRIL GTC
GCL: D1

JOB DESCRIPTION:

AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. The Science & Enabling Units IT is AZs global IT capability function supporting key business areas operating out of sites across the US, UK, Sweden, India & Mexico.

We are looking for AI Ops consultant who will leverage tools & technology best practices to improve delivery performance & data engineering capabilities in the D&A space.

ROLES & RESPONSIBILITIES:

7-10 years of experience in IT Operations involving Data Science, Artificial Intelligence-Machine Learning and Predictive Analytics. Experience in architecting and implementation of end-to-end AIOPs solutions through ELK stack, Splunk. Experience in applying statistical methods, analysis, pattern recognition and modeling on IT Operational data using ELK machine learning. Experience in extracting meaning full data from incoming data streams from different sources through RegEx, Grok etc. Hands-on experience in applying machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc in the IT Operation domain. Experience with machine learning and statistical programming languages - Python, R etc. Experience in assessing the existing IT environment and providing recommendations to reduce the critical applications impacting incidents. Experience in exploring and identifying areas where manual tasks can be automated in IT environment. Experience with various Enterprise IT monitoring solutions including Infrastructure monitoring, Application Performance Monitoring, Network Monitoring, Cloud monitoring etc. Experience in IT Service Management including Service Desk, Incident Management, Change Management, CMDB etc. Excellent knowledge on various IT infrastructure components that includes Server Infrastructure, middle ware, database and application architectures and Cloud Components. Experience/knowledge on Infra monitoring tools - NOI, Zabbix, AppDynamics, Datadog, SCOM, SolarWinds etc. and Service Management tools -IBM Control Desk, BMC Remedy, ServiceNow etc. Experience/Knowledge on BI tools Knowledge on distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc. Knowledge on other programming languages/scripting: Python, Java, JavaScript, etc. ( Added Advantage ) Good analytical skills, strong communication skills are must. Client facing experience is an added advantage. Excellent experience in understanding the problem statement, architect and designing the solution

MANDATORY SKILLS:
Significant experience with AWS cloud environments, working knowledge of Google and Azure platforms. Knowledge of Kubernetes, S3, EC2, Sagemaker, Athena, RDS and Glue is essential.
Experience provisioning computational resources in a variety of Cloud environments using Infrastructure as Code.
Experience with best practice of data transport and storage within cloud system.
Experience building large scale data processing pipelines. e. g. Spark and SQL.
Experience with containers and microservice architectures e.g. Kubernetes, Docker and serverless approaches.
Excellent working knowledge in DevOps, using continuous integration and continuous development.
Use of Data Science modelling tools e.g. R, Python, SAS and Data Science notebooks (e.g. Jupyter).
Good written and verbal skills, fluent English
DESIERED SKILLS:
Agile practices, especially being a SCRUM Master
EDUCATIONAL BACKGROUND: B.E/B.Tech/MCA

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",3.9,"AstraZeneca
3.9",Chennai,"Cambridge, United Kingdom",10000+ employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Roche, GlaxoSmithKline, Novartis"
1253,DATA ENGINEER,"JOB DESCRIPTION
As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements, and also research new uses for data acquisition. You should also know the ins and outs of the industry such as data mining practices, algorithms, and how data can be used.

DESIRED CANDIDATE PROFILE
An ideal candidate must possess prior experience leading a project.

Candidates must have:
> Experience in Hive, Spark, Scala, AWS DynamoDB, HBase, AWS Glue, Talend, Kafka, Snowflake ETL
> Strong experience in a BI/Data Warehouse environment with involvement in design, development, implementation, troubleshooting and support of ETL process using ETL tool.
> Experience in developing Data Marts, Data warehousing and Operational Data Store (ODS) on any of the databases or Hadoop environments.
> Experience in database like MS SQL, MySQL, Oracle, PostgreSQL
> Good to have programming experience in writing Complex Stored Procedures, Queries, Views, User Defined Functions, Cursors and Common Table Expressions using SQL or T-SQL.
> Experience in Performance Tuning and Query Optimization by Indexing, Partitioning and De-normalization.
> Experience in Developing a framework for ingesting data into Data lake
> Good database knowledge, analytical thinking
> Design, construct, install, test and maintain data management systems.
> Build high-performance algorithms, predictive models, and prototypes.
> Develop set processes for data mining, data modeling, and data production.
> Experience with cloud services: AWS (EC2, EMR, S3, Athena) and scripting languages like Python, /PySpark/R/SAS
> Install/update disaster recovery procedures.
> Experience in Agile Application Development & Scrum methodologies is preferred
> Ability to supervise and mentor junior developers on the team.
> Must be self-motivated and work well pulling people together in addition to being able to pull people together technically
> Demonstrated proficiency of troubleshooting techniques and detail-oriented problem diagnosis
> Ability to handle responsibility, is self-directed, with strong organizational and documentation skills
> Ability to work independently and efficiently under aggressive deadlines to meet project commitments
> Excellent verbal and written communication skills

EDUCATION
UG - B.Tech/B.E. - Computers, Electronics/Telecommunication, Diploma - Computers, Electronics/Telecommunication, B.Sc - Computers, BCA - Computers) AND (PG - M.Tech - Computers, Electronics/Telecommunication, MCA - Computers, M.Sc - Electronics, Computers) AND ( Doctorate - Any Doctorate - Any Specialization, Doctorate Not Required).

OTHER DETAILS
Number of vacancies: 4
Experience: 3 years
Location: Cochin

If you have a passion towards technology and coding, then we have the right job for you. Kindly forward your resumes to
Email: jobs@mjsofttech.com
Phone: 0484-2421245 / 928 720 7160",4.0,"MJ Softtech
4.0",Kochi,"Cochin, India",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
1254,Data Engineer,"Education/ Experience and Skill Requirement
4+ years of relevant experience in
Experience working with both relational and NoSQL databases.
Strong coding skills; Python (preferred) /R/Java/Scala
Experience in developing Data warehousing technologies Experience with AWS or equivalent cloud services preferred
Experience in BigData technologies (Hadoop, HDFS, MapReduce, Spark, Hive, HBase etc) will be valuable
Knowledge of Machine Learning a big plus (Random Forest, Decision Trees, SVM, NLP, Gradient Boosting, Supervised/Unsupervised Learning, Clustering, classification and regression modeling).
Responsibilities
Proficiency with several years’ experience in more than one of Python, R, Java, Scala, or robust Linux shell scripting
Implementation experience with data warehouse architecture & design, ETL design/development, and Analytics
Knowledge of general cloud architecture and cloud strategies especially around AWS services and concepts such as S3 object stores, RDS databases, EC2, Glacier, Lambda, IAM, enterprise security, data security, DevOps, replication and disaster recovery
Well versed with data mining & exploration, NLP and visualization
Understanding of data modeling, data integration, and data representation (metadata, OWL, ontologies)
Developing data marts and data management using SQL
Creating powerful visual outcomes
Independently manage daily client communication, especially over calls
Manage client deadlines, ensure quality of the deliverables, attention to detail
Experience/understanding of corporate finance data from company filings is desirable",3.6,"Copal Partners
3.6",Bengaluru,"New York, NY",10000+ employees,1900,Company - Public,Financial Analytics & Research,Finance,₹100 to ₹500 billion (INR),-1
1255,Data Engineer,"Job Description / Responsibilities
Build workflows to ensure data extraction quality and storage into our backend data store
Architect, build and train ML/AI models that can predict outcomes and report on anomalies.
Design data pipelines to perform ETL on content/data from multiple types of source systems.
Create data analytics views using RDBMS/Key-Value stores, on private and public/cloud
Create software that is well tested, maintainable, extensible and scales out with large data

Minimum Qualifications:
2+ years of software development with Python
2+ years of SQL (MySQL/Postgres) and Key-Value databases
1+ years of experience with scikit
2+ years of experience in data extraction, data transformation using custom Python/Java
Experience working with MapReduce/Hadoop/kafka/Elastic stack
Experience with Node backend and React/Redux
Experience working with git/mercurial, Amazon/Google cloud, Linux/LAMP stack
Experience in testing or test driven development
Experience with Data science and Machine Learning algorithm development

Location:
Hyderabad/Bangalore

Package:
Highly competitive to match experience and capability",3.7,"TVS
3.7",Bengaluru,"Chennai, India",5001 to 10000 employees,-1,Company - Private,Accounting,Accounting & Legal,₹100 to ₹500 billion (INR),-1
1256,Data Engineer,"Permanent position with US based client of iFlex.
Work Location: Bangalore
Experience Level: 2+ Years

Role:
As part of our global team you will work on the data platform reporting to the Data Engineering Lead. Your role includes specification, development, test and rollout of features on our data platform. You are expected to contribute to the vision, understand our product roadmap, integrate business value andclient experience and contribute to build an engineering culture within the team. This initiative is of critical important to the success of the organization and our roadmap, for instance, services like liquidity analytics, billing, client onboarding, reporting and others will rely on the data platform. Accurate, granular, complete and timely data will be our key differentiating factor and competitive advantage in the market place. We expect the successful candidate to deliver high quality software and to be passionate about data engineering..

Responsibility / Qualification:
Managing multiple tasks and use sound judgment when prioritizing.
Collaborating with global cross functional team in building customer-centric products.
Analyzing existing software implementations to identify areas of improvement and provide deadline estimates for implementing new features.
Updating and maintain documentation for team processes, best practices and software runbooks.
Establishing trusted partnerships with peers, product heads, and executive level stakeholders.
We are looking for someone who is passionate about technology and engineering.
Exceptional analytical skills and ability to apply knowledge and experience in decision-making to arrive at creative and commercial solutions.
Ability to leverage technology to deliver business value.
You are independent and comfortable in a fast paced, ambiguous and often multi-directional work environment.

Preferred Qualifications:
B.S. or higher in Computer Science.
Minimum 2 years of relevant professional experience using a modern programming language (preferably Java/Scala).
Experience leveraging test driven development technics.
Comfort with Agile operating models.
Team oriented.
Strong interpersonal and communication skills.
Energetic, self-directed, and self-motivated.
Experience with microservice architecture.
Experience with Kafka, MongoDB, Hadoop, Cassandra.
Experience with AWS.
Experience in Financial Services or Fintech.",-1,IFLEX,Bengaluru,"Moscow, Russia",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1257,CIEL/SEL/1941: Sr data scientist,"Mandatory skills required -
Databases (SQL, Oracle, Any RDBMS) - Should have working knowledge of atleast one database
PL/SQL Programming Languages
R, Python (Any One)
Inferential Statistics - Hypothesis, p-value, R2, RMSE, MAPE etc
Exploratory Data Analysis
Machine Learning Algorithms - Should have in-depth knowledge and implementation of atleast one algorithm

Responsibilities
: Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the why & how of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions

Education
Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics
Experience
Minimum years of related experience required: 3 years
Preferred years of experience: 5 years
Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desirable.

Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
1258,Data Engineer,Data Engineer,3.6,"Bookmyshow
3.6",Mumbai,"Mumbai, India",1001 to 5000 employees,2007,Company - Private,Ticket Sales,"Arts, Entertainment & Recreation",Unknown / Non-Applicable,-1
1259,Data Analyst,"Required Skills & Experience

We are looking for a Data Analyst Executive
Eligible Qualifications : B. Tech, BCA, M.Tech, MCA
Experience : 3-5 years, fresher’s can also be considered
Location of Job : Gurgaon/Connaught Place, New Delhi
Technicals Skills

Following technical skills are pre-requisite:
Well versed with Software development methodologies, such as SDLC (Software Development Life Cycle), DDLC (Document Development Life Cycle).
Database schema design and implementation
Should have worked in either of technologies Sql Query/ Tableau/ Excel (Macros)/ Access (Query) writing for data analytics.
For planning and coordinating activities, organizations remain in invariant communication with one another and the data transfer has to be performed efficiently and smoothly as possible.
He/ She should manage the execution of the technologies, help the businesses in utilizing the systems, and should be well versed with the basics of computer systems such as Networking, Installation of necessary software and hardware.
Ability to determine the interrelationships between solutions and requirements.
Ability to think analytically and should be a problem solver and logic building should be very strong.
Good interpersonal skills to form effective working relationships with people at all levels.
Excellent communication and presentation skills and strong written & oral English skills.
To know more about us visit us www.sspl.net.in or write to us at admin@sspl.net.in",-1,Substratal Solutions,Connaught Place,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1260,Artificial Intelligence Scientists,"Experience 2- 4 Years
Salary 4 LPA - 6 LPA
Job Location Chennai

Industry:
IT-Software / Software Services

Keywords:
Artificial Intelligence

About Job:
Must have Excellent knowledge in AI / Machine learning (Mandatory).
Machine learning frameworks like keras, tensor flow etc.
And also other big data tools like Hadoop etc, Must know R and python.
Good understanding in SDLC & Business cycle.",4.0,"Careerera
4.0",Chennai,"Wayland, MA",501 to 1000 employees,-1,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
1261,Senior Data Engineer,"About Us

upGrad is an online education platform building the careers of tomorrow by offering the most industry-relevant programs in an immersive learning experience. Our mission is to create a new digital-first learning experience to deliver tangible career impact to individuals at scale. upGrad currently offers programs in Data Science, Machine Learning, Product Management, Digital Marketing, and Entrepreneurship, etc. upGrad is looking for people passionate about management and education to help design learning programs for working professionals to stay sharp and stay relevant and help build the careers of tomorrow.
upGrad was awarded the Best Tech for Education by IAMAI for 2018-19
upGrad was also ranked as one of the LinkedIn Top Startups 2018: The 25 most sought-after startups in India
upGrad was earlier selected as one of the top ten most innovative companies in India by FastCompany.
We were also covered by the Financial Times along with other disruptors in Ed-Tech
upGrad is the official education partner for Government of India - Startup India program
Our program with IIIT B has been ranked #1 program in the country in the domain of Artificial Intelligence and Machine Learning
About the Role

We are looking for a Data Engineer to help us scale the existing data infrastructure and in parallel work on building the next generation data platform for analytics at scale, machine learning infrastructure and data validation systems.
In this role, you will be responsible for communicating effectively with data consumers to fine-tune data platform systems (existing or new), taking ownership and delivering high performing systems and data pipelines, and helping the team scale them up, to endure ever growing traffic.
This is a growing team, which makes for many opportunities to be involved directly with product management, development, sales, and support teams. Everybody on the team is passionate about their work and we’re looking for similarly motivated “get stuff done” kind of people to join us!

Roles & Responsibilities
Engineer data pipelines (batch and real-time ) that aids in creation of data-driven products for our platform
Design, develop and maintain a robust and scalable data-warehouse and data lake
Work closely alongside Product managers and data-scientists to bring the various datasets together and cater to our business intelligence and analytics use-cases
Design and develop solutions using data science techniques ranging from statistics, algorithms to machine learning
Perform hands-on devops work to keep the Data platform secure and reliable
Skills Required
Bachelor's degree in Computer Science, Information Systems, or related engineering discipline
6 + years’ experience with ETL, Data Mining, Data Modeling, and working with large-scale datasets
6+ years’ experience with an object-oriented programming language such as Python, Scala, Java, etc
Extremely proficient in writing performant SQL working with large data volumes
Experience with map-reduce, Spark, Kafka, Presto, and the ecosystem.
Experience in building automated analytical systems utilizing large data sets.
Experience with designing, scaling and optimizing cloud based data warehouses (like AWS Redshift) and data lakes
Familiarity with AWS technologies preferred
Qualification – B.Tech/M.Tech/MCA(IT/Computer Science)

Years of Exp – 6-9",3.5,"upGrad Education Private Limited
3.5",Mumbai,"Mumbai, India",501 to 1000 employees,2015,Company - Private,Education Training Services,Education,₹1 to ₹5 billion (INR),"Udacity, General Assembly, Springboard"
1262,BBRC-Genomics-Associate Scientist,"JOB DESCRIPTION

Designation: Associate Scientist

Job Location: Bangalore

Department: Translational Medicine- Translational Sciences

About Syngene

Incorporated in 1993, Syngene International Ltd. is an innovation-focused global discovery, development and manufacturing organization providing integrated scientific services to the pharmaceutical, biotechnology, nutrition, animal health, consumer goods and specialty chemical industries around the world. Syngene’ s clientele includes world leaders such as Bristol-Myers Squibb, Baxter, Amgen, GSK, Merck KGaA and Herbalife. Its innovative culture is driven by the passion of its 4240- strong team of scientists who work with clients from around the world to solve their scientific problems, improve R&D productivity, speed up time to market and lower the cost of innovation .

Job Purpose:
To play a key role in TM-TS, develop an early-stage research strategy, initiate and lead discovery programs while managing ongoing programs in TM-TS. The role will work part of TMTS, and work with internal and external collaborators .

Key Responsibilities:
Experience in isolating DNA and RNA from blood, tissues and FFPE samples and cell lines. Experience with optimization of extraction protocols and for parameters like yield, input sample quantities and sample types is important.
Expertise in PCR, qPCR, cDNA/gDNA library preparation. Exposure to microarray techniques.
Proficiency in preparation of libraries for Next Generation Sequencing of transcriptome and genome, with significant experience in optimization of parameters like input RNA/DNA quantities and sample type
Experience with single cell RNA-seq will be plus.
Experience with various NGS protocols (DNA Amplicon based, hybrid capture based low input, degraded DNA and RNA samples e.g. FFPE samples.
Strong understanding of experimental design and statistical principles behind experimental design and differential gene expression. Experience with analysis of single cell RNA-sequencing data will be a plus

Educational Qualification:
M.Sc or M. Tech in Biotechnology, Molecular biology or Biological Sciences,

Technical/functional Skills:
DNA/ RNA Isolation, Expertise in PCR, qPCR, Experience in NGS protocols

Experience:
2 to 5 Years

Behavioral Skills:
A proactive team player.
Ensure completion of experiments and generate accurate and reproducible data from experiments.
Ability to work independently, prioritize tasks and work on multiple projects simultaneously with; comfortable working in a dynamic environment with changing requirements.
Good oral and written communication and presentation skills to work in a multi-disciplinary team
Equal Opportunity Employer:
It is the policy of Syngene to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by applicable legislation or local law. In addition, Syngene will provide reasonable accommodations for qualified individuals with disabilities.",3.5,"Syngene
3.5",India,"BENGALURU, India",1001 to 5000 employees,1994,Unknown,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1263,Applied Scientist 1,"Position Requirements:
Master's degree in Computer Science, Computer or Electrical Engineer, Mathematics, or a related field plus at least one year of experience in the job offered or related occupations of Software Engineer, Software Developer, or a related occupation. Employer will accept a Bachelor’s degree and five years of experience in the job offered or a related occupation as equivalent to the Master’s degree and one year of experience. One year of experience in the job offered or related occupation must involve designing and developing large-scale, multi-tiered, distributed software applications, tools, systems and services using Java, Object Oriented Design and Distributed Programming].

Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, Oracle/Berkeley databases, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills

Amazon Selling Partner Services team drives the Selling On Amazon business and develops solutions that enable millions of sellers around the world to sell on Amazon's Marketplaces. More than half of shipments for Amazon customers are generated from this business. The team is focused on building a technology platform that will support the explosive business growth in existing markets, streamline the business for Amazon and the Selling partners and launch business in new markets and establish a fair marketplace.

Our team is seeking engineers with broad technical skills to help us optimize how we synthesize massive amounts of data and complex business rules into mission critical financial information. As a member of this team you will employ object oriented techniques in Java, and DynamoB, PostGres and ElasticSearch skills to help us support Amazon's next generation of selling partner services. Along the way you'll gain and leverage a unique understanding of how Amazon.com works; from the numerous software systems that comprise the website's back-end, to the details of our business model, and the relationships we're establishing with an ever-growing network of selling partners who depend on Amazon.com to run their businesses.

The ideal candidate will draw upon exemplary analytical, critical thinking, and problem solving skills, and a passion for maintaining highly reliable, distributed systems which operate 24/7/365. Successful members of this team collaborate effectively with internal end-users, aggressive cross-functional software development teams, and technical support/sustaining engineering teams to solve problems and deliver successfully against high operational standards of system availability and reliability. We look for engineers who are excellent communicators, self-motivated, flexible, hardworking, and who like to have fun!

Position Responsibilities:
Participate in the design, development, implementation, testing and documentation of large-scale, multi-tiered, distributed software applications, tools, systems and services using [Java, Object Oriented Design and Distributed Programming]. Translate functional requirements into robust, scalable, supportable solutions that work well within the overall system architecture. Participate in the full development cycle, end-to-end, from design, implementation, and testing to documentation, delivery and maintenance. Produce comprehensive, usable software documentation. Evaluate and make decisions around the use of new or existing software products and tools.

Preferred Qualifications
Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1264,Senior Clinical Data Analyst,"About Novotech:

Novotech is internationally recognised as the leading independent and full-service contract research organisation (CRO) in the Asia Pacific region. We provide a wide range of clinical development services across all research phases and therapeutic areas and have been instrumental in the success of hundreds of Phase I – IV clinical trials throughout the Asia Pacific. Powered by the highest quality people, Novotech strives to set the benchmark for both business and clinical trial performance. Our people are one of our key strengths. We value our people and recognise the work they do. We are lucky to have the best people and talent from across the Asia Pacific region work together to deliver to clinical trial success for our clients. Our people and those we look to recruit have an attitude of making things happen. They are problem solvers, driven with a focus on delivering quality, accountability and a high level of performance.

Brief Position Description:

As part of Novotech’s Biometrics unit, the Senior Data Analyst (SDA) is responsible for all data analysis and business intelligence activities related to study related clinical and operational data. The SDA acts as primary point of contact for all data analysis matters to the study team and is responsible for the timely delivery of quality outputs following all applicable regulatory, compliance, best practice and operational procedures.

Minimum Qualifications & Experience:

Graduate in information science, data science or life science-related field, or similar. More than five years’ experience in a senior role related to data science, data analysis, clinical data management or clinical data programming in a pharmaceutical company, CRO or EDC software provider.

Responsibilities
The Senior Data Analyst (SDA) is responsible for providing technical, procedural (SOPs) and planning leadership across multiple projects assigned to the data analyst team members ensuring that they deliver in accordance with SOPs, programming best practices, and the timelines agreed within the Project Team.
Collaborate with cross-functional stakeholders to implement data science solutions to solve business needs using available technological solutions.
Scope data analysis effort for projects and project manage all data analysis activities across multiple projects for different study stakeholders.
Gather study requirements from data management for data review and external data reconciliation and provide guidance on appropriate outputs (dashboards, visualisations, listings, reports).
Extract, assess, integrate, transform data sources to provide data visualisation outputs for analytics.
Design and develop prototypes and final versions of data outputs (dashboards, reports, visualisations, listings) using Business intelligence tools and Data Visualisation tools.
Design and develop standard dashboards and content for different audiences.
Analyse, manipulate and understand data from multiple sources to present and create dashboards and reports to make business decisions.
Assist teams on best-practice for data visualisation dashboard development.
Educate teams on how to use all the features of applicable data visualisation platform in conjunction with data visualisation dashboards.
SME for the data visualisation development and assisting team members.
Identify and communicate project risks and maintain documentation within project files as appropriate
Represent data analysis group at internal / external meetings as appropriate.
Assess and implement new data analysis, BI and data visualisation processes and technologies.
Take an active role in the development of best practices, process improvement, quality control and governance related to all data analysis matters.
Provide training and mentoring to Data Analysis of team members in SOPs, software applications, and best practices.
Provide Subject Matter Expertise on all data analysis and visualisation related activities.
Attributes and Skills

Expert knowledge of clinical study data structures and schemas of EDC databases. Expert knowledge in data processing activities such as extracting, integrating, transforming and presenting data. Statistical Programming skills in Python, R or similar. Knowledge of SQL and EDC systems. Working knowledge of Spotfire, Power BI, Tableau or other data review and visualisation tool. Ability to gather business requirements from multiple stakeholders and clients and provide guidance on the use of appropriate data visualisations.

Experience mentoring and training others. Awareness of regulatory and compliance issues and understanding of the application of SOPs and Quality Control to daily activities. Excellent analytical, communication and problem-solving skills.

Opportunities and Benefits:

To deliver clinical trial and research excellence for our clients, our people are 'best in class'.

At Novotech, we seek and nurture people with exceptional talent. We are committed to providing our people with regular internal and external training, a competitive bonus structure and a supportive work environment. We are also focused on providing our people with a wide variety of career growth and development opportunities.

For more information about where your next career step at Novotech might take you, visit http://novotech-cro.com/novotech-careers",4.5,"Novotech
4.5",Bengaluru,"Sydney, Australia",501 to 1000 employees,1996,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
1265,Data Engineer,"Data Engineer Responsibilities:
Liaising with coworkers and clients to elucidate the requirements for each task.
Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed.
Reformulating existing frameworks to optimize their functioning.
Testing such structures to ensure that they are fit for use.
Preparing raw data for manipulation by Data Scientists.
Detecting and correcting errors in your work.
Ensuring that your work remains backed up and readily accessible to relevant coworkers.
Remaining up-to-date with industry standards and technological advancements that will improve the quality of your outputs.
Data Engineer Requirements:
Bachelor's degree in Data Engineering, Big Data Analytics, Computer Engineering, or related field.
Master's degree in a relevant field is advantageous.
Proven experience as a Data Engineer, Software Developer, or similar.
Expert proficiency in Python, C++, Java, R, and SQL.
Familiarity with Hadoop or suitable equivalent.
Excellent analytical and problem-solving skills.
A knack for independent and group work.
Scrupulous approach to duties.
Capacity to successfully manage a pipeline of duties with minimal supervision.
Job Type: Full-time

Salary: ₹360,000.00 to ₹870,000.00 /year

Experience:
total work: 2 years (Preferred)
Data Engineer: 1 year (Preferred)
Education:
Diploma (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,Futurious Technologies,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1266,Quantitative Analyst,"The successful candidate will be a highly analytical individual with hands on programming skills. The candidate will work closely with the research team and clients towards the ongoing development and integration of new investment strategies, models and tools on Axle

Location

Mumbai
Responsibilities

Perform daily/weekly/monthly tasks of performance and risk reporting
Develop and automate investment processes and strategies via VBA and Matlab
Develop tools to integrate trading decision systems with risk management systems
Ad hoc tasks (such as operational tasks, internal documentation tasks and preparation of marketing materials)
Skills/Experience

Excellent programming skills in Matlab/Excel-VBA
Thorough with financial concepts and calculations like Drawdown, VaR, Eloss etc.
Understanding of financial market products like options, futures, FX forwards etc.
Working knowledge of Bloomberg is preferred
Should be self-driven and detail oriented with an analytical mindset
Should be a proactive and quick learner; a team player showing enthusiasm and drive to accomplish results in a fast paced environment
Min. 2 years of relevant work experience
Qualifications

B.Tech/M.Tech/MBA/CFA/FRM",5.0,"B&B Analytics
5.0",Mumbai,"Zug, Switzerland",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1267,Analyst - Data Scientist,"Job Summary

Experience:
3 - 5 Years

Location:
Mumbai

Designation:
Analyst - Data Scientist

Degree:
BE-Comp/IT, BE-Other, BTech-Comp/IT, BTech-Other, ME-Comp/IT, ME-Other, MTech-Comp/IT, MTech-Other, PhD-Comp/IT, PhD-Other

Educational Level:
Graduate/Bachelors

Industrial Type:
IT-Software/Software Services

Functional Area:
IT Software - Application Programming / Maintenance

Key Skills:
Data Scientist

Job Post Date:
Thursday, March 19, 2020

Company Description

We are capability centre based in Mumbai, initially started as a back-office operational support to the UK business unit.

However, over the recent years, we have significantly increased the breadth and depth of our capabilities and offerings to keep pace with the changing needs of the Group. These include Digital & Knowledge Services, Finance and Actuarial, Information Technology (IT), Customer Service, Risk and Audit.

Our core purpose is to be a strategic partner to company, enabling growth by delivering change and driving synergies through a highly capable and agile workforce.

With our diversified service offerings we provide our people with exciting opportunities to grow personally and professionally.

Company is a leading savings and investments business serving around 5.5 million retail customers and more than 800 institutional clients.

It-s innovative asset management and customer solutions are supported by extensive investment capabilities, an international distribution network and two strong brands.

Job Description

3 – 5 yrs experience as Data Scientist
Should have at-least 1 end-to-end ML project experience
Very high proficiency in R or Python
Excellent in forecasting methods like simple exponential smoothing, multiplicative seasonal indexes, simple and weighted moving averages and time series forecasting methods
Exposure to with advanced deep learning techniques such as LSTM. CNN, Dense neural networks as well as neural networks design and implementation through tools like tensorflow, keras, pytorch, deepai or equivalent.
Good SQL experience",3.8,"Sampoorna Computer People
3.8",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
1268,Data Lake Developer,"For Us, It's A Mission

At Mylan, we mean it when we say we work every day to provide access to high quality medicines to the world's 7 billion people. If you are unconventional, relentless and passionate. If you believe in doing what's right, not what's easy. If you are a doer and have a passion for serving others, we want to talk to you.

Make a Difference

At Mylan, each person has the ability to make a difference. From the providers who sell and market our products, to the producers who develop and manufacture them and finally to our business partners who support the providers and producers, we all have a mission critical role. Here's how this role will help:

ESSENTIAL DUTIES AND RESPONSIBILITIES
To perform this job successfully, an individual must satisfactorily perform each essential duty. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential duties.
1. Create and maintain optimal data pipeline architecture on Azure platform.
2. Develop batch processing solutions by using Data Factory and Azure Databricks.
3. Delivering a Data Warehouse in the Azure Cloud.
4. Design relational and non-relational data stores on Azure.
5. Identify, design, and implement internal process improvements : automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc..
6. Developing Big Data Solutions with Azure Machine Learning.
7. Strong interaction with business departments to provide consultative support for digitization efforts, as well as close collaboration with the Business Technology management, focused on future innovation topics.
8. Participate and lead in design sessions, demos and prototype sessions, testing and training workshops with business users and other IT colleagues.
9. Design & Build for any API Development or SQL DB development.
10. Providing service management, orchestration, monitoring and management requirements of Azure cloud platform.
11. Create data tools / products for analytics and data scientist team members that assist them in building and innovative solutions that drive tangible business value.
12. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
13. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
14. Design security for source data access. Chose the appropriate authentication mechanism, (ie Azure Active Directory (Azure AD), etc).
15. Design for real-time processing by using Stream Analytics and Azure Databricks.

Make Our Values Your Values

Mylan hires only the best. People who thrive in a culture of innovation and empowerment. People who are active learners and have a positive attitude. People who are leaders and know that by working together we can run faster, reach higher and achieve more. By doing so, we will continue to set new standards in health care. Here are the minimum qualifications and essential functions for this position:

QUALIFICATIONS

The qualifications listed below are representative of the minimum knowledge, skill, and/or ability required.

SKILLS AND ABILITIES

1. 10 years of experience in Microsoft technologies including SQL.

2. At least 5 years as a Sr Developer with at least 3 years hands on experience as Azure Data Engineer building large scale Azure data solutions.

3. At least 5 years of experience in Azure based data solutions.

4. At least 3 years of experience on working with large projects including the most recent project in the cloud (Azure) or on prem with a focus on Azure Data services.

5. At least 5 years of Hands-on administration, configuration management, monitoring, performance tuning of Hadoop/Distributed platforms.

6. At least 5 years of demonstrated experience at least in the most recent 2 years of designing and delivering solutions using Cortana Intelligence suite of analytics services part of Microsoft Azure including Azure Machine Learning Studio, HDInsight, Polybase, Azure Data Lake Analytics, Azure Data Warehouse, Streaming Analytics, Data Catalog, R/R Studio

7. Experience in designing and building logics required for optimal extraction, transformation, and loading of data from a wide variety of data sources

8. Experience within Data Security design, including but not limited to:

a. Choosing the appropriate authentication mechanism, such as Azure Active Directory (Azure AD)

b. Defining strategies for data encryption for data at rest and in transit

9. Experience partnering with Business Analysts and Data Scientists to enable effective and efficient data preparation and delivery

10. Experienced in vendor management and working with 3rd parties onshore & offshore.

11. Experience working in a global team.

12. Experience working in an Analytics / Big Data solutions on MS Azure Cloud

13. Experience with code management tools, automated testing

14. Experience creating and maintaining optimal data pipeline architecture on Azure platform

15. Experience developing batch and real-time processing solutions by using Data Factory and Azure Databricks

16. Familiar with AGILE and Azure DevOps methodology

17. Hands on PoC capabilities are needed to prove a particular architecture concept

18. Azure Native Services experience across Data Fabric and Service Fabric

19. Experience in Application modernization from legacy on-premise data architecture platform technology stack to modernized Azure Cloud base Architecture.

20. Experience with Git, NoSQL Data Solutions, Microsoft Azure, HD Insights, Azure ML, DataBricks ML Flow, R or Python.

21. Must have excellent communication skills.

EDUCATION/EXPERIENCE (Note: Please select one)

Minimum of a Bachelor's degree in Computer Science and Engineering is preferred with minimum 10 years of experience. However, a combination of experience and/or education will be taken into consideration

Why Mylan?

If you want to be part of a global health care company that is making a difference and changing lives, Mylan may be the place for you. With a workforce of more than 35,000 worldwide, we can make a difference. We encourage you to visit Mylan.com to learn more about our unconventional culture, our approach to doing business and how we plan to set new standards in health care.

Mylan offers competitive salary, excellent benefits and an environment conducive to professional growth and advancement. All qualified applicants will receive consideration for employment without regard to their disability or protected veteran status. Mylan is an Equal Opportunity Employer, Minorities/Female/Disabled/Veteran.",3.8,"Mylan Inc.
3.8",Bengaluru,"Hatfield, United Kingdom",10000+ employees,1961,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1269,Off Campus Recruitment - Quantitative Researcher,"Description:
Graviton is a privately funded quantitative trading firm striving for excellence in financial markets' research. We are seeking fresh talent from the top IIT's to join us as Quantitative Researchers for our team in Gurgaon.If you are a student graduating in 2020 from Computer Science , Electrical or Maths Stats Computing streams with a greater than 8 CGPA please apply here.

This role is open to students from campuses that we could not visit this year. Please check your individual placement policy restrictions before applying.

Graviton trades across a multitude of asset classes and trading venues using a gamut of concepts and techniques ranging from time series analysis, filtering, classification, stochastic models, pattern recognition to statistical inference analysing terabytes of data to come up with ideas to identify pricing anomalies in financial markets.

As a Quantitative researcher your responsibilities will include

Develop new or improve existing trading models using in-house platforms

Use advanced mathematical techniques to model and predict market movements

Analyse large financial datasets to identify trading opportunities

Provide real time analytical support to experienced traders

Requirements :
Possess a degree in a highly analytical field, such as Engineering, Mathematics, Computer Science from IITs schools

Quantitative bend of mind

A working knowledge of Linux/Unix

Programming experience, preferably in C++ or C

Strong interest in learning about financial markets.

Have a strong work ethic

Hard Working

Benefits:
Our open and casual work culture gives you the space to innovate and deliver. Our cubicle free offices , disdain for bureaucracy and insistence to hire the very best creates a melting pot for great ideas and technology innovations. Everyone on the team is approachable, there is nothing better than working with friends!

Our perks have you covered.

Competitive compensation

6 weeks of paid vacation

Monthly after work parties

Catered breakfast and lunch

Fully stocked kitchen

Gym membership

International team outing",5.0,"Graviton Research Capital LLP
5.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2014,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1270,Data Engineer,"Zauba Technologies is a startup based in Bangalore. Zauba's services are used by leading companies in India. Zauba is powered by a young and passionate team. We are looking for individuals who would like to be a part of our founding team.

As a Data Engineer and as a part of founding team, you will be expected to visualise and develop disruptive data products. Eventually you would be responsible for entire project lifecycle of products you would visualize. Your rewards will be directly proportional to the value you generate.

Job Responsibilities
Design and development of robust, scalable and highly efficient data engineering solutions for structured and unstructured data (Including gathering and processing raw data at scale, writing scripts, web scraping, calling APIs, writing SQL queries, etc.)
Develop processes for text mining and extraction of information from unstructured data
Design, architect and develop efficient data pipelines around the data collected
Take ownership of existing web product and applications
Design and implement data models that scale across the enterprise
Take ownership of existing data workflows and processes
Enhance scalability, performance, and stability of existing infrastructure
Work closely with other team members to integrate your innovations and algorithms into our production systems

Essentials
Java/Python - Intermediate to advanced level
SQL - Advanced
MySQL Intermediate to advanced level
Regex - Basic to intermediate level
Linux Basic to intermediate level

Good to have
Hadoop/Spark
R
MongoDB

Must have qualities
Skills to learn new skills quickly
Desire to create disruptive products and services
Passion - not just to work in startups but to take them to next level
Above average programming aptitude
Be passionate about producing high quality engineering deliverables
Be productive working independently or collaboratively
Have an eye for building efficient processes
Be self motivated
Proactively take ownership

Interested?

Send your resume to hr@zaubacorp.com",3.8,"Zauba Corp
3.8",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 million (INR),-1
1271,Quantitative Research,"We are looking for highly trained professionals who are interested in applying advanced mathematical quantitative methods to the modeling of global financial markets. You would be joining a group made up of highly proficient individuals from various scientific disciplines. We have a spectrum of opportunities for individuals with the right scientific skills. Experience in finance is not required.

The ideal research candidate will have:
A Ph.D. in Computer Science, Mathematics, Physics, Statistics, or a related technical discipline.

A demonstrated capacity to do first-class research.

Computer programming skills.

An intense interest in applying quantitative analysis to solve difficult problems.

Send us a copy of your resume to
careers@dolatcapital.com

For internship opportunities, please send us a copy of your resume to
careers@dolatcapital.com",4.0,"Dolat Capital
4.0",Mumbai,"Mumbai, India",51 to 200 employees,1970,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1272,Data Engineer,"Bachelor’s degree in Computer Science or related field
5+ years relevant experience
5+ years experience with SQL, SQL Tuning, Oracle, OLAP, Big Data Technologies
5+ years experience developing end-to-end Business Intelligence solutions: data modeling, ETL and reporting
Experience with Java and experience with scripting languages like Perl, Python, Unix shell scripts,VBA and MS Excel
Proficiency with Linux and systems administration
Proven ability at looking at solutions in unconventional ways. Sees opportunities to innovate and can lead the way.
Top notch communication (verbal and written) and interpersonal skills to convey key insights from complex analysis in summarized business terms and an ability to effectively communicate with technical teams.
Ability to work with shifting deadlines in a fast paced environment.
Operations Finance Technology team, responsible for building technical solutions for multi-billion WW Operational Cost analytic including Inbound cost (Receiving / PO), variable Cost, fixed cost, outbound (Customer Shipments / Transportation), and Customer Service, is looking for a Data Engineer.

As a data engineer, you will get the exciting opportunity to work on very large data sets in one of the world's largest and most complex data warehouse environments. You will work closely with the business teams in analysis on various cost savings initiatives, many non-standard and unique business problems and use creative-problem solving to deliver actionable output.
You will be responsible for designing and implementing an analytical environment using third-party and in-house reporting tools, modeling metadata, building reports and dashboards. You will have an opportunity to work with leading edge technologies like Redshift, Hadoop/Hive/Pig. You will be writing scalable queries and tuning performance on queries running over billion of rows of data.

You should be analytical, have an extremely high level of customer focus and a passion for process improvement. You should be motivated self-starter that can work independently in a fast paced, ambiguous environment. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions.
Bachelors in Computer Science or related field
Practical Knowledge of Linux or Unix shell scripting
Experience in working with business customers to drive requirements analysis
Exposure to large databases, BI applications, data quality and performance tuning
Excellent written and spoken communication skills
Experience with Hadoop-based technologies such as HBase, Pig, Hive and Spark
Strong proven ability in building high-performance, highly available and scalable data solutions using Oracle and/or Hadoop-based technologies
Knowledge of data warehousing concepts.
Strong sense of ownership, urgency, and drive
Strong troubleshooting and problem solving skills
Experience with Amazon Web Services",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1273,DATA ANALYST,"posted by Mahima Gaur

2 - 5 years Delhi

Job Description
Experience in data processing
Experience in data cleaning and data tabulation activities
Strong analytical, communication and team management skills
Strong understanding of data management using SPSS and research techniques
Competency in a Tabulation software (decipher / wincross / quantum etc), Excel, Powerpoint
Ability to summarize findings, draw conclusions, and put together a presentation using Powerpoint
Role Category : Data Analyst

Employment Type : Permanent Job, Full Time",4.9,"Knowledge Excel Services.
4.9",New Delhi,"New Delhi, India",1 to 50 employees,2007,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
1274,Data Engineer,"Key skills : Python , Spark , SQL , Pyspark • AWS platform used for the work • Strong experience in SQL is mandatory • Good familiarity of AWS landscape • Good experience in collecting business requirements & design them as per requirement from customer • Should able to work independently & interact business users & technical stakeholders • Strong communication skills both oral & written. • Should work as an individual resources",3.5,"Larsen & Toubro Infotech Limited
3.5",India,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1275,Big Data Engineer,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
1276,Client Data Analyst,"At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.
What is the Client Data Analyst – Client Analytics group responsible for?
This team manages business data to ensure accurate, timely, consistent and compliant data. Their contributions deliver quality data that is easily accessible and can be trusted. Key downstream capabilities such as reporting and analytics depend on this as well as operational data access on various systems. The Data Management Team is a support function that acts as an advocate and a point of contact for Sales and Marketing data.

What are the ongoing responsibilities of an Client Data Analyst ?
Understand the data flow, key consumption and production of data as well as context within the enterprise:
Build positive relationships with teams, especially the key data consumers and analytics. Take the time to increase knowledge of how they run their business and incorporate sales data into daily work
Connect regularly with each sales office to understand current issues and challenges. Probe the business and validate against other sales offices to understand the scope and priority of the issue
Make recommendations on how data unifications and flow can be used to improve business tasks. Liaise business partners to deliver solutions (reports, processes, technology) that add value.

Provide data management subject matter expertise. Appreciate the connection and data flow between applications and other corporate systems. Be able to clearly articulate the data needs and move initiatives forward by collaborating with business partners:
Actively participate in meetings with business partners to ensure that priorities are clearly understood, information is regularly shared and that key participants are “kept in the loop”
Provide context and background on issues. Collaborate on ideas for progressing initiatives. Ensure appropriate resources are involved to take initiatives forward
Provide insights and expertise to scope statements and requirements documentation
Actively consult or participate in the user acceptance testing process (test cases, documentation, testing execution, etc.)
Ensure business needs remain aligned with overall corporate initiatives and deliver the benefits as originally intended

Monitor the integrity of data and usefulness of reports. Ensure the information available within systems is accurate and up-to-date. Proactively seek data cleansing opportunities and evolve data to better support. Document and maintain ongoing processes for reporting and data clean-up:
Partner with all key data consumers to gain a solid understanding of usage and challenges around data. Establish processes for prioritization of enhancements, especially with the analytics groups
Provide 1st level support for data issues and data maintenance for owned data
Verify and execute data loads into our internal sales systems and ensure any upstream systems accurately receive their data

Increase awareness and promote data management capabilities. Share best practices and provide coaching to local offices on how to access and incorporate output into sales tasks. Encourage IAS leaders to leverage data to make more informed, strategic decisions:
Clearly articulate the goals and core services of the data management team. Proactively promote this information within IAS and ensure business partners understand the data management role within the organization
Share best practices and provides guidance on data capabilities. Reinforces ownership and accountability for data accuracy
Seek opportunities to share the benefits of leveraging sales data to make more informed business decisions

What ideal qualifications, skills & experience would help someone to be Successful?

Knowledge, Education And Experience:
Four year bachelor’s degree required (majors of preference include: business, computer science, mathematics) Advanced degree a plus
Understanding of the Franklin Templeton business model, how FT makes money, the sales process, how technology fits in with the business, etc. Knowledge of the GAS (Global Advisory Services) structure
Experience working through multiple business fiscal cycles; exposure and/or direct experience with project management and/or sales-related-capacity required
Prior work experience related to analytics, sales, marketing and/or international a must. Level will not be granted based on years of experience but will be determined by the employee’s ability to meet each job activity as outlined the ‘typical/expected focus by level
Skills And Abilities:
Ability to communicate effectively with all levels of management; ability to tailor communication style based on audience; ability to get others to want to collaborate with you; strong facilitation skills
Excellent writing skills (for presentations, documentation, etc.)
Working knowledge of the CRM, MDM, Excel, SQL, Power BI, Tableau, Business Objects, and Microsoft Products (PPT, Power Apps, Doc, Visio)
Ability to absorb and interpret large quantities of data; apply trend analysis and knowledge of the business to develop a meaningful and digestible summary with the appropriate level of detail
Ability to take a larger problem and break down the individual components; identify how to go about solving the problem and who to involve in the process
Ability to present recommended solutions to a variety of issues and problems (solutions that are consistent with organization objectives)
Must be extremely detail-oriented (managing lists, tasks/to-dos, etc.) good with follow through on own items; good with following up with others on outstanding item

What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.

Highlights of our benefits include:

Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.",3.8,"Franklin Templeton Investments
3.8",Hyderabad,"San Mateo, CA",5001 to 10000 employees,1947,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Fidelity Investments, Vanguard"
1277,Data Analyst,"Roles and Responsibilities:
Extracting, transforming and inputting data sets from various resources. Creating predictive models, translating non-technical aspects into quantifiable tasks. Analysis and representation of output data, highlight and explain trends and patterns, error elimination, using advanced statistical methods (regression, probability distribution, clusters etc.) to provide accurate results.
Data collection, Data Mining, Report generation, Problem identification and solution formulation Market analysis and establishing trends, Strategy development and implementation

Skills:
Extremely good analytical skills.
Good working knowledge of all MS-Office products, especially Advance Excel, Word, PowerPoint, MS-access.
Statistical tools and methods.

Interested candidates can send the updated resume on satish.mehra@exelaonline.com or call on 7722028636
00-7.00 Years",2.6,"Exela Technologies
2.6",Pune,"Irving, TX",10000+ employees,2017,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"SourceHOV, BancTec, Transcentra"
1278,Data Modeler,"• Minimum 5-8 years of working experience as Data modeler.
• Data modelling experience in designing.
• Minimum 2-3 years real time experience in Erwin tool is mandatory.
• Experience in normalized modeling techniques.
• Experience in designing the Start schema.
• Experience working in ORACLE.
• Experience with database design, capacity planning, performance tuning and query optimization.
• Experience in working with Bank or Banking and Finance or Financial domain.
• Excellent communication skills with leadership quality.

Job Segment:
Database, Oracle, ERP, Technology",3.5,"LTI
3.5",Mumbai,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1279,Machine Learning Engineer,"Looking for Data Scientists with Python/R Programming skills.
Specific experience in AI areas like Statistical Machine learning / Deep learning / Natural Language Processing (NLP)/ Operations Research (Optimization) will be an advantage.Individual in this role is expected to work with multiple stakeholders and teams

Qualifications and Requirements:-
Previous working experience as a Machine Learning/ Data Scientist for 2 years
MA in Computer Science or similar relevant field
Hands on experience with MALLET
In depth knowledge of Apache Tomcat/Open Source
Excellent project and time management skills
Attention to detail
Outstanding problem solving and analytical skills",-1,Tekolutions.ai,India,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1280,Data Science Internship,"About the company:
SkillBit is a leading staffing and recruitment company engaged in talent searching assignments for skilled and talented candidates for the industry.

About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Working on data science algorithms and AI concepts 2. Using Python or R for web scraping 3. Building AI models using Python, machine learning, and deep learning algorithms 4. Processing of unstructured/structured data

Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 6th Jun'20 and 11th Jul'20
are available for duration of 1 month
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply

Number of internships/jobs available: 3

Categories: Data Science",-1,SkillBit,Pune,-1,-1,-1,-1,-1,-1,-1,-1
1281,Data Engineer,"As a data engineer at TEAL, you'll be taking the plunge into a rich data lake that includes everything from satellite data to legal court orders. You'll be hustling and getting your hands dirty with every part of the data pipeline always having an implicit appreciation for how all of this data will ultimately power a revolutionary real estate risk platform.

Your day-to-day will include either all or some of the following:

Constantly scoping out new data sources to complement existing ones
Creating and maintaining distributed web scrapers using Python, RabbitMQ and other technologies
Architecting and managing data pipelines where data flows into multiple end-points including, but not limited to, Postgres, MongoDB and Apache Solr
Documenting workflows and constantly iterating to create better data infrastructure.

We'd love it if you:
Are proficient in Python or any other object-oriented language
Have worked with large (millions to hundreds of millions of rows in a SQL database) interdisciplinary datasets
Have scraped difficult websites and have some experience working with various data APIs
Are patient and methodical with unstructured and messy data
Are always hungry to learn newer and better technologies to make the data ecosystem faster, smoother and less silo-ed

Extra brownie points if you:
Have some experience working with large-scale search indexing
Have performed geospatial analyses in some capacity
Have created and managed data lakes in the cloud
Culture

To explore our culture and the values we embody click here

Testimonials
Testimonial

My experience at TEAL surpassed all my expectations from the get-go. I was asked to help solve one of the most daunting problems in the Indian real estate market. Every day while working on a subset of the problem, the ideas that I brought to the table were shaped into cohesive solutions by a collaborative team effort. At TEAL I was exposed to the most cutting edge technologies such as Cloud Computing, Big Data, ML and Data Science. The growth opportunities at TEAL are tremendous, If you are innovative and can demonstrate the will to realize your ideas, TEAL is an amazing organization to work for.
Gyan Vardhan, Data Science Intern
I had interned as a Data Scientist at Terra Economics and Analytics Lab during its early days, it was a rich learning experience working with a multi-disciplinary team who are extremely passionate about building a decision support platform for the insanely complicated realty market in India. It was exciting and challenging to work on mining huge volumes of property records; extracting patterns from the data, building data pipelines and brainstorming on building the core system. TEAL offers a very healthy work environment coupled with insanely talented people working together in an exciting setting.
Naga Anjaneyulu, Data Science Intern
I worked as a full-time Data science intern at TEAL. During this period, I got an opportunity to leverage my skillsets while also learning new technologies, working on tasks assigned to me. The company operates on the latest tech-stacks and gives opportunities to learn as much as you want. The work environment is challenging, the team at TEAL is super supportive and new ideas are always welcome. It has all the good perks of a startup; creativity and innovation, casual work atmosphere and a collaborative approach to solving problems. Personally, I loved working there, my experience was fantastic!
Archana Parmar, Data Science Intern
As a second-year college student, I was looking for an internship that would allow me to delve deeper into research and work with big data, TEAL gave me the perfect opportunity to do so, enabling me to develop proficiency in research and analysis. As a research analyst intern, I collated and cleaned data and helped in the preparation of reports and presentations, and I had members helping me at every stage of this process. This collaborative environment allowed me to cultivate my skills and also learn from my peers. The holy trinity of Rohan, Kshitij, and Shreyas served as not only excellent mentors and bosses but also as friends, helping me at every stage and giving us all food and ice cream to keep us going!
Arush Mehra, Research Intern
Internships are a crucial part of one’s early career. The internship experience at TEAL was a thrilling rollercoaster ride to say the least! It was more than implementing a standard model or building an already though out concept into reality. It was about finding the solution to a unique and open-ended problem.It was exciting to work on addressing a problem with far -reaching real world applications.Moreover, the work environment had the perfect balance of casual yet professional which kept you focused and stress free at the same time. Out of every 100 startups in India only 2 of them succeed, but there are very few like TEAL India which are bound to make it big at such an early stage.
Divyanshu Agarwal, NLP Intern",4.7,"Terra Economics & Analytics Lab (TEAL)
4.7",New Delhi,"Bengaluru, India",1 to 50 employees,2018,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
1282,Senior Consultant - ModellingOps Data Engineer,"Job Title: Senior Consultant - ModellingOps Data Engineer
Location: TRIL GTC
GCL: D1

JOB DESCRIPTION:

AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. The Science & Enabling Units IT is AZs global IT capability function supporting key business areas operating out of sites across the US, UK, Sweden, India & Mexico.

We are looking for AI Ops consultant who will leverage tools & technology best practices to improve delivery performance & data engineering capabilities in the D&A space.

ROLES & RESPONSIBILITIES:

7-10 years of experience in IT Operations involving Data Science, Artificial Intelligence-Machine Learning and Predictive Analytics. Experience in architecting and implementation of end-to-end AIOPs solutions through ELK stack, Splunk. Experience in applying statistical methods, analysis, pattern recognition and modeling on IT Operational data using ELK machine learning. Experience in extracting meaning full data from incoming data streams from different sources through RegEx, Grok etc. Hands-on experience in applying machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc in the IT Operation domain. Experience with machine learning and statistical programming languages - Python, R etc. Experience in assessing the existing IT environment and providing recommendations to reduce the critical applications impacting incidents. Experience in exploring and identifying areas where manual tasks can be automated in IT environment. Experience with various Enterprise IT monitoring solutions including Infrastructure monitoring, Application Performance Monitoring, Network Monitoring, Cloud monitoring etc. Experience in IT Service Management including Service Desk, Incident Management, Change Management, CMDB etc. Excellent knowledge on various IT infrastructure components that includes Server Infrastructure, middle ware, database and application architectures and Cloud Components. Experience/knowledge on Infra monitoring tools - NOI, Zabbix, AppDynamics, Datadog, SCOM, SolarWinds etc. and Service Management tools -IBM Control Desk, BMC Remedy, ServiceNow etc. Experience/Knowledge on BI tools Knowledge on distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc. Knowledge on other programming languages/scripting: Python, Java, JavaScript, etc. ( Added Advantage ) Good analytical skills, strong communication skills are must. Client facing experience is an added advantage. Excellent experience in understanding the problem statement, architect and designing the solution

MANDATORY SKILLS:
Significant experience with AWS cloud environments, working knowledge of Google and Azure platforms. Knowledge of Kubernetes, S3, EC2, Sagemaker, Athena, RDS and Glue is essential.
Experience provisioning computational resources in a variety of Cloud environments using Infrastructure as Code.
Experience with best practice of data transport and storage within cloud system.
Experience building large scale data processing pipelines. e. g. Spark and SQL.
Experience with containers and microservice architectures e.g. Kubernetes, Docker and serverless approaches.
Excellent working knowledge in DevOps, using continuous integration and continuous development.
Use of Data Science modelling tools e.g. R, Python, SAS and Data Science notebooks (e.g. Jupyter).
Good written and verbal skills, fluent English
DESIERED SKILLS:
Agile practices, especially being a SCRUM Master
EDUCATIONAL BACKGROUND: B.E/B.Tech/MCA

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",3.9,"AstraZeneca
3.9",Chennai,"Cambridge, United Kingdom",10000+ employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Roche, GlaxoSmithKline, Novartis"
1283,DATA ENGINEER,"JOB DESCRIPTION
As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements, and also research new uses for data acquisition. You should also know the ins and outs of the industry such as data mining practices, algorithms, and how data can be used.

DESIRED CANDIDATE PROFILE
An ideal candidate must possess prior experience leading a project.

Candidates must have:
> Experience in Hive, Spark, Scala, AWS DynamoDB, HBase, AWS Glue, Talend, Kafka, Snowflake ETL
> Strong experience in a BI/Data Warehouse environment with involvement in design, development, implementation, troubleshooting and support of ETL process using ETL tool.
> Experience in developing Data Marts, Data warehousing and Operational Data Store (ODS) on any of the databases or Hadoop environments.
> Experience in database like MS SQL, MySQL, Oracle, PostgreSQL
> Good to have programming experience in writing Complex Stored Procedures, Queries, Views, User Defined Functions, Cursors and Common Table Expressions using SQL or T-SQL.
> Experience in Performance Tuning and Query Optimization by Indexing, Partitioning and De-normalization.
> Experience in Developing a framework for ingesting data into Data lake
> Good database knowledge, analytical thinking
> Design, construct, install, test and maintain data management systems.
> Build high-performance algorithms, predictive models, and prototypes.
> Develop set processes for data mining, data modeling, and data production.
> Experience with cloud services: AWS (EC2, EMR, S3, Athena) and scripting languages like Python, /PySpark/R/SAS
> Install/update disaster recovery procedures.
> Experience in Agile Application Development & Scrum methodologies is preferred
> Ability to supervise and mentor junior developers on the team.
> Must be self-motivated and work well pulling people together in addition to being able to pull people together technically
> Demonstrated proficiency of troubleshooting techniques and detail-oriented problem diagnosis
> Ability to handle responsibility, is self-directed, with strong organizational and documentation skills
> Ability to work independently and efficiently under aggressive deadlines to meet project commitments
> Excellent verbal and written communication skills

EDUCATION
UG - B.Tech/B.E. - Computers, Electronics/Telecommunication, Diploma - Computers, Electronics/Telecommunication, B.Sc - Computers, BCA - Computers) AND (PG - M.Tech - Computers, Electronics/Telecommunication, MCA - Computers, M.Sc - Electronics, Computers) AND ( Doctorate - Any Doctorate - Any Specialization, Doctorate Not Required).

OTHER DETAILS
Number of vacancies: 4
Experience: 3 years
Location: Cochin

If you have a passion towards technology and coding, then we have the right job for you. Kindly forward your resumes to
Email: jobs@mjsofttech.com
Phone: 0484-2421245 / 928 720 7160",4.0,"MJ Softtech
4.0",Kochi,"Cochin, India",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
1284,Data Engineer,"Education/ Experience and Skill Requirement
4+ years of relevant experience in
Experience working with both relational and NoSQL databases.
Strong coding skills; Python (preferred) /R/Java/Scala
Experience in developing Data warehousing technologies Experience with AWS or equivalent cloud services preferred
Experience in BigData technologies (Hadoop, HDFS, MapReduce, Spark, Hive, HBase etc) will be valuable
Knowledge of Machine Learning a big plus (Random Forest, Decision Trees, SVM, NLP, Gradient Boosting, Supervised/Unsupervised Learning, Clustering, classification and regression modeling).
Responsibilities
Proficiency with several years’ experience in more than one of Python, R, Java, Scala, or robust Linux shell scripting
Implementation experience with data warehouse architecture & design, ETL design/development, and Analytics
Knowledge of general cloud architecture and cloud strategies especially around AWS services and concepts such as S3 object stores, RDS databases, EC2, Glacier, Lambda, IAM, enterprise security, data security, DevOps, replication and disaster recovery
Well versed with data mining & exploration, NLP and visualization
Understanding of data modeling, data integration, and data representation (metadata, OWL, ontologies)
Developing data marts and data management using SQL
Creating powerful visual outcomes
Independently manage daily client communication, especially over calls
Manage client deadlines, ensure quality of the deliverables, attention to detail
Experience/understanding of corporate finance data from company filings is desirable",3.6,"Copal Partners
3.6",Bengaluru,"New York, NY",10000+ employees,1900,Company - Public,Financial Analytics & Research,Finance,₹100 to ₹500 billion (INR),-1
1285,Data Engineer,"Job Description / Responsibilities
Build workflows to ensure data extraction quality and storage into our backend data store
Architect, build and train ML/AI models that can predict outcomes and report on anomalies.
Design data pipelines to perform ETL on content/data from multiple types of source systems.
Create data analytics views using RDBMS/Key-Value stores, on private and public/cloud
Create software that is well tested, maintainable, extensible and scales out with large data

Minimum Qualifications:
2+ years of software development with Python
2+ years of SQL (MySQL/Postgres) and Key-Value databases
1+ years of experience with scikit
2+ years of experience in data extraction, data transformation using custom Python/Java
Experience working with MapReduce/Hadoop/kafka/Elastic stack
Experience with Node backend and React/Redux
Experience working with git/mercurial, Amazon/Google cloud, Linux/LAMP stack
Experience in testing or test driven development
Experience with Data science and Machine Learning algorithm development

Location:
Hyderabad/Bangalore

Package:
Highly competitive to match experience and capability",3.7,"TVS
3.7",Bengaluru,"Chennai, India",5001 to 10000 employees,-1,Company - Private,Accounting,Accounting & Legal,₹100 to ₹500 billion (INR),-1
1286,Data Engineer,"Permanent position with US based client of iFlex.
Work Location: Bangalore
Experience Level: 2+ Years

Role:
As part of our global team you will work on the data platform reporting to the Data Engineering Lead. Your role includes specification, development, test and rollout of features on our data platform. You are expected to contribute to the vision, understand our product roadmap, integrate business value andclient experience and contribute to build an engineering culture within the team. This initiative is of critical important to the success of the organization and our roadmap, for instance, services like liquidity analytics, billing, client onboarding, reporting and others will rely on the data platform. Accurate, granular, complete and timely data will be our key differentiating factor and competitive advantage in the market place. We expect the successful candidate to deliver high quality software and to be passionate about data engineering..

Responsibility / Qualification:
Managing multiple tasks and use sound judgment when prioritizing.
Collaborating with global cross functional team in building customer-centric products.
Analyzing existing software implementations to identify areas of improvement and provide deadline estimates for implementing new features.
Updating and maintain documentation for team processes, best practices and software runbooks.
Establishing trusted partnerships with peers, product heads, and executive level stakeholders.
We are looking for someone who is passionate about technology and engineering.
Exceptional analytical skills and ability to apply knowledge and experience in decision-making to arrive at creative and commercial solutions.
Ability to leverage technology to deliver business value.
You are independent and comfortable in a fast paced, ambiguous and often multi-directional work environment.

Preferred Qualifications:
B.S. or higher in Computer Science.
Minimum 2 years of relevant professional experience using a modern programming language (preferably Java/Scala).
Experience leveraging test driven development technics.
Comfort with Agile operating models.
Team oriented.
Strong interpersonal and communication skills.
Energetic, self-directed, and self-motivated.
Experience with microservice architecture.
Experience with Kafka, MongoDB, Hadoop, Cassandra.
Experience with AWS.
Experience in Financial Services or Fintech.",-1,IFLEX,Bengaluru,"Moscow, Russia",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1287,CIEL/SEL/1941: Sr data scientist,"Mandatory skills required -
Databases (SQL, Oracle, Any RDBMS) - Should have working knowledge of atleast one database
PL/SQL Programming Languages
R, Python (Any One)
Inferential Statistics - Hypothesis, p-value, R2, RMSE, MAPE etc
Exploratory Data Analysis
Machine Learning Algorithms - Should have in-depth knowledge and implementation of atleast one algorithm

Responsibilities
: Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the why & how of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions

Education
Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics
Experience
Minimum years of related experience required: 3 years
Preferred years of experience: 5 years
Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desirable.

Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
1288,Data Engineer,Data Engineer,3.6,"Bookmyshow
3.6",Mumbai,"Mumbai, India",1001 to 5000 employees,2007,Company - Private,Ticket Sales,"Arts, Entertainment & Recreation",Unknown / Non-Applicable,-1
1289,Data Analyst,"Required Skills & Experience

We are looking for a Data Analyst Executive
Eligible Qualifications : B. Tech, BCA, M.Tech, MCA
Experience : 3-5 years, fresher’s can also be considered
Location of Job : Gurgaon/Connaught Place, New Delhi
Technicals Skills

Following technical skills are pre-requisite:
Well versed with Software development methodologies, such as SDLC (Software Development Life Cycle), DDLC (Document Development Life Cycle).
Database schema design and implementation
Should have worked in either of technologies Sql Query/ Tableau/ Excel (Macros)/ Access (Query) writing for data analytics.
For planning and coordinating activities, organizations remain in invariant communication with one another and the data transfer has to be performed efficiently and smoothly as possible.
He/ She should manage the execution of the technologies, help the businesses in utilizing the systems, and should be well versed with the basics of computer systems such as Networking, Installation of necessary software and hardware.
Ability to determine the interrelationships between solutions and requirements.
Ability to think analytically and should be a problem solver and logic building should be very strong.
Good interpersonal skills to form effective working relationships with people at all levels.
Excellent communication and presentation skills and strong written & oral English skills.
To know more about us visit us www.sspl.net.in or write to us at admin@sspl.net.in",-1,Substratal Solutions,Connaught Place,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1290,Artificial Intelligence Scientists,"Experience 2- 4 Years
Salary 4 LPA - 6 LPA
Job Location Chennai

Industry:
IT-Software / Software Services

Keywords:
Artificial Intelligence

About Job:
Must have Excellent knowledge in AI / Machine learning (Mandatory).
Machine learning frameworks like keras, tensor flow etc.
And also other big data tools like Hadoop etc, Must know R and python.
Good understanding in SDLC & Business cycle.",4.0,"Careerera
4.0",Chennai,"Wayland, MA",501 to 1000 employees,-1,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
1291,Senior Data Engineer,"About Us

upGrad is an online education platform building the careers of tomorrow by offering the most industry-relevant programs in an immersive learning experience. Our mission is to create a new digital-first learning experience to deliver tangible career impact to individuals at scale. upGrad currently offers programs in Data Science, Machine Learning, Product Management, Digital Marketing, and Entrepreneurship, etc. upGrad is looking for people passionate about management and education to help design learning programs for working professionals to stay sharp and stay relevant and help build the careers of tomorrow.
upGrad was awarded the Best Tech for Education by IAMAI for 2018-19
upGrad was also ranked as one of the LinkedIn Top Startups 2018: The 25 most sought-after startups in India
upGrad was earlier selected as one of the top ten most innovative companies in India by FastCompany.
We were also covered by the Financial Times along with other disruptors in Ed-Tech
upGrad is the official education partner for Government of India - Startup India program
Our program with IIIT B has been ranked #1 program in the country in the domain of Artificial Intelligence and Machine Learning
About the Role

We are looking for a Data Engineer to help us scale the existing data infrastructure and in parallel work on building the next generation data platform for analytics at scale, machine learning infrastructure and data validation systems.
In this role, you will be responsible for communicating effectively with data consumers to fine-tune data platform systems (existing or new), taking ownership and delivering high performing systems and data pipelines, and helping the team scale them up, to endure ever growing traffic.
This is a growing team, which makes for many opportunities to be involved directly with product management, development, sales, and support teams. Everybody on the team is passionate about their work and we’re looking for similarly motivated “get stuff done” kind of people to join us!

Roles & Responsibilities
Engineer data pipelines (batch and real-time ) that aids in creation of data-driven products for our platform
Design, develop and maintain a robust and scalable data-warehouse and data lake
Work closely alongside Product managers and data-scientists to bring the various datasets together and cater to our business intelligence and analytics use-cases
Design and develop solutions using data science techniques ranging from statistics, algorithms to machine learning
Perform hands-on devops work to keep the Data platform secure and reliable
Skills Required
Bachelor's degree in Computer Science, Information Systems, or related engineering discipline
6 + years’ experience with ETL, Data Mining, Data Modeling, and working with large-scale datasets
6+ years’ experience with an object-oriented programming language such as Python, Scala, Java, etc
Extremely proficient in writing performant SQL working with large data volumes
Experience with map-reduce, Spark, Kafka, Presto, and the ecosystem.
Experience in building automated analytical systems utilizing large data sets.
Experience with designing, scaling and optimizing cloud based data warehouses (like AWS Redshift) and data lakes
Familiarity with AWS technologies preferred
Qualification – B.Tech/M.Tech/MCA(IT/Computer Science)

Years of Exp – 6-9",3.5,"upGrad Education Private Limited
3.5",Mumbai,"Mumbai, India",501 to 1000 employees,2015,Company - Private,Education Training Services,Education,₹1 to ₹5 billion (INR),"Udacity, General Assembly, Springboard"
1292,BBRC-Genomics-Associate Scientist,"JOB DESCRIPTION

Designation: Associate Scientist

Job Location: Bangalore

Department: Translational Medicine- Translational Sciences

About Syngene

Incorporated in 1993, Syngene International Ltd. is an innovation-focused global discovery, development and manufacturing organization providing integrated scientific services to the pharmaceutical, biotechnology, nutrition, animal health, consumer goods and specialty chemical industries around the world. Syngene’ s clientele includes world leaders such as Bristol-Myers Squibb, Baxter, Amgen, GSK, Merck KGaA and Herbalife. Its innovative culture is driven by the passion of its 4240- strong team of scientists who work with clients from around the world to solve their scientific problems, improve R&D productivity, speed up time to market and lower the cost of innovation .

Job Purpose:
To play a key role in TM-TS, develop an early-stage research strategy, initiate and lead discovery programs while managing ongoing programs in TM-TS. The role will work part of TMTS, and work with internal and external collaborators .

Key Responsibilities:
Experience in isolating DNA and RNA from blood, tissues and FFPE samples and cell lines. Experience with optimization of extraction protocols and for parameters like yield, input sample quantities and sample types is important.
Expertise in PCR, qPCR, cDNA/gDNA library preparation. Exposure to microarray techniques.
Proficiency in preparation of libraries for Next Generation Sequencing of transcriptome and genome, with significant experience in optimization of parameters like input RNA/DNA quantities and sample type
Experience with single cell RNA-seq will be plus.
Experience with various NGS protocols (DNA Amplicon based, hybrid capture based low input, degraded DNA and RNA samples e.g. FFPE samples.
Strong understanding of experimental design and statistical principles behind experimental design and differential gene expression. Experience with analysis of single cell RNA-sequencing data will be a plus

Educational Qualification:
M.Sc or M. Tech in Biotechnology, Molecular biology or Biological Sciences,

Technical/functional Skills:
DNA/ RNA Isolation, Expertise in PCR, qPCR, Experience in NGS protocols

Experience:
2 to 5 Years

Behavioral Skills:
A proactive team player.
Ensure completion of experiments and generate accurate and reproducible data from experiments.
Ability to work independently, prioritize tasks and work on multiple projects simultaneously with; comfortable working in a dynamic environment with changing requirements.
Good oral and written communication and presentation skills to work in a multi-disciplinary team
Equal Opportunity Employer:
It is the policy of Syngene to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by applicable legislation or local law. In addition, Syngene will provide reasonable accommodations for qualified individuals with disabilities.",3.5,"Syngene
3.5",India,"BENGALURU, India",1001 to 5000 employees,1994,Unknown,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1293,Applied Scientist 1,"Position Requirements:
Master's degree in Computer Science, Computer or Electrical Engineer, Mathematics, or a related field plus at least one year of experience in the job offered or related occupations of Software Engineer, Software Developer, or a related occupation. Employer will accept a Bachelor’s degree and five years of experience in the job offered or a related occupation as equivalent to the Master’s degree and one year of experience. One year of experience in the job offered or related occupation must involve designing and developing large-scale, multi-tiered, distributed software applications, tools, systems and services using Java, Object Oriented Design and Distributed Programming].

Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, Oracle/Berkeley databases, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills

Amazon Selling Partner Services team drives the Selling On Amazon business and develops solutions that enable millions of sellers around the world to sell on Amazon's Marketplaces. More than half of shipments for Amazon customers are generated from this business. The team is focused on building a technology platform that will support the explosive business growth in existing markets, streamline the business for Amazon and the Selling partners and launch business in new markets and establish a fair marketplace.

Our team is seeking engineers with broad technical skills to help us optimize how we synthesize massive amounts of data and complex business rules into mission critical financial information. As a member of this team you will employ object oriented techniques in Java, and DynamoB, PostGres and ElasticSearch skills to help us support Amazon's next generation of selling partner services. Along the way you'll gain and leverage a unique understanding of how Amazon.com works; from the numerous software systems that comprise the website's back-end, to the details of our business model, and the relationships we're establishing with an ever-growing network of selling partners who depend on Amazon.com to run their businesses.

The ideal candidate will draw upon exemplary analytical, critical thinking, and problem solving skills, and a passion for maintaining highly reliable, distributed systems which operate 24/7/365. Successful members of this team collaborate effectively with internal end-users, aggressive cross-functional software development teams, and technical support/sustaining engineering teams to solve problems and deliver successfully against high operational standards of system availability and reliability. We look for engineers who are excellent communicators, self-motivated, flexible, hardworking, and who like to have fun!

Position Responsibilities:
Participate in the design, development, implementation, testing and documentation of large-scale, multi-tiered, distributed software applications, tools, systems and services using [Java, Object Oriented Design and Distributed Programming]. Translate functional requirements into robust, scalable, supportable solutions that work well within the overall system architecture. Participate in the full development cycle, end-to-end, from design, implementation, and testing to documentation, delivery and maintenance. Produce comprehensive, usable software documentation. Evaluate and make decisions around the use of new or existing software products and tools.

Preferred Qualifications
Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1294,Senior Clinical Data Analyst,"About Novotech:

Novotech is internationally recognised as the leading independent and full-service contract research organisation (CRO) in the Asia Pacific region. We provide a wide range of clinical development services across all research phases and therapeutic areas and have been instrumental in the success of hundreds of Phase I – IV clinical trials throughout the Asia Pacific. Powered by the highest quality people, Novotech strives to set the benchmark for both business and clinical trial performance. Our people are one of our key strengths. We value our people and recognise the work they do. We are lucky to have the best people and talent from across the Asia Pacific region work together to deliver to clinical trial success for our clients. Our people and those we look to recruit have an attitude of making things happen. They are problem solvers, driven with a focus on delivering quality, accountability and a high level of performance.

Brief Position Description:

As part of Novotech’s Biometrics unit, the Senior Data Analyst (SDA) is responsible for all data analysis and business intelligence activities related to study related clinical and operational data. The SDA acts as primary point of contact for all data analysis matters to the study team and is responsible for the timely delivery of quality outputs following all applicable regulatory, compliance, best practice and operational procedures.

Minimum Qualifications & Experience:

Graduate in information science, data science or life science-related field, or similar. More than five years’ experience in a senior role related to data science, data analysis, clinical data management or clinical data programming in a pharmaceutical company, CRO or EDC software provider.

Responsibilities
The Senior Data Analyst (SDA) is responsible for providing technical, procedural (SOPs) and planning leadership across multiple projects assigned to the data analyst team members ensuring that they deliver in accordance with SOPs, programming best practices, and the timelines agreed within the Project Team.
Collaborate with cross-functional stakeholders to implement data science solutions to solve business needs using available technological solutions.
Scope data analysis effort for projects and project manage all data analysis activities across multiple projects for different study stakeholders.
Gather study requirements from data management for data review and external data reconciliation and provide guidance on appropriate outputs (dashboards, visualisations, listings, reports).
Extract, assess, integrate, transform data sources to provide data visualisation outputs for analytics.
Design and develop prototypes and final versions of data outputs (dashboards, reports, visualisations, listings) using Business intelligence tools and Data Visualisation tools.
Design and develop standard dashboards and content for different audiences.
Analyse, manipulate and understand data from multiple sources to present and create dashboards and reports to make business decisions.
Assist teams on best-practice for data visualisation dashboard development.
Educate teams on how to use all the features of applicable data visualisation platform in conjunction with data visualisation dashboards.
SME for the data visualisation development and assisting team members.
Identify and communicate project risks and maintain documentation within project files as appropriate
Represent data analysis group at internal / external meetings as appropriate.
Assess and implement new data analysis, BI and data visualisation processes and technologies.
Take an active role in the development of best practices, process improvement, quality control and governance related to all data analysis matters.
Provide training and mentoring to Data Analysis of team members in SOPs, software applications, and best practices.
Provide Subject Matter Expertise on all data analysis and visualisation related activities.
Attributes and Skills

Expert knowledge of clinical study data structures and schemas of EDC databases. Expert knowledge in data processing activities such as extracting, integrating, transforming and presenting data. Statistical Programming skills in Python, R or similar. Knowledge of SQL and EDC systems. Working knowledge of Spotfire, Power BI, Tableau or other data review and visualisation tool. Ability to gather business requirements from multiple stakeholders and clients and provide guidance on the use of appropriate data visualisations.

Experience mentoring and training others. Awareness of regulatory and compliance issues and understanding of the application of SOPs and Quality Control to daily activities. Excellent analytical, communication and problem-solving skills.

Opportunities and Benefits:

To deliver clinical trial and research excellence for our clients, our people are 'best in class'.

At Novotech, we seek and nurture people with exceptional talent. We are committed to providing our people with regular internal and external training, a competitive bonus structure and a supportive work environment. We are also focused on providing our people with a wide variety of career growth and development opportunities.

For more information about where your next career step at Novotech might take you, visit http://novotech-cro.com/novotech-careers",4.5,"Novotech
4.5",Bengaluru,"Sydney, Australia",501 to 1000 employees,1996,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
1295,Data Engineer,"Data Engineer Responsibilities:
Liaising with coworkers and clients to elucidate the requirements for each task.
Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed.
Reformulating existing frameworks to optimize their functioning.
Testing such structures to ensure that they are fit for use.
Preparing raw data for manipulation by Data Scientists.
Detecting and correcting errors in your work.
Ensuring that your work remains backed up and readily accessible to relevant coworkers.
Remaining up-to-date with industry standards and technological advancements that will improve the quality of your outputs.
Data Engineer Requirements:
Bachelor's degree in Data Engineering, Big Data Analytics, Computer Engineering, or related field.
Master's degree in a relevant field is advantageous.
Proven experience as a Data Engineer, Software Developer, or similar.
Expert proficiency in Python, C++, Java, R, and SQL.
Familiarity with Hadoop or suitable equivalent.
Excellent analytical and problem-solving skills.
A knack for independent and group work.
Scrupulous approach to duties.
Capacity to successfully manage a pipeline of duties with minimal supervision.
Job Type: Full-time

Salary: ₹360,000.00 to ₹870,000.00 /year

Experience:
total work: 2 years (Preferred)
Data Engineer: 1 year (Preferred)
Education:
Diploma (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,Futurious Technologies,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1296,Quantitative Analyst,"The successful candidate will be a highly analytical individual with hands on programming skills. The candidate will work closely with the research team and clients towards the ongoing development and integration of new investment strategies, models and tools on Axle

Location

Mumbai
Responsibilities

Perform daily/weekly/monthly tasks of performance and risk reporting
Develop and automate investment processes and strategies via VBA and Matlab
Develop tools to integrate trading decision systems with risk management systems
Ad hoc tasks (such as operational tasks, internal documentation tasks and preparation of marketing materials)
Skills/Experience

Excellent programming skills in Matlab/Excel-VBA
Thorough with financial concepts and calculations like Drawdown, VaR, Eloss etc.
Understanding of financial market products like options, futures, FX forwards etc.
Working knowledge of Bloomberg is preferred
Should be self-driven and detail oriented with an analytical mindset
Should be a proactive and quick learner; a team player showing enthusiasm and drive to accomplish results in a fast paced environment
Min. 2 years of relevant work experience
Qualifications

B.Tech/M.Tech/MBA/CFA/FRM",5.0,"B&B Analytics
5.0",Mumbai,"Zug, Switzerland",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1297,Analyst - Data Scientist,"Job Summary

Experience:
3 - 5 Years

Location:
Mumbai

Designation:
Analyst - Data Scientist

Degree:
BE-Comp/IT, BE-Other, BTech-Comp/IT, BTech-Other, ME-Comp/IT, ME-Other, MTech-Comp/IT, MTech-Other, PhD-Comp/IT, PhD-Other

Educational Level:
Graduate/Bachelors

Industrial Type:
IT-Software/Software Services

Functional Area:
IT Software - Application Programming / Maintenance

Key Skills:
Data Scientist

Job Post Date:
Thursday, March 19, 2020

Company Description

We are capability centre based in Mumbai, initially started as a back-office operational support to the UK business unit.

However, over the recent years, we have significantly increased the breadth and depth of our capabilities and offerings to keep pace with the changing needs of the Group. These include Digital & Knowledge Services, Finance and Actuarial, Information Technology (IT), Customer Service, Risk and Audit.

Our core purpose is to be a strategic partner to company, enabling growth by delivering change and driving synergies through a highly capable and agile workforce.

With our diversified service offerings we provide our people with exciting opportunities to grow personally and professionally.

Company is a leading savings and investments business serving around 5.5 million retail customers and more than 800 institutional clients.

It-s innovative asset management and customer solutions are supported by extensive investment capabilities, an international distribution network and two strong brands.

Job Description

3 – 5 yrs experience as Data Scientist
Should have at-least 1 end-to-end ML project experience
Very high proficiency in R or Python
Excellent in forecasting methods like simple exponential smoothing, multiplicative seasonal indexes, simple and weighted moving averages and time series forecasting methods
Exposure to with advanced deep learning techniques such as LSTM. CNN, Dense neural networks as well as neural networks design and implementation through tools like tensorflow, keras, pytorch, deepai or equivalent.
Good SQL experience",3.8,"Sampoorna Computer People
3.8",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
1298,Data Lake Developer,"For Us, It's A Mission

At Mylan, we mean it when we say we work every day to provide access to high quality medicines to the world's 7 billion people. If you are unconventional, relentless and passionate. If you believe in doing what's right, not what's easy. If you are a doer and have a passion for serving others, we want to talk to you.

Make a Difference

At Mylan, each person has the ability to make a difference. From the providers who sell and market our products, to the producers who develop and manufacture them and finally to our business partners who support the providers and producers, we all have a mission critical role. Here's how this role will help:

ESSENTIAL DUTIES AND RESPONSIBILITIES
To perform this job successfully, an individual must satisfactorily perform each essential duty. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential duties.
1. Create and maintain optimal data pipeline architecture on Azure platform.
2. Develop batch processing solutions by using Data Factory and Azure Databricks.
3. Delivering a Data Warehouse in the Azure Cloud.
4. Design relational and non-relational data stores on Azure.
5. Identify, design, and implement internal process improvements : automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc..
6. Developing Big Data Solutions with Azure Machine Learning.
7. Strong interaction with business departments to provide consultative support for digitization efforts, as well as close collaboration with the Business Technology management, focused on future innovation topics.
8. Participate and lead in design sessions, demos and prototype sessions, testing and training workshops with business users and other IT colleagues.
9. Design & Build for any API Development or SQL DB development.
10. Providing service management, orchestration, monitoring and management requirements of Azure cloud platform.
11. Create data tools / products for analytics and data scientist team members that assist them in building and innovative solutions that drive tangible business value.
12. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
13. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
14. Design security for source data access. Chose the appropriate authentication mechanism, (ie Azure Active Directory (Azure AD), etc).
15. Design for real-time processing by using Stream Analytics and Azure Databricks.

Make Our Values Your Values

Mylan hires only the best. People who thrive in a culture of innovation and empowerment. People who are active learners and have a positive attitude. People who are leaders and know that by working together we can run faster, reach higher and achieve more. By doing so, we will continue to set new standards in health care. Here are the minimum qualifications and essential functions for this position:

QUALIFICATIONS

The qualifications listed below are representative of the minimum knowledge, skill, and/or ability required.

SKILLS AND ABILITIES

1. 10 years of experience in Microsoft technologies including SQL.

2. At least 5 years as a Sr Developer with at least 3 years hands on experience as Azure Data Engineer building large scale Azure data solutions.

3. At least 5 years of experience in Azure based data solutions.

4. At least 3 years of experience on working with large projects including the most recent project in the cloud (Azure) or on prem with a focus on Azure Data services.

5. At least 5 years of Hands-on administration, configuration management, monitoring, performance tuning of Hadoop/Distributed platforms.

6. At least 5 years of demonstrated experience at least in the most recent 2 years of designing and delivering solutions using Cortana Intelligence suite of analytics services part of Microsoft Azure including Azure Machine Learning Studio, HDInsight, Polybase, Azure Data Lake Analytics, Azure Data Warehouse, Streaming Analytics, Data Catalog, R/R Studio

7. Experience in designing and building logics required for optimal extraction, transformation, and loading of data from a wide variety of data sources

8. Experience within Data Security design, including but not limited to:

a. Choosing the appropriate authentication mechanism, such as Azure Active Directory (Azure AD)

b. Defining strategies for data encryption for data at rest and in transit

9. Experience partnering with Business Analysts and Data Scientists to enable effective and efficient data preparation and delivery

10. Experienced in vendor management and working with 3rd parties onshore & offshore.

11. Experience working in a global team.

12. Experience working in an Analytics / Big Data solutions on MS Azure Cloud

13. Experience with code management tools, automated testing

14. Experience creating and maintaining optimal data pipeline architecture on Azure platform

15. Experience developing batch and real-time processing solutions by using Data Factory and Azure Databricks

16. Familiar with AGILE and Azure DevOps methodology

17. Hands on PoC capabilities are needed to prove a particular architecture concept

18. Azure Native Services experience across Data Fabric and Service Fabric

19. Experience in Application modernization from legacy on-premise data architecture platform technology stack to modernized Azure Cloud base Architecture.

20. Experience with Git, NoSQL Data Solutions, Microsoft Azure, HD Insights, Azure ML, DataBricks ML Flow, R or Python.

21. Must have excellent communication skills.

EDUCATION/EXPERIENCE (Note: Please select one)

Minimum of a Bachelor's degree in Computer Science and Engineering is preferred with minimum 10 years of experience. However, a combination of experience and/or education will be taken into consideration

Why Mylan?

If you want to be part of a global health care company that is making a difference and changing lives, Mylan may be the place for you. With a workforce of more than 35,000 worldwide, we can make a difference. We encourage you to visit Mylan.com to learn more about our unconventional culture, our approach to doing business and how we plan to set new standards in health care.

Mylan offers competitive salary, excellent benefits and an environment conducive to professional growth and advancement. All qualified applicants will receive consideration for employment without regard to their disability or protected veteran status. Mylan is an Equal Opportunity Employer, Minorities/Female/Disabled/Veteran.",3.8,"Mylan Inc.
3.8",Bengaluru,"Hatfield, United Kingdom",10000+ employees,1961,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1299,Off Campus Recruitment - Quantitative Researcher,"Description:
Graviton is a privately funded quantitative trading firm striving for excellence in financial markets' research. We are seeking fresh talent from the top IIT's to join us as Quantitative Researchers for our team in Gurgaon.If you are a student graduating in 2020 from Computer Science , Electrical or Maths Stats Computing streams with a greater than 8 CGPA please apply here.

This role is open to students from campuses that we could not visit this year. Please check your individual placement policy restrictions before applying.

Graviton trades across a multitude of asset classes and trading venues using a gamut of concepts and techniques ranging from time series analysis, filtering, classification, stochastic models, pattern recognition to statistical inference analysing terabytes of data to come up with ideas to identify pricing anomalies in financial markets.

As a Quantitative researcher your responsibilities will include

Develop new or improve existing trading models using in-house platforms

Use advanced mathematical techniques to model and predict market movements

Analyse large financial datasets to identify trading opportunities

Provide real time analytical support to experienced traders

Requirements :
Possess a degree in a highly analytical field, such as Engineering, Mathematics, Computer Science from IITs schools

Quantitative bend of mind

A working knowledge of Linux/Unix

Programming experience, preferably in C++ or C

Strong interest in learning about financial markets.

Have a strong work ethic

Hard Working

Benefits:
Our open and casual work culture gives you the space to innovate and deliver. Our cubicle free offices , disdain for bureaucracy and insistence to hire the very best creates a melting pot for great ideas and technology innovations. Everyone on the team is approachable, there is nothing better than working with friends!

Our perks have you covered.

Competitive compensation

6 weeks of paid vacation

Monthly after work parties

Catered breakfast and lunch

Fully stocked kitchen

Gym membership

International team outing",5.0,"Graviton Research Capital LLP
5.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2014,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1300,Data Engineer,"Zauba Technologies is a startup based in Bangalore. Zauba's services are used by leading companies in India. Zauba is powered by a young and passionate team. We are looking for individuals who would like to be a part of our founding team.

As a Data Engineer and as a part of founding team, you will be expected to visualise and develop disruptive data products. Eventually you would be responsible for entire project lifecycle of products you would visualize. Your rewards will be directly proportional to the value you generate.

Job Responsibilities
Design and development of robust, scalable and highly efficient data engineering solutions for structured and unstructured data (Including gathering and processing raw data at scale, writing scripts, web scraping, calling APIs, writing SQL queries, etc.)
Develop processes for text mining and extraction of information from unstructured data
Design, architect and develop efficient data pipelines around the data collected
Take ownership of existing web product and applications
Design and implement data models that scale across the enterprise
Take ownership of existing data workflows and processes
Enhance scalability, performance, and stability of existing infrastructure
Work closely with other team members to integrate your innovations and algorithms into our production systems

Essentials
Java/Python - Intermediate to advanced level
SQL - Advanced
MySQL Intermediate to advanced level
Regex - Basic to intermediate level
Linux Basic to intermediate level

Good to have
Hadoop/Spark
R
MongoDB

Must have qualities
Skills to learn new skills quickly
Desire to create disruptive products and services
Passion - not just to work in startups but to take them to next level
Above average programming aptitude
Be passionate about producing high quality engineering deliverables
Be productive working independently or collaboratively
Have an eye for building efficient processes
Be self motivated
Proactively take ownership

Interested?

Send your resume to hr@zaubacorp.com",3.8,"Zauba Corp
3.8",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 million (INR),-1
1301,Quantitative Research,"We are looking for highly trained professionals who are interested in applying advanced mathematical quantitative methods to the modeling of global financial markets. You would be joining a group made up of highly proficient individuals from various scientific disciplines. We have a spectrum of opportunities for individuals with the right scientific skills. Experience in finance is not required.

The ideal research candidate will have:
A Ph.D. in Computer Science, Mathematics, Physics, Statistics, or a related technical discipline.

A demonstrated capacity to do first-class research.

Computer programming skills.

An intense interest in applying quantitative analysis to solve difficult problems.

Send us a copy of your resume to
careers@dolatcapital.com

For internship opportunities, please send us a copy of your resume to
careers@dolatcapital.com",4.0,"Dolat Capital
4.0",Mumbai,"Mumbai, India",51 to 200 employees,1970,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1302,Data Engineer,"Bachelor’s degree in Computer Science or related field
5+ years relevant experience
5+ years experience with SQL, SQL Tuning, Oracle, OLAP, Big Data Technologies
5+ years experience developing end-to-end Business Intelligence solutions: data modeling, ETL and reporting
Experience with Java and experience with scripting languages like Perl, Python, Unix shell scripts,VBA and MS Excel
Proficiency with Linux and systems administration
Proven ability at looking at solutions in unconventional ways. Sees opportunities to innovate and can lead the way.
Top notch communication (verbal and written) and interpersonal skills to convey key insights from complex analysis in summarized business terms and an ability to effectively communicate with technical teams.
Ability to work with shifting deadlines in a fast paced environment.
Operations Finance Technology team, responsible for building technical solutions for multi-billion WW Operational Cost analytic including Inbound cost (Receiving / PO), variable Cost, fixed cost, outbound (Customer Shipments / Transportation), and Customer Service, is looking for a Data Engineer.

As a data engineer, you will get the exciting opportunity to work on very large data sets in one of the world's largest and most complex data warehouse environments. You will work closely with the business teams in analysis on various cost savings initiatives, many non-standard and unique business problems and use creative-problem solving to deliver actionable output.
You will be responsible for designing and implementing an analytical environment using third-party and in-house reporting tools, modeling metadata, building reports and dashboards. You will have an opportunity to work with leading edge technologies like Redshift, Hadoop/Hive/Pig. You will be writing scalable queries and tuning performance on queries running over billion of rows of data.

You should be analytical, have an extremely high level of customer focus and a passion for process improvement. You should be motivated self-starter that can work independently in a fast paced, ambiguous environment. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions.
Bachelors in Computer Science or related field
Practical Knowledge of Linux or Unix shell scripting
Experience in working with business customers to drive requirements analysis
Exposure to large databases, BI applications, data quality and performance tuning
Excellent written and spoken communication skills
Experience with Hadoop-based technologies such as HBase, Pig, Hive and Spark
Strong proven ability in building high-performance, highly available and scalable data solutions using Oracle and/or Hadoop-based technologies
Knowledge of data warehousing concepts.
Strong sense of ownership, urgency, and drive
Strong troubleshooting and problem solving skills
Experience with Amazon Web Services",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1303,DATA ANALYST,"posted by Mahima Gaur

2 - 5 years Delhi

Job Description
Experience in data processing
Experience in data cleaning and data tabulation activities
Strong analytical, communication and team management skills
Strong understanding of data management using SPSS and research techniques
Competency in a Tabulation software (decipher / wincross / quantum etc), Excel, Powerpoint
Ability to summarize findings, draw conclusions, and put together a presentation using Powerpoint
Role Category : Data Analyst

Employment Type : Permanent Job, Full Time",4.9,"Knowledge Excel Services.
4.9",New Delhi,"New Delhi, India",1 to 50 employees,2007,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
1304,Data Engineer,"Key skills : Python , Spark , SQL , Pyspark • AWS platform used for the work • Strong experience in SQL is mandatory • Good familiarity of AWS landscape • Good experience in collecting business requirements & design them as per requirement from customer • Should able to work independently & interact business users & technical stakeholders • Strong communication skills both oral & written. • Should work as an individual resources",3.5,"Larsen & Toubro Infotech Limited
3.5",India,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1305,Big Data Engineer,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
1306,Client Data Analyst,"At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.
What is the Client Data Analyst – Client Analytics group responsible for?
This team manages business data to ensure accurate, timely, consistent and compliant data. Their contributions deliver quality data that is easily accessible and can be trusted. Key downstream capabilities such as reporting and analytics depend on this as well as operational data access on various systems. The Data Management Team is a support function that acts as an advocate and a point of contact for Sales and Marketing data.

What are the ongoing responsibilities of an Client Data Analyst ?
Understand the data flow, key consumption and production of data as well as context within the enterprise:
Build positive relationships with teams, especially the key data consumers and analytics. Take the time to increase knowledge of how they run their business and incorporate sales data into daily work
Connect regularly with each sales office to understand current issues and challenges. Probe the business and validate against other sales offices to understand the scope and priority of the issue
Make recommendations on how data unifications and flow can be used to improve business tasks. Liaise business partners to deliver solutions (reports, processes, technology) that add value.

Provide data management subject matter expertise. Appreciate the connection and data flow between applications and other corporate systems. Be able to clearly articulate the data needs and move initiatives forward by collaborating with business partners:
Actively participate in meetings with business partners to ensure that priorities are clearly understood, information is regularly shared and that key participants are “kept in the loop”
Provide context and background on issues. Collaborate on ideas for progressing initiatives. Ensure appropriate resources are involved to take initiatives forward
Provide insights and expertise to scope statements and requirements documentation
Actively consult or participate in the user acceptance testing process (test cases, documentation, testing execution, etc.)
Ensure business needs remain aligned with overall corporate initiatives and deliver the benefits as originally intended

Monitor the integrity of data and usefulness of reports. Ensure the information available within systems is accurate and up-to-date. Proactively seek data cleansing opportunities and evolve data to better support. Document and maintain ongoing processes for reporting and data clean-up:
Partner with all key data consumers to gain a solid understanding of usage and challenges around data. Establish processes for prioritization of enhancements, especially with the analytics groups
Provide 1st level support for data issues and data maintenance for owned data
Verify and execute data loads into our internal sales systems and ensure any upstream systems accurately receive their data

Increase awareness and promote data management capabilities. Share best practices and provide coaching to local offices on how to access and incorporate output into sales tasks. Encourage IAS leaders to leverage data to make more informed, strategic decisions:
Clearly articulate the goals and core services of the data management team. Proactively promote this information within IAS and ensure business partners understand the data management role within the organization
Share best practices and provides guidance on data capabilities. Reinforces ownership and accountability for data accuracy
Seek opportunities to share the benefits of leveraging sales data to make more informed business decisions

What ideal qualifications, skills & experience would help someone to be Successful?

Knowledge, Education And Experience:
Four year bachelor’s degree required (majors of preference include: business, computer science, mathematics) Advanced degree a plus
Understanding of the Franklin Templeton business model, how FT makes money, the sales process, how technology fits in with the business, etc. Knowledge of the GAS (Global Advisory Services) structure
Experience working through multiple business fiscal cycles; exposure and/or direct experience with project management and/or sales-related-capacity required
Prior work experience related to analytics, sales, marketing and/or international a must. Level will not be granted based on years of experience but will be determined by the employee’s ability to meet each job activity as outlined the ‘typical/expected focus by level
Skills And Abilities:
Ability to communicate effectively with all levels of management; ability to tailor communication style based on audience; ability to get others to want to collaborate with you; strong facilitation skills
Excellent writing skills (for presentations, documentation, etc.)
Working knowledge of the CRM, MDM, Excel, SQL, Power BI, Tableau, Business Objects, and Microsoft Products (PPT, Power Apps, Doc, Visio)
Ability to absorb and interpret large quantities of data; apply trend analysis and knowledge of the business to develop a meaningful and digestible summary with the appropriate level of detail
Ability to take a larger problem and break down the individual components; identify how to go about solving the problem and who to involve in the process
Ability to present recommended solutions to a variety of issues and problems (solutions that are consistent with organization objectives)
Must be extremely detail-oriented (managing lists, tasks/to-dos, etc.) good with follow through on own items; good with following up with others on outstanding item

What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.

Highlights of our benefits include:

Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.",3.8,"Franklin Templeton Investments
3.8",Hyderabad,"San Mateo, CA",5001 to 10000 employees,1947,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Fidelity Investments, Vanguard"
1307,Data Analyst,"Roles and Responsibilities:
Extracting, transforming and inputting data sets from various resources. Creating predictive models, translating non-technical aspects into quantifiable tasks. Analysis and representation of output data, highlight and explain trends and patterns, error elimination, using advanced statistical methods (regression, probability distribution, clusters etc.) to provide accurate results.
Data collection, Data Mining, Report generation, Problem identification and solution formulation Market analysis and establishing trends, Strategy development and implementation

Skills:
Extremely good analytical skills.
Good working knowledge of all MS-Office products, especially Advance Excel, Word, PowerPoint, MS-access.
Statistical tools and methods.

Interested candidates can send the updated resume on satish.mehra@exelaonline.com or call on 7722028636
00-7.00 Years",2.6,"Exela Technologies
2.6",Pune,"Irving, TX",10000+ employees,2017,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"SourceHOV, BancTec, Transcentra"
1308,Data Modeler,"• Minimum 5-8 years of working experience as Data modeler.
• Data modelling experience in designing.
• Minimum 2-3 years real time experience in Erwin tool is mandatory.
• Experience in normalized modeling techniques.
• Experience in designing the Start schema.
• Experience working in ORACLE.
• Experience with database design, capacity planning, performance tuning and query optimization.
• Experience in working with Bank or Banking and Finance or Financial domain.
• Excellent communication skills with leadership quality.

Job Segment:
Database, Oracle, ERP, Technology",3.5,"LTI
3.5",Mumbai,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1309,Machine Learning Engineer,"Looking for Data Scientists with Python/R Programming skills.
Specific experience in AI areas like Statistical Machine learning / Deep learning / Natural Language Processing (NLP)/ Operations Research (Optimization) will be an advantage.Individual in this role is expected to work with multiple stakeholders and teams

Qualifications and Requirements:-
Previous working experience as a Machine Learning/ Data Scientist for 2 years
MA in Computer Science or similar relevant field
Hands on experience with MALLET
In depth knowledge of Apache Tomcat/Open Source
Excellent project and time management skills
Attention to detail
Outstanding problem solving and analytical skills",-1,Tekolutions.ai,India,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1310,Data Science Internship,"About the company:
SkillBit is a leading staffing and recruitment company engaged in talent searching assignments for skilled and talented candidates for the industry.

About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Working on data science algorithms and AI concepts 2. Using Python or R for web scraping 3. Building AI models using Python, machine learning, and deep learning algorithms 4. Processing of unstructured/structured data

Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 6th Jun'20 and 11th Jul'20
are available for duration of 1 month
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply

Number of internships/jobs available: 3

Categories: Data Science",-1,SkillBit,Pune,-1,-1,-1,-1,-1,-1,-1,-1
1311,Data Engineer,"As a data engineer at TEAL, you'll be taking the plunge into a rich data lake that includes everything from satellite data to legal court orders. You'll be hustling and getting your hands dirty with every part of the data pipeline always having an implicit appreciation for how all of this data will ultimately power a revolutionary real estate risk platform.

Your day-to-day will include either all or some of the following:

Constantly scoping out new data sources to complement existing ones
Creating and maintaining distributed web scrapers using Python, RabbitMQ and other technologies
Architecting and managing data pipelines where data flows into multiple end-points including, but not limited to, Postgres, MongoDB and Apache Solr
Documenting workflows and constantly iterating to create better data infrastructure.

We'd love it if you:
Are proficient in Python or any other object-oriented language
Have worked with large (millions to hundreds of millions of rows in a SQL database) interdisciplinary datasets
Have scraped difficult websites and have some experience working with various data APIs
Are patient and methodical with unstructured and messy data
Are always hungry to learn newer and better technologies to make the data ecosystem faster, smoother and less silo-ed

Extra brownie points if you:
Have some experience working with large-scale search indexing
Have performed geospatial analyses in some capacity
Have created and managed data lakes in the cloud
Culture

To explore our culture and the values we embody click here

Testimonials
Testimonial

My experience at TEAL surpassed all my expectations from the get-go. I was asked to help solve one of the most daunting problems in the Indian real estate market. Every day while working on a subset of the problem, the ideas that I brought to the table were shaped into cohesive solutions by a collaborative team effort. At TEAL I was exposed to the most cutting edge technologies such as Cloud Computing, Big Data, ML and Data Science. The growth opportunities at TEAL are tremendous, If you are innovative and can demonstrate the will to realize your ideas, TEAL is an amazing organization to work for.
Gyan Vardhan, Data Science Intern
I had interned as a Data Scientist at Terra Economics and Analytics Lab during its early days, it was a rich learning experience working with a multi-disciplinary team who are extremely passionate about building a decision support platform for the insanely complicated realty market in India. It was exciting and challenging to work on mining huge volumes of property records; extracting patterns from the data, building data pipelines and brainstorming on building the core system. TEAL offers a very healthy work environment coupled with insanely talented people working together in an exciting setting.
Naga Anjaneyulu, Data Science Intern
I worked as a full-time Data science intern at TEAL. During this period, I got an opportunity to leverage my skillsets while also learning new technologies, working on tasks assigned to me. The company operates on the latest tech-stacks and gives opportunities to learn as much as you want. The work environment is challenging, the team at TEAL is super supportive and new ideas are always welcome. It has all the good perks of a startup; creativity and innovation, casual work atmosphere and a collaborative approach to solving problems. Personally, I loved working there, my experience was fantastic!
Archana Parmar, Data Science Intern
As a second-year college student, I was looking for an internship that would allow me to delve deeper into research and work with big data, TEAL gave me the perfect opportunity to do so, enabling me to develop proficiency in research and analysis. As a research analyst intern, I collated and cleaned data and helped in the preparation of reports and presentations, and I had members helping me at every stage of this process. This collaborative environment allowed me to cultivate my skills and also learn from my peers. The holy trinity of Rohan, Kshitij, and Shreyas served as not only excellent mentors and bosses but also as friends, helping me at every stage and giving us all food and ice cream to keep us going!
Arush Mehra, Research Intern
Internships are a crucial part of one’s early career. The internship experience at TEAL was a thrilling rollercoaster ride to say the least! It was more than implementing a standard model or building an already though out concept into reality. It was about finding the solution to a unique and open-ended problem.It was exciting to work on addressing a problem with far -reaching real world applications.Moreover, the work environment had the perfect balance of casual yet professional which kept you focused and stress free at the same time. Out of every 100 startups in India only 2 of them succeed, but there are very few like TEAL India which are bound to make it big at such an early stage.
Divyanshu Agarwal, NLP Intern",4.7,"Terra Economics & Analytics Lab (TEAL)
4.7",New Delhi,"Bengaluru, India",1 to 50 employees,2018,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
1312,Senior Consultant - ModellingOps Data Engineer,"Job Title: Senior Consultant - ModellingOps Data Engineer
Location: TRIL GTC
GCL: D1

JOB DESCRIPTION:

AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. The Science & Enabling Units IT is AZs global IT capability function supporting key business areas operating out of sites across the US, UK, Sweden, India & Mexico.

We are looking for AI Ops consultant who will leverage tools & technology best practices to improve delivery performance & data engineering capabilities in the D&A space.

ROLES & RESPONSIBILITIES:

7-10 years of experience in IT Operations involving Data Science, Artificial Intelligence-Machine Learning and Predictive Analytics. Experience in architecting and implementation of end-to-end AIOPs solutions through ELK stack, Splunk. Experience in applying statistical methods, analysis, pattern recognition and modeling on IT Operational data using ELK machine learning. Experience in extracting meaning full data from incoming data streams from different sources through RegEx, Grok etc. Hands-on experience in applying machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc in the IT Operation domain. Experience with machine learning and statistical programming languages - Python, R etc. Experience in assessing the existing IT environment and providing recommendations to reduce the critical applications impacting incidents. Experience in exploring and identifying areas where manual tasks can be automated in IT environment. Experience with various Enterprise IT monitoring solutions including Infrastructure monitoring, Application Performance Monitoring, Network Monitoring, Cloud monitoring etc. Experience in IT Service Management including Service Desk, Incident Management, Change Management, CMDB etc. Excellent knowledge on various IT infrastructure components that includes Server Infrastructure, middle ware, database and application architectures and Cloud Components. Experience/knowledge on Infra monitoring tools - NOI, Zabbix, AppDynamics, Datadog, SCOM, SolarWinds etc. and Service Management tools -IBM Control Desk, BMC Remedy, ServiceNow etc. Experience/Knowledge on BI tools Knowledge on distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc. Knowledge on other programming languages/scripting: Python, Java, JavaScript, etc. ( Added Advantage ) Good analytical skills, strong communication skills are must. Client facing experience is an added advantage. Excellent experience in understanding the problem statement, architect and designing the solution

MANDATORY SKILLS:
Significant experience with AWS cloud environments, working knowledge of Google and Azure platforms. Knowledge of Kubernetes, S3, EC2, Sagemaker, Athena, RDS and Glue is essential.
Experience provisioning computational resources in a variety of Cloud environments using Infrastructure as Code.
Experience with best practice of data transport and storage within cloud system.
Experience building large scale data processing pipelines. e. g. Spark and SQL.
Experience with containers and microservice architectures e.g. Kubernetes, Docker and serverless approaches.
Excellent working knowledge in DevOps, using continuous integration and continuous development.
Use of Data Science modelling tools e.g. R, Python, SAS and Data Science notebooks (e.g. Jupyter).
Good written and verbal skills, fluent English
DESIERED SKILLS:
Agile practices, especially being a SCRUM Master
EDUCATIONAL BACKGROUND: B.E/B.Tech/MCA

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",3.9,"AstraZeneca
3.9",Chennai,"Cambridge, United Kingdom",10000+ employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Roche, GlaxoSmithKline, Novartis"
1313,DATA ENGINEER,"JOB DESCRIPTION
As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements, and also research new uses for data acquisition. You should also know the ins and outs of the industry such as data mining practices, algorithms, and how data can be used.

DESIRED CANDIDATE PROFILE
An ideal candidate must possess prior experience leading a project.

Candidates must have:
> Experience in Hive, Spark, Scala, AWS DynamoDB, HBase, AWS Glue, Talend, Kafka, Snowflake ETL
> Strong experience in a BI/Data Warehouse environment with involvement in design, development, implementation, troubleshooting and support of ETL process using ETL tool.
> Experience in developing Data Marts, Data warehousing and Operational Data Store (ODS) on any of the databases or Hadoop environments.
> Experience in database like MS SQL, MySQL, Oracle, PostgreSQL
> Good to have programming experience in writing Complex Stored Procedures, Queries, Views, User Defined Functions, Cursors and Common Table Expressions using SQL or T-SQL.
> Experience in Performance Tuning and Query Optimization by Indexing, Partitioning and De-normalization.
> Experience in Developing a framework for ingesting data into Data lake
> Good database knowledge, analytical thinking
> Design, construct, install, test and maintain data management systems.
> Build high-performance algorithms, predictive models, and prototypes.
> Develop set processes for data mining, data modeling, and data production.
> Experience with cloud services: AWS (EC2, EMR, S3, Athena) and scripting languages like Python, /PySpark/R/SAS
> Install/update disaster recovery procedures.
> Experience in Agile Application Development & Scrum methodologies is preferred
> Ability to supervise and mentor junior developers on the team.
> Must be self-motivated and work well pulling people together in addition to being able to pull people together technically
> Demonstrated proficiency of troubleshooting techniques and detail-oriented problem diagnosis
> Ability to handle responsibility, is self-directed, with strong organizational and documentation skills
> Ability to work independently and efficiently under aggressive deadlines to meet project commitments
> Excellent verbal and written communication skills

EDUCATION
UG - B.Tech/B.E. - Computers, Electronics/Telecommunication, Diploma - Computers, Electronics/Telecommunication, B.Sc - Computers, BCA - Computers) AND (PG - M.Tech - Computers, Electronics/Telecommunication, MCA - Computers, M.Sc - Electronics, Computers) AND ( Doctorate - Any Doctorate - Any Specialization, Doctorate Not Required).

OTHER DETAILS
Number of vacancies: 4
Experience: 3 years
Location: Cochin

If you have a passion towards technology and coding, then we have the right job for you. Kindly forward your resumes to
Email: jobs@mjsofttech.com
Phone: 0484-2421245 / 928 720 7160",4.0,"MJ Softtech
4.0",Kochi,"Cochin, India",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
1314,Data Engineer,"Education/ Experience and Skill Requirement
4+ years of relevant experience in
Experience working with both relational and NoSQL databases.
Strong coding skills; Python (preferred) /R/Java/Scala
Experience in developing Data warehousing technologies Experience with AWS or equivalent cloud services preferred
Experience in BigData technologies (Hadoop, HDFS, MapReduce, Spark, Hive, HBase etc) will be valuable
Knowledge of Machine Learning a big plus (Random Forest, Decision Trees, SVM, NLP, Gradient Boosting, Supervised/Unsupervised Learning, Clustering, classification and regression modeling).
Responsibilities
Proficiency with several years’ experience in more than one of Python, R, Java, Scala, or robust Linux shell scripting
Implementation experience with data warehouse architecture & design, ETL design/development, and Analytics
Knowledge of general cloud architecture and cloud strategies especially around AWS services and concepts such as S3 object stores, RDS databases, EC2, Glacier, Lambda, IAM, enterprise security, data security, DevOps, replication and disaster recovery
Well versed with data mining & exploration, NLP and visualization
Understanding of data modeling, data integration, and data representation (metadata, OWL, ontologies)
Developing data marts and data management using SQL
Creating powerful visual outcomes
Independently manage daily client communication, especially over calls
Manage client deadlines, ensure quality of the deliverables, attention to detail
Experience/understanding of corporate finance data from company filings is desirable",3.6,"Copal Partners
3.6",Bengaluru,"New York, NY",10000+ employees,1900,Company - Public,Financial Analytics & Research,Finance,₹100 to ₹500 billion (INR),-1
1315,Data Engineer,"Job Description / Responsibilities
Build workflows to ensure data extraction quality and storage into our backend data store
Architect, build and train ML/AI models that can predict outcomes and report on anomalies.
Design data pipelines to perform ETL on content/data from multiple types of source systems.
Create data analytics views using RDBMS/Key-Value stores, on private and public/cloud
Create software that is well tested, maintainable, extensible and scales out with large data

Minimum Qualifications:
2+ years of software development with Python
2+ years of SQL (MySQL/Postgres) and Key-Value databases
1+ years of experience with scikit
2+ years of experience in data extraction, data transformation using custom Python/Java
Experience working with MapReduce/Hadoop/kafka/Elastic stack
Experience with Node backend and React/Redux
Experience working with git/mercurial, Amazon/Google cloud, Linux/LAMP stack
Experience in testing or test driven development
Experience with Data science and Machine Learning algorithm development

Location:
Hyderabad/Bangalore

Package:
Highly competitive to match experience and capability",3.7,"TVS
3.7",Bengaluru,"Chennai, India",5001 to 10000 employees,-1,Company - Private,Accounting,Accounting & Legal,₹100 to ₹500 billion (INR),-1
1316,Data Engineer,"Permanent position with US based client of iFlex.
Work Location: Bangalore
Experience Level: 2+ Years

Role:
As part of our global team you will work on the data platform reporting to the Data Engineering Lead. Your role includes specification, development, test and rollout of features on our data platform. You are expected to contribute to the vision, understand our product roadmap, integrate business value andclient experience and contribute to build an engineering culture within the team. This initiative is of critical important to the success of the organization and our roadmap, for instance, services like liquidity analytics, billing, client onboarding, reporting and others will rely on the data platform. Accurate, granular, complete and timely data will be our key differentiating factor and competitive advantage in the market place. We expect the successful candidate to deliver high quality software and to be passionate about data engineering..

Responsibility / Qualification:
Managing multiple tasks and use sound judgment when prioritizing.
Collaborating with global cross functional team in building customer-centric products.
Analyzing existing software implementations to identify areas of improvement and provide deadline estimates for implementing new features.
Updating and maintain documentation for team processes, best practices and software runbooks.
Establishing trusted partnerships with peers, product heads, and executive level stakeholders.
We are looking for someone who is passionate about technology and engineering.
Exceptional analytical skills and ability to apply knowledge and experience in decision-making to arrive at creative and commercial solutions.
Ability to leverage technology to deliver business value.
You are independent and comfortable in a fast paced, ambiguous and often multi-directional work environment.

Preferred Qualifications:
B.S. or higher in Computer Science.
Minimum 2 years of relevant professional experience using a modern programming language (preferably Java/Scala).
Experience leveraging test driven development technics.
Comfort with Agile operating models.
Team oriented.
Strong interpersonal and communication skills.
Energetic, self-directed, and self-motivated.
Experience with microservice architecture.
Experience with Kafka, MongoDB, Hadoop, Cassandra.
Experience with AWS.
Experience in Financial Services or Fintech.",-1,IFLEX,Bengaluru,"Moscow, Russia",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1317,CIEL/SEL/1941: Sr data scientist,"Mandatory skills required -
Databases (SQL, Oracle, Any RDBMS) - Should have working knowledge of atleast one database
PL/SQL Programming Languages
R, Python (Any One)
Inferential Statistics - Hypothesis, p-value, R2, RMSE, MAPE etc
Exploratory Data Analysis
Machine Learning Algorithms - Should have in-depth knowledge and implementation of atleast one algorithm

Responsibilities
: Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the why & how of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions

Education
Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics
Experience
Minimum years of related experience required: 3 years
Preferred years of experience: 5 years
Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desirable.

Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
1318,Data Engineer,Data Engineer,3.6,"Bookmyshow
3.6",Mumbai,"Mumbai, India",1001 to 5000 employees,2007,Company - Private,Ticket Sales,"Arts, Entertainment & Recreation",Unknown / Non-Applicable,-1
1319,Data Analyst,"Required Skills & Experience

We are looking for a Data Analyst Executive
Eligible Qualifications : B. Tech, BCA, M.Tech, MCA
Experience : 3-5 years, fresher’s can also be considered
Location of Job : Gurgaon/Connaught Place, New Delhi
Technicals Skills

Following technical skills are pre-requisite:
Well versed with Software development methodologies, such as SDLC (Software Development Life Cycle), DDLC (Document Development Life Cycle).
Database schema design and implementation
Should have worked in either of technologies Sql Query/ Tableau/ Excel (Macros)/ Access (Query) writing for data analytics.
For planning and coordinating activities, organizations remain in invariant communication with one another and the data transfer has to be performed efficiently and smoothly as possible.
He/ She should manage the execution of the technologies, help the businesses in utilizing the systems, and should be well versed with the basics of computer systems such as Networking, Installation of necessary software and hardware.
Ability to determine the interrelationships between solutions and requirements.
Ability to think analytically and should be a problem solver and logic building should be very strong.
Good interpersonal skills to form effective working relationships with people at all levels.
Excellent communication and presentation skills and strong written & oral English skills.
To know more about us visit us www.sspl.net.in or write to us at admin@sspl.net.in",-1,Substratal Solutions,Connaught Place,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1320,Artificial Intelligence Scientists,"Experience 2- 4 Years
Salary 4 LPA - 6 LPA
Job Location Chennai

Industry:
IT-Software / Software Services

Keywords:
Artificial Intelligence

About Job:
Must have Excellent knowledge in AI / Machine learning (Mandatory).
Machine learning frameworks like keras, tensor flow etc.
And also other big data tools like Hadoop etc, Must know R and python.
Good understanding in SDLC & Business cycle.",4.0,"Careerera
4.0",Chennai,"Wayland, MA",501 to 1000 employees,-1,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
1321,Senior Data Engineer,"About Us

upGrad is an online education platform building the careers of tomorrow by offering the most industry-relevant programs in an immersive learning experience. Our mission is to create a new digital-first learning experience to deliver tangible career impact to individuals at scale. upGrad currently offers programs in Data Science, Machine Learning, Product Management, Digital Marketing, and Entrepreneurship, etc. upGrad is looking for people passionate about management and education to help design learning programs for working professionals to stay sharp and stay relevant and help build the careers of tomorrow.
upGrad was awarded the Best Tech for Education by IAMAI for 2018-19
upGrad was also ranked as one of the LinkedIn Top Startups 2018: The 25 most sought-after startups in India
upGrad was earlier selected as one of the top ten most innovative companies in India by FastCompany.
We were also covered by the Financial Times along with other disruptors in Ed-Tech
upGrad is the official education partner for Government of India - Startup India program
Our program with IIIT B has been ranked #1 program in the country in the domain of Artificial Intelligence and Machine Learning
About the Role

We are looking for a Data Engineer to help us scale the existing data infrastructure and in parallel work on building the next generation data platform for analytics at scale, machine learning infrastructure and data validation systems.
In this role, you will be responsible for communicating effectively with data consumers to fine-tune data platform systems (existing or new), taking ownership and delivering high performing systems and data pipelines, and helping the team scale them up, to endure ever growing traffic.
This is a growing team, which makes for many opportunities to be involved directly with product management, development, sales, and support teams. Everybody on the team is passionate about their work and we’re looking for similarly motivated “get stuff done” kind of people to join us!

Roles & Responsibilities
Engineer data pipelines (batch and real-time ) that aids in creation of data-driven products for our platform
Design, develop and maintain a robust and scalable data-warehouse and data lake
Work closely alongside Product managers and data-scientists to bring the various datasets together and cater to our business intelligence and analytics use-cases
Design and develop solutions using data science techniques ranging from statistics, algorithms to machine learning
Perform hands-on devops work to keep the Data platform secure and reliable
Skills Required
Bachelor's degree in Computer Science, Information Systems, or related engineering discipline
6 + years’ experience with ETL, Data Mining, Data Modeling, and working with large-scale datasets
6+ years’ experience with an object-oriented programming language such as Python, Scala, Java, etc
Extremely proficient in writing performant SQL working with large data volumes
Experience with map-reduce, Spark, Kafka, Presto, and the ecosystem.
Experience in building automated analytical systems utilizing large data sets.
Experience with designing, scaling and optimizing cloud based data warehouses (like AWS Redshift) and data lakes
Familiarity with AWS technologies preferred
Qualification – B.Tech/M.Tech/MCA(IT/Computer Science)

Years of Exp – 6-9",3.5,"upGrad Education Private Limited
3.5",Mumbai,"Mumbai, India",501 to 1000 employees,2015,Company - Private,Education Training Services,Education,₹1 to ₹5 billion (INR),"Udacity, General Assembly, Springboard"
1322,BBRC-Genomics-Associate Scientist,"JOB DESCRIPTION

Designation: Associate Scientist

Job Location: Bangalore

Department: Translational Medicine- Translational Sciences

About Syngene

Incorporated in 1993, Syngene International Ltd. is an innovation-focused global discovery, development and manufacturing organization providing integrated scientific services to the pharmaceutical, biotechnology, nutrition, animal health, consumer goods and specialty chemical industries around the world. Syngene’ s clientele includes world leaders such as Bristol-Myers Squibb, Baxter, Amgen, GSK, Merck KGaA and Herbalife. Its innovative culture is driven by the passion of its 4240- strong team of scientists who work with clients from around the world to solve their scientific problems, improve R&D productivity, speed up time to market and lower the cost of innovation .

Job Purpose:
To play a key role in TM-TS, develop an early-stage research strategy, initiate and lead discovery programs while managing ongoing programs in TM-TS. The role will work part of TMTS, and work with internal and external collaborators .

Key Responsibilities:
Experience in isolating DNA and RNA from blood, tissues and FFPE samples and cell lines. Experience with optimization of extraction protocols and for parameters like yield, input sample quantities and sample types is important.
Expertise in PCR, qPCR, cDNA/gDNA library preparation. Exposure to microarray techniques.
Proficiency in preparation of libraries for Next Generation Sequencing of transcriptome and genome, with significant experience in optimization of parameters like input RNA/DNA quantities and sample type
Experience with single cell RNA-seq will be plus.
Experience with various NGS protocols (DNA Amplicon based, hybrid capture based low input, degraded DNA and RNA samples e.g. FFPE samples.
Strong understanding of experimental design and statistical principles behind experimental design and differential gene expression. Experience with analysis of single cell RNA-sequencing data will be a plus

Educational Qualification:
M.Sc or M. Tech in Biotechnology, Molecular biology or Biological Sciences,

Technical/functional Skills:
DNA/ RNA Isolation, Expertise in PCR, qPCR, Experience in NGS protocols

Experience:
2 to 5 Years

Behavioral Skills:
A proactive team player.
Ensure completion of experiments and generate accurate and reproducible data from experiments.
Ability to work independently, prioritize tasks and work on multiple projects simultaneously with; comfortable working in a dynamic environment with changing requirements.
Good oral and written communication and presentation skills to work in a multi-disciplinary team
Equal Opportunity Employer:
It is the policy of Syngene to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by applicable legislation or local law. In addition, Syngene will provide reasonable accommodations for qualified individuals with disabilities.",3.5,"Syngene
3.5",India,"BENGALURU, India",1001 to 5000 employees,1994,Unknown,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1323,Applied Scientist 1,"Position Requirements:
Master's degree in Computer Science, Computer or Electrical Engineer, Mathematics, or a related field plus at least one year of experience in the job offered or related occupations of Software Engineer, Software Developer, or a related occupation. Employer will accept a Bachelor’s degree and five years of experience in the job offered or a related occupation as equivalent to the Master’s degree and one year of experience. One year of experience in the job offered or related occupation must involve designing and developing large-scale, multi-tiered, distributed software applications, tools, systems and services using Java, Object Oriented Design and Distributed Programming].

Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, Oracle/Berkeley databases, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills

Amazon Selling Partner Services team drives the Selling On Amazon business and develops solutions that enable millions of sellers around the world to sell on Amazon's Marketplaces. More than half of shipments for Amazon customers are generated from this business. The team is focused on building a technology platform that will support the explosive business growth in existing markets, streamline the business for Amazon and the Selling partners and launch business in new markets and establish a fair marketplace.

Our team is seeking engineers with broad technical skills to help us optimize how we synthesize massive amounts of data and complex business rules into mission critical financial information. As a member of this team you will employ object oriented techniques in Java, and DynamoB, PostGres and ElasticSearch skills to help us support Amazon's next generation of selling partner services. Along the way you'll gain and leverage a unique understanding of how Amazon.com works; from the numerous software systems that comprise the website's back-end, to the details of our business model, and the relationships we're establishing with an ever-growing network of selling partners who depend on Amazon.com to run their businesses.

The ideal candidate will draw upon exemplary analytical, critical thinking, and problem solving skills, and a passion for maintaining highly reliable, distributed systems which operate 24/7/365. Successful members of this team collaborate effectively with internal end-users, aggressive cross-functional software development teams, and technical support/sustaining engineering teams to solve problems and deliver successfully against high operational standards of system availability and reliability. We look for engineers who are excellent communicators, self-motivated, flexible, hardworking, and who like to have fun!

Position Responsibilities:
Participate in the design, development, implementation, testing and documentation of large-scale, multi-tiered, distributed software applications, tools, systems and services using [Java, Object Oriented Design and Distributed Programming]. Translate functional requirements into robust, scalable, supportable solutions that work well within the overall system architecture. Participate in the full development cycle, end-to-end, from design, implementation, and testing to documentation, delivery and maintenance. Produce comprehensive, usable software documentation. Evaluate and make decisions around the use of new or existing software products and tools.

Preferred Qualifications
Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1324,Senior Clinical Data Analyst,"About Novotech:

Novotech is internationally recognised as the leading independent and full-service contract research organisation (CRO) in the Asia Pacific region. We provide a wide range of clinical development services across all research phases and therapeutic areas and have been instrumental in the success of hundreds of Phase I – IV clinical trials throughout the Asia Pacific. Powered by the highest quality people, Novotech strives to set the benchmark for both business and clinical trial performance. Our people are one of our key strengths. We value our people and recognise the work they do. We are lucky to have the best people and talent from across the Asia Pacific region work together to deliver to clinical trial success for our clients. Our people and those we look to recruit have an attitude of making things happen. They are problem solvers, driven with a focus on delivering quality, accountability and a high level of performance.

Brief Position Description:

As part of Novotech’s Biometrics unit, the Senior Data Analyst (SDA) is responsible for all data analysis and business intelligence activities related to study related clinical and operational data. The SDA acts as primary point of contact for all data analysis matters to the study team and is responsible for the timely delivery of quality outputs following all applicable regulatory, compliance, best practice and operational procedures.

Minimum Qualifications & Experience:

Graduate in information science, data science or life science-related field, or similar. More than five years’ experience in a senior role related to data science, data analysis, clinical data management or clinical data programming in a pharmaceutical company, CRO or EDC software provider.

Responsibilities
The Senior Data Analyst (SDA) is responsible for providing technical, procedural (SOPs) and planning leadership across multiple projects assigned to the data analyst team members ensuring that they deliver in accordance with SOPs, programming best practices, and the timelines agreed within the Project Team.
Collaborate with cross-functional stakeholders to implement data science solutions to solve business needs using available technological solutions.
Scope data analysis effort for projects and project manage all data analysis activities across multiple projects for different study stakeholders.
Gather study requirements from data management for data review and external data reconciliation and provide guidance on appropriate outputs (dashboards, visualisations, listings, reports).
Extract, assess, integrate, transform data sources to provide data visualisation outputs for analytics.
Design and develop prototypes and final versions of data outputs (dashboards, reports, visualisations, listings) using Business intelligence tools and Data Visualisation tools.
Design and develop standard dashboards and content for different audiences.
Analyse, manipulate and understand data from multiple sources to present and create dashboards and reports to make business decisions.
Assist teams on best-practice for data visualisation dashboard development.
Educate teams on how to use all the features of applicable data visualisation platform in conjunction with data visualisation dashboards.
SME for the data visualisation development and assisting team members.
Identify and communicate project risks and maintain documentation within project files as appropriate
Represent data analysis group at internal / external meetings as appropriate.
Assess and implement new data analysis, BI and data visualisation processes and technologies.
Take an active role in the development of best practices, process improvement, quality control and governance related to all data analysis matters.
Provide training and mentoring to Data Analysis of team members in SOPs, software applications, and best practices.
Provide Subject Matter Expertise on all data analysis and visualisation related activities.
Attributes and Skills

Expert knowledge of clinical study data structures and schemas of EDC databases. Expert knowledge in data processing activities such as extracting, integrating, transforming and presenting data. Statistical Programming skills in Python, R or similar. Knowledge of SQL and EDC systems. Working knowledge of Spotfire, Power BI, Tableau or other data review and visualisation tool. Ability to gather business requirements from multiple stakeholders and clients and provide guidance on the use of appropriate data visualisations.

Experience mentoring and training others. Awareness of regulatory and compliance issues and understanding of the application of SOPs and Quality Control to daily activities. Excellent analytical, communication and problem-solving skills.

Opportunities and Benefits:

To deliver clinical trial and research excellence for our clients, our people are 'best in class'.

At Novotech, we seek and nurture people with exceptional talent. We are committed to providing our people with regular internal and external training, a competitive bonus structure and a supportive work environment. We are also focused on providing our people with a wide variety of career growth and development opportunities.

For more information about where your next career step at Novotech might take you, visit http://novotech-cro.com/novotech-careers",4.5,"Novotech
4.5",Bengaluru,"Sydney, Australia",501 to 1000 employees,1996,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
1325,Data Engineer,"Data Engineer Responsibilities:
Liaising with coworkers and clients to elucidate the requirements for each task.
Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed.
Reformulating existing frameworks to optimize their functioning.
Testing such structures to ensure that they are fit for use.
Preparing raw data for manipulation by Data Scientists.
Detecting and correcting errors in your work.
Ensuring that your work remains backed up and readily accessible to relevant coworkers.
Remaining up-to-date with industry standards and technological advancements that will improve the quality of your outputs.
Data Engineer Requirements:
Bachelor's degree in Data Engineering, Big Data Analytics, Computer Engineering, or related field.
Master's degree in a relevant field is advantageous.
Proven experience as a Data Engineer, Software Developer, or similar.
Expert proficiency in Python, C++, Java, R, and SQL.
Familiarity with Hadoop or suitable equivalent.
Excellent analytical and problem-solving skills.
A knack for independent and group work.
Scrupulous approach to duties.
Capacity to successfully manage a pipeline of duties with minimal supervision.
Job Type: Full-time

Salary: ₹360,000.00 to ₹870,000.00 /year

Experience:
total work: 2 years (Preferred)
Data Engineer: 1 year (Preferred)
Education:
Diploma (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,Futurious Technologies,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1326,Quantitative Analyst,"The successful candidate will be a highly analytical individual with hands on programming skills. The candidate will work closely with the research team and clients towards the ongoing development and integration of new investment strategies, models and tools on Axle

Location

Mumbai
Responsibilities

Perform daily/weekly/monthly tasks of performance and risk reporting
Develop and automate investment processes and strategies via VBA and Matlab
Develop tools to integrate trading decision systems with risk management systems
Ad hoc tasks (such as operational tasks, internal documentation tasks and preparation of marketing materials)
Skills/Experience

Excellent programming skills in Matlab/Excel-VBA
Thorough with financial concepts and calculations like Drawdown, VaR, Eloss etc.
Understanding of financial market products like options, futures, FX forwards etc.
Working knowledge of Bloomberg is preferred
Should be self-driven and detail oriented with an analytical mindset
Should be a proactive and quick learner; a team player showing enthusiasm and drive to accomplish results in a fast paced environment
Min. 2 years of relevant work experience
Qualifications

B.Tech/M.Tech/MBA/CFA/FRM",5.0,"B&B Analytics
5.0",Mumbai,"Zug, Switzerland",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1327,Analyst - Data Scientist,"Job Summary

Experience:
3 - 5 Years

Location:
Mumbai

Designation:
Analyst - Data Scientist

Degree:
BE-Comp/IT, BE-Other, BTech-Comp/IT, BTech-Other, ME-Comp/IT, ME-Other, MTech-Comp/IT, MTech-Other, PhD-Comp/IT, PhD-Other

Educational Level:
Graduate/Bachelors

Industrial Type:
IT-Software/Software Services

Functional Area:
IT Software - Application Programming / Maintenance

Key Skills:
Data Scientist

Job Post Date:
Thursday, March 19, 2020

Company Description

We are capability centre based in Mumbai, initially started as a back-office operational support to the UK business unit.

However, over the recent years, we have significantly increased the breadth and depth of our capabilities and offerings to keep pace with the changing needs of the Group. These include Digital & Knowledge Services, Finance and Actuarial, Information Technology (IT), Customer Service, Risk and Audit.

Our core purpose is to be a strategic partner to company, enabling growth by delivering change and driving synergies through a highly capable and agile workforce.

With our diversified service offerings we provide our people with exciting opportunities to grow personally and professionally.

Company is a leading savings and investments business serving around 5.5 million retail customers and more than 800 institutional clients.

It-s innovative asset management and customer solutions are supported by extensive investment capabilities, an international distribution network and two strong brands.

Job Description

3 – 5 yrs experience as Data Scientist
Should have at-least 1 end-to-end ML project experience
Very high proficiency in R or Python
Excellent in forecasting methods like simple exponential smoothing, multiplicative seasonal indexes, simple and weighted moving averages and time series forecasting methods
Exposure to with advanced deep learning techniques such as LSTM. CNN, Dense neural networks as well as neural networks design and implementation through tools like tensorflow, keras, pytorch, deepai or equivalent.
Good SQL experience",3.8,"Sampoorna Computer People
3.8",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
1328,Data Lake Developer,"For Us, It's A Mission

At Mylan, we mean it when we say we work every day to provide access to high quality medicines to the world's 7 billion people. If you are unconventional, relentless and passionate. If you believe in doing what's right, not what's easy. If you are a doer and have a passion for serving others, we want to talk to you.

Make a Difference

At Mylan, each person has the ability to make a difference. From the providers who sell and market our products, to the producers who develop and manufacture them and finally to our business partners who support the providers and producers, we all have a mission critical role. Here's how this role will help:

ESSENTIAL DUTIES AND RESPONSIBILITIES
To perform this job successfully, an individual must satisfactorily perform each essential duty. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential duties.
1. Create and maintain optimal data pipeline architecture on Azure platform.
2. Develop batch processing solutions by using Data Factory and Azure Databricks.
3. Delivering a Data Warehouse in the Azure Cloud.
4. Design relational and non-relational data stores on Azure.
5. Identify, design, and implement internal process improvements : automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc..
6. Developing Big Data Solutions with Azure Machine Learning.
7. Strong interaction with business departments to provide consultative support for digitization efforts, as well as close collaboration with the Business Technology management, focused on future innovation topics.
8. Participate and lead in design sessions, demos and prototype sessions, testing and training workshops with business users and other IT colleagues.
9. Design & Build for any API Development or SQL DB development.
10. Providing service management, orchestration, monitoring and management requirements of Azure cloud platform.
11. Create data tools / products for analytics and data scientist team members that assist them in building and innovative solutions that drive tangible business value.
12. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
13. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
14. Design security for source data access. Chose the appropriate authentication mechanism, (ie Azure Active Directory (Azure AD), etc).
15. Design for real-time processing by using Stream Analytics and Azure Databricks.

Make Our Values Your Values

Mylan hires only the best. People who thrive in a culture of innovation and empowerment. People who are active learners and have a positive attitude. People who are leaders and know that by working together we can run faster, reach higher and achieve more. By doing so, we will continue to set new standards in health care. Here are the minimum qualifications and essential functions for this position:

QUALIFICATIONS

The qualifications listed below are representative of the minimum knowledge, skill, and/or ability required.

SKILLS AND ABILITIES

1. 10 years of experience in Microsoft technologies including SQL.

2. At least 5 years as a Sr Developer with at least 3 years hands on experience as Azure Data Engineer building large scale Azure data solutions.

3. At least 5 years of experience in Azure based data solutions.

4. At least 3 years of experience on working with large projects including the most recent project in the cloud (Azure) or on prem with a focus on Azure Data services.

5. At least 5 years of Hands-on administration, configuration management, monitoring, performance tuning of Hadoop/Distributed platforms.

6. At least 5 years of demonstrated experience at least in the most recent 2 years of designing and delivering solutions using Cortana Intelligence suite of analytics services part of Microsoft Azure including Azure Machine Learning Studio, HDInsight, Polybase, Azure Data Lake Analytics, Azure Data Warehouse, Streaming Analytics, Data Catalog, R/R Studio

7. Experience in designing and building logics required for optimal extraction, transformation, and loading of data from a wide variety of data sources

8. Experience within Data Security design, including but not limited to:

a. Choosing the appropriate authentication mechanism, such as Azure Active Directory (Azure AD)

b. Defining strategies for data encryption for data at rest and in transit

9. Experience partnering with Business Analysts and Data Scientists to enable effective and efficient data preparation and delivery

10. Experienced in vendor management and working with 3rd parties onshore & offshore.

11. Experience working in a global team.

12. Experience working in an Analytics / Big Data solutions on MS Azure Cloud

13. Experience with code management tools, automated testing

14. Experience creating and maintaining optimal data pipeline architecture on Azure platform

15. Experience developing batch and real-time processing solutions by using Data Factory and Azure Databricks

16. Familiar with AGILE and Azure DevOps methodology

17. Hands on PoC capabilities are needed to prove a particular architecture concept

18. Azure Native Services experience across Data Fabric and Service Fabric

19. Experience in Application modernization from legacy on-premise data architecture platform technology stack to modernized Azure Cloud base Architecture.

20. Experience with Git, NoSQL Data Solutions, Microsoft Azure, HD Insights, Azure ML, DataBricks ML Flow, R or Python.

21. Must have excellent communication skills.

EDUCATION/EXPERIENCE (Note: Please select one)

Minimum of a Bachelor's degree in Computer Science and Engineering is preferred with minimum 10 years of experience. However, a combination of experience and/or education will be taken into consideration

Why Mylan?

If you want to be part of a global health care company that is making a difference and changing lives, Mylan may be the place for you. With a workforce of more than 35,000 worldwide, we can make a difference. We encourage you to visit Mylan.com to learn more about our unconventional culture, our approach to doing business and how we plan to set new standards in health care.

Mylan offers competitive salary, excellent benefits and an environment conducive to professional growth and advancement. All qualified applicants will receive consideration for employment without regard to their disability or protected veteran status. Mylan is an Equal Opportunity Employer, Minorities/Female/Disabled/Veteran.",3.8,"Mylan Inc.
3.8",Bengaluru,"Hatfield, United Kingdom",10000+ employees,1961,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1329,Off Campus Recruitment - Quantitative Researcher,"Description:
Graviton is a privately funded quantitative trading firm striving for excellence in financial markets' research. We are seeking fresh talent from the top IIT's to join us as Quantitative Researchers for our team in Gurgaon.If you are a student graduating in 2020 from Computer Science , Electrical or Maths Stats Computing streams with a greater than 8 CGPA please apply here.

This role is open to students from campuses that we could not visit this year. Please check your individual placement policy restrictions before applying.

Graviton trades across a multitude of asset classes and trading venues using a gamut of concepts and techniques ranging from time series analysis, filtering, classification, stochastic models, pattern recognition to statistical inference analysing terabytes of data to come up with ideas to identify pricing anomalies in financial markets.

As a Quantitative researcher your responsibilities will include

Develop new or improve existing trading models using in-house platforms

Use advanced mathematical techniques to model and predict market movements

Analyse large financial datasets to identify trading opportunities

Provide real time analytical support to experienced traders

Requirements :
Possess a degree in a highly analytical field, such as Engineering, Mathematics, Computer Science from IITs schools

Quantitative bend of mind

A working knowledge of Linux/Unix

Programming experience, preferably in C++ or C

Strong interest in learning about financial markets.

Have a strong work ethic

Hard Working

Benefits:
Our open and casual work culture gives you the space to innovate and deliver. Our cubicle free offices , disdain for bureaucracy and insistence to hire the very best creates a melting pot for great ideas and technology innovations. Everyone on the team is approachable, there is nothing better than working with friends!

Our perks have you covered.

Competitive compensation

6 weeks of paid vacation

Monthly after work parties

Catered breakfast and lunch

Fully stocked kitchen

Gym membership

International team outing",5.0,"Graviton Research Capital LLP
5.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2014,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1330,Data Engineer,"Zauba Technologies is a startup based in Bangalore. Zauba's services are used by leading companies in India. Zauba is powered by a young and passionate team. We are looking for individuals who would like to be a part of our founding team.

As a Data Engineer and as a part of founding team, you will be expected to visualise and develop disruptive data products. Eventually you would be responsible for entire project lifecycle of products you would visualize. Your rewards will be directly proportional to the value you generate.

Job Responsibilities
Design and development of robust, scalable and highly efficient data engineering solutions for structured and unstructured data (Including gathering and processing raw data at scale, writing scripts, web scraping, calling APIs, writing SQL queries, etc.)
Develop processes for text mining and extraction of information from unstructured data
Design, architect and develop efficient data pipelines around the data collected
Take ownership of existing web product and applications
Design and implement data models that scale across the enterprise
Take ownership of existing data workflows and processes
Enhance scalability, performance, and stability of existing infrastructure
Work closely with other team members to integrate your innovations and algorithms into our production systems

Essentials
Java/Python - Intermediate to advanced level
SQL - Advanced
MySQL Intermediate to advanced level
Regex - Basic to intermediate level
Linux Basic to intermediate level

Good to have
Hadoop/Spark
R
MongoDB

Must have qualities
Skills to learn new skills quickly
Desire to create disruptive products and services
Passion - not just to work in startups but to take them to next level
Above average programming aptitude
Be passionate about producing high quality engineering deliverables
Be productive working independently or collaboratively
Have an eye for building efficient processes
Be self motivated
Proactively take ownership

Interested?

Send your resume to hr@zaubacorp.com",3.8,"Zauba Corp
3.8",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 million (INR),-1
1331,Quantitative Research,"We are looking for highly trained professionals who are interested in applying advanced mathematical quantitative methods to the modeling of global financial markets. You would be joining a group made up of highly proficient individuals from various scientific disciplines. We have a spectrum of opportunities for individuals with the right scientific skills. Experience in finance is not required.

The ideal research candidate will have:
A Ph.D. in Computer Science, Mathematics, Physics, Statistics, or a related technical discipline.

A demonstrated capacity to do first-class research.

Computer programming skills.

An intense interest in applying quantitative analysis to solve difficult problems.

Send us a copy of your resume to
careers@dolatcapital.com

For internship opportunities, please send us a copy of your resume to
careers@dolatcapital.com",4.0,"Dolat Capital
4.0",Mumbai,"Mumbai, India",51 to 200 employees,1970,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1332,Data Engineer,"Bachelor’s degree in Computer Science or related field
5+ years relevant experience
5+ years experience with SQL, SQL Tuning, Oracle, OLAP, Big Data Technologies
5+ years experience developing end-to-end Business Intelligence solutions: data modeling, ETL and reporting
Experience with Java and experience with scripting languages like Perl, Python, Unix shell scripts,VBA and MS Excel
Proficiency with Linux and systems administration
Proven ability at looking at solutions in unconventional ways. Sees opportunities to innovate and can lead the way.
Top notch communication (verbal and written) and interpersonal skills to convey key insights from complex analysis in summarized business terms and an ability to effectively communicate with technical teams.
Ability to work with shifting deadlines in a fast paced environment.
Operations Finance Technology team, responsible for building technical solutions for multi-billion WW Operational Cost analytic including Inbound cost (Receiving / PO), variable Cost, fixed cost, outbound (Customer Shipments / Transportation), and Customer Service, is looking for a Data Engineer.

As a data engineer, you will get the exciting opportunity to work on very large data sets in one of the world's largest and most complex data warehouse environments. You will work closely with the business teams in analysis on various cost savings initiatives, many non-standard and unique business problems and use creative-problem solving to deliver actionable output.
You will be responsible for designing and implementing an analytical environment using third-party and in-house reporting tools, modeling metadata, building reports and dashboards. You will have an opportunity to work with leading edge technologies like Redshift, Hadoop/Hive/Pig. You will be writing scalable queries and tuning performance on queries running over billion of rows of data.

You should be analytical, have an extremely high level of customer focus and a passion for process improvement. You should be motivated self-starter that can work independently in a fast paced, ambiguous environment. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions.
Bachelors in Computer Science or related field
Practical Knowledge of Linux or Unix shell scripting
Experience in working with business customers to drive requirements analysis
Exposure to large databases, BI applications, data quality and performance tuning
Excellent written and spoken communication skills
Experience with Hadoop-based technologies such as HBase, Pig, Hive and Spark
Strong proven ability in building high-performance, highly available and scalable data solutions using Oracle and/or Hadoop-based technologies
Knowledge of data warehousing concepts.
Strong sense of ownership, urgency, and drive
Strong troubleshooting and problem solving skills
Experience with Amazon Web Services",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1333,DATA ANALYST,"posted by Mahima Gaur

2 - 5 years Delhi

Job Description
Experience in data processing
Experience in data cleaning and data tabulation activities
Strong analytical, communication and team management skills
Strong understanding of data management using SPSS and research techniques
Competency in a Tabulation software (decipher / wincross / quantum etc), Excel, Powerpoint
Ability to summarize findings, draw conclusions, and put together a presentation using Powerpoint
Role Category : Data Analyst

Employment Type : Permanent Job, Full Time",4.9,"Knowledge Excel Services.
4.9",New Delhi,"New Delhi, India",1 to 50 employees,2007,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
1334,Data Engineer,"Key skills : Python , Spark , SQL , Pyspark • AWS platform used for the work • Strong experience in SQL is mandatory • Good familiarity of AWS landscape • Good experience in collecting business requirements & design them as per requirement from customer • Should able to work independently & interact business users & technical stakeholders • Strong communication skills both oral & written. • Should work as an individual resources",3.5,"Larsen & Toubro Infotech Limited
3.5",India,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1335,Big Data Engineer,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
1336,Client Data Analyst,"At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.
What is the Client Data Analyst – Client Analytics group responsible for?
This team manages business data to ensure accurate, timely, consistent and compliant data. Their contributions deliver quality data that is easily accessible and can be trusted. Key downstream capabilities such as reporting and analytics depend on this as well as operational data access on various systems. The Data Management Team is a support function that acts as an advocate and a point of contact for Sales and Marketing data.

What are the ongoing responsibilities of an Client Data Analyst ?
Understand the data flow, key consumption and production of data as well as context within the enterprise:
Build positive relationships with teams, especially the key data consumers and analytics. Take the time to increase knowledge of how they run their business and incorporate sales data into daily work
Connect regularly with each sales office to understand current issues and challenges. Probe the business and validate against other sales offices to understand the scope and priority of the issue
Make recommendations on how data unifications and flow can be used to improve business tasks. Liaise business partners to deliver solutions (reports, processes, technology) that add value.

Provide data management subject matter expertise. Appreciate the connection and data flow between applications and other corporate systems. Be able to clearly articulate the data needs and move initiatives forward by collaborating with business partners:
Actively participate in meetings with business partners to ensure that priorities are clearly understood, information is regularly shared and that key participants are “kept in the loop”
Provide context and background on issues. Collaborate on ideas for progressing initiatives. Ensure appropriate resources are involved to take initiatives forward
Provide insights and expertise to scope statements and requirements documentation
Actively consult or participate in the user acceptance testing process (test cases, documentation, testing execution, etc.)
Ensure business needs remain aligned with overall corporate initiatives and deliver the benefits as originally intended

Monitor the integrity of data and usefulness of reports. Ensure the information available within systems is accurate and up-to-date. Proactively seek data cleansing opportunities and evolve data to better support. Document and maintain ongoing processes for reporting and data clean-up:
Partner with all key data consumers to gain a solid understanding of usage and challenges around data. Establish processes for prioritization of enhancements, especially with the analytics groups
Provide 1st level support for data issues and data maintenance for owned data
Verify and execute data loads into our internal sales systems and ensure any upstream systems accurately receive their data

Increase awareness and promote data management capabilities. Share best practices and provide coaching to local offices on how to access and incorporate output into sales tasks. Encourage IAS leaders to leverage data to make more informed, strategic decisions:
Clearly articulate the goals and core services of the data management team. Proactively promote this information within IAS and ensure business partners understand the data management role within the organization
Share best practices and provides guidance on data capabilities. Reinforces ownership and accountability for data accuracy
Seek opportunities to share the benefits of leveraging sales data to make more informed business decisions

What ideal qualifications, skills & experience would help someone to be Successful?

Knowledge, Education And Experience:
Four year bachelor’s degree required (majors of preference include: business, computer science, mathematics) Advanced degree a plus
Understanding of the Franklin Templeton business model, how FT makes money, the sales process, how technology fits in with the business, etc. Knowledge of the GAS (Global Advisory Services) structure
Experience working through multiple business fiscal cycles; exposure and/or direct experience with project management and/or sales-related-capacity required
Prior work experience related to analytics, sales, marketing and/or international a must. Level will not be granted based on years of experience but will be determined by the employee’s ability to meet each job activity as outlined the ‘typical/expected focus by level
Skills And Abilities:
Ability to communicate effectively with all levels of management; ability to tailor communication style based on audience; ability to get others to want to collaborate with you; strong facilitation skills
Excellent writing skills (for presentations, documentation, etc.)
Working knowledge of the CRM, MDM, Excel, SQL, Power BI, Tableau, Business Objects, and Microsoft Products (PPT, Power Apps, Doc, Visio)
Ability to absorb and interpret large quantities of data; apply trend analysis and knowledge of the business to develop a meaningful and digestible summary with the appropriate level of detail
Ability to take a larger problem and break down the individual components; identify how to go about solving the problem and who to involve in the process
Ability to present recommended solutions to a variety of issues and problems (solutions that are consistent with organization objectives)
Must be extremely detail-oriented (managing lists, tasks/to-dos, etc.) good with follow through on own items; good with following up with others on outstanding item

What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.

Highlights of our benefits include:

Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.",3.8,"Franklin Templeton Investments
3.8",Hyderabad,"San Mateo, CA",5001 to 10000 employees,1947,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Fidelity Investments, Vanguard"
1337,Data Analyst,"Roles and Responsibilities:
Extracting, transforming and inputting data sets from various resources. Creating predictive models, translating non-technical aspects into quantifiable tasks. Analysis and representation of output data, highlight and explain trends and patterns, error elimination, using advanced statistical methods (regression, probability distribution, clusters etc.) to provide accurate results.
Data collection, Data Mining, Report generation, Problem identification and solution formulation Market analysis and establishing trends, Strategy development and implementation

Skills:
Extremely good analytical skills.
Good working knowledge of all MS-Office products, especially Advance Excel, Word, PowerPoint, MS-access.
Statistical tools and methods.

Interested candidates can send the updated resume on satish.mehra@exelaonline.com or call on 7722028636
00-7.00 Years",2.6,"Exela Technologies
2.6",Pune,"Irving, TX",10000+ employees,2017,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"SourceHOV, BancTec, Transcentra"
1338,Data Modeler,"• Minimum 5-8 years of working experience as Data modeler.
• Data modelling experience in designing.
• Minimum 2-3 years real time experience in Erwin tool is mandatory.
• Experience in normalized modeling techniques.
• Experience in designing the Start schema.
• Experience working in ORACLE.
• Experience with database design, capacity planning, performance tuning and query optimization.
• Experience in working with Bank or Banking and Finance or Financial domain.
• Excellent communication skills with leadership quality.

Job Segment:
Database, Oracle, ERP, Technology",3.5,"LTI
3.5",Mumbai,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1339,Machine Learning Engineer,"Looking for Data Scientists with Python/R Programming skills.
Specific experience in AI areas like Statistical Machine learning / Deep learning / Natural Language Processing (NLP)/ Operations Research (Optimization) will be an advantage.Individual in this role is expected to work with multiple stakeholders and teams

Qualifications and Requirements:-
Previous working experience as a Machine Learning/ Data Scientist for 2 years
MA in Computer Science or similar relevant field
Hands on experience with MALLET
In depth knowledge of Apache Tomcat/Open Source
Excellent project and time management skills
Attention to detail
Outstanding problem solving and analytical skills",-1,Tekolutions.ai,India,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1340,Data Science Internship,"About the company:
SkillBit is a leading staffing and recruitment company engaged in talent searching assignments for skilled and talented candidates for the industry.

About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Working on data science algorithms and AI concepts 2. Using Python or R for web scraping 3. Building AI models using Python, machine learning, and deep learning algorithms 4. Processing of unstructured/structured data

Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 6th Jun'20 and 11th Jul'20
are available for duration of 1 month
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply

Number of internships/jobs available: 3

Categories: Data Science",-1,SkillBit,Pune,-1,-1,-1,-1,-1,-1,-1,-1
1341,Data Engineer,"As a data engineer at TEAL, you'll be taking the plunge into a rich data lake that includes everything from satellite data to legal court orders. You'll be hustling and getting your hands dirty with every part of the data pipeline always having an implicit appreciation for how all of this data will ultimately power a revolutionary real estate risk platform.

Your day-to-day will include either all or some of the following:

Constantly scoping out new data sources to complement existing ones
Creating and maintaining distributed web scrapers using Python, RabbitMQ and other technologies
Architecting and managing data pipelines where data flows into multiple end-points including, but not limited to, Postgres, MongoDB and Apache Solr
Documenting workflows and constantly iterating to create better data infrastructure.

We'd love it if you:
Are proficient in Python or any other object-oriented language
Have worked with large (millions to hundreds of millions of rows in a SQL database) interdisciplinary datasets
Have scraped difficult websites and have some experience working with various data APIs
Are patient and methodical with unstructured and messy data
Are always hungry to learn newer and better technologies to make the data ecosystem faster, smoother and less silo-ed

Extra brownie points if you:
Have some experience working with large-scale search indexing
Have performed geospatial analyses in some capacity
Have created and managed data lakes in the cloud
Culture

To explore our culture and the values we embody click here

Testimonials
Testimonial

My experience at TEAL surpassed all my expectations from the get-go. I was asked to help solve one of the most daunting problems in the Indian real estate market. Every day while working on a subset of the problem, the ideas that I brought to the table were shaped into cohesive solutions by a collaborative team effort. At TEAL I was exposed to the most cutting edge technologies such as Cloud Computing, Big Data, ML and Data Science. The growth opportunities at TEAL are tremendous, If you are innovative and can demonstrate the will to realize your ideas, TEAL is an amazing organization to work for.
Gyan Vardhan, Data Science Intern
I had interned as a Data Scientist at Terra Economics and Analytics Lab during its early days, it was a rich learning experience working with a multi-disciplinary team who are extremely passionate about building a decision support platform for the insanely complicated realty market in India. It was exciting and challenging to work on mining huge volumes of property records; extracting patterns from the data, building data pipelines and brainstorming on building the core system. TEAL offers a very healthy work environment coupled with insanely talented people working together in an exciting setting.
Naga Anjaneyulu, Data Science Intern
I worked as a full-time Data science intern at TEAL. During this period, I got an opportunity to leverage my skillsets while also learning new technologies, working on tasks assigned to me. The company operates on the latest tech-stacks and gives opportunities to learn as much as you want. The work environment is challenging, the team at TEAL is super supportive and new ideas are always welcome. It has all the good perks of a startup; creativity and innovation, casual work atmosphere and a collaborative approach to solving problems. Personally, I loved working there, my experience was fantastic!
Archana Parmar, Data Science Intern
As a second-year college student, I was looking for an internship that would allow me to delve deeper into research and work with big data, TEAL gave me the perfect opportunity to do so, enabling me to develop proficiency in research and analysis. As a research analyst intern, I collated and cleaned data and helped in the preparation of reports and presentations, and I had members helping me at every stage of this process. This collaborative environment allowed me to cultivate my skills and also learn from my peers. The holy trinity of Rohan, Kshitij, and Shreyas served as not only excellent mentors and bosses but also as friends, helping me at every stage and giving us all food and ice cream to keep us going!
Arush Mehra, Research Intern
Internships are a crucial part of one’s early career. The internship experience at TEAL was a thrilling rollercoaster ride to say the least! It was more than implementing a standard model or building an already though out concept into reality. It was about finding the solution to a unique and open-ended problem.It was exciting to work on addressing a problem with far -reaching real world applications.Moreover, the work environment had the perfect balance of casual yet professional which kept you focused and stress free at the same time. Out of every 100 startups in India only 2 of them succeed, but there are very few like TEAL India which are bound to make it big at such an early stage.
Divyanshu Agarwal, NLP Intern",4.7,"Terra Economics & Analytics Lab (TEAL)
4.7",New Delhi,"Bengaluru, India",1 to 50 employees,2018,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
1342,Senior Consultant - ModellingOps Data Engineer,"Job Title: Senior Consultant - ModellingOps Data Engineer
Location: TRIL GTC
GCL: D1

JOB DESCRIPTION:

AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. The Science & Enabling Units IT is AZs global IT capability function supporting key business areas operating out of sites across the US, UK, Sweden, India & Mexico.

We are looking for AI Ops consultant who will leverage tools & technology best practices to improve delivery performance & data engineering capabilities in the D&A space.

ROLES & RESPONSIBILITIES:

7-10 years of experience in IT Operations involving Data Science, Artificial Intelligence-Machine Learning and Predictive Analytics. Experience in architecting and implementation of end-to-end AIOPs solutions through ELK stack, Splunk. Experience in applying statistical methods, analysis, pattern recognition and modeling on IT Operational data using ELK machine learning. Experience in extracting meaning full data from incoming data streams from different sources through RegEx, Grok etc. Hands-on experience in applying machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc in the IT Operation domain. Experience with machine learning and statistical programming languages - Python, R etc. Experience in assessing the existing IT environment and providing recommendations to reduce the critical applications impacting incidents. Experience in exploring and identifying areas where manual tasks can be automated in IT environment. Experience with various Enterprise IT monitoring solutions including Infrastructure monitoring, Application Performance Monitoring, Network Monitoring, Cloud monitoring etc. Experience in IT Service Management including Service Desk, Incident Management, Change Management, CMDB etc. Excellent knowledge on various IT infrastructure components that includes Server Infrastructure, middle ware, database and application architectures and Cloud Components. Experience/knowledge on Infra monitoring tools - NOI, Zabbix, AppDynamics, Datadog, SCOM, SolarWinds etc. and Service Management tools -IBM Control Desk, BMC Remedy, ServiceNow etc. Experience/Knowledge on BI tools Knowledge on distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc. Knowledge on other programming languages/scripting: Python, Java, JavaScript, etc. ( Added Advantage ) Good analytical skills, strong communication skills are must. Client facing experience is an added advantage. Excellent experience in understanding the problem statement, architect and designing the solution

MANDATORY SKILLS:
Significant experience with AWS cloud environments, working knowledge of Google and Azure platforms. Knowledge of Kubernetes, S3, EC2, Sagemaker, Athena, RDS and Glue is essential.
Experience provisioning computational resources in a variety of Cloud environments using Infrastructure as Code.
Experience with best practice of data transport and storage within cloud system.
Experience building large scale data processing pipelines. e. g. Spark and SQL.
Experience with containers and microservice architectures e.g. Kubernetes, Docker and serverless approaches.
Excellent working knowledge in DevOps, using continuous integration and continuous development.
Use of Data Science modelling tools e.g. R, Python, SAS and Data Science notebooks (e.g. Jupyter).
Good written and verbal skills, fluent English
DESIERED SKILLS:
Agile practices, especially being a SCRUM Master
EDUCATIONAL BACKGROUND: B.E/B.Tech/MCA

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",3.9,"AstraZeneca
3.9",Chennai,"Cambridge, United Kingdom",10000+ employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Roche, GlaxoSmithKline, Novartis"
1343,DATA ENGINEER,"JOB DESCRIPTION
As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements, and also research new uses for data acquisition. You should also know the ins and outs of the industry such as data mining practices, algorithms, and how data can be used.

DESIRED CANDIDATE PROFILE
An ideal candidate must possess prior experience leading a project.

Candidates must have:
> Experience in Hive, Spark, Scala, AWS DynamoDB, HBase, AWS Glue, Talend, Kafka, Snowflake ETL
> Strong experience in a BI/Data Warehouse environment with involvement in design, development, implementation, troubleshooting and support of ETL process using ETL tool.
> Experience in developing Data Marts, Data warehousing and Operational Data Store (ODS) on any of the databases or Hadoop environments.
> Experience in database like MS SQL, MySQL, Oracle, PostgreSQL
> Good to have programming experience in writing Complex Stored Procedures, Queries, Views, User Defined Functions, Cursors and Common Table Expressions using SQL or T-SQL.
> Experience in Performance Tuning and Query Optimization by Indexing, Partitioning and De-normalization.
> Experience in Developing a framework for ingesting data into Data lake
> Good database knowledge, analytical thinking
> Design, construct, install, test and maintain data management systems.
> Build high-performance algorithms, predictive models, and prototypes.
> Develop set processes for data mining, data modeling, and data production.
> Experience with cloud services: AWS (EC2, EMR, S3, Athena) and scripting languages like Python, /PySpark/R/SAS
> Install/update disaster recovery procedures.
> Experience in Agile Application Development & Scrum methodologies is preferred
> Ability to supervise and mentor junior developers on the team.
> Must be self-motivated and work well pulling people together in addition to being able to pull people together technically
> Demonstrated proficiency of troubleshooting techniques and detail-oriented problem diagnosis
> Ability to handle responsibility, is self-directed, with strong organizational and documentation skills
> Ability to work independently and efficiently under aggressive deadlines to meet project commitments
> Excellent verbal and written communication skills

EDUCATION
UG - B.Tech/B.E. - Computers, Electronics/Telecommunication, Diploma - Computers, Electronics/Telecommunication, B.Sc - Computers, BCA - Computers) AND (PG - M.Tech - Computers, Electronics/Telecommunication, MCA - Computers, M.Sc - Electronics, Computers) AND ( Doctorate - Any Doctorate - Any Specialization, Doctorate Not Required).

OTHER DETAILS
Number of vacancies: 4
Experience: 3 years
Location: Cochin

If you have a passion towards technology and coding, then we have the right job for you. Kindly forward your resumes to
Email: jobs@mjsofttech.com
Phone: 0484-2421245 / 928 720 7160",4.0,"MJ Softtech
4.0",Kochi,"Cochin, India",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
1344,Data Engineer,"Education/ Experience and Skill Requirement
4+ years of relevant experience in
Experience working with both relational and NoSQL databases.
Strong coding skills; Python (preferred) /R/Java/Scala
Experience in developing Data warehousing technologies Experience with AWS or equivalent cloud services preferred
Experience in BigData technologies (Hadoop, HDFS, MapReduce, Spark, Hive, HBase etc) will be valuable
Knowledge of Machine Learning a big plus (Random Forest, Decision Trees, SVM, NLP, Gradient Boosting, Supervised/Unsupervised Learning, Clustering, classification and regression modeling).
Responsibilities
Proficiency with several years’ experience in more than one of Python, R, Java, Scala, or robust Linux shell scripting
Implementation experience with data warehouse architecture & design, ETL design/development, and Analytics
Knowledge of general cloud architecture and cloud strategies especially around AWS services and concepts such as S3 object stores, RDS databases, EC2, Glacier, Lambda, IAM, enterprise security, data security, DevOps, replication and disaster recovery
Well versed with data mining & exploration, NLP and visualization
Understanding of data modeling, data integration, and data representation (metadata, OWL, ontologies)
Developing data marts and data management using SQL
Creating powerful visual outcomes
Independently manage daily client communication, especially over calls
Manage client deadlines, ensure quality of the deliverables, attention to detail
Experience/understanding of corporate finance data from company filings is desirable",3.6,"Copal Partners
3.6",Bengaluru,"New York, NY",10000+ employees,1900,Company - Public,Financial Analytics & Research,Finance,₹100 to ₹500 billion (INR),-1
1345,Data Engineer,"Job Description / Responsibilities
Build workflows to ensure data extraction quality and storage into our backend data store
Architect, build and train ML/AI models that can predict outcomes and report on anomalies.
Design data pipelines to perform ETL on content/data from multiple types of source systems.
Create data analytics views using RDBMS/Key-Value stores, on private and public/cloud
Create software that is well tested, maintainable, extensible and scales out with large data

Minimum Qualifications:
2+ years of software development with Python
2+ years of SQL (MySQL/Postgres) and Key-Value databases
1+ years of experience with scikit
2+ years of experience in data extraction, data transformation using custom Python/Java
Experience working with MapReduce/Hadoop/kafka/Elastic stack
Experience with Node backend and React/Redux
Experience working with git/mercurial, Amazon/Google cloud, Linux/LAMP stack
Experience in testing or test driven development
Experience with Data science and Machine Learning algorithm development

Location:
Hyderabad/Bangalore

Package:
Highly competitive to match experience and capability",3.7,"TVS
3.7",Bengaluru,"Chennai, India",5001 to 10000 employees,-1,Company - Private,Accounting,Accounting & Legal,₹100 to ₹500 billion (INR),-1
1346,Data Engineer,"Permanent position with US based client of iFlex.
Work Location: Bangalore
Experience Level: 2+ Years

Role:
As part of our global team you will work on the data platform reporting to the Data Engineering Lead. Your role includes specification, development, test and rollout of features on our data platform. You are expected to contribute to the vision, understand our product roadmap, integrate business value andclient experience and contribute to build an engineering culture within the team. This initiative is of critical important to the success of the organization and our roadmap, for instance, services like liquidity analytics, billing, client onboarding, reporting and others will rely on the data platform. Accurate, granular, complete and timely data will be our key differentiating factor and competitive advantage in the market place. We expect the successful candidate to deliver high quality software and to be passionate about data engineering..

Responsibility / Qualification:
Managing multiple tasks and use sound judgment when prioritizing.
Collaborating with global cross functional team in building customer-centric products.
Analyzing existing software implementations to identify areas of improvement and provide deadline estimates for implementing new features.
Updating and maintain documentation for team processes, best practices and software runbooks.
Establishing trusted partnerships with peers, product heads, and executive level stakeholders.
We are looking for someone who is passionate about technology and engineering.
Exceptional analytical skills and ability to apply knowledge and experience in decision-making to arrive at creative and commercial solutions.
Ability to leverage technology to deliver business value.
You are independent and comfortable in a fast paced, ambiguous and often multi-directional work environment.

Preferred Qualifications:
B.S. or higher in Computer Science.
Minimum 2 years of relevant professional experience using a modern programming language (preferably Java/Scala).
Experience leveraging test driven development technics.
Comfort with Agile operating models.
Team oriented.
Strong interpersonal and communication skills.
Energetic, self-directed, and self-motivated.
Experience with microservice architecture.
Experience with Kafka, MongoDB, Hadoop, Cassandra.
Experience with AWS.
Experience in Financial Services or Fintech.",-1,IFLEX,Bengaluru,"Moscow, Russia",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1347,CIEL/SEL/1941: Sr data scientist,"Mandatory skills required -
Databases (SQL, Oracle, Any RDBMS) - Should have working knowledge of atleast one database
PL/SQL Programming Languages
R, Python (Any One)
Inferential Statistics - Hypothesis, p-value, R2, RMSE, MAPE etc
Exploratory Data Analysis
Machine Learning Algorithms - Should have in-depth knowledge and implementation of atleast one algorithm

Responsibilities
: Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the why & how of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions

Education
Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics
Experience
Minimum years of related experience required: 3 years
Preferred years of experience: 5 years
Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desirable.

Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
1348,Data Engineer,Data Engineer,3.6,"Bookmyshow
3.6",Mumbai,"Mumbai, India",1001 to 5000 employees,2007,Company - Private,Ticket Sales,"Arts, Entertainment & Recreation",Unknown / Non-Applicable,-1
1349,Data Analyst,"Required Skills & Experience

We are looking for a Data Analyst Executive
Eligible Qualifications : B. Tech, BCA, M.Tech, MCA
Experience : 3-5 years, fresher’s can also be considered
Location of Job : Gurgaon/Connaught Place, New Delhi
Technicals Skills

Following technical skills are pre-requisite:
Well versed with Software development methodologies, such as SDLC (Software Development Life Cycle), DDLC (Document Development Life Cycle).
Database schema design and implementation
Should have worked in either of technologies Sql Query/ Tableau/ Excel (Macros)/ Access (Query) writing for data analytics.
For planning and coordinating activities, organizations remain in invariant communication with one another and the data transfer has to be performed efficiently and smoothly as possible.
He/ She should manage the execution of the technologies, help the businesses in utilizing the systems, and should be well versed with the basics of computer systems such as Networking, Installation of necessary software and hardware.
Ability to determine the interrelationships between solutions and requirements.
Ability to think analytically and should be a problem solver and logic building should be very strong.
Good interpersonal skills to form effective working relationships with people at all levels.
Excellent communication and presentation skills and strong written & oral English skills.
To know more about us visit us www.sspl.net.in or write to us at admin@sspl.net.in",-1,Substratal Solutions,Connaught Place,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1350,Artificial Intelligence Scientists,"Experience 2- 4 Years
Salary 4 LPA - 6 LPA
Job Location Chennai

Industry:
IT-Software / Software Services

Keywords:
Artificial Intelligence

About Job:
Must have Excellent knowledge in AI / Machine learning (Mandatory).
Machine learning frameworks like keras, tensor flow etc.
And also other big data tools like Hadoop etc, Must know R and python.
Good understanding in SDLC & Business cycle.",4.0,"Careerera
4.0",Chennai,"Wayland, MA",501 to 1000 employees,-1,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
1351,Senior Data Engineer,"About Us

upGrad is an online education platform building the careers of tomorrow by offering the most industry-relevant programs in an immersive learning experience. Our mission is to create a new digital-first learning experience to deliver tangible career impact to individuals at scale. upGrad currently offers programs in Data Science, Machine Learning, Product Management, Digital Marketing, and Entrepreneurship, etc. upGrad is looking for people passionate about management and education to help design learning programs for working professionals to stay sharp and stay relevant and help build the careers of tomorrow.
upGrad was awarded the Best Tech for Education by IAMAI for 2018-19
upGrad was also ranked as one of the LinkedIn Top Startups 2018: The 25 most sought-after startups in India
upGrad was earlier selected as one of the top ten most innovative companies in India by FastCompany.
We were also covered by the Financial Times along with other disruptors in Ed-Tech
upGrad is the official education partner for Government of India - Startup India program
Our program with IIIT B has been ranked #1 program in the country in the domain of Artificial Intelligence and Machine Learning
About the Role

We are looking for a Data Engineer to help us scale the existing data infrastructure and in parallel work on building the next generation data platform for analytics at scale, machine learning infrastructure and data validation systems.
In this role, you will be responsible for communicating effectively with data consumers to fine-tune data platform systems (existing or new), taking ownership and delivering high performing systems and data pipelines, and helping the team scale them up, to endure ever growing traffic.
This is a growing team, which makes for many opportunities to be involved directly with product management, development, sales, and support teams. Everybody on the team is passionate about their work and we’re looking for similarly motivated “get stuff done” kind of people to join us!

Roles & Responsibilities
Engineer data pipelines (batch and real-time ) that aids in creation of data-driven products for our platform
Design, develop and maintain a robust and scalable data-warehouse and data lake
Work closely alongside Product managers and data-scientists to bring the various datasets together and cater to our business intelligence and analytics use-cases
Design and develop solutions using data science techniques ranging from statistics, algorithms to machine learning
Perform hands-on devops work to keep the Data platform secure and reliable
Skills Required
Bachelor's degree in Computer Science, Information Systems, or related engineering discipline
6 + years’ experience with ETL, Data Mining, Data Modeling, and working with large-scale datasets
6+ years’ experience with an object-oriented programming language such as Python, Scala, Java, etc
Extremely proficient in writing performant SQL working with large data volumes
Experience with map-reduce, Spark, Kafka, Presto, and the ecosystem.
Experience in building automated analytical systems utilizing large data sets.
Experience with designing, scaling and optimizing cloud based data warehouses (like AWS Redshift) and data lakes
Familiarity with AWS technologies preferred
Qualification – B.Tech/M.Tech/MCA(IT/Computer Science)

Years of Exp – 6-9",3.5,"upGrad Education Private Limited
3.5",Mumbai,"Mumbai, India",501 to 1000 employees,2015,Company - Private,Education Training Services,Education,₹1 to ₹5 billion (INR),"Udacity, General Assembly, Springboard"
1352,BBRC-Genomics-Associate Scientist,"JOB DESCRIPTION

Designation: Associate Scientist

Job Location: Bangalore

Department: Translational Medicine- Translational Sciences

About Syngene

Incorporated in 1993, Syngene International Ltd. is an innovation-focused global discovery, development and manufacturing organization providing integrated scientific services to the pharmaceutical, biotechnology, nutrition, animal health, consumer goods and specialty chemical industries around the world. Syngene’ s clientele includes world leaders such as Bristol-Myers Squibb, Baxter, Amgen, GSK, Merck KGaA and Herbalife. Its innovative culture is driven by the passion of its 4240- strong team of scientists who work with clients from around the world to solve their scientific problems, improve R&D productivity, speed up time to market and lower the cost of innovation .

Job Purpose:
To play a key role in TM-TS, develop an early-stage research strategy, initiate and lead discovery programs while managing ongoing programs in TM-TS. The role will work part of TMTS, and work with internal and external collaborators .

Key Responsibilities:
Experience in isolating DNA and RNA from blood, tissues and FFPE samples and cell lines. Experience with optimization of extraction protocols and for parameters like yield, input sample quantities and sample types is important.
Expertise in PCR, qPCR, cDNA/gDNA library preparation. Exposure to microarray techniques.
Proficiency in preparation of libraries for Next Generation Sequencing of transcriptome and genome, with significant experience in optimization of parameters like input RNA/DNA quantities and sample type
Experience with single cell RNA-seq will be plus.
Experience with various NGS protocols (DNA Amplicon based, hybrid capture based low input, degraded DNA and RNA samples e.g. FFPE samples.
Strong understanding of experimental design and statistical principles behind experimental design and differential gene expression. Experience with analysis of single cell RNA-sequencing data will be a plus

Educational Qualification:
M.Sc or M. Tech in Biotechnology, Molecular biology or Biological Sciences,

Technical/functional Skills:
DNA/ RNA Isolation, Expertise in PCR, qPCR, Experience in NGS protocols

Experience:
2 to 5 Years

Behavioral Skills:
A proactive team player.
Ensure completion of experiments and generate accurate and reproducible data from experiments.
Ability to work independently, prioritize tasks and work on multiple projects simultaneously with; comfortable working in a dynamic environment with changing requirements.
Good oral and written communication and presentation skills to work in a multi-disciplinary team
Equal Opportunity Employer:
It is the policy of Syngene to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by applicable legislation or local law. In addition, Syngene will provide reasonable accommodations for qualified individuals with disabilities.",3.5,"Syngene
3.5",India,"BENGALURU, India",1001 to 5000 employees,1994,Unknown,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1353,Applied Scientist 1,"Position Requirements:
Master's degree in Computer Science, Computer or Electrical Engineer, Mathematics, or a related field plus at least one year of experience in the job offered or related occupations of Software Engineer, Software Developer, or a related occupation. Employer will accept a Bachelor’s degree and five years of experience in the job offered or a related occupation as equivalent to the Master’s degree and one year of experience. One year of experience in the job offered or related occupation must involve designing and developing large-scale, multi-tiered, distributed software applications, tools, systems and services using Java, Object Oriented Design and Distributed Programming].

Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, Oracle/Berkeley databases, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills

Amazon Selling Partner Services team drives the Selling On Amazon business and develops solutions that enable millions of sellers around the world to sell on Amazon's Marketplaces. More than half of shipments for Amazon customers are generated from this business. The team is focused on building a technology platform that will support the explosive business growth in existing markets, streamline the business for Amazon and the Selling partners and launch business in new markets and establish a fair marketplace.

Our team is seeking engineers with broad technical skills to help us optimize how we synthesize massive amounts of data and complex business rules into mission critical financial information. As a member of this team you will employ object oriented techniques in Java, and DynamoB, PostGres and ElasticSearch skills to help us support Amazon's next generation of selling partner services. Along the way you'll gain and leverage a unique understanding of how Amazon.com works; from the numerous software systems that comprise the website's back-end, to the details of our business model, and the relationships we're establishing with an ever-growing network of selling partners who depend on Amazon.com to run their businesses.

The ideal candidate will draw upon exemplary analytical, critical thinking, and problem solving skills, and a passion for maintaining highly reliable, distributed systems which operate 24/7/365. Successful members of this team collaborate effectively with internal end-users, aggressive cross-functional software development teams, and technical support/sustaining engineering teams to solve problems and deliver successfully against high operational standards of system availability and reliability. We look for engineers who are excellent communicators, self-motivated, flexible, hardworking, and who like to have fun!

Position Responsibilities:
Participate in the design, development, implementation, testing and documentation of large-scale, multi-tiered, distributed software applications, tools, systems and services using [Java, Object Oriented Design and Distributed Programming]. Translate functional requirements into robust, scalable, supportable solutions that work well within the overall system architecture. Participate in the full development cycle, end-to-end, from design, implementation, and testing to documentation, delivery and maintenance. Produce comprehensive, usable software documentation. Evaluate and make decisions around the use of new or existing software products and tools.

Preferred Qualifications
Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1354,Senior Clinical Data Analyst,"About Novotech:

Novotech is internationally recognised as the leading independent and full-service contract research organisation (CRO) in the Asia Pacific region. We provide a wide range of clinical development services across all research phases and therapeutic areas and have been instrumental in the success of hundreds of Phase I – IV clinical trials throughout the Asia Pacific. Powered by the highest quality people, Novotech strives to set the benchmark for both business and clinical trial performance. Our people are one of our key strengths. We value our people and recognise the work they do. We are lucky to have the best people and talent from across the Asia Pacific region work together to deliver to clinical trial success for our clients. Our people and those we look to recruit have an attitude of making things happen. They are problem solvers, driven with a focus on delivering quality, accountability and a high level of performance.

Brief Position Description:

As part of Novotech’s Biometrics unit, the Senior Data Analyst (SDA) is responsible for all data analysis and business intelligence activities related to study related clinical and operational data. The SDA acts as primary point of contact for all data analysis matters to the study team and is responsible for the timely delivery of quality outputs following all applicable regulatory, compliance, best practice and operational procedures.

Minimum Qualifications & Experience:

Graduate in information science, data science or life science-related field, or similar. More than five years’ experience in a senior role related to data science, data analysis, clinical data management or clinical data programming in a pharmaceutical company, CRO or EDC software provider.

Responsibilities
The Senior Data Analyst (SDA) is responsible for providing technical, procedural (SOPs) and planning leadership across multiple projects assigned to the data analyst team members ensuring that they deliver in accordance with SOPs, programming best practices, and the timelines agreed within the Project Team.
Collaborate with cross-functional stakeholders to implement data science solutions to solve business needs using available technological solutions.
Scope data analysis effort for projects and project manage all data analysis activities across multiple projects for different study stakeholders.
Gather study requirements from data management for data review and external data reconciliation and provide guidance on appropriate outputs (dashboards, visualisations, listings, reports).
Extract, assess, integrate, transform data sources to provide data visualisation outputs for analytics.
Design and develop prototypes and final versions of data outputs (dashboards, reports, visualisations, listings) using Business intelligence tools and Data Visualisation tools.
Design and develop standard dashboards and content for different audiences.
Analyse, manipulate and understand data from multiple sources to present and create dashboards and reports to make business decisions.
Assist teams on best-practice for data visualisation dashboard development.
Educate teams on how to use all the features of applicable data visualisation platform in conjunction with data visualisation dashboards.
SME for the data visualisation development and assisting team members.
Identify and communicate project risks and maintain documentation within project files as appropriate
Represent data analysis group at internal / external meetings as appropriate.
Assess and implement new data analysis, BI and data visualisation processes and technologies.
Take an active role in the development of best practices, process improvement, quality control and governance related to all data analysis matters.
Provide training and mentoring to Data Analysis of team members in SOPs, software applications, and best practices.
Provide Subject Matter Expertise on all data analysis and visualisation related activities.
Attributes and Skills

Expert knowledge of clinical study data structures and schemas of EDC databases. Expert knowledge in data processing activities such as extracting, integrating, transforming and presenting data. Statistical Programming skills in Python, R or similar. Knowledge of SQL and EDC systems. Working knowledge of Spotfire, Power BI, Tableau or other data review and visualisation tool. Ability to gather business requirements from multiple stakeholders and clients and provide guidance on the use of appropriate data visualisations.

Experience mentoring and training others. Awareness of regulatory and compliance issues and understanding of the application of SOPs and Quality Control to daily activities. Excellent analytical, communication and problem-solving skills.

Opportunities and Benefits:

To deliver clinical trial and research excellence for our clients, our people are 'best in class'.

At Novotech, we seek and nurture people with exceptional talent. We are committed to providing our people with regular internal and external training, a competitive bonus structure and a supportive work environment. We are also focused on providing our people with a wide variety of career growth and development opportunities.

For more information about where your next career step at Novotech might take you, visit http://novotech-cro.com/novotech-careers",4.5,"Novotech
4.5",Bengaluru,"Sydney, Australia",501 to 1000 employees,1996,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
1355,Data Engineer,"Data Engineer Responsibilities:
Liaising with coworkers and clients to elucidate the requirements for each task.
Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed.
Reformulating existing frameworks to optimize their functioning.
Testing such structures to ensure that they are fit for use.
Preparing raw data for manipulation by Data Scientists.
Detecting and correcting errors in your work.
Ensuring that your work remains backed up and readily accessible to relevant coworkers.
Remaining up-to-date with industry standards and technological advancements that will improve the quality of your outputs.
Data Engineer Requirements:
Bachelor's degree in Data Engineering, Big Data Analytics, Computer Engineering, or related field.
Master's degree in a relevant field is advantageous.
Proven experience as a Data Engineer, Software Developer, or similar.
Expert proficiency in Python, C++, Java, R, and SQL.
Familiarity with Hadoop or suitable equivalent.
Excellent analytical and problem-solving skills.
A knack for independent and group work.
Scrupulous approach to duties.
Capacity to successfully manage a pipeline of duties with minimal supervision.
Job Type: Full-time

Salary: ₹360,000.00 to ₹870,000.00 /year

Experience:
total work: 2 years (Preferred)
Data Engineer: 1 year (Preferred)
Education:
Diploma (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,Futurious Technologies,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1356,Quantitative Analyst,"The successful candidate will be a highly analytical individual with hands on programming skills. The candidate will work closely with the research team and clients towards the ongoing development and integration of new investment strategies, models and tools on Axle

Location

Mumbai
Responsibilities

Perform daily/weekly/monthly tasks of performance and risk reporting
Develop and automate investment processes and strategies via VBA and Matlab
Develop tools to integrate trading decision systems with risk management systems
Ad hoc tasks (such as operational tasks, internal documentation tasks and preparation of marketing materials)
Skills/Experience

Excellent programming skills in Matlab/Excel-VBA
Thorough with financial concepts and calculations like Drawdown, VaR, Eloss etc.
Understanding of financial market products like options, futures, FX forwards etc.
Working knowledge of Bloomberg is preferred
Should be self-driven and detail oriented with an analytical mindset
Should be a proactive and quick learner; a team player showing enthusiasm and drive to accomplish results in a fast paced environment
Min. 2 years of relevant work experience
Qualifications

B.Tech/M.Tech/MBA/CFA/FRM",5.0,"B&B Analytics
5.0",Mumbai,"Zug, Switzerland",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1357,Analyst - Data Scientist,"Job Summary

Experience:
3 - 5 Years

Location:
Mumbai

Designation:
Analyst - Data Scientist

Degree:
BE-Comp/IT, BE-Other, BTech-Comp/IT, BTech-Other, ME-Comp/IT, ME-Other, MTech-Comp/IT, MTech-Other, PhD-Comp/IT, PhD-Other

Educational Level:
Graduate/Bachelors

Industrial Type:
IT-Software/Software Services

Functional Area:
IT Software - Application Programming / Maintenance

Key Skills:
Data Scientist

Job Post Date:
Thursday, March 19, 2020

Company Description

We are capability centre based in Mumbai, initially started as a back-office operational support to the UK business unit.

However, over the recent years, we have significantly increased the breadth and depth of our capabilities and offerings to keep pace with the changing needs of the Group. These include Digital & Knowledge Services, Finance and Actuarial, Information Technology (IT), Customer Service, Risk and Audit.

Our core purpose is to be a strategic partner to company, enabling growth by delivering change and driving synergies through a highly capable and agile workforce.

With our diversified service offerings we provide our people with exciting opportunities to grow personally and professionally.

Company is a leading savings and investments business serving around 5.5 million retail customers and more than 800 institutional clients.

It-s innovative asset management and customer solutions are supported by extensive investment capabilities, an international distribution network and two strong brands.

Job Description

3 – 5 yrs experience as Data Scientist
Should have at-least 1 end-to-end ML project experience
Very high proficiency in R or Python
Excellent in forecasting methods like simple exponential smoothing, multiplicative seasonal indexes, simple and weighted moving averages and time series forecasting methods
Exposure to with advanced deep learning techniques such as LSTM. CNN, Dense neural networks as well as neural networks design and implementation through tools like tensorflow, keras, pytorch, deepai or equivalent.
Good SQL experience",3.8,"Sampoorna Computer People
3.8",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
1358,Data Lake Developer,"For Us, It's A Mission

At Mylan, we mean it when we say we work every day to provide access to high quality medicines to the world's 7 billion people. If you are unconventional, relentless and passionate. If you believe in doing what's right, not what's easy. If you are a doer and have a passion for serving others, we want to talk to you.

Make a Difference

At Mylan, each person has the ability to make a difference. From the providers who sell and market our products, to the producers who develop and manufacture them and finally to our business partners who support the providers and producers, we all have a mission critical role. Here's how this role will help:

ESSENTIAL DUTIES AND RESPONSIBILITIES
To perform this job successfully, an individual must satisfactorily perform each essential duty. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential duties.
1. Create and maintain optimal data pipeline architecture on Azure platform.
2. Develop batch processing solutions by using Data Factory and Azure Databricks.
3. Delivering a Data Warehouse in the Azure Cloud.
4. Design relational and non-relational data stores on Azure.
5. Identify, design, and implement internal process improvements : automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc..
6. Developing Big Data Solutions with Azure Machine Learning.
7. Strong interaction with business departments to provide consultative support for digitization efforts, as well as close collaboration with the Business Technology management, focused on future innovation topics.
8. Participate and lead in design sessions, demos and prototype sessions, testing and training workshops with business users and other IT colleagues.
9. Design & Build for any API Development or SQL DB development.
10. Providing service management, orchestration, monitoring and management requirements of Azure cloud platform.
11. Create data tools / products for analytics and data scientist team members that assist them in building and innovative solutions that drive tangible business value.
12. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
13. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
14. Design security for source data access. Chose the appropriate authentication mechanism, (ie Azure Active Directory (Azure AD), etc).
15. Design for real-time processing by using Stream Analytics and Azure Databricks.

Make Our Values Your Values

Mylan hires only the best. People who thrive in a culture of innovation and empowerment. People who are active learners and have a positive attitude. People who are leaders and know that by working together we can run faster, reach higher and achieve more. By doing so, we will continue to set new standards in health care. Here are the minimum qualifications and essential functions for this position:

QUALIFICATIONS

The qualifications listed below are representative of the minimum knowledge, skill, and/or ability required.

SKILLS AND ABILITIES

1. 10 years of experience in Microsoft technologies including SQL.

2. At least 5 years as a Sr Developer with at least 3 years hands on experience as Azure Data Engineer building large scale Azure data solutions.

3. At least 5 years of experience in Azure based data solutions.

4. At least 3 years of experience on working with large projects including the most recent project in the cloud (Azure) or on prem with a focus on Azure Data services.

5. At least 5 years of Hands-on administration, configuration management, monitoring, performance tuning of Hadoop/Distributed platforms.

6. At least 5 years of demonstrated experience at least in the most recent 2 years of designing and delivering solutions using Cortana Intelligence suite of analytics services part of Microsoft Azure including Azure Machine Learning Studio, HDInsight, Polybase, Azure Data Lake Analytics, Azure Data Warehouse, Streaming Analytics, Data Catalog, R/R Studio

7. Experience in designing and building logics required for optimal extraction, transformation, and loading of data from a wide variety of data sources

8. Experience within Data Security design, including but not limited to:

a. Choosing the appropriate authentication mechanism, such as Azure Active Directory (Azure AD)

b. Defining strategies for data encryption for data at rest and in transit

9. Experience partnering with Business Analysts and Data Scientists to enable effective and efficient data preparation and delivery

10. Experienced in vendor management and working with 3rd parties onshore & offshore.

11. Experience working in a global team.

12. Experience working in an Analytics / Big Data solutions on MS Azure Cloud

13. Experience with code management tools, automated testing

14. Experience creating and maintaining optimal data pipeline architecture on Azure platform

15. Experience developing batch and real-time processing solutions by using Data Factory and Azure Databricks

16. Familiar with AGILE and Azure DevOps methodology

17. Hands on PoC capabilities are needed to prove a particular architecture concept

18. Azure Native Services experience across Data Fabric and Service Fabric

19. Experience in Application modernization from legacy on-premise data architecture platform technology stack to modernized Azure Cloud base Architecture.

20. Experience with Git, NoSQL Data Solutions, Microsoft Azure, HD Insights, Azure ML, DataBricks ML Flow, R or Python.

21. Must have excellent communication skills.

EDUCATION/EXPERIENCE (Note: Please select one)

Minimum of a Bachelor's degree in Computer Science and Engineering is preferred with minimum 10 years of experience. However, a combination of experience and/or education will be taken into consideration

Why Mylan?

If you want to be part of a global health care company that is making a difference and changing lives, Mylan may be the place for you. With a workforce of more than 35,000 worldwide, we can make a difference. We encourage you to visit Mylan.com to learn more about our unconventional culture, our approach to doing business and how we plan to set new standards in health care.

Mylan offers competitive salary, excellent benefits and an environment conducive to professional growth and advancement. All qualified applicants will receive consideration for employment without regard to their disability or protected veteran status. Mylan is an Equal Opportunity Employer, Minorities/Female/Disabled/Veteran.",3.8,"Mylan Inc.
3.8",Bengaluru,"Hatfield, United Kingdom",10000+ employees,1961,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1359,Off Campus Recruitment - Quantitative Researcher,"Description:
Graviton is a privately funded quantitative trading firm striving for excellence in financial markets' research. We are seeking fresh talent from the top IIT's to join us as Quantitative Researchers for our team in Gurgaon.If you are a student graduating in 2020 from Computer Science , Electrical or Maths Stats Computing streams with a greater than 8 CGPA please apply here.

This role is open to students from campuses that we could not visit this year. Please check your individual placement policy restrictions before applying.

Graviton trades across a multitude of asset classes and trading venues using a gamut of concepts and techniques ranging from time series analysis, filtering, classification, stochastic models, pattern recognition to statistical inference analysing terabytes of data to come up with ideas to identify pricing anomalies in financial markets.

As a Quantitative researcher your responsibilities will include

Develop new or improve existing trading models using in-house platforms

Use advanced mathematical techniques to model and predict market movements

Analyse large financial datasets to identify trading opportunities

Provide real time analytical support to experienced traders

Requirements :
Possess a degree in a highly analytical field, such as Engineering, Mathematics, Computer Science from IITs schools

Quantitative bend of mind

A working knowledge of Linux/Unix

Programming experience, preferably in C++ or C

Strong interest in learning about financial markets.

Have a strong work ethic

Hard Working

Benefits:
Our open and casual work culture gives you the space to innovate and deliver. Our cubicle free offices , disdain for bureaucracy and insistence to hire the very best creates a melting pot for great ideas and technology innovations. Everyone on the team is approachable, there is nothing better than working with friends!

Our perks have you covered.

Competitive compensation

6 weeks of paid vacation

Monthly after work parties

Catered breakfast and lunch

Fully stocked kitchen

Gym membership

International team outing",5.0,"Graviton Research Capital LLP
5.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2014,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1360,Data Engineer,"Zauba Technologies is a startup based in Bangalore. Zauba's services are used by leading companies in India. Zauba is powered by a young and passionate team. We are looking for individuals who would like to be a part of our founding team.

As a Data Engineer and as a part of founding team, you will be expected to visualise and develop disruptive data products. Eventually you would be responsible for entire project lifecycle of products you would visualize. Your rewards will be directly proportional to the value you generate.

Job Responsibilities
Design and development of robust, scalable and highly efficient data engineering solutions for structured and unstructured data (Including gathering and processing raw data at scale, writing scripts, web scraping, calling APIs, writing SQL queries, etc.)
Develop processes for text mining and extraction of information from unstructured data
Design, architect and develop efficient data pipelines around the data collected
Take ownership of existing web product and applications
Design and implement data models that scale across the enterprise
Take ownership of existing data workflows and processes
Enhance scalability, performance, and stability of existing infrastructure
Work closely with other team members to integrate your innovations and algorithms into our production systems

Essentials
Java/Python - Intermediate to advanced level
SQL - Advanced
MySQL Intermediate to advanced level
Regex - Basic to intermediate level
Linux Basic to intermediate level

Good to have
Hadoop/Spark
R
MongoDB

Must have qualities
Skills to learn new skills quickly
Desire to create disruptive products and services
Passion - not just to work in startups but to take them to next level
Above average programming aptitude
Be passionate about producing high quality engineering deliverables
Be productive working independently or collaboratively
Have an eye for building efficient processes
Be self motivated
Proactively take ownership

Interested?

Send your resume to hr@zaubacorp.com",3.8,"Zauba Corp
3.8",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 million (INR),-1
1361,Quantitative Research,"We are looking for highly trained professionals who are interested in applying advanced mathematical quantitative methods to the modeling of global financial markets. You would be joining a group made up of highly proficient individuals from various scientific disciplines. We have a spectrum of opportunities for individuals with the right scientific skills. Experience in finance is not required.

The ideal research candidate will have:
A Ph.D. in Computer Science, Mathematics, Physics, Statistics, or a related technical discipline.

A demonstrated capacity to do first-class research.

Computer programming skills.

An intense interest in applying quantitative analysis to solve difficult problems.

Send us a copy of your resume to
careers@dolatcapital.com

For internship opportunities, please send us a copy of your resume to
careers@dolatcapital.com",4.0,"Dolat Capital
4.0",Mumbai,"Mumbai, India",51 to 200 employees,1970,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1362,Data Engineer,"Bachelor’s degree in Computer Science or related field
5+ years relevant experience
5+ years experience with SQL, SQL Tuning, Oracle, OLAP, Big Data Technologies
5+ years experience developing end-to-end Business Intelligence solutions: data modeling, ETL and reporting
Experience with Java and experience with scripting languages like Perl, Python, Unix shell scripts,VBA and MS Excel
Proficiency with Linux and systems administration
Proven ability at looking at solutions in unconventional ways. Sees opportunities to innovate and can lead the way.
Top notch communication (verbal and written) and interpersonal skills to convey key insights from complex analysis in summarized business terms and an ability to effectively communicate with technical teams.
Ability to work with shifting deadlines in a fast paced environment.
Operations Finance Technology team, responsible for building technical solutions for multi-billion WW Operational Cost analytic including Inbound cost (Receiving / PO), variable Cost, fixed cost, outbound (Customer Shipments / Transportation), and Customer Service, is looking for a Data Engineer.

As a data engineer, you will get the exciting opportunity to work on very large data sets in one of the world's largest and most complex data warehouse environments. You will work closely with the business teams in analysis on various cost savings initiatives, many non-standard and unique business problems and use creative-problem solving to deliver actionable output.
You will be responsible for designing and implementing an analytical environment using third-party and in-house reporting tools, modeling metadata, building reports and dashboards. You will have an opportunity to work with leading edge technologies like Redshift, Hadoop/Hive/Pig. You will be writing scalable queries and tuning performance on queries running over billion of rows of data.

You should be analytical, have an extremely high level of customer focus and a passion for process improvement. You should be motivated self-starter that can work independently in a fast paced, ambiguous environment. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions.
Bachelors in Computer Science or related field
Practical Knowledge of Linux or Unix shell scripting
Experience in working with business customers to drive requirements analysis
Exposure to large databases, BI applications, data quality and performance tuning
Excellent written and spoken communication skills
Experience with Hadoop-based technologies such as HBase, Pig, Hive and Spark
Strong proven ability in building high-performance, highly available and scalable data solutions using Oracle and/or Hadoop-based technologies
Knowledge of data warehousing concepts.
Strong sense of ownership, urgency, and drive
Strong troubleshooting and problem solving skills
Experience with Amazon Web Services",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1363,DATA ANALYST,"posted by Mahima Gaur

2 - 5 years Delhi

Job Description
Experience in data processing
Experience in data cleaning and data tabulation activities
Strong analytical, communication and team management skills
Strong understanding of data management using SPSS and research techniques
Competency in a Tabulation software (decipher / wincross / quantum etc), Excel, Powerpoint
Ability to summarize findings, draw conclusions, and put together a presentation using Powerpoint
Role Category : Data Analyst

Employment Type : Permanent Job, Full Time",4.9,"Knowledge Excel Services.
4.9",New Delhi,"New Delhi, India",1 to 50 employees,2007,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
1364,Data Engineer,"Key skills : Python , Spark , SQL , Pyspark • AWS platform used for the work • Strong experience in SQL is mandatory • Good familiarity of AWS landscape • Good experience in collecting business requirements & design them as per requirement from customer • Should able to work independently & interact business users & technical stakeholders • Strong communication skills both oral & written. • Should work as an individual resources",3.5,"Larsen & Toubro Infotech Limited
3.5",India,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1365,Big Data Engineer,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
1366,Client Data Analyst,"At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.
What is the Client Data Analyst – Client Analytics group responsible for?
This team manages business data to ensure accurate, timely, consistent and compliant data. Their contributions deliver quality data that is easily accessible and can be trusted. Key downstream capabilities such as reporting and analytics depend on this as well as operational data access on various systems. The Data Management Team is a support function that acts as an advocate and a point of contact for Sales and Marketing data.

What are the ongoing responsibilities of an Client Data Analyst ?
Understand the data flow, key consumption and production of data as well as context within the enterprise:
Build positive relationships with teams, especially the key data consumers and analytics. Take the time to increase knowledge of how they run their business and incorporate sales data into daily work
Connect regularly with each sales office to understand current issues and challenges. Probe the business and validate against other sales offices to understand the scope and priority of the issue
Make recommendations on how data unifications and flow can be used to improve business tasks. Liaise business partners to deliver solutions (reports, processes, technology) that add value.

Provide data management subject matter expertise. Appreciate the connection and data flow between applications and other corporate systems. Be able to clearly articulate the data needs and move initiatives forward by collaborating with business partners:
Actively participate in meetings with business partners to ensure that priorities are clearly understood, information is regularly shared and that key participants are “kept in the loop”
Provide context and background on issues. Collaborate on ideas for progressing initiatives. Ensure appropriate resources are involved to take initiatives forward
Provide insights and expertise to scope statements and requirements documentation
Actively consult or participate in the user acceptance testing process (test cases, documentation, testing execution, etc.)
Ensure business needs remain aligned with overall corporate initiatives and deliver the benefits as originally intended

Monitor the integrity of data and usefulness of reports. Ensure the information available within systems is accurate and up-to-date. Proactively seek data cleansing opportunities and evolve data to better support. Document and maintain ongoing processes for reporting and data clean-up:
Partner with all key data consumers to gain a solid understanding of usage and challenges around data. Establish processes for prioritization of enhancements, especially with the analytics groups
Provide 1st level support for data issues and data maintenance for owned data
Verify and execute data loads into our internal sales systems and ensure any upstream systems accurately receive their data

Increase awareness and promote data management capabilities. Share best practices and provide coaching to local offices on how to access and incorporate output into sales tasks. Encourage IAS leaders to leverage data to make more informed, strategic decisions:
Clearly articulate the goals and core services of the data management team. Proactively promote this information within IAS and ensure business partners understand the data management role within the organization
Share best practices and provides guidance on data capabilities. Reinforces ownership and accountability for data accuracy
Seek opportunities to share the benefits of leveraging sales data to make more informed business decisions

What ideal qualifications, skills & experience would help someone to be Successful?

Knowledge, Education And Experience:
Four year bachelor’s degree required (majors of preference include: business, computer science, mathematics) Advanced degree a plus
Understanding of the Franklin Templeton business model, how FT makes money, the sales process, how technology fits in with the business, etc. Knowledge of the GAS (Global Advisory Services) structure
Experience working through multiple business fiscal cycles; exposure and/or direct experience with project management and/or sales-related-capacity required
Prior work experience related to analytics, sales, marketing and/or international a must. Level will not be granted based on years of experience but will be determined by the employee’s ability to meet each job activity as outlined the ‘typical/expected focus by level
Skills And Abilities:
Ability to communicate effectively with all levels of management; ability to tailor communication style based on audience; ability to get others to want to collaborate with you; strong facilitation skills
Excellent writing skills (for presentations, documentation, etc.)
Working knowledge of the CRM, MDM, Excel, SQL, Power BI, Tableau, Business Objects, and Microsoft Products (PPT, Power Apps, Doc, Visio)
Ability to absorb and interpret large quantities of data; apply trend analysis and knowledge of the business to develop a meaningful and digestible summary with the appropriate level of detail
Ability to take a larger problem and break down the individual components; identify how to go about solving the problem and who to involve in the process
Ability to present recommended solutions to a variety of issues and problems (solutions that are consistent with organization objectives)
Must be extremely detail-oriented (managing lists, tasks/to-dos, etc.) good with follow through on own items; good with following up with others on outstanding item

What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.

Highlights of our benefits include:

Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.",3.8,"Franklin Templeton Investments
3.8",Hyderabad,"San Mateo, CA",5001 to 10000 employees,1947,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Fidelity Investments, Vanguard"
1367,Data Analyst,"Roles and Responsibilities:
Extracting, transforming and inputting data sets from various resources. Creating predictive models, translating non-technical aspects into quantifiable tasks. Analysis and representation of output data, highlight and explain trends and patterns, error elimination, using advanced statistical methods (regression, probability distribution, clusters etc.) to provide accurate results.
Data collection, Data Mining, Report generation, Problem identification and solution formulation Market analysis and establishing trends, Strategy development and implementation

Skills:
Extremely good analytical skills.
Good working knowledge of all MS-Office products, especially Advance Excel, Word, PowerPoint, MS-access.
Statistical tools and methods.

Interested candidates can send the updated resume on satish.mehra@exelaonline.com or call on 7722028636
00-7.00 Years",2.6,"Exela Technologies
2.6",Pune,"Irving, TX",10000+ employees,2017,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"SourceHOV, BancTec, Transcentra"
1368,Data Modeler,"• Minimum 5-8 years of working experience as Data modeler.
• Data modelling experience in designing.
• Minimum 2-3 years real time experience in Erwin tool is mandatory.
• Experience in normalized modeling techniques.
• Experience in designing the Start schema.
• Experience working in ORACLE.
• Experience with database design, capacity planning, performance tuning and query optimization.
• Experience in working with Bank or Banking and Finance or Financial domain.
• Excellent communication skills with leadership quality.

Job Segment:
Database, Oracle, ERP, Technology",3.5,"LTI
3.5",Mumbai,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1369,Machine Learning Engineer,"Looking for Data Scientists with Python/R Programming skills.
Specific experience in AI areas like Statistical Machine learning / Deep learning / Natural Language Processing (NLP)/ Operations Research (Optimization) will be an advantage.Individual in this role is expected to work with multiple stakeholders and teams

Qualifications and Requirements:-
Previous working experience as a Machine Learning/ Data Scientist for 2 years
MA in Computer Science or similar relevant field
Hands on experience with MALLET
In depth knowledge of Apache Tomcat/Open Source
Excellent project and time management skills
Attention to detail
Outstanding problem solving and analytical skills",-1,Tekolutions.ai,India,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1370,Data Science Internship,"About the company:
SkillBit is a leading staffing and recruitment company engaged in talent searching assignments for skilled and talented candidates for the industry.

About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Working on data science algorithms and AI concepts 2. Using Python or R for web scraping 3. Building AI models using Python, machine learning, and deep learning algorithms 4. Processing of unstructured/structured data

Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 6th Jun'20 and 11th Jul'20
are available for duration of 1 month
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply

Number of internships/jobs available: 3

Categories: Data Science",-1,SkillBit,Pune,-1,-1,-1,-1,-1,-1,-1,-1
1371,Data Engineer,"As a data engineer at TEAL, you'll be taking the plunge into a rich data lake that includes everything from satellite data to legal court orders. You'll be hustling and getting your hands dirty with every part of the data pipeline always having an implicit appreciation for how all of this data will ultimately power a revolutionary real estate risk platform.

Your day-to-day will include either all or some of the following:

Constantly scoping out new data sources to complement existing ones
Creating and maintaining distributed web scrapers using Python, RabbitMQ and other technologies
Architecting and managing data pipelines where data flows into multiple end-points including, but not limited to, Postgres, MongoDB and Apache Solr
Documenting workflows and constantly iterating to create better data infrastructure.

We'd love it if you:
Are proficient in Python or any other object-oriented language
Have worked with large (millions to hundreds of millions of rows in a SQL database) interdisciplinary datasets
Have scraped difficult websites and have some experience working with various data APIs
Are patient and methodical with unstructured and messy data
Are always hungry to learn newer and better technologies to make the data ecosystem faster, smoother and less silo-ed

Extra brownie points if you:
Have some experience working with large-scale search indexing
Have performed geospatial analyses in some capacity
Have created and managed data lakes in the cloud
Culture

To explore our culture and the values we embody click here

Testimonials
Testimonial

My experience at TEAL surpassed all my expectations from the get-go. I was asked to help solve one of the most daunting problems in the Indian real estate market. Every day while working on a subset of the problem, the ideas that I brought to the table were shaped into cohesive solutions by a collaborative team effort. At TEAL I was exposed to the most cutting edge technologies such as Cloud Computing, Big Data, ML and Data Science. The growth opportunities at TEAL are tremendous, If you are innovative and can demonstrate the will to realize your ideas, TEAL is an amazing organization to work for.
Gyan Vardhan, Data Science Intern
I had interned as a Data Scientist at Terra Economics and Analytics Lab during its early days, it was a rich learning experience working with a multi-disciplinary team who are extremely passionate about building a decision support platform for the insanely complicated realty market in India. It was exciting and challenging to work on mining huge volumes of property records; extracting patterns from the data, building data pipelines and brainstorming on building the core system. TEAL offers a very healthy work environment coupled with insanely talented people working together in an exciting setting.
Naga Anjaneyulu, Data Science Intern
I worked as a full-time Data science intern at TEAL. During this period, I got an opportunity to leverage my skillsets while also learning new technologies, working on tasks assigned to me. The company operates on the latest tech-stacks and gives opportunities to learn as much as you want. The work environment is challenging, the team at TEAL is super supportive and new ideas are always welcome. It has all the good perks of a startup; creativity and innovation, casual work atmosphere and a collaborative approach to solving problems. Personally, I loved working there, my experience was fantastic!
Archana Parmar, Data Science Intern
As a second-year college student, I was looking for an internship that would allow me to delve deeper into research and work with big data, TEAL gave me the perfect opportunity to do so, enabling me to develop proficiency in research and analysis. As a research analyst intern, I collated and cleaned data and helped in the preparation of reports and presentations, and I had members helping me at every stage of this process. This collaborative environment allowed me to cultivate my skills and also learn from my peers. The holy trinity of Rohan, Kshitij, and Shreyas served as not only excellent mentors and bosses but also as friends, helping me at every stage and giving us all food and ice cream to keep us going!
Arush Mehra, Research Intern
Internships are a crucial part of one’s early career. The internship experience at TEAL was a thrilling rollercoaster ride to say the least! It was more than implementing a standard model or building an already though out concept into reality. It was about finding the solution to a unique and open-ended problem.It was exciting to work on addressing a problem with far -reaching real world applications.Moreover, the work environment had the perfect balance of casual yet professional which kept you focused and stress free at the same time. Out of every 100 startups in India only 2 of them succeed, but there are very few like TEAL India which are bound to make it big at such an early stage.
Divyanshu Agarwal, NLP Intern",4.7,"Terra Economics & Analytics Lab (TEAL)
4.7",New Delhi,"Bengaluru, India",1 to 50 employees,2018,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
1372,Senior Consultant - ModellingOps Data Engineer,"Job Title: Senior Consultant - ModellingOps Data Engineer
Location: TRIL GTC
GCL: D1

JOB DESCRIPTION:

AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. The Science & Enabling Units IT is AZs global IT capability function supporting key business areas operating out of sites across the US, UK, Sweden, India & Mexico.

We are looking for AI Ops consultant who will leverage tools & technology best practices to improve delivery performance & data engineering capabilities in the D&A space.

ROLES & RESPONSIBILITIES:

7-10 years of experience in IT Operations involving Data Science, Artificial Intelligence-Machine Learning and Predictive Analytics. Experience in architecting and implementation of end-to-end AIOPs solutions through ELK stack, Splunk. Experience in applying statistical methods, analysis, pattern recognition and modeling on IT Operational data using ELK machine learning. Experience in extracting meaning full data from incoming data streams from different sources through RegEx, Grok etc. Hands-on experience in applying machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc in the IT Operation domain. Experience with machine learning and statistical programming languages - Python, R etc. Experience in assessing the existing IT environment and providing recommendations to reduce the critical applications impacting incidents. Experience in exploring and identifying areas where manual tasks can be automated in IT environment. Experience with various Enterprise IT monitoring solutions including Infrastructure monitoring, Application Performance Monitoring, Network Monitoring, Cloud monitoring etc. Experience in IT Service Management including Service Desk, Incident Management, Change Management, CMDB etc. Excellent knowledge on various IT infrastructure components that includes Server Infrastructure, middle ware, database and application architectures and Cloud Components. Experience/knowledge on Infra monitoring tools - NOI, Zabbix, AppDynamics, Datadog, SCOM, SolarWinds etc. and Service Management tools -IBM Control Desk, BMC Remedy, ServiceNow etc. Experience/Knowledge on BI tools Knowledge on distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc. Knowledge on other programming languages/scripting: Python, Java, JavaScript, etc. ( Added Advantage ) Good analytical skills, strong communication skills are must. Client facing experience is an added advantage. Excellent experience in understanding the problem statement, architect and designing the solution

MANDATORY SKILLS:
Significant experience with AWS cloud environments, working knowledge of Google and Azure platforms. Knowledge of Kubernetes, S3, EC2, Sagemaker, Athena, RDS and Glue is essential.
Experience provisioning computational resources in a variety of Cloud environments using Infrastructure as Code.
Experience with best practice of data transport and storage within cloud system.
Experience building large scale data processing pipelines. e. g. Spark and SQL.
Experience with containers and microservice architectures e.g. Kubernetes, Docker and serverless approaches.
Excellent working knowledge in DevOps, using continuous integration and continuous development.
Use of Data Science modelling tools e.g. R, Python, SAS and Data Science notebooks (e.g. Jupyter).
Good written and verbal skills, fluent English
DESIERED SKILLS:
Agile practices, especially being a SCRUM Master
EDUCATIONAL BACKGROUND: B.E/B.Tech/MCA

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",3.9,"AstraZeneca
3.9",Chennai,"Cambridge, United Kingdom",10000+ employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Roche, GlaxoSmithKline, Novartis"
1373,DATA ENGINEER,"JOB DESCRIPTION
As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements, and also research new uses for data acquisition. You should also know the ins and outs of the industry such as data mining practices, algorithms, and how data can be used.

DESIRED CANDIDATE PROFILE
An ideal candidate must possess prior experience leading a project.

Candidates must have:
> Experience in Hive, Spark, Scala, AWS DynamoDB, HBase, AWS Glue, Talend, Kafka, Snowflake ETL
> Strong experience in a BI/Data Warehouse environment with involvement in design, development, implementation, troubleshooting and support of ETL process using ETL tool.
> Experience in developing Data Marts, Data warehousing and Operational Data Store (ODS) on any of the databases or Hadoop environments.
> Experience in database like MS SQL, MySQL, Oracle, PostgreSQL
> Good to have programming experience in writing Complex Stored Procedures, Queries, Views, User Defined Functions, Cursors and Common Table Expressions using SQL or T-SQL.
> Experience in Performance Tuning and Query Optimization by Indexing, Partitioning and De-normalization.
> Experience in Developing a framework for ingesting data into Data lake
> Good database knowledge, analytical thinking
> Design, construct, install, test and maintain data management systems.
> Build high-performance algorithms, predictive models, and prototypes.
> Develop set processes for data mining, data modeling, and data production.
> Experience with cloud services: AWS (EC2, EMR, S3, Athena) and scripting languages like Python, /PySpark/R/SAS
> Install/update disaster recovery procedures.
> Experience in Agile Application Development & Scrum methodologies is preferred
> Ability to supervise and mentor junior developers on the team.
> Must be self-motivated and work well pulling people together in addition to being able to pull people together technically
> Demonstrated proficiency of troubleshooting techniques and detail-oriented problem diagnosis
> Ability to handle responsibility, is self-directed, with strong organizational and documentation skills
> Ability to work independently and efficiently under aggressive deadlines to meet project commitments
> Excellent verbal and written communication skills

EDUCATION
UG - B.Tech/B.E. - Computers, Electronics/Telecommunication, Diploma - Computers, Electronics/Telecommunication, B.Sc - Computers, BCA - Computers) AND (PG - M.Tech - Computers, Electronics/Telecommunication, MCA - Computers, M.Sc - Electronics, Computers) AND ( Doctorate - Any Doctorate - Any Specialization, Doctorate Not Required).

OTHER DETAILS
Number of vacancies: 4
Experience: 3 years
Location: Cochin

If you have a passion towards technology and coding, then we have the right job for you. Kindly forward your resumes to
Email: jobs@mjsofttech.com
Phone: 0484-2421245 / 928 720 7160",4.0,"MJ Softtech
4.0",Kochi,"Cochin, India",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
1374,Data Engineer,"Education/ Experience and Skill Requirement
4+ years of relevant experience in
Experience working with both relational and NoSQL databases.
Strong coding skills; Python (preferred) /R/Java/Scala
Experience in developing Data warehousing technologies Experience with AWS or equivalent cloud services preferred
Experience in BigData technologies (Hadoop, HDFS, MapReduce, Spark, Hive, HBase etc) will be valuable
Knowledge of Machine Learning a big plus (Random Forest, Decision Trees, SVM, NLP, Gradient Boosting, Supervised/Unsupervised Learning, Clustering, classification and regression modeling).
Responsibilities
Proficiency with several years’ experience in more than one of Python, R, Java, Scala, or robust Linux shell scripting
Implementation experience with data warehouse architecture & design, ETL design/development, and Analytics
Knowledge of general cloud architecture and cloud strategies especially around AWS services and concepts such as S3 object stores, RDS databases, EC2, Glacier, Lambda, IAM, enterprise security, data security, DevOps, replication and disaster recovery
Well versed with data mining & exploration, NLP and visualization
Understanding of data modeling, data integration, and data representation (metadata, OWL, ontologies)
Developing data marts and data management using SQL
Creating powerful visual outcomes
Independently manage daily client communication, especially over calls
Manage client deadlines, ensure quality of the deliverables, attention to detail
Experience/understanding of corporate finance data from company filings is desirable",3.6,"Copal Partners
3.6",Bengaluru,"New York, NY",10000+ employees,1900,Company - Public,Financial Analytics & Research,Finance,₹100 to ₹500 billion (INR),-1
1375,Data Engineer,"Job Description / Responsibilities
Build workflows to ensure data extraction quality and storage into our backend data store
Architect, build and train ML/AI models that can predict outcomes and report on anomalies.
Design data pipelines to perform ETL on content/data from multiple types of source systems.
Create data analytics views using RDBMS/Key-Value stores, on private and public/cloud
Create software that is well tested, maintainable, extensible and scales out with large data

Minimum Qualifications:
2+ years of software development with Python
2+ years of SQL (MySQL/Postgres) and Key-Value databases
1+ years of experience with scikit
2+ years of experience in data extraction, data transformation using custom Python/Java
Experience working with MapReduce/Hadoop/kafka/Elastic stack
Experience with Node backend and React/Redux
Experience working with git/mercurial, Amazon/Google cloud, Linux/LAMP stack
Experience in testing or test driven development
Experience with Data science and Machine Learning algorithm development

Location:
Hyderabad/Bangalore

Package:
Highly competitive to match experience and capability",3.7,"TVS
3.7",Bengaluru,"Chennai, India",5001 to 10000 employees,-1,Company - Private,Accounting,Accounting & Legal,₹100 to ₹500 billion (INR),-1
1376,Data Engineer,"Permanent position with US based client of iFlex.
Work Location: Bangalore
Experience Level: 2+ Years

Role:
As part of our global team you will work on the data platform reporting to the Data Engineering Lead. Your role includes specification, development, test and rollout of features on our data platform. You are expected to contribute to the vision, understand our product roadmap, integrate business value andclient experience and contribute to build an engineering culture within the team. This initiative is of critical important to the success of the organization and our roadmap, for instance, services like liquidity analytics, billing, client onboarding, reporting and others will rely on the data platform. Accurate, granular, complete and timely data will be our key differentiating factor and competitive advantage in the market place. We expect the successful candidate to deliver high quality software and to be passionate about data engineering..

Responsibility / Qualification:
Managing multiple tasks and use sound judgment when prioritizing.
Collaborating with global cross functional team in building customer-centric products.
Analyzing existing software implementations to identify areas of improvement and provide deadline estimates for implementing new features.
Updating and maintain documentation for team processes, best practices and software runbooks.
Establishing trusted partnerships with peers, product heads, and executive level stakeholders.
We are looking for someone who is passionate about technology and engineering.
Exceptional analytical skills and ability to apply knowledge and experience in decision-making to arrive at creative and commercial solutions.
Ability to leverage technology to deliver business value.
You are independent and comfortable in a fast paced, ambiguous and often multi-directional work environment.

Preferred Qualifications:
B.S. or higher in Computer Science.
Minimum 2 years of relevant professional experience using a modern programming language (preferably Java/Scala).
Experience leveraging test driven development technics.
Comfort with Agile operating models.
Team oriented.
Strong interpersonal and communication skills.
Energetic, self-directed, and self-motivated.
Experience with microservice architecture.
Experience with Kafka, MongoDB, Hadoop, Cassandra.
Experience with AWS.
Experience in Financial Services or Fintech.",-1,IFLEX,Bengaluru,"Moscow, Russia",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1377,CIEL/SEL/1941: Sr data scientist,"Mandatory skills required -
Databases (SQL, Oracle, Any RDBMS) - Should have working knowledge of atleast one database
PL/SQL Programming Languages
R, Python (Any One)
Inferential Statistics - Hypothesis, p-value, R2, RMSE, MAPE etc
Exploratory Data Analysis
Machine Learning Algorithms - Should have in-depth knowledge and implementation of atleast one algorithm

Responsibilities
: Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the why & how of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions

Education
Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics
Experience
Minimum years of related experience required: 3 years
Preferred years of experience: 5 years
Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desirable.

Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
1378,Data Engineer,Data Engineer,3.6,"Bookmyshow
3.6",Mumbai,"Mumbai, India",1001 to 5000 employees,2007,Company - Private,Ticket Sales,"Arts, Entertainment & Recreation",Unknown / Non-Applicable,-1
1379,Data Analyst,"Required Skills & Experience

We are looking for a Data Analyst Executive
Eligible Qualifications : B. Tech, BCA, M.Tech, MCA
Experience : 3-5 years, fresher’s can also be considered
Location of Job : Gurgaon/Connaught Place, New Delhi
Technicals Skills

Following technical skills are pre-requisite:
Well versed with Software development methodologies, such as SDLC (Software Development Life Cycle), DDLC (Document Development Life Cycle).
Database schema design and implementation
Should have worked in either of technologies Sql Query/ Tableau/ Excel (Macros)/ Access (Query) writing for data analytics.
For planning and coordinating activities, organizations remain in invariant communication with one another and the data transfer has to be performed efficiently and smoothly as possible.
He/ She should manage the execution of the technologies, help the businesses in utilizing the systems, and should be well versed with the basics of computer systems such as Networking, Installation of necessary software and hardware.
Ability to determine the interrelationships between solutions and requirements.
Ability to think analytically and should be a problem solver and logic building should be very strong.
Good interpersonal skills to form effective working relationships with people at all levels.
Excellent communication and presentation skills and strong written & oral English skills.
To know more about us visit us www.sspl.net.in or write to us at admin@sspl.net.in",-1,Substratal Solutions,Connaught Place,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1380,Artificial Intelligence Scientists,"Experience 2- 4 Years
Salary 4 LPA - 6 LPA
Job Location Chennai

Industry:
IT-Software / Software Services

Keywords:
Artificial Intelligence

About Job:
Must have Excellent knowledge in AI / Machine learning (Mandatory).
Machine learning frameworks like keras, tensor flow etc.
And also other big data tools like Hadoop etc, Must know R and python.
Good understanding in SDLC & Business cycle.",4.0,"Careerera
4.0",Chennai,"Wayland, MA",501 to 1000 employees,-1,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
1381,Senior Data Engineer,"About Us

upGrad is an online education platform building the careers of tomorrow by offering the most industry-relevant programs in an immersive learning experience. Our mission is to create a new digital-first learning experience to deliver tangible career impact to individuals at scale. upGrad currently offers programs in Data Science, Machine Learning, Product Management, Digital Marketing, and Entrepreneurship, etc. upGrad is looking for people passionate about management and education to help design learning programs for working professionals to stay sharp and stay relevant and help build the careers of tomorrow.
upGrad was awarded the Best Tech for Education by IAMAI for 2018-19
upGrad was also ranked as one of the LinkedIn Top Startups 2018: The 25 most sought-after startups in India
upGrad was earlier selected as one of the top ten most innovative companies in India by FastCompany.
We were also covered by the Financial Times along with other disruptors in Ed-Tech
upGrad is the official education partner for Government of India - Startup India program
Our program with IIIT B has been ranked #1 program in the country in the domain of Artificial Intelligence and Machine Learning
About the Role

We are looking for a Data Engineer to help us scale the existing data infrastructure and in parallel work on building the next generation data platform for analytics at scale, machine learning infrastructure and data validation systems.
In this role, you will be responsible for communicating effectively with data consumers to fine-tune data platform systems (existing or new), taking ownership and delivering high performing systems and data pipelines, and helping the team scale them up, to endure ever growing traffic.
This is a growing team, which makes for many opportunities to be involved directly with product management, development, sales, and support teams. Everybody on the team is passionate about their work and we’re looking for similarly motivated “get stuff done” kind of people to join us!

Roles & Responsibilities
Engineer data pipelines (batch and real-time ) that aids in creation of data-driven products for our platform
Design, develop and maintain a robust and scalable data-warehouse and data lake
Work closely alongside Product managers and data-scientists to bring the various datasets together and cater to our business intelligence and analytics use-cases
Design and develop solutions using data science techniques ranging from statistics, algorithms to machine learning
Perform hands-on devops work to keep the Data platform secure and reliable
Skills Required
Bachelor's degree in Computer Science, Information Systems, or related engineering discipline
6 + years’ experience with ETL, Data Mining, Data Modeling, and working with large-scale datasets
6+ years’ experience with an object-oriented programming language such as Python, Scala, Java, etc
Extremely proficient in writing performant SQL working with large data volumes
Experience with map-reduce, Spark, Kafka, Presto, and the ecosystem.
Experience in building automated analytical systems utilizing large data sets.
Experience with designing, scaling and optimizing cloud based data warehouses (like AWS Redshift) and data lakes
Familiarity with AWS technologies preferred
Qualification – B.Tech/M.Tech/MCA(IT/Computer Science)

Years of Exp – 6-9",3.5,"upGrad Education Private Limited
3.5",Mumbai,"Mumbai, India",501 to 1000 employees,2015,Company - Private,Education Training Services,Education,₹1 to ₹5 billion (INR),"Udacity, General Assembly, Springboard"
1382,BBRC-Genomics-Associate Scientist,"JOB DESCRIPTION

Designation: Associate Scientist

Job Location: Bangalore

Department: Translational Medicine- Translational Sciences

About Syngene

Incorporated in 1993, Syngene International Ltd. is an innovation-focused global discovery, development and manufacturing organization providing integrated scientific services to the pharmaceutical, biotechnology, nutrition, animal health, consumer goods and specialty chemical industries around the world. Syngene’ s clientele includes world leaders such as Bristol-Myers Squibb, Baxter, Amgen, GSK, Merck KGaA and Herbalife. Its innovative culture is driven by the passion of its 4240- strong team of scientists who work with clients from around the world to solve their scientific problems, improve R&D productivity, speed up time to market and lower the cost of innovation .

Job Purpose:
To play a key role in TM-TS, develop an early-stage research strategy, initiate and lead discovery programs while managing ongoing programs in TM-TS. The role will work part of TMTS, and work with internal and external collaborators .

Key Responsibilities:
Experience in isolating DNA and RNA from blood, tissues and FFPE samples and cell lines. Experience with optimization of extraction protocols and for parameters like yield, input sample quantities and sample types is important.
Expertise in PCR, qPCR, cDNA/gDNA library preparation. Exposure to microarray techniques.
Proficiency in preparation of libraries for Next Generation Sequencing of transcriptome and genome, with significant experience in optimization of parameters like input RNA/DNA quantities and sample type
Experience with single cell RNA-seq will be plus.
Experience with various NGS protocols (DNA Amplicon based, hybrid capture based low input, degraded DNA and RNA samples e.g. FFPE samples.
Strong understanding of experimental design and statistical principles behind experimental design and differential gene expression. Experience with analysis of single cell RNA-sequencing data will be a plus

Educational Qualification:
M.Sc or M. Tech in Biotechnology, Molecular biology or Biological Sciences,

Technical/functional Skills:
DNA/ RNA Isolation, Expertise in PCR, qPCR, Experience in NGS protocols

Experience:
2 to 5 Years

Behavioral Skills:
A proactive team player.
Ensure completion of experiments and generate accurate and reproducible data from experiments.
Ability to work independently, prioritize tasks and work on multiple projects simultaneously with; comfortable working in a dynamic environment with changing requirements.
Good oral and written communication and presentation skills to work in a multi-disciplinary team
Equal Opportunity Employer:
It is the policy of Syngene to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by applicable legislation or local law. In addition, Syngene will provide reasonable accommodations for qualified individuals with disabilities.",3.5,"Syngene
3.5",India,"BENGALURU, India",1001 to 5000 employees,1994,Unknown,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1383,Applied Scientist 1,"Position Requirements:
Master's degree in Computer Science, Computer or Electrical Engineer, Mathematics, or a related field plus at least one year of experience in the job offered or related occupations of Software Engineer, Software Developer, or a related occupation. Employer will accept a Bachelor’s degree and five years of experience in the job offered or a related occupation as equivalent to the Master’s degree and one year of experience. One year of experience in the job offered or related occupation must involve designing and developing large-scale, multi-tiered, distributed software applications, tools, systems and services using Java, Object Oriented Design and Distributed Programming].

Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, Oracle/Berkeley databases, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills

Amazon Selling Partner Services team drives the Selling On Amazon business and develops solutions that enable millions of sellers around the world to sell on Amazon's Marketplaces. More than half of shipments for Amazon customers are generated from this business. The team is focused on building a technology platform that will support the explosive business growth in existing markets, streamline the business for Amazon and the Selling partners and launch business in new markets and establish a fair marketplace.

Our team is seeking engineers with broad technical skills to help us optimize how we synthesize massive amounts of data and complex business rules into mission critical financial information. As a member of this team you will employ object oriented techniques in Java, and DynamoB, PostGres and ElasticSearch skills to help us support Amazon's next generation of selling partner services. Along the way you'll gain and leverage a unique understanding of how Amazon.com works; from the numerous software systems that comprise the website's back-end, to the details of our business model, and the relationships we're establishing with an ever-growing network of selling partners who depend on Amazon.com to run their businesses.

The ideal candidate will draw upon exemplary analytical, critical thinking, and problem solving skills, and a passion for maintaining highly reliable, distributed systems which operate 24/7/365. Successful members of this team collaborate effectively with internal end-users, aggressive cross-functional software development teams, and technical support/sustaining engineering teams to solve problems and deliver successfully against high operational standards of system availability and reliability. We look for engineers who are excellent communicators, self-motivated, flexible, hardworking, and who like to have fun!

Position Responsibilities:
Participate in the design, development, implementation, testing and documentation of large-scale, multi-tiered, distributed software applications, tools, systems and services using [Java, Object Oriented Design and Distributed Programming]. Translate functional requirements into robust, scalable, supportable solutions that work well within the overall system architecture. Participate in the full development cycle, end-to-end, from design, implementation, and testing to documentation, delivery and maintenance. Produce comprehensive, usable software documentation. Evaluate and make decisions around the use of new or existing software products and tools.

Preferred Qualifications
Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1384,Senior Clinical Data Analyst,"About Novotech:

Novotech is internationally recognised as the leading independent and full-service contract research organisation (CRO) in the Asia Pacific region. We provide a wide range of clinical development services across all research phases and therapeutic areas and have been instrumental in the success of hundreds of Phase I – IV clinical trials throughout the Asia Pacific. Powered by the highest quality people, Novotech strives to set the benchmark for both business and clinical trial performance. Our people are one of our key strengths. We value our people and recognise the work they do. We are lucky to have the best people and talent from across the Asia Pacific region work together to deliver to clinical trial success for our clients. Our people and those we look to recruit have an attitude of making things happen. They are problem solvers, driven with a focus on delivering quality, accountability and a high level of performance.

Brief Position Description:

As part of Novotech’s Biometrics unit, the Senior Data Analyst (SDA) is responsible for all data analysis and business intelligence activities related to study related clinical and operational data. The SDA acts as primary point of contact for all data analysis matters to the study team and is responsible for the timely delivery of quality outputs following all applicable regulatory, compliance, best practice and operational procedures.

Minimum Qualifications & Experience:

Graduate in information science, data science or life science-related field, or similar. More than five years’ experience in a senior role related to data science, data analysis, clinical data management or clinical data programming in a pharmaceutical company, CRO or EDC software provider.

Responsibilities
The Senior Data Analyst (SDA) is responsible for providing technical, procedural (SOPs) and planning leadership across multiple projects assigned to the data analyst team members ensuring that they deliver in accordance with SOPs, programming best practices, and the timelines agreed within the Project Team.
Collaborate with cross-functional stakeholders to implement data science solutions to solve business needs using available technological solutions.
Scope data analysis effort for projects and project manage all data analysis activities across multiple projects for different study stakeholders.
Gather study requirements from data management for data review and external data reconciliation and provide guidance on appropriate outputs (dashboards, visualisations, listings, reports).
Extract, assess, integrate, transform data sources to provide data visualisation outputs for analytics.
Design and develop prototypes and final versions of data outputs (dashboards, reports, visualisations, listings) using Business intelligence tools and Data Visualisation tools.
Design and develop standard dashboards and content for different audiences.
Analyse, manipulate and understand data from multiple sources to present and create dashboards and reports to make business decisions.
Assist teams on best-practice for data visualisation dashboard development.
Educate teams on how to use all the features of applicable data visualisation platform in conjunction with data visualisation dashboards.
SME for the data visualisation development and assisting team members.
Identify and communicate project risks and maintain documentation within project files as appropriate
Represent data analysis group at internal / external meetings as appropriate.
Assess and implement new data analysis, BI and data visualisation processes and technologies.
Take an active role in the development of best practices, process improvement, quality control and governance related to all data analysis matters.
Provide training and mentoring to Data Analysis of team members in SOPs, software applications, and best practices.
Provide Subject Matter Expertise on all data analysis and visualisation related activities.
Attributes and Skills

Expert knowledge of clinical study data structures and schemas of EDC databases. Expert knowledge in data processing activities such as extracting, integrating, transforming and presenting data. Statistical Programming skills in Python, R or similar. Knowledge of SQL and EDC systems. Working knowledge of Spotfire, Power BI, Tableau or other data review and visualisation tool. Ability to gather business requirements from multiple stakeholders and clients and provide guidance on the use of appropriate data visualisations.

Experience mentoring and training others. Awareness of regulatory and compliance issues and understanding of the application of SOPs and Quality Control to daily activities. Excellent analytical, communication and problem-solving skills.

Opportunities and Benefits:

To deliver clinical trial and research excellence for our clients, our people are 'best in class'.

At Novotech, we seek and nurture people with exceptional talent. We are committed to providing our people with regular internal and external training, a competitive bonus structure and a supportive work environment. We are also focused on providing our people with a wide variety of career growth and development opportunities.

For more information about where your next career step at Novotech might take you, visit http://novotech-cro.com/novotech-careers",4.5,"Novotech
4.5",Bengaluru,"Sydney, Australia",501 to 1000 employees,1996,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
1385,Data Engineer,"Data Engineer Responsibilities:
Liaising with coworkers and clients to elucidate the requirements for each task.
Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed.
Reformulating existing frameworks to optimize their functioning.
Testing such structures to ensure that they are fit for use.
Preparing raw data for manipulation by Data Scientists.
Detecting and correcting errors in your work.
Ensuring that your work remains backed up and readily accessible to relevant coworkers.
Remaining up-to-date with industry standards and technological advancements that will improve the quality of your outputs.
Data Engineer Requirements:
Bachelor's degree in Data Engineering, Big Data Analytics, Computer Engineering, or related field.
Master's degree in a relevant field is advantageous.
Proven experience as a Data Engineer, Software Developer, or similar.
Expert proficiency in Python, C++, Java, R, and SQL.
Familiarity with Hadoop or suitable equivalent.
Excellent analytical and problem-solving skills.
A knack for independent and group work.
Scrupulous approach to duties.
Capacity to successfully manage a pipeline of duties with minimal supervision.
Job Type: Full-time

Salary: ₹360,000.00 to ₹870,000.00 /year

Experience:
total work: 2 years (Preferred)
Data Engineer: 1 year (Preferred)
Education:
Diploma (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,Futurious Technologies,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1386,Quantitative Analyst,"The successful candidate will be a highly analytical individual with hands on programming skills. The candidate will work closely with the research team and clients towards the ongoing development and integration of new investment strategies, models and tools on Axle

Location

Mumbai
Responsibilities

Perform daily/weekly/monthly tasks of performance and risk reporting
Develop and automate investment processes and strategies via VBA and Matlab
Develop tools to integrate trading decision systems with risk management systems
Ad hoc tasks (such as operational tasks, internal documentation tasks and preparation of marketing materials)
Skills/Experience

Excellent programming skills in Matlab/Excel-VBA
Thorough with financial concepts and calculations like Drawdown, VaR, Eloss etc.
Understanding of financial market products like options, futures, FX forwards etc.
Working knowledge of Bloomberg is preferred
Should be self-driven and detail oriented with an analytical mindset
Should be a proactive and quick learner; a team player showing enthusiasm and drive to accomplish results in a fast paced environment
Min. 2 years of relevant work experience
Qualifications

B.Tech/M.Tech/MBA/CFA/FRM",5.0,"B&B Analytics
5.0",Mumbai,"Zug, Switzerland",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1387,Analyst - Data Scientist,"Job Summary

Experience:
3 - 5 Years

Location:
Mumbai

Designation:
Analyst - Data Scientist

Degree:
BE-Comp/IT, BE-Other, BTech-Comp/IT, BTech-Other, ME-Comp/IT, ME-Other, MTech-Comp/IT, MTech-Other, PhD-Comp/IT, PhD-Other

Educational Level:
Graduate/Bachelors

Industrial Type:
IT-Software/Software Services

Functional Area:
IT Software - Application Programming / Maintenance

Key Skills:
Data Scientist

Job Post Date:
Thursday, March 19, 2020

Company Description

We are capability centre based in Mumbai, initially started as a back-office operational support to the UK business unit.

However, over the recent years, we have significantly increased the breadth and depth of our capabilities and offerings to keep pace with the changing needs of the Group. These include Digital & Knowledge Services, Finance and Actuarial, Information Technology (IT), Customer Service, Risk and Audit.

Our core purpose is to be a strategic partner to company, enabling growth by delivering change and driving synergies through a highly capable and agile workforce.

With our diversified service offerings we provide our people with exciting opportunities to grow personally and professionally.

Company is a leading savings and investments business serving around 5.5 million retail customers and more than 800 institutional clients.

It-s innovative asset management and customer solutions are supported by extensive investment capabilities, an international distribution network and two strong brands.

Job Description

3 – 5 yrs experience as Data Scientist
Should have at-least 1 end-to-end ML project experience
Very high proficiency in R or Python
Excellent in forecasting methods like simple exponential smoothing, multiplicative seasonal indexes, simple and weighted moving averages and time series forecasting methods
Exposure to with advanced deep learning techniques such as LSTM. CNN, Dense neural networks as well as neural networks design and implementation through tools like tensorflow, keras, pytorch, deepai or equivalent.
Good SQL experience",3.8,"Sampoorna Computer People
3.8",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
1388,Data Lake Developer,"For Us, It's A Mission

At Mylan, we mean it when we say we work every day to provide access to high quality medicines to the world's 7 billion people. If you are unconventional, relentless and passionate. If you believe in doing what's right, not what's easy. If you are a doer and have a passion for serving others, we want to talk to you.

Make a Difference

At Mylan, each person has the ability to make a difference. From the providers who sell and market our products, to the producers who develop and manufacture them and finally to our business partners who support the providers and producers, we all have a mission critical role. Here's how this role will help:

ESSENTIAL DUTIES AND RESPONSIBILITIES
To perform this job successfully, an individual must satisfactorily perform each essential duty. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential duties.
1. Create and maintain optimal data pipeline architecture on Azure platform.
2. Develop batch processing solutions by using Data Factory and Azure Databricks.
3. Delivering a Data Warehouse in the Azure Cloud.
4. Design relational and non-relational data stores on Azure.
5. Identify, design, and implement internal process improvements : automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc..
6. Developing Big Data Solutions with Azure Machine Learning.
7. Strong interaction with business departments to provide consultative support for digitization efforts, as well as close collaboration with the Business Technology management, focused on future innovation topics.
8. Participate and lead in design sessions, demos and prototype sessions, testing and training workshops with business users and other IT colleagues.
9. Design & Build for any API Development or SQL DB development.
10. Providing service management, orchestration, monitoring and management requirements of Azure cloud platform.
11. Create data tools / products for analytics and data scientist team members that assist them in building and innovative solutions that drive tangible business value.
12. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
13. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
14. Design security for source data access. Chose the appropriate authentication mechanism, (ie Azure Active Directory (Azure AD), etc).
15. Design for real-time processing by using Stream Analytics and Azure Databricks.

Make Our Values Your Values

Mylan hires only the best. People who thrive in a culture of innovation and empowerment. People who are active learners and have a positive attitude. People who are leaders and know that by working together we can run faster, reach higher and achieve more. By doing so, we will continue to set new standards in health care. Here are the minimum qualifications and essential functions for this position:

QUALIFICATIONS

The qualifications listed below are representative of the minimum knowledge, skill, and/or ability required.

SKILLS AND ABILITIES

1. 10 years of experience in Microsoft technologies including SQL.

2. At least 5 years as a Sr Developer with at least 3 years hands on experience as Azure Data Engineer building large scale Azure data solutions.

3. At least 5 years of experience in Azure based data solutions.

4. At least 3 years of experience on working with large projects including the most recent project in the cloud (Azure) or on prem with a focus on Azure Data services.

5. At least 5 years of Hands-on administration, configuration management, monitoring, performance tuning of Hadoop/Distributed platforms.

6. At least 5 years of demonstrated experience at least in the most recent 2 years of designing and delivering solutions using Cortana Intelligence suite of analytics services part of Microsoft Azure including Azure Machine Learning Studio, HDInsight, Polybase, Azure Data Lake Analytics, Azure Data Warehouse, Streaming Analytics, Data Catalog, R/R Studio

7. Experience in designing and building logics required for optimal extraction, transformation, and loading of data from a wide variety of data sources

8. Experience within Data Security design, including but not limited to:

a. Choosing the appropriate authentication mechanism, such as Azure Active Directory (Azure AD)

b. Defining strategies for data encryption for data at rest and in transit

9. Experience partnering with Business Analysts and Data Scientists to enable effective and efficient data preparation and delivery

10. Experienced in vendor management and working with 3rd parties onshore & offshore.

11. Experience working in a global team.

12. Experience working in an Analytics / Big Data solutions on MS Azure Cloud

13. Experience with code management tools, automated testing

14. Experience creating and maintaining optimal data pipeline architecture on Azure platform

15. Experience developing batch and real-time processing solutions by using Data Factory and Azure Databricks

16. Familiar with AGILE and Azure DevOps methodology

17. Hands on PoC capabilities are needed to prove a particular architecture concept

18. Azure Native Services experience across Data Fabric and Service Fabric

19. Experience in Application modernization from legacy on-premise data architecture platform technology stack to modernized Azure Cloud base Architecture.

20. Experience with Git, NoSQL Data Solutions, Microsoft Azure, HD Insights, Azure ML, DataBricks ML Flow, R or Python.

21. Must have excellent communication skills.

EDUCATION/EXPERIENCE (Note: Please select one)

Minimum of a Bachelor's degree in Computer Science and Engineering is preferred with minimum 10 years of experience. However, a combination of experience and/or education will be taken into consideration

Why Mylan?

If you want to be part of a global health care company that is making a difference and changing lives, Mylan may be the place for you. With a workforce of more than 35,000 worldwide, we can make a difference. We encourage you to visit Mylan.com to learn more about our unconventional culture, our approach to doing business and how we plan to set new standards in health care.

Mylan offers competitive salary, excellent benefits and an environment conducive to professional growth and advancement. All qualified applicants will receive consideration for employment without regard to their disability or protected veteran status. Mylan is an Equal Opportunity Employer, Minorities/Female/Disabled/Veteran.",3.8,"Mylan Inc.
3.8",Bengaluru,"Hatfield, United Kingdom",10000+ employees,1961,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1389,Off Campus Recruitment - Quantitative Researcher,"Description:
Graviton is a privately funded quantitative trading firm striving for excellence in financial markets' research. We are seeking fresh talent from the top IIT's to join us as Quantitative Researchers for our team in Gurgaon.If you are a student graduating in 2020 from Computer Science , Electrical or Maths Stats Computing streams with a greater than 8 CGPA please apply here.

This role is open to students from campuses that we could not visit this year. Please check your individual placement policy restrictions before applying.

Graviton trades across a multitude of asset classes and trading venues using a gamut of concepts and techniques ranging from time series analysis, filtering, classification, stochastic models, pattern recognition to statistical inference analysing terabytes of data to come up with ideas to identify pricing anomalies in financial markets.

As a Quantitative researcher your responsibilities will include

Develop new or improve existing trading models using in-house platforms

Use advanced mathematical techniques to model and predict market movements

Analyse large financial datasets to identify trading opportunities

Provide real time analytical support to experienced traders

Requirements :
Possess a degree in a highly analytical field, such as Engineering, Mathematics, Computer Science from IITs schools

Quantitative bend of mind

A working knowledge of Linux/Unix

Programming experience, preferably in C++ or C

Strong interest in learning about financial markets.

Have a strong work ethic

Hard Working

Benefits:
Our open and casual work culture gives you the space to innovate and deliver. Our cubicle free offices , disdain for bureaucracy and insistence to hire the very best creates a melting pot for great ideas and technology innovations. Everyone on the team is approachable, there is nothing better than working with friends!

Our perks have you covered.

Competitive compensation

6 weeks of paid vacation

Monthly after work parties

Catered breakfast and lunch

Fully stocked kitchen

Gym membership

International team outing",5.0,"Graviton Research Capital LLP
5.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2014,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1390,Data Engineer,"Zauba Technologies is a startup based in Bangalore. Zauba's services are used by leading companies in India. Zauba is powered by a young and passionate team. We are looking for individuals who would like to be a part of our founding team.

As a Data Engineer and as a part of founding team, you will be expected to visualise and develop disruptive data products. Eventually you would be responsible for entire project lifecycle of products you would visualize. Your rewards will be directly proportional to the value you generate.

Job Responsibilities
Design and development of robust, scalable and highly efficient data engineering solutions for structured and unstructured data (Including gathering and processing raw data at scale, writing scripts, web scraping, calling APIs, writing SQL queries, etc.)
Develop processes for text mining and extraction of information from unstructured data
Design, architect and develop efficient data pipelines around the data collected
Take ownership of existing web product and applications
Design and implement data models that scale across the enterprise
Take ownership of existing data workflows and processes
Enhance scalability, performance, and stability of existing infrastructure
Work closely with other team members to integrate your innovations and algorithms into our production systems

Essentials
Java/Python - Intermediate to advanced level
SQL - Advanced
MySQL Intermediate to advanced level
Regex - Basic to intermediate level
Linux Basic to intermediate level

Good to have
Hadoop/Spark
R
MongoDB

Must have qualities
Skills to learn new skills quickly
Desire to create disruptive products and services
Passion - not just to work in startups but to take them to next level
Above average programming aptitude
Be passionate about producing high quality engineering deliverables
Be productive working independently or collaboratively
Have an eye for building efficient processes
Be self motivated
Proactively take ownership

Interested?

Send your resume to hr@zaubacorp.com",3.8,"Zauba Corp
3.8",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 million (INR),-1
1391,Quantitative Research,"We are looking for highly trained professionals who are interested in applying advanced mathematical quantitative methods to the modeling of global financial markets. You would be joining a group made up of highly proficient individuals from various scientific disciplines. We have a spectrum of opportunities for individuals with the right scientific skills. Experience in finance is not required.

The ideal research candidate will have:
A Ph.D. in Computer Science, Mathematics, Physics, Statistics, or a related technical discipline.

A demonstrated capacity to do first-class research.

Computer programming skills.

An intense interest in applying quantitative analysis to solve difficult problems.

Send us a copy of your resume to
careers@dolatcapital.com

For internship opportunities, please send us a copy of your resume to
careers@dolatcapital.com",4.0,"Dolat Capital
4.0",Mumbai,"Mumbai, India",51 to 200 employees,1970,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1392,Data Engineer,"Bachelor’s degree in Computer Science or related field
5+ years relevant experience
5+ years experience with SQL, SQL Tuning, Oracle, OLAP, Big Data Technologies
5+ years experience developing end-to-end Business Intelligence solutions: data modeling, ETL and reporting
Experience with Java and experience with scripting languages like Perl, Python, Unix shell scripts,VBA and MS Excel
Proficiency with Linux and systems administration
Proven ability at looking at solutions in unconventional ways. Sees opportunities to innovate and can lead the way.
Top notch communication (verbal and written) and interpersonal skills to convey key insights from complex analysis in summarized business terms and an ability to effectively communicate with technical teams.
Ability to work with shifting deadlines in a fast paced environment.
Operations Finance Technology team, responsible for building technical solutions for multi-billion WW Operational Cost analytic including Inbound cost (Receiving / PO), variable Cost, fixed cost, outbound (Customer Shipments / Transportation), and Customer Service, is looking for a Data Engineer.

As a data engineer, you will get the exciting opportunity to work on very large data sets in one of the world's largest and most complex data warehouse environments. You will work closely with the business teams in analysis on various cost savings initiatives, many non-standard and unique business problems and use creative-problem solving to deliver actionable output.
You will be responsible for designing and implementing an analytical environment using third-party and in-house reporting tools, modeling metadata, building reports and dashboards. You will have an opportunity to work with leading edge technologies like Redshift, Hadoop/Hive/Pig. You will be writing scalable queries and tuning performance on queries running over billion of rows of data.

You should be analytical, have an extremely high level of customer focus and a passion for process improvement. You should be motivated self-starter that can work independently in a fast paced, ambiguous environment. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions.
Bachelors in Computer Science or related field
Practical Knowledge of Linux or Unix shell scripting
Experience in working with business customers to drive requirements analysis
Exposure to large databases, BI applications, data quality and performance tuning
Excellent written and spoken communication skills
Experience with Hadoop-based technologies such as HBase, Pig, Hive and Spark
Strong proven ability in building high-performance, highly available and scalable data solutions using Oracle and/or Hadoop-based technologies
Knowledge of data warehousing concepts.
Strong sense of ownership, urgency, and drive
Strong troubleshooting and problem solving skills
Experience with Amazon Web Services",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1393,DATA ANALYST,"posted by Mahima Gaur

2 - 5 years Delhi

Job Description
Experience in data processing
Experience in data cleaning and data tabulation activities
Strong analytical, communication and team management skills
Strong understanding of data management using SPSS and research techniques
Competency in a Tabulation software (decipher / wincross / quantum etc), Excel, Powerpoint
Ability to summarize findings, draw conclusions, and put together a presentation using Powerpoint
Role Category : Data Analyst

Employment Type : Permanent Job, Full Time",4.9,"Knowledge Excel Services.
4.9",New Delhi,"New Delhi, India",1 to 50 employees,2007,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
1394,Data Engineer,"Key skills : Python , Spark , SQL , Pyspark • AWS platform used for the work • Strong experience in SQL is mandatory • Good familiarity of AWS landscape • Good experience in collecting business requirements & design them as per requirement from customer • Should able to work independently & interact business users & technical stakeholders • Strong communication skills both oral & written. • Should work as an individual resources",3.5,"Larsen & Toubro Infotech Limited
3.5",India,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1395,Big Data Engineer,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
1396,Client Data Analyst,"At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.
What is the Client Data Analyst – Client Analytics group responsible for?
This team manages business data to ensure accurate, timely, consistent and compliant data. Their contributions deliver quality data that is easily accessible and can be trusted. Key downstream capabilities such as reporting and analytics depend on this as well as operational data access on various systems. The Data Management Team is a support function that acts as an advocate and a point of contact for Sales and Marketing data.

What are the ongoing responsibilities of an Client Data Analyst ?
Understand the data flow, key consumption and production of data as well as context within the enterprise:
Build positive relationships with teams, especially the key data consumers and analytics. Take the time to increase knowledge of how they run their business and incorporate sales data into daily work
Connect regularly with each sales office to understand current issues and challenges. Probe the business and validate against other sales offices to understand the scope and priority of the issue
Make recommendations on how data unifications and flow can be used to improve business tasks. Liaise business partners to deliver solutions (reports, processes, technology) that add value.

Provide data management subject matter expertise. Appreciate the connection and data flow between applications and other corporate systems. Be able to clearly articulate the data needs and move initiatives forward by collaborating with business partners:
Actively participate in meetings with business partners to ensure that priorities are clearly understood, information is regularly shared and that key participants are “kept in the loop”
Provide context and background on issues. Collaborate on ideas for progressing initiatives. Ensure appropriate resources are involved to take initiatives forward
Provide insights and expertise to scope statements and requirements documentation
Actively consult or participate in the user acceptance testing process (test cases, documentation, testing execution, etc.)
Ensure business needs remain aligned with overall corporate initiatives and deliver the benefits as originally intended

Monitor the integrity of data and usefulness of reports. Ensure the information available within systems is accurate and up-to-date. Proactively seek data cleansing opportunities and evolve data to better support. Document and maintain ongoing processes for reporting and data clean-up:
Partner with all key data consumers to gain a solid understanding of usage and challenges around data. Establish processes for prioritization of enhancements, especially with the analytics groups
Provide 1st level support for data issues and data maintenance for owned data
Verify and execute data loads into our internal sales systems and ensure any upstream systems accurately receive their data

Increase awareness and promote data management capabilities. Share best practices and provide coaching to local offices on how to access and incorporate output into sales tasks. Encourage IAS leaders to leverage data to make more informed, strategic decisions:
Clearly articulate the goals and core services of the data management team. Proactively promote this information within IAS and ensure business partners understand the data management role within the organization
Share best practices and provides guidance on data capabilities. Reinforces ownership and accountability for data accuracy
Seek opportunities to share the benefits of leveraging sales data to make more informed business decisions

What ideal qualifications, skills & experience would help someone to be Successful?

Knowledge, Education And Experience:
Four year bachelor’s degree required (majors of preference include: business, computer science, mathematics) Advanced degree a plus
Understanding of the Franklin Templeton business model, how FT makes money, the sales process, how technology fits in with the business, etc. Knowledge of the GAS (Global Advisory Services) structure
Experience working through multiple business fiscal cycles; exposure and/or direct experience with project management and/or sales-related-capacity required
Prior work experience related to analytics, sales, marketing and/or international a must. Level will not be granted based on years of experience but will be determined by the employee’s ability to meet each job activity as outlined the ‘typical/expected focus by level
Skills And Abilities:
Ability to communicate effectively with all levels of management; ability to tailor communication style based on audience; ability to get others to want to collaborate with you; strong facilitation skills
Excellent writing skills (for presentations, documentation, etc.)
Working knowledge of the CRM, MDM, Excel, SQL, Power BI, Tableau, Business Objects, and Microsoft Products (PPT, Power Apps, Doc, Visio)
Ability to absorb and interpret large quantities of data; apply trend analysis and knowledge of the business to develop a meaningful and digestible summary with the appropriate level of detail
Ability to take a larger problem and break down the individual components; identify how to go about solving the problem and who to involve in the process
Ability to present recommended solutions to a variety of issues and problems (solutions that are consistent with organization objectives)
Must be extremely detail-oriented (managing lists, tasks/to-dos, etc.) good with follow through on own items; good with following up with others on outstanding item

What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.

Highlights of our benefits include:

Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.",3.8,"Franklin Templeton Investments
3.8",Hyderabad,"San Mateo, CA",5001 to 10000 employees,1947,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Fidelity Investments, Vanguard"
1397,Data Analyst,"Roles and Responsibilities:
Extracting, transforming and inputting data sets from various resources. Creating predictive models, translating non-technical aspects into quantifiable tasks. Analysis and representation of output data, highlight and explain trends and patterns, error elimination, using advanced statistical methods (regression, probability distribution, clusters etc.) to provide accurate results.
Data collection, Data Mining, Report generation, Problem identification and solution formulation Market analysis and establishing trends, Strategy development and implementation

Skills:
Extremely good analytical skills.
Good working knowledge of all MS-Office products, especially Advance Excel, Word, PowerPoint, MS-access.
Statistical tools and methods.

Interested candidates can send the updated resume on satish.mehra@exelaonline.com or call on 7722028636
00-7.00 Years",2.6,"Exela Technologies
2.6",Pune,"Irving, TX",10000+ employees,2017,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"SourceHOV, BancTec, Transcentra"
1398,Data Modeler,"• Minimum 5-8 years of working experience as Data modeler.
• Data modelling experience in designing.
• Minimum 2-3 years real time experience in Erwin tool is mandatory.
• Experience in normalized modeling techniques.
• Experience in designing the Start schema.
• Experience working in ORACLE.
• Experience with database design, capacity planning, performance tuning and query optimization.
• Experience in working with Bank or Banking and Finance or Financial domain.
• Excellent communication skills with leadership quality.

Job Segment:
Database, Oracle, ERP, Technology",3.5,"LTI
3.5",Mumbai,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1399,Machine Learning Engineer,"Looking for Data Scientists with Python/R Programming skills.
Specific experience in AI areas like Statistical Machine learning / Deep learning / Natural Language Processing (NLP)/ Operations Research (Optimization) will be an advantage.Individual in this role is expected to work with multiple stakeholders and teams

Qualifications and Requirements:-
Previous working experience as a Machine Learning/ Data Scientist for 2 years
MA in Computer Science or similar relevant field
Hands on experience with MALLET
In depth knowledge of Apache Tomcat/Open Source
Excellent project and time management skills
Attention to detail
Outstanding problem solving and analytical skills",-1,Tekolutions.ai,India,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1400,Data Science Internship,"About the company:
SkillBit is a leading staffing and recruitment company engaged in talent searching assignments for skilled and talented candidates for the industry.

About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Working on data science algorithms and AI concepts 2. Using Python or R for web scraping 3. Building AI models using Python, machine learning, and deep learning algorithms 4. Processing of unstructured/structured data

Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 6th Jun'20 and 11th Jul'20
are available for duration of 1 month
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply

Number of internships/jobs available: 3

Categories: Data Science",-1,SkillBit,Pune,-1,-1,-1,-1,-1,-1,-1,-1
1401,Data Engineer,"As a data engineer at TEAL, you'll be taking the plunge into a rich data lake that includes everything from satellite data to legal court orders. You'll be hustling and getting your hands dirty with every part of the data pipeline always having an implicit appreciation for how all of this data will ultimately power a revolutionary real estate risk platform.

Your day-to-day will include either all or some of the following:

Constantly scoping out new data sources to complement existing ones
Creating and maintaining distributed web scrapers using Python, RabbitMQ and other technologies
Architecting and managing data pipelines where data flows into multiple end-points including, but not limited to, Postgres, MongoDB and Apache Solr
Documenting workflows and constantly iterating to create better data infrastructure.

We'd love it if you:
Are proficient in Python or any other object-oriented language
Have worked with large (millions to hundreds of millions of rows in a SQL database) interdisciplinary datasets
Have scraped difficult websites and have some experience working with various data APIs
Are patient and methodical with unstructured and messy data
Are always hungry to learn newer and better technologies to make the data ecosystem faster, smoother and less silo-ed

Extra brownie points if you:
Have some experience working with large-scale search indexing
Have performed geospatial analyses in some capacity
Have created and managed data lakes in the cloud
Culture

To explore our culture and the values we embody click here

Testimonials
Testimonial

My experience at TEAL surpassed all my expectations from the get-go. I was asked to help solve one of the most daunting problems in the Indian real estate market. Every day while working on a subset of the problem, the ideas that I brought to the table were shaped into cohesive solutions by a collaborative team effort. At TEAL I was exposed to the most cutting edge technologies such as Cloud Computing, Big Data, ML and Data Science. The growth opportunities at TEAL are tremendous, If you are innovative and can demonstrate the will to realize your ideas, TEAL is an amazing organization to work for.
Gyan Vardhan, Data Science Intern
I had interned as a Data Scientist at Terra Economics and Analytics Lab during its early days, it was a rich learning experience working with a multi-disciplinary team who are extremely passionate about building a decision support platform for the insanely complicated realty market in India. It was exciting and challenging to work on mining huge volumes of property records; extracting patterns from the data, building data pipelines and brainstorming on building the core system. TEAL offers a very healthy work environment coupled with insanely talented people working together in an exciting setting.
Naga Anjaneyulu, Data Science Intern
I worked as a full-time Data science intern at TEAL. During this period, I got an opportunity to leverage my skillsets while also learning new technologies, working on tasks assigned to me. The company operates on the latest tech-stacks and gives opportunities to learn as much as you want. The work environment is challenging, the team at TEAL is super supportive and new ideas are always welcome. It has all the good perks of a startup; creativity and innovation, casual work atmosphere and a collaborative approach to solving problems. Personally, I loved working there, my experience was fantastic!
Archana Parmar, Data Science Intern
As a second-year college student, I was looking for an internship that would allow me to delve deeper into research and work with big data, TEAL gave me the perfect opportunity to do so, enabling me to develop proficiency in research and analysis. As a research analyst intern, I collated and cleaned data and helped in the preparation of reports and presentations, and I had members helping me at every stage of this process. This collaborative environment allowed me to cultivate my skills and also learn from my peers. The holy trinity of Rohan, Kshitij, and Shreyas served as not only excellent mentors and bosses but also as friends, helping me at every stage and giving us all food and ice cream to keep us going!
Arush Mehra, Research Intern
Internships are a crucial part of one’s early career. The internship experience at TEAL was a thrilling rollercoaster ride to say the least! It was more than implementing a standard model or building an already though out concept into reality. It was about finding the solution to a unique and open-ended problem.It was exciting to work on addressing a problem with far -reaching real world applications.Moreover, the work environment had the perfect balance of casual yet professional which kept you focused and stress free at the same time. Out of every 100 startups in India only 2 of them succeed, but there are very few like TEAL India which are bound to make it big at such an early stage.
Divyanshu Agarwal, NLP Intern",4.7,"Terra Economics & Analytics Lab (TEAL)
4.7",New Delhi,"Bengaluru, India",1 to 50 employees,2018,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
1402,Senior Consultant - ModellingOps Data Engineer,"Job Title: Senior Consultant - ModellingOps Data Engineer
Location: TRIL GTC
GCL: D1

JOB DESCRIPTION:

AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. The Science & Enabling Units IT is AZs global IT capability function supporting key business areas operating out of sites across the US, UK, Sweden, India & Mexico.

We are looking for AI Ops consultant who will leverage tools & technology best practices to improve delivery performance & data engineering capabilities in the D&A space.

ROLES & RESPONSIBILITIES:

7-10 years of experience in IT Operations involving Data Science, Artificial Intelligence-Machine Learning and Predictive Analytics. Experience in architecting and implementation of end-to-end AIOPs solutions through ELK stack, Splunk. Experience in applying statistical methods, analysis, pattern recognition and modeling on IT Operational data using ELK machine learning. Experience in extracting meaning full data from incoming data streams from different sources through RegEx, Grok etc. Hands-on experience in applying machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc in the IT Operation domain. Experience with machine learning and statistical programming languages - Python, R etc. Experience in assessing the existing IT environment and providing recommendations to reduce the critical applications impacting incidents. Experience in exploring and identifying areas where manual tasks can be automated in IT environment. Experience with various Enterprise IT monitoring solutions including Infrastructure monitoring, Application Performance Monitoring, Network Monitoring, Cloud monitoring etc. Experience in IT Service Management including Service Desk, Incident Management, Change Management, CMDB etc. Excellent knowledge on various IT infrastructure components that includes Server Infrastructure, middle ware, database and application architectures and Cloud Components. Experience/knowledge on Infra monitoring tools - NOI, Zabbix, AppDynamics, Datadog, SCOM, SolarWinds etc. and Service Management tools -IBM Control Desk, BMC Remedy, ServiceNow etc. Experience/Knowledge on BI tools Knowledge on distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc. Knowledge on other programming languages/scripting: Python, Java, JavaScript, etc. ( Added Advantage ) Good analytical skills, strong communication skills are must. Client facing experience is an added advantage. Excellent experience in understanding the problem statement, architect and designing the solution

MANDATORY SKILLS:
Significant experience with AWS cloud environments, working knowledge of Google and Azure platforms. Knowledge of Kubernetes, S3, EC2, Sagemaker, Athena, RDS and Glue is essential.
Experience provisioning computational resources in a variety of Cloud environments using Infrastructure as Code.
Experience with best practice of data transport and storage within cloud system.
Experience building large scale data processing pipelines. e. g. Spark and SQL.
Experience with containers and microservice architectures e.g. Kubernetes, Docker and serverless approaches.
Excellent working knowledge in DevOps, using continuous integration and continuous development.
Use of Data Science modelling tools e.g. R, Python, SAS and Data Science notebooks (e.g. Jupyter).
Good written and verbal skills, fluent English
DESIERED SKILLS:
Agile practices, especially being a SCRUM Master
EDUCATIONAL BACKGROUND: B.E/B.Tech/MCA

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",3.9,"AstraZeneca
3.9",Chennai,"Cambridge, United Kingdom",10000+ employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Roche, GlaxoSmithKline, Novartis"
1403,DATA ENGINEER,"JOB DESCRIPTION
As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements, and also research new uses for data acquisition. You should also know the ins and outs of the industry such as data mining practices, algorithms, and how data can be used.

DESIRED CANDIDATE PROFILE
An ideal candidate must possess prior experience leading a project.

Candidates must have:
> Experience in Hive, Spark, Scala, AWS DynamoDB, HBase, AWS Glue, Talend, Kafka, Snowflake ETL
> Strong experience in a BI/Data Warehouse environment with involvement in design, development, implementation, troubleshooting and support of ETL process using ETL tool.
> Experience in developing Data Marts, Data warehousing and Operational Data Store (ODS) on any of the databases or Hadoop environments.
> Experience in database like MS SQL, MySQL, Oracle, PostgreSQL
> Good to have programming experience in writing Complex Stored Procedures, Queries, Views, User Defined Functions, Cursors and Common Table Expressions using SQL or T-SQL.
> Experience in Performance Tuning and Query Optimization by Indexing, Partitioning and De-normalization.
> Experience in Developing a framework for ingesting data into Data lake
> Good database knowledge, analytical thinking
> Design, construct, install, test and maintain data management systems.
> Build high-performance algorithms, predictive models, and prototypes.
> Develop set processes for data mining, data modeling, and data production.
> Experience with cloud services: AWS (EC2, EMR, S3, Athena) and scripting languages like Python, /PySpark/R/SAS
> Install/update disaster recovery procedures.
> Experience in Agile Application Development & Scrum methodologies is preferred
> Ability to supervise and mentor junior developers on the team.
> Must be self-motivated and work well pulling people together in addition to being able to pull people together technically
> Demonstrated proficiency of troubleshooting techniques and detail-oriented problem diagnosis
> Ability to handle responsibility, is self-directed, with strong organizational and documentation skills
> Ability to work independently and efficiently under aggressive deadlines to meet project commitments
> Excellent verbal and written communication skills

EDUCATION
UG - B.Tech/B.E. - Computers, Electronics/Telecommunication, Diploma - Computers, Electronics/Telecommunication, B.Sc - Computers, BCA - Computers) AND (PG - M.Tech - Computers, Electronics/Telecommunication, MCA - Computers, M.Sc - Electronics, Computers) AND ( Doctorate - Any Doctorate - Any Specialization, Doctorate Not Required).

OTHER DETAILS
Number of vacancies: 4
Experience: 3 years
Location: Cochin

If you have a passion towards technology and coding, then we have the right job for you. Kindly forward your resumes to
Email: jobs@mjsofttech.com
Phone: 0484-2421245 / 928 720 7160",4.0,"MJ Softtech
4.0",Kochi,"Cochin, India",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
1404,Data Engineer,"Education/ Experience and Skill Requirement
4+ years of relevant experience in
Experience working with both relational and NoSQL databases.
Strong coding skills; Python (preferred) /R/Java/Scala
Experience in developing Data warehousing technologies Experience with AWS or equivalent cloud services preferred
Experience in BigData technologies (Hadoop, HDFS, MapReduce, Spark, Hive, HBase etc) will be valuable
Knowledge of Machine Learning a big plus (Random Forest, Decision Trees, SVM, NLP, Gradient Boosting, Supervised/Unsupervised Learning, Clustering, classification and regression modeling).
Responsibilities
Proficiency with several years’ experience in more than one of Python, R, Java, Scala, or robust Linux shell scripting
Implementation experience with data warehouse architecture & design, ETL design/development, and Analytics
Knowledge of general cloud architecture and cloud strategies especially around AWS services and concepts such as S3 object stores, RDS databases, EC2, Glacier, Lambda, IAM, enterprise security, data security, DevOps, replication and disaster recovery
Well versed with data mining & exploration, NLP and visualization
Understanding of data modeling, data integration, and data representation (metadata, OWL, ontologies)
Developing data marts and data management using SQL
Creating powerful visual outcomes
Independently manage daily client communication, especially over calls
Manage client deadlines, ensure quality of the deliverables, attention to detail
Experience/understanding of corporate finance data from company filings is desirable",3.6,"Copal Partners
3.6",Bengaluru,"New York, NY",10000+ employees,1900,Company - Public,Financial Analytics & Research,Finance,₹100 to ₹500 billion (INR),-1
1405,Data Engineer,"Job Description / Responsibilities
Build workflows to ensure data extraction quality and storage into our backend data store
Architect, build and train ML/AI models that can predict outcomes and report on anomalies.
Design data pipelines to perform ETL on content/data from multiple types of source systems.
Create data analytics views using RDBMS/Key-Value stores, on private and public/cloud
Create software that is well tested, maintainable, extensible and scales out with large data

Minimum Qualifications:
2+ years of software development with Python
2+ years of SQL (MySQL/Postgres) and Key-Value databases
1+ years of experience with scikit
2+ years of experience in data extraction, data transformation using custom Python/Java
Experience working with MapReduce/Hadoop/kafka/Elastic stack
Experience with Node backend and React/Redux
Experience working with git/mercurial, Amazon/Google cloud, Linux/LAMP stack
Experience in testing or test driven development
Experience with Data science and Machine Learning algorithm development

Location:
Hyderabad/Bangalore

Package:
Highly competitive to match experience and capability",3.7,"TVS
3.7",Bengaluru,"Chennai, India",5001 to 10000 employees,-1,Company - Private,Accounting,Accounting & Legal,₹100 to ₹500 billion (INR),-1
1406,Data Engineer,"Permanent position with US based client of iFlex.
Work Location: Bangalore
Experience Level: 2+ Years

Role:
As part of our global team you will work on the data platform reporting to the Data Engineering Lead. Your role includes specification, development, test and rollout of features on our data platform. You are expected to contribute to the vision, understand our product roadmap, integrate business value andclient experience and contribute to build an engineering culture within the team. This initiative is of critical important to the success of the organization and our roadmap, for instance, services like liquidity analytics, billing, client onboarding, reporting and others will rely on the data platform. Accurate, granular, complete and timely data will be our key differentiating factor and competitive advantage in the market place. We expect the successful candidate to deliver high quality software and to be passionate about data engineering..

Responsibility / Qualification:
Managing multiple tasks and use sound judgment when prioritizing.
Collaborating with global cross functional team in building customer-centric products.
Analyzing existing software implementations to identify areas of improvement and provide deadline estimates for implementing new features.
Updating and maintain documentation for team processes, best practices and software runbooks.
Establishing trusted partnerships with peers, product heads, and executive level stakeholders.
We are looking for someone who is passionate about technology and engineering.
Exceptional analytical skills and ability to apply knowledge and experience in decision-making to arrive at creative and commercial solutions.
Ability to leverage technology to deliver business value.
You are independent and comfortable in a fast paced, ambiguous and often multi-directional work environment.

Preferred Qualifications:
B.S. or higher in Computer Science.
Minimum 2 years of relevant professional experience using a modern programming language (preferably Java/Scala).
Experience leveraging test driven development technics.
Comfort with Agile operating models.
Team oriented.
Strong interpersonal and communication skills.
Energetic, self-directed, and self-motivated.
Experience with microservice architecture.
Experience with Kafka, MongoDB, Hadoop, Cassandra.
Experience with AWS.
Experience in Financial Services or Fintech.",-1,IFLEX,Bengaluru,"Moscow, Russia",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1407,CIEL/SEL/1941: Sr data scientist,"Mandatory skills required -
Databases (SQL, Oracle, Any RDBMS) - Should have working knowledge of atleast one database
PL/SQL Programming Languages
R, Python (Any One)
Inferential Statistics - Hypothesis, p-value, R2, RMSE, MAPE etc
Exploratory Data Analysis
Machine Learning Algorithms - Should have in-depth knowledge and implementation of atleast one algorithm

Responsibilities
: Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the why & how of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions

Education
Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics
Experience
Minimum years of related experience required: 3 years
Preferred years of experience: 5 years
Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desirable.

Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
1408,Data Engineer,Data Engineer,3.6,"Bookmyshow
3.6",Mumbai,"Mumbai, India",1001 to 5000 employees,2007,Company - Private,Ticket Sales,"Arts, Entertainment & Recreation",Unknown / Non-Applicable,-1
1409,Data Analyst,"Required Skills & Experience

We are looking for a Data Analyst Executive
Eligible Qualifications : B. Tech, BCA, M.Tech, MCA
Experience : 3-5 years, fresher’s can also be considered
Location of Job : Gurgaon/Connaught Place, New Delhi
Technicals Skills

Following technical skills are pre-requisite:
Well versed with Software development methodologies, such as SDLC (Software Development Life Cycle), DDLC (Document Development Life Cycle).
Database schema design and implementation
Should have worked in either of technologies Sql Query/ Tableau/ Excel (Macros)/ Access (Query) writing for data analytics.
For planning and coordinating activities, organizations remain in invariant communication with one another and the data transfer has to be performed efficiently and smoothly as possible.
He/ She should manage the execution of the technologies, help the businesses in utilizing the systems, and should be well versed with the basics of computer systems such as Networking, Installation of necessary software and hardware.
Ability to determine the interrelationships between solutions and requirements.
Ability to think analytically and should be a problem solver and logic building should be very strong.
Good interpersonal skills to form effective working relationships with people at all levels.
Excellent communication and presentation skills and strong written & oral English skills.
To know more about us visit us www.sspl.net.in or write to us at admin@sspl.net.in",-1,Substratal Solutions,Connaught Place,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1410,Artificial Intelligence Scientists,"Experience 2- 4 Years
Salary 4 LPA - 6 LPA
Job Location Chennai

Industry:
IT-Software / Software Services

Keywords:
Artificial Intelligence

About Job:
Must have Excellent knowledge in AI / Machine learning (Mandatory).
Machine learning frameworks like keras, tensor flow etc.
And also other big data tools like Hadoop etc, Must know R and python.
Good understanding in SDLC & Business cycle.",4.0,"Careerera
4.0",Chennai,"Wayland, MA",501 to 1000 employees,-1,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
1411,Senior Data Engineer,"About Us

upGrad is an online education platform building the careers of tomorrow by offering the most industry-relevant programs in an immersive learning experience. Our mission is to create a new digital-first learning experience to deliver tangible career impact to individuals at scale. upGrad currently offers programs in Data Science, Machine Learning, Product Management, Digital Marketing, and Entrepreneurship, etc. upGrad is looking for people passionate about management and education to help design learning programs for working professionals to stay sharp and stay relevant and help build the careers of tomorrow.
upGrad was awarded the Best Tech for Education by IAMAI for 2018-19
upGrad was also ranked as one of the LinkedIn Top Startups 2018: The 25 most sought-after startups in India
upGrad was earlier selected as one of the top ten most innovative companies in India by FastCompany.
We were also covered by the Financial Times along with other disruptors in Ed-Tech
upGrad is the official education partner for Government of India - Startup India program
Our program with IIIT B has been ranked #1 program in the country in the domain of Artificial Intelligence and Machine Learning
About the Role

We are looking for a Data Engineer to help us scale the existing data infrastructure and in parallel work on building the next generation data platform for analytics at scale, machine learning infrastructure and data validation systems.
In this role, you will be responsible for communicating effectively with data consumers to fine-tune data platform systems (existing or new), taking ownership and delivering high performing systems and data pipelines, and helping the team scale them up, to endure ever growing traffic.
This is a growing team, which makes for many opportunities to be involved directly with product management, development, sales, and support teams. Everybody on the team is passionate about their work and we’re looking for similarly motivated “get stuff done” kind of people to join us!

Roles & Responsibilities
Engineer data pipelines (batch and real-time ) that aids in creation of data-driven products for our platform
Design, develop and maintain a robust and scalable data-warehouse and data lake
Work closely alongside Product managers and data-scientists to bring the various datasets together and cater to our business intelligence and analytics use-cases
Design and develop solutions using data science techniques ranging from statistics, algorithms to machine learning
Perform hands-on devops work to keep the Data platform secure and reliable
Skills Required
Bachelor's degree in Computer Science, Information Systems, or related engineering discipline
6 + years’ experience with ETL, Data Mining, Data Modeling, and working with large-scale datasets
6+ years’ experience with an object-oriented programming language such as Python, Scala, Java, etc
Extremely proficient in writing performant SQL working with large data volumes
Experience with map-reduce, Spark, Kafka, Presto, and the ecosystem.
Experience in building automated analytical systems utilizing large data sets.
Experience with designing, scaling and optimizing cloud based data warehouses (like AWS Redshift) and data lakes
Familiarity with AWS technologies preferred
Qualification – B.Tech/M.Tech/MCA(IT/Computer Science)

Years of Exp – 6-9",3.5,"upGrad Education Private Limited
3.5",Mumbai,"Mumbai, India",501 to 1000 employees,2015,Company - Private,Education Training Services,Education,₹1 to ₹5 billion (INR),"Udacity, General Assembly, Springboard"
1412,BBRC-Genomics-Associate Scientist,"JOB DESCRIPTION

Designation: Associate Scientist

Job Location: Bangalore

Department: Translational Medicine- Translational Sciences

About Syngene

Incorporated in 1993, Syngene International Ltd. is an innovation-focused global discovery, development and manufacturing organization providing integrated scientific services to the pharmaceutical, biotechnology, nutrition, animal health, consumer goods and specialty chemical industries around the world. Syngene’ s clientele includes world leaders such as Bristol-Myers Squibb, Baxter, Amgen, GSK, Merck KGaA and Herbalife. Its innovative culture is driven by the passion of its 4240- strong team of scientists who work with clients from around the world to solve their scientific problems, improve R&D productivity, speed up time to market and lower the cost of innovation .

Job Purpose:
To play a key role in TM-TS, develop an early-stage research strategy, initiate and lead discovery programs while managing ongoing programs in TM-TS. The role will work part of TMTS, and work with internal and external collaborators .

Key Responsibilities:
Experience in isolating DNA and RNA from blood, tissues and FFPE samples and cell lines. Experience with optimization of extraction protocols and for parameters like yield, input sample quantities and sample types is important.
Expertise in PCR, qPCR, cDNA/gDNA library preparation. Exposure to microarray techniques.
Proficiency in preparation of libraries for Next Generation Sequencing of transcriptome and genome, with significant experience in optimization of parameters like input RNA/DNA quantities and sample type
Experience with single cell RNA-seq will be plus.
Experience with various NGS protocols (DNA Amplicon based, hybrid capture based low input, degraded DNA and RNA samples e.g. FFPE samples.
Strong understanding of experimental design and statistical principles behind experimental design and differential gene expression. Experience with analysis of single cell RNA-sequencing data will be a plus

Educational Qualification:
M.Sc or M. Tech in Biotechnology, Molecular biology or Biological Sciences,

Technical/functional Skills:
DNA/ RNA Isolation, Expertise in PCR, qPCR, Experience in NGS protocols

Experience:
2 to 5 Years

Behavioral Skills:
A proactive team player.
Ensure completion of experiments and generate accurate and reproducible data from experiments.
Ability to work independently, prioritize tasks and work on multiple projects simultaneously with; comfortable working in a dynamic environment with changing requirements.
Good oral and written communication and presentation skills to work in a multi-disciplinary team
Equal Opportunity Employer:
It is the policy of Syngene to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by applicable legislation or local law. In addition, Syngene will provide reasonable accommodations for qualified individuals with disabilities.",3.5,"Syngene
3.5",India,"BENGALURU, India",1001 to 5000 employees,1994,Unknown,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1413,Applied Scientist 1,"Position Requirements:
Master's degree in Computer Science, Computer or Electrical Engineer, Mathematics, or a related field plus at least one year of experience in the job offered or related occupations of Software Engineer, Software Developer, or a related occupation. Employer will accept a Bachelor’s degree and five years of experience in the job offered or a related occupation as equivalent to the Master’s degree and one year of experience. One year of experience in the job offered or related occupation must involve designing and developing large-scale, multi-tiered, distributed software applications, tools, systems and services using Java, Object Oriented Design and Distributed Programming].

Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, Oracle/Berkeley databases, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills

Amazon Selling Partner Services team drives the Selling On Amazon business and develops solutions that enable millions of sellers around the world to sell on Amazon's Marketplaces. More than half of shipments for Amazon customers are generated from this business. The team is focused on building a technology platform that will support the explosive business growth in existing markets, streamline the business for Amazon and the Selling partners and launch business in new markets and establish a fair marketplace.

Our team is seeking engineers with broad technical skills to help us optimize how we synthesize massive amounts of data and complex business rules into mission critical financial information. As a member of this team you will employ object oriented techniques in Java, and DynamoB, PostGres and ElasticSearch skills to help us support Amazon's next generation of selling partner services. Along the way you'll gain and leverage a unique understanding of how Amazon.com works; from the numerous software systems that comprise the website's back-end, to the details of our business model, and the relationships we're establishing with an ever-growing network of selling partners who depend on Amazon.com to run their businesses.

The ideal candidate will draw upon exemplary analytical, critical thinking, and problem solving skills, and a passion for maintaining highly reliable, distributed systems which operate 24/7/365. Successful members of this team collaborate effectively with internal end-users, aggressive cross-functional software development teams, and technical support/sustaining engineering teams to solve problems and deliver successfully against high operational standards of system availability and reliability. We look for engineers who are excellent communicators, self-motivated, flexible, hardworking, and who like to have fun!

Position Responsibilities:
Participate in the design, development, implementation, testing and documentation of large-scale, multi-tiered, distributed software applications, tools, systems and services using [Java, Object Oriented Design and Distributed Programming]. Translate functional requirements into robust, scalable, supportable solutions that work well within the overall system architecture. Participate in the full development cycle, end-to-end, from design, implementation, and testing to documentation, delivery and maintenance. Produce comprehensive, usable software documentation. Evaluate and make decisions around the use of new or existing software products and tools.

Preferred Qualifications
Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1414,Senior Clinical Data Analyst,"About Novotech:

Novotech is internationally recognised as the leading independent and full-service contract research organisation (CRO) in the Asia Pacific region. We provide a wide range of clinical development services across all research phases and therapeutic areas and have been instrumental in the success of hundreds of Phase I – IV clinical trials throughout the Asia Pacific. Powered by the highest quality people, Novotech strives to set the benchmark for both business and clinical trial performance. Our people are one of our key strengths. We value our people and recognise the work they do. We are lucky to have the best people and talent from across the Asia Pacific region work together to deliver to clinical trial success for our clients. Our people and those we look to recruit have an attitude of making things happen. They are problem solvers, driven with a focus on delivering quality, accountability and a high level of performance.

Brief Position Description:

As part of Novotech’s Biometrics unit, the Senior Data Analyst (SDA) is responsible for all data analysis and business intelligence activities related to study related clinical and operational data. The SDA acts as primary point of contact for all data analysis matters to the study team and is responsible for the timely delivery of quality outputs following all applicable regulatory, compliance, best practice and operational procedures.

Minimum Qualifications & Experience:

Graduate in information science, data science or life science-related field, or similar. More than five years’ experience in a senior role related to data science, data analysis, clinical data management or clinical data programming in a pharmaceutical company, CRO or EDC software provider.

Responsibilities
The Senior Data Analyst (SDA) is responsible for providing technical, procedural (SOPs) and planning leadership across multiple projects assigned to the data analyst team members ensuring that they deliver in accordance with SOPs, programming best practices, and the timelines agreed within the Project Team.
Collaborate with cross-functional stakeholders to implement data science solutions to solve business needs using available technological solutions.
Scope data analysis effort for projects and project manage all data analysis activities across multiple projects for different study stakeholders.
Gather study requirements from data management for data review and external data reconciliation and provide guidance on appropriate outputs (dashboards, visualisations, listings, reports).
Extract, assess, integrate, transform data sources to provide data visualisation outputs for analytics.
Design and develop prototypes and final versions of data outputs (dashboards, reports, visualisations, listings) using Business intelligence tools and Data Visualisation tools.
Design and develop standard dashboards and content for different audiences.
Analyse, manipulate and understand data from multiple sources to present and create dashboards and reports to make business decisions.
Assist teams on best-practice for data visualisation dashboard development.
Educate teams on how to use all the features of applicable data visualisation platform in conjunction with data visualisation dashboards.
SME for the data visualisation development and assisting team members.
Identify and communicate project risks and maintain documentation within project files as appropriate
Represent data analysis group at internal / external meetings as appropriate.
Assess and implement new data analysis, BI and data visualisation processes and technologies.
Take an active role in the development of best practices, process improvement, quality control and governance related to all data analysis matters.
Provide training and mentoring to Data Analysis of team members in SOPs, software applications, and best practices.
Provide Subject Matter Expertise on all data analysis and visualisation related activities.
Attributes and Skills

Expert knowledge of clinical study data structures and schemas of EDC databases. Expert knowledge in data processing activities such as extracting, integrating, transforming and presenting data. Statistical Programming skills in Python, R or similar. Knowledge of SQL and EDC systems. Working knowledge of Spotfire, Power BI, Tableau or other data review and visualisation tool. Ability to gather business requirements from multiple stakeholders and clients and provide guidance on the use of appropriate data visualisations.

Experience mentoring and training others. Awareness of regulatory and compliance issues and understanding of the application of SOPs and Quality Control to daily activities. Excellent analytical, communication and problem-solving skills.

Opportunities and Benefits:

To deliver clinical trial and research excellence for our clients, our people are 'best in class'.

At Novotech, we seek and nurture people with exceptional talent. We are committed to providing our people with regular internal and external training, a competitive bonus structure and a supportive work environment. We are also focused on providing our people with a wide variety of career growth and development opportunities.

For more information about where your next career step at Novotech might take you, visit http://novotech-cro.com/novotech-careers",4.5,"Novotech
4.5",Bengaluru,"Sydney, Australia",501 to 1000 employees,1996,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
1415,Data Engineer,"Data Engineer Responsibilities:
Liaising with coworkers and clients to elucidate the requirements for each task.
Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed.
Reformulating existing frameworks to optimize their functioning.
Testing such structures to ensure that they are fit for use.
Preparing raw data for manipulation by Data Scientists.
Detecting and correcting errors in your work.
Ensuring that your work remains backed up and readily accessible to relevant coworkers.
Remaining up-to-date with industry standards and technological advancements that will improve the quality of your outputs.
Data Engineer Requirements:
Bachelor's degree in Data Engineering, Big Data Analytics, Computer Engineering, or related field.
Master's degree in a relevant field is advantageous.
Proven experience as a Data Engineer, Software Developer, or similar.
Expert proficiency in Python, C++, Java, R, and SQL.
Familiarity with Hadoop or suitable equivalent.
Excellent analytical and problem-solving skills.
A knack for independent and group work.
Scrupulous approach to duties.
Capacity to successfully manage a pipeline of duties with minimal supervision.
Job Type: Full-time

Salary: ₹360,000.00 to ₹870,000.00 /year

Experience:
total work: 2 years (Preferred)
Data Engineer: 1 year (Preferred)
Education:
Diploma (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,Futurious Technologies,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1416,Quantitative Analyst,"The successful candidate will be a highly analytical individual with hands on programming skills. The candidate will work closely with the research team and clients towards the ongoing development and integration of new investment strategies, models and tools on Axle

Location

Mumbai
Responsibilities

Perform daily/weekly/monthly tasks of performance and risk reporting
Develop and automate investment processes and strategies via VBA and Matlab
Develop tools to integrate trading decision systems with risk management systems
Ad hoc tasks (such as operational tasks, internal documentation tasks and preparation of marketing materials)
Skills/Experience

Excellent programming skills in Matlab/Excel-VBA
Thorough with financial concepts and calculations like Drawdown, VaR, Eloss etc.
Understanding of financial market products like options, futures, FX forwards etc.
Working knowledge of Bloomberg is preferred
Should be self-driven and detail oriented with an analytical mindset
Should be a proactive and quick learner; a team player showing enthusiasm and drive to accomplish results in a fast paced environment
Min. 2 years of relevant work experience
Qualifications

B.Tech/M.Tech/MBA/CFA/FRM",5.0,"B&B Analytics
5.0",Mumbai,"Zug, Switzerland",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1417,Analyst - Data Scientist,"Job Summary

Experience:
3 - 5 Years

Location:
Mumbai

Designation:
Analyst - Data Scientist

Degree:
BE-Comp/IT, BE-Other, BTech-Comp/IT, BTech-Other, ME-Comp/IT, ME-Other, MTech-Comp/IT, MTech-Other, PhD-Comp/IT, PhD-Other

Educational Level:
Graduate/Bachelors

Industrial Type:
IT-Software/Software Services

Functional Area:
IT Software - Application Programming / Maintenance

Key Skills:
Data Scientist

Job Post Date:
Thursday, March 19, 2020

Company Description

We are capability centre based in Mumbai, initially started as a back-office operational support to the UK business unit.

However, over the recent years, we have significantly increased the breadth and depth of our capabilities and offerings to keep pace with the changing needs of the Group. These include Digital & Knowledge Services, Finance and Actuarial, Information Technology (IT), Customer Service, Risk and Audit.

Our core purpose is to be a strategic partner to company, enabling growth by delivering change and driving synergies through a highly capable and agile workforce.

With our diversified service offerings we provide our people with exciting opportunities to grow personally and professionally.

Company is a leading savings and investments business serving around 5.5 million retail customers and more than 800 institutional clients.

It-s innovative asset management and customer solutions are supported by extensive investment capabilities, an international distribution network and two strong brands.

Job Description

3 – 5 yrs experience as Data Scientist
Should have at-least 1 end-to-end ML project experience
Very high proficiency in R or Python
Excellent in forecasting methods like simple exponential smoothing, multiplicative seasonal indexes, simple and weighted moving averages and time series forecasting methods
Exposure to with advanced deep learning techniques such as LSTM. CNN, Dense neural networks as well as neural networks design and implementation through tools like tensorflow, keras, pytorch, deepai or equivalent.
Good SQL experience",3.8,"Sampoorna Computer People
3.8",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
1418,Data Lake Developer,"For Us, It's A Mission

At Mylan, we mean it when we say we work every day to provide access to high quality medicines to the world's 7 billion people. If you are unconventional, relentless and passionate. If you believe in doing what's right, not what's easy. If you are a doer and have a passion for serving others, we want to talk to you.

Make a Difference

At Mylan, each person has the ability to make a difference. From the providers who sell and market our products, to the producers who develop and manufacture them and finally to our business partners who support the providers and producers, we all have a mission critical role. Here's how this role will help:

ESSENTIAL DUTIES AND RESPONSIBILITIES
To perform this job successfully, an individual must satisfactorily perform each essential duty. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential duties.
1. Create and maintain optimal data pipeline architecture on Azure platform.
2. Develop batch processing solutions by using Data Factory and Azure Databricks.
3. Delivering a Data Warehouse in the Azure Cloud.
4. Design relational and non-relational data stores on Azure.
5. Identify, design, and implement internal process improvements : automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc..
6. Developing Big Data Solutions with Azure Machine Learning.
7. Strong interaction with business departments to provide consultative support for digitization efforts, as well as close collaboration with the Business Technology management, focused on future innovation topics.
8. Participate and lead in design sessions, demos and prototype sessions, testing and training workshops with business users and other IT colleagues.
9. Design & Build for any API Development or SQL DB development.
10. Providing service management, orchestration, monitoring and management requirements of Azure cloud platform.
11. Create data tools / products for analytics and data scientist team members that assist them in building and innovative solutions that drive tangible business value.
12. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
13. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
14. Design security for source data access. Chose the appropriate authentication mechanism, (ie Azure Active Directory (Azure AD), etc).
15. Design for real-time processing by using Stream Analytics and Azure Databricks.

Make Our Values Your Values

Mylan hires only the best. People who thrive in a culture of innovation and empowerment. People who are active learners and have a positive attitude. People who are leaders and know that by working together we can run faster, reach higher and achieve more. By doing so, we will continue to set new standards in health care. Here are the minimum qualifications and essential functions for this position:

QUALIFICATIONS

The qualifications listed below are representative of the minimum knowledge, skill, and/or ability required.

SKILLS AND ABILITIES

1. 10 years of experience in Microsoft technologies including SQL.

2. At least 5 years as a Sr Developer with at least 3 years hands on experience as Azure Data Engineer building large scale Azure data solutions.

3. At least 5 years of experience in Azure based data solutions.

4. At least 3 years of experience on working with large projects including the most recent project in the cloud (Azure) or on prem with a focus on Azure Data services.

5. At least 5 years of Hands-on administration, configuration management, monitoring, performance tuning of Hadoop/Distributed platforms.

6. At least 5 years of demonstrated experience at least in the most recent 2 years of designing and delivering solutions using Cortana Intelligence suite of analytics services part of Microsoft Azure including Azure Machine Learning Studio, HDInsight, Polybase, Azure Data Lake Analytics, Azure Data Warehouse, Streaming Analytics, Data Catalog, R/R Studio

7. Experience in designing and building logics required for optimal extraction, transformation, and loading of data from a wide variety of data sources

8. Experience within Data Security design, including but not limited to:

a. Choosing the appropriate authentication mechanism, such as Azure Active Directory (Azure AD)

b. Defining strategies for data encryption for data at rest and in transit

9. Experience partnering with Business Analysts and Data Scientists to enable effective and efficient data preparation and delivery

10. Experienced in vendor management and working with 3rd parties onshore & offshore.

11. Experience working in a global team.

12. Experience working in an Analytics / Big Data solutions on MS Azure Cloud

13. Experience with code management tools, automated testing

14. Experience creating and maintaining optimal data pipeline architecture on Azure platform

15. Experience developing batch and real-time processing solutions by using Data Factory and Azure Databricks

16. Familiar with AGILE and Azure DevOps methodology

17. Hands on PoC capabilities are needed to prove a particular architecture concept

18. Azure Native Services experience across Data Fabric and Service Fabric

19. Experience in Application modernization from legacy on-premise data architecture platform technology stack to modernized Azure Cloud base Architecture.

20. Experience with Git, NoSQL Data Solutions, Microsoft Azure, HD Insights, Azure ML, DataBricks ML Flow, R or Python.

21. Must have excellent communication skills.

EDUCATION/EXPERIENCE (Note: Please select one)

Minimum of a Bachelor's degree in Computer Science and Engineering is preferred with minimum 10 years of experience. However, a combination of experience and/or education will be taken into consideration

Why Mylan?

If you want to be part of a global health care company that is making a difference and changing lives, Mylan may be the place for you. With a workforce of more than 35,000 worldwide, we can make a difference. We encourage you to visit Mylan.com to learn more about our unconventional culture, our approach to doing business and how we plan to set new standards in health care.

Mylan offers competitive salary, excellent benefits and an environment conducive to professional growth and advancement. All qualified applicants will receive consideration for employment without regard to their disability or protected veteran status. Mylan is an Equal Opportunity Employer, Minorities/Female/Disabled/Veteran.",3.8,"Mylan Inc.
3.8",Bengaluru,"Hatfield, United Kingdom",10000+ employees,1961,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1419,Off Campus Recruitment - Quantitative Researcher,"Description:
Graviton is a privately funded quantitative trading firm striving for excellence in financial markets' research. We are seeking fresh talent from the top IIT's to join us as Quantitative Researchers for our team in Gurgaon.If you are a student graduating in 2020 from Computer Science , Electrical or Maths Stats Computing streams with a greater than 8 CGPA please apply here.

This role is open to students from campuses that we could not visit this year. Please check your individual placement policy restrictions before applying.

Graviton trades across a multitude of asset classes and trading venues using a gamut of concepts and techniques ranging from time series analysis, filtering, classification, stochastic models, pattern recognition to statistical inference analysing terabytes of data to come up with ideas to identify pricing anomalies in financial markets.

As a Quantitative researcher your responsibilities will include

Develop new or improve existing trading models using in-house platforms

Use advanced mathematical techniques to model and predict market movements

Analyse large financial datasets to identify trading opportunities

Provide real time analytical support to experienced traders

Requirements :
Possess a degree in a highly analytical field, such as Engineering, Mathematics, Computer Science from IITs schools

Quantitative bend of mind

A working knowledge of Linux/Unix

Programming experience, preferably in C++ or C

Strong interest in learning about financial markets.

Have a strong work ethic

Hard Working

Benefits:
Our open and casual work culture gives you the space to innovate and deliver. Our cubicle free offices , disdain for bureaucracy and insistence to hire the very best creates a melting pot for great ideas and technology innovations. Everyone on the team is approachable, there is nothing better than working with friends!

Our perks have you covered.

Competitive compensation

6 weeks of paid vacation

Monthly after work parties

Catered breakfast and lunch

Fully stocked kitchen

Gym membership

International team outing",5.0,"Graviton Research Capital LLP
5.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2014,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1420,Data Engineer,"Zauba Technologies is a startup based in Bangalore. Zauba's services are used by leading companies in India. Zauba is powered by a young and passionate team. We are looking for individuals who would like to be a part of our founding team.

As a Data Engineer and as a part of founding team, you will be expected to visualise and develop disruptive data products. Eventually you would be responsible for entire project lifecycle of products you would visualize. Your rewards will be directly proportional to the value you generate.

Job Responsibilities
Design and development of robust, scalable and highly efficient data engineering solutions for structured and unstructured data (Including gathering and processing raw data at scale, writing scripts, web scraping, calling APIs, writing SQL queries, etc.)
Develop processes for text mining and extraction of information from unstructured data
Design, architect and develop efficient data pipelines around the data collected
Take ownership of existing web product and applications
Design and implement data models that scale across the enterprise
Take ownership of existing data workflows and processes
Enhance scalability, performance, and stability of existing infrastructure
Work closely with other team members to integrate your innovations and algorithms into our production systems

Essentials
Java/Python - Intermediate to advanced level
SQL - Advanced
MySQL Intermediate to advanced level
Regex - Basic to intermediate level
Linux Basic to intermediate level

Good to have
Hadoop/Spark
R
MongoDB

Must have qualities
Skills to learn new skills quickly
Desire to create disruptive products and services
Passion - not just to work in startups but to take them to next level
Above average programming aptitude
Be passionate about producing high quality engineering deliverables
Be productive working independently or collaboratively
Have an eye for building efficient processes
Be self motivated
Proactively take ownership

Interested?

Send your resume to hr@zaubacorp.com",3.8,"Zauba Corp
3.8",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 million (INR),-1
1421,Quantitative Research,"We are looking for highly trained professionals who are interested in applying advanced mathematical quantitative methods to the modeling of global financial markets. You would be joining a group made up of highly proficient individuals from various scientific disciplines. We have a spectrum of opportunities for individuals with the right scientific skills. Experience in finance is not required.

The ideal research candidate will have:
A Ph.D. in Computer Science, Mathematics, Physics, Statistics, or a related technical discipline.

A demonstrated capacity to do first-class research.

Computer programming skills.

An intense interest in applying quantitative analysis to solve difficult problems.

Send us a copy of your resume to
careers@dolatcapital.com

For internship opportunities, please send us a copy of your resume to
careers@dolatcapital.com",4.0,"Dolat Capital
4.0",Mumbai,"Mumbai, India",51 to 200 employees,1970,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1422,Data Engineer,"Bachelor’s degree in Computer Science or related field
5+ years relevant experience
5+ years experience with SQL, SQL Tuning, Oracle, OLAP, Big Data Technologies
5+ years experience developing end-to-end Business Intelligence solutions: data modeling, ETL and reporting
Experience with Java and experience with scripting languages like Perl, Python, Unix shell scripts,VBA and MS Excel
Proficiency with Linux and systems administration
Proven ability at looking at solutions in unconventional ways. Sees opportunities to innovate and can lead the way.
Top notch communication (verbal and written) and interpersonal skills to convey key insights from complex analysis in summarized business terms and an ability to effectively communicate with technical teams.
Ability to work with shifting deadlines in a fast paced environment.
Operations Finance Technology team, responsible for building technical solutions for multi-billion WW Operational Cost analytic including Inbound cost (Receiving / PO), variable Cost, fixed cost, outbound (Customer Shipments / Transportation), and Customer Service, is looking for a Data Engineer.

As a data engineer, you will get the exciting opportunity to work on very large data sets in one of the world's largest and most complex data warehouse environments. You will work closely with the business teams in analysis on various cost savings initiatives, many non-standard and unique business problems and use creative-problem solving to deliver actionable output.
You will be responsible for designing and implementing an analytical environment using third-party and in-house reporting tools, modeling metadata, building reports and dashboards. You will have an opportunity to work with leading edge technologies like Redshift, Hadoop/Hive/Pig. You will be writing scalable queries and tuning performance on queries running over billion of rows of data.

You should be analytical, have an extremely high level of customer focus and a passion for process improvement. You should be motivated self-starter that can work independently in a fast paced, ambiguous environment. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions.
Bachelors in Computer Science or related field
Practical Knowledge of Linux or Unix shell scripting
Experience in working with business customers to drive requirements analysis
Exposure to large databases, BI applications, data quality and performance tuning
Excellent written and spoken communication skills
Experience with Hadoop-based technologies such as HBase, Pig, Hive and Spark
Strong proven ability in building high-performance, highly available and scalable data solutions using Oracle and/or Hadoop-based technologies
Knowledge of data warehousing concepts.
Strong sense of ownership, urgency, and drive
Strong troubleshooting and problem solving skills
Experience with Amazon Web Services",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1423,DATA ANALYST,"posted by Mahima Gaur

2 - 5 years Delhi

Job Description
Experience in data processing
Experience in data cleaning and data tabulation activities
Strong analytical, communication and team management skills
Strong understanding of data management using SPSS and research techniques
Competency in a Tabulation software (decipher / wincross / quantum etc), Excel, Powerpoint
Ability to summarize findings, draw conclusions, and put together a presentation using Powerpoint
Role Category : Data Analyst

Employment Type : Permanent Job, Full Time",4.9,"Knowledge Excel Services.
4.9",New Delhi,"New Delhi, India",1 to 50 employees,2007,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
1424,Data Engineer,"Key skills : Python , Spark , SQL , Pyspark • AWS platform used for the work • Strong experience in SQL is mandatory • Good familiarity of AWS landscape • Good experience in collecting business requirements & design them as per requirement from customer • Should able to work independently & interact business users & technical stakeholders • Strong communication skills both oral & written. • Should work as an individual resources",3.5,"Larsen & Toubro Infotech Limited
3.5",India,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1425,Big Data Engineer,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
1426,Client Data Analyst,"At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.
What is the Client Data Analyst – Client Analytics group responsible for?
This team manages business data to ensure accurate, timely, consistent and compliant data. Their contributions deliver quality data that is easily accessible and can be trusted. Key downstream capabilities such as reporting and analytics depend on this as well as operational data access on various systems. The Data Management Team is a support function that acts as an advocate and a point of contact for Sales and Marketing data.

What are the ongoing responsibilities of an Client Data Analyst ?
Understand the data flow, key consumption and production of data as well as context within the enterprise:
Build positive relationships with teams, especially the key data consumers and analytics. Take the time to increase knowledge of how they run their business and incorporate sales data into daily work
Connect regularly with each sales office to understand current issues and challenges. Probe the business and validate against other sales offices to understand the scope and priority of the issue
Make recommendations on how data unifications and flow can be used to improve business tasks. Liaise business partners to deliver solutions (reports, processes, technology) that add value.

Provide data management subject matter expertise. Appreciate the connection and data flow between applications and other corporate systems. Be able to clearly articulate the data needs and move initiatives forward by collaborating with business partners:
Actively participate in meetings with business partners to ensure that priorities are clearly understood, information is regularly shared and that key participants are “kept in the loop”
Provide context and background on issues. Collaborate on ideas for progressing initiatives. Ensure appropriate resources are involved to take initiatives forward
Provide insights and expertise to scope statements and requirements documentation
Actively consult or participate in the user acceptance testing process (test cases, documentation, testing execution, etc.)
Ensure business needs remain aligned with overall corporate initiatives and deliver the benefits as originally intended

Monitor the integrity of data and usefulness of reports. Ensure the information available within systems is accurate and up-to-date. Proactively seek data cleansing opportunities and evolve data to better support. Document and maintain ongoing processes for reporting and data clean-up:
Partner with all key data consumers to gain a solid understanding of usage and challenges around data. Establish processes for prioritization of enhancements, especially with the analytics groups
Provide 1st level support for data issues and data maintenance for owned data
Verify and execute data loads into our internal sales systems and ensure any upstream systems accurately receive their data

Increase awareness and promote data management capabilities. Share best practices and provide coaching to local offices on how to access and incorporate output into sales tasks. Encourage IAS leaders to leverage data to make more informed, strategic decisions:
Clearly articulate the goals and core services of the data management team. Proactively promote this information within IAS and ensure business partners understand the data management role within the organization
Share best practices and provides guidance on data capabilities. Reinforces ownership and accountability for data accuracy
Seek opportunities to share the benefits of leveraging sales data to make more informed business decisions

What ideal qualifications, skills & experience would help someone to be Successful?

Knowledge, Education And Experience:
Four year bachelor’s degree required (majors of preference include: business, computer science, mathematics) Advanced degree a plus
Understanding of the Franklin Templeton business model, how FT makes money, the sales process, how technology fits in with the business, etc. Knowledge of the GAS (Global Advisory Services) structure
Experience working through multiple business fiscal cycles; exposure and/or direct experience with project management and/or sales-related-capacity required
Prior work experience related to analytics, sales, marketing and/or international a must. Level will not be granted based on years of experience but will be determined by the employee’s ability to meet each job activity as outlined the ‘typical/expected focus by level
Skills And Abilities:
Ability to communicate effectively with all levels of management; ability to tailor communication style based on audience; ability to get others to want to collaborate with you; strong facilitation skills
Excellent writing skills (for presentations, documentation, etc.)
Working knowledge of the CRM, MDM, Excel, SQL, Power BI, Tableau, Business Objects, and Microsoft Products (PPT, Power Apps, Doc, Visio)
Ability to absorb and interpret large quantities of data; apply trend analysis and knowledge of the business to develop a meaningful and digestible summary with the appropriate level of detail
Ability to take a larger problem and break down the individual components; identify how to go about solving the problem and who to involve in the process
Ability to present recommended solutions to a variety of issues and problems (solutions that are consistent with organization objectives)
Must be extremely detail-oriented (managing lists, tasks/to-dos, etc.) good with follow through on own items; good with following up with others on outstanding item

What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.

Highlights of our benefits include:

Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.",3.8,"Franklin Templeton Investments
3.8",Hyderabad,"San Mateo, CA",5001 to 10000 employees,1947,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Fidelity Investments, Vanguard"
1427,Data Analyst,"Roles and Responsibilities:
Extracting, transforming and inputting data sets from various resources. Creating predictive models, translating non-technical aspects into quantifiable tasks. Analysis and representation of output data, highlight and explain trends and patterns, error elimination, using advanced statistical methods (regression, probability distribution, clusters etc.) to provide accurate results.
Data collection, Data Mining, Report generation, Problem identification and solution formulation Market analysis and establishing trends, Strategy development and implementation

Skills:
Extremely good analytical skills.
Good working knowledge of all MS-Office products, especially Advance Excel, Word, PowerPoint, MS-access.
Statistical tools and methods.

Interested candidates can send the updated resume on satish.mehra@exelaonline.com or call on 7722028636
00-7.00 Years",2.6,"Exela Technologies
2.6",Pune,"Irving, TX",10000+ employees,2017,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"SourceHOV, BancTec, Transcentra"
1428,Data Modeler,"• Minimum 5-8 years of working experience as Data modeler.
• Data modelling experience in designing.
• Minimum 2-3 years real time experience in Erwin tool is mandatory.
• Experience in normalized modeling techniques.
• Experience in designing the Start schema.
• Experience working in ORACLE.
• Experience with database design, capacity planning, performance tuning and query optimization.
• Experience in working with Bank or Banking and Finance or Financial domain.
• Excellent communication skills with leadership quality.

Job Segment:
Database, Oracle, ERP, Technology",3.5,"LTI
3.5",Mumbai,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1429,Machine Learning Engineer,"Looking for Data Scientists with Python/R Programming skills.
Specific experience in AI areas like Statistical Machine learning / Deep learning / Natural Language Processing (NLP)/ Operations Research (Optimization) will be an advantage.Individual in this role is expected to work with multiple stakeholders and teams

Qualifications and Requirements:-
Previous working experience as a Machine Learning/ Data Scientist for 2 years
MA in Computer Science or similar relevant field
Hands on experience with MALLET
In depth knowledge of Apache Tomcat/Open Source
Excellent project and time management skills
Attention to detail
Outstanding problem solving and analytical skills",-1,Tekolutions.ai,India,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1430,Data Science Internship,"About the company:
SkillBit is a leading staffing and recruitment company engaged in talent searching assignments for skilled and talented candidates for the industry.

About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Working on data science algorithms and AI concepts 2. Using Python or R for web scraping 3. Building AI models using Python, machine learning, and deep learning algorithms 4. Processing of unstructured/structured data

Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 6th Jun'20 and 11th Jul'20
are available for duration of 1 month
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply

Number of internships/jobs available: 3

Categories: Data Science",-1,SkillBit,Pune,-1,-1,-1,-1,-1,-1,-1,-1
1431,Data Engineer,"As a data engineer at TEAL, you'll be taking the plunge into a rich data lake that includes everything from satellite data to legal court orders. You'll be hustling and getting your hands dirty with every part of the data pipeline always having an implicit appreciation for how all of this data will ultimately power a revolutionary real estate risk platform.

Your day-to-day will include either all or some of the following:

Constantly scoping out new data sources to complement existing ones
Creating and maintaining distributed web scrapers using Python, RabbitMQ and other technologies
Architecting and managing data pipelines where data flows into multiple end-points including, but not limited to, Postgres, MongoDB and Apache Solr
Documenting workflows and constantly iterating to create better data infrastructure.

We'd love it if you:
Are proficient in Python or any other object-oriented language
Have worked with large (millions to hundreds of millions of rows in a SQL database) interdisciplinary datasets
Have scraped difficult websites and have some experience working with various data APIs
Are patient and methodical with unstructured and messy data
Are always hungry to learn newer and better technologies to make the data ecosystem faster, smoother and less silo-ed

Extra brownie points if you:
Have some experience working with large-scale search indexing
Have performed geospatial analyses in some capacity
Have created and managed data lakes in the cloud
Culture

To explore our culture and the values we embody click here

Testimonials
Testimonial

My experience at TEAL surpassed all my expectations from the get-go. I was asked to help solve one of the most daunting problems in the Indian real estate market. Every day while working on a subset of the problem, the ideas that I brought to the table were shaped into cohesive solutions by a collaborative team effort. At TEAL I was exposed to the most cutting edge technologies such as Cloud Computing, Big Data, ML and Data Science. The growth opportunities at TEAL are tremendous, If you are innovative and can demonstrate the will to realize your ideas, TEAL is an amazing organization to work for.
Gyan Vardhan, Data Science Intern
I had interned as a Data Scientist at Terra Economics and Analytics Lab during its early days, it was a rich learning experience working with a multi-disciplinary team who are extremely passionate about building a decision support platform for the insanely complicated realty market in India. It was exciting and challenging to work on mining huge volumes of property records; extracting patterns from the data, building data pipelines and brainstorming on building the core system. TEAL offers a very healthy work environment coupled with insanely talented people working together in an exciting setting.
Naga Anjaneyulu, Data Science Intern
I worked as a full-time Data science intern at TEAL. During this period, I got an opportunity to leverage my skillsets while also learning new technologies, working on tasks assigned to me. The company operates on the latest tech-stacks and gives opportunities to learn as much as you want. The work environment is challenging, the team at TEAL is super supportive and new ideas are always welcome. It has all the good perks of a startup; creativity and innovation, casual work atmosphere and a collaborative approach to solving problems. Personally, I loved working there, my experience was fantastic!
Archana Parmar, Data Science Intern
As a second-year college student, I was looking for an internship that would allow me to delve deeper into research and work with big data, TEAL gave me the perfect opportunity to do so, enabling me to develop proficiency in research and analysis. As a research analyst intern, I collated and cleaned data and helped in the preparation of reports and presentations, and I had members helping me at every stage of this process. This collaborative environment allowed me to cultivate my skills and also learn from my peers. The holy trinity of Rohan, Kshitij, and Shreyas served as not only excellent mentors and bosses but also as friends, helping me at every stage and giving us all food and ice cream to keep us going!
Arush Mehra, Research Intern
Internships are a crucial part of one’s early career. The internship experience at TEAL was a thrilling rollercoaster ride to say the least! It was more than implementing a standard model or building an already though out concept into reality. It was about finding the solution to a unique and open-ended problem.It was exciting to work on addressing a problem with far -reaching real world applications.Moreover, the work environment had the perfect balance of casual yet professional which kept you focused and stress free at the same time. Out of every 100 startups in India only 2 of them succeed, but there are very few like TEAL India which are bound to make it big at such an early stage.
Divyanshu Agarwal, NLP Intern",4.7,"Terra Economics & Analytics Lab (TEAL)
4.7",New Delhi,"Bengaluru, India",1 to 50 employees,2018,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
1432,Senior Consultant - ModellingOps Data Engineer,"Job Title: Senior Consultant - ModellingOps Data Engineer
Location: TRIL GTC
GCL: D1

JOB DESCRIPTION:

AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. The Science & Enabling Units IT is AZs global IT capability function supporting key business areas operating out of sites across the US, UK, Sweden, India & Mexico.

We are looking for AI Ops consultant who will leverage tools & technology best practices to improve delivery performance & data engineering capabilities in the D&A space.

ROLES & RESPONSIBILITIES:

7-10 years of experience in IT Operations involving Data Science, Artificial Intelligence-Machine Learning and Predictive Analytics. Experience in architecting and implementation of end-to-end AIOPs solutions through ELK stack, Splunk. Experience in applying statistical methods, analysis, pattern recognition and modeling on IT Operational data using ELK machine learning. Experience in extracting meaning full data from incoming data streams from different sources through RegEx, Grok etc. Hands-on experience in applying machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc in the IT Operation domain. Experience with machine learning and statistical programming languages - Python, R etc. Experience in assessing the existing IT environment and providing recommendations to reduce the critical applications impacting incidents. Experience in exploring and identifying areas where manual tasks can be automated in IT environment. Experience with various Enterprise IT monitoring solutions including Infrastructure monitoring, Application Performance Monitoring, Network Monitoring, Cloud monitoring etc. Experience in IT Service Management including Service Desk, Incident Management, Change Management, CMDB etc. Excellent knowledge on various IT infrastructure components that includes Server Infrastructure, middle ware, database and application architectures and Cloud Components. Experience/knowledge on Infra monitoring tools - NOI, Zabbix, AppDynamics, Datadog, SCOM, SolarWinds etc. and Service Management tools -IBM Control Desk, BMC Remedy, ServiceNow etc. Experience/Knowledge on BI tools Knowledge on distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc. Knowledge on other programming languages/scripting: Python, Java, JavaScript, etc. ( Added Advantage ) Good analytical skills, strong communication skills are must. Client facing experience is an added advantage. Excellent experience in understanding the problem statement, architect and designing the solution

MANDATORY SKILLS:
Significant experience with AWS cloud environments, working knowledge of Google and Azure platforms. Knowledge of Kubernetes, S3, EC2, Sagemaker, Athena, RDS and Glue is essential.
Experience provisioning computational resources in a variety of Cloud environments using Infrastructure as Code.
Experience with best practice of data transport and storage within cloud system.
Experience building large scale data processing pipelines. e. g. Spark and SQL.
Experience with containers and microservice architectures e.g. Kubernetes, Docker and serverless approaches.
Excellent working knowledge in DevOps, using continuous integration and continuous development.
Use of Data Science modelling tools e.g. R, Python, SAS and Data Science notebooks (e.g. Jupyter).
Good written and verbal skills, fluent English
DESIERED SKILLS:
Agile practices, especially being a SCRUM Master
EDUCATIONAL BACKGROUND: B.E/B.Tech/MCA

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",3.9,"AstraZeneca
3.9",Chennai,"Cambridge, United Kingdom",10000+ employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Roche, GlaxoSmithKline, Novartis"
1433,DATA ENGINEER,"JOB DESCRIPTION
As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements, and also research new uses for data acquisition. You should also know the ins and outs of the industry such as data mining practices, algorithms, and how data can be used.

DESIRED CANDIDATE PROFILE
An ideal candidate must possess prior experience leading a project.

Candidates must have:
> Experience in Hive, Spark, Scala, AWS DynamoDB, HBase, AWS Glue, Talend, Kafka, Snowflake ETL
> Strong experience in a BI/Data Warehouse environment with involvement in design, development, implementation, troubleshooting and support of ETL process using ETL tool.
> Experience in developing Data Marts, Data warehousing and Operational Data Store (ODS) on any of the databases or Hadoop environments.
> Experience in database like MS SQL, MySQL, Oracle, PostgreSQL
> Good to have programming experience in writing Complex Stored Procedures, Queries, Views, User Defined Functions, Cursors and Common Table Expressions using SQL or T-SQL.
> Experience in Performance Tuning and Query Optimization by Indexing, Partitioning and De-normalization.
> Experience in Developing a framework for ingesting data into Data lake
> Good database knowledge, analytical thinking
> Design, construct, install, test and maintain data management systems.
> Build high-performance algorithms, predictive models, and prototypes.
> Develop set processes for data mining, data modeling, and data production.
> Experience with cloud services: AWS (EC2, EMR, S3, Athena) and scripting languages like Python, /PySpark/R/SAS
> Install/update disaster recovery procedures.
> Experience in Agile Application Development & Scrum methodologies is preferred
> Ability to supervise and mentor junior developers on the team.
> Must be self-motivated and work well pulling people together in addition to being able to pull people together technically
> Demonstrated proficiency of troubleshooting techniques and detail-oriented problem diagnosis
> Ability to handle responsibility, is self-directed, with strong organizational and documentation skills
> Ability to work independently and efficiently under aggressive deadlines to meet project commitments
> Excellent verbal and written communication skills

EDUCATION
UG - B.Tech/B.E. - Computers, Electronics/Telecommunication, Diploma - Computers, Electronics/Telecommunication, B.Sc - Computers, BCA - Computers) AND (PG - M.Tech - Computers, Electronics/Telecommunication, MCA - Computers, M.Sc - Electronics, Computers) AND ( Doctorate - Any Doctorate - Any Specialization, Doctorate Not Required).

OTHER DETAILS
Number of vacancies: 4
Experience: 3 years
Location: Cochin

If you have a passion towards technology and coding, then we have the right job for you. Kindly forward your resumes to
Email: jobs@mjsofttech.com
Phone: 0484-2421245 / 928 720 7160",4.0,"MJ Softtech
4.0",Kochi,"Cochin, India",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
1434,Data Engineer,"Education/ Experience and Skill Requirement
4+ years of relevant experience in
Experience working with both relational and NoSQL databases.
Strong coding skills; Python (preferred) /R/Java/Scala
Experience in developing Data warehousing technologies Experience with AWS or equivalent cloud services preferred
Experience in BigData technologies (Hadoop, HDFS, MapReduce, Spark, Hive, HBase etc) will be valuable
Knowledge of Machine Learning a big plus (Random Forest, Decision Trees, SVM, NLP, Gradient Boosting, Supervised/Unsupervised Learning, Clustering, classification and regression modeling).
Responsibilities
Proficiency with several years’ experience in more than one of Python, R, Java, Scala, or robust Linux shell scripting
Implementation experience with data warehouse architecture & design, ETL design/development, and Analytics
Knowledge of general cloud architecture and cloud strategies especially around AWS services and concepts such as S3 object stores, RDS databases, EC2, Glacier, Lambda, IAM, enterprise security, data security, DevOps, replication and disaster recovery
Well versed with data mining & exploration, NLP and visualization
Understanding of data modeling, data integration, and data representation (metadata, OWL, ontologies)
Developing data marts and data management using SQL
Creating powerful visual outcomes
Independently manage daily client communication, especially over calls
Manage client deadlines, ensure quality of the deliverables, attention to detail
Experience/understanding of corporate finance data from company filings is desirable",3.6,"Copal Partners
3.6",Bengaluru,"New York, NY",10000+ employees,1900,Company - Public,Financial Analytics & Research,Finance,₹100 to ₹500 billion (INR),-1
1435,Data Engineer,"Job Description / Responsibilities
Build workflows to ensure data extraction quality and storage into our backend data store
Architect, build and train ML/AI models that can predict outcomes and report on anomalies.
Design data pipelines to perform ETL on content/data from multiple types of source systems.
Create data analytics views using RDBMS/Key-Value stores, on private and public/cloud
Create software that is well tested, maintainable, extensible and scales out with large data

Minimum Qualifications:
2+ years of software development with Python
2+ years of SQL (MySQL/Postgres) and Key-Value databases
1+ years of experience with scikit
2+ years of experience in data extraction, data transformation using custom Python/Java
Experience working with MapReduce/Hadoop/kafka/Elastic stack
Experience with Node backend and React/Redux
Experience working with git/mercurial, Amazon/Google cloud, Linux/LAMP stack
Experience in testing or test driven development
Experience with Data science and Machine Learning algorithm development

Location:
Hyderabad/Bangalore

Package:
Highly competitive to match experience and capability",3.7,"TVS
3.7",Bengaluru,"Chennai, India",5001 to 10000 employees,-1,Company - Private,Accounting,Accounting & Legal,₹100 to ₹500 billion (INR),-1
1436,Data Engineer,"Permanent position with US based client of iFlex.
Work Location: Bangalore
Experience Level: 2+ Years

Role:
As part of our global team you will work on the data platform reporting to the Data Engineering Lead. Your role includes specification, development, test and rollout of features on our data platform. You are expected to contribute to the vision, understand our product roadmap, integrate business value andclient experience and contribute to build an engineering culture within the team. This initiative is of critical important to the success of the organization and our roadmap, for instance, services like liquidity analytics, billing, client onboarding, reporting and others will rely on the data platform. Accurate, granular, complete and timely data will be our key differentiating factor and competitive advantage in the market place. We expect the successful candidate to deliver high quality software and to be passionate about data engineering..

Responsibility / Qualification:
Managing multiple tasks and use sound judgment when prioritizing.
Collaborating with global cross functional team in building customer-centric products.
Analyzing existing software implementations to identify areas of improvement and provide deadline estimates for implementing new features.
Updating and maintain documentation for team processes, best practices and software runbooks.
Establishing trusted partnerships with peers, product heads, and executive level stakeholders.
We are looking for someone who is passionate about technology and engineering.
Exceptional analytical skills and ability to apply knowledge and experience in decision-making to arrive at creative and commercial solutions.
Ability to leverage technology to deliver business value.
You are independent and comfortable in a fast paced, ambiguous and often multi-directional work environment.

Preferred Qualifications:
B.S. or higher in Computer Science.
Minimum 2 years of relevant professional experience using a modern programming language (preferably Java/Scala).
Experience leveraging test driven development technics.
Comfort with Agile operating models.
Team oriented.
Strong interpersonal and communication skills.
Energetic, self-directed, and self-motivated.
Experience with microservice architecture.
Experience with Kafka, MongoDB, Hadoop, Cassandra.
Experience with AWS.
Experience in Financial Services or Fintech.",-1,IFLEX,Bengaluru,"Moscow, Russia",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1437,CIEL/SEL/1941: Sr data scientist,"Mandatory skills required -
Databases (SQL, Oracle, Any RDBMS) - Should have working knowledge of atleast one database
PL/SQL Programming Languages
R, Python (Any One)
Inferential Statistics - Hypothesis, p-value, R2, RMSE, MAPE etc
Exploratory Data Analysis
Machine Learning Algorithms - Should have in-depth knowledge and implementation of atleast one algorithm

Responsibilities
: Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the why & how of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions

Education
Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics
Experience
Minimum years of related experience required: 3 years
Preferred years of experience: 5 years
Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desirable.

Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
1438,Data Engineer,Data Engineer,3.6,"Bookmyshow
3.6",Mumbai,"Mumbai, India",1001 to 5000 employees,2007,Company - Private,Ticket Sales,"Arts, Entertainment & Recreation",Unknown / Non-Applicable,-1
1439,Data Analyst,"Required Skills & Experience

We are looking for a Data Analyst Executive
Eligible Qualifications : B. Tech, BCA, M.Tech, MCA
Experience : 3-5 years, fresher’s can also be considered
Location of Job : Gurgaon/Connaught Place, New Delhi
Technicals Skills

Following technical skills are pre-requisite:
Well versed with Software development methodologies, such as SDLC (Software Development Life Cycle), DDLC (Document Development Life Cycle).
Database schema design and implementation
Should have worked in either of technologies Sql Query/ Tableau/ Excel (Macros)/ Access (Query) writing for data analytics.
For planning and coordinating activities, organizations remain in invariant communication with one another and the data transfer has to be performed efficiently and smoothly as possible.
He/ She should manage the execution of the technologies, help the businesses in utilizing the systems, and should be well versed with the basics of computer systems such as Networking, Installation of necessary software and hardware.
Ability to determine the interrelationships between solutions and requirements.
Ability to think analytically and should be a problem solver and logic building should be very strong.
Good interpersonal skills to form effective working relationships with people at all levels.
Excellent communication and presentation skills and strong written & oral English skills.
To know more about us visit us www.sspl.net.in or write to us at admin@sspl.net.in",-1,Substratal Solutions,Connaught Place,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1440,Artificial Intelligence Scientists,"Experience 2- 4 Years
Salary 4 LPA - 6 LPA
Job Location Chennai

Industry:
IT-Software / Software Services

Keywords:
Artificial Intelligence

About Job:
Must have Excellent knowledge in AI / Machine learning (Mandatory).
Machine learning frameworks like keras, tensor flow etc.
And also other big data tools like Hadoop etc, Must know R and python.
Good understanding in SDLC & Business cycle.",4.0,"Careerera
4.0",Chennai,"Wayland, MA",501 to 1000 employees,-1,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
1441,Senior Data Engineer,"About Us

upGrad is an online education platform building the careers of tomorrow by offering the most industry-relevant programs in an immersive learning experience. Our mission is to create a new digital-first learning experience to deliver tangible career impact to individuals at scale. upGrad currently offers programs in Data Science, Machine Learning, Product Management, Digital Marketing, and Entrepreneurship, etc. upGrad is looking for people passionate about management and education to help design learning programs for working professionals to stay sharp and stay relevant and help build the careers of tomorrow.
upGrad was awarded the Best Tech for Education by IAMAI for 2018-19
upGrad was also ranked as one of the LinkedIn Top Startups 2018: The 25 most sought-after startups in India
upGrad was earlier selected as one of the top ten most innovative companies in India by FastCompany.
We were also covered by the Financial Times along with other disruptors in Ed-Tech
upGrad is the official education partner for Government of India - Startup India program
Our program with IIIT B has been ranked #1 program in the country in the domain of Artificial Intelligence and Machine Learning
About the Role

We are looking for a Data Engineer to help us scale the existing data infrastructure and in parallel work on building the next generation data platform for analytics at scale, machine learning infrastructure and data validation systems.
In this role, you will be responsible for communicating effectively with data consumers to fine-tune data platform systems (existing or new), taking ownership and delivering high performing systems and data pipelines, and helping the team scale them up, to endure ever growing traffic.
This is a growing team, which makes for many opportunities to be involved directly with product management, development, sales, and support teams. Everybody on the team is passionate about their work and we’re looking for similarly motivated “get stuff done” kind of people to join us!

Roles & Responsibilities
Engineer data pipelines (batch and real-time ) that aids in creation of data-driven products for our platform
Design, develop and maintain a robust and scalable data-warehouse and data lake
Work closely alongside Product managers and data-scientists to bring the various datasets together and cater to our business intelligence and analytics use-cases
Design and develop solutions using data science techniques ranging from statistics, algorithms to machine learning
Perform hands-on devops work to keep the Data platform secure and reliable
Skills Required
Bachelor's degree in Computer Science, Information Systems, or related engineering discipline
6 + years’ experience with ETL, Data Mining, Data Modeling, and working with large-scale datasets
6+ years’ experience with an object-oriented programming language such as Python, Scala, Java, etc
Extremely proficient in writing performant SQL working with large data volumes
Experience with map-reduce, Spark, Kafka, Presto, and the ecosystem.
Experience in building automated analytical systems utilizing large data sets.
Experience with designing, scaling and optimizing cloud based data warehouses (like AWS Redshift) and data lakes
Familiarity with AWS technologies preferred
Qualification – B.Tech/M.Tech/MCA(IT/Computer Science)

Years of Exp – 6-9",3.5,"upGrad Education Private Limited
3.5",Mumbai,"Mumbai, India",501 to 1000 employees,2015,Company - Private,Education Training Services,Education,₹1 to ₹5 billion (INR),"Udacity, General Assembly, Springboard"
1442,BBRC-Genomics-Associate Scientist,"JOB DESCRIPTION

Designation: Associate Scientist

Job Location: Bangalore

Department: Translational Medicine- Translational Sciences

About Syngene

Incorporated in 1993, Syngene International Ltd. is an innovation-focused global discovery, development and manufacturing organization providing integrated scientific services to the pharmaceutical, biotechnology, nutrition, animal health, consumer goods and specialty chemical industries around the world. Syngene’ s clientele includes world leaders such as Bristol-Myers Squibb, Baxter, Amgen, GSK, Merck KGaA and Herbalife. Its innovative culture is driven by the passion of its 4240- strong team of scientists who work with clients from around the world to solve their scientific problems, improve R&D productivity, speed up time to market and lower the cost of innovation .

Job Purpose:
To play a key role in TM-TS, develop an early-stage research strategy, initiate and lead discovery programs while managing ongoing programs in TM-TS. The role will work part of TMTS, and work with internal and external collaborators .

Key Responsibilities:
Experience in isolating DNA and RNA from blood, tissues and FFPE samples and cell lines. Experience with optimization of extraction protocols and for parameters like yield, input sample quantities and sample types is important.
Expertise in PCR, qPCR, cDNA/gDNA library preparation. Exposure to microarray techniques.
Proficiency in preparation of libraries for Next Generation Sequencing of transcriptome and genome, with significant experience in optimization of parameters like input RNA/DNA quantities and sample type
Experience with single cell RNA-seq will be plus.
Experience with various NGS protocols (DNA Amplicon based, hybrid capture based low input, degraded DNA and RNA samples e.g. FFPE samples.
Strong understanding of experimental design and statistical principles behind experimental design and differential gene expression. Experience with analysis of single cell RNA-sequencing data will be a plus

Educational Qualification:
M.Sc or M. Tech in Biotechnology, Molecular biology or Biological Sciences,

Technical/functional Skills:
DNA/ RNA Isolation, Expertise in PCR, qPCR, Experience in NGS protocols

Experience:
2 to 5 Years

Behavioral Skills:
A proactive team player.
Ensure completion of experiments and generate accurate and reproducible data from experiments.
Ability to work independently, prioritize tasks and work on multiple projects simultaneously with; comfortable working in a dynamic environment with changing requirements.
Good oral and written communication and presentation skills to work in a multi-disciplinary team
Equal Opportunity Employer:
It is the policy of Syngene to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by applicable legislation or local law. In addition, Syngene will provide reasonable accommodations for qualified individuals with disabilities.",3.5,"Syngene
3.5",India,"BENGALURU, India",1001 to 5000 employees,1994,Unknown,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1443,Applied Scientist 1,"Position Requirements:
Master's degree in Computer Science, Computer or Electrical Engineer, Mathematics, or a related field plus at least one year of experience in the job offered or related occupations of Software Engineer, Software Developer, or a related occupation. Employer will accept a Bachelor’s degree and five years of experience in the job offered or a related occupation as equivalent to the Master’s degree and one year of experience. One year of experience in the job offered or related occupation must involve designing and developing large-scale, multi-tiered, distributed software applications, tools, systems and services using Java, Object Oriented Design and Distributed Programming].

Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, Oracle/Berkeley databases, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills

Amazon Selling Partner Services team drives the Selling On Amazon business and develops solutions that enable millions of sellers around the world to sell on Amazon's Marketplaces. More than half of shipments for Amazon customers are generated from this business. The team is focused on building a technology platform that will support the explosive business growth in existing markets, streamline the business for Amazon and the Selling partners and launch business in new markets and establish a fair marketplace.

Our team is seeking engineers with broad technical skills to help us optimize how we synthesize massive amounts of data and complex business rules into mission critical financial information. As a member of this team you will employ object oriented techniques in Java, and DynamoB, PostGres and ElasticSearch skills to help us support Amazon's next generation of selling partner services. Along the way you'll gain and leverage a unique understanding of how Amazon.com works; from the numerous software systems that comprise the website's back-end, to the details of our business model, and the relationships we're establishing with an ever-growing network of selling partners who depend on Amazon.com to run their businesses.

The ideal candidate will draw upon exemplary analytical, critical thinking, and problem solving skills, and a passion for maintaining highly reliable, distributed systems which operate 24/7/365. Successful members of this team collaborate effectively with internal end-users, aggressive cross-functional software development teams, and technical support/sustaining engineering teams to solve problems and deliver successfully against high operational standards of system availability and reliability. We look for engineers who are excellent communicators, self-motivated, flexible, hardworking, and who like to have fun!

Position Responsibilities:
Participate in the design, development, implementation, testing and documentation of large-scale, multi-tiered, distributed software applications, tools, systems and services using [Java, Object Oriented Design and Distributed Programming]. Translate functional requirements into robust, scalable, supportable solutions that work well within the overall system architecture. Participate in the full development cycle, end-to-end, from design, implementation, and testing to documentation, delivery and maintenance. Produce comprehensive, usable software documentation. Evaluate and make decisions around the use of new or existing software products and tools.

Preferred Qualifications
Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1444,Senior Clinical Data Analyst,"About Novotech:

Novotech is internationally recognised as the leading independent and full-service contract research organisation (CRO) in the Asia Pacific region. We provide a wide range of clinical development services across all research phases and therapeutic areas and have been instrumental in the success of hundreds of Phase I – IV clinical trials throughout the Asia Pacific. Powered by the highest quality people, Novotech strives to set the benchmark for both business and clinical trial performance. Our people are one of our key strengths. We value our people and recognise the work they do. We are lucky to have the best people and talent from across the Asia Pacific region work together to deliver to clinical trial success for our clients. Our people and those we look to recruit have an attitude of making things happen. They are problem solvers, driven with a focus on delivering quality, accountability and a high level of performance.

Brief Position Description:

As part of Novotech’s Biometrics unit, the Senior Data Analyst (SDA) is responsible for all data analysis and business intelligence activities related to study related clinical and operational data. The SDA acts as primary point of contact for all data analysis matters to the study team and is responsible for the timely delivery of quality outputs following all applicable regulatory, compliance, best practice and operational procedures.

Minimum Qualifications & Experience:

Graduate in information science, data science or life science-related field, or similar. More than five years’ experience in a senior role related to data science, data analysis, clinical data management or clinical data programming in a pharmaceutical company, CRO or EDC software provider.

Responsibilities
The Senior Data Analyst (SDA) is responsible for providing technical, procedural (SOPs) and planning leadership across multiple projects assigned to the data analyst team members ensuring that they deliver in accordance with SOPs, programming best practices, and the timelines agreed within the Project Team.
Collaborate with cross-functional stakeholders to implement data science solutions to solve business needs using available technological solutions.
Scope data analysis effort for projects and project manage all data analysis activities across multiple projects for different study stakeholders.
Gather study requirements from data management for data review and external data reconciliation and provide guidance on appropriate outputs (dashboards, visualisations, listings, reports).
Extract, assess, integrate, transform data sources to provide data visualisation outputs for analytics.
Design and develop prototypes and final versions of data outputs (dashboards, reports, visualisations, listings) using Business intelligence tools and Data Visualisation tools.
Design and develop standard dashboards and content for different audiences.
Analyse, manipulate and understand data from multiple sources to present and create dashboards and reports to make business decisions.
Assist teams on best-practice for data visualisation dashboard development.
Educate teams on how to use all the features of applicable data visualisation platform in conjunction with data visualisation dashboards.
SME for the data visualisation development and assisting team members.
Identify and communicate project risks and maintain documentation within project files as appropriate
Represent data analysis group at internal / external meetings as appropriate.
Assess and implement new data analysis, BI and data visualisation processes and technologies.
Take an active role in the development of best practices, process improvement, quality control and governance related to all data analysis matters.
Provide training and mentoring to Data Analysis of team members in SOPs, software applications, and best practices.
Provide Subject Matter Expertise on all data analysis and visualisation related activities.
Attributes and Skills

Expert knowledge of clinical study data structures and schemas of EDC databases. Expert knowledge in data processing activities such as extracting, integrating, transforming and presenting data. Statistical Programming skills in Python, R or similar. Knowledge of SQL and EDC systems. Working knowledge of Spotfire, Power BI, Tableau or other data review and visualisation tool. Ability to gather business requirements from multiple stakeholders and clients and provide guidance on the use of appropriate data visualisations.

Experience mentoring and training others. Awareness of regulatory and compliance issues and understanding of the application of SOPs and Quality Control to daily activities. Excellent analytical, communication and problem-solving skills.

Opportunities and Benefits:

To deliver clinical trial and research excellence for our clients, our people are 'best in class'.

At Novotech, we seek and nurture people with exceptional talent. We are committed to providing our people with regular internal and external training, a competitive bonus structure and a supportive work environment. We are also focused on providing our people with a wide variety of career growth and development opportunities.

For more information about where your next career step at Novotech might take you, visit http://novotech-cro.com/novotech-careers",4.5,"Novotech
4.5",Bengaluru,"Sydney, Australia",501 to 1000 employees,1996,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
1445,Data Engineer,"Data Engineer Responsibilities:
Liaising with coworkers and clients to elucidate the requirements for each task.
Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed.
Reformulating existing frameworks to optimize their functioning.
Testing such structures to ensure that they are fit for use.
Preparing raw data for manipulation by Data Scientists.
Detecting and correcting errors in your work.
Ensuring that your work remains backed up and readily accessible to relevant coworkers.
Remaining up-to-date with industry standards and technological advancements that will improve the quality of your outputs.
Data Engineer Requirements:
Bachelor's degree in Data Engineering, Big Data Analytics, Computer Engineering, or related field.
Master's degree in a relevant field is advantageous.
Proven experience as a Data Engineer, Software Developer, or similar.
Expert proficiency in Python, C++, Java, R, and SQL.
Familiarity with Hadoop or suitable equivalent.
Excellent analytical and problem-solving skills.
A knack for independent and group work.
Scrupulous approach to duties.
Capacity to successfully manage a pipeline of duties with minimal supervision.
Job Type: Full-time

Salary: ₹360,000.00 to ₹870,000.00 /year

Experience:
total work: 2 years (Preferred)
Data Engineer: 1 year (Preferred)
Education:
Diploma (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,Futurious Technologies,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1446,Quantitative Analyst,"The successful candidate will be a highly analytical individual with hands on programming skills. The candidate will work closely with the research team and clients towards the ongoing development and integration of new investment strategies, models and tools on Axle

Location

Mumbai
Responsibilities

Perform daily/weekly/monthly tasks of performance and risk reporting
Develop and automate investment processes and strategies via VBA and Matlab
Develop tools to integrate trading decision systems with risk management systems
Ad hoc tasks (such as operational tasks, internal documentation tasks and preparation of marketing materials)
Skills/Experience

Excellent programming skills in Matlab/Excel-VBA
Thorough with financial concepts and calculations like Drawdown, VaR, Eloss etc.
Understanding of financial market products like options, futures, FX forwards etc.
Working knowledge of Bloomberg is preferred
Should be self-driven and detail oriented with an analytical mindset
Should be a proactive and quick learner; a team player showing enthusiasm and drive to accomplish results in a fast paced environment
Min. 2 years of relevant work experience
Qualifications

B.Tech/M.Tech/MBA/CFA/FRM",5.0,"B&B Analytics
5.0",Mumbai,"Zug, Switzerland",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1447,Analyst - Data Scientist,"Job Summary

Experience:
3 - 5 Years

Location:
Mumbai

Designation:
Analyst - Data Scientist

Degree:
BE-Comp/IT, BE-Other, BTech-Comp/IT, BTech-Other, ME-Comp/IT, ME-Other, MTech-Comp/IT, MTech-Other, PhD-Comp/IT, PhD-Other

Educational Level:
Graduate/Bachelors

Industrial Type:
IT-Software/Software Services

Functional Area:
IT Software - Application Programming / Maintenance

Key Skills:
Data Scientist

Job Post Date:
Thursday, March 19, 2020

Company Description

We are capability centre based in Mumbai, initially started as a back-office operational support to the UK business unit.

However, over the recent years, we have significantly increased the breadth and depth of our capabilities and offerings to keep pace with the changing needs of the Group. These include Digital & Knowledge Services, Finance and Actuarial, Information Technology (IT), Customer Service, Risk and Audit.

Our core purpose is to be a strategic partner to company, enabling growth by delivering change and driving synergies through a highly capable and agile workforce.

With our diversified service offerings we provide our people with exciting opportunities to grow personally and professionally.

Company is a leading savings and investments business serving around 5.5 million retail customers and more than 800 institutional clients.

It-s innovative asset management and customer solutions are supported by extensive investment capabilities, an international distribution network and two strong brands.

Job Description

3 – 5 yrs experience as Data Scientist
Should have at-least 1 end-to-end ML project experience
Very high proficiency in R or Python
Excellent in forecasting methods like simple exponential smoothing, multiplicative seasonal indexes, simple and weighted moving averages and time series forecasting methods
Exposure to with advanced deep learning techniques such as LSTM. CNN, Dense neural networks as well as neural networks design and implementation through tools like tensorflow, keras, pytorch, deepai or equivalent.
Good SQL experience",3.8,"Sampoorna Computer People
3.8",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
1448,Data Lake Developer,"For Us, It's A Mission

At Mylan, we mean it when we say we work every day to provide access to high quality medicines to the world's 7 billion people. If you are unconventional, relentless and passionate. If you believe in doing what's right, not what's easy. If you are a doer and have a passion for serving others, we want to talk to you.

Make a Difference

At Mylan, each person has the ability to make a difference. From the providers who sell and market our products, to the producers who develop and manufacture them and finally to our business partners who support the providers and producers, we all have a mission critical role. Here's how this role will help:

ESSENTIAL DUTIES AND RESPONSIBILITIES
To perform this job successfully, an individual must satisfactorily perform each essential duty. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential duties.
1. Create and maintain optimal data pipeline architecture on Azure platform.
2. Develop batch processing solutions by using Data Factory and Azure Databricks.
3. Delivering a Data Warehouse in the Azure Cloud.
4. Design relational and non-relational data stores on Azure.
5. Identify, design, and implement internal process improvements : automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc..
6. Developing Big Data Solutions with Azure Machine Learning.
7. Strong interaction with business departments to provide consultative support for digitization efforts, as well as close collaboration with the Business Technology management, focused on future innovation topics.
8. Participate and lead in design sessions, demos and prototype sessions, testing and training workshops with business users and other IT colleagues.
9. Design & Build for any API Development or SQL DB development.
10. Providing service management, orchestration, monitoring and management requirements of Azure cloud platform.
11. Create data tools / products for analytics and data scientist team members that assist them in building and innovative solutions that drive tangible business value.
12. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
13. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
14. Design security for source data access. Chose the appropriate authentication mechanism, (ie Azure Active Directory (Azure AD), etc).
15. Design for real-time processing by using Stream Analytics and Azure Databricks.

Make Our Values Your Values

Mylan hires only the best. People who thrive in a culture of innovation and empowerment. People who are active learners and have a positive attitude. People who are leaders and know that by working together we can run faster, reach higher and achieve more. By doing so, we will continue to set new standards in health care. Here are the minimum qualifications and essential functions for this position:

QUALIFICATIONS

The qualifications listed below are representative of the minimum knowledge, skill, and/or ability required.

SKILLS AND ABILITIES

1. 10 years of experience in Microsoft technologies including SQL.

2. At least 5 years as a Sr Developer with at least 3 years hands on experience as Azure Data Engineer building large scale Azure data solutions.

3. At least 5 years of experience in Azure based data solutions.

4. At least 3 years of experience on working with large projects including the most recent project in the cloud (Azure) or on prem with a focus on Azure Data services.

5. At least 5 years of Hands-on administration, configuration management, monitoring, performance tuning of Hadoop/Distributed platforms.

6. At least 5 years of demonstrated experience at least in the most recent 2 years of designing and delivering solutions using Cortana Intelligence suite of analytics services part of Microsoft Azure including Azure Machine Learning Studio, HDInsight, Polybase, Azure Data Lake Analytics, Azure Data Warehouse, Streaming Analytics, Data Catalog, R/R Studio

7. Experience in designing and building logics required for optimal extraction, transformation, and loading of data from a wide variety of data sources

8. Experience within Data Security design, including but not limited to:

a. Choosing the appropriate authentication mechanism, such as Azure Active Directory (Azure AD)

b. Defining strategies for data encryption for data at rest and in transit

9. Experience partnering with Business Analysts and Data Scientists to enable effective and efficient data preparation and delivery

10. Experienced in vendor management and working with 3rd parties onshore & offshore.

11. Experience working in a global team.

12. Experience working in an Analytics / Big Data solutions on MS Azure Cloud

13. Experience with code management tools, automated testing

14. Experience creating and maintaining optimal data pipeline architecture on Azure platform

15. Experience developing batch and real-time processing solutions by using Data Factory and Azure Databricks

16. Familiar with AGILE and Azure DevOps methodology

17. Hands on PoC capabilities are needed to prove a particular architecture concept

18. Azure Native Services experience across Data Fabric and Service Fabric

19. Experience in Application modernization from legacy on-premise data architecture platform technology stack to modernized Azure Cloud base Architecture.

20. Experience with Git, NoSQL Data Solutions, Microsoft Azure, HD Insights, Azure ML, DataBricks ML Flow, R or Python.

21. Must have excellent communication skills.

EDUCATION/EXPERIENCE (Note: Please select one)

Minimum of a Bachelor's degree in Computer Science and Engineering is preferred with minimum 10 years of experience. However, a combination of experience and/or education will be taken into consideration

Why Mylan?

If you want to be part of a global health care company that is making a difference and changing lives, Mylan may be the place for you. With a workforce of more than 35,000 worldwide, we can make a difference. We encourage you to visit Mylan.com to learn more about our unconventional culture, our approach to doing business and how we plan to set new standards in health care.

Mylan offers competitive salary, excellent benefits and an environment conducive to professional growth and advancement. All qualified applicants will receive consideration for employment without regard to their disability or protected veteran status. Mylan is an Equal Opportunity Employer, Minorities/Female/Disabled/Veteran.",3.8,"Mylan Inc.
3.8",Bengaluru,"Hatfield, United Kingdom",10000+ employees,1961,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1449,Off Campus Recruitment - Quantitative Researcher,"Description:
Graviton is a privately funded quantitative trading firm striving for excellence in financial markets' research. We are seeking fresh talent from the top IIT's to join us as Quantitative Researchers for our team in Gurgaon.If you are a student graduating in 2020 from Computer Science , Electrical or Maths Stats Computing streams with a greater than 8 CGPA please apply here.

This role is open to students from campuses that we could not visit this year. Please check your individual placement policy restrictions before applying.

Graviton trades across a multitude of asset classes and trading venues using a gamut of concepts and techniques ranging from time series analysis, filtering, classification, stochastic models, pattern recognition to statistical inference analysing terabytes of data to come up with ideas to identify pricing anomalies in financial markets.

As a Quantitative researcher your responsibilities will include

Develop new or improve existing trading models using in-house platforms

Use advanced mathematical techniques to model and predict market movements

Analyse large financial datasets to identify trading opportunities

Provide real time analytical support to experienced traders

Requirements :
Possess a degree in a highly analytical field, such as Engineering, Mathematics, Computer Science from IITs schools

Quantitative bend of mind

A working knowledge of Linux/Unix

Programming experience, preferably in C++ or C

Strong interest in learning about financial markets.

Have a strong work ethic

Hard Working

Benefits:
Our open and casual work culture gives you the space to innovate and deliver. Our cubicle free offices , disdain for bureaucracy and insistence to hire the very best creates a melting pot for great ideas and technology innovations. Everyone on the team is approachable, there is nothing better than working with friends!

Our perks have you covered.

Competitive compensation

6 weeks of paid vacation

Monthly after work parties

Catered breakfast and lunch

Fully stocked kitchen

Gym membership

International team outing",5.0,"Graviton Research Capital LLP
5.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2014,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1450,Data Engineer,"Zauba Technologies is a startup based in Bangalore. Zauba's services are used by leading companies in India. Zauba is powered by a young and passionate team. We are looking for individuals who would like to be a part of our founding team.

As a Data Engineer and as a part of founding team, you will be expected to visualise and develop disruptive data products. Eventually you would be responsible for entire project lifecycle of products you would visualize. Your rewards will be directly proportional to the value you generate.

Job Responsibilities
Design and development of robust, scalable and highly efficient data engineering solutions for structured and unstructured data (Including gathering and processing raw data at scale, writing scripts, web scraping, calling APIs, writing SQL queries, etc.)
Develop processes for text mining and extraction of information from unstructured data
Design, architect and develop efficient data pipelines around the data collected
Take ownership of existing web product and applications
Design and implement data models that scale across the enterprise
Take ownership of existing data workflows and processes
Enhance scalability, performance, and stability of existing infrastructure
Work closely with other team members to integrate your innovations and algorithms into our production systems

Essentials
Java/Python - Intermediate to advanced level
SQL - Advanced
MySQL Intermediate to advanced level
Regex - Basic to intermediate level
Linux Basic to intermediate level

Good to have
Hadoop/Spark
R
MongoDB

Must have qualities
Skills to learn new skills quickly
Desire to create disruptive products and services
Passion - not just to work in startups but to take them to next level
Above average programming aptitude
Be passionate about producing high quality engineering deliverables
Be productive working independently or collaboratively
Have an eye for building efficient processes
Be self motivated
Proactively take ownership

Interested?

Send your resume to hr@zaubacorp.com",3.8,"Zauba Corp
3.8",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 million (INR),-1
1451,Quantitative Research,"We are looking for highly trained professionals who are interested in applying advanced mathematical quantitative methods to the modeling of global financial markets. You would be joining a group made up of highly proficient individuals from various scientific disciplines. We have a spectrum of opportunities for individuals with the right scientific skills. Experience in finance is not required.

The ideal research candidate will have:
A Ph.D. in Computer Science, Mathematics, Physics, Statistics, or a related technical discipline.

A demonstrated capacity to do first-class research.

Computer programming skills.

An intense interest in applying quantitative analysis to solve difficult problems.

Send us a copy of your resume to
careers@dolatcapital.com

For internship opportunities, please send us a copy of your resume to
careers@dolatcapital.com",4.0,"Dolat Capital
4.0",Mumbai,"Mumbai, India",51 to 200 employees,1970,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1452,Data Engineer,"Bachelor’s degree in Computer Science or related field
5+ years relevant experience
5+ years experience with SQL, SQL Tuning, Oracle, OLAP, Big Data Technologies
5+ years experience developing end-to-end Business Intelligence solutions: data modeling, ETL and reporting
Experience with Java and experience with scripting languages like Perl, Python, Unix shell scripts,VBA and MS Excel
Proficiency with Linux and systems administration
Proven ability at looking at solutions in unconventional ways. Sees opportunities to innovate and can lead the way.
Top notch communication (verbal and written) and interpersonal skills to convey key insights from complex analysis in summarized business terms and an ability to effectively communicate with technical teams.
Ability to work with shifting deadlines in a fast paced environment.
Operations Finance Technology team, responsible for building technical solutions for multi-billion WW Operational Cost analytic including Inbound cost (Receiving / PO), variable Cost, fixed cost, outbound (Customer Shipments / Transportation), and Customer Service, is looking for a Data Engineer.

As a data engineer, you will get the exciting opportunity to work on very large data sets in one of the world's largest and most complex data warehouse environments. You will work closely with the business teams in analysis on various cost savings initiatives, many non-standard and unique business problems and use creative-problem solving to deliver actionable output.
You will be responsible for designing and implementing an analytical environment using third-party and in-house reporting tools, modeling metadata, building reports and dashboards. You will have an opportunity to work with leading edge technologies like Redshift, Hadoop/Hive/Pig. You will be writing scalable queries and tuning performance on queries running over billion of rows of data.

You should be analytical, have an extremely high level of customer focus and a passion for process improvement. You should be motivated self-starter that can work independently in a fast paced, ambiguous environment. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions.
Bachelors in Computer Science or related field
Practical Knowledge of Linux or Unix shell scripting
Experience in working with business customers to drive requirements analysis
Exposure to large databases, BI applications, data quality and performance tuning
Excellent written and spoken communication skills
Experience with Hadoop-based technologies such as HBase, Pig, Hive and Spark
Strong proven ability in building high-performance, highly available and scalable data solutions using Oracle and/or Hadoop-based technologies
Knowledge of data warehousing concepts.
Strong sense of ownership, urgency, and drive
Strong troubleshooting and problem solving skills
Experience with Amazon Web Services",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1453,DATA ANALYST,"posted by Mahima Gaur

2 - 5 years Delhi

Job Description
Experience in data processing
Experience in data cleaning and data tabulation activities
Strong analytical, communication and team management skills
Strong understanding of data management using SPSS and research techniques
Competency in a Tabulation software (decipher / wincross / quantum etc), Excel, Powerpoint
Ability to summarize findings, draw conclusions, and put together a presentation using Powerpoint
Role Category : Data Analyst

Employment Type : Permanent Job, Full Time",4.9,"Knowledge Excel Services.
4.9",New Delhi,"New Delhi, India",1 to 50 employees,2007,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
1454,Data Engineer,"Key skills : Python , Spark , SQL , Pyspark • AWS platform used for the work • Strong experience in SQL is mandatory • Good familiarity of AWS landscape • Good experience in collecting business requirements & design them as per requirement from customer • Should able to work independently & interact business users & technical stakeholders • Strong communication skills both oral & written. • Should work as an individual resources",3.5,"Larsen & Toubro Infotech Limited
3.5",India,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1455,Big Data Engineer,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
1456,Client Data Analyst,"At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.
What is the Client Data Analyst – Client Analytics group responsible for?
This team manages business data to ensure accurate, timely, consistent and compliant data. Their contributions deliver quality data that is easily accessible and can be trusted. Key downstream capabilities such as reporting and analytics depend on this as well as operational data access on various systems. The Data Management Team is a support function that acts as an advocate and a point of contact for Sales and Marketing data.

What are the ongoing responsibilities of an Client Data Analyst ?
Understand the data flow, key consumption and production of data as well as context within the enterprise:
Build positive relationships with teams, especially the key data consumers and analytics. Take the time to increase knowledge of how they run their business and incorporate sales data into daily work
Connect regularly with each sales office to understand current issues and challenges. Probe the business and validate against other sales offices to understand the scope and priority of the issue
Make recommendations on how data unifications and flow can be used to improve business tasks. Liaise business partners to deliver solutions (reports, processes, technology) that add value.

Provide data management subject matter expertise. Appreciate the connection and data flow between applications and other corporate systems. Be able to clearly articulate the data needs and move initiatives forward by collaborating with business partners:
Actively participate in meetings with business partners to ensure that priorities are clearly understood, information is regularly shared and that key participants are “kept in the loop”
Provide context and background on issues. Collaborate on ideas for progressing initiatives. Ensure appropriate resources are involved to take initiatives forward
Provide insights and expertise to scope statements and requirements documentation
Actively consult or participate in the user acceptance testing process (test cases, documentation, testing execution, etc.)
Ensure business needs remain aligned with overall corporate initiatives and deliver the benefits as originally intended

Monitor the integrity of data and usefulness of reports. Ensure the information available within systems is accurate and up-to-date. Proactively seek data cleansing opportunities and evolve data to better support. Document and maintain ongoing processes for reporting and data clean-up:
Partner with all key data consumers to gain a solid understanding of usage and challenges around data. Establish processes for prioritization of enhancements, especially with the analytics groups
Provide 1st level support for data issues and data maintenance for owned data
Verify and execute data loads into our internal sales systems and ensure any upstream systems accurately receive their data

Increase awareness and promote data management capabilities. Share best practices and provide coaching to local offices on how to access and incorporate output into sales tasks. Encourage IAS leaders to leverage data to make more informed, strategic decisions:
Clearly articulate the goals and core services of the data management team. Proactively promote this information within IAS and ensure business partners understand the data management role within the organization
Share best practices and provides guidance on data capabilities. Reinforces ownership and accountability for data accuracy
Seek opportunities to share the benefits of leveraging sales data to make more informed business decisions

What ideal qualifications, skills & experience would help someone to be Successful?

Knowledge, Education And Experience:
Four year bachelor’s degree required (majors of preference include: business, computer science, mathematics) Advanced degree a plus
Understanding of the Franklin Templeton business model, how FT makes money, the sales process, how technology fits in with the business, etc. Knowledge of the GAS (Global Advisory Services) structure
Experience working through multiple business fiscal cycles; exposure and/or direct experience with project management and/or sales-related-capacity required
Prior work experience related to analytics, sales, marketing and/or international a must. Level will not be granted based on years of experience but will be determined by the employee’s ability to meet each job activity as outlined the ‘typical/expected focus by level
Skills And Abilities:
Ability to communicate effectively with all levels of management; ability to tailor communication style based on audience; ability to get others to want to collaborate with you; strong facilitation skills
Excellent writing skills (for presentations, documentation, etc.)
Working knowledge of the CRM, MDM, Excel, SQL, Power BI, Tableau, Business Objects, and Microsoft Products (PPT, Power Apps, Doc, Visio)
Ability to absorb and interpret large quantities of data; apply trend analysis and knowledge of the business to develop a meaningful and digestible summary with the appropriate level of detail
Ability to take a larger problem and break down the individual components; identify how to go about solving the problem and who to involve in the process
Ability to present recommended solutions to a variety of issues and problems (solutions that are consistent with organization objectives)
Must be extremely detail-oriented (managing lists, tasks/to-dos, etc.) good with follow through on own items; good with following up with others on outstanding item

What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.

Highlights of our benefits include:

Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.",3.8,"Franklin Templeton Investments
3.8",Hyderabad,"San Mateo, CA",5001 to 10000 employees,1947,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Fidelity Investments, Vanguard"
1457,Data Analyst,"Roles and Responsibilities:
Extracting, transforming and inputting data sets from various resources. Creating predictive models, translating non-technical aspects into quantifiable tasks. Analysis and representation of output data, highlight and explain trends and patterns, error elimination, using advanced statistical methods (regression, probability distribution, clusters etc.) to provide accurate results.
Data collection, Data Mining, Report generation, Problem identification and solution formulation Market analysis and establishing trends, Strategy development and implementation

Skills:
Extremely good analytical skills.
Good working knowledge of all MS-Office products, especially Advance Excel, Word, PowerPoint, MS-access.
Statistical tools and methods.

Interested candidates can send the updated resume on satish.mehra@exelaonline.com or call on 7722028636
00-7.00 Years",2.6,"Exela Technologies
2.6",Pune,"Irving, TX",10000+ employees,2017,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"SourceHOV, BancTec, Transcentra"
1458,Data Modeler,"• Minimum 5-8 years of working experience as Data modeler.
• Data modelling experience in designing.
• Minimum 2-3 years real time experience in Erwin tool is mandatory.
• Experience in normalized modeling techniques.
• Experience in designing the Start schema.
• Experience working in ORACLE.
• Experience with database design, capacity planning, performance tuning and query optimization.
• Experience in working with Bank or Banking and Finance or Financial domain.
• Excellent communication skills with leadership quality.

Job Segment:
Database, Oracle, ERP, Technology",3.5,"LTI
3.5",Mumbai,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1459,Machine Learning Engineer,"Looking for Data Scientists with Python/R Programming skills.
Specific experience in AI areas like Statistical Machine learning / Deep learning / Natural Language Processing (NLP)/ Operations Research (Optimization) will be an advantage.Individual in this role is expected to work with multiple stakeholders and teams

Qualifications and Requirements:-
Previous working experience as a Machine Learning/ Data Scientist for 2 years
MA in Computer Science or similar relevant field
Hands on experience with MALLET
In depth knowledge of Apache Tomcat/Open Source
Excellent project and time management skills
Attention to detail
Outstanding problem solving and analytical skills",-1,Tekolutions.ai,India,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1460,Data Science Internship,"About the company:
SkillBit is a leading staffing and recruitment company engaged in talent searching assignments for skilled and talented candidates for the industry.

About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Working on data science algorithms and AI concepts 2. Using Python or R for web scraping 3. Building AI models using Python, machine learning, and deep learning algorithms 4. Processing of unstructured/structured data

Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 6th Jun'20 and 11th Jul'20
are available for duration of 1 month
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply

Number of internships/jobs available: 3

Categories: Data Science",-1,SkillBit,Pune,-1,-1,-1,-1,-1,-1,-1,-1
1461,Data Engineer,"As a data engineer at TEAL, you'll be taking the plunge into a rich data lake that includes everything from satellite data to legal court orders. You'll be hustling and getting your hands dirty with every part of the data pipeline always having an implicit appreciation for how all of this data will ultimately power a revolutionary real estate risk platform.

Your day-to-day will include either all or some of the following:

Constantly scoping out new data sources to complement existing ones
Creating and maintaining distributed web scrapers using Python, RabbitMQ and other technologies
Architecting and managing data pipelines where data flows into multiple end-points including, but not limited to, Postgres, MongoDB and Apache Solr
Documenting workflows and constantly iterating to create better data infrastructure.

We'd love it if you:
Are proficient in Python or any other object-oriented language
Have worked with large (millions to hundreds of millions of rows in a SQL database) interdisciplinary datasets
Have scraped difficult websites and have some experience working with various data APIs
Are patient and methodical with unstructured and messy data
Are always hungry to learn newer and better technologies to make the data ecosystem faster, smoother and less silo-ed

Extra brownie points if you:
Have some experience working with large-scale search indexing
Have performed geospatial analyses in some capacity
Have created and managed data lakes in the cloud
Culture

To explore our culture and the values we embody click here

Testimonials
Testimonial

My experience at TEAL surpassed all my expectations from the get-go. I was asked to help solve one of the most daunting problems in the Indian real estate market. Every day while working on a subset of the problem, the ideas that I brought to the table were shaped into cohesive solutions by a collaborative team effort. At TEAL I was exposed to the most cutting edge technologies such as Cloud Computing, Big Data, ML and Data Science. The growth opportunities at TEAL are tremendous, If you are innovative and can demonstrate the will to realize your ideas, TEAL is an amazing organization to work for.
Gyan Vardhan, Data Science Intern
I had interned as a Data Scientist at Terra Economics and Analytics Lab during its early days, it was a rich learning experience working with a multi-disciplinary team who are extremely passionate about building a decision support platform for the insanely complicated realty market in India. It was exciting and challenging to work on mining huge volumes of property records; extracting patterns from the data, building data pipelines and brainstorming on building the core system. TEAL offers a very healthy work environment coupled with insanely talented people working together in an exciting setting.
Naga Anjaneyulu, Data Science Intern
I worked as a full-time Data science intern at TEAL. During this period, I got an opportunity to leverage my skillsets while also learning new technologies, working on tasks assigned to me. The company operates on the latest tech-stacks and gives opportunities to learn as much as you want. The work environment is challenging, the team at TEAL is super supportive and new ideas are always welcome. It has all the good perks of a startup; creativity and innovation, casual work atmosphere and a collaborative approach to solving problems. Personally, I loved working there, my experience was fantastic!
Archana Parmar, Data Science Intern
As a second-year college student, I was looking for an internship that would allow me to delve deeper into research and work with big data, TEAL gave me the perfect opportunity to do so, enabling me to develop proficiency in research and analysis. As a research analyst intern, I collated and cleaned data and helped in the preparation of reports and presentations, and I had members helping me at every stage of this process. This collaborative environment allowed me to cultivate my skills and also learn from my peers. The holy trinity of Rohan, Kshitij, and Shreyas served as not only excellent mentors and bosses but also as friends, helping me at every stage and giving us all food and ice cream to keep us going!
Arush Mehra, Research Intern
Internships are a crucial part of one’s early career. The internship experience at TEAL was a thrilling rollercoaster ride to say the least! It was more than implementing a standard model or building an already though out concept into reality. It was about finding the solution to a unique and open-ended problem.It was exciting to work on addressing a problem with far -reaching real world applications.Moreover, the work environment had the perfect balance of casual yet professional which kept you focused and stress free at the same time. Out of every 100 startups in India only 2 of them succeed, but there are very few like TEAL India which are bound to make it big at such an early stage.
Divyanshu Agarwal, NLP Intern",4.7,"Terra Economics & Analytics Lab (TEAL)
4.7",New Delhi,"Bengaluru, India",1 to 50 employees,2018,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
1462,Senior Consultant - ModellingOps Data Engineer,"Job Title: Senior Consultant - ModellingOps Data Engineer
Location: TRIL GTC
GCL: D1

JOB DESCRIPTION:

AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. The Science & Enabling Units IT is AZs global IT capability function supporting key business areas operating out of sites across the US, UK, Sweden, India & Mexico.

We are looking for AI Ops consultant who will leverage tools & technology best practices to improve delivery performance & data engineering capabilities in the D&A space.

ROLES & RESPONSIBILITIES:

7-10 years of experience in IT Operations involving Data Science, Artificial Intelligence-Machine Learning and Predictive Analytics. Experience in architecting and implementation of end-to-end AIOPs solutions through ELK stack, Splunk. Experience in applying statistical methods, analysis, pattern recognition and modeling on IT Operational data using ELK machine learning. Experience in extracting meaning full data from incoming data streams from different sources through RegEx, Grok etc. Hands-on experience in applying machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc in the IT Operation domain. Experience with machine learning and statistical programming languages - Python, R etc. Experience in assessing the existing IT environment and providing recommendations to reduce the critical applications impacting incidents. Experience in exploring and identifying areas where manual tasks can be automated in IT environment. Experience with various Enterprise IT monitoring solutions including Infrastructure monitoring, Application Performance Monitoring, Network Monitoring, Cloud monitoring etc. Experience in IT Service Management including Service Desk, Incident Management, Change Management, CMDB etc. Excellent knowledge on various IT infrastructure components that includes Server Infrastructure, middle ware, database and application architectures and Cloud Components. Experience/knowledge on Infra monitoring tools - NOI, Zabbix, AppDynamics, Datadog, SCOM, SolarWinds etc. and Service Management tools -IBM Control Desk, BMC Remedy, ServiceNow etc. Experience/Knowledge on BI tools Knowledge on distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc. Knowledge on other programming languages/scripting: Python, Java, JavaScript, etc. ( Added Advantage ) Good analytical skills, strong communication skills are must. Client facing experience is an added advantage. Excellent experience in understanding the problem statement, architect and designing the solution

MANDATORY SKILLS:
Significant experience with AWS cloud environments, working knowledge of Google and Azure platforms. Knowledge of Kubernetes, S3, EC2, Sagemaker, Athena, RDS and Glue is essential.
Experience provisioning computational resources in a variety of Cloud environments using Infrastructure as Code.
Experience with best practice of data transport and storage within cloud system.
Experience building large scale data processing pipelines. e. g. Spark and SQL.
Experience with containers and microservice architectures e.g. Kubernetes, Docker and serverless approaches.
Excellent working knowledge in DevOps, using continuous integration and continuous development.
Use of Data Science modelling tools e.g. R, Python, SAS and Data Science notebooks (e.g. Jupyter).
Good written and verbal skills, fluent English
DESIERED SKILLS:
Agile practices, especially being a SCRUM Master
EDUCATIONAL BACKGROUND: B.E/B.Tech/MCA

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",3.9,"AstraZeneca
3.9",Chennai,"Cambridge, United Kingdom",10000+ employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Roche, GlaxoSmithKline, Novartis"
1463,DATA ENGINEER,"JOB DESCRIPTION
As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements, and also research new uses for data acquisition. You should also know the ins and outs of the industry such as data mining practices, algorithms, and how data can be used.

DESIRED CANDIDATE PROFILE
An ideal candidate must possess prior experience leading a project.

Candidates must have:
> Experience in Hive, Spark, Scala, AWS DynamoDB, HBase, AWS Glue, Talend, Kafka, Snowflake ETL
> Strong experience in a BI/Data Warehouse environment with involvement in design, development, implementation, troubleshooting and support of ETL process using ETL tool.
> Experience in developing Data Marts, Data warehousing and Operational Data Store (ODS) on any of the databases or Hadoop environments.
> Experience in database like MS SQL, MySQL, Oracle, PostgreSQL
> Good to have programming experience in writing Complex Stored Procedures, Queries, Views, User Defined Functions, Cursors and Common Table Expressions using SQL or T-SQL.
> Experience in Performance Tuning and Query Optimization by Indexing, Partitioning and De-normalization.
> Experience in Developing a framework for ingesting data into Data lake
> Good database knowledge, analytical thinking
> Design, construct, install, test and maintain data management systems.
> Build high-performance algorithms, predictive models, and prototypes.
> Develop set processes for data mining, data modeling, and data production.
> Experience with cloud services: AWS (EC2, EMR, S3, Athena) and scripting languages like Python, /PySpark/R/SAS
> Install/update disaster recovery procedures.
> Experience in Agile Application Development & Scrum methodologies is preferred
> Ability to supervise and mentor junior developers on the team.
> Must be self-motivated and work well pulling people together in addition to being able to pull people together technically
> Demonstrated proficiency of troubleshooting techniques and detail-oriented problem diagnosis
> Ability to handle responsibility, is self-directed, with strong organizational and documentation skills
> Ability to work independently and efficiently under aggressive deadlines to meet project commitments
> Excellent verbal and written communication skills

EDUCATION
UG - B.Tech/B.E. - Computers, Electronics/Telecommunication, Diploma - Computers, Electronics/Telecommunication, B.Sc - Computers, BCA - Computers) AND (PG - M.Tech - Computers, Electronics/Telecommunication, MCA - Computers, M.Sc - Electronics, Computers) AND ( Doctorate - Any Doctorate - Any Specialization, Doctorate Not Required).

OTHER DETAILS
Number of vacancies: 4
Experience: 3 years
Location: Cochin

If you have a passion towards technology and coding, then we have the right job for you. Kindly forward your resumes to
Email: jobs@mjsofttech.com
Phone: 0484-2421245 / 928 720 7160",4.0,"MJ Softtech
4.0",Kochi,"Cochin, India",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
1464,Data Engineer,"Education/ Experience and Skill Requirement
4+ years of relevant experience in
Experience working with both relational and NoSQL databases.
Strong coding skills; Python (preferred) /R/Java/Scala
Experience in developing Data warehousing technologies Experience with AWS or equivalent cloud services preferred
Experience in BigData technologies (Hadoop, HDFS, MapReduce, Spark, Hive, HBase etc) will be valuable
Knowledge of Machine Learning a big plus (Random Forest, Decision Trees, SVM, NLP, Gradient Boosting, Supervised/Unsupervised Learning, Clustering, classification and regression modeling).
Responsibilities
Proficiency with several years’ experience in more than one of Python, R, Java, Scala, or robust Linux shell scripting
Implementation experience with data warehouse architecture & design, ETL design/development, and Analytics
Knowledge of general cloud architecture and cloud strategies especially around AWS services and concepts such as S3 object stores, RDS databases, EC2, Glacier, Lambda, IAM, enterprise security, data security, DevOps, replication and disaster recovery
Well versed with data mining & exploration, NLP and visualization
Understanding of data modeling, data integration, and data representation (metadata, OWL, ontologies)
Developing data marts and data management using SQL
Creating powerful visual outcomes
Independently manage daily client communication, especially over calls
Manage client deadlines, ensure quality of the deliverables, attention to detail
Experience/understanding of corporate finance data from company filings is desirable",3.6,"Copal Partners
3.6",Bengaluru,"New York, NY",10000+ employees,1900,Company - Public,Financial Analytics & Research,Finance,₹100 to ₹500 billion (INR),-1
1465,Data Engineer,"Job Description / Responsibilities
Build workflows to ensure data extraction quality and storage into our backend data store
Architect, build and train ML/AI models that can predict outcomes and report on anomalies.
Design data pipelines to perform ETL on content/data from multiple types of source systems.
Create data analytics views using RDBMS/Key-Value stores, on private and public/cloud
Create software that is well tested, maintainable, extensible and scales out with large data

Minimum Qualifications:
2+ years of software development with Python
2+ years of SQL (MySQL/Postgres) and Key-Value databases
1+ years of experience with scikit
2+ years of experience in data extraction, data transformation using custom Python/Java
Experience working with MapReduce/Hadoop/kafka/Elastic stack
Experience with Node backend and React/Redux
Experience working with git/mercurial, Amazon/Google cloud, Linux/LAMP stack
Experience in testing or test driven development
Experience with Data science and Machine Learning algorithm development

Location:
Hyderabad/Bangalore

Package:
Highly competitive to match experience and capability",3.7,"TVS
3.7",Bengaluru,"Chennai, India",5001 to 10000 employees,-1,Company - Private,Accounting,Accounting & Legal,₹100 to ₹500 billion (INR),-1
1466,Data Engineer,"Permanent position with US based client of iFlex.
Work Location: Bangalore
Experience Level: 2+ Years

Role:
As part of our global team you will work on the data platform reporting to the Data Engineering Lead. Your role includes specification, development, test and rollout of features on our data platform. You are expected to contribute to the vision, understand our product roadmap, integrate business value andclient experience and contribute to build an engineering culture within the team. This initiative is of critical important to the success of the organization and our roadmap, for instance, services like liquidity analytics, billing, client onboarding, reporting and others will rely on the data platform. Accurate, granular, complete and timely data will be our key differentiating factor and competitive advantage in the market place. We expect the successful candidate to deliver high quality software and to be passionate about data engineering..

Responsibility / Qualification:
Managing multiple tasks and use sound judgment when prioritizing.
Collaborating with global cross functional team in building customer-centric products.
Analyzing existing software implementations to identify areas of improvement and provide deadline estimates for implementing new features.
Updating and maintain documentation for team processes, best practices and software runbooks.
Establishing trusted partnerships with peers, product heads, and executive level stakeholders.
We are looking for someone who is passionate about technology and engineering.
Exceptional analytical skills and ability to apply knowledge and experience in decision-making to arrive at creative and commercial solutions.
Ability to leverage technology to deliver business value.
You are independent and comfortable in a fast paced, ambiguous and often multi-directional work environment.

Preferred Qualifications:
B.S. or higher in Computer Science.
Minimum 2 years of relevant professional experience using a modern programming language (preferably Java/Scala).
Experience leveraging test driven development technics.
Comfort with Agile operating models.
Team oriented.
Strong interpersonal and communication skills.
Energetic, self-directed, and self-motivated.
Experience with microservice architecture.
Experience with Kafka, MongoDB, Hadoop, Cassandra.
Experience with AWS.
Experience in Financial Services or Fintech.",-1,IFLEX,Bengaluru,"Moscow, Russia",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1467,CIEL/SEL/1941: Sr data scientist,"Mandatory skills required -
Databases (SQL, Oracle, Any RDBMS) - Should have working knowledge of atleast one database
PL/SQL Programming Languages
R, Python (Any One)
Inferential Statistics - Hypothesis, p-value, R2, RMSE, MAPE etc
Exploratory Data Analysis
Machine Learning Algorithms - Should have in-depth knowledge and implementation of atleast one algorithm

Responsibilities
: Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the why & how of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions

Education
Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics
Experience
Minimum years of related experience required: 3 years
Preferred years of experience: 5 years
Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desirable.

Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
1468,Data Engineer,Data Engineer,3.6,"Bookmyshow
3.6",Mumbai,"Mumbai, India",1001 to 5000 employees,2007,Company - Private,Ticket Sales,"Arts, Entertainment & Recreation",Unknown / Non-Applicable,-1
1469,Data Analyst,"Required Skills & Experience

We are looking for a Data Analyst Executive
Eligible Qualifications : B. Tech, BCA, M.Tech, MCA
Experience : 3-5 years, fresher’s can also be considered
Location of Job : Gurgaon/Connaught Place, New Delhi
Technicals Skills

Following technical skills are pre-requisite:
Well versed with Software development methodologies, such as SDLC (Software Development Life Cycle), DDLC (Document Development Life Cycle).
Database schema design and implementation
Should have worked in either of technologies Sql Query/ Tableau/ Excel (Macros)/ Access (Query) writing for data analytics.
For planning and coordinating activities, organizations remain in invariant communication with one another and the data transfer has to be performed efficiently and smoothly as possible.
He/ She should manage the execution of the technologies, help the businesses in utilizing the systems, and should be well versed with the basics of computer systems such as Networking, Installation of necessary software and hardware.
Ability to determine the interrelationships between solutions and requirements.
Ability to think analytically and should be a problem solver and logic building should be very strong.
Good interpersonal skills to form effective working relationships with people at all levels.
Excellent communication and presentation skills and strong written & oral English skills.
To know more about us visit us www.sspl.net.in or write to us at admin@sspl.net.in",-1,Substratal Solutions,Connaught Place,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1470,Artificial Intelligence Scientists,"Experience 2- 4 Years
Salary 4 LPA - 6 LPA
Job Location Chennai

Industry:
IT-Software / Software Services

Keywords:
Artificial Intelligence

About Job:
Must have Excellent knowledge in AI / Machine learning (Mandatory).
Machine learning frameworks like keras, tensor flow etc.
And also other big data tools like Hadoop etc, Must know R and python.
Good understanding in SDLC & Business cycle.",4.0,"Careerera
4.0",Chennai,"Wayland, MA",501 to 1000 employees,-1,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
1471,Senior Data Engineer,"About Us

upGrad is an online education platform building the careers of tomorrow by offering the most industry-relevant programs in an immersive learning experience. Our mission is to create a new digital-first learning experience to deliver tangible career impact to individuals at scale. upGrad currently offers programs in Data Science, Machine Learning, Product Management, Digital Marketing, and Entrepreneurship, etc. upGrad is looking for people passionate about management and education to help design learning programs for working professionals to stay sharp and stay relevant and help build the careers of tomorrow.
upGrad was awarded the Best Tech for Education by IAMAI for 2018-19
upGrad was also ranked as one of the LinkedIn Top Startups 2018: The 25 most sought-after startups in India
upGrad was earlier selected as one of the top ten most innovative companies in India by FastCompany.
We were also covered by the Financial Times along with other disruptors in Ed-Tech
upGrad is the official education partner for Government of India - Startup India program
Our program with IIIT B has been ranked #1 program in the country in the domain of Artificial Intelligence and Machine Learning
About the Role

We are looking for a Data Engineer to help us scale the existing data infrastructure and in parallel work on building the next generation data platform for analytics at scale, machine learning infrastructure and data validation systems.
In this role, you will be responsible for communicating effectively with data consumers to fine-tune data platform systems (existing or new), taking ownership and delivering high performing systems and data pipelines, and helping the team scale them up, to endure ever growing traffic.
This is a growing team, which makes for many opportunities to be involved directly with product management, development, sales, and support teams. Everybody on the team is passionate about their work and we’re looking for similarly motivated “get stuff done” kind of people to join us!

Roles & Responsibilities
Engineer data pipelines (batch and real-time ) that aids in creation of data-driven products for our platform
Design, develop and maintain a robust and scalable data-warehouse and data lake
Work closely alongside Product managers and data-scientists to bring the various datasets together and cater to our business intelligence and analytics use-cases
Design and develop solutions using data science techniques ranging from statistics, algorithms to machine learning
Perform hands-on devops work to keep the Data platform secure and reliable
Skills Required
Bachelor's degree in Computer Science, Information Systems, or related engineering discipline
6 + years’ experience with ETL, Data Mining, Data Modeling, and working with large-scale datasets
6+ years’ experience with an object-oriented programming language such as Python, Scala, Java, etc
Extremely proficient in writing performant SQL working with large data volumes
Experience with map-reduce, Spark, Kafka, Presto, and the ecosystem.
Experience in building automated analytical systems utilizing large data sets.
Experience with designing, scaling and optimizing cloud based data warehouses (like AWS Redshift) and data lakes
Familiarity with AWS technologies preferred
Qualification – B.Tech/M.Tech/MCA(IT/Computer Science)

Years of Exp – 6-9",3.5,"upGrad Education Private Limited
3.5",Mumbai,"Mumbai, India",501 to 1000 employees,2015,Company - Private,Education Training Services,Education,₹1 to ₹5 billion (INR),"Udacity, General Assembly, Springboard"
1472,BBRC-Genomics-Associate Scientist,"JOB DESCRIPTION

Designation: Associate Scientist

Job Location: Bangalore

Department: Translational Medicine- Translational Sciences

About Syngene

Incorporated in 1993, Syngene International Ltd. is an innovation-focused global discovery, development and manufacturing organization providing integrated scientific services to the pharmaceutical, biotechnology, nutrition, animal health, consumer goods and specialty chemical industries around the world. Syngene’ s clientele includes world leaders such as Bristol-Myers Squibb, Baxter, Amgen, GSK, Merck KGaA and Herbalife. Its innovative culture is driven by the passion of its 4240- strong team of scientists who work with clients from around the world to solve their scientific problems, improve R&D productivity, speed up time to market and lower the cost of innovation .

Job Purpose:
To play a key role in TM-TS, develop an early-stage research strategy, initiate and lead discovery programs while managing ongoing programs in TM-TS. The role will work part of TMTS, and work with internal and external collaborators .

Key Responsibilities:
Experience in isolating DNA and RNA from blood, tissues and FFPE samples and cell lines. Experience with optimization of extraction protocols and for parameters like yield, input sample quantities and sample types is important.
Expertise in PCR, qPCR, cDNA/gDNA library preparation. Exposure to microarray techniques.
Proficiency in preparation of libraries for Next Generation Sequencing of transcriptome and genome, with significant experience in optimization of parameters like input RNA/DNA quantities and sample type
Experience with single cell RNA-seq will be plus.
Experience with various NGS protocols (DNA Amplicon based, hybrid capture based low input, degraded DNA and RNA samples e.g. FFPE samples.
Strong understanding of experimental design and statistical principles behind experimental design and differential gene expression. Experience with analysis of single cell RNA-sequencing data will be a plus

Educational Qualification:
M.Sc or M. Tech in Biotechnology, Molecular biology or Biological Sciences,

Technical/functional Skills:
DNA/ RNA Isolation, Expertise in PCR, qPCR, Experience in NGS protocols

Experience:
2 to 5 Years

Behavioral Skills:
A proactive team player.
Ensure completion of experiments and generate accurate and reproducible data from experiments.
Ability to work independently, prioritize tasks and work on multiple projects simultaneously with; comfortable working in a dynamic environment with changing requirements.
Good oral and written communication and presentation skills to work in a multi-disciplinary team
Equal Opportunity Employer:
It is the policy of Syngene to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by applicable legislation or local law. In addition, Syngene will provide reasonable accommodations for qualified individuals with disabilities.",3.5,"Syngene
3.5",India,"BENGALURU, India",1001 to 5000 employees,1994,Unknown,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1473,Applied Scientist 1,"Position Requirements:
Master's degree in Computer Science, Computer or Electrical Engineer, Mathematics, or a related field plus at least one year of experience in the job offered or related occupations of Software Engineer, Software Developer, or a related occupation. Employer will accept a Bachelor’s degree and five years of experience in the job offered or a related occupation as equivalent to the Master’s degree and one year of experience. One year of experience in the job offered or related occupation must involve designing and developing large-scale, multi-tiered, distributed software applications, tools, systems and services using Java, Object Oriented Design and Distributed Programming].

Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, Oracle/Berkeley databases, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills

Amazon Selling Partner Services team drives the Selling On Amazon business and develops solutions that enable millions of sellers around the world to sell on Amazon's Marketplaces. More than half of shipments for Amazon customers are generated from this business. The team is focused on building a technology platform that will support the explosive business growth in existing markets, streamline the business for Amazon and the Selling partners and launch business in new markets and establish a fair marketplace.

Our team is seeking engineers with broad technical skills to help us optimize how we synthesize massive amounts of data and complex business rules into mission critical financial information. As a member of this team you will employ object oriented techniques in Java, and DynamoB, PostGres and ElasticSearch skills to help us support Amazon's next generation of selling partner services. Along the way you'll gain and leverage a unique understanding of how Amazon.com works; from the numerous software systems that comprise the website's back-end, to the details of our business model, and the relationships we're establishing with an ever-growing network of selling partners who depend on Amazon.com to run their businesses.

The ideal candidate will draw upon exemplary analytical, critical thinking, and problem solving skills, and a passion for maintaining highly reliable, distributed systems which operate 24/7/365. Successful members of this team collaborate effectively with internal end-users, aggressive cross-functional software development teams, and technical support/sustaining engineering teams to solve problems and deliver successfully against high operational standards of system availability and reliability. We look for engineers who are excellent communicators, self-motivated, flexible, hardworking, and who like to have fun!

Position Responsibilities:
Participate in the design, development, implementation, testing and documentation of large-scale, multi-tiered, distributed software applications, tools, systems and services using [Java, Object Oriented Design and Distributed Programming]. Translate functional requirements into robust, scalable, supportable solutions that work well within the overall system architecture. Participate in the full development cycle, end-to-end, from design, implementation, and testing to documentation, delivery and maintenance. Produce comprehensive, usable software documentation. Evaluate and make decisions around the use of new or existing software products and tools.

Preferred Qualifications
Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1474,Senior Clinical Data Analyst,"About Novotech:

Novotech is internationally recognised as the leading independent and full-service contract research organisation (CRO) in the Asia Pacific region. We provide a wide range of clinical development services across all research phases and therapeutic areas and have been instrumental in the success of hundreds of Phase I – IV clinical trials throughout the Asia Pacific. Powered by the highest quality people, Novotech strives to set the benchmark for both business and clinical trial performance. Our people are one of our key strengths. We value our people and recognise the work they do. We are lucky to have the best people and talent from across the Asia Pacific region work together to deliver to clinical trial success for our clients. Our people and those we look to recruit have an attitude of making things happen. They are problem solvers, driven with a focus on delivering quality, accountability and a high level of performance.

Brief Position Description:

As part of Novotech’s Biometrics unit, the Senior Data Analyst (SDA) is responsible for all data analysis and business intelligence activities related to study related clinical and operational data. The SDA acts as primary point of contact for all data analysis matters to the study team and is responsible for the timely delivery of quality outputs following all applicable regulatory, compliance, best practice and operational procedures.

Minimum Qualifications & Experience:

Graduate in information science, data science or life science-related field, or similar. More than five years’ experience in a senior role related to data science, data analysis, clinical data management or clinical data programming in a pharmaceutical company, CRO or EDC software provider.

Responsibilities
The Senior Data Analyst (SDA) is responsible for providing technical, procedural (SOPs) and planning leadership across multiple projects assigned to the data analyst team members ensuring that they deliver in accordance with SOPs, programming best practices, and the timelines agreed within the Project Team.
Collaborate with cross-functional stakeholders to implement data science solutions to solve business needs using available technological solutions.
Scope data analysis effort for projects and project manage all data analysis activities across multiple projects for different study stakeholders.
Gather study requirements from data management for data review and external data reconciliation and provide guidance on appropriate outputs (dashboards, visualisations, listings, reports).
Extract, assess, integrate, transform data sources to provide data visualisation outputs for analytics.
Design and develop prototypes and final versions of data outputs (dashboards, reports, visualisations, listings) using Business intelligence tools and Data Visualisation tools.
Design and develop standard dashboards and content for different audiences.
Analyse, manipulate and understand data from multiple sources to present and create dashboards and reports to make business decisions.
Assist teams on best-practice for data visualisation dashboard development.
Educate teams on how to use all the features of applicable data visualisation platform in conjunction with data visualisation dashboards.
SME for the data visualisation development and assisting team members.
Identify and communicate project risks and maintain documentation within project files as appropriate
Represent data analysis group at internal / external meetings as appropriate.
Assess and implement new data analysis, BI and data visualisation processes and technologies.
Take an active role in the development of best practices, process improvement, quality control and governance related to all data analysis matters.
Provide training and mentoring to Data Analysis of team members in SOPs, software applications, and best practices.
Provide Subject Matter Expertise on all data analysis and visualisation related activities.
Attributes and Skills

Expert knowledge of clinical study data structures and schemas of EDC databases. Expert knowledge in data processing activities such as extracting, integrating, transforming and presenting data. Statistical Programming skills in Python, R or similar. Knowledge of SQL and EDC systems. Working knowledge of Spotfire, Power BI, Tableau or other data review and visualisation tool. Ability to gather business requirements from multiple stakeholders and clients and provide guidance on the use of appropriate data visualisations.

Experience mentoring and training others. Awareness of regulatory and compliance issues and understanding of the application of SOPs and Quality Control to daily activities. Excellent analytical, communication and problem-solving skills.

Opportunities and Benefits:

To deliver clinical trial and research excellence for our clients, our people are 'best in class'.

At Novotech, we seek and nurture people with exceptional talent. We are committed to providing our people with regular internal and external training, a competitive bonus structure and a supportive work environment. We are also focused on providing our people with a wide variety of career growth and development opportunities.

For more information about where your next career step at Novotech might take you, visit http://novotech-cro.com/novotech-careers",4.5,"Novotech
4.5",Bengaluru,"Sydney, Australia",501 to 1000 employees,1996,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
1475,Data Engineer,"Data Engineer Responsibilities:
Liaising with coworkers and clients to elucidate the requirements for each task.
Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed.
Reformulating existing frameworks to optimize their functioning.
Testing such structures to ensure that they are fit for use.
Preparing raw data for manipulation by Data Scientists.
Detecting and correcting errors in your work.
Ensuring that your work remains backed up and readily accessible to relevant coworkers.
Remaining up-to-date with industry standards and technological advancements that will improve the quality of your outputs.
Data Engineer Requirements:
Bachelor's degree in Data Engineering, Big Data Analytics, Computer Engineering, or related field.
Master's degree in a relevant field is advantageous.
Proven experience as a Data Engineer, Software Developer, or similar.
Expert proficiency in Python, C++, Java, R, and SQL.
Familiarity with Hadoop or suitable equivalent.
Excellent analytical and problem-solving skills.
A knack for independent and group work.
Scrupulous approach to duties.
Capacity to successfully manage a pipeline of duties with minimal supervision.
Job Type: Full-time

Salary: ₹360,000.00 to ₹870,000.00 /year

Experience:
total work: 2 years (Preferred)
Data Engineer: 1 year (Preferred)
Education:
Diploma (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,Futurious Technologies,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1476,Quantitative Analyst,"The successful candidate will be a highly analytical individual with hands on programming skills. The candidate will work closely with the research team and clients towards the ongoing development and integration of new investment strategies, models and tools on Axle

Location

Mumbai
Responsibilities

Perform daily/weekly/monthly tasks of performance and risk reporting
Develop and automate investment processes and strategies via VBA and Matlab
Develop tools to integrate trading decision systems with risk management systems
Ad hoc tasks (such as operational tasks, internal documentation tasks and preparation of marketing materials)
Skills/Experience

Excellent programming skills in Matlab/Excel-VBA
Thorough with financial concepts and calculations like Drawdown, VaR, Eloss etc.
Understanding of financial market products like options, futures, FX forwards etc.
Working knowledge of Bloomberg is preferred
Should be self-driven and detail oriented with an analytical mindset
Should be a proactive and quick learner; a team player showing enthusiasm and drive to accomplish results in a fast paced environment
Min. 2 years of relevant work experience
Qualifications

B.Tech/M.Tech/MBA/CFA/FRM",5.0,"B&B Analytics
5.0",Mumbai,"Zug, Switzerland",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1477,Analyst - Data Scientist,"Job Summary

Experience:
3 - 5 Years

Location:
Mumbai

Designation:
Analyst - Data Scientist

Degree:
BE-Comp/IT, BE-Other, BTech-Comp/IT, BTech-Other, ME-Comp/IT, ME-Other, MTech-Comp/IT, MTech-Other, PhD-Comp/IT, PhD-Other

Educational Level:
Graduate/Bachelors

Industrial Type:
IT-Software/Software Services

Functional Area:
IT Software - Application Programming / Maintenance

Key Skills:
Data Scientist

Job Post Date:
Thursday, March 19, 2020

Company Description

We are capability centre based in Mumbai, initially started as a back-office operational support to the UK business unit.

However, over the recent years, we have significantly increased the breadth and depth of our capabilities and offerings to keep pace with the changing needs of the Group. These include Digital & Knowledge Services, Finance and Actuarial, Information Technology (IT), Customer Service, Risk and Audit.

Our core purpose is to be a strategic partner to company, enabling growth by delivering change and driving synergies through a highly capable and agile workforce.

With our diversified service offerings we provide our people with exciting opportunities to grow personally and professionally.

Company is a leading savings and investments business serving around 5.5 million retail customers and more than 800 institutional clients.

It-s innovative asset management and customer solutions are supported by extensive investment capabilities, an international distribution network and two strong brands.

Job Description

3 – 5 yrs experience as Data Scientist
Should have at-least 1 end-to-end ML project experience
Very high proficiency in R or Python
Excellent in forecasting methods like simple exponential smoothing, multiplicative seasonal indexes, simple and weighted moving averages and time series forecasting methods
Exposure to with advanced deep learning techniques such as LSTM. CNN, Dense neural networks as well as neural networks design and implementation through tools like tensorflow, keras, pytorch, deepai or equivalent.
Good SQL experience",3.8,"Sampoorna Computer People
3.8",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
1478,Data Lake Developer,"For Us, It's A Mission

At Mylan, we mean it when we say we work every day to provide access to high quality medicines to the world's 7 billion people. If you are unconventional, relentless and passionate. If you believe in doing what's right, not what's easy. If you are a doer and have a passion for serving others, we want to talk to you.

Make a Difference

At Mylan, each person has the ability to make a difference. From the providers who sell and market our products, to the producers who develop and manufacture them and finally to our business partners who support the providers and producers, we all have a mission critical role. Here's how this role will help:

ESSENTIAL DUTIES AND RESPONSIBILITIES
To perform this job successfully, an individual must satisfactorily perform each essential duty. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential duties.
1. Create and maintain optimal data pipeline architecture on Azure platform.
2. Develop batch processing solutions by using Data Factory and Azure Databricks.
3. Delivering a Data Warehouse in the Azure Cloud.
4. Design relational and non-relational data stores on Azure.
5. Identify, design, and implement internal process improvements : automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc..
6. Developing Big Data Solutions with Azure Machine Learning.
7. Strong interaction with business departments to provide consultative support for digitization efforts, as well as close collaboration with the Business Technology management, focused on future innovation topics.
8. Participate and lead in design sessions, demos and prototype sessions, testing and training workshops with business users and other IT colleagues.
9. Design & Build for any API Development or SQL DB development.
10. Providing service management, orchestration, monitoring and management requirements of Azure cloud platform.
11. Create data tools / products for analytics and data scientist team members that assist them in building and innovative solutions that drive tangible business value.
12. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
13. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
14. Design security for source data access. Chose the appropriate authentication mechanism, (ie Azure Active Directory (Azure AD), etc).
15. Design for real-time processing by using Stream Analytics and Azure Databricks.

Make Our Values Your Values

Mylan hires only the best. People who thrive in a culture of innovation and empowerment. People who are active learners and have a positive attitude. People who are leaders and know that by working together we can run faster, reach higher and achieve more. By doing so, we will continue to set new standards in health care. Here are the minimum qualifications and essential functions for this position:

QUALIFICATIONS

The qualifications listed below are representative of the minimum knowledge, skill, and/or ability required.

SKILLS AND ABILITIES

1. 10 years of experience in Microsoft technologies including SQL.

2. At least 5 years as a Sr Developer with at least 3 years hands on experience as Azure Data Engineer building large scale Azure data solutions.

3. At least 5 years of experience in Azure based data solutions.

4. At least 3 years of experience on working with large projects including the most recent project in the cloud (Azure) or on prem with a focus on Azure Data services.

5. At least 5 years of Hands-on administration, configuration management, monitoring, performance tuning of Hadoop/Distributed platforms.

6. At least 5 years of demonstrated experience at least in the most recent 2 years of designing and delivering solutions using Cortana Intelligence suite of analytics services part of Microsoft Azure including Azure Machine Learning Studio, HDInsight, Polybase, Azure Data Lake Analytics, Azure Data Warehouse, Streaming Analytics, Data Catalog, R/R Studio

7. Experience in designing and building logics required for optimal extraction, transformation, and loading of data from a wide variety of data sources

8. Experience within Data Security design, including but not limited to:

a. Choosing the appropriate authentication mechanism, such as Azure Active Directory (Azure AD)

b. Defining strategies for data encryption for data at rest and in transit

9. Experience partnering with Business Analysts and Data Scientists to enable effective and efficient data preparation and delivery

10. Experienced in vendor management and working with 3rd parties onshore & offshore.

11. Experience working in a global team.

12. Experience working in an Analytics / Big Data solutions on MS Azure Cloud

13. Experience with code management tools, automated testing

14. Experience creating and maintaining optimal data pipeline architecture on Azure platform

15. Experience developing batch and real-time processing solutions by using Data Factory and Azure Databricks

16. Familiar with AGILE and Azure DevOps methodology

17. Hands on PoC capabilities are needed to prove a particular architecture concept

18. Azure Native Services experience across Data Fabric and Service Fabric

19. Experience in Application modernization from legacy on-premise data architecture platform technology stack to modernized Azure Cloud base Architecture.

20. Experience with Git, NoSQL Data Solutions, Microsoft Azure, HD Insights, Azure ML, DataBricks ML Flow, R or Python.

21. Must have excellent communication skills.

EDUCATION/EXPERIENCE (Note: Please select one)

Minimum of a Bachelor's degree in Computer Science and Engineering is preferred with minimum 10 years of experience. However, a combination of experience and/or education will be taken into consideration

Why Mylan?

If you want to be part of a global health care company that is making a difference and changing lives, Mylan may be the place for you. With a workforce of more than 35,000 worldwide, we can make a difference. We encourage you to visit Mylan.com to learn more about our unconventional culture, our approach to doing business and how we plan to set new standards in health care.

Mylan offers competitive salary, excellent benefits and an environment conducive to professional growth and advancement. All qualified applicants will receive consideration for employment without regard to their disability or protected veteran status. Mylan is an Equal Opportunity Employer, Minorities/Female/Disabled/Veteran.",3.8,"Mylan Inc.
3.8",Bengaluru,"Hatfield, United Kingdom",10000+ employees,1961,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1479,Off Campus Recruitment - Quantitative Researcher,"Description:
Graviton is a privately funded quantitative trading firm striving for excellence in financial markets' research. We are seeking fresh talent from the top IIT's to join us as Quantitative Researchers for our team in Gurgaon.If you are a student graduating in 2020 from Computer Science , Electrical or Maths Stats Computing streams with a greater than 8 CGPA please apply here.

This role is open to students from campuses that we could not visit this year. Please check your individual placement policy restrictions before applying.

Graviton trades across a multitude of asset classes and trading venues using a gamut of concepts and techniques ranging from time series analysis, filtering, classification, stochastic models, pattern recognition to statistical inference analysing terabytes of data to come up with ideas to identify pricing anomalies in financial markets.

As a Quantitative researcher your responsibilities will include

Develop new or improve existing trading models using in-house platforms

Use advanced mathematical techniques to model and predict market movements

Analyse large financial datasets to identify trading opportunities

Provide real time analytical support to experienced traders

Requirements :
Possess a degree in a highly analytical field, such as Engineering, Mathematics, Computer Science from IITs schools

Quantitative bend of mind

A working knowledge of Linux/Unix

Programming experience, preferably in C++ or C

Strong interest in learning about financial markets.

Have a strong work ethic

Hard Working

Benefits:
Our open and casual work culture gives you the space to innovate and deliver. Our cubicle free offices , disdain for bureaucracy and insistence to hire the very best creates a melting pot for great ideas and technology innovations. Everyone on the team is approachable, there is nothing better than working with friends!

Our perks have you covered.

Competitive compensation

6 weeks of paid vacation

Monthly after work parties

Catered breakfast and lunch

Fully stocked kitchen

Gym membership

International team outing",5.0,"Graviton Research Capital LLP
5.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2014,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1480,Data Engineer,"Zauba Technologies is a startup based in Bangalore. Zauba's services are used by leading companies in India. Zauba is powered by a young and passionate team. We are looking for individuals who would like to be a part of our founding team.

As a Data Engineer and as a part of founding team, you will be expected to visualise and develop disruptive data products. Eventually you would be responsible for entire project lifecycle of products you would visualize. Your rewards will be directly proportional to the value you generate.

Job Responsibilities
Design and development of robust, scalable and highly efficient data engineering solutions for structured and unstructured data (Including gathering and processing raw data at scale, writing scripts, web scraping, calling APIs, writing SQL queries, etc.)
Develop processes for text mining and extraction of information from unstructured data
Design, architect and develop efficient data pipelines around the data collected
Take ownership of existing web product and applications
Design and implement data models that scale across the enterprise
Take ownership of existing data workflows and processes
Enhance scalability, performance, and stability of existing infrastructure
Work closely with other team members to integrate your innovations and algorithms into our production systems

Essentials
Java/Python - Intermediate to advanced level
SQL - Advanced
MySQL Intermediate to advanced level
Regex - Basic to intermediate level
Linux Basic to intermediate level

Good to have
Hadoop/Spark
R
MongoDB

Must have qualities
Skills to learn new skills quickly
Desire to create disruptive products and services
Passion - not just to work in startups but to take them to next level
Above average programming aptitude
Be passionate about producing high quality engineering deliverables
Be productive working independently or collaboratively
Have an eye for building efficient processes
Be self motivated
Proactively take ownership

Interested?

Send your resume to hr@zaubacorp.com",3.8,"Zauba Corp
3.8",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 million (INR),-1
1481,Quantitative Research,"We are looking for highly trained professionals who are interested in applying advanced mathematical quantitative methods to the modeling of global financial markets. You would be joining a group made up of highly proficient individuals from various scientific disciplines. We have a spectrum of opportunities for individuals with the right scientific skills. Experience in finance is not required.

The ideal research candidate will have:
A Ph.D. in Computer Science, Mathematics, Physics, Statistics, or a related technical discipline.

A demonstrated capacity to do first-class research.

Computer programming skills.

An intense interest in applying quantitative analysis to solve difficult problems.

Send us a copy of your resume to
careers@dolatcapital.com

For internship opportunities, please send us a copy of your resume to
careers@dolatcapital.com",4.0,"Dolat Capital
4.0",Mumbai,"Mumbai, India",51 to 200 employees,1970,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1482,Data Engineer,"Bachelor’s degree in Computer Science or related field
5+ years relevant experience
5+ years experience with SQL, SQL Tuning, Oracle, OLAP, Big Data Technologies
5+ years experience developing end-to-end Business Intelligence solutions: data modeling, ETL and reporting
Experience with Java and experience with scripting languages like Perl, Python, Unix shell scripts,VBA and MS Excel
Proficiency with Linux and systems administration
Proven ability at looking at solutions in unconventional ways. Sees opportunities to innovate and can lead the way.
Top notch communication (verbal and written) and interpersonal skills to convey key insights from complex analysis in summarized business terms and an ability to effectively communicate with technical teams.
Ability to work with shifting deadlines in a fast paced environment.
Operations Finance Technology team, responsible for building technical solutions for multi-billion WW Operational Cost analytic including Inbound cost (Receiving / PO), variable Cost, fixed cost, outbound (Customer Shipments / Transportation), and Customer Service, is looking for a Data Engineer.

As a data engineer, you will get the exciting opportunity to work on very large data sets in one of the world's largest and most complex data warehouse environments. You will work closely with the business teams in analysis on various cost savings initiatives, many non-standard and unique business problems and use creative-problem solving to deliver actionable output.
You will be responsible for designing and implementing an analytical environment using third-party and in-house reporting tools, modeling metadata, building reports and dashboards. You will have an opportunity to work with leading edge technologies like Redshift, Hadoop/Hive/Pig. You will be writing scalable queries and tuning performance on queries running over billion of rows of data.

You should be analytical, have an extremely high level of customer focus and a passion for process improvement. You should be motivated self-starter that can work independently in a fast paced, ambiguous environment. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions.
Bachelors in Computer Science or related field
Practical Knowledge of Linux or Unix shell scripting
Experience in working with business customers to drive requirements analysis
Exposure to large databases, BI applications, data quality and performance tuning
Excellent written and spoken communication skills
Experience with Hadoop-based technologies such as HBase, Pig, Hive and Spark
Strong proven ability in building high-performance, highly available and scalable data solutions using Oracle and/or Hadoop-based technologies
Knowledge of data warehousing concepts.
Strong sense of ownership, urgency, and drive
Strong troubleshooting and problem solving skills
Experience with Amazon Web Services",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1483,DATA ANALYST,"posted by Mahima Gaur

2 - 5 years Delhi

Job Description
Experience in data processing
Experience in data cleaning and data tabulation activities
Strong analytical, communication and team management skills
Strong understanding of data management using SPSS and research techniques
Competency in a Tabulation software (decipher / wincross / quantum etc), Excel, Powerpoint
Ability to summarize findings, draw conclusions, and put together a presentation using Powerpoint
Role Category : Data Analyst

Employment Type : Permanent Job, Full Time",4.9,"Knowledge Excel Services.
4.9",New Delhi,"New Delhi, India",1 to 50 employees,2007,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
1484,Data Engineer,"Key skills : Python , Spark , SQL , Pyspark • AWS platform used for the work • Strong experience in SQL is mandatory • Good familiarity of AWS landscape • Good experience in collecting business requirements & design them as per requirement from customer • Should able to work independently & interact business users & technical stakeholders • Strong communication skills both oral & written. • Should work as an individual resources",3.5,"Larsen & Toubro Infotech Limited
3.5",India,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1485,Big Data Engineer,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
1486,Client Data Analyst,"At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.
What is the Client Data Analyst – Client Analytics group responsible for?
This team manages business data to ensure accurate, timely, consistent and compliant data. Their contributions deliver quality data that is easily accessible and can be trusted. Key downstream capabilities such as reporting and analytics depend on this as well as operational data access on various systems. The Data Management Team is a support function that acts as an advocate and a point of contact for Sales and Marketing data.

What are the ongoing responsibilities of an Client Data Analyst ?
Understand the data flow, key consumption and production of data as well as context within the enterprise:
Build positive relationships with teams, especially the key data consumers and analytics. Take the time to increase knowledge of how they run their business and incorporate sales data into daily work
Connect regularly with each sales office to understand current issues and challenges. Probe the business and validate against other sales offices to understand the scope and priority of the issue
Make recommendations on how data unifications and flow can be used to improve business tasks. Liaise business partners to deliver solutions (reports, processes, technology) that add value.

Provide data management subject matter expertise. Appreciate the connection and data flow between applications and other corporate systems. Be able to clearly articulate the data needs and move initiatives forward by collaborating with business partners:
Actively participate in meetings with business partners to ensure that priorities are clearly understood, information is regularly shared and that key participants are “kept in the loop”
Provide context and background on issues. Collaborate on ideas for progressing initiatives. Ensure appropriate resources are involved to take initiatives forward
Provide insights and expertise to scope statements and requirements documentation
Actively consult or participate in the user acceptance testing process (test cases, documentation, testing execution, etc.)
Ensure business needs remain aligned with overall corporate initiatives and deliver the benefits as originally intended

Monitor the integrity of data and usefulness of reports. Ensure the information available within systems is accurate and up-to-date. Proactively seek data cleansing opportunities and evolve data to better support. Document and maintain ongoing processes for reporting and data clean-up:
Partner with all key data consumers to gain a solid understanding of usage and challenges around data. Establish processes for prioritization of enhancements, especially with the analytics groups
Provide 1st level support for data issues and data maintenance for owned data
Verify and execute data loads into our internal sales systems and ensure any upstream systems accurately receive their data

Increase awareness and promote data management capabilities. Share best practices and provide coaching to local offices on how to access and incorporate output into sales tasks. Encourage IAS leaders to leverage data to make more informed, strategic decisions:
Clearly articulate the goals and core services of the data management team. Proactively promote this information within IAS and ensure business partners understand the data management role within the organization
Share best practices and provides guidance on data capabilities. Reinforces ownership and accountability for data accuracy
Seek opportunities to share the benefits of leveraging sales data to make more informed business decisions

What ideal qualifications, skills & experience would help someone to be Successful?

Knowledge, Education And Experience:
Four year bachelor’s degree required (majors of preference include: business, computer science, mathematics) Advanced degree a plus
Understanding of the Franklin Templeton business model, how FT makes money, the sales process, how technology fits in with the business, etc. Knowledge of the GAS (Global Advisory Services) structure
Experience working through multiple business fiscal cycles; exposure and/or direct experience with project management and/or sales-related-capacity required
Prior work experience related to analytics, sales, marketing and/or international a must. Level will not be granted based on years of experience but will be determined by the employee’s ability to meet each job activity as outlined the ‘typical/expected focus by level
Skills And Abilities:
Ability to communicate effectively with all levels of management; ability to tailor communication style based on audience; ability to get others to want to collaborate with you; strong facilitation skills
Excellent writing skills (for presentations, documentation, etc.)
Working knowledge of the CRM, MDM, Excel, SQL, Power BI, Tableau, Business Objects, and Microsoft Products (PPT, Power Apps, Doc, Visio)
Ability to absorb and interpret large quantities of data; apply trend analysis and knowledge of the business to develop a meaningful and digestible summary with the appropriate level of detail
Ability to take a larger problem and break down the individual components; identify how to go about solving the problem and who to involve in the process
Ability to present recommended solutions to a variety of issues and problems (solutions that are consistent with organization objectives)
Must be extremely detail-oriented (managing lists, tasks/to-dos, etc.) good with follow through on own items; good with following up with others on outstanding item

What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.

Highlights of our benefits include:

Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.",3.8,"Franklin Templeton Investments
3.8",Hyderabad,"San Mateo, CA",5001 to 10000 employees,1947,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Fidelity Investments, Vanguard"
1487,Data Analyst,"Roles and Responsibilities:
Extracting, transforming and inputting data sets from various resources. Creating predictive models, translating non-technical aspects into quantifiable tasks. Analysis and representation of output data, highlight and explain trends and patterns, error elimination, using advanced statistical methods (regression, probability distribution, clusters etc.) to provide accurate results.
Data collection, Data Mining, Report generation, Problem identification and solution formulation Market analysis and establishing trends, Strategy development and implementation

Skills:
Extremely good analytical skills.
Good working knowledge of all MS-Office products, especially Advance Excel, Word, PowerPoint, MS-access.
Statistical tools and methods.

Interested candidates can send the updated resume on satish.mehra@exelaonline.com or call on 7722028636
00-7.00 Years",2.6,"Exela Technologies
2.6",Pune,"Irving, TX",10000+ employees,2017,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"SourceHOV, BancTec, Transcentra"
1488,Data Modeler,"• Minimum 5-8 years of working experience as Data modeler.
• Data modelling experience in designing.
• Minimum 2-3 years real time experience in Erwin tool is mandatory.
• Experience in normalized modeling techniques.
• Experience in designing the Start schema.
• Experience working in ORACLE.
• Experience with database design, capacity planning, performance tuning and query optimization.
• Experience in working with Bank or Banking and Finance or Financial domain.
• Excellent communication skills with leadership quality.

Job Segment:
Database, Oracle, ERP, Technology",3.5,"LTI
3.5",Mumbai,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1489,Machine Learning Engineer,"Looking for Data Scientists with Python/R Programming skills.
Specific experience in AI areas like Statistical Machine learning / Deep learning / Natural Language Processing (NLP)/ Operations Research (Optimization) will be an advantage.Individual in this role is expected to work with multiple stakeholders and teams

Qualifications and Requirements:-
Previous working experience as a Machine Learning/ Data Scientist for 2 years
MA in Computer Science or similar relevant field
Hands on experience with MALLET
In depth knowledge of Apache Tomcat/Open Source
Excellent project and time management skills
Attention to detail
Outstanding problem solving and analytical skills",-1,Tekolutions.ai,India,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1490,Data Science Internship,"About the company:
SkillBit is a leading staffing and recruitment company engaged in talent searching assignments for skilled and talented candidates for the industry.

About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Working on data science algorithms and AI concepts 2. Using Python or R for web scraping 3. Building AI models using Python, machine learning, and deep learning algorithms 4. Processing of unstructured/structured data

Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 6th Jun'20 and 11th Jul'20
are available for duration of 1 month
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply

Number of internships/jobs available: 3

Categories: Data Science",-1,SkillBit,Pune,-1,-1,-1,-1,-1,-1,-1,-1
1491,Data Engineer,"As a data engineer at TEAL, you'll be taking the plunge into a rich data lake that includes everything from satellite data to legal court orders. You'll be hustling and getting your hands dirty with every part of the data pipeline always having an implicit appreciation for how all of this data will ultimately power a revolutionary real estate risk platform.

Your day-to-day will include either all or some of the following:

Constantly scoping out new data sources to complement existing ones
Creating and maintaining distributed web scrapers using Python, RabbitMQ and other technologies
Architecting and managing data pipelines where data flows into multiple end-points including, but not limited to, Postgres, MongoDB and Apache Solr
Documenting workflows and constantly iterating to create better data infrastructure.

We'd love it if you:
Are proficient in Python or any other object-oriented language
Have worked with large (millions to hundreds of millions of rows in a SQL database) interdisciplinary datasets
Have scraped difficult websites and have some experience working with various data APIs
Are patient and methodical with unstructured and messy data
Are always hungry to learn newer and better technologies to make the data ecosystem faster, smoother and less silo-ed

Extra brownie points if you:
Have some experience working with large-scale search indexing
Have performed geospatial analyses in some capacity
Have created and managed data lakes in the cloud
Culture

To explore our culture and the values we embody click here

Testimonials
Testimonial

My experience at TEAL surpassed all my expectations from the get-go. I was asked to help solve one of the most daunting problems in the Indian real estate market. Every day while working on a subset of the problem, the ideas that I brought to the table were shaped into cohesive solutions by a collaborative team effort. At TEAL I was exposed to the most cutting edge technologies such as Cloud Computing, Big Data, ML and Data Science. The growth opportunities at TEAL are tremendous, If you are innovative and can demonstrate the will to realize your ideas, TEAL is an amazing organization to work for.
Gyan Vardhan, Data Science Intern
I had interned as a Data Scientist at Terra Economics and Analytics Lab during its early days, it was a rich learning experience working with a multi-disciplinary team who are extremely passionate about building a decision support platform for the insanely complicated realty market in India. It was exciting and challenging to work on mining huge volumes of property records; extracting patterns from the data, building data pipelines and brainstorming on building the core system. TEAL offers a very healthy work environment coupled with insanely talented people working together in an exciting setting.
Naga Anjaneyulu, Data Science Intern
I worked as a full-time Data science intern at TEAL. During this period, I got an opportunity to leverage my skillsets while also learning new technologies, working on tasks assigned to me. The company operates on the latest tech-stacks and gives opportunities to learn as much as you want. The work environment is challenging, the team at TEAL is super supportive and new ideas are always welcome. It has all the good perks of a startup; creativity and innovation, casual work atmosphere and a collaborative approach to solving problems. Personally, I loved working there, my experience was fantastic!
Archana Parmar, Data Science Intern
As a second-year college student, I was looking for an internship that would allow me to delve deeper into research and work with big data, TEAL gave me the perfect opportunity to do so, enabling me to develop proficiency in research and analysis. As a research analyst intern, I collated and cleaned data and helped in the preparation of reports and presentations, and I had members helping me at every stage of this process. This collaborative environment allowed me to cultivate my skills and also learn from my peers. The holy trinity of Rohan, Kshitij, and Shreyas served as not only excellent mentors and bosses but also as friends, helping me at every stage and giving us all food and ice cream to keep us going!
Arush Mehra, Research Intern
Internships are a crucial part of one’s early career. The internship experience at TEAL was a thrilling rollercoaster ride to say the least! It was more than implementing a standard model or building an already though out concept into reality. It was about finding the solution to a unique and open-ended problem.It was exciting to work on addressing a problem with far -reaching real world applications.Moreover, the work environment had the perfect balance of casual yet professional which kept you focused and stress free at the same time. Out of every 100 startups in India only 2 of them succeed, but there are very few like TEAL India which are bound to make it big at such an early stage.
Divyanshu Agarwal, NLP Intern",4.7,"Terra Economics & Analytics Lab (TEAL)
4.7",New Delhi,"Bengaluru, India",1 to 50 employees,2018,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
1492,Senior Consultant - ModellingOps Data Engineer,"Job Title: Senior Consultant - ModellingOps Data Engineer
Location: TRIL GTC
GCL: D1

JOB DESCRIPTION:

AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. The Science & Enabling Units IT is AZs global IT capability function supporting key business areas operating out of sites across the US, UK, Sweden, India & Mexico.

We are looking for AI Ops consultant who will leverage tools & technology best practices to improve delivery performance & data engineering capabilities in the D&A space.

ROLES & RESPONSIBILITIES:

7-10 years of experience in IT Operations involving Data Science, Artificial Intelligence-Machine Learning and Predictive Analytics. Experience in architecting and implementation of end-to-end AIOPs solutions through ELK stack, Splunk. Experience in applying statistical methods, analysis, pattern recognition and modeling on IT Operational data using ELK machine learning. Experience in extracting meaning full data from incoming data streams from different sources through RegEx, Grok etc. Hands-on experience in applying machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc in the IT Operation domain. Experience with machine learning and statistical programming languages - Python, R etc. Experience in assessing the existing IT environment and providing recommendations to reduce the critical applications impacting incidents. Experience in exploring and identifying areas where manual tasks can be automated in IT environment. Experience with various Enterprise IT monitoring solutions including Infrastructure monitoring, Application Performance Monitoring, Network Monitoring, Cloud monitoring etc. Experience in IT Service Management including Service Desk, Incident Management, Change Management, CMDB etc. Excellent knowledge on various IT infrastructure components that includes Server Infrastructure, middle ware, database and application architectures and Cloud Components. Experience/knowledge on Infra monitoring tools - NOI, Zabbix, AppDynamics, Datadog, SCOM, SolarWinds etc. and Service Management tools -IBM Control Desk, BMC Remedy, ServiceNow etc. Experience/Knowledge on BI tools Knowledge on distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc. Knowledge on other programming languages/scripting: Python, Java, JavaScript, etc. ( Added Advantage ) Good analytical skills, strong communication skills are must. Client facing experience is an added advantage. Excellent experience in understanding the problem statement, architect and designing the solution

MANDATORY SKILLS:
Significant experience with AWS cloud environments, working knowledge of Google and Azure platforms. Knowledge of Kubernetes, S3, EC2, Sagemaker, Athena, RDS and Glue is essential.
Experience provisioning computational resources in a variety of Cloud environments using Infrastructure as Code.
Experience with best practice of data transport and storage within cloud system.
Experience building large scale data processing pipelines. e. g. Spark and SQL.
Experience with containers and microservice architectures e.g. Kubernetes, Docker and serverless approaches.
Excellent working knowledge in DevOps, using continuous integration and continuous development.
Use of Data Science modelling tools e.g. R, Python, SAS and Data Science notebooks (e.g. Jupyter).
Good written and verbal skills, fluent English
DESIERED SKILLS:
Agile practices, especially being a SCRUM Master
EDUCATIONAL BACKGROUND: B.E/B.Tech/MCA

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",3.9,"AstraZeneca
3.9",Chennai,"Cambridge, United Kingdom",10000+ employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Roche, GlaxoSmithKline, Novartis"
1493,DATA ENGINEER,"JOB DESCRIPTION
As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements, and also research new uses for data acquisition. You should also know the ins and outs of the industry such as data mining practices, algorithms, and how data can be used.

DESIRED CANDIDATE PROFILE
An ideal candidate must possess prior experience leading a project.

Candidates must have:
> Experience in Hive, Spark, Scala, AWS DynamoDB, HBase, AWS Glue, Talend, Kafka, Snowflake ETL
> Strong experience in a BI/Data Warehouse environment with involvement in design, development, implementation, troubleshooting and support of ETL process using ETL tool.
> Experience in developing Data Marts, Data warehousing and Operational Data Store (ODS) on any of the databases or Hadoop environments.
> Experience in database like MS SQL, MySQL, Oracle, PostgreSQL
> Good to have programming experience in writing Complex Stored Procedures, Queries, Views, User Defined Functions, Cursors and Common Table Expressions using SQL or T-SQL.
> Experience in Performance Tuning and Query Optimization by Indexing, Partitioning and De-normalization.
> Experience in Developing a framework for ingesting data into Data lake
> Good database knowledge, analytical thinking
> Design, construct, install, test and maintain data management systems.
> Build high-performance algorithms, predictive models, and prototypes.
> Develop set processes for data mining, data modeling, and data production.
> Experience with cloud services: AWS (EC2, EMR, S3, Athena) and scripting languages like Python, /PySpark/R/SAS
> Install/update disaster recovery procedures.
> Experience in Agile Application Development & Scrum methodologies is preferred
> Ability to supervise and mentor junior developers on the team.
> Must be self-motivated and work well pulling people together in addition to being able to pull people together technically
> Demonstrated proficiency of troubleshooting techniques and detail-oriented problem diagnosis
> Ability to handle responsibility, is self-directed, with strong organizational and documentation skills
> Ability to work independently and efficiently under aggressive deadlines to meet project commitments
> Excellent verbal and written communication skills

EDUCATION
UG - B.Tech/B.E. - Computers, Electronics/Telecommunication, Diploma - Computers, Electronics/Telecommunication, B.Sc - Computers, BCA - Computers) AND (PG - M.Tech - Computers, Electronics/Telecommunication, MCA - Computers, M.Sc - Electronics, Computers) AND ( Doctorate - Any Doctorate - Any Specialization, Doctorate Not Required).

OTHER DETAILS
Number of vacancies: 4
Experience: 3 years
Location: Cochin

If you have a passion towards technology and coding, then we have the right job for you. Kindly forward your resumes to
Email: jobs@mjsofttech.com
Phone: 0484-2421245 / 928 720 7160",4.0,"MJ Softtech
4.0",Kochi,"Cochin, India",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
1494,Data Engineer,"Education/ Experience and Skill Requirement
4+ years of relevant experience in
Experience working with both relational and NoSQL databases.
Strong coding skills; Python (preferred) /R/Java/Scala
Experience in developing Data warehousing technologies Experience with AWS or equivalent cloud services preferred
Experience in BigData technologies (Hadoop, HDFS, MapReduce, Spark, Hive, HBase etc) will be valuable
Knowledge of Machine Learning a big plus (Random Forest, Decision Trees, SVM, NLP, Gradient Boosting, Supervised/Unsupervised Learning, Clustering, classification and regression modeling).
Responsibilities
Proficiency with several years’ experience in more than one of Python, R, Java, Scala, or robust Linux shell scripting
Implementation experience with data warehouse architecture & design, ETL design/development, and Analytics
Knowledge of general cloud architecture and cloud strategies especially around AWS services and concepts such as S3 object stores, RDS databases, EC2, Glacier, Lambda, IAM, enterprise security, data security, DevOps, replication and disaster recovery
Well versed with data mining & exploration, NLP and visualization
Understanding of data modeling, data integration, and data representation (metadata, OWL, ontologies)
Developing data marts and data management using SQL
Creating powerful visual outcomes
Independently manage daily client communication, especially over calls
Manage client deadlines, ensure quality of the deliverables, attention to detail
Experience/understanding of corporate finance data from company filings is desirable",3.6,"Copal Partners
3.6",Bengaluru,"New York, NY",10000+ employees,1900,Company - Public,Financial Analytics & Research,Finance,₹100 to ₹500 billion (INR),-1
1495,Data Engineer,"Job Description / Responsibilities
Build workflows to ensure data extraction quality and storage into our backend data store
Architect, build and train ML/AI models that can predict outcomes and report on anomalies.
Design data pipelines to perform ETL on content/data from multiple types of source systems.
Create data analytics views using RDBMS/Key-Value stores, on private and public/cloud
Create software that is well tested, maintainable, extensible and scales out with large data

Minimum Qualifications:
2+ years of software development with Python
2+ years of SQL (MySQL/Postgres) and Key-Value databases
1+ years of experience with scikit
2+ years of experience in data extraction, data transformation using custom Python/Java
Experience working with MapReduce/Hadoop/kafka/Elastic stack
Experience with Node backend and React/Redux
Experience working with git/mercurial, Amazon/Google cloud, Linux/LAMP stack
Experience in testing or test driven development
Experience with Data science and Machine Learning algorithm development

Location:
Hyderabad/Bangalore

Package:
Highly competitive to match experience and capability",3.7,"TVS
3.7",Bengaluru,"Chennai, India",5001 to 10000 employees,-1,Company - Private,Accounting,Accounting & Legal,₹100 to ₹500 billion (INR),-1
1496,Data Engineer,"Permanent position with US based client of iFlex.
Work Location: Bangalore
Experience Level: 2+ Years

Role:
As part of our global team you will work on the data platform reporting to the Data Engineering Lead. Your role includes specification, development, test and rollout of features on our data platform. You are expected to contribute to the vision, understand our product roadmap, integrate business value andclient experience and contribute to build an engineering culture within the team. This initiative is of critical important to the success of the organization and our roadmap, for instance, services like liquidity analytics, billing, client onboarding, reporting and others will rely on the data platform. Accurate, granular, complete and timely data will be our key differentiating factor and competitive advantage in the market place. We expect the successful candidate to deliver high quality software and to be passionate about data engineering..

Responsibility / Qualification:
Managing multiple tasks and use sound judgment when prioritizing.
Collaborating with global cross functional team in building customer-centric products.
Analyzing existing software implementations to identify areas of improvement and provide deadline estimates for implementing new features.
Updating and maintain documentation for team processes, best practices and software runbooks.
Establishing trusted partnerships with peers, product heads, and executive level stakeholders.
We are looking for someone who is passionate about technology and engineering.
Exceptional analytical skills and ability to apply knowledge and experience in decision-making to arrive at creative and commercial solutions.
Ability to leverage technology to deliver business value.
You are independent and comfortable in a fast paced, ambiguous and often multi-directional work environment.

Preferred Qualifications:
B.S. or higher in Computer Science.
Minimum 2 years of relevant professional experience using a modern programming language (preferably Java/Scala).
Experience leveraging test driven development technics.
Comfort with Agile operating models.
Team oriented.
Strong interpersonal and communication skills.
Energetic, self-directed, and self-motivated.
Experience with microservice architecture.
Experience with Kafka, MongoDB, Hadoop, Cassandra.
Experience with AWS.
Experience in Financial Services or Fintech.",-1,IFLEX,Bengaluru,"Moscow, Russia",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1497,CIEL/SEL/1941: Sr data scientist,"Mandatory skills required -
Databases (SQL, Oracle, Any RDBMS) - Should have working knowledge of atleast one database
PL/SQL Programming Languages
R, Python (Any One)
Inferential Statistics - Hypothesis, p-value, R2, RMSE, MAPE etc
Exploratory Data Analysis
Machine Learning Algorithms - Should have in-depth knowledge and implementation of atleast one algorithm

Responsibilities
: Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the why & how of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions

Education
Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics
Experience
Minimum years of related experience required: 3 years
Preferred years of experience: 5 years
Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desirable.

Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
1498,Data Engineer,Data Engineer,3.6,"Bookmyshow
3.6",Mumbai,"Mumbai, India",1001 to 5000 employees,2007,Company - Private,Ticket Sales,"Arts, Entertainment & Recreation",Unknown / Non-Applicable,-1
1499,Data Analyst,"Required Skills & Experience

We are looking for a Data Analyst Executive
Eligible Qualifications : B. Tech, BCA, M.Tech, MCA
Experience : 3-5 years, fresher’s can also be considered
Location of Job : Gurgaon/Connaught Place, New Delhi
Technicals Skills

Following technical skills are pre-requisite:
Well versed with Software development methodologies, such as SDLC (Software Development Life Cycle), DDLC (Document Development Life Cycle).
Database schema design and implementation
Should have worked in either of technologies Sql Query/ Tableau/ Excel (Macros)/ Access (Query) writing for data analytics.
For planning and coordinating activities, organizations remain in invariant communication with one another and the data transfer has to be performed efficiently and smoothly as possible.
He/ She should manage the execution of the technologies, help the businesses in utilizing the systems, and should be well versed with the basics of computer systems such as Networking, Installation of necessary software and hardware.
Ability to determine the interrelationships between solutions and requirements.
Ability to think analytically and should be a problem solver and logic building should be very strong.
Good interpersonal skills to form effective working relationships with people at all levels.
Excellent communication and presentation skills and strong written & oral English skills.
To know more about us visit us www.sspl.net.in or write to us at admin@sspl.net.in",-1,Substratal Solutions,Connaught Place,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1500,Artificial Intelligence Scientists,"Experience 2- 4 Years
Salary 4 LPA - 6 LPA
Job Location Chennai

Industry:
IT-Software / Software Services

Keywords:
Artificial Intelligence

About Job:
Must have Excellent knowledge in AI / Machine learning (Mandatory).
Machine learning frameworks like keras, tensor flow etc.
And also other big data tools like Hadoop etc, Must know R and python.
Good understanding in SDLC & Business cycle.",4.0,"Careerera
4.0",Chennai,"Wayland, MA",501 to 1000 employees,-1,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
1501,Senior Data Engineer,"About Us

upGrad is an online education platform building the careers of tomorrow by offering the most industry-relevant programs in an immersive learning experience. Our mission is to create a new digital-first learning experience to deliver tangible career impact to individuals at scale. upGrad currently offers programs in Data Science, Machine Learning, Product Management, Digital Marketing, and Entrepreneurship, etc. upGrad is looking for people passionate about management and education to help design learning programs for working professionals to stay sharp and stay relevant and help build the careers of tomorrow.
upGrad was awarded the Best Tech for Education by IAMAI for 2018-19
upGrad was also ranked as one of the LinkedIn Top Startups 2018: The 25 most sought-after startups in India
upGrad was earlier selected as one of the top ten most innovative companies in India by FastCompany.
We were also covered by the Financial Times along with other disruptors in Ed-Tech
upGrad is the official education partner for Government of India - Startup India program
Our program with IIIT B has been ranked #1 program in the country in the domain of Artificial Intelligence and Machine Learning
About the Role

We are looking for a Data Engineer to help us scale the existing data infrastructure and in parallel work on building the next generation data platform for analytics at scale, machine learning infrastructure and data validation systems.
In this role, you will be responsible for communicating effectively with data consumers to fine-tune data platform systems (existing or new), taking ownership and delivering high performing systems and data pipelines, and helping the team scale them up, to endure ever growing traffic.
This is a growing team, which makes for many opportunities to be involved directly with product management, development, sales, and support teams. Everybody on the team is passionate about their work and we’re looking for similarly motivated “get stuff done” kind of people to join us!

Roles & Responsibilities
Engineer data pipelines (batch and real-time ) that aids in creation of data-driven products for our platform
Design, develop and maintain a robust and scalable data-warehouse and data lake
Work closely alongside Product managers and data-scientists to bring the various datasets together and cater to our business intelligence and analytics use-cases
Design and develop solutions using data science techniques ranging from statistics, algorithms to machine learning
Perform hands-on devops work to keep the Data platform secure and reliable
Skills Required
Bachelor's degree in Computer Science, Information Systems, or related engineering discipline
6 + years’ experience with ETL, Data Mining, Data Modeling, and working with large-scale datasets
6+ years’ experience with an object-oriented programming language such as Python, Scala, Java, etc
Extremely proficient in writing performant SQL working with large data volumes
Experience with map-reduce, Spark, Kafka, Presto, and the ecosystem.
Experience in building automated analytical systems utilizing large data sets.
Experience with designing, scaling and optimizing cloud based data warehouses (like AWS Redshift) and data lakes
Familiarity with AWS technologies preferred
Qualification – B.Tech/M.Tech/MCA(IT/Computer Science)

Years of Exp – 6-9",3.5,"upGrad Education Private Limited
3.5",Mumbai,"Mumbai, India",501 to 1000 employees,2015,Company - Private,Education Training Services,Education,₹1 to ₹5 billion (INR),"Udacity, General Assembly, Springboard"
1502,BBRC-Genomics-Associate Scientist,"JOB DESCRIPTION

Designation: Associate Scientist

Job Location: Bangalore

Department: Translational Medicine- Translational Sciences

About Syngene

Incorporated in 1993, Syngene International Ltd. is an innovation-focused global discovery, development and manufacturing organization providing integrated scientific services to the pharmaceutical, biotechnology, nutrition, animal health, consumer goods and specialty chemical industries around the world. Syngene’ s clientele includes world leaders such as Bristol-Myers Squibb, Baxter, Amgen, GSK, Merck KGaA and Herbalife. Its innovative culture is driven by the passion of its 4240- strong team of scientists who work with clients from around the world to solve their scientific problems, improve R&D productivity, speed up time to market and lower the cost of innovation .

Job Purpose:
To play a key role in TM-TS, develop an early-stage research strategy, initiate and lead discovery programs while managing ongoing programs in TM-TS. The role will work part of TMTS, and work with internal and external collaborators .

Key Responsibilities:
Experience in isolating DNA and RNA from blood, tissues and FFPE samples and cell lines. Experience with optimization of extraction protocols and for parameters like yield, input sample quantities and sample types is important.
Expertise in PCR, qPCR, cDNA/gDNA library preparation. Exposure to microarray techniques.
Proficiency in preparation of libraries for Next Generation Sequencing of transcriptome and genome, with significant experience in optimization of parameters like input RNA/DNA quantities and sample type
Experience with single cell RNA-seq will be plus.
Experience with various NGS protocols (DNA Amplicon based, hybrid capture based low input, degraded DNA and RNA samples e.g. FFPE samples.
Strong understanding of experimental design and statistical principles behind experimental design and differential gene expression. Experience with analysis of single cell RNA-sequencing data will be a plus

Educational Qualification:
M.Sc or M. Tech in Biotechnology, Molecular biology or Biological Sciences,

Technical/functional Skills:
DNA/ RNA Isolation, Expertise in PCR, qPCR, Experience in NGS protocols

Experience:
2 to 5 Years

Behavioral Skills:
A proactive team player.
Ensure completion of experiments and generate accurate and reproducible data from experiments.
Ability to work independently, prioritize tasks and work on multiple projects simultaneously with; comfortable working in a dynamic environment with changing requirements.
Good oral and written communication and presentation skills to work in a multi-disciplinary team
Equal Opportunity Employer:
It is the policy of Syngene to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by applicable legislation or local law. In addition, Syngene will provide reasonable accommodations for qualified individuals with disabilities.",3.5,"Syngene
3.5",India,"BENGALURU, India",1001 to 5000 employees,1994,Unknown,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1503,Applied Scientist 1,"Position Requirements:
Master's degree in Computer Science, Computer or Electrical Engineer, Mathematics, or a related field plus at least one year of experience in the job offered or related occupations of Software Engineer, Software Developer, or a related occupation. Employer will accept a Bachelor’s degree and five years of experience in the job offered or a related occupation as equivalent to the Master’s degree and one year of experience. One year of experience in the job offered or related occupation must involve designing and developing large-scale, multi-tiered, distributed software applications, tools, systems and services using Java, Object Oriented Design and Distributed Programming].

Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, Oracle/Berkeley databases, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills

Amazon Selling Partner Services team drives the Selling On Amazon business and develops solutions that enable millions of sellers around the world to sell on Amazon's Marketplaces. More than half of shipments for Amazon customers are generated from this business. The team is focused on building a technology platform that will support the explosive business growth in existing markets, streamline the business for Amazon and the Selling partners and launch business in new markets and establish a fair marketplace.

Our team is seeking engineers with broad technical skills to help us optimize how we synthesize massive amounts of data and complex business rules into mission critical financial information. As a member of this team you will employ object oriented techniques in Java, and DynamoB, PostGres and ElasticSearch skills to help us support Amazon's next generation of selling partner services. Along the way you'll gain and leverage a unique understanding of how Amazon.com works; from the numerous software systems that comprise the website's back-end, to the details of our business model, and the relationships we're establishing with an ever-growing network of selling partners who depend on Amazon.com to run their businesses.

The ideal candidate will draw upon exemplary analytical, critical thinking, and problem solving skills, and a passion for maintaining highly reliable, distributed systems which operate 24/7/365. Successful members of this team collaborate effectively with internal end-users, aggressive cross-functional software development teams, and technical support/sustaining engineering teams to solve problems and deliver successfully against high operational standards of system availability and reliability. We look for engineers who are excellent communicators, self-motivated, flexible, hardworking, and who like to have fun!

Position Responsibilities:
Participate in the design, development, implementation, testing and documentation of large-scale, multi-tiered, distributed software applications, tools, systems and services using [Java, Object Oriented Design and Distributed Programming]. Translate functional requirements into robust, scalable, supportable solutions that work well within the overall system architecture. Participate in the full development cycle, end-to-end, from design, implementation, and testing to documentation, delivery and maintenance. Produce comprehensive, usable software documentation. Evaluate and make decisions around the use of new or existing software products and tools.

Preferred Qualifications
Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1504,Senior Clinical Data Analyst,"About Novotech:

Novotech is internationally recognised as the leading independent and full-service contract research organisation (CRO) in the Asia Pacific region. We provide a wide range of clinical development services across all research phases and therapeutic areas and have been instrumental in the success of hundreds of Phase I – IV clinical trials throughout the Asia Pacific. Powered by the highest quality people, Novotech strives to set the benchmark for both business and clinical trial performance. Our people are one of our key strengths. We value our people and recognise the work they do. We are lucky to have the best people and talent from across the Asia Pacific region work together to deliver to clinical trial success for our clients. Our people and those we look to recruit have an attitude of making things happen. They are problem solvers, driven with a focus on delivering quality, accountability and a high level of performance.

Brief Position Description:

As part of Novotech’s Biometrics unit, the Senior Data Analyst (SDA) is responsible for all data analysis and business intelligence activities related to study related clinical and operational data. The SDA acts as primary point of contact for all data analysis matters to the study team and is responsible for the timely delivery of quality outputs following all applicable regulatory, compliance, best practice and operational procedures.

Minimum Qualifications & Experience:

Graduate in information science, data science or life science-related field, or similar. More than five years’ experience in a senior role related to data science, data analysis, clinical data management or clinical data programming in a pharmaceutical company, CRO or EDC software provider.

Responsibilities
The Senior Data Analyst (SDA) is responsible for providing technical, procedural (SOPs) and planning leadership across multiple projects assigned to the data analyst team members ensuring that they deliver in accordance with SOPs, programming best practices, and the timelines agreed within the Project Team.
Collaborate with cross-functional stakeholders to implement data science solutions to solve business needs using available technological solutions.
Scope data analysis effort for projects and project manage all data analysis activities across multiple projects for different study stakeholders.
Gather study requirements from data management for data review and external data reconciliation and provide guidance on appropriate outputs (dashboards, visualisations, listings, reports).
Extract, assess, integrate, transform data sources to provide data visualisation outputs for analytics.
Design and develop prototypes and final versions of data outputs (dashboards, reports, visualisations, listings) using Business intelligence tools and Data Visualisation tools.
Design and develop standard dashboards and content for different audiences.
Analyse, manipulate and understand data from multiple sources to present and create dashboards and reports to make business decisions.
Assist teams on best-practice for data visualisation dashboard development.
Educate teams on how to use all the features of applicable data visualisation platform in conjunction with data visualisation dashboards.
SME for the data visualisation development and assisting team members.
Identify and communicate project risks and maintain documentation within project files as appropriate
Represent data analysis group at internal / external meetings as appropriate.
Assess and implement new data analysis, BI and data visualisation processes and technologies.
Take an active role in the development of best practices, process improvement, quality control and governance related to all data analysis matters.
Provide training and mentoring to Data Analysis of team members in SOPs, software applications, and best practices.
Provide Subject Matter Expertise on all data analysis and visualisation related activities.
Attributes and Skills

Expert knowledge of clinical study data structures and schemas of EDC databases. Expert knowledge in data processing activities such as extracting, integrating, transforming and presenting data. Statistical Programming skills in Python, R or similar. Knowledge of SQL and EDC systems. Working knowledge of Spotfire, Power BI, Tableau or other data review and visualisation tool. Ability to gather business requirements from multiple stakeholders and clients and provide guidance on the use of appropriate data visualisations.

Experience mentoring and training others. Awareness of regulatory and compliance issues and understanding of the application of SOPs and Quality Control to daily activities. Excellent analytical, communication and problem-solving skills.

Opportunities and Benefits:

To deliver clinical trial and research excellence for our clients, our people are 'best in class'.

At Novotech, we seek and nurture people with exceptional talent. We are committed to providing our people with regular internal and external training, a competitive bonus structure and a supportive work environment. We are also focused on providing our people with a wide variety of career growth and development opportunities.

For more information about where your next career step at Novotech might take you, visit http://novotech-cro.com/novotech-careers",4.5,"Novotech
4.5",Bengaluru,"Sydney, Australia",501 to 1000 employees,1996,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
1505,Data Engineer,"Data Engineer Responsibilities:
Liaising with coworkers and clients to elucidate the requirements for each task.
Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed.
Reformulating existing frameworks to optimize their functioning.
Testing such structures to ensure that they are fit for use.
Preparing raw data for manipulation by Data Scientists.
Detecting and correcting errors in your work.
Ensuring that your work remains backed up and readily accessible to relevant coworkers.
Remaining up-to-date with industry standards and technological advancements that will improve the quality of your outputs.
Data Engineer Requirements:
Bachelor's degree in Data Engineering, Big Data Analytics, Computer Engineering, or related field.
Master's degree in a relevant field is advantageous.
Proven experience as a Data Engineer, Software Developer, or similar.
Expert proficiency in Python, C++, Java, R, and SQL.
Familiarity with Hadoop or suitable equivalent.
Excellent analytical and problem-solving skills.
A knack for independent and group work.
Scrupulous approach to duties.
Capacity to successfully manage a pipeline of duties with minimal supervision.
Job Type: Full-time

Salary: ₹360,000.00 to ₹870,000.00 /year

Experience:
total work: 2 years (Preferred)
Data Engineer: 1 year (Preferred)
Education:
Diploma (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,Futurious Technologies,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1506,Quantitative Analyst,"The successful candidate will be a highly analytical individual with hands on programming skills. The candidate will work closely with the research team and clients towards the ongoing development and integration of new investment strategies, models and tools on Axle

Location

Mumbai
Responsibilities

Perform daily/weekly/monthly tasks of performance and risk reporting
Develop and automate investment processes and strategies via VBA and Matlab
Develop tools to integrate trading decision systems with risk management systems
Ad hoc tasks (such as operational tasks, internal documentation tasks and preparation of marketing materials)
Skills/Experience

Excellent programming skills in Matlab/Excel-VBA
Thorough with financial concepts and calculations like Drawdown, VaR, Eloss etc.
Understanding of financial market products like options, futures, FX forwards etc.
Working knowledge of Bloomberg is preferred
Should be self-driven and detail oriented with an analytical mindset
Should be a proactive and quick learner; a team player showing enthusiasm and drive to accomplish results in a fast paced environment
Min. 2 years of relevant work experience
Qualifications

B.Tech/M.Tech/MBA/CFA/FRM",5.0,"B&B Analytics
5.0",Mumbai,"Zug, Switzerland",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1507,Analyst - Data Scientist,"Job Summary

Experience:
3 - 5 Years

Location:
Mumbai

Designation:
Analyst - Data Scientist

Degree:
BE-Comp/IT, BE-Other, BTech-Comp/IT, BTech-Other, ME-Comp/IT, ME-Other, MTech-Comp/IT, MTech-Other, PhD-Comp/IT, PhD-Other

Educational Level:
Graduate/Bachelors

Industrial Type:
IT-Software/Software Services

Functional Area:
IT Software - Application Programming / Maintenance

Key Skills:
Data Scientist

Job Post Date:
Thursday, March 19, 2020

Company Description

We are capability centre based in Mumbai, initially started as a back-office operational support to the UK business unit.

However, over the recent years, we have significantly increased the breadth and depth of our capabilities and offerings to keep pace with the changing needs of the Group. These include Digital & Knowledge Services, Finance and Actuarial, Information Technology (IT), Customer Service, Risk and Audit.

Our core purpose is to be a strategic partner to company, enabling growth by delivering change and driving synergies through a highly capable and agile workforce.

With our diversified service offerings we provide our people with exciting opportunities to grow personally and professionally.

Company is a leading savings and investments business serving around 5.5 million retail customers and more than 800 institutional clients.

It-s innovative asset management and customer solutions are supported by extensive investment capabilities, an international distribution network and two strong brands.

Job Description

3 – 5 yrs experience as Data Scientist
Should have at-least 1 end-to-end ML project experience
Very high proficiency in R or Python
Excellent in forecasting methods like simple exponential smoothing, multiplicative seasonal indexes, simple and weighted moving averages and time series forecasting methods
Exposure to with advanced deep learning techniques such as LSTM. CNN, Dense neural networks as well as neural networks design and implementation through tools like tensorflow, keras, pytorch, deepai or equivalent.
Good SQL experience",3.8,"Sampoorna Computer People
3.8",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
1508,Data Lake Developer,"For Us, It's A Mission

At Mylan, we mean it when we say we work every day to provide access to high quality medicines to the world's 7 billion people. If you are unconventional, relentless and passionate. If you believe in doing what's right, not what's easy. If you are a doer and have a passion for serving others, we want to talk to you.

Make a Difference

At Mylan, each person has the ability to make a difference. From the providers who sell and market our products, to the producers who develop and manufacture them and finally to our business partners who support the providers and producers, we all have a mission critical role. Here's how this role will help:

ESSENTIAL DUTIES AND RESPONSIBILITIES
To perform this job successfully, an individual must satisfactorily perform each essential duty. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential duties.
1. Create and maintain optimal data pipeline architecture on Azure platform.
2. Develop batch processing solutions by using Data Factory and Azure Databricks.
3. Delivering a Data Warehouse in the Azure Cloud.
4. Design relational and non-relational data stores on Azure.
5. Identify, design, and implement internal process improvements : automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc..
6. Developing Big Data Solutions with Azure Machine Learning.
7. Strong interaction with business departments to provide consultative support for digitization efforts, as well as close collaboration with the Business Technology management, focused on future innovation topics.
8. Participate and lead in design sessions, demos and prototype sessions, testing and training workshops with business users and other IT colleagues.
9. Design & Build for any API Development or SQL DB development.
10. Providing service management, orchestration, monitoring and management requirements of Azure cloud platform.
11. Create data tools / products for analytics and data scientist team members that assist them in building and innovative solutions that drive tangible business value.
12. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
13. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
14. Design security for source data access. Chose the appropriate authentication mechanism, (ie Azure Active Directory (Azure AD), etc).
15. Design for real-time processing by using Stream Analytics and Azure Databricks.

Make Our Values Your Values

Mylan hires only the best. People who thrive in a culture of innovation and empowerment. People who are active learners and have a positive attitude. People who are leaders and know that by working together we can run faster, reach higher and achieve more. By doing so, we will continue to set new standards in health care. Here are the minimum qualifications and essential functions for this position:

QUALIFICATIONS

The qualifications listed below are representative of the minimum knowledge, skill, and/or ability required.

SKILLS AND ABILITIES

1. 10 years of experience in Microsoft technologies including SQL.

2. At least 5 years as a Sr Developer with at least 3 years hands on experience as Azure Data Engineer building large scale Azure data solutions.

3. At least 5 years of experience in Azure based data solutions.

4. At least 3 years of experience on working with large projects including the most recent project in the cloud (Azure) or on prem with a focus on Azure Data services.

5. At least 5 years of Hands-on administration, configuration management, monitoring, performance tuning of Hadoop/Distributed platforms.

6. At least 5 years of demonstrated experience at least in the most recent 2 years of designing and delivering solutions using Cortana Intelligence suite of analytics services part of Microsoft Azure including Azure Machine Learning Studio, HDInsight, Polybase, Azure Data Lake Analytics, Azure Data Warehouse, Streaming Analytics, Data Catalog, R/R Studio

7. Experience in designing and building logics required for optimal extraction, transformation, and loading of data from a wide variety of data sources

8. Experience within Data Security design, including but not limited to:

a. Choosing the appropriate authentication mechanism, such as Azure Active Directory (Azure AD)

b. Defining strategies for data encryption for data at rest and in transit

9. Experience partnering with Business Analysts and Data Scientists to enable effective and efficient data preparation and delivery

10. Experienced in vendor management and working with 3rd parties onshore & offshore.

11. Experience working in a global team.

12. Experience working in an Analytics / Big Data solutions on MS Azure Cloud

13. Experience with code management tools, automated testing

14. Experience creating and maintaining optimal data pipeline architecture on Azure platform

15. Experience developing batch and real-time processing solutions by using Data Factory and Azure Databricks

16. Familiar with AGILE and Azure DevOps methodology

17. Hands on PoC capabilities are needed to prove a particular architecture concept

18. Azure Native Services experience across Data Fabric and Service Fabric

19. Experience in Application modernization from legacy on-premise data architecture platform technology stack to modernized Azure Cloud base Architecture.

20. Experience with Git, NoSQL Data Solutions, Microsoft Azure, HD Insights, Azure ML, DataBricks ML Flow, R or Python.

21. Must have excellent communication skills.

EDUCATION/EXPERIENCE (Note: Please select one)

Minimum of a Bachelor's degree in Computer Science and Engineering is preferred with minimum 10 years of experience. However, a combination of experience and/or education will be taken into consideration

Why Mylan?

If you want to be part of a global health care company that is making a difference and changing lives, Mylan may be the place for you. With a workforce of more than 35,000 worldwide, we can make a difference. We encourage you to visit Mylan.com to learn more about our unconventional culture, our approach to doing business and how we plan to set new standards in health care.

Mylan offers competitive salary, excellent benefits and an environment conducive to professional growth and advancement. All qualified applicants will receive consideration for employment without regard to their disability or protected veteran status. Mylan is an Equal Opportunity Employer, Minorities/Female/Disabled/Veteran.",3.8,"Mylan Inc.
3.8",Bengaluru,"Hatfield, United Kingdom",10000+ employees,1961,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1509,Off Campus Recruitment - Quantitative Researcher,"Description:
Graviton is a privately funded quantitative trading firm striving for excellence in financial markets' research. We are seeking fresh talent from the top IIT's to join us as Quantitative Researchers for our team in Gurgaon.If you are a student graduating in 2020 from Computer Science , Electrical or Maths Stats Computing streams with a greater than 8 CGPA please apply here.

This role is open to students from campuses that we could not visit this year. Please check your individual placement policy restrictions before applying.

Graviton trades across a multitude of asset classes and trading venues using a gamut of concepts and techniques ranging from time series analysis, filtering, classification, stochastic models, pattern recognition to statistical inference analysing terabytes of data to come up with ideas to identify pricing anomalies in financial markets.

As a Quantitative researcher your responsibilities will include

Develop new or improve existing trading models using in-house platforms

Use advanced mathematical techniques to model and predict market movements

Analyse large financial datasets to identify trading opportunities

Provide real time analytical support to experienced traders

Requirements :
Possess a degree in a highly analytical field, such as Engineering, Mathematics, Computer Science from IITs schools

Quantitative bend of mind

A working knowledge of Linux/Unix

Programming experience, preferably in C++ or C

Strong interest in learning about financial markets.

Have a strong work ethic

Hard Working

Benefits:
Our open and casual work culture gives you the space to innovate and deliver. Our cubicle free offices , disdain for bureaucracy and insistence to hire the very best creates a melting pot for great ideas and technology innovations. Everyone on the team is approachable, there is nothing better than working with friends!

Our perks have you covered.

Competitive compensation

6 weeks of paid vacation

Monthly after work parties

Catered breakfast and lunch

Fully stocked kitchen

Gym membership

International team outing",5.0,"Graviton Research Capital LLP
5.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2014,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1510,Data Engineer,"Zauba Technologies is a startup based in Bangalore. Zauba's services are used by leading companies in India. Zauba is powered by a young and passionate team. We are looking for individuals who would like to be a part of our founding team.

As a Data Engineer and as a part of founding team, you will be expected to visualise and develop disruptive data products. Eventually you would be responsible for entire project lifecycle of products you would visualize. Your rewards will be directly proportional to the value you generate.

Job Responsibilities
Design and development of robust, scalable and highly efficient data engineering solutions for structured and unstructured data (Including gathering and processing raw data at scale, writing scripts, web scraping, calling APIs, writing SQL queries, etc.)
Develop processes for text mining and extraction of information from unstructured data
Design, architect and develop efficient data pipelines around the data collected
Take ownership of existing web product and applications
Design and implement data models that scale across the enterprise
Take ownership of existing data workflows and processes
Enhance scalability, performance, and stability of existing infrastructure
Work closely with other team members to integrate your innovations and algorithms into our production systems

Essentials
Java/Python - Intermediate to advanced level
SQL - Advanced
MySQL Intermediate to advanced level
Regex - Basic to intermediate level
Linux Basic to intermediate level

Good to have
Hadoop/Spark
R
MongoDB

Must have qualities
Skills to learn new skills quickly
Desire to create disruptive products and services
Passion - not just to work in startups but to take them to next level
Above average programming aptitude
Be passionate about producing high quality engineering deliverables
Be productive working independently or collaboratively
Have an eye for building efficient processes
Be self motivated
Proactively take ownership

Interested?

Send your resume to hr@zaubacorp.com",3.8,"Zauba Corp
3.8",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 million (INR),-1
1511,Quantitative Research,"We are looking for highly trained professionals who are interested in applying advanced mathematical quantitative methods to the modeling of global financial markets. You would be joining a group made up of highly proficient individuals from various scientific disciplines. We have a spectrum of opportunities for individuals with the right scientific skills. Experience in finance is not required.

The ideal research candidate will have:
A Ph.D. in Computer Science, Mathematics, Physics, Statistics, or a related technical discipline.

A demonstrated capacity to do first-class research.

Computer programming skills.

An intense interest in applying quantitative analysis to solve difficult problems.

Send us a copy of your resume to
careers@dolatcapital.com

For internship opportunities, please send us a copy of your resume to
careers@dolatcapital.com",4.0,"Dolat Capital
4.0",Mumbai,"Mumbai, India",51 to 200 employees,1970,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1512,Data Engineer,"Bachelor’s degree in Computer Science or related field
5+ years relevant experience
5+ years experience with SQL, SQL Tuning, Oracle, OLAP, Big Data Technologies
5+ years experience developing end-to-end Business Intelligence solutions: data modeling, ETL and reporting
Experience with Java and experience with scripting languages like Perl, Python, Unix shell scripts,VBA and MS Excel
Proficiency with Linux and systems administration
Proven ability at looking at solutions in unconventional ways. Sees opportunities to innovate and can lead the way.
Top notch communication (verbal and written) and interpersonal skills to convey key insights from complex analysis in summarized business terms and an ability to effectively communicate with technical teams.
Ability to work with shifting deadlines in a fast paced environment.
Operations Finance Technology team, responsible for building technical solutions for multi-billion WW Operational Cost analytic including Inbound cost (Receiving / PO), variable Cost, fixed cost, outbound (Customer Shipments / Transportation), and Customer Service, is looking for a Data Engineer.

As a data engineer, you will get the exciting opportunity to work on very large data sets in one of the world's largest and most complex data warehouse environments. You will work closely with the business teams in analysis on various cost savings initiatives, many non-standard and unique business problems and use creative-problem solving to deliver actionable output.
You will be responsible for designing and implementing an analytical environment using third-party and in-house reporting tools, modeling metadata, building reports and dashboards. You will have an opportunity to work with leading edge technologies like Redshift, Hadoop/Hive/Pig. You will be writing scalable queries and tuning performance on queries running over billion of rows of data.

You should be analytical, have an extremely high level of customer focus and a passion for process improvement. You should be motivated self-starter that can work independently in a fast paced, ambiguous environment. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions.
Bachelors in Computer Science or related field
Practical Knowledge of Linux or Unix shell scripting
Experience in working with business customers to drive requirements analysis
Exposure to large databases, BI applications, data quality and performance tuning
Excellent written and spoken communication skills
Experience with Hadoop-based technologies such as HBase, Pig, Hive and Spark
Strong proven ability in building high-performance, highly available and scalable data solutions using Oracle and/or Hadoop-based technologies
Knowledge of data warehousing concepts.
Strong sense of ownership, urgency, and drive
Strong troubleshooting and problem solving skills
Experience with Amazon Web Services",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1513,DATA ANALYST,"posted by Mahima Gaur

2 - 5 years Delhi

Job Description
Experience in data processing
Experience in data cleaning and data tabulation activities
Strong analytical, communication and team management skills
Strong understanding of data management using SPSS and research techniques
Competency in a Tabulation software (decipher / wincross / quantum etc), Excel, Powerpoint
Ability to summarize findings, draw conclusions, and put together a presentation using Powerpoint
Role Category : Data Analyst

Employment Type : Permanent Job, Full Time",4.9,"Knowledge Excel Services.
4.9",New Delhi,"New Delhi, India",1 to 50 employees,2007,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
1514,Data Engineer,"Key skills : Python , Spark , SQL , Pyspark • AWS platform used for the work • Strong experience in SQL is mandatory • Good familiarity of AWS landscape • Good experience in collecting business requirements & design them as per requirement from customer • Should able to work independently & interact business users & technical stakeholders • Strong communication skills both oral & written. • Should work as an individual resources",3.5,"Larsen & Toubro Infotech Limited
3.5",India,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1515,Big Data Engineer,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
1516,Client Data Analyst,"At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.
What is the Client Data Analyst – Client Analytics group responsible for?
This team manages business data to ensure accurate, timely, consistent and compliant data. Their contributions deliver quality data that is easily accessible and can be trusted. Key downstream capabilities such as reporting and analytics depend on this as well as operational data access on various systems. The Data Management Team is a support function that acts as an advocate and a point of contact for Sales and Marketing data.

What are the ongoing responsibilities of an Client Data Analyst ?
Understand the data flow, key consumption and production of data as well as context within the enterprise:
Build positive relationships with teams, especially the key data consumers and analytics. Take the time to increase knowledge of how they run their business and incorporate sales data into daily work
Connect regularly with each sales office to understand current issues and challenges. Probe the business and validate against other sales offices to understand the scope and priority of the issue
Make recommendations on how data unifications and flow can be used to improve business tasks. Liaise business partners to deliver solutions (reports, processes, technology) that add value.

Provide data management subject matter expertise. Appreciate the connection and data flow between applications and other corporate systems. Be able to clearly articulate the data needs and move initiatives forward by collaborating with business partners:
Actively participate in meetings with business partners to ensure that priorities are clearly understood, information is regularly shared and that key participants are “kept in the loop”
Provide context and background on issues. Collaborate on ideas for progressing initiatives. Ensure appropriate resources are involved to take initiatives forward
Provide insights and expertise to scope statements and requirements documentation
Actively consult or participate in the user acceptance testing process (test cases, documentation, testing execution, etc.)
Ensure business needs remain aligned with overall corporate initiatives and deliver the benefits as originally intended

Monitor the integrity of data and usefulness of reports. Ensure the information available within systems is accurate and up-to-date. Proactively seek data cleansing opportunities and evolve data to better support. Document and maintain ongoing processes for reporting and data clean-up:
Partner with all key data consumers to gain a solid understanding of usage and challenges around data. Establish processes for prioritization of enhancements, especially with the analytics groups
Provide 1st level support for data issues and data maintenance for owned data
Verify and execute data loads into our internal sales systems and ensure any upstream systems accurately receive their data

Increase awareness and promote data management capabilities. Share best practices and provide coaching to local offices on how to access and incorporate output into sales tasks. Encourage IAS leaders to leverage data to make more informed, strategic decisions:
Clearly articulate the goals and core services of the data management team. Proactively promote this information within IAS and ensure business partners understand the data management role within the organization
Share best practices and provides guidance on data capabilities. Reinforces ownership and accountability for data accuracy
Seek opportunities to share the benefits of leveraging sales data to make more informed business decisions

What ideal qualifications, skills & experience would help someone to be Successful?

Knowledge, Education And Experience:
Four year bachelor’s degree required (majors of preference include: business, computer science, mathematics) Advanced degree a plus
Understanding of the Franklin Templeton business model, how FT makes money, the sales process, how technology fits in with the business, etc. Knowledge of the GAS (Global Advisory Services) structure
Experience working through multiple business fiscal cycles; exposure and/or direct experience with project management and/or sales-related-capacity required
Prior work experience related to analytics, sales, marketing and/or international a must. Level will not be granted based on years of experience but will be determined by the employee’s ability to meet each job activity as outlined the ‘typical/expected focus by level
Skills And Abilities:
Ability to communicate effectively with all levels of management; ability to tailor communication style based on audience; ability to get others to want to collaborate with you; strong facilitation skills
Excellent writing skills (for presentations, documentation, etc.)
Working knowledge of the CRM, MDM, Excel, SQL, Power BI, Tableau, Business Objects, and Microsoft Products (PPT, Power Apps, Doc, Visio)
Ability to absorb and interpret large quantities of data; apply trend analysis and knowledge of the business to develop a meaningful and digestible summary with the appropriate level of detail
Ability to take a larger problem and break down the individual components; identify how to go about solving the problem and who to involve in the process
Ability to present recommended solutions to a variety of issues and problems (solutions that are consistent with organization objectives)
Must be extremely detail-oriented (managing lists, tasks/to-dos, etc.) good with follow through on own items; good with following up with others on outstanding item

What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.

Highlights of our benefits include:

Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.",3.8,"Franklin Templeton Investments
3.8",Hyderabad,"San Mateo, CA",5001 to 10000 employees,1947,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Fidelity Investments, Vanguard"
1517,Data Analyst,"Roles and Responsibilities:
Extracting, transforming and inputting data sets from various resources. Creating predictive models, translating non-technical aspects into quantifiable tasks. Analysis and representation of output data, highlight and explain trends and patterns, error elimination, using advanced statistical methods (regression, probability distribution, clusters etc.) to provide accurate results.
Data collection, Data Mining, Report generation, Problem identification and solution formulation Market analysis and establishing trends, Strategy development and implementation

Skills:
Extremely good analytical skills.
Good working knowledge of all MS-Office products, especially Advance Excel, Word, PowerPoint, MS-access.
Statistical tools and methods.

Interested candidates can send the updated resume on satish.mehra@exelaonline.com or call on 7722028636
00-7.00 Years",2.6,"Exela Technologies
2.6",Pune,"Irving, TX",10000+ employees,2017,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"SourceHOV, BancTec, Transcentra"
1518,Data Modeler,"• Minimum 5-8 years of working experience as Data modeler.
• Data modelling experience in designing.
• Minimum 2-3 years real time experience in Erwin tool is mandatory.
• Experience in normalized modeling techniques.
• Experience in designing the Start schema.
• Experience working in ORACLE.
• Experience with database design, capacity planning, performance tuning and query optimization.
• Experience in working with Bank or Banking and Finance or Financial domain.
• Excellent communication skills with leadership quality.

Job Segment:
Database, Oracle, ERP, Technology",3.5,"LTI
3.5",Mumbai,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1519,Machine Learning Engineer,"Looking for Data Scientists with Python/R Programming skills.
Specific experience in AI areas like Statistical Machine learning / Deep learning / Natural Language Processing (NLP)/ Operations Research (Optimization) will be an advantage.Individual in this role is expected to work with multiple stakeholders and teams

Qualifications and Requirements:-
Previous working experience as a Machine Learning/ Data Scientist for 2 years
MA in Computer Science or similar relevant field
Hands on experience with MALLET
In depth knowledge of Apache Tomcat/Open Source
Excellent project and time management skills
Attention to detail
Outstanding problem solving and analytical skills",-1,Tekolutions.ai,India,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1520,Data Science Internship,"About the company:
SkillBit is a leading staffing and recruitment company engaged in talent searching assignments for skilled and talented candidates for the industry.

About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Working on data science algorithms and AI concepts 2. Using Python or R for web scraping 3. Building AI models using Python, machine learning, and deep learning algorithms 4. Processing of unstructured/structured data

Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 6th Jun'20 and 11th Jul'20
are available for duration of 1 month
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply

Number of internships/jobs available: 3

Categories: Data Science",-1,SkillBit,Pune,-1,-1,-1,-1,-1,-1,-1,-1
1521,Data Engineer,"As a data engineer at TEAL, you'll be taking the plunge into a rich data lake that includes everything from satellite data to legal court orders. You'll be hustling and getting your hands dirty with every part of the data pipeline always having an implicit appreciation for how all of this data will ultimately power a revolutionary real estate risk platform.

Your day-to-day will include either all or some of the following:

Constantly scoping out new data sources to complement existing ones
Creating and maintaining distributed web scrapers using Python, RabbitMQ and other technologies
Architecting and managing data pipelines where data flows into multiple end-points including, but not limited to, Postgres, MongoDB and Apache Solr
Documenting workflows and constantly iterating to create better data infrastructure.

We'd love it if you:
Are proficient in Python or any other object-oriented language
Have worked with large (millions to hundreds of millions of rows in a SQL database) interdisciplinary datasets
Have scraped difficult websites and have some experience working with various data APIs
Are patient and methodical with unstructured and messy data
Are always hungry to learn newer and better technologies to make the data ecosystem faster, smoother and less silo-ed

Extra brownie points if you:
Have some experience working with large-scale search indexing
Have performed geospatial analyses in some capacity
Have created and managed data lakes in the cloud
Culture

To explore our culture and the values we embody click here

Testimonials
Testimonial

My experience at TEAL surpassed all my expectations from the get-go. I was asked to help solve one of the most daunting problems in the Indian real estate market. Every day while working on a subset of the problem, the ideas that I brought to the table were shaped into cohesive solutions by a collaborative team effort. At TEAL I was exposed to the most cutting edge technologies such as Cloud Computing, Big Data, ML and Data Science. The growth opportunities at TEAL are tremendous, If you are innovative and can demonstrate the will to realize your ideas, TEAL is an amazing organization to work for.
Gyan Vardhan, Data Science Intern
I had interned as a Data Scientist at Terra Economics and Analytics Lab during its early days, it was a rich learning experience working with a multi-disciplinary team who are extremely passionate about building a decision support platform for the insanely complicated realty market in India. It was exciting and challenging to work on mining huge volumes of property records; extracting patterns from the data, building data pipelines and brainstorming on building the core system. TEAL offers a very healthy work environment coupled with insanely talented people working together in an exciting setting.
Naga Anjaneyulu, Data Science Intern
I worked as a full-time Data science intern at TEAL. During this period, I got an opportunity to leverage my skillsets while also learning new technologies, working on tasks assigned to me. The company operates on the latest tech-stacks and gives opportunities to learn as much as you want. The work environment is challenging, the team at TEAL is super supportive and new ideas are always welcome. It has all the good perks of a startup; creativity and innovation, casual work atmosphere and a collaborative approach to solving problems. Personally, I loved working there, my experience was fantastic!
Archana Parmar, Data Science Intern
As a second-year college student, I was looking for an internship that would allow me to delve deeper into research and work with big data, TEAL gave me the perfect opportunity to do so, enabling me to develop proficiency in research and analysis. As a research analyst intern, I collated and cleaned data and helped in the preparation of reports and presentations, and I had members helping me at every stage of this process. This collaborative environment allowed me to cultivate my skills and also learn from my peers. The holy trinity of Rohan, Kshitij, and Shreyas served as not only excellent mentors and bosses but also as friends, helping me at every stage and giving us all food and ice cream to keep us going!
Arush Mehra, Research Intern
Internships are a crucial part of one’s early career. The internship experience at TEAL was a thrilling rollercoaster ride to say the least! It was more than implementing a standard model or building an already though out concept into reality. It was about finding the solution to a unique and open-ended problem.It was exciting to work on addressing a problem with far -reaching real world applications.Moreover, the work environment had the perfect balance of casual yet professional which kept you focused and stress free at the same time. Out of every 100 startups in India only 2 of them succeed, but there are very few like TEAL India which are bound to make it big at such an early stage.
Divyanshu Agarwal, NLP Intern",4.7,"Terra Economics & Analytics Lab (TEAL)
4.7",New Delhi,"Bengaluru, India",1 to 50 employees,2018,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
1522,Senior Consultant - ModellingOps Data Engineer,"Job Title: Senior Consultant - ModellingOps Data Engineer
Location: TRIL GTC
GCL: D1

JOB DESCRIPTION:

AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. The Science & Enabling Units IT is AZs global IT capability function supporting key business areas operating out of sites across the US, UK, Sweden, India & Mexico.

We are looking for AI Ops consultant who will leverage tools & technology best practices to improve delivery performance & data engineering capabilities in the D&A space.

ROLES & RESPONSIBILITIES:

7-10 years of experience in IT Operations involving Data Science, Artificial Intelligence-Machine Learning and Predictive Analytics. Experience in architecting and implementation of end-to-end AIOPs solutions through ELK stack, Splunk. Experience in applying statistical methods, analysis, pattern recognition and modeling on IT Operational data using ELK machine learning. Experience in extracting meaning full data from incoming data streams from different sources through RegEx, Grok etc. Hands-on experience in applying machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc in the IT Operation domain. Experience with machine learning and statistical programming languages - Python, R etc. Experience in assessing the existing IT environment and providing recommendations to reduce the critical applications impacting incidents. Experience in exploring and identifying areas where manual tasks can be automated in IT environment. Experience with various Enterprise IT monitoring solutions including Infrastructure monitoring, Application Performance Monitoring, Network Monitoring, Cloud monitoring etc. Experience in IT Service Management including Service Desk, Incident Management, Change Management, CMDB etc. Excellent knowledge on various IT infrastructure components that includes Server Infrastructure, middle ware, database and application architectures and Cloud Components. Experience/knowledge on Infra monitoring tools - NOI, Zabbix, AppDynamics, Datadog, SCOM, SolarWinds etc. and Service Management tools -IBM Control Desk, BMC Remedy, ServiceNow etc. Experience/Knowledge on BI tools Knowledge on distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc. Knowledge on other programming languages/scripting: Python, Java, JavaScript, etc. ( Added Advantage ) Good analytical skills, strong communication skills are must. Client facing experience is an added advantage. Excellent experience in understanding the problem statement, architect and designing the solution

MANDATORY SKILLS:
Significant experience with AWS cloud environments, working knowledge of Google and Azure platforms. Knowledge of Kubernetes, S3, EC2, Sagemaker, Athena, RDS and Glue is essential.
Experience provisioning computational resources in a variety of Cloud environments using Infrastructure as Code.
Experience with best practice of data transport and storage within cloud system.
Experience building large scale data processing pipelines. e. g. Spark and SQL.
Experience with containers and microservice architectures e.g. Kubernetes, Docker and serverless approaches.
Excellent working knowledge in DevOps, using continuous integration and continuous development.
Use of Data Science modelling tools e.g. R, Python, SAS and Data Science notebooks (e.g. Jupyter).
Good written and verbal skills, fluent English
DESIERED SKILLS:
Agile practices, especially being a SCRUM Master
EDUCATIONAL BACKGROUND: B.E/B.Tech/MCA

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",3.9,"AstraZeneca
3.9",Chennai,"Cambridge, United Kingdom",10000+ employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Roche, GlaxoSmithKline, Novartis"
1523,DATA ENGINEER,"JOB DESCRIPTION
As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements, and also research new uses for data acquisition. You should also know the ins and outs of the industry such as data mining practices, algorithms, and how data can be used.

DESIRED CANDIDATE PROFILE
An ideal candidate must possess prior experience leading a project.

Candidates must have:
> Experience in Hive, Spark, Scala, AWS DynamoDB, HBase, AWS Glue, Talend, Kafka, Snowflake ETL
> Strong experience in a BI/Data Warehouse environment with involvement in design, development, implementation, troubleshooting and support of ETL process using ETL tool.
> Experience in developing Data Marts, Data warehousing and Operational Data Store (ODS) on any of the databases or Hadoop environments.
> Experience in database like MS SQL, MySQL, Oracle, PostgreSQL
> Good to have programming experience in writing Complex Stored Procedures, Queries, Views, User Defined Functions, Cursors and Common Table Expressions using SQL or T-SQL.
> Experience in Performance Tuning and Query Optimization by Indexing, Partitioning and De-normalization.
> Experience in Developing a framework for ingesting data into Data lake
> Good database knowledge, analytical thinking
> Design, construct, install, test and maintain data management systems.
> Build high-performance algorithms, predictive models, and prototypes.
> Develop set processes for data mining, data modeling, and data production.
> Experience with cloud services: AWS (EC2, EMR, S3, Athena) and scripting languages like Python, /PySpark/R/SAS
> Install/update disaster recovery procedures.
> Experience in Agile Application Development & Scrum methodologies is preferred
> Ability to supervise and mentor junior developers on the team.
> Must be self-motivated and work well pulling people together in addition to being able to pull people together technically
> Demonstrated proficiency of troubleshooting techniques and detail-oriented problem diagnosis
> Ability to handle responsibility, is self-directed, with strong organizational and documentation skills
> Ability to work independently and efficiently under aggressive deadlines to meet project commitments
> Excellent verbal and written communication skills

EDUCATION
UG - B.Tech/B.E. - Computers, Electronics/Telecommunication, Diploma - Computers, Electronics/Telecommunication, B.Sc - Computers, BCA - Computers) AND (PG - M.Tech - Computers, Electronics/Telecommunication, MCA - Computers, M.Sc - Electronics, Computers) AND ( Doctorate - Any Doctorate - Any Specialization, Doctorate Not Required).

OTHER DETAILS
Number of vacancies: 4
Experience: 3 years
Location: Cochin

If you have a passion towards technology and coding, then we have the right job for you. Kindly forward your resumes to
Email: jobs@mjsofttech.com
Phone: 0484-2421245 / 928 720 7160",4.0,"MJ Softtech
4.0",Kochi,"Cochin, India",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
1524,Data Engineer,"Education/ Experience and Skill Requirement
4+ years of relevant experience in
Experience working with both relational and NoSQL databases.
Strong coding skills; Python (preferred) /R/Java/Scala
Experience in developing Data warehousing technologies Experience with AWS or equivalent cloud services preferred
Experience in BigData technologies (Hadoop, HDFS, MapReduce, Spark, Hive, HBase etc) will be valuable
Knowledge of Machine Learning a big plus (Random Forest, Decision Trees, SVM, NLP, Gradient Boosting, Supervised/Unsupervised Learning, Clustering, classification and regression modeling).
Responsibilities
Proficiency with several years’ experience in more than one of Python, R, Java, Scala, or robust Linux shell scripting
Implementation experience with data warehouse architecture & design, ETL design/development, and Analytics
Knowledge of general cloud architecture and cloud strategies especially around AWS services and concepts such as S3 object stores, RDS databases, EC2, Glacier, Lambda, IAM, enterprise security, data security, DevOps, replication and disaster recovery
Well versed with data mining & exploration, NLP and visualization
Understanding of data modeling, data integration, and data representation (metadata, OWL, ontologies)
Developing data marts and data management using SQL
Creating powerful visual outcomes
Independently manage daily client communication, especially over calls
Manage client deadlines, ensure quality of the deliverables, attention to detail
Experience/understanding of corporate finance data from company filings is desirable",3.6,"Copal Partners
3.6",Bengaluru,"New York, NY",10000+ employees,1900,Company - Public,Financial Analytics & Research,Finance,₹100 to ₹500 billion (INR),-1
1525,Data Engineer,"Job Description / Responsibilities
Build workflows to ensure data extraction quality and storage into our backend data store
Architect, build and train ML/AI models that can predict outcomes and report on anomalies.
Design data pipelines to perform ETL on content/data from multiple types of source systems.
Create data analytics views using RDBMS/Key-Value stores, on private and public/cloud
Create software that is well tested, maintainable, extensible and scales out with large data

Minimum Qualifications:
2+ years of software development with Python
2+ years of SQL (MySQL/Postgres) and Key-Value databases
1+ years of experience with scikit
2+ years of experience in data extraction, data transformation using custom Python/Java
Experience working with MapReduce/Hadoop/kafka/Elastic stack
Experience with Node backend and React/Redux
Experience working with git/mercurial, Amazon/Google cloud, Linux/LAMP stack
Experience in testing or test driven development
Experience with Data science and Machine Learning algorithm development

Location:
Hyderabad/Bangalore

Package:
Highly competitive to match experience and capability",3.7,"TVS
3.7",Bengaluru,"Chennai, India",5001 to 10000 employees,-1,Company - Private,Accounting,Accounting & Legal,₹100 to ₹500 billion (INR),-1
1526,Data Engineer,"Permanent position with US based client of iFlex.
Work Location: Bangalore
Experience Level: 2+ Years

Role:
As part of our global team you will work on the data platform reporting to the Data Engineering Lead. Your role includes specification, development, test and rollout of features on our data platform. You are expected to contribute to the vision, understand our product roadmap, integrate business value andclient experience and contribute to build an engineering culture within the team. This initiative is of critical important to the success of the organization and our roadmap, for instance, services like liquidity analytics, billing, client onboarding, reporting and others will rely on the data platform. Accurate, granular, complete and timely data will be our key differentiating factor and competitive advantage in the market place. We expect the successful candidate to deliver high quality software and to be passionate about data engineering..

Responsibility / Qualification:
Managing multiple tasks and use sound judgment when prioritizing.
Collaborating with global cross functional team in building customer-centric products.
Analyzing existing software implementations to identify areas of improvement and provide deadline estimates for implementing new features.
Updating and maintain documentation for team processes, best practices and software runbooks.
Establishing trusted partnerships with peers, product heads, and executive level stakeholders.
We are looking for someone who is passionate about technology and engineering.
Exceptional analytical skills and ability to apply knowledge and experience in decision-making to arrive at creative and commercial solutions.
Ability to leverage technology to deliver business value.
You are independent and comfortable in a fast paced, ambiguous and often multi-directional work environment.

Preferred Qualifications:
B.S. or higher in Computer Science.
Minimum 2 years of relevant professional experience using a modern programming language (preferably Java/Scala).
Experience leveraging test driven development technics.
Comfort with Agile operating models.
Team oriented.
Strong interpersonal and communication skills.
Energetic, self-directed, and self-motivated.
Experience with microservice architecture.
Experience with Kafka, MongoDB, Hadoop, Cassandra.
Experience with AWS.
Experience in Financial Services or Fintech.",-1,IFLEX,Bengaluru,"Moscow, Russia",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1527,CIEL/SEL/1941: Sr data scientist,"Mandatory skills required -
Databases (SQL, Oracle, Any RDBMS) - Should have working knowledge of atleast one database
PL/SQL Programming Languages
R, Python (Any One)
Inferential Statistics - Hypothesis, p-value, R2, RMSE, MAPE etc
Exploratory Data Analysis
Machine Learning Algorithms - Should have in-depth knowledge and implementation of atleast one algorithm

Responsibilities
: Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the why & how of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions

Education
Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics
Experience
Minimum years of related experience required: 3 years
Preferred years of experience: 5 years
Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desirable.

Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
1528,Data Engineer,Data Engineer,3.6,"Bookmyshow
3.6",Mumbai,"Mumbai, India",1001 to 5000 employees,2007,Company - Private,Ticket Sales,"Arts, Entertainment & Recreation",Unknown / Non-Applicable,-1
1529,Data Analyst,"Required Skills & Experience

We are looking for a Data Analyst Executive
Eligible Qualifications : B. Tech, BCA, M.Tech, MCA
Experience : 3-5 years, fresher’s can also be considered
Location of Job : Gurgaon/Connaught Place, New Delhi
Technicals Skills

Following technical skills are pre-requisite:
Well versed with Software development methodologies, such as SDLC (Software Development Life Cycle), DDLC (Document Development Life Cycle).
Database schema design and implementation
Should have worked in either of technologies Sql Query/ Tableau/ Excel (Macros)/ Access (Query) writing for data analytics.
For planning and coordinating activities, organizations remain in invariant communication with one another and the data transfer has to be performed efficiently and smoothly as possible.
He/ She should manage the execution of the technologies, help the businesses in utilizing the systems, and should be well versed with the basics of computer systems such as Networking, Installation of necessary software and hardware.
Ability to determine the interrelationships between solutions and requirements.
Ability to think analytically and should be a problem solver and logic building should be very strong.
Good interpersonal skills to form effective working relationships with people at all levels.
Excellent communication and presentation skills and strong written & oral English skills.
To know more about us visit us www.sspl.net.in or write to us at admin@sspl.net.in",-1,Substratal Solutions,Connaught Place,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1530,Artificial Intelligence Scientists,"Experience 2- 4 Years
Salary 4 LPA - 6 LPA
Job Location Chennai

Industry:
IT-Software / Software Services

Keywords:
Artificial Intelligence

About Job:
Must have Excellent knowledge in AI / Machine learning (Mandatory).
Machine learning frameworks like keras, tensor flow etc.
And also other big data tools like Hadoop etc, Must know R and python.
Good understanding in SDLC & Business cycle.",4.0,"Careerera
4.0",Chennai,"Wayland, MA",501 to 1000 employees,-1,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
1531,Senior Data Engineer,"About Us

upGrad is an online education platform building the careers of tomorrow by offering the most industry-relevant programs in an immersive learning experience. Our mission is to create a new digital-first learning experience to deliver tangible career impact to individuals at scale. upGrad currently offers programs in Data Science, Machine Learning, Product Management, Digital Marketing, and Entrepreneurship, etc. upGrad is looking for people passionate about management and education to help design learning programs for working professionals to stay sharp and stay relevant and help build the careers of tomorrow.
upGrad was awarded the Best Tech for Education by IAMAI for 2018-19
upGrad was also ranked as one of the LinkedIn Top Startups 2018: The 25 most sought-after startups in India
upGrad was earlier selected as one of the top ten most innovative companies in India by FastCompany.
We were also covered by the Financial Times along with other disruptors in Ed-Tech
upGrad is the official education partner for Government of India - Startup India program
Our program with IIIT B has been ranked #1 program in the country in the domain of Artificial Intelligence and Machine Learning
About the Role

We are looking for a Data Engineer to help us scale the existing data infrastructure and in parallel work on building the next generation data platform for analytics at scale, machine learning infrastructure and data validation systems.
In this role, you will be responsible for communicating effectively with data consumers to fine-tune data platform systems (existing or new), taking ownership and delivering high performing systems and data pipelines, and helping the team scale them up, to endure ever growing traffic.
This is a growing team, which makes for many opportunities to be involved directly with product management, development, sales, and support teams. Everybody on the team is passionate about their work and we’re looking for similarly motivated “get stuff done” kind of people to join us!

Roles & Responsibilities
Engineer data pipelines (batch and real-time ) that aids in creation of data-driven products for our platform
Design, develop and maintain a robust and scalable data-warehouse and data lake
Work closely alongside Product managers and data-scientists to bring the various datasets together and cater to our business intelligence and analytics use-cases
Design and develop solutions using data science techniques ranging from statistics, algorithms to machine learning
Perform hands-on devops work to keep the Data platform secure and reliable
Skills Required
Bachelor's degree in Computer Science, Information Systems, or related engineering discipline
6 + years’ experience with ETL, Data Mining, Data Modeling, and working with large-scale datasets
6+ years’ experience with an object-oriented programming language such as Python, Scala, Java, etc
Extremely proficient in writing performant SQL working with large data volumes
Experience with map-reduce, Spark, Kafka, Presto, and the ecosystem.
Experience in building automated analytical systems utilizing large data sets.
Experience with designing, scaling and optimizing cloud based data warehouses (like AWS Redshift) and data lakes
Familiarity with AWS technologies preferred
Qualification – B.Tech/M.Tech/MCA(IT/Computer Science)

Years of Exp – 6-9",3.5,"upGrad Education Private Limited
3.5",Mumbai,"Mumbai, India",501 to 1000 employees,2015,Company - Private,Education Training Services,Education,₹1 to ₹5 billion (INR),"Udacity, General Assembly, Springboard"
1532,BBRC-Genomics-Associate Scientist,"JOB DESCRIPTION

Designation: Associate Scientist

Job Location: Bangalore

Department: Translational Medicine- Translational Sciences

About Syngene

Incorporated in 1993, Syngene International Ltd. is an innovation-focused global discovery, development and manufacturing organization providing integrated scientific services to the pharmaceutical, biotechnology, nutrition, animal health, consumer goods and specialty chemical industries around the world. Syngene’ s clientele includes world leaders such as Bristol-Myers Squibb, Baxter, Amgen, GSK, Merck KGaA and Herbalife. Its innovative culture is driven by the passion of its 4240- strong team of scientists who work with clients from around the world to solve their scientific problems, improve R&D productivity, speed up time to market and lower the cost of innovation .

Job Purpose:
To play a key role in TM-TS, develop an early-stage research strategy, initiate and lead discovery programs while managing ongoing programs in TM-TS. The role will work part of TMTS, and work with internal and external collaborators .

Key Responsibilities:
Experience in isolating DNA and RNA from blood, tissues and FFPE samples and cell lines. Experience with optimization of extraction protocols and for parameters like yield, input sample quantities and sample types is important.
Expertise in PCR, qPCR, cDNA/gDNA library preparation. Exposure to microarray techniques.
Proficiency in preparation of libraries for Next Generation Sequencing of transcriptome and genome, with significant experience in optimization of parameters like input RNA/DNA quantities and sample type
Experience with single cell RNA-seq will be plus.
Experience with various NGS protocols (DNA Amplicon based, hybrid capture based low input, degraded DNA and RNA samples e.g. FFPE samples.
Strong understanding of experimental design and statistical principles behind experimental design and differential gene expression. Experience with analysis of single cell RNA-sequencing data will be a plus

Educational Qualification:
M.Sc or M. Tech in Biotechnology, Molecular biology or Biological Sciences,

Technical/functional Skills:
DNA/ RNA Isolation, Expertise in PCR, qPCR, Experience in NGS protocols

Experience:
2 to 5 Years

Behavioral Skills:
A proactive team player.
Ensure completion of experiments and generate accurate and reproducible data from experiments.
Ability to work independently, prioritize tasks and work on multiple projects simultaneously with; comfortable working in a dynamic environment with changing requirements.
Good oral and written communication and presentation skills to work in a multi-disciplinary team
Equal Opportunity Employer:
It is the policy of Syngene to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by applicable legislation or local law. In addition, Syngene will provide reasonable accommodations for qualified individuals with disabilities.",3.5,"Syngene
3.5",India,"BENGALURU, India",1001 to 5000 employees,1994,Unknown,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1533,Applied Scientist 1,"Position Requirements:
Master's degree in Computer Science, Computer or Electrical Engineer, Mathematics, or a related field plus at least one year of experience in the job offered or related occupations of Software Engineer, Software Developer, or a related occupation. Employer will accept a Bachelor’s degree and five years of experience in the job offered or a related occupation as equivalent to the Master’s degree and one year of experience. One year of experience in the job offered or related occupation must involve designing and developing large-scale, multi-tiered, distributed software applications, tools, systems and services using Java, Object Oriented Design and Distributed Programming].

Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, Oracle/Berkeley databases, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills

Amazon Selling Partner Services team drives the Selling On Amazon business and develops solutions that enable millions of sellers around the world to sell on Amazon's Marketplaces. More than half of shipments for Amazon customers are generated from this business. The team is focused on building a technology platform that will support the explosive business growth in existing markets, streamline the business for Amazon and the Selling partners and launch business in new markets and establish a fair marketplace.

Our team is seeking engineers with broad technical skills to help us optimize how we synthesize massive amounts of data and complex business rules into mission critical financial information. As a member of this team you will employ object oriented techniques in Java, and DynamoB, PostGres and ElasticSearch skills to help us support Amazon's next generation of selling partner services. Along the way you'll gain and leverage a unique understanding of how Amazon.com works; from the numerous software systems that comprise the website's back-end, to the details of our business model, and the relationships we're establishing with an ever-growing network of selling partners who depend on Amazon.com to run their businesses.

The ideal candidate will draw upon exemplary analytical, critical thinking, and problem solving skills, and a passion for maintaining highly reliable, distributed systems which operate 24/7/365. Successful members of this team collaborate effectively with internal end-users, aggressive cross-functional software development teams, and technical support/sustaining engineering teams to solve problems and deliver successfully against high operational standards of system availability and reliability. We look for engineers who are excellent communicators, self-motivated, flexible, hardworking, and who like to have fun!

Position Responsibilities:
Participate in the design, development, implementation, testing and documentation of large-scale, multi-tiered, distributed software applications, tools, systems and services using [Java, Object Oriented Design and Distributed Programming]. Translate functional requirements into robust, scalable, supportable solutions that work well within the overall system architecture. Participate in the full development cycle, end-to-end, from design, implementation, and testing to documentation, delivery and maintenance. Produce comprehensive, usable software documentation. Evaluate and make decisions around the use of new or existing software products and tools.

Preferred Qualifications
Familiarity with Ruby, Perl, JavaScript, AJAX, XML/XSLT, SOAP, SQL, caching technologies, web protocols, Web services technologies a strong plus.
Solid understanding of Object-Oriented design and concepts
Experience developing software in a Unix/Linux environment
Excellent communication and analytical skills",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1534,Senior Clinical Data Analyst,"About Novotech:

Novotech is internationally recognised as the leading independent and full-service contract research organisation (CRO) in the Asia Pacific region. We provide a wide range of clinical development services across all research phases and therapeutic areas and have been instrumental in the success of hundreds of Phase I – IV clinical trials throughout the Asia Pacific. Powered by the highest quality people, Novotech strives to set the benchmark for both business and clinical trial performance. Our people are one of our key strengths. We value our people and recognise the work they do. We are lucky to have the best people and talent from across the Asia Pacific region work together to deliver to clinical trial success for our clients. Our people and those we look to recruit have an attitude of making things happen. They are problem solvers, driven with a focus on delivering quality, accountability and a high level of performance.

Brief Position Description:

As part of Novotech’s Biometrics unit, the Senior Data Analyst (SDA) is responsible for all data analysis and business intelligence activities related to study related clinical and operational data. The SDA acts as primary point of contact for all data analysis matters to the study team and is responsible for the timely delivery of quality outputs following all applicable regulatory, compliance, best practice and operational procedures.

Minimum Qualifications & Experience:

Graduate in information science, data science or life science-related field, or similar. More than five years’ experience in a senior role related to data science, data analysis, clinical data management or clinical data programming in a pharmaceutical company, CRO or EDC software provider.

Responsibilities
The Senior Data Analyst (SDA) is responsible for providing technical, procedural (SOPs) and planning leadership across multiple projects assigned to the data analyst team members ensuring that they deliver in accordance with SOPs, programming best practices, and the timelines agreed within the Project Team.
Collaborate with cross-functional stakeholders to implement data science solutions to solve business needs using available technological solutions.
Scope data analysis effort for projects and project manage all data analysis activities across multiple projects for different study stakeholders.
Gather study requirements from data management for data review and external data reconciliation and provide guidance on appropriate outputs (dashboards, visualisations, listings, reports).
Extract, assess, integrate, transform data sources to provide data visualisation outputs for analytics.
Design and develop prototypes and final versions of data outputs (dashboards, reports, visualisations, listings) using Business intelligence tools and Data Visualisation tools.
Design and develop standard dashboards and content for different audiences.
Analyse, manipulate and understand data from multiple sources to present and create dashboards and reports to make business decisions.
Assist teams on best-practice for data visualisation dashboard development.
Educate teams on how to use all the features of applicable data visualisation platform in conjunction with data visualisation dashboards.
SME for the data visualisation development and assisting team members.
Identify and communicate project risks and maintain documentation within project files as appropriate
Represent data analysis group at internal / external meetings as appropriate.
Assess and implement new data analysis, BI and data visualisation processes and technologies.
Take an active role in the development of best practices, process improvement, quality control and governance related to all data analysis matters.
Provide training and mentoring to Data Analysis of team members in SOPs, software applications, and best practices.
Provide Subject Matter Expertise on all data analysis and visualisation related activities.
Attributes and Skills

Expert knowledge of clinical study data structures and schemas of EDC databases. Expert knowledge in data processing activities such as extracting, integrating, transforming and presenting data. Statistical Programming skills in Python, R or similar. Knowledge of SQL and EDC systems. Working knowledge of Spotfire, Power BI, Tableau or other data review and visualisation tool. Ability to gather business requirements from multiple stakeholders and clients and provide guidance on the use of appropriate data visualisations.

Experience mentoring and training others. Awareness of regulatory and compliance issues and understanding of the application of SOPs and Quality Control to daily activities. Excellent analytical, communication and problem-solving skills.

Opportunities and Benefits:

To deliver clinical trial and research excellence for our clients, our people are 'best in class'.

At Novotech, we seek and nurture people with exceptional talent. We are committed to providing our people with regular internal and external training, a competitive bonus structure and a supportive work environment. We are also focused on providing our people with a wide variety of career growth and development opportunities.

For more information about where your next career step at Novotech might take you, visit http://novotech-cro.com/novotech-careers",4.5,"Novotech
4.5",Bengaluru,"Sydney, Australia",501 to 1000 employees,1996,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
1535,Data Engineer,"Data Engineer Responsibilities:
Liaising with coworkers and clients to elucidate the requirements for each task.
Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed.
Reformulating existing frameworks to optimize their functioning.
Testing such structures to ensure that they are fit for use.
Preparing raw data for manipulation by Data Scientists.
Detecting and correcting errors in your work.
Ensuring that your work remains backed up and readily accessible to relevant coworkers.
Remaining up-to-date with industry standards and technological advancements that will improve the quality of your outputs.
Data Engineer Requirements:
Bachelor's degree in Data Engineering, Big Data Analytics, Computer Engineering, or related field.
Master's degree in a relevant field is advantageous.
Proven experience as a Data Engineer, Software Developer, or similar.
Expert proficiency in Python, C++, Java, R, and SQL.
Familiarity with Hadoop or suitable equivalent.
Excellent analytical and problem-solving skills.
A knack for independent and group work.
Scrupulous approach to duties.
Capacity to successfully manage a pipeline of duties with minimal supervision.
Job Type: Full-time

Salary: ₹360,000.00 to ₹870,000.00 /year

Experience:
total work: 2 years (Preferred)
Data Engineer: 1 year (Preferred)
Education:
Diploma (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,Futurious Technologies,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1536,Quantitative Analyst,"The successful candidate will be a highly analytical individual with hands on programming skills. The candidate will work closely with the research team and clients towards the ongoing development and integration of new investment strategies, models and tools on Axle

Location

Mumbai
Responsibilities

Perform daily/weekly/monthly tasks of performance and risk reporting
Develop and automate investment processes and strategies via VBA and Matlab
Develop tools to integrate trading decision systems with risk management systems
Ad hoc tasks (such as operational tasks, internal documentation tasks and preparation of marketing materials)
Skills/Experience

Excellent programming skills in Matlab/Excel-VBA
Thorough with financial concepts and calculations like Drawdown, VaR, Eloss etc.
Understanding of financial market products like options, futures, FX forwards etc.
Working knowledge of Bloomberg is preferred
Should be self-driven and detail oriented with an analytical mindset
Should be a proactive and quick learner; a team player showing enthusiasm and drive to accomplish results in a fast paced environment
Min. 2 years of relevant work experience
Qualifications

B.Tech/M.Tech/MBA/CFA/FRM",5.0,"B&B Analytics
5.0",Mumbai,"Zug, Switzerland",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1537,Analyst - Data Scientist,"Job Summary

Experience:
3 - 5 Years

Location:
Mumbai

Designation:
Analyst - Data Scientist

Degree:
BE-Comp/IT, BE-Other, BTech-Comp/IT, BTech-Other, ME-Comp/IT, ME-Other, MTech-Comp/IT, MTech-Other, PhD-Comp/IT, PhD-Other

Educational Level:
Graduate/Bachelors

Industrial Type:
IT-Software/Software Services

Functional Area:
IT Software - Application Programming / Maintenance

Key Skills:
Data Scientist

Job Post Date:
Thursday, March 19, 2020

Company Description

We are capability centre based in Mumbai, initially started as a back-office operational support to the UK business unit.

However, over the recent years, we have significantly increased the breadth and depth of our capabilities and offerings to keep pace with the changing needs of the Group. These include Digital & Knowledge Services, Finance and Actuarial, Information Technology (IT), Customer Service, Risk and Audit.

Our core purpose is to be a strategic partner to company, enabling growth by delivering change and driving synergies through a highly capable and agile workforce.

With our diversified service offerings we provide our people with exciting opportunities to grow personally and professionally.

Company is a leading savings and investments business serving around 5.5 million retail customers and more than 800 institutional clients.

It-s innovative asset management and customer solutions are supported by extensive investment capabilities, an international distribution network and two strong brands.

Job Description

3 – 5 yrs experience as Data Scientist
Should have at-least 1 end-to-end ML project experience
Very high proficiency in R or Python
Excellent in forecasting methods like simple exponential smoothing, multiplicative seasonal indexes, simple and weighted moving averages and time series forecasting methods
Exposure to with advanced deep learning techniques such as LSTM. CNN, Dense neural networks as well as neural networks design and implementation through tools like tensorflow, keras, pytorch, deepai or equivalent.
Good SQL experience",3.8,"Sampoorna Computer People
3.8",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
1538,Data Lake Developer,"For Us, It's A Mission

At Mylan, we mean it when we say we work every day to provide access to high quality medicines to the world's 7 billion people. If you are unconventional, relentless and passionate. If you believe in doing what's right, not what's easy. If you are a doer and have a passion for serving others, we want to talk to you.

Make a Difference

At Mylan, each person has the ability to make a difference. From the providers who sell and market our products, to the producers who develop and manufacture them and finally to our business partners who support the providers and producers, we all have a mission critical role. Here's how this role will help:

ESSENTIAL DUTIES AND RESPONSIBILITIES
To perform this job successfully, an individual must satisfactorily perform each essential duty. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential duties.
1. Create and maintain optimal data pipeline architecture on Azure platform.
2. Develop batch processing solutions by using Data Factory and Azure Databricks.
3. Delivering a Data Warehouse in the Azure Cloud.
4. Design relational and non-relational data stores on Azure.
5. Identify, design, and implement internal process improvements : automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc..
6. Developing Big Data Solutions with Azure Machine Learning.
7. Strong interaction with business departments to provide consultative support for digitization efforts, as well as close collaboration with the Business Technology management, focused on future innovation topics.
8. Participate and lead in design sessions, demos and prototype sessions, testing and training workshops with business users and other IT colleagues.
9. Design & Build for any API Development or SQL DB development.
10. Providing service management, orchestration, monitoring and management requirements of Azure cloud platform.
11. Create data tools / products for analytics and data scientist team members that assist them in building and innovative solutions that drive tangible business value.
12. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
13. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
14. Design security for source data access. Chose the appropriate authentication mechanism, (ie Azure Active Directory (Azure AD), etc).
15. Design for real-time processing by using Stream Analytics and Azure Databricks.

Make Our Values Your Values

Mylan hires only the best. People who thrive in a culture of innovation and empowerment. People who are active learners and have a positive attitude. People who are leaders and know that by working together we can run faster, reach higher and achieve more. By doing so, we will continue to set new standards in health care. Here are the minimum qualifications and essential functions for this position:

QUALIFICATIONS

The qualifications listed below are representative of the minimum knowledge, skill, and/or ability required.

SKILLS AND ABILITIES

1. 10 years of experience in Microsoft technologies including SQL.

2. At least 5 years as a Sr Developer with at least 3 years hands on experience as Azure Data Engineer building large scale Azure data solutions.

3. At least 5 years of experience in Azure based data solutions.

4. At least 3 years of experience on working with large projects including the most recent project in the cloud (Azure) or on prem with a focus on Azure Data services.

5. At least 5 years of Hands-on administration, configuration management, monitoring, performance tuning of Hadoop/Distributed platforms.

6. At least 5 years of demonstrated experience at least in the most recent 2 years of designing and delivering solutions using Cortana Intelligence suite of analytics services part of Microsoft Azure including Azure Machine Learning Studio, HDInsight, Polybase, Azure Data Lake Analytics, Azure Data Warehouse, Streaming Analytics, Data Catalog, R/R Studio

7. Experience in designing and building logics required for optimal extraction, transformation, and loading of data from a wide variety of data sources

8. Experience within Data Security design, including but not limited to:

a. Choosing the appropriate authentication mechanism, such as Azure Active Directory (Azure AD)

b. Defining strategies for data encryption for data at rest and in transit

9. Experience partnering with Business Analysts and Data Scientists to enable effective and efficient data preparation and delivery

10. Experienced in vendor management and working with 3rd parties onshore & offshore.

11. Experience working in a global team.

12. Experience working in an Analytics / Big Data solutions on MS Azure Cloud

13. Experience with code management tools, automated testing

14. Experience creating and maintaining optimal data pipeline architecture on Azure platform

15. Experience developing batch and real-time processing solutions by using Data Factory and Azure Databricks

16. Familiar with AGILE and Azure DevOps methodology

17. Hands on PoC capabilities are needed to prove a particular architecture concept

18. Azure Native Services experience across Data Fabric and Service Fabric

19. Experience in Application modernization from legacy on-premise data architecture platform technology stack to modernized Azure Cloud base Architecture.

20. Experience with Git, NoSQL Data Solutions, Microsoft Azure, HD Insights, Azure ML, DataBricks ML Flow, R or Python.

21. Must have excellent communication skills.

EDUCATION/EXPERIENCE (Note: Please select one)

Minimum of a Bachelor's degree in Computer Science and Engineering is preferred with minimum 10 years of experience. However, a combination of experience and/or education will be taken into consideration

Why Mylan?

If you want to be part of a global health care company that is making a difference and changing lives, Mylan may be the place for you. With a workforce of more than 35,000 worldwide, we can make a difference. We encourage you to visit Mylan.com to learn more about our unconventional culture, our approach to doing business and how we plan to set new standards in health care.

Mylan offers competitive salary, excellent benefits and an environment conducive to professional growth and advancement. All qualified applicants will receive consideration for employment without regard to their disability or protected veteran status. Mylan is an Equal Opportunity Employer, Minorities/Female/Disabled/Veteran.",3.8,"Mylan Inc.
3.8",Bengaluru,"Hatfield, United Kingdom",10000+ employees,1961,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
1539,Off Campus Recruitment - Quantitative Researcher,"Description:
Graviton is a privately funded quantitative trading firm striving for excellence in financial markets' research. We are seeking fresh talent from the top IIT's to join us as Quantitative Researchers for our team in Gurgaon.If you are a student graduating in 2020 from Computer Science , Electrical or Maths Stats Computing streams with a greater than 8 CGPA please apply here.

This role is open to students from campuses that we could not visit this year. Please check your individual placement policy restrictions before applying.

Graviton trades across a multitude of asset classes and trading venues using a gamut of concepts and techniques ranging from time series analysis, filtering, classification, stochastic models, pattern recognition to statistical inference analysing terabytes of data to come up with ideas to identify pricing anomalies in financial markets.

As a Quantitative researcher your responsibilities will include

Develop new or improve existing trading models using in-house platforms

Use advanced mathematical techniques to model and predict market movements

Analyse large financial datasets to identify trading opportunities

Provide real time analytical support to experienced traders

Requirements :
Possess a degree in a highly analytical field, such as Engineering, Mathematics, Computer Science from IITs schools

Quantitative bend of mind

A working knowledge of Linux/Unix

Programming experience, preferably in C++ or C

Strong interest in learning about financial markets.

Have a strong work ethic

Hard Working

Benefits:
Our open and casual work culture gives you the space to innovate and deliver. Our cubicle free offices , disdain for bureaucracy and insistence to hire the very best creates a melting pot for great ideas and technology innovations. Everyone on the team is approachable, there is nothing better than working with friends!

Our perks have you covered.

Competitive compensation

6 weeks of paid vacation

Monthly after work parties

Catered breakfast and lunch

Fully stocked kitchen

Gym membership

International team outing",5.0,"Graviton Research Capital LLP
5.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2014,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1540,Data Engineer,"Zauba Technologies is a startup based in Bangalore. Zauba's services are used by leading companies in India. Zauba is powered by a young and passionate team. We are looking for individuals who would like to be a part of our founding team.

As a Data Engineer and as a part of founding team, you will be expected to visualise and develop disruptive data products. Eventually you would be responsible for entire project lifecycle of products you would visualize. Your rewards will be directly proportional to the value you generate.

Job Responsibilities
Design and development of robust, scalable and highly efficient data engineering solutions for structured and unstructured data (Including gathering and processing raw data at scale, writing scripts, web scraping, calling APIs, writing SQL queries, etc.)
Develop processes for text mining and extraction of information from unstructured data
Design, architect and develop efficient data pipelines around the data collected
Take ownership of existing web product and applications
Design and implement data models that scale across the enterprise
Take ownership of existing data workflows and processes
Enhance scalability, performance, and stability of existing infrastructure
Work closely with other team members to integrate your innovations and algorithms into our production systems

Essentials
Java/Python - Intermediate to advanced level
SQL - Advanced
MySQL Intermediate to advanced level
Regex - Basic to intermediate level
Linux Basic to intermediate level

Good to have
Hadoop/Spark
R
MongoDB

Must have qualities
Skills to learn new skills quickly
Desire to create disruptive products and services
Passion - not just to work in startups but to take them to next level
Above average programming aptitude
Be passionate about producing high quality engineering deliverables
Be productive working independently or collaboratively
Have an eye for building efficient processes
Be self motivated
Proactively take ownership

Interested?

Send your resume to hr@zaubacorp.com",3.8,"Zauba Corp
3.8",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 million (INR),-1
1541,Quantitative Research,"We are looking for highly trained professionals who are interested in applying advanced mathematical quantitative methods to the modeling of global financial markets. You would be joining a group made up of highly proficient individuals from various scientific disciplines. We have a spectrum of opportunities for individuals with the right scientific skills. Experience in finance is not required.

The ideal research candidate will have:
A Ph.D. in Computer Science, Mathematics, Physics, Statistics, or a related technical discipline.

A demonstrated capacity to do first-class research.

Computer programming skills.

An intense interest in applying quantitative analysis to solve difficult problems.

Send us a copy of your resume to
careers@dolatcapital.com

For internship opportunities, please send us a copy of your resume to
careers@dolatcapital.com",4.0,"Dolat Capital
4.0",Mumbai,"Mumbai, India",51 to 200 employees,1970,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
1542,Data Engineer,"Bachelor’s degree in Computer Science or related field
5+ years relevant experience
5+ years experience with SQL, SQL Tuning, Oracle, OLAP, Big Data Technologies
5+ years experience developing end-to-end Business Intelligence solutions: data modeling, ETL and reporting
Experience with Java and experience with scripting languages like Perl, Python, Unix shell scripts,VBA and MS Excel
Proficiency with Linux and systems administration
Proven ability at looking at solutions in unconventional ways. Sees opportunities to innovate and can lead the way.
Top notch communication (verbal and written) and interpersonal skills to convey key insights from complex analysis in summarized business terms and an ability to effectively communicate with technical teams.
Ability to work with shifting deadlines in a fast paced environment.
Operations Finance Technology team, responsible for building technical solutions for multi-billion WW Operational Cost analytic including Inbound cost (Receiving / PO), variable Cost, fixed cost, outbound (Customer Shipments / Transportation), and Customer Service, is looking for a Data Engineer.

As a data engineer, you will get the exciting opportunity to work on very large data sets in one of the world's largest and most complex data warehouse environments. You will work closely with the business teams in analysis on various cost savings initiatives, many non-standard and unique business problems and use creative-problem solving to deliver actionable output.
You will be responsible for designing and implementing an analytical environment using third-party and in-house reporting tools, modeling metadata, building reports and dashboards. You will have an opportunity to work with leading edge technologies like Redshift, Hadoop/Hive/Pig. You will be writing scalable queries and tuning performance on queries running over billion of rows of data.

You should be analytical, have an extremely high level of customer focus and a passion for process improvement. You should be motivated self-starter that can work independently in a fast paced, ambiguous environment. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions.
Bachelors in Computer Science or related field
Practical Knowledge of Linux or Unix shell scripting
Experience in working with business customers to drive requirements analysis
Exposure to large databases, BI applications, data quality and performance tuning
Excellent written and spoken communication skills
Experience with Hadoop-based technologies such as HBase, Pig, Hive and Spark
Strong proven ability in building high-performance, highly available and scalable data solutions using Oracle and/or Hadoop-based technologies
Knowledge of data warehousing concepts.
Strong sense of ownership, urgency, and drive
Strong troubleshooting and problem solving skills
Experience with Amazon Web Services",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
1543,DATA ANALYST,"posted by Mahima Gaur

2 - 5 years Delhi

Job Description
Experience in data processing
Experience in data cleaning and data tabulation activities
Strong analytical, communication and team management skills
Strong understanding of data management using SPSS and research techniques
Competency in a Tabulation software (decipher / wincross / quantum etc), Excel, Powerpoint
Ability to summarize findings, draw conclusions, and put together a presentation using Powerpoint
Role Category : Data Analyst

Employment Type : Permanent Job, Full Time",4.9,"Knowledge Excel Services.
4.9",New Delhi,"New Delhi, India",1 to 50 employees,2007,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
1544,Data Engineer,"Key skills : Python , Spark , SQL , Pyspark • AWS platform used for the work • Strong experience in SQL is mandatory • Good familiarity of AWS landscape • Good experience in collecting business requirements & design them as per requirement from customer • Should able to work independently & interact business users & technical stakeholders • Strong communication skills both oral & written. • Should work as an individual resources",3.5,"Larsen & Toubro Infotech Limited
3.5",India,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1545,Big Data Engineer,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
1546,Client Data Analyst,"At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.
What is the Client Data Analyst – Client Analytics group responsible for?
This team manages business data to ensure accurate, timely, consistent and compliant data. Their contributions deliver quality data that is easily accessible and can be trusted. Key downstream capabilities such as reporting and analytics depend on this as well as operational data access on various systems. The Data Management Team is a support function that acts as an advocate and a point of contact for Sales and Marketing data.

What are the ongoing responsibilities of an Client Data Analyst ?
Understand the data flow, key consumption and production of data as well as context within the enterprise:
Build positive relationships with teams, especially the key data consumers and analytics. Take the time to increase knowledge of how they run their business and incorporate sales data into daily work
Connect regularly with each sales office to understand current issues and challenges. Probe the business and validate against other sales offices to understand the scope and priority of the issue
Make recommendations on how data unifications and flow can be used to improve business tasks. Liaise business partners to deliver solutions (reports, processes, technology) that add value.

Provide data management subject matter expertise. Appreciate the connection and data flow between applications and other corporate systems. Be able to clearly articulate the data needs and move initiatives forward by collaborating with business partners:
Actively participate in meetings with business partners to ensure that priorities are clearly understood, information is regularly shared and that key participants are “kept in the loop”
Provide context and background on issues. Collaborate on ideas for progressing initiatives. Ensure appropriate resources are involved to take initiatives forward
Provide insights and expertise to scope statements and requirements documentation
Actively consult or participate in the user acceptance testing process (test cases, documentation, testing execution, etc.)
Ensure business needs remain aligned with overall corporate initiatives and deliver the benefits as originally intended

Monitor the integrity of data and usefulness of reports. Ensure the information available within systems is accurate and up-to-date. Proactively seek data cleansing opportunities and evolve data to better support. Document and maintain ongoing processes for reporting and data clean-up:
Partner with all key data consumers to gain a solid understanding of usage and challenges around data. Establish processes for prioritization of enhancements, especially with the analytics groups
Provide 1st level support for data issues and data maintenance for owned data
Verify and execute data loads into our internal sales systems and ensure any upstream systems accurately receive their data

Increase awareness and promote data management capabilities. Share best practices and provide coaching to local offices on how to access and incorporate output into sales tasks. Encourage IAS leaders to leverage data to make more informed, strategic decisions:
Clearly articulate the goals and core services of the data management team. Proactively promote this information within IAS and ensure business partners understand the data management role within the organization
Share best practices and provides guidance on data capabilities. Reinforces ownership and accountability for data accuracy
Seek opportunities to share the benefits of leveraging sales data to make more informed business decisions

What ideal qualifications, skills & experience would help someone to be Successful?

Knowledge, Education And Experience:
Four year bachelor’s degree required (majors of preference include: business, computer science, mathematics) Advanced degree a plus
Understanding of the Franklin Templeton business model, how FT makes money, the sales process, how technology fits in with the business, etc. Knowledge of the GAS (Global Advisory Services) structure
Experience working through multiple business fiscal cycles; exposure and/or direct experience with project management and/or sales-related-capacity required
Prior work experience related to analytics, sales, marketing and/or international a must. Level will not be granted based on years of experience but will be determined by the employee’s ability to meet each job activity as outlined the ‘typical/expected focus by level
Skills And Abilities:
Ability to communicate effectively with all levels of management; ability to tailor communication style based on audience; ability to get others to want to collaborate with you; strong facilitation skills
Excellent writing skills (for presentations, documentation, etc.)
Working knowledge of the CRM, MDM, Excel, SQL, Power BI, Tableau, Business Objects, and Microsoft Products (PPT, Power Apps, Doc, Visio)
Ability to absorb and interpret large quantities of data; apply trend analysis and knowledge of the business to develop a meaningful and digestible summary with the appropriate level of detail
Ability to take a larger problem and break down the individual components; identify how to go about solving the problem and who to involve in the process
Ability to present recommended solutions to a variety of issues and problems (solutions that are consistent with organization objectives)
Must be extremely detail-oriented (managing lists, tasks/to-dos, etc.) good with follow through on own items; good with following up with others on outstanding item

What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.

Highlights of our benefits include:

Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.",3.8,"Franklin Templeton Investments
3.8",Hyderabad,"San Mateo, CA",5001 to 10000 employees,1947,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Fidelity Investments, Vanguard"
1547,Data Analyst,"Roles and Responsibilities:
Extracting, transforming and inputting data sets from various resources. Creating predictive models, translating non-technical aspects into quantifiable tasks. Analysis and representation of output data, highlight and explain trends and patterns, error elimination, using advanced statistical methods (regression, probability distribution, clusters etc.) to provide accurate results.
Data collection, Data Mining, Report generation, Problem identification and solution formulation Market analysis and establishing trends, Strategy development and implementation

Skills:
Extremely good analytical skills.
Good working knowledge of all MS-Office products, especially Advance Excel, Word, PowerPoint, MS-access.
Statistical tools and methods.

Interested candidates can send the updated resume on satish.mehra@exelaonline.com or call on 7722028636
00-7.00 Years",2.6,"Exela Technologies
2.6",Pune,"Irving, TX",10000+ employees,2017,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"SourceHOV, BancTec, Transcentra"
1548,Data Modeler,"• Minimum 5-8 years of working experience as Data modeler.
• Data modelling experience in designing.
• Minimum 2-3 years real time experience in Erwin tool is mandatory.
• Experience in normalized modeling techniques.
• Experience in designing the Start schema.
• Experience working in ORACLE.
• Experience with database design, capacity planning, performance tuning and query optimization.
• Experience in working with Bank or Banking and Finance or Financial domain.
• Excellent communication skills with leadership quality.

Job Segment:
Database, Oracle, ERP, Technology",3.5,"LTI
3.5",Mumbai,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
1549,Machine Learning Engineer,"Looking for Data Scientists with Python/R Programming skills.
Specific experience in AI areas like Statistical Machine learning / Deep learning / Natural Language Processing (NLP)/ Operations Research (Optimization) will be an advantage.Individual in this role is expected to work with multiple stakeholders and teams

Qualifications and Requirements:-
Previous working experience as a Machine Learning/ Data Scientist for 2 years
MA in Computer Science or similar relevant field
Hands on experience with MALLET
In depth knowledge of Apache Tomcat/Open Source
Excellent project and time management skills
Attention to detail
Outstanding problem solving and analytical skills",-1,Tekolutions.ai,India,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
1550,Data Science Internship,"About the company:
SkillBit is a leading staffing and recruitment company engaged in talent searching assignments for skilled and talented candidates for the industry.

About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Working on data science algorithms and AI concepts 2. Using Python or R for web scraping 3. Building AI models using Python, machine learning, and deep learning algorithms 4. Processing of unstructured/structured data

Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 6th Jun'20 and 11th Jul'20
are available for duration of 1 month
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply

Number of internships/jobs available: 3

Categories: Data Science",-1,SkillBit,Pune,-1,-1,-1,-1,-1,-1,-1,-1
1551,Data Engineer,"As a data engineer at TEAL, you'll be taking the plunge into a rich data lake that includes everything from satellite data to legal court orders. You'll be hustling and getting your hands dirty with every part of the data pipeline always having an implicit appreciation for how all of this data will ultimately power a revolutionary real estate risk platform.

Your day-to-day will include either all or some of the following:

Constantly scoping out new data sources to complement existing ones
Creating and maintaining distributed web scrapers using Python, RabbitMQ and other technologies
Architecting and managing data pipelines where data flows into multiple end-points including, but not limited to, Postgres, MongoDB and Apache Solr
Documenting workflows and constantly iterating to create better data infrastructure.

We'd love it if you:
Are proficient in Python or any other object-oriented language
Have worked with large (millions to hundreds of millions of rows in a SQL database) interdisciplinary datasets
Have scraped difficult websites and have some experience working with various data APIs
Are patient and methodical with unstructured and messy data
Are always hungry to learn newer and better technologies to make the data ecosystem faster, smoother and less silo-ed

Extra brownie points if you:
Have some experience working with large-scale search indexing
Have performed geospatial analyses in some capacity
Have created and managed data lakes in the cloud
Culture

To explore our culture and the values we embody click here

Testimonials
Testimonial

My experience at TEAL surpassed all my expectations from the get-go. I was asked to help solve one of the most daunting problems in the Indian real estate market. Every day while working on a subset of the problem, the ideas that I brought to the table were shaped into cohesive solutions by a collaborative team effort. At TEAL I was exposed to the most cutting edge technologies such as Cloud Computing, Big Data, ML and Data Science. The growth opportunities at TEAL are tremendous, If you are innovative and can demonstrate the will to realize your ideas, TEAL is an amazing organization to work for.
Gyan Vardhan, Data Science Intern
I had interned as a Data Scientist at Terra Economics and Analytics Lab during its early days, it was a rich learning experience working with a multi-disciplinary team who are extremely passionate about building a decision support platform for the insanely complicated realty market in India. It was exciting and challenging to work on mining huge volumes of property records; extracting patterns from the data, building data pipelines and brainstorming on building the core system. TEAL offers a very healthy work environment coupled with insanely talented people working together in an exciting setting.
Naga Anjaneyulu, Data Science Intern
I worked as a full-time Data science intern at TEAL. During this period, I got an opportunity to leverage my skillsets while also learning new technologies, working on tasks assigned to me. The company operates on the latest tech-stacks and gives opportunities to learn as much as you want. The work environment is challenging, the team at TEAL is super supportive and new ideas are always welcome. It has all the good perks of a startup; creativity and innovation, casual work atmosphere and a collaborative approach to solving problems. Personally, I loved working there, my experience was fantastic!
Archana Parmar, Data Science Intern
As a second-year college student, I was looking for an internship that would allow me to delve deeper into research and work with big data, TEAL gave me the perfect opportunity to do so, enabling me to develop proficiency in research and analysis. As a research analyst intern, I collated and cleaned data and helped in the preparation of reports and presentations, and I had members helping me at every stage of this process. This collaborative environment allowed me to cultivate my skills and also learn from my peers. The holy trinity of Rohan, Kshitij, and Shreyas served as not only excellent mentors and bosses but also as friends, helping me at every stage and giving us all food and ice cream to keep us going!
Arush Mehra, Research Intern
Internships are a crucial part of one’s early career. The internship experience at TEAL was a thrilling rollercoaster ride to say the least! It was more than implementing a standard model or building an already though out concept into reality. It was about finding the solution to a unique and open-ended problem.It was exciting to work on addressing a problem with far -reaching real world applications.Moreover, the work environment had the perfect balance of casual yet professional which kept you focused and stress free at the same time. Out of every 100 startups in India only 2 of them succeed, but there are very few like TEAL India which are bound to make it big at such an early stage.
Divyanshu Agarwal, NLP Intern",4.7,"Terra Economics & Analytics Lab (TEAL)
4.7",New Delhi,"Bengaluru, India",1 to 50 employees,2018,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
